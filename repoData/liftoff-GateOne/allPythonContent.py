__FILENAME__ = app_example
# -*- coding: utf-8 -*-
#
#    LICENSE: Public Domain with NO WARRANTY.  Feel free to use it as a base
#             for developing your own Gate One application(s).  You may then
#             use whatever license you see fit.
#

__doc__ = """\
A Gate One Application (`GOApplication`) that provides an example of how to
write a Gate One Application.

.. note::

    This application is hidden by default to show it make sure to set the
    ``HIDDEN`` variable to ``False``.
"""
HIDDEN = True

# Meta information about the plugin.  Your plugin doesn't *have* to have this
# but it is a good idea.
__version__ = '1.0'
__license__ = "Public Domain" # Replace this with your own license
__version_info__ = (1, 0)
__author__ = 'You <you@domain.com>'

# Import stdlib stuff
import os

# Import Gate One stuff
# These are things you'll definitely need:
from gateone.core.server import GOApplication
from gateone.auth.authorization import require, authenticated
from gateone.auth.authorization import applicable_policies, policies
from gateone.core.log import go_logger # So your app will have its own log
# These are things you'll *probably* need:
from gateone.core.server import BaseHandler
from gateone.core.utils import bind
# If you want your app to be able to use its own plugins you'll need these:
from gateone.core.utils import get_plugins, load_modules
# You can use this for providing localization but you could just use the stdlib
# gettext stuff if you want:
from gateone.core.locale import get_translation


# 3rd party imports
# You can add command line options to Gate One with define():
from tornado.options import define, options
# You need 'options' to get define()'d values

# Globals
SESSIONS = {} # This will get replaced with gateone.py's SESSIONS dict
# NOTE: The overwriting of SESSIONS happens inside of gateone.py as part of
# the application initialization process.
APPLICATION_PATH = os.path.split(__file__)[0] # Path to our application
web_handlers = [] # Populated at the bottom of this file
example_log = go_logger("gateone.example") # Our app's logger
# NOTE: You can pass additional metadata to logs which will be JSON-encoded
# when your messages are logged.  Examples of how to do this are further along
# in this file...

# Localization support
_ = get_translation() # You don't *have* to do this but it is a good idea

# This is how you add command-line options to Gate One:
define(
    "example_option", # NOTE: underscores are the preferred word separator here
    default=True,
    help=_("Doesn't do anything (just an example from the example app).")
)
# You could then reference this option like so:
# print(options.example_option)

ALLOW = True # Used by polcy_example() below
def policy_test_example(cls, policy):
    """
    An example policy-checking function.  It will return ``True`` if conditions
    are met.  ``False`` if not.

    This function just checks that the ALLOW global is set to ``True`` but you
    can have functions like this check whatever you want.  It will have access
    to the current instance of your application via ``cls.instance``.

    See the comments for details on how it works.
    """
    instance = cls.instance # This is how to access the current app instance
    session = instance.ws.session # The user's session ID
    user = instance.current_user # The current user dict
    # If you want to check the arguments passed to the decorated function you
    # can examine cls.f_args:
    f_args = cls.f_args # Wrapped function's arguments
    # You can access keyword arguments the same way:
    f_kwargs = cls.kw_args # Wrapped function's keyword arguments
    function = cls.function # Wrapped function (in case you need it)
    # Here's how to get the locations dict (if your app supports this feature):
    locations = SESSIONS[session]['locations']
    if ALLOW:
        return True
    else:
        example_log.error(_(
            "%s denied access to the 'test_example' function by policy."
            % user['upn']))
        return False

def example_policies(cls):
    """
    This function gets registered under 'example' in the
    :attr:`gateone.ApplicationWebSocket.security` dict and is called by the
    :func:`auth.require` decorator by way of the :class:`auth.policies`
    sub-function. It returns ``True`` or ``False`` depending on what is defined
    in the settings dir and what function is being called.
    """
    instance = cls.instance # Your Application instance
    function = cls.function # Wrapped function
    f_args = cls.f_args     # Wrapped function's arguments
    f_kwargs = cls.f_kwargs # Wrapped function's keyword arguments
    # This is a convenient way to map function/method names to specific policy
    # functions:
    policy_functions = {
        'test_example': policy_test_example,
    }
    user = instance.current_user
    # The applicable_policies() function takes an application 'scope', a user
    # dict (must have a 'upn' key), and a dict that contains all of Gate One's
    # settings (always available via ApplicationWebSocket.prefs) and returns
    # a single dict containing the merged settings (aka policies) for that
    # scope.
    # In other words, if you have this inside a file in gateone/settings/:
    #    {
    #        "*": {
    #            "example": {
    #                "foo": "bar"
    #            }
    #        },
    #        "user.upn=joe@company.com": {
    #            "example": {
    #                "foo": "joe!"
    #            }
    #        }
    #    }
    #
    # applicable_policies() would return:
    #
    #    {"foo": "bar"}
    #
    # for regular users but joe@company.com would get:
    #
    #    {"foo": "joe!"}
    policy = applicable_policies('example', user, instance.ws.prefs)
    if not policy: # No policies found for the given scope
        return True # A world without limits!
    # Check the basics first...  Is {"allow": true}?
    if 'allow' in policy: # Only check this if there's an "allow" somewhere
        if not policy['allow']: # User is DENIED!
            example_log.error(_(
                "%s denied access to the Example application by policy."
                % user['upn']))
            return False
    # Here we run through our policy_functions dict and call the appropriate
    # policy-checking function that matches the decorated method's name:
    if function.__name__ in policy_functions:
        return policy_functions[function.__name__](cls, policy)
    return True # Default to permissive if we made it this far

class ExampleHandler(BaseHandler):
    """
    Renders example.html to demonstrate how to add a URL handler to an
    application.
    """
    def get(self):
        # Our example.html template is inside the application's 'templaces' dir:
        template_path = os.path.join(APPLICATION_PATH, 'templates')
        example_template_path = os.path.join(template_path, 'example.html')
        self.render(
            example_template_path,
            foo="bar" # An example of passing a value to a template
        )

# Notice that I've scattered many calls to example_log.debug() and
# example_log.info() throughout this app.  Be sure to use your own logger
# instead of just 'logging.<level>' so that your application logs can be easily
# differentiated from other parts of Gate One.  All logs still go to the main,
# 'gateone.log' so you don't have to worry about being cut out of the fun :)
class ExampleApplication(GOApplication):
    """
    A Gate One Application (`GOApplication`) that serves as an example of how
    to write a Gate One application.
    """
    info = {
        'name': "Example", # A user-friendly name for your app
        'version': __version__,
    # A description of what your app does:
        'description': "An example of how to write a Gate One Application.",
        'hidden': HIDDEN
    }
    def __init__(self, ws):
        example_log.debug("ExampleApplication.__init__(%s)" % ws)
        # Having your app's policies handy is a good idea.  However, you can't
        # get them until you've got a user to pass to applicable_policies().
        # For this reason we'll place a `self.policy` placeholder here and
        # assign it after the user authenticates (successfully)...
        self.policy = {} # Gets set in authenticate() below
        # If you override __init__() (like we are here) don't forget to call
        # the parent __init__():
        GOApplication.__init__(self, ws)

    def initialize(self):
        """
        Called when the WebSocket is instantiated, sets up our WebSocket
        actions, security policies, and attaches all of our plugin hooks/events.
        """
        example_log.debug("ExampleApplication.initialize()")
        # Register our security policy function in the 'security' dict
        self.ws.security.update({'example': example_policies})
        # Register some WebSocket actions...
        # These can be called from the client like so:
        # GateOne.ws.send(JSON.stringify({'example:test_example': whatever}));
        self.ws.actions.update({
            'example:test_example': self.test_example,
        })
        # Gate One provides a location where you can store information that you
        # want to be persistent across user sesions/connections and whatnot:
        if 'example' not in self.ws.persist:
            # If it doesn't belong in SESSIONS but you still need it to stick
            # around after the user disconnects put it here:
            self.ws.persist['example'] = {}
        # NOTE: If you don't care about your app having its own plugins you can
        # delete everything from here until the end of this function.
        # -- BEGIN PLUGIN CODE --
        # If you want your app to support plugins here's how you do it:
        # First let's check if someone has explicitly given us a list of plugins
        # that should be enabled (so we can exclude the others):
        enabled_plugins = self.ws.prefs['*']['example'].get(
            'enabled_plugins', [])
        # Now we'll use Gate One's utils.get_plugins() function to fetch a dict
        # containing all our Python, JavaScript, and CSS plugin files.  This is
        # really only so we can log which plugins are enabled because the
        # process of importing Python plugins happens inside of init() and
        # JS/CSS plugin files get sent via the send_plugin_static_files()
        # function inside of authenticate().
        self.plugins = get_plugins( # Get everything in example/plugins/
            os.path.join(APPLICATION_PATH, 'plugins'), enabled_plugins)
        # Now let's separate the plugins by type (to save some typing)
        js_plugins = []
        for js_path in self.plugins['js']:
            name = js_path.split(os.path.sep)[-2]
            name = os.path.splitext(name)[0]
            js_plugins.append(name)
        css_plugins = []
        for css_path in css_plugins:
            name = css_path.split(os.path.sep)[-2]
            css_plugins.append(name)
        plugin_list = list(set(self.plugins['py'] + js_plugins + css_plugins))
        plugin_list.sort() # So there's consistent ordering
        example_log.info(_(
            "Active Example Plugins: %s" % ", ".join(plugin_list)))
        # Now let's attach plugin hooks.  Plugin hooks can be whatever you like
        # and called from anywhere in your application.  There's three types of
        # hooks you'll definitely want though:  initialize(), 'WebSocket' and
        # 'Events'
        #
        # The initialize() hook just calls a given plugin's "initializ()"
        # function if it has one.  The function will be passed `self` (the
        # current instance of your app).  This allows plugins to take care of
        # any initialization stuff that needs to happen before anything else.
        #
        # 'WebSocket' hooks are what allow plugins to add their own WebSocket
        # actions such as, "myplugin:do_something" which is a very important
        # part of Gate One.
        #
        # 'Events' hooks allow plugins to attach functions to `OnOff` events
        # such as 'self.on("example:some_event", handle_some_event)'
        #
        # With those three kinds of hooks plugins can add or override pretty
        # much anything.
        #
        # NOTE: All GOApplication instances include the OnOff mixin class so
        # they can use self.on(), self.off, self.trigger(), and self.once()
        #
        # How do plugins assign these hooks?  They simply include a 'hooks' dict
        # somewhere in the global scope of their .py files.  Example:
        # hooks = {
        #     'WebSocket': {'myplugin:some_func': some_func}
        #     'Events': {'example:authenticate': auth_func}
        # }
        self.plugin_hooks = {} # We'll store our plugin hooks here
        imported = load_modules(self.plugins['py'])
        for plugin in imported:
            try:
                # Add the plugin's hooks dict to self.plugin_hooks:
                self.plugin_hooks.update({plugin.__name__: plugin.hooks})
                # Now we'll call the plugin's initialize() function:
                if hasattr(plugin, 'initialize'):
                    plugin.initialize(self)
            except AttributeError:
                pass # No hooks--probably just a supporting .py file.
        # Now we hook up the hooks:
        for plugin_name, hooks in self.plugin_hooks.items():
            if 'WebSocket' in hooks:
                # Apply the plugin's WebSocket actions to ApplicationWebSocket
                for ws_command, func in hooks['WebSocket'].items():
                    self.ws.actions.update({ws_command: bind(func, self)})
                # Attach the plugin's event hooks to their respective events:
            if 'Events' in hooks:
                for event, callback in hooks['Events'].items():
                    self.on(event, bind(callback, self))
        # -- END PLUGIN CODE --

    def open(self):
        """
        This gets called at the end of :meth:`ApplicationWebSocket.open` when
        the WebSocket is opened.  It just triggers the "example:open" event.

        .. note::

            The authenticate() method is usually a better place to call stuff
            that needs to happen after the user loads the page.
        """
        example_log.debug('ExampleApplication.open()')
        self.trigger("example:open")

    def authenticate(self):
        """
        This gets called immediately after the user is authenticated
        successfully at the end of :meth:`ApplicationWebSocket.authenticate`.
        Sends all plugin JavaScript files to the client and triggers the
        'example:authenticate' event.
        """
        example_log.debug('ExampleApplication.authenticate()')
        # This is the log metadata that was mentioned near the top of this file.
        # This log_metadata will be JSON-encoded and included in all log
        # messages that use `self.example_log` which is super useful when
        # you need to parse logs at some later date and want to know the
        # circumstances surrounding any given message.
        self.log_metadata = {
            'upn': self.current_user['upn'],
            'ip_address': self.ws.request.remote_ip,
            # If your app uses the location feature make sure to include it:
            'location': self.ws.location
        }
        self.example_log = go_logger("gateone.example", **self.log_metadata)
        # NOTE:  To include even *more* metadata in a log message on a one-time
        # basis simply pass the metadata to the logger like so:
        #   self.example_log("Some log message", metadata={'foo': 'bar'})
        # That will ensure that {'foo': 'bar'} is included in the JSON portion
        # Assign our user-specific settings/policies for quick reference
        self.policy = applicable_policies(
            'example', self.current_user, self.ws.prefs)
        # NOTE:  The applicable_policies() function *is* memoized but the above
        #        is still much faster.
        # Start by determining if the user can even use this app
        if 'allow' in self.policy:
            # This is the same check inside example_policies().  Why put it here
            # too?  So we can skip sending the client JS/CSS that they won't be
            # able to use.
            if not self.policy['allow']:
                # User is not allowed to access this application.  Don't
                # bother sending them any static files and whatnot...
                self.example_log.debug(_(
                    "User is not allowed to use the Example application.  "
                    "Skipping post-authentication functions."))
                return
        # Render and send the client our example.css
        example_css = os.path.join(
            APPLICATION_PATH, 'templates', 'example.css')
        self.render_and_send_css(example_css, element_id="example.css")
        # NOTE:  See the Gate One docs for gateone.py to see how
        #        render_and_send_css() works.  It auto-minifies and caches!
        # Send the client our application's static JavaScript files
        static_dir = os.path.join(APPLICATION_PATH, 'static')
        js_files = []
        if os.path.isdir(static_dir):
            js_files = os.listdir(static_dir) # Everything in static/*.js
            js_files.sort()
        for fname in js_files:
            if fname.endswith('.js'):
                js_file_path = os.path.join(static_dir, fname)
                # This is notable:  To ensure that all your JavaScript files
                # get loaded *after* example.js we add 'example.js' as a
                # dependency for all JS files we send to the client.
                if fname == 'example.js':
                    # Adding CSS as a dependency to your app's JS is also a
                    # good idea.  You could also put 'theme.css' if you want to
                    # ensure that the theme gets loaded before your JavaScript
                    # init() function is called.
                    self.send_js(js_file_path, requires=["example.css"])
                else:
                    # Send any other discovered JS files to the client with
                    # example.js as the only dependency.
                    self.send_js(js_file_path, requires='example.js')
        # If you're not using plugins you can disregard this:
        # The send_plugin_static_files() function will locate any JS/CSS files
        # in your plugins' respective static directories and send them to the
        # client.  It is also smart enough to know which plugins are enabled
        # or disabled.
        self.ws.send_plugin_static_files(
            os.path.join(APPLICATION_PATH, 'plugins'),
            application="example",
            requires=["example.js"])
        sess = SESSIONS[self.ws.session] # A shortcut to save some typing
        # Create a place to store app-specific stuff related to this session
        # (but not necessarily this 'location')
        if "example" not in sess:
            sess['example'] = {} # A mostly persistent place to store info
        # If you want to call a function whenever Gate One exits just add it
        # to SESSIONS[self.ws.session]["kill_session_callbacks"] like so:
        #if kill_session_func not in sess["kill_session_callbacks"]:
            #sess["kill_session_callbacks"].append(kill_session_func)
        # If you want to call a function whenever a user's session times out
        # just attach it to SESSIONS[self.ws.session]["timeout_callbacks"]
        # like so:
        #if timeout_session_func not in sess["timeout_callbacks"]:
            #sess["timeout_callbacks"].append(timeout_session_func)
        # NOTE: The user will often be authenticated before example.js is
        # loaded.  In fact, the only time this won't be the case is when the
        # user is disconnected (e.g. server restart) and then reconnects.
        self.trigger("example:authenticate")

    def on_close(self):
        """
        This method gets called when the WebSocket connection closes
        (disconnected).  Triggers the `example:on_close` event.
        """
        # This is a nice little check to prevent you from calling all sorts
        # of uninitialization/teardown stuff when you don't need to:
        if not hasattr(self.ws, 'location'):
            return # Connection closed before authentication completed
        # Here's where you'd deal with any uninitialization/teardown stuff
        self.trigger("example:on_close")

    @require(authenticated(), policies('example'))
    def test_example(self, settings):
        """
        This is an example WebSocket action that sends a message to the client
        indicating that it was called successfully.  Calls the
        `example:test_example` event when complete.
        """
        self.ws.send_message(_(
            "The test_example WebSocket action was called successfully!"))
        self.ws.send_message(_("Here's what was recieved: %s") % repr(settings))
        self.trigger("example:test_example", settings)

# Application init() functions are called inside of gateone.main() after global
# plugins are loaded, command line options are parsed, and settings get loaded.
# The init() function will be passed Gate One's *settings* dict (same as
# 'ApplicationWebSocket.prefs') as the only argument.
def init(settings):
    """
    Checks to make sure 50example.conf is created if example-specific settings
    are not found in the settings directory.  Basically, it creates some
    defaults to make things easier on users.
    """
    # I put this code here because I know someone was going to ask, "How do I
    # setup initial preferences and whatnot?"
    if 'example' not in settings['*']:
        # Create some defaults and save the config as 50example.conf
        settings_path = options.settings_dir
        # This is the final destination of our 50example.conf:
        example_conf_path = os.path.join(settings_path, '50example.conf')
        if not os.path.exists(example_conf_path): # Only if not already present
            from gateone.core.utils import settings_template
            template_path = os.path.join(
                APPLICATION_PATH, 'templates', 'settings', '50example.conf')
            settings['*']['example'] = {}
            # Update the settings with defaults
            settings['*']['example'].update({
                'allow': True,
                'example_option': 'An example option',
            })
            new_settings = settings_template(
                template_path, settings=settings['*']['example'])
            with open(example_conf_path, 'w') as s:
                # Add a nice comment/header before everything else:
                s.write(_(
                    "// This is Gate One's Example application settings "
                    "file.\n"))
                s.write(new_settings)

# Tell Gate One which classes are applications
apps = [ExampleApplication] # Very important!
# Tell Gate One about our example handler (all handlers in the global
# 'web_handlers' will be automatically assigned inside of gateone.main()).
web_handlers.append((r'example/(.*)', ExampleHandler))

########NEW FILE########
__FILENAME__ = app_terminal
# -*- coding: utf-8 -*-
#
#       Copyright 2013 Liftoff Software Corporation
#
from __future__ import unicode_literals

__doc__ = """\
A Gate One Application (`GOApplication`) that provides a terminal emulator.
"""

# Meta
__version__ = '1.2'
__license__ = "AGPLv3 or Proprietary (see LICENSE.txt)"
__version_info__ = (1, 2)
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'

# Standard library imports
import os, sys, time, io, atexit
from datetime import datetime, timedelta
from functools import partial

# Gate One imports
from gateone import GATEONE_DIR, SESSIONS
from gateone.core.server import StaticHandler, BaseHandler, GOApplication
from gateone.core.server import ApplicationWebSocket
from gateone.auth.authorization import require, authenticated
from gateone.auth.authorization import applicable_policies, policies
from gateone.core.configuration import get_settings, RUDict
from gateone.core.utils import cmd_var_swap, json_encode
from gateone.core.utils import mkdir_p, get_plugins
from gateone.core.utils import process_opt_esc_sequence, bind, MimeTypeFail
from gateone.core.utils import which
from gateone.core.utils import short_hash, load_modules, create_data_uri
from gateone.core.locale import get_translation
from gateone.core.log import go_logger, string_to_syslog_facility
from gateone.applications.terminal.logviewer import main as logviewer_main
from gateone.applications.terminal.policy import terminal_policies

# 3rd party imports
from tornado.escape import json_decode
from tornado.options import options, define

# Globals
APPLICATION_PATH = os.path.split(__file__)[0] # Path to our application
REGISTERED_HANDLERS = [] # So we don't accidentally re-add handlers
web_handlers = [] # Assigned in init()
term_log = go_logger("gateone.terminal")

# Localization support
_ = get_translation()

# Terminal-specific command line options.  These become options you can pass to
# gateone.py (e.g. --session_logging)
if not hasattr(options, 'session_logging'):
    define(
        "session_logging",
        default=True,
        group='terminal',
        help=_("If enabled, logs of user sessions will be saved in "
                "<user_dir>/<user>/logs.  Default: Enabled")
    )
    define( # This is an easy way to support cetralized logging
        "syslog_session_logging",
        default=False,
        group='terminal',
        help=_("If enabled, logs of user sessions will be written to syslog.")
    )
    define(
        "dtach",
        default=True,
        group='terminal',
        help=_("Wrap terminals with dtach. Allows sessions to be resumed even "
                "if Gate One is stopped and started (which is a sweet feature).")
    )
    define(
        "kill",
        default=False,
        group='terminal',
        help=_("Kill any running Gate One terminal processes including dtach'd "
                "processes.")
    )

def kill_session(session, kill_dtach=False):
    """
    Terminates all the terminal processes associated with *session*.  If
    *kill_dtach* is True, the dtach processes associated with the session will
    also be killed.

    .. note::

        This function gets appended to the
        `SESSIONS[session]["kill_session_callbacks"]` list inside of
        :meth:`TerminalApplication.authenticate`.
    """
    term_log.debug('kill_session(%s)' % session)
    if kill_dtach:
        from gateone.core.utils import kill_dtached_proc
    for location, apps in list(SESSIONS[session]['locations'].items()):
        loc = SESSIONS[session]['locations'][location]['terminal']
        terms = apps['terminal']
        for term in terms:
            if isinstance(term, int):
                if loc[term]['multiplex'].isalive():
                    loc[term]['multiplex'].terminate()
                if kill_dtach:
                    kill_dtached_proc(session, location, term)

def timeout_session(session):
    """
    Attached to Gate One's 'timeout_callbacks'; kills the given session.

    If 'dtach' support is enabled the dtach processes associated with the
    session will also be killed.
    """
    kill_session(session, kill_dtach=True)

@atexit.register
def quit():
    from gateone.core.utils import killall
    if not options.dtach:
        # If we're not using dtach play it safe by cleaning up any leftover
        # processes.  When passwords are used with the ssh_conenct.py script
        # it runs os.setsid() on the child process which means it won't die
        # when Gate One is closed.  This is primarily to handle that
        # specific situation.
        killall(options.session_dir, options.pid_file)

# NOTE:  THE BELOW IS A WORK IN PROGRESS
class SharedTermHandler(BaseHandler):
    """
    Renders shared.html which allows an anonymous user to view a shared
    terminal.
    """
    def get(self, share_id):
        hostname = os.uname()[1]
        prefs = self.get_argument("prefs", None)
        gateone_js = "%sstatic/gateone.js" % self.settings['url_prefix']
        minified_js_abspath = os.path.join(GATEONE_DIR, 'static')
        minified_js_abspath = os.path.join(
            minified_js_abspath, 'gateone.min.js')
        # Use the minified version if it exists
        if os.path.exists(minified_js_abspath):
            gateone_js = "%sstatic/gateone.min.js" % self.settings['url_prefix']
        template_path = os.path.join(APPLICATION_PATH, 'templates')
        index_path = os.path.join(template_path, 'share.html')
        self.render(
            index_path,
            share_id=share_id,
            hostname=hostname,
            gateone_js=gateone_js,
            url_prefix=self.settings['url_prefix'],
            prefs=prefs
        )

class TermStaticFiles(StaticHandler):
    """
    Serves static files in the `gateone/applications/terminal/static` directory.

    .. note::

        This is configured via the `web_handlers` global (a feature inherent to
        Gate One applications).
    """
    pass

class TerminalApplication(GOApplication):
    """
    A Gate One Application (`GOApplication`) that handles creating and
    controlling terminal applications running on the Gate One server.
    """
    info = {
        'name': "Terminal",
        'version': __version__,
        'description': (
            "Open terminals running any number of configured applications."),
        'dependencies': ['terminal.js', 'terminal_input.js']
    }
    name = "Terminal" # A user-friendly name that will be displayed to the user
    def __init__(self, ws):
        term_log.debug("TerminalApplication.__init__(%s)" % ws)
        self.policy = {} # Gets set in authenticate() below
        self.terms = {}
        self.loc_terms = {}
        # So we can keep track and avoid sending unnecessary messages:
        self.titles = {}
        self.em_dimensions = None
        self.race_check = False
        self.log_metadata = {'application': 'terminal'}
        GOApplication.__init__(self, ws)

    def initialize(self):
        """
        Called when the WebSocket is instantiated, sets up our WebSocket
        actions, security policies, and attaches all of our plugin hooks/events.
        """
        self.log_metadata = {
            'application': 'terminal',
            'ip_address': self.ws.request.remote_ip,
            'location': self.ws.location
        }
        self.term_log = go_logger("gateone.terminal")
        self.term_log.debug("TerminalApplication.initialize()")
        # Register our security policy function
        self.ws.security.update({'terminal': terminal_policies})
        # Register our WebSocket actions
        self.ws.actions.update({
            'terminal:new_terminal': self.new_terminal,
            'terminal:set_terminal': self.set_terminal,
            'terminal:move_terminal': self.move_terminal,
            'terminal:swap_terminals': self.swap_terminals,
            'terminal:kill_terminal': self.kill_terminal,
            'c': self.char_handler, # Just 'c' to keep the bandwidth down
            'terminal:write_chars': self.write_chars,
            'terminal:refresh': self.refresh_screen,
            'terminal:full_refresh': self.full_refresh,
            'terminal:resize': self.resize,
            'terminal:get_bell': self.get_bell,
            'terminal:manual_title': self.manual_title,
            'terminal:reset_terminal': self.reset_terminal,
            'terminal:get_webworker': self.get_webworker,
            'terminal:get_font': self.get_font,
            'terminal:get_colors': self.get_colors,
            'terminal:set_encoding': self.set_term_encoding,
            'terminal:set_keyboard_mode': self.set_term_keyboard_mode,
            'terminal:get_locations': self.get_locations,
            'terminal:get_terminals': self.terminals,
            'terminal:get_client_files': self.send_client_files,
            'terminal:permissions': self.permissions,
            'terminal:new_share_id': self.new_share_id,
            'terminal:share_user_list': self.share_user_list,
            #'terminal:unshare_terminal': self.unshare_terminal,
            'terminal:enumerate_commands': self.enumerate_commands,
            'terminal:enumerate_fonts': self.enumerate_fonts,
            'terminal:enumerate_colors': self.enumerate_colors,
            'terminal:list_shared_terminals': self.list_shared_terminals,
            'terminal:attach_shared_terminal': self.attach_shared_terminal,
            'terminal:detach_shared_terminal': self.detach_shared_terminal,
            #'terminal:set_sharing_permissions': self.set_sharing_permissions,
            'terminal:debug_terminal': self.debug_terminal
        })
        if 'terminal' not in self.ws.persist:
            self.ws.persist['terminal'] = {}
        # Initialize plugins (every time a connection is established so we can
        # load new plugins with a simple page reload)
        enabled_plugins = self.ws.prefs['*']['terminal'].get(
            'enabled_plugins', [])
        self.plugins = get_plugins(
            os.path.join(APPLICATION_PATH, 'plugins'), enabled_plugins)
        py_plugins = []
        for module_path in self.plugins['py']:
            name = module_path.split('.')[-1]
            py_plugins.append(name)
        js_plugins = []
        for js_path in self.plugins['js']:
            name = js_path.split(os.path.sep)[0]
            js_plugins.append(name)
        css_plugins = []
        for css_path in css_plugins:
            name = css_path.split(os.path.sep)[-2]
            css_plugins.append(name)
        plugin_list = list(set(py_plugins + js_plugins + css_plugins))
        plugin_list.sort() # So there's consistent ordering
        term_log.info(_("Active Terminal Plugins: %s" % ", ".join(plugin_list)))
        # Setup some events
        terminals_func = partial(self.terminals, self)
        self.ws.on("go:set_location", terminals_func)
        # Attach plugin hooks
        self.plugin_hooks = {}
        # TODO: Keep track of plugins and hooks to determine when they've
        #       changed so we can tell clients to pull updates and whatnot
        imported = load_modules(self.plugins['py'])
        for plugin in imported:
            try:
                self.plugin_hooks.update({plugin.__name__: plugin.hooks})
                if hasattr(plugin, 'initialize'):
                    plugin.initialize(self)
            except AttributeError as e:
                if options.logging.lower() == 'debug':
                    self.term_log.error(
                        _("Got exception trying to initialize the {0} plugin:"
                         ).format(plugin))
                    self.term_log.error(e)
                    import traceback
                    traceback.print_exc(file=sys.stdout)
                pass # No hooks--probably just a supporting .py file.
        # Hook up the hooks
        # NOTE:  Most of these will soon be replaced with on() and off() events
        # and maybe some functions related to initialization.
        self.plugin_esc_handlers = {}
        self.plugin_auth_hooks = []
        self.plugin_command_hooks = []
        self.plugin_log_metadata_hooks = []
        self.plugin_new_multiplex_hooks = []
        self.plugin_new_term_hooks = {}
        self.plugin_env_hooks = {}
        for plugin_name, hooks in self.plugin_hooks.items():
            plugin_name = plugin_name.split('.')[-1]
            if 'WebSocket' in hooks:
                # Apply the plugin's WebSocket actions
                for ws_command, func in hooks['WebSocket'].items():
                    self.ws.actions.update({ws_command: bind(func, self)})
            if 'Escape' in hooks:
                # Apply the plugin's Escape handler
                self.on(
                    "terminal:opt_esc_handler:%s" %
                    plugin_name, bind(hooks['Escape'], self))
            if 'Command' in hooks:
                # Apply the plugin's 'Command' hooks (called by new_multiplex)
                if isinstance(hooks['Command'], (list, tuple)):
                    self.plugin_command_hooks.extend(hooks['Command'])
                else:
                    self.plugin_command_hooks.append(hooks['Command'])
            if 'Metadata' in hooks:
                # Apply the plugin's 'Metadata' hooks (called by new_multiplex)
                if isinstance(hooks['Metadata'], (list, tuple)):
                    self.plugin_log_metadata_hooks.extend(hooks['Metadata'])
                else:
                    self.plugin_log_metadata_hooks.append(hooks['Metadata'])
            if 'Multiplex' in hooks:
                # Apply the plugin's Multiplex hooks (called by new_multiplex)
                if isinstance(hooks['Multiplex'], (list, tuple)):
                    self.plugin_new_multiplex_hooks.extend(hooks['Multiplex'])
                else:
                    self.plugin_new_multiplex_hooks.append(hooks['Multiplex'])
            if 'TermInstance' in hooks:
                # Apply the plugin's TermInstance hooks (called by new_terminal)
                if isinstance(hooks['TermInstance'], (list, tuple)):
                    self.plugin_new_term_hooks.extend(hooks['TermInstance'])
                else:
                    self.plugin_new_term_hooks.append(hooks['TermInstance'])
            if 'Environment' in hooks:
                self.plugin_env_hooks.update(hooks['Environment'])
            if 'Events' in hooks:
                for event, callback in hooks['Events'].items():
                    self.on(event, bind(callback, self))

    def open(self):
        """
        This gets called at the end of :meth:`ApplicationWebSocket.open` when
        the WebSocket is opened.
        """
        term_log.debug('TerminalApplication.open()')
        self.callback_id = "%s;%s;%s" % (
            self.ws.client_id, self.request.host, self.request.remote_ip)
        self.trigger("terminal:open")

    def send_client_files(self):
        """
        Sends the client our standard CSS and JS.
        """
        # Render and send the client our terminal.css
        templates_path = os.path.join(APPLICATION_PATH, 'templates')
        terminal_css = os.path.join(templates_path, 'terminal.css')
        self.render_and_send_css(terminal_css, element_id="terminal.css")
        # Send the client our JavaScript files
        static_dir = os.path.join(APPLICATION_PATH, 'static')
        js_files = os.listdir(static_dir)
        js_files.sort()
        for fname in js_files:
            if fname.endswith('.js'):
                js_file_path = os.path.join(static_dir, fname)
                if fname == 'terminal.js':
                    self.ws.send_js(js_file_path,
                    requires=["terminal.css"])
                elif fname == 'terminal_input.js':
                    self.ws.send_js(js_file_path, requires="terminal.js")
                else:
                    self.ws.send_js(js_file_path, requires='terminal_input.js')
        self.ws.send_plugin_static_files(
            os.path.join(APPLICATION_PATH, 'plugins'),
            application="terminal",
            requires=["terminal_input.js"])
        # Send the client the 256-color style information and our printing CSS
        self.send_256_colors()
        self.send_print_stylesheet()

    def authenticate(self):
        """
        This gets called immediately after the user is authenticated
        successfully at the end of :meth:`ApplicationWebSocket.authenticate`.
        Sends all plugin JavaScript files to the client and triggers the
        'terminal:authenticate' event.
        """
        term_log.debug('TerminalApplication.authenticate()')
        self.log_metadata = {
            'application': 'terminal',
            'upn': self.current_user['upn'],
            'ip_address': self.ws.request.remote_ip,
            'location': self.ws.location
        }
        self.term_log = go_logger("gateone.terminal", **self.log_metadata)
        # Get our user-specific settings/policies for quick reference
        self.policy = applicable_policies(
            'terminal', self.current_user, self.ws.prefs)
        # NOTE: If you want to be able to check policies on-the-fly without
        # requiring the user reload the page when a change is made make sure
        # call applicable_policies() on your own using self.ws.prefs every time
        # you want to check them.  This will ensure it's always up-to-date.
        # NOTE:  applicable_policies() is memoized so calling it over and over
        # again shouldn't slow anything down.
        # Start by determining if the user can even login to the terminal app
        if 'allow' in self.policy:
            if not self.policy['allow']:
                # User is not allowed to access the terminal application.  Don't
                # bother sending them any static files and whatnot.
                self.term_log.debug(_(
                    "User is not allowed to use the Terminal application.  "
                    "Skipping post-authentication functions."))
                return
        self.send_client_files()
        sess = SESSIONS[self.ws.session]
        # Create a place to store app-specific stuff related to this session
        # (but not necessarily this 'location')
        if "terminal" not in sess:
            sess['terminal'] = {}
        # When Gate One exits...
        if kill_session not in sess["kill_session_callbacks"]:
            sess["kill_session_callbacks"].append(kill_session)
        # When a session actually times out (kill dtach'd processes too)...
        if timeout_session not in sess["timeout_callbacks"]:
            sess["timeout_callbacks"].append(timeout_session)
        # Set the sub-applications list to our commands
        commands = list(self.policy['commands'].keys())
        sub_apps = []
        for command in commands:
            if isinstance(self.policy['commands'][command], dict):
                sub_app = self.policy['commands'][command].copy()
                del sub_app['command'] # Don't want clients to know this
                sub_app['name'] = command # Let them have the short name
                if 'icon' in sub_app:
                    if sub_app['icon'].startswith(os.path.sep):
                        # This is a path to the icon instead of the actual
                        # icon (has to be SVG, after all).  Replace it with
                        # the actual icon data (should start with <svg>)
                        if os.path.exists(sub_app['icon']):
                            with io.open(
                                sub_app['icon'], encoding='utf-8') as f:
                                sub_app['icon'] = f.read()
                        else:
                            self.term_log.error(_(
                                "Path to icon ({icon}) for command, "
                                "'{cmd}' could not be found.").format(
                                    cmd=sub_app['name'],
                                    icon=sub_app['icon']))
                            del sub_app['icon']
            else:
                sub_app = {'name': command}
            if 'icon' not in sub_app:
                # Use the generic one
                templates_path = os.path.join(APPLICATION_PATH, 'templates')
                icon_path = os.path.join(templates_path, 'command_icon.svg')
                with io.open(icon_path, encoding='utf-8') as f:
                    sub_app['icon'] = f.read().format(cmd=sub_app['name'])
            sub_apps.append(sub_app)
        self.info['sub_applications'] = sorted(
            sub_apps, key=lambda k: k['name'])
        # NOTE: The user will often be authenticated before terminal.js is
        # loaded.  This means that self.terminals() will be ignored in most
        # cases (only when the connection lost and re-connected without a page
        # reload).  For this reason GateOne.Terminal.init() calls
        # getOpenTerminals().
        self.terminals() # Tell the client about open terminals
        self.list_shared_terminals() # Also tell them about any shared terms
        self.trigger("terminal:authenticate")

    def on_close(self):
        """
        Removes all attached callbacks and triggers the `terminal:on_close`
        event.
        """
        # Remove all attached callbacks so we're not wasting memory/CPU on
        # disconnected clients
        if not hasattr(self.ws, 'location'):
            return # Connection closed before authentication completed
        if not self.ws.session: # Broadcast terminal
            self.trigger("terminal:on_close")
            return
        session_locs = SESSIONS[self.ws.session]['locations']
        if self.ws.location in session_locs and hasattr(self, 'loc_terms'):
            for term in self.loc_terms:
                if isinstance(term, int):
                    term_obj = self.loc_terms[term]
                    try:
                        multiplex = term_obj['multiplex']
                        multiplex.remove_all_callbacks(self.callback_id)
                        client_dict = term_obj[self.ws.client_id]
                        term_emulator = multiplex.term
                        term_emulator.remove_all_callbacks(self.callback_id)
                        # Remove anything associated with the client_id
                        multiplex.io_loop.remove_timeout(
                            client_dict['refresh_timeout'])
                        del self.loc_terms[term][self.ws.client_id]
                    except (AttributeError, KeyError):
                        # User never completed opening a terminal so
                        # self.callback_id is missing.  Nothing to worry about
                        if self.ws.client_id in term_obj:
                            del term_obj[self.ws.client_id]
        self.trigger("terminal:on_close")

    @require(authenticated(), policies('terminal'))
    def enumerate_commands(self):
        """
        Tell the client which 'commands' (from settings/policy) that are
        available via the `terminal:commands_list` WebSocket action.
        """
        # Get the current settings in case they've changed:
        policy = applicable_policies(
            'terminal', self.current_user, self.ws.prefs)
        commands = list(policy.get('commands', {}).keys())
        if not commands:
            self.term_log.error(_("You're missing the 'commands' setting!"))
            return
        message = {'terminal:commands_list': {'commands': commands}}
        self.write_message(message)

    def enumerate_fonts(self):
        """
        Returns a JSON-encoded object containing the installed fonts.
        """
        from .woff_info import woff_info
        fonts_path = os.path.join(APPLICATION_PATH, 'static', 'fonts')
        fonts = os.listdir(fonts_path)
        font_list = []
        for font in fonts:
            if not font.endswith('.woff'):
                continue
            font_path = os.path.join(fonts_path, font)
            font_info = woff_info(font_path)
            if "Font Family" not in font_info:
                self.ws.logger.error(_(
                    "Bad font in fonts dir (missing Font Family in name "
                    "table): %s" % font))
                continue # Bad font
            if font_info["Font Family"] not in font_list:
                font_list.append(font_info["Font Family"])
        message = {'terminal:fonts_list': {'fonts': font_list}}
        self.write_message(message)

    @require(policies('terminal'))
    def get_font(self, settings):
        """
        Attached to the `terminal:get_font` WebSocket action; sends the client
        CSS that includes a complete set of fonts associated with
        *settings["font_family"]*.  Optionally, the following additional
        *settings* may be provided:

            :font_size:

                Assigns the 'font-size' property according to the given value.
        """
        font_family = settings['font_family']
        font_size = settings.get('font_size', '90%')
        templates_path = templates_path = os.path.join(
            APPLICATION_PATH, 'templates')
        filename = 'font.css'
        font_css_path = os.path.join(templates_path, filename)
        if font_family == 'monospace':
            # User wants the browser to control the font; real simple:
            rendered_path = self.render_style(
                font_css_path,
                force=True,
                font_family=font_family,
                font_size=font_size)
            self.send_css(
                rendered_path, element_id="terminal_font", filename=filename)
            return
        from .woff_info import woff_info
        fonts_path = os.path.join(APPLICATION_PATH, 'static', 'fonts')
        fonts = os.listdir(fonts_path)
        woffs = {}
        for font in fonts:
            if not font.endswith('.woff'):
                continue
            font_path = os.path.join(fonts_path, font)
            font_info = woff_info(font_path)
            if "Font Family" not in font_info:
                self.ws.logger.error(_(
                    "Bad font in fonts dir (missing Font Family in name "
                    "table): %s" % font))
                continue # Bad font
            if font_info["Font Family"] == font_family:
                font_dict = {
                    "subfamily": font_info["Font Subfamily"],
                    "font_style": "normal", # Overwritten below (if warranted)
                    "font_weight": "normal", # Ditto
                    "locals": "",
                    "url": (
                        "{server_url}terminal/static/fonts/{font}".format(
                            server_url=self.ws.base_url,
                            font=font)
                    )
                }
                if "Full Name" in font_info:
                    font_dict["locals"] += (
                        "local('{0}')".format(font_info["Full Name"]))
                if "Postscript Name" in font_info:
                    font_dict["locals"] += (
                        ", local('{0}')".format(font_info["Postscript Name"]))
                if 'italic' in font_info["Font Subfamily"].lower():
                    font_dict["font_style"] = "italic"
                if 'oblique' in font_info["Font Subfamily"].lower():
                    font_dict["font_style"] = "oblique"
                if 'bold' in font_info["Font Subfamily"].lower():
                    font_dict["font_weight"] = "bold"
                woffs.update({font: font_dict})
        # NOTE: Not using render_and_send_css() because the source CSS file will
        # never change but the output will.
        rendered_path = self.render_style(
            font_css_path,
            force=True,
            woffs=woffs,
            font_family=font_family,
            font_size=font_size)
        self.send_css(
            rendered_path, element_id="terminal_font", filename=filename)

    def enumerate_colors(self):
        """
        Returns a JSON-encoded object containing the installed text color
        schemes.
        """
        colors_path = os.path.join(APPLICATION_PATH, 'templates', 'term_colors')
        colors = os.listdir(colors_path)
        colors = [a.replace('.css', '') for a in colors]
        message = {'terminal:colors_list': {'colors': colors}}
        self.write_message(message)

    def save_term_settings(self, term, settings):
        """
        Saves whatever *settings* (must be JSON-encodable) are provided in the
        user's session directory; associated with the given *term*.

        The `restore_term_settings` function can be used to restore the provided
        settings.

        .. note:: This method is primarily to aid dtach support.
        """
        self.term_log.debug("save_term_settings(%s, %s)" % (term, settings))
        from .term_utils import save_term_settings as _save
        term = str(term) # JSON wants strings as keys
        def saved(result): # NOTE: result will always be None
            """
            Called when we're done JSON-decoding and re-encoding the given
            settings.  Just triggers the `terminal:save_term_settings` event.
            """
            self.trigger("terminal:save_term_settings", term, settings)
        # Why bother with an async call for something so small?  Well, we can't
        # be sure it will *always* be a tiny amount of data.  What if some app
        # embedding Gate One wants to pass in some huge amount of metadata when
        # they open new terminals?  Don't want to block while the read, JSON
        # decode, JSON encode, and write operations take place.
        # Also note that this function gets called whenever a new terminal is
        # opened or resumed.  So if you have 100 users each with a dozen or so
        # terminals it could slow things down quite a bit in the event that a
        # number of users lose connectivity and reconnect at once (or the server
        # is restarted with dtach support enabled).
        self.cpu_async.call_singleton( # Singleton since we're writing async
            _save,
            'save_term_settings_%s' % self.ws.session,
            term,
            self.ws.location,
            self.ws.session,
            settings,
            callback=saved)

    def restore_term_settings(self, term):
        """
        Reads the settings associated with the given *term* that are stored in
        the user's session directory and applies them to
        ``self.loc_terms[term]``
        """
        term = str(term) # JSON wants strings as keys
        self.term_log.debug("restore_term_settings(%s)" % term)
        from .term_utils import restore_term_settings as _restore
        def restore(settings):
            """
            Saves the *settings* returned by :func:`restore_term_settings`
            in `self.loc_terms[term]` and triggers the
            `terminal:restore_term_settings` event.
            """
            if self.ws.location in settings:
                if term in settings[self.ws.location]:
                    termNum = int(term)
                    self.loc_terms[termNum].update(
                        settings[self.ws.location][term])
                    # The terminal title needs some special love
                    self.loc_terms[termNum]['multiplex'].term.title = (
                        self.loc_terms[termNum]['title'])
            self.trigger("terminal:restore_term_settings", term, settings)
        future = self.cpu_async.call(
            _restore,
            self.ws.location,
            self.ws.session,
            memoize=False,
            callback=restore)
        return future

    def clear_term_settings(self, term):
        """
        Removes any settings associated with the given *term* in the user's
        term_settings.json file (in their session directory).
        """
        term = str(term)
        self.term_log.debug("clear_term_settings(%s)" % term)
        term_settings = RUDict()
        term_settings[self.ws.location] = {term: {}}
        session_dir = options.session_dir
        session_dir = os.path.join(session_dir, self.ws.session)
        settings_path = os.path.join(session_dir, 'term_settings.json')
        if not os.path.exists(settings_path):
            return # Nothing to do
        # First we read in the existing settings and then update them.
        if os.path.exists(settings_path):
            with io.open(settings_path, encoding='utf-8') as f:
                term_settings.update(json_decode(f.read()))
        del term_settings[self.ws.location][term]
        with io.open(settings_path, 'w', encoding='utf-8') as f:
            f.write(json_encode(term_settings))
        self.trigger("terminal:clear_term_settings", term)

    @require(policies('terminal'))
    def terminals(self, *args, **kwargs):
        """
        Sends a list of the current open terminals to the client using the
        `terminal:terminals` WebSocket action.
        """
        # Note: *args and **kwargs are present so we can attach this to a go:
        # event and just ignore the provided arguments.
        self.term_log.debug('terminals()')
        terminals = {}
        # Create an application-specific storage space in the locations dict
        if 'terminal' not in self.ws.locations[self.ws.location]:
            self.ws.locations[self.ws.location]['terminal'] = {}
        # Quick reference for our terminals in the current location:
        if not self.ws.location:
            return # WebSocket disconnected or not-yet-authenticated
        self.loc_terms = self.ws.locations[self.ws.location]['terminal']
        for term in list(self.loc_terms.keys()):
            if isinstance(term, int): # Only terminals are integers in the dict
                terminals.update({
                    term: {
                        'metadata': self.loc_terms[term]['metadata'],
                        'title': self.loc_terms[term]['title']
                    }})
                share_id = self.loc_terms[term].get('share_id', None)
                if share_id:
                    terminals[term].update({'share_id': share_id})
        if not self.ws.session:
            return # Just a broadcast terminal viewer
        # Check for any dtach'd terminals we might have missed
        if options.dtach and which('dtach'):
            from .term_utils import restore_term_settings
            term_settings = restore_term_settings(
                self.ws.location, self.ws.session)
            session_dir = options.session_dir
            session_dir = os.path.join(session_dir, self.ws.session)
            if not os.path.exists(session_dir):
                mkdir_p(session_dir)
                os.chmod(session_dir, 0o770)
            for item in os.listdir(session_dir):
                if item.startswith('dtach_'):
                    split = item.split('_')
                    location = split[1]
                    if location == self.ws.location:
                        term = int(split[2])
                        if term not in terminals:
                            if self.ws.location not in term_settings:
                                continue
                            # NOTE: str() below because the dict comes from JSON
                            if str(term) not in term_settings[self.ws.location]:
                                continue
                            data = term_settings[self.ws.location][str(term)]
                            metadata = data.get('metadata', {})
                            title = data.get('title', 'Gate One')
                            terminals.update({term: {
                                'metadata': metadata,
                                'title': title
                            }})
        self.trigger('terminal:terminals', terminals)
        message = {'terminal:terminals': terminals}
        self.write_message(json_encode(message))

    def term_ended(self, term):
        """
        Sends the 'term_ended' message to the client letting it know that the
        given *term* is no more.
        """
        metadata = {"term": term}
        if term in self.loc_terms:
            metadata["command"] = self.loc_terms[term].get("command", None)
        self.term_log.info(
            "Terminal Closed: %s" % term, metadata=metadata)
        message = {'terminal:term_ended': term}
        if term in self.loc_terms:
            timediff = datetime.now() - self.loc_terms[term]['created']
            if self.race_check:
                race_check_timediff = datetime.now() - self.race_check
                if race_check_timediff < timedelta(milliseconds=500):
                    # Definitely a race condition (command is failing to run).
                    # Add a delay
                    self.add_timeout("5s", partial(self.term_ended, term))
                    self.race_check = False
                    self.ws.send_message(_(
                        "Warning: Terminals are closing too fast.  If you see "
                        "this message multiple times it is likely that the "
                        "configured command is failing to execute.  Please "
                        "check your server settings."
                    ))
                    cmd = self.loc_terms[term]['multiplex'].cmd
                    self.term_log.warning(_(
                        "Terminals are closing too quickly after being opened "
                        "(command: %s).  Please check your 'commands' (usually "
                        "in settings/50terminal.conf)." % repr(cmd)))
                    return
            elif timediff < timedelta(seconds=1):
                # Potential race condition
                # Alow the first one to go through immediately
                self.race_check = datetime.now()
        try:
            self.write_message(json_encode(message))
        except AttributeError:
            # Because this function can be called after a timeout it is possible
            # that the client will have disconnected in the mean time resulting
            # in this exception.  Not a problem; ignore.
            return
        self.trigger("terminal:term_ended", term)

    def add_terminal_callbacks(self, term, multiplex, callback_id):
        """
        Sets up all the callbacks associated with the given *term*, *multiplex*
        instance and *callback_id*.
        """
        import terminal
        refresh = partial(self.refresh_screen, term)
        multiplex.add_callback(multiplex.CALLBACK_UPDATE, refresh, callback_id)
        ended = partial(self.term_ended, term)
        multiplex.add_callback(multiplex.CALLBACK_EXIT, ended, callback_id)
        # Setup the terminal emulator callbacks
        term_emulator = multiplex.term
        set_title = partial(self.set_title, term)
        term_emulator.add_callback(
            terminal.CALLBACK_TITLE, set_title, callback_id)
        #set_title() # Set initial title
        bell = partial(self.bell, term)
        term_emulator.add_callback(
            terminal.CALLBACK_BELL, bell, callback_id)
        opt_esc_handler = partial(self.opt_esc_handler, term, multiplex)
        term_emulator.add_callback(
            terminal.CALLBACK_OPT, opt_esc_handler, callback_id)
        mode_handler = partial(self.mode_handler, term)
        term_emulator.add_callback(
            terminal.CALLBACK_MODE, mode_handler, callback_id)
        reset_term = partial(self.reset_client_terminal, term)
        term_emulator.add_callback(
            terminal.CALLBACK_RESET, reset_term, callback_id)
        dsr = partial(self.dsr, term)
        term_emulator.add_callback(
            terminal.CALLBACK_DSR, dsr, callback_id)
        term_emulator.add_callback(
            terminal.CALLBACK_MESSAGE, self.ws.send_message, callback_id)
        # Call any registered plugin Terminal hooks
        self.trigger(
            "terminal:add_terminal_callbacks", term, multiplex, callback_id)

    def remove_terminal_callbacks(self, multiplex, callback_id):
        """
        Removes all the Multiplex and terminal emulator callbacks attached to
        the given *multiplex* instance and *callback_id*.
        """
        import terminal
        multiplex.remove_callback(multiplex.CALLBACK_UPDATE, callback_id)
        multiplex.remove_callback(multiplex.CALLBACK_EXIT, callback_id)
        term_emulator = multiplex.term
        term_emulator.remove_callback(terminal.CALLBACK_TITLE, callback_id)
        term_emulator.remove_callback(
            terminal.CALLBACK_MESSAGE, callback_id)
        term_emulator.remove_callback(terminal.CALLBACK_DSR, callback_id)
        term_emulator.remove_callback(terminal.CALLBACK_RESET, callback_id)
        term_emulator.remove_callback(terminal.CALLBACK_MODE, callback_id)
        term_emulator.remove_callback(terminal.CALLBACK_OPT, callback_id)
        term_emulator.remove_callback(terminal.CALLBACK_BELL, callback_id)

    def new_multiplex(self,
        cmd, term_id, logging=True, encoding='utf-8', debug=False):
        """
        Returns a new instance of :py:class:`termio.Multiplex` with the proper
        global and client-specific settings.

            :cmd:
                The command to execute inside of Multiplex.
            :term_id:
                The terminal to associate with this Multiplex or a descriptive
                identifier (it's only used for logging purposes).
            :logging:
                If ``False``, logging will be disabled for this instance of
                Multiplex (even if it would otherwise be enabled).
            :encoding:
                The default encoding that will be used when reading or writing
                to the Multiplex instance.
            :debug:
                If ``True``, will enable debugging on the created Multiplex
                instance.
        """
        import termio
        policies = applicable_policies(
            'terminal', self.current_user, self.ws.prefs)
        shell_command = policies.get('shell_command', None)
        enabled_filetypes = policies.get('enabled_filetypes', 'all')
        use_shell = policies.get('use_shell', True)
        user_dir = self.settings['user_dir']
        try:
            user = self.current_user['upn']
        except:
            # No auth, use ANONYMOUS (% is there to prevent conflicts)
            user = r'ANONYMOUS' # Don't get on this guy's bad side
        session_dir = options.session_dir
        session_dir = os.path.join(session_dir, self.ws.session)
        log_path = None
        syslog_logging = False
        if logging:
            syslog_logging = policies['syslog_session_logging']
            if policies['session_logging']:
                log_dir = os.path.join(user_dir, user)
                log_dir = os.path.join(log_dir, 'logs')
                # Create the log dir if not already present
                if not os.path.exists(log_dir):
                    mkdir_p(log_dir)
                log_suffix = "-{0}.golog".format(
                    self.current_user['ip_address'])
                log_name = datetime.now().strftime(
                    '%Y%m%d%H%M%S%f') + log_suffix
                log_path = os.path.join(log_dir, log_name)
        facility = string_to_syslog_facility(self.settings['syslog_facility'])
        # This allows plugins to transform the command however they like
        if self.plugin_command_hooks:
            for func in self.plugin_command_hooks:
                cmd = func(self, cmd)
        additional_log_metadata = {
            'ip_address': self.current_user.get('ip_address', "")
        }
        # This allows plugins to add their own metadata to .golog files:
        if self.plugin_log_metadata_hooks:
            for func in self.plugin_log_metadata_hooks:
                metadata = func(self)
                additional_log_metadata.update(metadata)
        terminal_emulator_kwargs = {}
        if enabled_filetypes != 'all':
            # Only need to bother if it is something other than the default
            terminal_emulator_kwargs = {'enabled_filetypes': enabled_filetypes}
        m = termio.Multiplex(
            cmd,
            terminal_emulator_kwargs=terminal_emulator_kwargs,
            log_path=log_path,
            user=user,
            term_id=term_id,
            debug=debug,
            syslog=syslog_logging,
            syslog_facility=facility,
            additional_metadata=additional_log_metadata,
            encoding=encoding
        )
        if use_shell:
            m.use_shell = True # This is the default anyway
            if shell_command:
                m.shell_command = shell_command
        else:
            m.use_shell = False
        if self.plugin_new_multiplex_hooks:
            for func in self.plugin_new_multiplex_hooks:
                func(self, m)
        self.trigger("terminal:new_multiplex", m)
        return m

    def highest_term_num(self, location=None):
        """
        Returns the highest terminal number at the given *location* (so we can
        figure out what's next).  If *location* is omitted, uses
        `self.ws.location`.
        """
        if not self.ws.session:
            return 1 # Broadcast terminal viewer
        if not location:
            location = self.ws.location
        loc = SESSIONS[self.ws.session]['locations'][location]['terminal']
        highest = 0
        for term in list(loc.keys()):
            if isinstance(term, int):
                if term > highest:
                    highest = term
        return highest

    @require(authenticated(), policies('terminal'))
    def new_terminal(self, settings):
        """
        Starts up a new terminal associated with the user's session using
        *settings* as the parameters.  If a terminal already exists with the
        same number as *settings[term]*, self.set_terminal() will be called
        instead of starting a new terminal (so clients can resume their session
        without having to worry about figuring out if a new terminal already
        exists or not).
        """
        term = int(settings['term'])
        # TODO: Make these specific to each terminal:
        rows = settings['rows']
        cols = settings['columns']
        if rows < 2 or cols < 2: # Something went wrong calculating term size
            # Fall back to a standard default
            rows = 24
            cols = 80
        default_env = {"TERM": 'xterm-256color'} # Only one default
        policy = applicable_policies(
            'terminal', self.current_user, self.ws.prefs)
        environment_vars = policy.get('environment_vars', default_env)
        default_encoding = policy.get('default_encoding', 'utf-8')
        encoding = settings.get('encoding', default_encoding)
        if not encoding: # Was passed as None or 'null'
            encoding = default_encoding
        term_metadata = settings.get('metadata', {})
        settings_dir = self.settings['settings_dir']
        user_session_dir = os.path.join(options.session_dir, self.ws.session)
        # NOTE: 'command' here is actually just the short name of the command.
        #       ...which maps to what's configured the 'commands' part of your
        #       terminal settings.
        if 'command' in settings and settings['command']:
            command = settings['command']
        else:
            try:
                command = policy['default_command']
            except KeyError:
                self.term_log.error(_(
                   "You are missing a 'default_command' in your terminal "
                   "settings (usually 50terminal.conf in %s)"
                   % settings_dir))
                return
        # Get the full command
        try:
            full_command = policy['commands'][command]
        except KeyError:
            # The given command isn't an option
            self.term_log.error(_(
                "%s: Attempted to execute invalid command (%s)." % (
                self.current_user['upn'], command)))
            self.ws.send_message(_("Terminal: Invalid command: %s" % command))
            self.term_ended(term)
            return
        if isinstance(full_command, dict): # Extended command definition
            full_command = full_command['command']
        # Make a nice, useful logging line with extra metadata
        log_metadata = {
            "rows": settings["rows"],
            "columns": settings["columns"],
            "term": term,
            "command": command
        }
        self.term_log.info("New Terminal: %s" % term, metadata=log_metadata)
        # Now remove the new-term-specific metadata
        if 'em_dimensions' in settings:
            self.em_dimensions = {
                'height': settings['em_dimensions']['h'],
                'width': settings['em_dimensions']['w']
            }
        user_dir = self.settings['user_dir']
        if term not in self.loc_terms:
            # Setup the requisite dict
            self.loc_terms[term] = {
                'last_activity': datetime.now(),
                'title': 'Gate One',
                'command': command,
                'manual_title': False,
                'metadata': term_metadata, # Any extra info the client gave us
                # This is needed by the terminal sharing policies:
                'user': self.current_user # So we can determine the owner
            }
        term_obj = self.loc_terms[term]
        if self.ws.client_id not in term_obj:
            term_obj[self.ws.client_id] = {
                # Used by refresh_screen()
                'refresh_timeout': None
            }
        if 'multiplex' not in term_obj:
            # Start up a new terminal
            term_obj['created'] = datetime.now()
            # NOTE: Not doing anything with 'created'...  yet!
            now = int(round(time.time() * 1000))
            try:
                user = self.current_user['upn']
            except:
                # No auth, use ANONYMOUS (% is there to prevent conflicts)
                user = 'ANONYMOUS' # Don't get on this guy's bad side
            cmd = cmd_var_swap(full_command, # Swap out variables like %USER%
                gateone_dir=GATEONE_DIR,
                session=self.ws.session, # with their real-world values.
                session_dir=options.session_dir,
                session_hash=short_hash(self.ws.session),
                userdir=user_dir,
                user=user,
                time=now
            )
            # Now swap out any variables like $PATH, $HOME, $USER, etc
            cmd = os.path.expandvars(cmd)
            resumed_dtach = False
            # Create the user's session dir if not already present
            if not os.path.exists(user_session_dir):
                mkdir_p(user_session_dir)
                os.chmod(user_session_dir, 0o770)
            if options.dtach and which('dtach'):
                # Wrap in dtach (love this tool!)
                dtach_path = "{session_dir}/dtach_{location}_{term}".format(
                    session_dir=user_session_dir,
                    location=self.ws.location,
                    term=term)
                if os.path.exists(dtach_path):
                    # Using 'none' for the refresh because termio
                    # likes to manage things like that on his own...
                    cmd = "dtach -a %s -E -z -r none" % dtach_path
                    resumed_dtach = True
                else: # No existing dtach session...  Make a new one
                    cmd = "dtach -c %s -E -z -r none %s" % (dtach_path, cmd)
            self.term_log.debug(_("new_terminal cmd: %s" % repr(cmd)))
            m = term_obj['multiplex'] = self.new_multiplex(
                cmd, term, encoding=encoding)
            # Set some environment variables so the programs we execute can use
            # them (very handy).  Allows for "tight integration" and "synergy"!
            env = {
                'GO_DIR': GATEONE_DIR,
                'GO_SETTINGS_DIR': settings_dir,
                'GO_USER_DIR': user_dir,
                'GO_USER': user,
                'GO_TERM': str(term),
                'GO_LOCATION': self.ws.location,
                'GO_SESSION': self.ws.session,
                'GO_SESSION_DIR': options.session_dir,
                'GO_USER_SESSION_DIR': user_session_dir,
            }
            env.update(os.environ) # Add the defaults for this system
            env.update(environment_vars) # Apply policy-based environment
            if self.plugin_env_hooks:
                # This allows plugins to add/override environment variables
                env.update(self.plugin_env_hooks)
            m.spawn(rows, cols, env=env, em_dimensions=self.em_dimensions)
            # Give the terminal emulator a path to store temporary files
            m.term.temppath = os.path.join(user_session_dir, 'downloads')
            if not os.path.exists(m.term.temppath):
                os.mkdir(m.term.temppath)
            # Tell it how to serve them up (origin ensures correct link)
            m.term.linkpath = "{server_url}downloads".format(
                server_url=self.ws.base_url)
            # Make sure it can generate pretty icons for file downloads
            m.term.icondir = os.path.join(GATEONE_DIR, 'static', 'icons')
            if resumed_dtach:
                # Send an extra Ctrl-L to refresh the screen and fix the sizing
                # after it has been reattached.
                m.write('\x0c')
        else:
            # Terminal already exists
            m = term_obj['multiplex']
            if m.isalive():
                # It's ALIVE!!!
                if term_obj['user'] == self.current_user:
                    m.resize(
                        rows, cols,
                        ctrl_l=False,
                        em_dimensions=self.em_dimensions)
                message = {'terminal:term_exists': {'term': term}}
                self.write_message(json_encode(message))
                # This resets the screen diff
                m.prev_output[self.ws.client_id] = [None] * rows
            else:
                # Tell the client this terminal is no more
                self.term_ended(term)
                return
        # Setup callbacks so that everything gets called when it should
        self.add_terminal_callbacks(
            term, term_obj['multiplex'], self.callback_id)
        # NOTE: refresh_screen will also take care of cleaning things up if
        #       term_obj['multiplex'].isalive() is False
        self.refresh_screen(term, True) # Send a fresh screen to the client
        self.current_term = term
        # Restore expanded modes
        for mode, setting in m.term.expanded_modes.items():
            self.mode_handler(term, mode, setting)
        if self.settings['logging'] == 'debug':
            self.ws.send_message(_(
                "WARNING: Logging is set to DEBUG.  All keystrokes will be "
                "logged!"))
        self.send_term_encoding(term, encoding)
        if self.loc_terms[term]['multiplex'].cmd.startswith('dtach -a'):
            # This dtach session was resumed; restore terminal settings
            m_term = term_obj['multiplex'].term
            future = self.restore_term_settings(term)
            self.io_loop.add_future(
                future, lambda f: self.set_title(term, force=True, save=False))
            # The multiplex instance needs the title set by hand (it's special)
            self.io_loop.add_future(
                future, lambda f: m_term.set_title(
                    self.loc_terms[term]['title']))
        self.trigger("terminal:new_terminal", term)
        # Calling save_term_settings() after the event is fired so that plugins
        # can modify the metadata before it gets saved.
        self.save_term_settings(
            term, {'metadata': self.loc_terms[term]['metadata']})

    @require(authenticated(), policies('terminal'))
    def set_term_encoding(self, settings):
        """
        Sets the encoding for the given *settings['term']* to
        *settings['encoding']*.
        """
        term = int(settings['term'])
        encoding = settings['encoding']
        try:
            " ".encode(encoding)
        except LookupError:
            # Invalid encoding
            self.ws.send_message(_(
                "Invalid encoding.  For a list of valid encodings see:<br>"
    "<a href='http://docs.python.org/2/library/codecs.html#standard-encodings'"
                " target='new'>Standard Encodings</a>"
            ))
            return
        term_obj = self.loc_terms[term]
        m = term_obj['multiplex']
        m.set_encoding(encoding)
        # Make sure the client is aware that the change was successful

    def send_term_encoding(self, term, encoding):
        """
        Sends a message to the client indicating the *encoding* of *term* (in
        the event that a terminal is reattached or when sharing a terminal).
        """
        message = {'terminal:encoding': {'term': term, 'encoding': encoding}}
        self.write_message(message)

    @require(authenticated(), policies('terminal'))
    def set_term_keyboard_mode(self, settings):
        """
        Sets the keyboard mode (e.g. 'sco') for the given *settings['term']* to
        *settings['mode']*.  This is only so we can inform the client of the
        mode when a terminal is re-attached (the serer-side stuff doesn't use
        keyboard modes).
        """
        valid_modes = ['default', 'sco', 'xterm', 'linux']
        term = int(settings['term'])
        mode = settings['mode']
        if mode not in valid_modes:
            self.ws.send_message(_(
                "Invalid keyboard mode.  Must be one of: %s"
                % ", ".join(valid_modes)))
            return
        term_obj = self.loc_terms[term]
        term_obj['keyboard_mode'] = mode

    def send_term_keyboard_mode(self, term, mode):
        """
        Sends a message to the client indicating the *mode* of *term* (in
        the event that a terminal is reattached or when sharing a terminal).
        """
        message = {'terminal:keyboard_mode': {'term': term, 'mode': mode}}
        self.write_message(message)

    @require(authenticated(), policies('terminal'))
    def swap_terminals(self, settings):
        """
        Swaps the numbers of *settings['term1']* and *settings['term2']*.
        """
        term1 = int(settings.get('term1', 0))
        term2 = int(settings.get('term2', 0))
        if not term1 or not term2:
            return # Nothing to do
        missing_msg = _("Error: Terminal {term} does not exist.")
        if term1 not in self.loc_terms:
            self.ws.send_message(missing_msg.format(term=term1))
            return
        if term2 not in self.loc_terms:
            self.ws.send_message(missing_msg.format(term=term2))
            return
        term1_dict = self.loc_terms.pop(term1)
        term2_dict = self.loc_terms.pop(term2)
        self.loc_terms.update({term1: term2_dict})
        self.loc_terms.update({term2: term1_dict})
        self.trigger("terminal:swap_terminals", term1, term2)

    @require(authenticated(), policies('terminal'))
    def move_terminal(self, settings):
        """
        Attached to the `terminal:move_terminal` WebSocket action. Moves
        *settings['term']* (terminal number) to
        ``SESSIONS[self.ws.session][[*settings['location']*]['terminal']``.  In
        other words, it moves the given terminal to the given location in the
        *SESSIONS* dict.

        If the given location dict doesn't exist (yet) it will be created.
        """
        self.term_log.debug("move_terminal(%s)" % settings)
        new_location_exists = True
        term = existing_term = int(settings['term'])
        new_location = settings['location']
        if term not in self.loc_terms:
            self.ws.send_message(_(
                "Error: Terminal {term} does not exist at the current location"
                " ({location})".format(term=term, location=self.ws.location)))
            return
        existing_term_obj = self.loc_terms[term]
        if new_location not in self.ws.locations:
            term = 1 # Starting anew in the new location
            self.ws.locations[new_location] = {}
            self.ws.locations[new_location]['terminal'] = {
                term: existing_term_obj
            }
            new_location_exists = False
        else:
            existing_terms = [
                a for a in self.ws.locations[
                  new_location]['terminal'].keys()
                    if isinstance(a, int)]
            existing_terms.sort()
            new_term_num = 1
            if existing_terms:
                new_term_num = existing_terms[-1] + 1
            self.ws.locations[new_location][
                'terminal'][new_term_num] = existing_term_obj
        multiplex = existing_term_obj['multiplex']
        # Remove the existing object's callbacks so we don't end up sending
        # things like screen updates to the wrong place.
        try:
            self.remove_terminal_callbacks(multiplex, self.callback_id)
        except KeyError:
            pass # Already removed callbacks--no biggie
        em_dimensions = {
            'h': multiplex.em_dimensions['height'],
            'w': multiplex.em_dimensions['width']
        }
        if new_location_exists:
            # Already an open window using this 'location'...  Tell it to open
            # a new terminal for the user.
            new_location_instance = None
            # Find the ApplicationWebSocket instance using the given 'location':
            for instance in self.ws.instances:
                if instance.location == new_location:
                    ws_instance = instance
                    break
            # Find the TerminalApplication inside the ws_instance:
            for app in ws_instance.apps:
                if isinstance(app, TerminalApplication):
                    new_location_instance = app
            new_location_instance.new_terminal({
                'term': new_term_num,
                'rows': multiplex.rows,
                'columns': multiplex.cols,
                'em_dimensions': em_dimensions
            })
            ws_instance.send_message(_(
                "Incoming terminal from location: %s" % self.ws.location))
        #else:
            # Make sure the new location dict is setup properly
            #self.add_terminal_callbacks(term, multiplex, callback_id)
        # Remove old location:
        del self.loc_terms[existing_term]
        details = {
            'term': term,
            'location': new_location
        }
        message = { # Closes the term in the current window/tab
            'terminal:term_moved': details,
        }
        self.write_message(message)
        self.trigger("terminal:move_terminal", details)

    @require(authenticated(), policies('terminal'))
    def kill_terminal(self, term):
        """
        Kills *term* and any associated processes.
        """
        term = int(term)
        if term not in self.loc_terms:
            return # Nothing to do
        metadata = {
            "term": term,
            "command": self.loc_terms[term]["command"]
        }
        self.term_log.info(
            "Terminal Killed: %s" % term, metadata=metadata)
        multiplex = self.loc_terms[term]['multiplex']
        # Remove the EXIT callback so the terminal doesn't restart itself
        multiplex.remove_callback(multiplex.CALLBACK_EXIT, self.callback_id)
        try:
            if options.dtach: # dtach needs special love
                from gateone.core.utils import kill_dtached_proc
                kill_dtached_proc(self.ws.session, self.ws.location, term)
            if multiplex.isalive():
                multiplex.terminate()
        except KeyError:
            pass # The EVIL termio has killed my child!  Wait, that's good...
                 # Because now I don't have to worry about it!
        finally:
            del self.loc_terms[term]
            self.clear_term_settings(term)
        self.trigger("terminal:kill_terminal", term)

    def set_terminal(self, term):
        """
        Sets `self.current_term = *term*` so we can determine where to send
        keystrokes.
        """
        try:
            self.current_term = int(term)
            self.trigger("terminal:set_terminal", term)
        except TypeError:
            pass # Bad term given

    def reset_client_terminal(self, term):
        """
        Tells the client to reset the terminal (clear the screen and remove
        scrollback).
        """
        message = {'terminal:reset_client_terminal': term}
        self.write_message(json_encode(message))
        self.trigger("terminal:reset_client_terminal", term)

    @require(authenticated(), policies('terminal'))
    def reset_terminal(self, term):
        """
        Performs the equivalent of the 'reset' command which resets the terminal
        emulator (among other things) to return the terminal to a sane state in
        the event that something went wrong (bad escape sequence).
        """
        self.term_log.debug('reset_terminal(%s)' % term)
        term = int(term)
        # This re-creates all the tabstops:
        tabs = '\x1bH        ' * 22
        reset_sequence = (
            '\r\x1b[3g        %sr\x1bc\x1b[!p\x1b[?3;4l\x1b[4l\x1b>\r' % tabs)
        multiplex = self.loc_terms[term]['multiplex']
        multiplex.term.write(reset_sequence)
        multiplex.write('\x0c') # ctrl-l
        self.full_refresh(term)
        self.trigger("terminal:reset_terminal", term)

    def set_title(self, term, force=False, save=True):
        """
        Sends a message to the client telling it to set the window title of
        *term* to whatever comes out of::

            self.loc_terms[term]['multiplex'].term.get_title() # Whew! Say that three times fast!

        Example message::

            {'set_title': {'term': 1, 'title': "user@host"}}

        If *force* resolves to True the title will be sent to the cleint even if
        it matches the previously-set title.

        if *save* is ``True`` (the default) the title will be saved via the
        `TerminalApplication.save_term_settings` function so that it may be
        restored later (in the event of a server restart--if you've got dtach
        support enabled).

        .. note:: Why the complexity on something as simple as setting the title?  Many prompts set the title.  This means we'd be sending a 'title' message to the client with nearly every screen update which is a pointless waste of bandwidth if the title hasn't changed.
        """
        self.term_log.debug("set_title(%s, %s, %s)" % (term, force, save))
        term = int(term)
        term_obj = self.loc_terms[term]
        if term_obj['manual_title']:
            if force:
                title = term_obj['title']
                title_message = {
                    'terminal:set_title': {'term': term, 'title': title}}
                self.write_message(json_encode(title_message))
            return
        title = term_obj['multiplex'].term.get_title()
        # Only send a title update if it actually changed
        if title != term_obj['title'] or force:
            term_obj['title'] = title
            title_message = {
                'terminal:set_title': {'term': term, 'title': title}}
            self.write_message(json_encode(title_message))
            # Save it in case we're restarted (only matters for dtach)
            if save:
                self.save_term_settings(term, {'title': title})
        self.trigger("terminal:set_title", term, title)

    @require(authenticated(), policies('terminal'))
    def manual_title(self, settings):
        """
        Sets the title of *settings['term']* to *settings['title']*.  Differs
        from :func:`set_title` in that this is an action that gets called by the
        client when the user sets a terminal title manually.
        """
        self.term_log.debug("manual_title: %s" % settings)
        term = int(settings['term'])
        title = settings['title']
        term_obj = self.loc_terms[term]
        if not title:
            title = term_obj['multiplex'].term.get_title()
            term_obj['manual_title'] = False
        else:
            term_obj['manual_title'] = True
        term_obj['title'] = title
        title_message = {'terminal:set_title': {'term': term, 'title': title}}
        self.write_message(json_encode(title_message))
        # Save it in case we're restarted (only matters for dtach)
        self.save_term_settings(term, {'title': title})
        self.trigger("terminal:manual_title", title)

    def bell(self, term):
        """
        Sends a message to the client indicating that a bell was encountered in
        the given terminal (*term*).  Example message::

            {'bell': {'term': 1}}
        """
        bell_message = {'terminal:bell': {'term': term}}
        self.write_message(json_encode(bell_message))
        self.trigger("terminal:bell", term)

    def mode_handler(self, term, setting, boolean):
        """
        Handles mode settings that require an action on the client by pasing it
        a message like::

            {
                'terminal:set_mode': {
                    'mode': setting,
                    'bool': True,
                    'term': term
                }
            }
        """
        self.term_log.debug(
            "mode_handler() term: %s, setting: %s, boolean: %s" %
            (term, setting, boolean))
        term_obj = self.loc_terms[term]
        # So we can restore it:
        term_obj['application_mode'] = boolean
        if boolean:
            # Tell client to set this mode
            mode_message = {'terminal:set_mode': {
                'mode': setting,
                'bool': True,
                'term': term
            }}
            self.write_message(json_encode(mode_message))
        else:
            # Tell client to reset this mode
            mode_message = {'terminal:set_mode': {
                'mode': setting,
                'bool': False,
                'term': term
            }}
            self.write_message(json_encode(mode_message))
        self.trigger("terminal:mode_handler", term, setting, boolean)

    def dsr(self, term, response):
        """
        Handles Device Status Report (DSR) calls from the underlying program
        that get caught by the terminal emulator.  *response* is what the
        terminal emulator returns from the CALLBACK_DSR callback.

        .. note:: This also handles the CSI DSR sequence.
        """
        m = self.loc_terms[term]['multiplex']
        m.write(response)

    def _send_refresh(self, term, full=False):
        """Sends a screen update to the client."""
        try:
            term_obj = self.loc_terms[term]
            term_obj['last_activity'] = datetime.now()
        except KeyError:
            # This can happen if the user disconnected in the middle of a screen
            # update or if the terminal was closed really quickly before the
            # Tornado framework got a chance to call this function.  Nothing to
            # be concerned about.
            return # Ignore
        multiplex = term_obj['multiplex']
        scrollback, screen = multiplex.dump_html(
            full=full, client_id=self.ws.client_id)
        if [a for a in screen if a]: # Checking for non-empty lines here
            output_dict = {
                'terminal:termupdate': {
                    'term': term,
                    'scrollback': scrollback,
                    'screen' : screen,
                    'ratelimiter': multiplex.ratelimiter_engaged
                }
            }
            try:
                self.write_message(json_encode(output_dict))
            except IOError: # Socket was just closed, no biggie
                self.term_log.info(
                    _("WebSocket closed (%s)") % self.current_user['upn'])
                multiplex = term_obj['multiplex']
                multiplex.remove_callback( # Stop trying to write
                    multiplex.CALLBACK_UPDATE, self.callback_id)

    def refresh_screen(self, term, full=False):
        """
        Writes the state of the given terminal's screen and scrollback buffer to
        the client using `_send_refresh()`.  Also ensures that screen updates
        don't get sent too fast to the client by instituting a rate limiter that
        also forces a refresh every 150ms.  This keeps things smooth on the
        client side and also reduces the bandwidth used by the application (CPU
        too).

        If *full*, send the whole screen (not just the difference).
        """
        # Commented this out because it was getting annoying.
        # Note to self: add more levels of debugging beyond just "debug".
        #self.term_log.debug(
            #"refresh_screen (full=%s) on %s" % (full, self.callback_id))
        if term:
            term = int(term)
        else:
            return # This just prevents an exception when the cookie is invalid
        term_obj = self.loc_terms[term]
        try:
            msec = timedelta(milliseconds=50) # Keeps things smooth
            # In testing, 150 milliseconds was about as low as I could go and
            # still remain practical.
            force_refresh_threshold = timedelta(milliseconds=150)
            last_activity = term_obj['last_activity']
            timediff = datetime.now() - last_activity
            # Because users can be connected to their session from more than one
            # browser/computer we differentiate between refresh timeouts by
            # tying the timeout to the client_id.
            client_dict = term_obj[self.ws.client_id]
            multiplex = term_obj['multiplex']
            refresh = partial(self._send_refresh, term, full)
            # We impose a rate limit of max one screen update every 50ms by
            # wrapping the call to _send_refresh() in an IOLoop timeout that
            # gets cancelled and replaced if screen updates come in faster than
            # once every 50ms.  If screen updates are consistently faster than
            # that (e.g. a key is held down) we also force sending the screen
            # to the client every 150ms.  This ensures that no matter how fast
            # screen updates are happening the user will get at least one
            # update every 150ms.  It works out quite nice, actually.
            if client_dict['refresh_timeout']:
                multiplex.io_loop.remove_timeout(client_dict['refresh_timeout'])
            if timediff > force_refresh_threshold:
                refresh()
            else:
                client_dict['refresh_timeout'] = multiplex.io_loop.add_timeout(
                    msec, refresh)
        except KeyError as e: # Session died (i.e. command ended).
            self.term_log.debug(_("KeyError in refresh_screen: %s" % e))
        self.trigger("terminal:refresh_screen", term)

    def full_refresh(self, term):
        """Calls `self.refresh_screen(*term*, full=True)`"""
        try:
            term = int(term)
        except ValueError:
            self.term_log.debug(_(
                "Invalid terminal number given to full_refresh(): %s" % term))
        self.refresh_screen(term, full=True)
        self.trigger("terminal:full_refresh", term)

    @require(authenticated(), policies('terminal'))
    def resize(self, resize_obj):
        """
        Resize the terminal window to the rows/columns specified in *resize_obj*

        Example *resize_obj*::

            {'rows': 24, 'columns': 80}
        """
        term = None
        if 'term' in resize_obj:
            try:
                term = int(resize_obj['term'])
            except ValueError:
                return # Got bad value, skip this resize
        self.term_log.info("Resizing Terminal: %s" % term, metadata=resize_obj)
        rows = resize_obj['rows']
        cols = resize_obj['columns']
        self.em_dimensions = {
            'height': resize_obj['em_dimensions']['h'],
            'width': resize_obj['em_dimensions']['w']
        }
        ctrl_l = False
        if 'ctrl_l' in resize_obj:
            ctrl_l = resize_obj['ctrl_l']
        if rows < 2 or cols < 2:
            # Fall back to a standard default:
            rows = 24
            cols = 80
        # If the user already has a running session, set the new terminal size:
        try:
            if term:
                m = self.loc_terms[term]['multiplex']
                m.resize(
                    rows,
                    cols,
                    em_dimensions=self.em_dimensions,
                    ctrl_l=ctrl_l
                )
            else: # Resize them all
                for term in list(self.loc_terms.keys()):
                    if isinstance(term, int): # Skip the TidyThread
                        self.loc_terms[term]['multiplex'].resize(
                            rows,
                            cols,
                            em_dimensions=self.em_dimensions,
                            ctrl_l=ctrl_l
                        )
        except KeyError: # Session doesn't exist yet, no biggie
            pass
        self.write_message(
            {"terminal:resize": {"term": term, "rows": rows, "columns": cols}})
        self.trigger("terminal:resize", term)

    @require(authenticated(), policies('terminal'))
    def char_handler(self, chars, term=None):
        """
        Writes *chars* (string) to *term*.  If *term* is not provided the
        characters will be sent to the currently-selected terminal.
        """
        self.term_log.debug("char_handler(%s, %s)" % (repr(chars), repr(term)))
        if not term:
            term = self.current_term
        term = int(term) # Just in case it was sent as a string
        if self.ws.session in SESSIONS and term in self.loc_terms:
            multiplex = self.loc_terms[term]['multiplex']
            if multiplex.isalive():
                multiplex.write(chars)
                # Handle (gracefully) the situation where a capture is stopped
                if '\x03' in chars:
                    if not multiplex.term.capture:
                        return # Nothing to do
                    # Make sure the call to abort_capture() comes *after* the
                    # underlying program has itself caught the SIGINT (Ctrl-C)
                    multiplex.io_loop.add_timeout(
                        timedelta(milliseconds=1000),
                        multiplex.term.abort_capture)
                    # Also make sure the client gets a screen update
                    refresh = partial(self.refresh_screen, term)
                    multiplex.io_loop.add_timeout(
                        timedelta(milliseconds=1050), refresh)

    @require(authenticated(), policies('terminal'))
    def write_chars(self, message):
        """
        Writes *message['chars']* to *message['term']*.  If *message['term']*
        is not present, *self.current_term* will be used.
        """
        #self.term_log.debug('write_chars(%s)' % message)
        if 'chars' not in message:
            return # Invalid message
        if 'term' not in message:
            message['term'] = self.current_term
        try:
            self.char_handler(message['chars'], message['term'])
        except Exception as e:
            # Term is closed or invalid
            self.term_log.error(_(
                "Got exception trying to write_chars() to terminal %s"
                % message['term']))
            self.term_log.error(str(e))
            import traceback
            traceback.print_exc(file=sys.stdout)

    def opt_esc_handler(self, term, multiplex, chars):
        """
        Calls whatever function is attached to the
        'terminal:opt_esc_handler:<name>' event; passing it the *text* (second
        item in the tuple) that is returned by
        :func:`utils.process_opt_esc_sequence`.  Such functions are usually
        attached via the 'Escape' plugin hook but may also be registered via
        the usual event method, :meth`self.on`::

            self.on('terminal:opt_esc_handler:somename', some_function)

        The above example would result in :func:`some_function` being called
        whenever a matching optional escape sequence handler is encountered.
        For example:

        .. ansi-block::

            $ echo -e "\033]_;somename|Text passed to some_function()\007"

        Which would result in :func:`some_function` being called like so::

            some_function(
                self, "Text passed to some_function()", term, multiplex)

        In the above example, *term* will be the terminal number that emitted
        the event and *multiplex* will be the `termio.Multiplex` instance that
        controls the terminal.
        """
        self.term_log.debug("opt_esc_handler(%s)" % repr(chars))
        plugin_name, text = process_opt_esc_sequence(chars)
        if plugin_name:
            try:
                event = "terminal:opt_esc_handler:%s" % plugin_name
                self.trigger(event, text, term=term, multiplex=multiplex)
            except Exception as e:
                self.term_log.error(_(
                    "Got exception trying to execute plugin's optional ESC "
                    "sequence handler..."))
                self.term_log.error(str(e))
                import traceback
                traceback.print_exc(file=sys.stdout)

    def get_bell(self):
        """
        Sends the bell sound data to the client in in the form of a data::URI.
        """
        bell_path = os.path.join(APPLICATION_PATH, 'static')
        bell_path = os.path.join(bell_path, 'bell.ogg')
        try:
            bell_data_uri = create_data_uri(bell_path)
        except (IOError, MimeTypeFail): # There's always the fallback
            self.term_log.error(_("Could not load bell: %s") % bell_path)
            fallback_path = os.path.join(
                APPLICATION_PATH, 'static', 'fallback_bell.txt')
            with io.open(fallback_path, encoding='utf-8') as f:
                bell_data_uri = f.read()
        mimetype = bell_data_uri.split(';')[0].split(':')[1]
        message = {
            'terminal:load_bell': {
                'data_uri': bell_data_uri, 'mimetype': mimetype
            }
        }
        self.write_message(json_encode(message))

    def get_webworker(self):
        """
        Sends the text of our term_ww.js to the client in order to get
        around the limitations of loading remote Web Worker URLs (for embedding
        Gate One into other apps).
        """
        static_url = os.path.join(APPLICATION_PATH, "static")
        webworker_path = os.path.join(static_url, 'webworkers', 'term_ww.js')
        with io.open(webworker_path, encoding='utf-8') as f:
            go_process = f.read()
        message = {'terminal:load_webworker': go_process}
        self.write_message(json_encode(message))

    def get_colors(self, settings):
        """
        Sends the text color stylesheet matching the properties specified in
        *settings* to the client.  *settings* must contain the following:

           :colors: The name of the CSS text color scheme to be retrieved.
        """
        self.term_log.debug('get_colors(%s)' % settings)
        send_css = self.ws.prefs['*']['gateone'].get('send_css', True)
        if not send_css:
            if not hasattr('logged_css_message', self):
                self.term_log.info(_(
                    "send_css is false; will not send JavaScript."))
            # So we don't repeat this message a zillion times in the logs:
            self.logged_css_message = True
            return
        templates_path = os.path.join(APPLICATION_PATH, 'templates')
        term_colors_path = os.path.join(templates_path, 'term_colors')
        colors_filename = "%s.css" % settings["colors"]
        colors_path = os.path.join(term_colors_path, colors_filename)
        filename = "term_colors.css" # Make sure it's the same every time
        self.render_and_send_css(colors_path,
            element_id="text_colors", filename=filename)

    @require(policies('terminal'))
    def get_locations(self):
        """
        Attached to the `terminal:get_locations` WebSocket action.  Sends a
        message to the client (via the `terminal:term_locations` WebSocket
        action) listing all 'locations' where terminals reside.

        .. note::

            Typically the location mechanism is used to open terminals in
            different windows/tabs.
        """
        term_locations = {}
        for location, obj in self.ws.locations.items():
            terms = obj.get('terminal', None)
            if terms:
                term_locations[location] = terms.keys()
        message = {'terminal:term_locations': term_locations}
        self.write_message(json_encode(message))
        self.trigger("terminal:term_locations", term_locations)

# Terminal sharing TODO (not in any particular order or priority):
#   * GUI elements that allow a user to share a terminal:
#       DONE Share this terminal:
#           DONE - Allow anyone with the right URL to view (requires authorization-on-connect).
#           DONE - Allow only authenticated users.
#           DONE - Allow only specified users.
#       - Sharing controls widget (pause/resume sharing, primarily).
#       - Chat widget (or similar--maybe with audio/video via WebRTC).
#       - A mechanism to invite people (send an email/alert).
#       - A mechanism to approve inbound viewers (for "allow AUTHENTICATED" situations).
#   * A server-side API to control sharing:
#       DONE - Share X with authorization options (allow anon w/URL and/or password, authenticated users, or a specific list)
#       DONE            - Stop sharing terminal X.
#       - Pause sharing of terminal X (So it can be resumed without having to change the viewers/write list).
#       DONE - Generate sharing URL for terminal X.
#       - Send invitation to view terminal X.  Connected user(s), email, and possibly other mechanisms (Jabber/Google Talk, SMS, etc)
#       - Approve inbound viewer.
#       DONE            - Allow viewer(s) to control terminal X.
#       - A completely separate chat/communications API.
#       DONE            - List shared terminals.
#       DONE            - Must integrate policy support for @require(policies('terminal'))
#   * A client-side API to control sharing:
#       DONE - Notify user of connected viewers.
#       - Notify user of access/control grants.
#       - Control playback history via server-side events (in case a viewer wants to point something out that just happened).
#   * DONE - A RequestHandler to handle anonymous connections to shared terminals.  Needs to serve up something specific (not index.html).
#   * DONE - A mechanism to generate anonymous sharing URLs.
#   * A way for users to communicate with each other (chat, audio, video).
#   * DONE - A mechansim for password-protecting shared terminals.
#   * Logic to detect the optimum terminal size for all viewers.
#   * DONE - A data structure of some sort to keep track of shared terminals and who is currently connected to them.
#   * A way to view multiple shared terminals on a single page with the option to break them out into individual windows/tabs.
    @require(authenticated(), policies('terminal'))
    def permissions(self, settings):
        """
        Attached to the `terminal:permissions` WebSocket action; controls the
        sharing permissions on a given *settings['term']*.  Specifically, who
        may view or write to a given terminal.

        The *settings* dict **must** contain the following::

            {
                'term': <terminal number>,
                'read': <"ANONYMOUS", "AUTHENTICATED", or a list of UPNs>
            }

        Optionally, the *settings* dict may also contain the following::

            {
                'broadcast': <True/False>, # Default: False
                'password': <string>, # Default: No password
                'write': <"ANONYMOUS", "AUTHENTICATED",  or a list of UPNs>
                # If "write" is omitted the terminal will be shared read-only
            }

        If *broadcast* is True, anyone will be able to connect to the shared
        terminal without a password.  A URL where users can access the shared
        terminal will be automatically generated.

        If a *password* is provided, the given password will be required before
        users may connect to the shared terminal.

        Example WebSocket command to share a terminal:

        .. code-block:: javascript

            settings = {
                "term": 1,
                "read": "AUTHENTICATED",
                "password": "foo" // Omit if no password is required
            }
            GateOne.ws.send(JSON.stringify({"terminal:permissions": settings}));

        .. note::

            If the server is configured with `"auth": "none"` and
            *settings['read']* is "AUTHENTICATED" all users will be able to view
            the shared terminal without having to enter a password.
        """
        self.term_log.debug("permissions(%s)" % settings)
        from gateone.core.utils import random_words
        share_dict = {}
        term = int(settings.get('term', self.current_term))
        # Share permissions get stored in the PERSIST global
        if 'shared' not in self.ws.persist['terminal']:
            self.ws.persist['terminal']['shared'] = {}
        shared_terms = self.ws.persist['terminal']['shared']
        term_obj = self.loc_terms.get(term, None)
        if not term_obj:
            return # Terminal does not exist (anymore)
        read = settings.get('read', []) # List of who to share with
        if not isinstance(read, (list, tuple)):
            read = [read] # Must be a list even if only one permission
        write = settings.get('write', []) # Who can write (implies read access)
        if not isinstance(write, (list, tuple)):
            write = [write]
        password = settings.get('password', None)
        # "broadcast" mode allows anonymous access without a password
        broadcast_url_template = "{base_url}terminal/shared/{share_id}"
        broadcast = settings.get('broadcast', False)
        for share_id, val in shared_terms.items():
            if val['term_obj'] == term_obj:
                # Save the original read permissions for access check/revoke
                orig_read = shared_terms[share_id]['read']
                # Update existing permissions
                shared_terms[share_id]['read'] = read
                shared_terms[share_id]['write'] = write
                shared_terms[share_id]['password'] = password
                if broadcast == True: # Generate a new broadcast URL
                    broadcast = broadcast_url_template.format(
                        base_url=self.ws.base_url,
                        share_id=share_id)
                shared_terms[share_id]['broadcast'] = broadcast
                # Perform an access check and revoke access for existing viewers
                # if they have been removed from the 'read' list
                for upn in orig_read:
                    if upn not in shared_terms[share_id]['read']:
                        self.remove_viewer(term, upn)
                # Check if nothing is shared anymore so we can remove it
                if not read and not write and not broadcast:
                    self.remove_viewer(term) # Remove all viewers
                    del self.ws.persist['terminal']['shared'][share_id]
                self.get_permissions(term)
                self.notify_permissions()
                return
        if not read and not write and not broadcast:
            return # Nothing to do
        share_id = '-'.join(random_words(2))
        if broadcast == True: # Generate a broadcast URL
            broadcast = broadcast_url_template.format(
                base_url=self.ws.base_url,
                share_id=share_id)
        share_dict.update({
            'user': self.current_user,
            'term': term,
            'term_obj': term_obj,
            'read': read,
            'write': write, # Populated on-demand by the sharing user
            'broadcast': broadcast,
            'password': settings.get('password', None),
            'viewers': []
        })
        shared_terms[share_id] = share_dict
        term_obj['share_id'] = share_id # So we can quickly tell it's shared
        # Make a note of this shared terminal and its permissions in the logs
        self.term_log.info(
            _("{upn} updated sharing permissions on terminal {term} ({title}))")
            .format(
                upn=self.current_user['upn'],
                term=term,
                title=term_obj['title']),
                metadata={'permissions': settings, 'share_id': share_id})
        self.trigger("terminal:permissions", settings)
        # Send the client the permissions information now that it's changed
        self.get_permissions(term)
        self.notify_permissions()

    def remove_viewer(self, term, upn=None):
        """
        Disconnects all callbacks attached to the given *term* for the given
        *upn* and notifies that user that the terminal is no longer shared (so
        it can be shown to be disconnected at the client).

        If *upn* is `None` all users (broadcast viewers included) will have the
        given *term* disconnected.
        """
        cls = ApplicationWebSocket
        term_obj = self.loc_terms[term]
        share_id = term_obj['share_id']
        shared_terms = self.ws.persist['terminal']['shared']
        share_obj = shared_terms[share_id]
        term_app_instance = None
        def disconnect(term_instance, term):
            message = {'terminal:share_disconnected': {'term': term}}
            #self.write_message(json_encode(message))
            if user['upn'] == 'ANONYMOUS':
                cls._deliver(message, session=user['session'])
            else:
                cls._deliver(message, upn=user['upn'])
        for instance in cls.instances:
            try:
                user = instance.current_user
            except AttributeError:
                continue
            if upn and user.get('upn', None) != upn:
                continue
            if share_obj['user'] == user:
                continue # Don't need to "remove" the owner
            for app in instance.apps:
                if isinstance(app, TerminalApplication):
                    # This is that user's instance of the Terminal app
                    term_app_instance = app
                    break
            for u_term_obj in list(term_app_instance.loc_terms.values()):
                if term_obj == u_term_obj:
                    multiplex = u_term_obj['multiplex']
                    self.remove_terminal_callbacks(
                        multiplex, term_app_instance.callback_id)
                    del term_app_instance.loc_terms[term]
                    term_app_instance.clear_term_settings(term)
                    term_app_instance.term_ended(term)
            for i, viewer in enumerate(list(share_obj['viewers'])):
                if viewer['upn'] == user['upn']:
                    share_obj['viewers'].pop(i)
                    break
            if upn and user.get('upn', None) == upn:
                break
        if not term_app_instance:
            return # User is no longer viewing the terminal

    def notify_permissions(self):
        """
        Sends clients the list of shared terminals if they have been granted
        access to any shared terminal.

        .. note::

            Normally this only gets called from
            `~TerminalApplication.permissions` after something changed.
        """
        self.term_log.debug("notify_permissions()")
        cls = ApplicationWebSocket
        users = cls._list_connected_users()
        shared_terms = self.ws.persist['terminal']['shared']
        def send_message(user):
            out_dict = self._shared_terminals_dict(user=user)
            message = {'terminal:shared_terminals': {'terminals': out_dict}}
            if user['upn'] == 'ANONYMOUS':
                cls._deliver(message, session=user['session'])
            else:
                cls._deliver(message, upn=user['upn'])
        for user in users:
            upn = user.get('upn', None)
            if not upn:
                continue
            for share_id, share_dict in shared_terms.items():
                try:
                    if share_dict['user'] == user: # Owner
                        send_message(user)
                        break
                    if 'AUTHENTICATED' in share_dict['read']:
                        send_message(user)
                        break
                    if upn in share_dict['read']:
                        send_message(user)
                        break
                except AttributeError:
                    pass # User disconnected in the middle of this operation

    @require(authenticated(), policies('terminal'))
    def new_share_id(self, settings):
        """
        Generates a new pair of words to act as the share/broadcast ID for a
        given *settings['term']*.  If a 'term' is not provided the currently
        selected terminal will be used.

        Optionally, *settings['share_id'] may be provied to explicitly set it to
        the given value.

        .. note:: The terminal must already be shared with broadcast enabled.
        """
        from gateone.core.utils import random_words
        if 'term' not in settings:
            return # Invalid
        term = int(settings.get('term', self.current_term))
        random_share_id = '-'.join(random_words(2))
        new_share_id = settings.get('share_id', random_share_id)
        shared_terms = self.ws.persist['terminal']['shared']
        term_obj = self.loc_terms[term]
        broadcast_url_template = "{base_url}terminal/shared/{share_id}"
        old_share_id = None
        if new_share_id in shared_terms: # Already exists
            self.write_message(
                _("Share ID '%s' is already in use") % new_share_id)
            return
        for share_id, val in list(shared_terms.items()):
            if val['term_obj'] == term_obj:
                old_share_id = share_id
                broadcast = broadcast_url_template.format(
                    base_url=self.ws.base_url,
                    share_id=new_share_id)
                shared_terms[new_share_id] = shared_terms[share_id]
                shared_terms[new_share_id]['broadcast'] = broadcast
                del shared_terms[share_id]
                self.get_permissions(term)
        self.term_log.info(
            _("{upn} changed share ID of terminal {term} from '{old}'' to "
              "'{new}'").format(
                upn=self.current_user['upn'],
                term=term,
                old=old_share_id,
                new=new_share_id))

    @require(authenticated(), policies('terminal'))
    def get_permissions(self, term):
        """
        Sends the client an object representing the permissions of the given
        *term*.  Example JavaScript:

        .. code-block:: javascript

            GateOne.ws.send(JSON.stringify({
                "terminal:get_permissions": 1
            }));
        """
        if 'shared' not in self.ws.persist['terminal']:
            error_msg = _("Error: Invalid share ID.")
            self.ws.send_message(error_msg)
            return
        out_dict = {'result': 'Success'}
        term_obj = self.loc_terms.get(term, None)
        if not term_obj:
            return # Term doesn't exist
        shared_terms = self.ws.persist['terminal']['shared']
        for share_id, share_dict in shared_terms.items():
            if share_dict['term_obj'] == term_obj:
                out_dict['write'] = share_dict['write']
                out_dict['read'] = share_dict['read']
                out_dict['share_id'] = share_id
                break
        message = {'terminal:sharing_permissions': out_dict}
        self.write_message(json_encode(message))
        self.trigger("terminal:get_sharing_permissions", term)

    @require(authenticated(), policies('terminal'))
    def share_user_list(self, share_id):
        """
        Sends the client a dict of users that are currently viewing the terminal
        associated with *share_id* using the 'terminal:share_user_list'
        WebSocket action.  The output will indicate which users have write
        access.  Example JavaScript:

        .. code-block:: javascript

            var shareID = "notification-chicken";
            GateOne.ws.send(JSON.stringify({
                "terminal:share_user_list": shareID
            }));
        """
        out_dict = {'viewers': [], 'write': []}
        message = {'terminal:share_user_list': out_dict}
        try:
            share_obj = self.ws.persist['terminal']['shared'][share_id]
        except KeyError:
            error_msg = _("No terminal associated with the given share_id.")
            message = {'go:notice': error_msg}
            self.write_message(message)
            return
        if 'viewers' in share_obj:
            for user in share_obj['viewers']:
                # Only let the client know about the UPN and IP Address
                user_dict = {
                    'upn': user['upn'],
                    'ip_address': user['ip_address']
                }
                if 'email' in user:
                    user_dict.update({'email': user['email']})
                out_dict['viewers'].append(user_dict)
        if isinstance(share_obj['write'], list):
            for allowed in share_obj['write']:
                out_dict['write'].append(allowed)
        else:
            out_dict['write'] = share_obj['write']
        self.write_message(message)
        self.trigger("terminal:share_user_list", share_id)

    def _shared_terminals_dict(self, user=None):
        """
        Returns a dict containing information about all shared terminals that
        the given *user* has access to.  If no *user* is given
        `self.current_user` will be used.
        """
        out_dict = {}
        if not user:
            user = self.current_user
        shared_terms = self.ws.persist['terminal'].get('shared', {})
        for share_id, share_dict in shared_terms.items():
            owner = False
            auth_or_anon = False
            explicit_user = False
            for read_perm in share_dict['read']:
                if read_perm in ['AUTHENTICATED', 'ANONYMOUS']:
                    auth_or_anon = True
            if user['upn'] in share_dict['read']:
                explicit_user = True
            if share_dict['user']['upn'] == user['upn']:
                owner = True
            if owner or auth_or_anon or explicit_user:
                password = share_dict.get('password', False)
                if password == None:
                    password = False # Looks better at the client this way
                elif password and not owner: # This would be a string
                    password = True # Don't want to reveal it to the client!
                broadcast = share_dict.get('broadcast', False)
                out_dict[share_id] = {
                    'owner': share_dict['user']['upn'],
                    'term': share_dict['term'], # Only useful for the owner
                    'title': share_dict['term_obj']['title'],
                    'read': share_dict['read'],
                    'write': share_dict['write'],
                    'viewers': share_dict['viewers'],
                    'password_protected': password,
                    'broadcast': broadcast
                }
        return out_dict

    @require(authenticated(), policies('terminal'))
    def list_shared_terminals(self):
        """
        Returns a message to the client listing all the shared terminals they
        may access.  Example JavaScript:

        .. code-block:: javascript

            GateOne.ws.send(JSON.stringify({
                "terminal:list_shared_terminals": null
            }));

        The client will be sent the list of shared terminals via the
        `terminal:shared_terminals` WebSocket action.
        """
        out_dict = self._shared_terminals_dict()
        message = {'terminal:shared_terminals': {'terminals': out_dict}}
        self.write_message(json_encode(message))
        self.trigger("terminal:list_shared_terminals")

    # NOTE: This doesn't require authenticated() so anonymous sharing can work
    @require(policies('terminal'))
    def attach_shared_terminal(self, settings):
        """
        Attaches callbacks for the terminals associated with
        *settings['share_id']* if the user is authorized to view the share or if
        the given *settings['password']* is correct (if shared anonymously).

        To attach to a shared terminal from the client:

        .. code-block:: javascript

            settings = {
                "share_id": "ZWVjNGRiZTA0OTllNDJiODkwOGZjNDA2ZWNkNGU4Y2UwM",
                "password": "password here",
                "metadata": {"optional metadata": "would go here"}
            }
            GateOne.ws.send(JSON.stringify({
                "terminal:attach_shared_terminal": settings
            }));

        .. note::

            Providing a password is only necessary if the shared terminal
            requires it.
        """
        cls = ApplicationWebSocket
        self.term_log.debug("attach_shared_terminal(%s)" % settings)
        if 'share_id' not in settings:
            self.term_log.error(_("Invalid share_id."))
            return
        shared_terms = self.ws.persist['terminal'].get('shared', {})
        password = settings.get('password', None)
        share_obj = None
        for share_id, share_dict in shared_terms.items():
            if share_id == settings['share_id']:
                share_obj = share_dict
                break # This is the share_dict we want
        if not share_obj:
            self.ws.send_message(_("Requested shared terminal does not exist."))
            return
        if not share_obj['broadcast']:
            if 'AUTHENTICATED' not in share_obj['read']:
                if self.current_user['upn'] not in share_obj['read']:
                    self.ws.send_message(_(
                        "You are not authorized to view this terminal"))
                    return
        if share_obj['password'] and password != share_obj['password']:
            self.ws.send_message(_("Invalid password."))
            return
        term = self.highest_term_num() + 1
        term_obj = share_obj['term_obj']
        # Add this terminal to our existing SESSION
        self.loc_terms[term] = term_obj
        # We're basically making a new terminal for this client that happens to
        # have been started by someone else.
        multiplex = term_obj['multiplex']
        if self.ws.client_id not in term_obj:
            term_obj[self.ws.client_id] = {
                # Used by refresh_screen()
                'refresh_timeout': None
            }
        if multiplex.isalive():
            message = {
                'terminal:term_exists': {
                    'term': term, 'share_id': settings['share_id']
                }
            }
            self.write_message(json_encode(message))
            # This resets the screen diff
            multiplex.prev_output[self.ws.client_id] = [
                None for a in range(multiplex.rows-1)]
        # Setup callbacks so that everything gets called when it should
        self.add_terminal_callbacks(
            term, term_obj['multiplex'], self.callback_id)
        # NOTE: refresh_screen will also take care of cleaning things up if
        #       term_obj['multiplex'].isalive() is False
        self.refresh_screen(term, True) # Send a fresh screen to the client
        self.current_term = term
        # Restore expanded modes (at the client)
        for mode, setting in multiplex.term.expanded_modes.items():
            self.mode_handler(term, mode, setting)
        # Tell the client about this terminal's title
        self.set_title(term, force=True, save=False)
        # TODO: Get this performing lookups in an attribute repository
        metadata = settings.get('metadata', {})
        if not metadata:
            metadata = {} # In case it's null/None
        email = metadata.get('email', None)
        upn = metadata.get('upn', email)
        broadcast_viewer = True
        if self.current_user:
            upn = self.current_user['upn']
            broadcast_viewer = False
        # Add this user to the list of viewers
        current_viewer = self.current_user
        if not current_viewer: # Anonymous broadcast viewer
            current_viewer = {
                'upn': upn,
                'email': email,
                'ip_address': self.ws.request.remote_ip,
                'broadcast': True,
                'client_id': self.ws.client_id
            }
        viewer_dict = { # Limit it so we don't give away sensitive info
            'upn': current_viewer['upn'],
            'email': current_viewer.get('email', email),
            'ip_address': current_viewer['ip_address'],
            'broadcast': current_viewer.get('broadcast', False),
            'client_id': self.ws.client_id
        }
        if 'viewers' not in share_obj:
            share_obj['viewers'] = [viewer_dict]
        else:
            share_obj['viewers'].append(viewer_dict)
        # Make a note of this connection in the logs
        self.term_log.info(
            _("{upn} connected to terminal shared by {owner}").format(
                upn=upn,
                owner=share_obj['user']['upn']),
            metadata=current_viewer)
        out_dict = self._shared_terminals_dict(user=share_obj['user'])
        message = {'terminal:shared_terminals': {'terminals': out_dict}}
        self.write_message(json_encode(message))
        # Notify the owner of the terminal that this user is now viewing:
        notice = _("%s (%s) is now viewing terminal %s" % (
            current_viewer['upn'],
            current_viewer['ip_address'],
            share_obj['term']))
        if upn == 'ANONYMOUS':
            self.ws.send_message(notice, session=share_obj['user']['session'])
            # Also send them an updated shared_terminals list:
            cls._deliver(message, session=share_obj['user']['session'])
        else:
            self.ws.send_message(notice, upn=share_obj['user']['upn'])
            cls._deliver(message, upn=share_obj['user']['upn'])
        def remove_callbacks():
            try:
                self.remove_terminal_callbacks(multiplex, self.callback_id)
            except KeyError:
                pass # Already removed callbacks--no biggie
        if broadcast_viewer:
            detach = partial(self.detach_shared_terminal, {'term': term})
            self.on('terminal:on_close', detach)
        else: # This lets regular users resume
            self.on('terminal:on_close', remove_callbacks)
        self.trigger("terminal:attach_shared_terminal", term)

    @require(policies('terminal'))
    def detach_shared_terminal(self, settings):
        """
        Stops watching the terminal specified via *settings['term']*.
        """
        self.term_log.debug("detach_shared_terminal(%s)" % settings)
        term = settings.get('term', None)
        if not term:
            return # bad settings
        term = int(term)
        if term not in self.loc_terms:
            return # Already detached
        term_obj = self.loc_terms[term]
        multiplex = term_obj['multiplex']
        shared_terms = self.ws.persist['terminal'].get('shared', {})
        share_obj = []
        for share_id, share_dict in shared_terms.items():
            if term_obj == share_dict['term_obj']:
                share_obj = share_dict
                break # This is the share dict we want
        # Remove ourselves from the list of viewers for this terminal
        for viewer in list(share_obj['viewers']):
            if viewer['client_id'] == self.ws.client_id:
                share_obj['viewers'].remove(viewer)
        try:
            self.remove_terminal_callbacks(multiplex, self.callback_id)
            del self.loc_terms[term]
            if self.ws.session:
                self.clear_term_settings(term)
        except KeyError:
            pass # Already removed callbacks--no biggie
        finally:
            self.notify_permissions()

    def render_256_colors(self):
        """
        Renders the CSS for 256 color support and saves the result as
        '256_colors.css' in Gate One's configured `cache_dir`.  If that file
        already exists and has not been modified since the last time it was
        generated rendering will be skipped.

        Returns the path to that file as a string.
        """
        # NOTE:  Why generate this every time?  Presumably these colors can be
        #        changed on-the-fly by terminal programs.  That functionality
        #        has yet to be implemented but this function will enable use to
        #        eventually do that.
        # Use the get_settings() function to import our 256 colors (convenient)
        cache_dir = self.ws.settings['cache_dir']
        cached_256_colors = os.path.join(cache_dir, '256_colors.css')
        if os.path.exists(cached_256_colors):
            return cached_256_colors
        colors_json_path = os.path.join(
            APPLICATION_PATH, 'static', '256colors.json')
        color_map = get_settings(colors_json_path, add_default=False)
        # Setup our 256-color support CSS:
        colors_256 = ""
        for i in xrange(256):
            i = str(i)
            fg = "#%s span.fx%s {color: #%s;}" % (
                self.ws.container, i, color_map[i])
            bg = "#%s span.bx%s {background-color: #%s;} " % (
                self.ws.container, i, color_map[i])
            fg_rev =(
                "#%s span.reverse.fx%s {background-color: #%s; color: "
                "inherit;}" % (self.ws.container, i, color_map[i]))
            bg_rev =(
                "#%s span.reverse.bx%s {color: #%s; background-color: "
                "inherit;} " % (self.ws.container, i, color_map[i]))
            colors_256 += "%s %s %s %s\n" % (fg, bg, fg_rev, bg_rev)
        with io.open(cached_256_colors, 'w', encoding="utf-8") as f:
            f.write(colors_256)
        # send_css() will take care of minifiying and caching further
        return cached_256_colors

    def send_256_colors(self):
        """
        Sends the client the CSS to handle 256 color support.
        """
        self.ws.send_css(self.render_256_colors())

    def send_print_stylesheet(self):
        """
        Sends the 'templates/printing/printing.css' stylesheet to the client
        using `ApplicationWebSocket.ws.send_css` with the "media" set to
        "print".
        """
        print_css_path = os.path.join(
            APPLICATION_PATH, 'templates', 'printing', 'printing.css')
        self.render_and_send_css(
            print_css_path, element_id="terminal_print_css", media="print")

    @require(authenticated())
    def debug_terminal(self, term):
        """
        Prints the terminal's screen and renditions to stdout so they can be
        examined more closely.

        .. note:: Can only be called from a JavaScript console like so...

        .. code-block:: javascript

            GateOne.ws.send(JSON.stringify({'terminal:debug_terminal': *term*}));
        """
        m = self.loc_terms[term]['multiplex']
        term_obj = m.term
        screen = term_obj.screen
        renditions = term_obj.renditions
        for i, line in enumerate(screen):
            # This gets rid of images:
            line = [a for a in line if len(a) == 1]
            print("%s:%s" % (i, "".join(line)))
            print(renditions[i])
        try:
            from pympler import asizeof
            print("screen size: %s" % asizeof.asizeof(screen))
            print("renditions size: %s" % asizeof.asizeof(renditions))
            print("Total term object size: %s" % asizeof.asizeof(term_obj))
        except ImportError:
            pass # No biggie
        self.ws.debug() # Do regular debugging as well

def apply_cli_overrides(settings):
    """
    Updates *settings* in-place with values given on the command line and
    updates the `options` global with the values from *settings* if not provided
    on the command line.
    """
    # Figure out which options are being overridden on the command line
    arguments = []
    terminal_options = ('dtach', 'syslog_session_logging', 'session_logging')
    for arg in list(sys.argv)[1:]:
        if not arg.startswith('-'):
            break
        else:
            arguments.append(arg.lstrip('-').split('=', 1)[0])
    for argument in arguments:
        if argument not in terminal_options:
            continue
        if argument in options:
            settings[argument] = options[argument]
    for key, value in settings.items():
        if key in options:
            if str == bytes: # Python 2
                if isinstance(value, unicode):
                    # For whatever reason Tornado doesn't like unicode values
                    # for its own settings unless you're using Python 3...
                    value = str(value)
            setattr(options, key, value)

def init(settings):
    """
    Checks to make sure 50terminal.conf is created if terminal-specific settings
    are not found in the settings directory.

    Also checks to make sure that the logviewer.py script is executable.
    """
    logviewer_path = os.path.join(APPLICATION_PATH, 'logviewer.py')
    import stat
    st = os.stat(logviewer_path)
    if not bool(st.st_mode & stat.S_IXOTH):
        try:
            os.chmod(logviewer_path, 0o755)
        except OSError:
            # We don't have permission to change it.  Not a big deal.
            pass
    terminal_options = ( # These are now terminal-app-specific setttings
        'command', 'dtach', 'session_logging', 'syslog_session_logging'
    )
    if os.path.exists(options.config):
        # Get the old settings from the old config file and use them to generate
        # a new 50terminal.conf
        if 'terminal' not in settings['*']:
            settings['*']['terminal'] = {}
        with io.open(options.config, encoding='utf-8') as f:
            for line in f:
                if line.startswith('#'):
                    continue
                key = line.split('=', 1)[0].strip()
                value = eval(line.split('=', 1)[1].strip())
                if key not in terminal_options:
                    continue
                if key == 'command':
                    # Fix the path to ssh_connect.py if present
                    if 'ssh_connect.py' in value:
                        value = value.replace(
                            '/plugins/', '/applications/terminal/plugins/')
                    # Also fix the path to the known_hosts file
                    if '/ssh/known_hosts' in value:
                        value = value.replace(
                            '/ssh/known_hosts', '/.ssh/known_hosts')
                    key = 'commands' # Convert to new name
                    value = {'SSH': value}
                settings['*']['terminal'].update({key: value})
    required_settings = ('commands', 'default_command', 'session_logging')
    term_settings = settings['*'].get('terminal', {})
    generate_terminal_config = False
    for setting in required_settings:
        if setting not in term_settings:
            generate_terminal_config = True
    if not term_settings or generate_terminal_config:
        # Create some defaults and save the config as 50terminal.conf
        settings_path = options.settings_dir
        terminal_conf_path = os.path.join(settings_path, '50terminal.conf')
        if not os.path.exists(terminal_conf_path):
            from gateone.core.configuration import settings_template
            # TODO: Think about moving 50terminal.conf template into the
            # terminal application's directory.
            template_path = os.path.join(
                GATEONE_DIR, 'templates', 'settings', '50terminal.conf')
            settings['*']['terminal'] = {}
            # Update the settings with defaults
            default_command = (
              GATEONE_DIR +
              "/applications/terminal/plugins/ssh/scripts/ssh_connect.py -S "
              r"'%SESSION_DIR%/%SESSION%/%SHORT_SOCKET%' --sshfp "
              r"-a '-oUserKnownHostsFile=\"%USERDIR%/%USER%/.ssh/known_hosts\"'"
            )
            settings['*']['terminal'].update({
                'dtach': True,
                'session_logging': True,
                'syslog_session_logging': False,
                'commands': {
                    'SSH': {
                        "command": default_command,
                        "description": "Connect to hosts via SSH."
                    }
                },
                'default_command': 'SSH',
                'environment_vars': {
                    'TERM': 'xterm-256color'
                },
                'enabled_filetypes': 'all'
            })
            new_term_settings = settings_template(
                template_path, settings=settings['*']['terminal'])
            with io.open(terminal_conf_path, 'w', encoding='utf-8') as s:
                s.write(_(
                    "// This is Gate One's Terminal application settings "
                    "file.\n"))
                s.write(new_term_settings)
    term_settings = settings['*']['terminal']
    if options.kill:
        from gateone.core.utils import killall
        go_settings = settings['*']['gateone']
        # Kill all running dtach sessions (associated with Gate One anyway)
        killall(go_settings['session_dir'], go_settings['pid_file'])
        # Cleanup the session_dir (it is supposed to only contain temp stuff)
        import shutil
        shutil.rmtree(go_settings['session_dir'], ignore_errors=True)
        sys.exit(0)
    if not which('dtach'):
        term_log.warning(
            _("dtach command not found.  dtach support has been disabled."))
    apply_cli_overrides(term_settings)
    # Fix the path to known_hosts if using the old default command
    for name, command in term_settings['commands'].items():
        if '\"%USERDIR%/%USER%/ssh/known_hosts\"' in command:
            term_log.warning(_(
                "The default path to known_hosts has been changed.  Please "
                "update your settings to use '/.ssh/known_hosts' instead of "
                "'/ssh/known_hosts'.  Applying a termporary fix..."))
            term_settings['commands'][name] = command.replace('/ssh/', '/.ssh/')
    # Initialize plugins so we can add their 'Web' handlers
    enabled_plugins = settings['*']['terminal'].get('enabled_plugins', [])
    plugins_path = os.path.join(APPLICATION_PATH, 'plugins')
    plugins = get_plugins(plugins_path, enabled_plugins)
    # Attach plugin hooks
    plugin_hooks = {}
    imported = load_modules(plugins['py'])
    for plugin in imported:
        try:
            plugin_hooks.update({plugin.__name__: plugin.hooks})
        except AttributeError:
            pass # No hooks, no problem
    # Add static handlers for all the JS plugins (primarily for source maps)
    url_prefix = settings['*']['gateone']['url_prefix']
    plugin_dirs = os.listdir(plugins_path)
    # Remove anything that isn't a directory (just in case)
    plugin_dirs = [
        a for a in plugin_dirs
            if os.path.isdir(os.path.join(plugins_path, a))
    ]
    if not enabled_plugins: # Use all of them
        enabled_plugins = plugin_dirs
    for plugin_name in enabled_plugins:
        plugin_static_url = r"{prefix}terminal/{name}/static/(.*)".format(
            prefix=url_prefix, name=plugin_name)
        static_path = os.path.join(
            APPLICATION_PATH, 'plugins', plugin_name, 'static')
        if os.path.exists(static_path):
            handler = (
                plugin_static_url, StaticHandler, {"path": static_path})
            if handler not in REGISTERED_HANDLERS:
                REGISTERED_HANDLERS.append(handler)
                web_handlers.append(handler)
    # Hook up the 'Web' handlers so those URLs are immediately available
    for hooks in plugin_hooks.values():
        if 'Web' in hooks:
            for handler in hooks['Web']:
                if handler in REGISTERED_HANDLERS:
                    continue # Already registered this one
                else:
                    REGISTERED_HANDLERS.append(handler)
                    web_handlers.append(handler)


# Tell Gate One which classes are applications
apps = [TerminalApplication]
# Tell Gate One about our terminal-specific static file handler
web_handlers.append((
    r'terminal/static/(.*)',
    TermStaticFiles,
    {"path": os.path.join(APPLICATION_PATH, 'static')}
))
web_handlers.append((r'terminal/shared/(.*)', SharedTermHandler))

# Command line argument commands
commands = {
    'termlog': logviewer_main
}

########NEW FILE########
__FILENAME__ = logviewer
#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
#       Copyright 2013 Liftoff Software Corporation
#

# Meta
__version__ = '1.0'
__license__ = "AGPLv3 or Proprietary (see LICENSE.txt)"
__version_info__ = (1, 0)
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'

# Import stdlib stuff
import os, sys, re, io, gzip, fcntl, termios, struct, shutil, tempfile
from time import sleep
from datetime import datetime
from optparse import OptionParser

try:
    import curses
except ImportError:
    curses = None

# Import our own stuff
from gateone import GATEONE_DIR
from gateone.core.utils import raw
from gateone.core.configuration import get_settings, combine_css

# 3rd party imports
from tornado.escape import json_encode, json_decode
import tornado.template

__doc__ = """\
.. _log_viewer:

Log Viewer
==========
Allows the user to play back a given log file like a video (default) or display
it in a syslog-like format.  To view usage information, run it with the --help
switch:

.. ansi-block::
    \x1b[1;31mroot\x1b[0m@host\x1b[1;34m:/opt/gateone $\x1b[0m ./logviewer.py --help
    Usage:  logviewer.py [options] <log file>

    Options:
    --version       show program's version number and exit
    -h, --help      show this help message and exit
    -f, --flat      Display the log line-by-line in a syslog-like format.
    -p, --playback  Play back the log in a video-like fashion. This is the
                    default view.
    --pretty        Preserve font and character renditions when displaying the
                    log in flat view (default).
    --raw           Display control characters and escape sequences when
                    viewing.

Here's an example of how to display a Gate One log (.golog) in a flat, greppable
format:

.. ansi-block::

    \x1b[1;31mroot\x1b[0m@host\x1b[1;34m:/opt/gateone $\x1b[0m ./logviewer.py --flat
    Sep 09 21:07:14 Host/IP or SSH URL [localhost]: modern-host
    Sep 09 21:07:16 Port [22]:
    Sep 09 21:07:16 User: bsmith
    Sep 09 21:07:17 Connecting to: ssh://bsmith@modern-host:22
    Sep 09 21:07:17
    Sep 09 21:07:17 bsmith@modern-host's password:
    Sep 09 21:07:20 Welcome to Ubuntu 11.04 (GNU/Linux 2.6.38-11-generic x86_64)
    Sep 09 21:07:20
    Sep 09 21:07:20  * Documentation:  https://help.ubuntu.com/
    Sep 09 21:07:20
    Sep 09 21:07:20 Last login: Thu Sep 29 08:51:27 2011 from portarisk
    Sep 09 21:07:20 \x1b[1;34mbsmith\x1b[0m@modern-host\x1b[1;34m:~ $\x1b[0m ls
    Sep 09 21:07:21 why_I_love_gate_one.txtto_dont_list.txt
    Sep 09 21:07:21 \x1b[1;34mbsmith\x1b[0m@modern-host\x1b[1;34m:~ $\x1b[0m

About Gate One's Log Format
===========================
Gate One's log format (.golog) is a gzip-compressed unicode (UTF-8) text file
consisting of time-based frames separated by the unicode character, U+F0F0F0.
Each frame consists of JavaScript-style timestamp (because it is compact)
followed by a colon and then the text characters of the frame.  A frame ends
when a U+F0F0F0 character is encountered.

Here are two example .golog frames demonstrating the format::

    1317344834868:\\x1b[H\\x1b[2JHost/IP or SSH URL [localhost]: <U+F0F0F>1317344836086:\\r\\nPort [22]: <U+F0F0F>

Gate One logs can be opened, decoded, and parsed in Python fairly easily::

    import gzip
    golog = gzip.open(path_to_golog).read()
    for frame in golog.split(u"\U000f0f0f".encode('UTF-8')):
        frame_time = float(frame[:13]) # First 13 chars is the timestamp
        # Timestames can be converted into datetime objects very simply:
        datetime_obj = datetime.fromtimestamp(frame_time/1000)
        frame_text = frame[14:] # This gets you the actual text minus the colon
        # Do something with the datetime_obj and the frame_text

.. note:: U+F0F0F0 is from Private Use Area (PUA) 15 in the Unicode Character Set (UCS). It was chosen at random (mostly =) from PUA-15 because it is highly unlikely to be used in an actual terminal program where it could corrupt a session log.

Class Docstrings
================
"""

# Globals
APPLICATION_PATH = os.path.split(__file__)[0]
SEPARATOR = u"\U000f0f0f" # The character used to separate frames in the log
RE_OPT_SEQ = re.compile(r'\x1b\]_\;(.+?)(\x07|\x1b\\)', re.MULTILINE)
RE_TITLE_SEQ = re.compile(
    r'.*\x1b\][0-2]\;(.+?)(\x07|\x1b\\)', re.DOTALL|re.MULTILINE)

# TODO: Support Fast forward/rewind/pause like Gate One itself.
def get_frames(golog_path, chunk_size=131072):
    """
    A generator that iterates over the frames in a .golog file, returning them
    as strings.
    """
    encoded_separator = SEPARATOR.encode('UTF-8')
    golog = gzip.open(golog_path)
    frame = b""
    while True:
        chunk = golog.read(chunk_size)
        frame += chunk
        if encoded_separator in chunk:
            split_frames = frame.split(encoded_separator)
            next_frame = split_frames[-1]
            for fr in split_frames[:-1]:
                # Undo extra CRs caused by capturing shell output on top of
                # shell output
                fr = fr.replace(b'\r\n', b'\n')
                yield fr
            frame = next_frame
        if len(chunk) < chunk_size:
            # Write last frame
            if frame:
                frame = frame.replace(b'\r\n', b'\n')
                yield frame
            break

def retrieve_first_frame(golog_path):
    """
    Retrieves the first frame from the given *golog_path*.
    """
    found_first_frame = None
    frame = b""
    f = gzip.open(golog_path)
    while not found_first_frame:
        frame += f.read(1) # One byte at a time
        if frame.decode('UTF-8', "ignore").endswith(SEPARATOR):
            # That's it; wrap this up
            found_first_frame = True
    distance = f.tell()
    f.close()
    return (frame.decode('UTF-8', "ignore").rstrip(SEPARATOR), distance)

def get_log_metadata(golog_path):
    """
    Returns the metadata from the log at the given *golog_path* in the form of
    a dict.
    """
    metadata = {}
    if not os.path.getsize(golog_path): # 0 bytes
        return metadata # Nothing to do
    try:
        first_frame, distance = retrieve_first_frame(golog_path)
    except IOError:
        # Something wrong with the log...  Probably still being written to
        return metadata
    if first_frame[14:].startswith('{'):
        # This is JSON, capture metadata
        metadata = json_decode(first_frame[14:])
    return metadata # All done

def playback_log(log_path, file_like, show_esc=False):
    """
    Plays back the log file at *log_path* by way of timely output to *file_like*
    which is expected to be any file-like object with write() and flush()
    methods.

    If *show_esc* is True, escape sequences and control characters will be
    escaped so they can be seen in the output.  There will also be no delay
    between the output of frames (under the assumption that if you want to see
    the raw log you want it to output all at once so you can pipe it into
    some other app).
    """
    prev_frame_time = None
    try:
        for count, frame in enumerate(get_frames(log_path)):
            frame_time = float(frame[:13]) # First 13 chars is the timestamp
            frame = frame[14:] # [14:] Skips the timestamp and the colon
            if count == 0:
                # Write it out immediately
                if show_esc:
                    frame = raw(frame)
                file_like.write(frame)
                prev_frame_time = frame_time
            else:
                if show_esc:
                    frame = raw(frame)
                else:
                    # Wait until the time between the previous frame and now
                    # has passed
                    wait_time = (frame_time - prev_frame_time)/1000.0
                    sleep(wait_time) # frame times are in milliseconds
                file_like.write(frame)
                prev_frame_time = frame_time
            file_like.flush()
    except IOError: # Something wrong with the file
        return

def escape_escape_seq(text, preserve_renditions=True, rstrip=True):
    """
    Escapes escape sequences so they don't muck with the terminal viewing *text*
    Also replaces special characters with unicode symbol equivalents (e.g. so
    you can see what they are without having them do anything to your running
    shell)

    If *preserve_renditions* is True, CSI escape sequences for renditions will
    be preserved as-is (e.g. font color, background, etc).

    If *rstrip* is true, trailing escape sequences and whitespace will be
    removed.
    """
    esc_sequence = re.compile(
        r'\x1b(.*\x1b\\|[ABCDEFGHIJKLMNOQRSTUVWXYZa-z0-9=]|[()# %*+].)')
    csi_sequence = re.compile(r'\x1B\[([?A-Za-z0-9;@:\!]*)([A-Za-z@_])')
    #esc_rstrip = re.compile('[ \t]+\x1b.+$')
    out = u""
    esc_buffer = u""
    # If this seems confusing it is because text parsing is a black art! ARRR!
    for char in text:
        if not esc_buffer:
            if char == u'\x1b': # Start of an ESC sequence
                esc_buffer = char
            # TODO: Determine if we should bring this back:
            #elif ord(char) in replacement_map:
                #out += replacement_map[ord(char)]
            else: # Vanilla char.  Booooring.
                out += raw(char)
        else: # Something interesting is going on
            esc_buffer += char
            if char == u'\x07' or esc_buffer.endswith(u'\x1b\\'): # Likely title
                esc_buffer = u'' # Nobody wants to see your naked ESC sequence
                continue
            elif esc_buffer.endswith('\x1b\\'):
                esc_buffer = u'' # Ignore
                continue
            # Nobody wants to see plain ESC sequences in the buf...
            match_obj = esc_sequence.match(esc_buffer)
            if match_obj:
                #seq_type = match_obj.group(1)
                esc_buffer = u'' # Just when you thought you've ESC'd...
                continue
            # CSI ESC sequences...  These are worth a second look
            match_obj = csi_sequence.match(esc_buffer)
            if match_obj:
                csi_type = match_obj.group(2)
                if csi_type == 'm' and preserve_renditions: # mmmmmm!
                    out += esc_buffer # Ooh, naked viewing of pretty things!
                elif csi_type == 'C': # Move cursor right (we want to do this)
                    # Will be something like this: \x1b[208C
                    num_spaces = match_obj.group(1)
                    if not num_spaces:
                        num_spaces = 1
                    spaces = int(num_spaces)
                    out += u' ' * spaces # Add an equivalent amount of spaces
                esc_buffer = u'' # Make room for more!
                continue
    if rstrip:
        # Remove trailing whitespace + trailing ESC sequences
        return out.rstrip()
    else: # All these trailers better make for a good movie
        return out

def flatten_log(log_path, file_like, preserve_renditions=True, show_esc=False):
    """
    Given a log file at *log_path*, write a string of log lines contained
    within to *file_like*.  Where *file_like* is expected to be any file-like
    object with write() and flush() methods.

    If *preserve_renditions* is True, CSI escape sequences for renditions will
    be preserved as-is (e.g. font color, background, etc).  This is to make the
    output appear as close to how it was originally displayed as possible.
    Besides that, it looks really nice =)

    If *show_esc* is True, escape sequences and control characters will be
    visible in the output.  Trailing whitespace and escape sequences will not be
    removed.

    ..note::

        Converts our standard recording-based log format into something that
        can be used with grep and similar search/filter tools.
    """
    from terminal import Terminal, SPECIAL
    metadata = get_log_metadata(log_path)
    rows = metadata.get('rows', 24)
    cols = metadata.get('columns', None)
    if not cols:
        # Try the old metadata format which used 'cols':
        cols = metadata.get('cols', 80)
    term = Terminal(rows=rows, cols=cols, em_dimensions=0)
    out_line = u""
    cr = False
    # We skip the first frame, [1:] because it holds the recording metadata
    for count, frame in enumerate(get_frames(log_path)):
        if count == 0:
            # Skip the first frame (it's just JSON-encoded metadata)
            continue
        # First 13 chars is the timestamp:
        frame_time = float(frame.decode('UTF-8', 'ignore')[:13])
        # Convert to datetime object
        frame_time = datetime.fromtimestamp(frame_time/1000)
        if show_esc:
            frame_time = frame_time.strftime(u'\x1b[0m%b %m %H:%M:%S')
        else: # Renditions preserved == I want pretty.  Make the date bold:
            frame_time = frame_time.strftime(u'\x1b[0;1m%b %m %H:%M:%S\x1b[m')
        if not show_esc:
            term.write(frame[14:])
        if term.capture:
            # Capturing a file...  Keep feeding it frames until complete
            continue
        elif term.captured_files:
            for line in term.screen:
                # Find all the characters that come before/after the capture
                for char in line:
                    if ord(char) >= SPECIAL:
                        adjusted = escape_escape_seq(out_line, rstrip=True)
                        adjusted = frame_time + u' %s\n' % adjusted
                        file_like.write(adjusted.encode('utf-8'))
                        out_line = u""
                        if char in term.captured_files:
                            captured_file = term.captured_files[char].file_obj
                            captured_file.seek(0)
                            file_like.write(captured_file.read())
                            file_like.write(b'\n')
                            del captured_file
                            term.clear_screen()
                            term.close_captured_fds() # Instant cleanup
                    else:
                        out_line += char
            if not out_line:
                continue
            adjusted = frame_time + u' %s\n' % out_line.strip()
            file_like.write(adjusted.encode('utf-8'))
            out_line = u""
            continue
        else:
            term.clear_screen()
        frame = frame.decode('UTF-8', 'ignore')
        for char in frame[14:]:
            if '\x1b[H\x1b[2J' in out_line: # Clear screen sequence
                # Handle the clear screen (usually ctrl-l) by outputting
                # a new log entry line to avoid confusion regarding what
                # happened at this time.
                out_line += u"^L" # Clear screen is a ctrl-l or equivalent
                if show_esc:
                    adjusted = raw(out_line)
                else:
                    adjusted = escape_escape_seq(out_line, rstrip=True)
                adjusted = frame_time + u' %s\n' % adjusted
                file_like.write(adjusted.encode('utf-8'))
                out_line = u""
                continue
            if char == u'\n':
                if show_esc:
                    adjusted = raw(out_line)
                else:
                    adjusted = escape_escape_seq(out_line, rstrip=True)
                if not adjusted:
                    out_line = u"" # Skip empty lines
                    continue
                adjusted = frame_time + u' %s\n' % adjusted
                file_like.write(adjusted.encode('utf-8'))
                out_line = u""
                cr = False
            elif char == u'\r':
                # Carriage returns need special handling.  Make a note of it
                cr = True
            else:
                # \r without \n means that characters were (likely)
                # overwritten.  This usually happens when the user gets to
                # the end of the line (which would create a newline in the
                # terminal but not necessarily the log), erases their
                # current line (e.g. ctrl-u), or an escape sequence modified
                # the line in-place.  To clearly indicate what happened we
                # insert a '^M' and start a new line so as to avoid
                # confusion over these events.
                if cr:
                    out_line += "^M"
                    file_like.write((frame_time + u' ').encode('utf-8'))
                    if show_esc:
                        adjusted = raw(out_line)
                    else:
                        adjusted = escape_escape_seq(out_line, rstrip=True)
                    file_like.write((adjusted + u'\n').encode('utf-8'))
                    out_line = u""
                out_line += char
                cr = False
        file_like.flush()
    del term

def render_log_frames(golog_path, rows, cols, limit=None):
    """
    Returns the frames of *golog_path* as a list of HTML-encoded strings that
    can be used with the playback_log.html template.  It accomplishes this task
    by running the frames through the terminal emulator and capturing the HTML
    output from the `Terminal.dump_html` method.

    If *limit* is given, only return that number of frames (e.g. for preview)
    """
    out_frames = []
    from terminal import Terminal
    term = Terminal(
        # 14/7 for the em_height should be OK for most browsers to ensure that
        # images don't always wind up at the bottom of the screen.
        rows=rows, cols=cols, em_dimensions={'height':14, 'width':7})
    for i, frame in enumerate(get_frames(golog_path)):
        if limit and i == limit:
            break
        if len(frame) > 14:
            if i == 0 and frame[14:15] == b'{':
                # This is just the metadata frame.  Skip it
                continue
            frame_time = int(float(frame[:13]))
            frame_screen = frame[14:] # Skips the colon
            # Emulate how a real shell would output newlines:
            frame_screen = frame_screen.replace(b'\n', b'\r\n')
            term.write(frame_screen)
            # Ensure we're not in the middle of capturing a file.  Otherwise
            # it might get cut off and result in no image being shown.
            if term.capture:
                continue
            scrollback, screen = term.dump_html()
            out_frames.append({'screen': screen, 'time': frame_time})
    del term # Ensures any file capture file descriptors are cleaned up
    return out_frames # Skip the first frame which is the metadata

def get_256_colors(container="gateone"):
    """
    Returns the rendered 256-color CSS.  If *container* is provided it will be
    used as the ``{{container}}`` variable when rendering the template (
    defaults to "gateone").
    """
    colors_json_path = os.path.join(
        APPLICATION_PATH, 'static', '256colors.json')
    # Using get_settings() as a cool hack to get the color data as a nice dict:
    color_map = get_settings(colors_json_path, add_default=False)
    # Setup our 256-color support CSS:
    colors_256 = ""
    for i in xrange(256):
        i = str(i)
        fg = u"#%s span.fx%s {color: #%s;}" % (
            container, i, color_map[i])
        bg = u"#%s span.bx%s {background-color: #%s;} " % (
            container, i, color_map[i])
        fg_rev =(
            u"#%s span.reverse.fx%s {background-color: #%s; color: "
            u"inherit;}" % (container, i, color_map[i]))
        bg_rev =(
            u"#%s span.reverse.bx%s {color: #%s; background-color: "
            u"inherit;} " % (container, i, color_map[i]))
        colors_256 += "%s %s %s %s\n" % (fg, bg, fg_rev, bg_rev)
    return colors_256

def render_html_playback(golog_path, render_settings=None):
    """
    Generates a self-contained HTML playback file from the .golog at the given
    *golog_path*.  The HTML will be output to stdout.  The optional
    *render_settings* argument (dict) can include the following options
    to control how the output is rendered:

        :prefix:
            (Default: `"go_default_"`) The GateOne.prefs.prefix to emulate when
            rendering the HTML template.
        :container:
            (Default: `"gateone"`) The name of the #gateone container to emulate
            when rendering the HTML template.
        :theme:
            (Default: `"black"`) The theme to use when rendering the HTML
            template.
        :colors:
            (Default: `"default"`) The text color scheme to use when rendering
            the HTML template.
    """
    # Get the necessary variables out of render_settings
    if not render_settings:
        render_settings = {}
    terminal_app_path = os.path.join(GATEONE_DIR, 'applications', 'terminal')
    prefix = render_settings.get('prefix', 'go_default_')
    container = render_settings.get('container', 'gateone')
    colors = render_settings.get('colors', 'default')
    theme = render_settings.get('theme', 'black')
    temploc = tempfile.mkdtemp(prefix='logviewer') # stores rendered CSS
    # This function renders all themes
    combine_css(os.path.join(
        temploc, 'gateone.css'), container, log=False)
    theme_css_file = "gateone_theme_{theme}.css".format(theme=theme)
    theme_css_path = os.path.join(temploc, theme_css_file)
    with io.open(theme_css_path, mode='r', encoding='utf-8') as f:
        theme_css = f.read()
    # Cleanup the CSS files since we're now down with them
    shutil.rmtree(temploc)
    # Colors are easiest since they don't need to be rendered
    colors_css_file = "{0}.css".format(colors)
    colors_css_path = os.path.join(
        terminal_app_path, 'templates', 'term_colors', colors_css_file)
    with io.open(colors_css_path, mode='r', encoding='utf-8') as f:
        colors_css = f.read()
    templates_path = os.path.join(
        terminal_app_path, 'plugins', 'logging', 'templates')
    asis = lambda x: x # Used to disable autoescape
    loader = tornado.template.Loader(templates_path, autoescape="asis")
    playback_template = loader.load('playback_log.html')
    metadata = get_log_metadata(golog_path)
    rows = metadata.get('rows', 24)
    cols = metadata.get('columns', None)
    if not cols:
        # Try the old metadata format which used 'cols':
        cols = metadata.get('cols', 80)
    recording = render_log_frames(golog_path, rows, cols)
    playback_html = playback_template.generate(
        asis=asis,
        prefix=prefix,
        container=container,
        theme=theme_css,
        colors=colors_css,
        colors_256=get_256_colors(container),
        preview="false", # Only used by the logging plugin
        recording=json_encode(recording)
    )
    if not isinstance(playback_html, str):
        playback_html = playback_html.decode('utf-8')
    return playback_html

def get_terminal_size():
    """
    Returns the size of the current terminal in the form of (rows, cols).
    """
    env = os.environ
    def ioctl_GWINSZ(fd):
        try:
            cr = struct.unpack('hh', fcntl.ioctl(fd, termios.TIOCGWINSZ,
        '1234'))
        except:
            return None
        return cr
    cr = ioctl_GWINSZ(0) or ioctl_GWINSZ(1) or ioctl_GWINSZ(2)
    if not cr:
        try:
            fd = os.open(os.ctermid(), os.O_RDONLY)
            cr = ioctl_GWINSZ(fd)
            os.close(fd)
        except:
            pass
    if not cr:
        try:
            cr = (env['LINES'], env['COLUMNS'])
        except:
            cr = (25, 80)
    return int(cr[0]), int(cr[1])

def main(args=sys.argv):
    """
    Parse command line arguments and view the log in the specified format.
    """
    usage = ('\t%prog [options] <log file>')
    parser = OptionParser(usage=usage, version=__version__)
    parser.disable_interspersed_args()
    parser.add_option("-f", "--flat",
        dest="flat",
        default=False,
        action="store_true",
        help="Display the log line-by-line in a syslog-like format."
    )
    parser.add_option("-p", "--playback",
        dest="playback",
        default=True,
        action="store_false",
        help=("Play back the log in a video-like fashion. This is the default "
              "view.")
    )
    parser.add_option("--pretty",
        dest="pretty",
        default=True,
        action="store_true",
        help=("Preserve font and character renditions when displaying the log "
              "in flat view (default).")
    )
    parser.add_option("--raw",
        dest="raw",
        default=False,
        action="store_true",
        help="Display control characters and escape sequences when viewing."
    )
    parser.add_option("--html",
        dest="html",
        default=False,
        action="store_true",
        help=(
            "Render a given .golog as a self-contained HTML playback file "
            "(to stdout).")
    )
    parser.add_option("--metadata",
        dest="metadata",
        default=False,
        action="store_true",
        help=( "Prints (to stdout) the metadata of the given .golog")
    )
    (options, args) = parser.parse_args(args=args)
    if len(args) < 1:
        print("ERROR: You must specify a log file to view.")
        parser.print_help()
        sys.exit(1)
    log_path = args[0]
    if not os.path.exists(log_path):
        print("ERROR: %s does not exist" % log_path)
        sys.exit(1)
    sys_stdout = sys.stdout
    if bytes != str: # Python 3
        sys_stdout = sys.stdout.buffer
    sys.stdout.flush() # Make sure it's empty before writing to the buffer
    try:
        if options.metadata:
            import json
            if curses and sys.stderr.isatty():
                try:
                    curses.setupterm()
                    print(json.dumps(get_log_metadata(log_path), indent=4))
                except Exception:
                    print(json.dumps(get_log_metadata(log_path)))
            sys.exit(0)
        elif options.flat:
            flatten_log(
                log_path,
                sys_stdout,
                preserve_renditions=options.pretty, show_esc=options.raw)
        elif options.html:
            result = render_html_playback(log_path)
            print(result)
        else:
            playback_log(log_path, sys_stdout, show_esc=options.raw)
    except (IOError, KeyboardInterrupt):
        # Move the cursor to the bottom of the screen to ensure it isn't in the
        # middle of the log playback output
        rows, cols = get_terminal_size()
        print("\x1b[%s;0H\n" % rows)
    sys.exit(0)

if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = bookmarks
# -*- coding: utf-8 -*-
#
#       Copyright 2011 Liftoff Software Corporation
#

__doc__ = """\
bookmarks.py - A plugin for Gate One that adds fancy bookmarking capabilities.

Hooks
-----
This Python plugin file implements the following hooks::

    hooks = {
        'Web': [
            (r"/bookmarks/fetchicon", FaviconHandler),
            (r"/bookmarks/export", ExportHandler),
            (r"/bookmarks/import", ImportHandler),
        ],
        'WebSocket': {
            'terminal:bookmarks_sync': save_bookmarks,
            'terminal:bookmarks_get': get_bookmarks,
            'terminal:bookmarks_deleted': delete_bookmarks,
            'terminal:bookmarks_rename_tags': rename_tags,
        },
        'Events': {
            'terminal:authenticate': send_bookmarks_css_template
        }
    }

Docstrings
----------
"""

# Meta
__version__ = '1.0'
__license__ = "GNU AGPLv3 or Proprietary (see LICENSE.txt)"
__version_info__ = (1, 0)
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'

# Python stdlib
import os, sys, time, json, socket
from functools import partial

# Our stuff
from gateone.core.server import BaseHandler
from gateone.core.utils import noop, json_encode

# Tornado stuff
import tornado.web
from tornado.escape import json_decode

# 3rd party stuff
PLUGIN_PATH = os.path.split(__file__)[0]
#sys.path.append(os.path.join(PLUGIN_PATH, "dependencies"))

# Globals
boolean_fix = {
    True: True,
    False: False,
    'True': True,
    'False': False,
    'true': True,
    'false': False
}

# Helper functions
def unescape(s):
    """
    Unescape HTML code refs; c.f. http://wiki.python.org/moin/EscapingHtml
    """
    import re
    from htmlentitydefs import name2codepoint
    # Fix the missing one:
    name2codepoint['#39'] = 39
    return re.sub('&(%s);' % '|'.join(name2codepoint), lambda m: unichr(name2codepoint[m.group(1)]), s)

def parse_bookmarks_html(html):
    """
    Reads the Netscape-style bookmarks.html in string, *html* and returns a
    list of Bookmark objects.
    """
    # If this looks impossibly complicated it's because parsing HTML streams is
    # dark voodoo.  I had to push my brains back behind my eyes and into my ears
    # a few times while writing this.
    import html5lib
    out_list = []
    p = html5lib.HTMLParser(tree=html5lib.treebuilders.getTreeBuilder("dom"))
    dom_tree = p.parse(html)
    walker = html5lib.treewalkers.getTreeWalker("dom")
    stream = walker(dom_tree)
    level = 0
    tags = []
    h3on = False
    aon = False
    ddon = False
    add_date = None
    url = None
    icon = None
    name = ""
    for token in stream:
        if 'name' in token:
            if token['name'] == 'dl':
                if token['type'] == 'StartTag':
                    level += 1
                elif token['type'] == 'EndTag':
                    if tags:
                        tags.pop()
                    level -= 1
            if token['name'] == 'dd':
                if token['type'] == 'StartTag':
                    ddon = True
                elif token['type'] == 'EndTag':
                    ddon = False
            if token['name'] == 'h3':
                if token['type'] == 'StartTag':
                    h3on = True
                elif token['type'] == 'EndTag':
                    h3on = False
            if token['name'] == 'a':
                if token['type'] == 'StartTag':
                    aon = True
                elif token['type'] == 'EndTag':
                    aon = False
                    if not add_date: # JavaScript-style 13-digit epoch:
                        add_date = int(round(time.time() * 1000))
                    add_date = int(add_date)
                    if add_date > 9999999999999: # Delicious goes out to 16
                        add_date = int(add_date/1000)
                    if add_date < 10000000000: # Chrome only goes to 10 digits
                        add_date = int(add_date*1000)
                    bm = {
                        'url': url,
                        'name': name.strip(),
                        'tags': [a for a in tags if a], # Remove empty tags
                        'notes': "", # notes
                        'visits': 0, # visits
                        'updated': add_date, # updated
                        'created': add_date, # created
                        'updateSequenceNum': 0, # updateSequenceNum
                        'images': {'favicon': icon}
                    }
                    out_list.append(bm)
                    # Reset everything (just in case)
                    add_date = None
                    url = None
                    icon = None
                    name = ""
        if h3on:
            if token['data']:
                if type(token['data']) == str:
                    tags.append(token['data'])
                elif type(token['data']) == unicode:
                    tags.append(token['data'])
        if ddon: # Indicates that there's notes here
            if token['data']:
                if token['type'] == 'Characters':
                    # Notes get attached to the bookmark we just created
                    out_list[-1]['notes'] = unescape(token['data'].strip())
        if aon:
            if token['type'] == 'StartTag':
                # html5lib changed from using lists to using dicts at some point
                # after 0.90.  Hence the two conditionals below
                if isinstance(token['data'], list):
                    for tup in token['data']:
                        if tup[0] == 'add_date':
                            add_date = tup[1]
                        elif tup[0] == 'href':
                            url = tup[1]
                        elif tup[0] == 'icon':
                            icon = tup[1]
                        elif tup[0] == 'tags':
                            tags = tup[1].split(',') # Delicious-style
                elif isinstance(token['data'], dict):
                    for tup in token['data']:
                        if 'add_date' in tup:
                            add_date = token['data'][tup]
                        elif 'href' in tup:
                            url = token['data'][tup]
                        elif 'icon' in tup:
                            icon = token['data'][tup]
                        elif 'tags' in tup:
                            tags = token['data'][tup].split(',') # Delicious
            elif token['type'] == 'Characters':
                name += unescape(token['data'])
    return out_list

def get_json_tags(bookmarks, url):
    """
    Iterates over *bookmarks* (dict) trying to find tags associated with the
    given *url*.  Returns the tags found as a list.
    """
    tags = []
    # This function has been brought to you by your favorite stock symbol
    if bookmarks.has_key('root') and bookmarks.has_key('children'):
        for item in bookmarks['children']:
            if item['title'] == 'Tags':
                for child in item['children']:
                    if child['type'] == 'text/x-moz-place-container':
                        for subchild in child['children']:
                            if subchild['type'] == 'text/x-moz-place':
                                if subchild['uri'] == url:
                                    tags.append(child['title'])
                                        # "Ahhhhhhh"
                                            # "hhhhhhhh"
                                                # "hhhhhhh"
                                                    # "hhhhhh"
                                                        # "hhhhh"
                                                            # "!!!"
                                                                # <splat>
    return tags

def get_ns_json_bookmarks(json_dict, bookmarks):
    """
    Given a *json_dict*, updates *bookmarks* with each URL as it is found
    within.

    .. note:: Only works with Netscape-style bookmarks.json files.
    """
    if json_dict.has_key('children'):
        for child in json_dict['children']:
            if child['type'] == 'text/x-moz-place':
                if not bookmarks[0].has_key(child['uri']):
                    # Browser won't let you load file: URIs from HTTP pages
                    if child['uri'][0:6] not in ['place:', 'file:/']:
                        # Note the use of json_dict as bookmarks[1] here:
                        tags = get_json_tags(bookmarks[1], child['uri'])
                        if not tags:
                            tags = ['Untagged']
                        if child.has_key("annos"):
                            notes = child["annos"]
                        else:
                            notes = ""
                        if child['lastModified'] > 9999999999999:
                            # Chop off the microseconds to make it 13 digits
                            child['lastModified'] = int(child['lastModified']/1000)
                        elif child['lastModified'] < 10000000000:
                            child['lastModified'] = int(child['lastModified']*1000)
                        if child['dateAdded'] > 9999999999999: # Delicious
                            # Chop off the microseconds to make it 13 digits
                            child['dateAdded'] = int(child['dateAdded']/1000)
                        elif child['dateAdded'] < 10000000000: # Chrome
                            child['dateAdded'] = int(child['dateAdded']*1000)
                        bm = {
                            'url': child['uri'],
                            'name': child['title'].strip(),
                            'tags': tags,
                            'notes': notes,
                            'visits': 0, # visits
                            'updated': child['lastModified'], # updated
                            'created': child['dateAdded'], # created
                            'updateSequenceNum': 0, # updateSequenceNum
                            'images': {} # No icons in JSON :(
                        }
                        bookmarks[0].update({child['uri']: bm})
            elif child['type'] == 'text/x-moz-place-container':
                get_ns_json_bookmarks(child, bookmarks)

def parse_bookmarks_json(json_str):
    """
    Given *json_str*, returns a list of bookmark objects representing the data
    contained therein.
    """
    # TODO: Get this recognizing and parsing our own JSON format.
    json_obj = json.loads(json_str)
    out_list = []
    bookmarks = [{}, json_obj] # Inside a list for persistence
    get_ns_json_bookmarks(json_obj, bookmarks) # Updates urls in-place
    for url, bm in bookmarks[0].items():
        out_list.append(bm)
    return out_list

# Data Structures
class BookmarksDB(object):
    """
    Used to read and write bookmarks to a file on disk.  Can also synchronize
    a given list of bookmarks with what's on disk.  Uses a given bookmark's
    ``updateSequenceNum`` to track what wins the "who is newer?" comparison.
    """
    def __init__(self, user_dir, user):
        """
        Sets up our bookmarks database object and reads everything in.
        """
        self.bookmarks = [] # For temp storage of all bookmarks
        self.user_dir = user_dir
        self.user = user
        users_dir = os.path.join(user_dir, user) # "User's dir"
        self.bookmarks_path = os.path.join(users_dir, "bookmarks.json")
        # Read existing bookmarks into self.bookmarks
        self.open_bookmarks()

    def open_bookmarks(self):
        """
        Opens the bookmarks stored in self.user_dir.  If not present, an
        empty file will be created.
        """
        if not os.path.exists(self.bookmarks_path):
            with open(self.bookmarks_path, 'w') as f:
                f.write('[]') # That's an empty JSON list
            return # Default of empty list will do
        with open(self.bookmarks_path) as f:
            self.bookmarks = json_decode(f.read())

    def save_bookmarks(self):
        """
        Saves self.bookmarks to self.bookmarks_path as a JSON-encoded list.
        """
        with open(self.bookmarks_path, 'w') as f:
            f.write(json_encode(self.bookmarks))

    def sync_bookmarks(self, bookmarks):
        """
        Given *bookmarks*, synchronize with self.bookmarks doing conflict
        resolution and whatnot.
        """
        highest_USN = self.get_highest_USN()
        changed = False # For if there's changes that need to be written
        updated_bookmarks = [] # For bookmarks that are newer on the server
        for bm in bookmarks:
            if bm['url'] == "web+deleted:bookmarks/":
                # Remove the existing deleted entry if it exists
                for j, deleted_bm in enumerate(bm['notes']):
                    if deleted_bm['url'] == bm['url']:
                        # Remove the deleted bookmark entry
                        bm['notes'].pop(j)
            found_existing = False
            for i, db_bookmark in enumerate(self.bookmarks):
                if bm['url'] == db_bookmark['url']:
                    # Bookmark already exists, check which is newer
                    found_existing = True
                    if bm['updateSequenceNum'] > db_bookmark['updateSequenceNum']:
                        # The given bookmark is newer than what's in the DB
                        self.bookmarks[i] = bm # Replace it
                        highest_USN += 1 # Increment the USN
                        self.bookmarks[i]['updateSequenceNum'] = highest_USN
                        changed = True
                    elif bm['updateSequenceNum'] < db_bookmark['updateSequenceNum']:
                        # DB has a newer bookmark.  Add it to the list to send
                        # to the client.
                        updated_bookmarks.append(db_bookmark)
                    # Otherwise the USNs are equal and there's nothing to do
            if not found_existing:
                # This is a new bookmark.  Add it
                highest_USN += 1 # Increment the USN
                bm['updateSequenceNum'] = highest_USN
                self.bookmarks.append(bm)
                changed = True # So it will be saved
        if changed:
            # Write the changes to disk
            self.save_bookmarks()
        # Let the client know what's newer on the server
        return updated_bookmarks

    def delete_bookmark(self, bookmark):
        """Deletes the given *bookmark*."""
        highest_USN = self.get_highest_USN()
        for i, db_bookmark in enumerate(self.bookmarks):
            if bookmark['url'] == db_bookmark['url']:
                # Remove it
                self.bookmarks.pop(i)
                # Add it to the list of deleted bookmarks
                special_deleted_bm = None
                for bm in self.bookmarks:
                    if bm['url'] == "web+deleted:bookmarks/":
                        special_deleted_bm = bm
                # The deleted bookmarks 'bookmark' is just a list of URLs that
                # have been deleted along with the time it happened.  This lets
                # us keep multiple browsers in sync with what's been deleted
                # so we don't inadvertently end up re-adding bookmarks that were
                # deleted by another client.
                if not special_deleted_bm:
                    # Make our first entry
                    special_deleted_bm = {
                        'url': "web+deleted:bookmarks/",
                        'name': "Deleted Bookmarks",
                        'tags': [],
                        'notes': [bookmark],
                        'visits': highest_USN + 1,
                        'updated': int(round(time.time() * 1000)),
                        'created': int(round(time.time() * 1000)),
                        'updateSequenceNum': 0,
                        'images': {}
                    }
                    self.bookmarks.append(special_deleted_bm)
                else:
                    # Check for pre-existing
                    updated = False
                    for j, deleted_bm in enumerate(special_deleted_bm['notes']):
                        if deleted_bm['url'] == bookmark['url']:
                            # Update it in place
                            special_deleted_bm['notes'][j] = bookmark
                            updated = True
                    if not updated:
                        special_deleted_bm['notes'].append(bookmark)
                    highest_USN += 1
                    special_deleted_bm['updateSequenceNum'] = highest_USN
                break
        # Save the change to disk
        self.save_bookmarks()

    def get_bookmarks(self, updateSequenceNum=0):
        """
        Returns a list of bookmarks newer than *updateSequenceNum*.
        If *updateSequenceNum* is 0 or undefined, all bookmarks will be
        returned.
        """
        out_bookmarks = []
        for bm in self.bookmarks:
            if bm['updateSequenceNum'] > updateSequenceNum:
                out_bookmarks.append(bm)
        return out_bookmarks

    def get_highest_USN(self):
        """Returns the highest updateSequenceNum in self.bookmarks"""
        highest_USN = 0
        for bm in self.bookmarks:
            if bm['updateSequenceNum'] > highest_USN:
                highest_USN = bm['updateSequenceNum']
        return highest_USN

    def rename_tag(self, old_tag, new_tag):
        """
        Goes through all bookmarks and renames all tags named *old_tag* to be
        *new_tag*.
        """
        highest_USN = self.get_highest_USN()
        for bm in self.bookmarks:
            if old_tag in bm['tags']:
                highest_USN += 1
                i = bm['tags'].index(old_tag)
                bm['tags'][i] = new_tag
                # Made a change so we need to increment the USN to ensure sync
                bm['updateSequenceNum'] = highest_USN
                bm['updated'] = int(round(time.time() * 1000))
        # Save the change to disk
        self.save_bookmarks()

# Handlers
class FaviconHandler(BaseHandler):
    """
    Retrives the biggest favicon-like icon at the given URL.  It will try to
    fetch apple-touch-icons (which can be nice and big) before it falls back
    to grabbing the favicon.

    .. note:: Works with GET and POST requests but POST is preferred since it keeps the URL from winding up in the server logs.
    """
    # Valid favicon mime types
    favicon_mimetypes = [
        'image/vnd.microsoft.icon',
        'image/x-icon',
        'image/png',
        'image/svg+xml',
        'image/gif',
        'image/jpeg'
    ]
    @tornado.web.asynchronous
    def get(self):
        self.process()

    @tornado.web.asynchronous
    def post(self):
        self.process()

    def process(self):
        url = self.get_argument("url")
        http = tornado.httpclient.AsyncHTTPClient()
        callback = partial(self.on_response, url)
        http.fetch(url, callback, connect_timeout=5.0, request_timeout=5.0)

    def get_favicon_url(self, html):
        """
        Parses *html* looking for a favicon URL.  Returns a tuple of::

            (<url>, <mimetype>)

        If no favicon can be found, returns::

            (None, None)
        """
        import html5lib
        p = html5lib.HTMLParser(
            tree=html5lib.treebuilders.getTreeBuilder("dom"))
        dom_tree = p.parse(html)
        walker = html5lib.treewalkers.getTreeWalker("dom")
        stream = walker(dom_tree)
        fetch_url = None
        mimetype = None
        icon = False
        for token in stream:
            if 'name' in token:
                if token['name'] == 'link':
                    for attr in token['data']:
                        if attr[0] == 'rel':
                            if 'shortcut icon' in attr[1].lower():
                                icon = True
                        elif attr[0] == 'href':
                            fetch_url = attr[1]
                        elif attr[0] == 'type':
                            mimetype = attr[1]
                    if fetch_url and icon:
                        if not mimetype:
                            mimetype = "image/x-icon"
                        if mimetype in self.favicon_mimetypes:
                            return (fetch_url, mimetype)
        return (None, None)

    def on_response(self, url, response):
        try:
            from urlparse import urlparse
        except ImportError: # Python 3.X
            from urllib import parse as urlparse
        if response.error:
            self.write('Unable to fetch icon.')
            self.finish()
            return
        fetch_url = None
        try:
            content = response.body.decode('utf-8')
        except UnicodeDecodeError:
            content = response.body
        parsed_url = urlparse(url)
        (fetch_url, mimetype) = self.get_favicon_url(content)
        if fetch_url:
            if not fetch_url.startswith('http'):
                fetch_url = '%s://%s%s' % (
                    parsed_url.scheme, parsed_url.netloc, fetch_url)
        if not mimetype:
            mimetype = "image/x-icon" # Default
        if not fetch_url:
            fetch_url = '%s://%s/favicon.ico' % (
                parsed_url.scheme, parsed_url.netloc)
        if fetch_url.startswith('http://') or fetch_url.startswith('https://'):
            noop()
        else:
            raise tornado.web.HTTPError(404)
        http = tornado.httpclient.AsyncHTTPClient()
        callback = partial(self.icon_fetch, url, mimetype)
        try:
            http.fetch(
                fetch_url,
                callback,
                connect_timeout=5.0,
                request_timeout=5.0
            )
        except socket.gaierror: # No address associated with hostname
            self.write('Unable to fetch icon.')
            self.finish()
            return

    def icon_multifetch(self, urls, response):
        """
        Fetches the icon at the given URLs, stopping when it finds the biggest.
        If an icon is not found, calls itself again with the next icon URL.
        If the icon is found, writes it to the client and finishes the request.
        """
        if response.error:
            if urls:
                url = urls.pop()
                http = tornado.httpclient.AsyncHTTPClient()
                callback = partial(self.icon_multifetch, urls)
                try:
                    http.fetch(url, callback)
                except socket.gaierror:
                    raise tornado.web.HTTPError(404)
            else:
                raise tornado.web.HTTPError(404)
        else:
            if 'Content-Type' in response.headers:
                mimetype = response.headers['Content-Type']
                self.set_header("Content-Type", mimetype)
            else:
                mimetype = "image/vnd.microsoft.icon"
                self.set_header("Content-Type", mimetype)
            data_uri = "data:%s;base64,%s" % (
                mimetype,
                response.body.encode('base64').replace('\n', '')
            )
            self.write(data_uri)
            self.finish()

    def icon_fetch(self, url, mimetype, response):
        """Returns the fetched icon to the client."""
        if response.error:
            self.write('Unable to fetch icon.')
            self.finish()
            return
        data_uri = "data:%s;base64,%s" % (
            mimetype,
            response.body.encode('base64').replace('\n', '')
        )
        self.set_header("Content-Type", mimetype)
        self.write(data_uri)
        self.finish()

class ImportHandler(tornado.web.RequestHandler):
    """
    Takes a bookmarks.html in a POST and returns a list of bookmarks in JSON
    format
    """
    @tornado.web.asynchronous
    def post(self):
        html = self.request.body
        if html.startswith(b'{'): # This is a JSON file
            bookmarks = parse_bookmarks_json(html)
        else:
            bookmarks = parse_bookmarks_html(html)
        self.write(tornado.escape.json_encode(bookmarks))
        self.finish()
        # NOTE: The client will take care of storing these at the next sync

class ExportHandler(tornado.web.RequestHandler):
    """
    Takes a JSON-encoded list of bookmarks and returns a Netscape-style HTML
    file.
    """
    @tornado.web.asynchronous
    def post(self):
        bookmarks = self.get_argument("bookmarks")
        bookmarks = tornado.escape.json_decode(bookmarks)
        self.set_header("Content-Type", "text/html")
        self.set_header(
            "Content-Disposition", 'attachment; filename="bookmarks.html"')
        templates_path = os.path.join(PLUGIN_PATH, "templates")
        bookmarks_html =  os.path.join(templates_path, "bookmarks.html")
        self.render(bookmarks_html, bookmarks=bookmarks)

# WebSocket commands (not the same as handlers)
def save_bookmarks(self, bookmarks):
    """
    Handles saving *bookmarks* for clients.
    """
    out_dict = {
        'updates': [],
        'count': 0,
        'errors': []
    }
    try:
        user = self.current_user['upn']
        bookmarks_db = BookmarksDB(self.ws.settings['user_dir'], user)
        updates = bookmarks_db.sync_bookmarks(bookmarks)
        out_dict.update({
            'updates': updates,
            'count': len(bookmarks),
        })
        out_dict['updateSequenceNum'] = bookmarks_db.get_highest_USN()
    except Exception as e:
        import traceback
        self.term_log.error("Got exception synchronizing bookmarks: %s" % e)
        traceback.print_exc(file=sys.stdout)
        out_dict['errors'].append(str(e))
    if out_dict['errors']:
        out_dict['result'] = "Upload completed but errors were encountered."
    else:
        out_dict['result'] = "Upload successful"
    message = {'terminal:bookmarks_save_result': out_dict}
    self.write_message(json_encode(message))

def get_bookmarks(self, updateSequenceNum):
    """
    Returns a JSON-encoded list of bookmarks updated since the last
    *updateSequenceNum*.

    If *updateSequenceNum* resolves to False, all bookmarks will be sent to
    the client.
    """
    user = self.current_user['upn']
    bookmarks_db = BookmarksDB(self.settings['user_dir'], user)
    if updateSequenceNum:
        updateSequenceNum = int(updateSequenceNum)
    else: # This will force a full download
        updateSequenceNum = 0
    updated_bookmarks = bookmarks_db.get_bookmarks(updateSequenceNum)
    message = {'terminal:bookmarks_updated': updated_bookmarks}
    self.write_message(json_encode(message))

def delete_bookmarks(self, deleted_bookmarks):
    """
    Handles deleting bookmarks given a *deleted_bookmarks* list.
    """
    user = self.current_user['upn']
    bookmarks_db = BookmarksDB(self.ws.settings['user_dir'], user)
    out_dict = {
        'result': "",
        'count': 0,
        'errors': [],
    }
    try:
        for bookmark in deleted_bookmarks:
            out_dict['count'] += 1
            bookmarks_db.delete_bookmark(bookmark)
        out_dict['result'] = "Success"
    except Exception as e: # TODO: Make this more specific
        self.term_log.error("delete_bookmarks error: %s" % e)
        import traceback
        traceback.print_exc(file=sys.stdout)
        out_dict['result'] = "Errors"
        out_dict['errors'].append(str(e))
    message = {'terminal:bookmarks_delete_result': out_dict}
    self.write_message(json_encode(message))

def rename_tags(self, renamed_tags):
    """
    Handles renaming tags.
    """
    user = self.current_user['upn']
    bookmarks_db = BookmarksDB(self.ws.settings['user_dir'], user)
    out_dict = {
        'result': "",
        'count': 0,
        'errors': [],
        'updates': []
    }
    for pair in renamed_tags:
        old_name, new_name = pair.split(',')
        bookmarks_db.rename_tag(old_name, new_name)
        out_dict['count'] += 1
    message = {'terminal:bookmarks_renamed_tags': out_dict}
    self.write_message(json_encode(message))

def send_bookmarks_css_template(self):
    """
    Sends our bookmarks.css template to the client using the 'load_style'
    WebSocket action.  The rendered template will be saved in Gate One's
    'cache_dir'.
    """
    css_path = os.path.join(PLUGIN_PATH, 'templates', 'bookmarks.css')
    self.ws.render_and_send_css(css_path)

hooks = {
    'Web': [
        (r"/bookmarks/fetchicon", FaviconHandler),
        (r"/bookmarks/export", ExportHandler),
        (r"/bookmarks/import", ImportHandler),
    ],
    'WebSocket': {
        'terminal:bookmarks_sync': save_bookmarks,
        'terminal:bookmarks_get': get_bookmarks,
        'terminal:bookmarks_deleted': delete_bookmarks,
        'terminal:bookmarks_rename_tags': rename_tags,
    },
    'Events': {
        'terminal:authenticate': send_bookmarks_css_template
    }
}

########NEW FILE########
__FILENAME__ = example
# -*- coding: utf-8 -*-
#
#       Copyright 2011 Liftoff Software Corporation
#

__doc__ = """\
example.py - A plugin to demonstrate how to write a Python plugin for Gate One.
Specifically, how to write your own web handlers, WebSocket actions, and take
advantage of all the available hooks and built-in functions.

.. tip:: This plugin is heavily commented with useful information.  Click on the `[source]` links to the right of any given class or function to see the actual code.

Hooks
-----
This Python plugin file implements the following hooks::

    hooks = {
        'Web': [(r"/example", ExampleHandler)],
        'WebSocket': {
            'example_action': example_websocket_action
        },
        'Escape': example_opt_esc_handler,
    }

Docstrings
----------
"""

# Meta information about the plugin.  Your plugin doesn't *have* to have this
# but it is a good idea.
__version__ = '1.0'
__license__ = "Apache 2.0" # The "just don't sue me" license
__version_info__ = (1, 0)
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'

# I like to start my files with imports from Python's standard library...
import os

# Then I like to import things from Gate One itself or my own stuff...
from gateone.core.server import BaseHandler
#from gateone import GATEONE_DIR # <--if you need that path it's here

# This is where I'd typically put 3rd party imports such as Tornado...
import tornado.escape
import tornado.web

# Globals
# This is in case we have relative imports, templates, or whatever:
PLUGIN_PATH = os.path.split(__file__)[0] # Path to our plugin's directory

# Traditional web handler
class ExampleHandler(BaseHandler):
    """
    This is how you add a URL handler to Gate One...  This example attaches
    itslef to https://<your Gate One server>/example in the 'Web' hook at the
    bottom of this file.  It works just like any Tornado
    :class:`~tornado.web.RequestHandler`.  See:

    http://www.tornadoweb.org/documentation/web.html

    ...for documentation on how to write a :class:`tornado.web.RequestHandler` for
    the Tornado framework.  Fairly boilerplate stuff.

    .. note:: The only reason we use :class:`gateone.BaseHandler` instead of a vanilla :class:`tornado.web.RequestHandler` is so we have access to Gate One's :func:`gateone.BaseHandler.get_current_user` function.
    """
    @tornado.web.authenticated # Require the user be authenticated
    def get(self):
        """
        Handle an HTTP GET request to this :class:`~tornado.web.RequestHandler`.
        Connect to:

        https://<your Gate One server>/example

        ...to try it out.
        """
        # This is all that's in example_template.html (so you don't have to open
        # it separately):
        #   <html><head><title>{{bygolly}}, it works!</title></head>
        #   <body>
        #   <p>You're logged in as: {{user}}.</p>
        #   <p>Your session ID ends with {{session}}.</p>
        #   </body>
        #   </html>
        #
        # NOTE: I highly recommend using os.path.join() instead of just using
        # '/' everywhere...  You never know; Gate One might run on Windows one
        # day!
        templates_path = os.path.join(PLUGIN_PATH, "templates")
        example_template =  os.path.join(templates_path, "example_template.html")
        bygolly = "By golly"
        # The get_current_user() function returns a whole dict of information.
        # What's available in there is dependent on which authentication type
        # you're using but you can be assured that 'upn' and 'session' will
        # always be present.
        user_dict = self.get_current_user()
        # Gate One refers to the username as a userPrincipalName (like Kerberos)
        # or 'upn' for short.  Why?  Because it might actually be a username
        # plus a realm or domain name.  e.g. user@REALM or user@company.com
        username = user_dict['upn']
        session = user_dict['session'][:3] # Just the last three (for security)
        self.render(
            example_template, # The path to a template file
            bygolly=bygolly, # Just match up your template's {{whatever}} with
            user=username,   # the keyword arguments passed to self.render()
            session=session)

    def post(self):
        """
        Example Handler for an `HTTP POST <http://en.wikipedia.org/wiki/POST_(HTTP)>`_
        request.  Doesn't actually do anything.
        """
        # If data is POSTed to this handler via an XMLHTTPRequest send() it
        # will show up like this:
        #posted_as_a_whole = self.request.body # xhr.send()
        # If data was POSTed as arguments (i.e. traditional form) it will show
        # up as individual arguments like this:
        #posted_as_argument = self.get_argument("arg") # Form elem 'name="arg"'
        # This is how you can parse JSON:
        #parsed = tornado.escape.json_decode(posted_as_an_argument)
        json_output = {'result': 'Success!'}
        self.write(json_output)
        # You'd put self.finish() here if post() was wrapped with tornado's
        # asynchronous decorator.

# WebSocket actions (aka commands or "functions that are exposed")
def example_websocket_action(self, message):
    """
    This `WebSocket <https://developer.mozilla.org/en/WebSockets/WebSockets_reference/WebSocket>`_
    action gets exposed to the client automatically by way of the 'WebSocket'
    hook at the bottom of this file.  The way it works is like this:

    .. rubric:: How The WebSocket Hook Works

    Whenever a message is received via the `WebSocket <https://developer.mozilla.org/en/WebSockets/WebSockets_reference/WebSocket>`_
    Gate One will automatically
    decode it into a Python :class:`dict` (only JSON-encoded messages are accepted).
    Any and all keys in that :class:`dict` will be assumed to be 'actions' (just
    like :js:attr:`GateOne.Net.actions` but on the server) such as this one.  If
    the incoming key matches a registered action that action will be called
    like so::

        key(value)
        # ...or just:
        key() # If the value is None ('null' in JavaScript)

    ...where *key* is the action and *value* is what will be passed to said
    action as an argument.  Since Gate One will automatically decode the message
    as JSON the *value* will typically be passed to actions as a single :class:`dict`.
    You can provide different kinds of arguments of course but be aware that
    their ordering is unpredictable so always be sure to either pass *one*
    argument to your function (assuming it is a :class:`dict`) or 100% keyword
    arguments.

    The *self* argument here is automatically assigned by
    :class:`TerminalApplication` using the `utils.bind` method.

    The typical naming convention for `WebSocket <https://developer.mozilla.org/en/WebSockets/WebSockets_reference/WebSocket>`_
    actions is: `<plugin name>_<action>`.  Whether or not your action names
    match your function names is up to you.  All that matters is that you line
    up an *action* (string) with a *function* in `hooks['WebSocket']` (see below).

    This `WebSocket <https://developer.mozilla.org/en/WebSockets/WebSockets_reference/WebSocket>`_
    *action* duplicates the functionality of Gate One's built-in
    :func:`gateone.TerminalWebSocket.pong` function.  You can see how it is
    called by the client (browser) inside of example.js (which is in this
    plugin's 'static' dir).
    """
    timestamp = "just pretend"
    message = {'terminal:example_pong': timestamp}
    self.write_message(message)
    # WebSockets are asynchronous so you can send as many messages as you want
    message2 = {'go:notice': 'You just executed the "example_action" action.'}
    self.write_message(message2)
    # Alternatively, you can combine multiple messages/actions into one message:
    combined = {
        'go:notice': 'Hurray!',
        'terminal:bell': {'term': self.current_term}
    }
    self.write_message(combined)

# Now for some special sauce...  The Special Optional Escape Sequence Handler!
def example_opt_esc_handler(self, message, term=None, multiplex=None):
    """
    Gate One includes a mechanism for plugins to send messages from terminal
    programs directly to plugins written in Python.  It's called the "Special
    Optional Escape Sequence Handler" or SOESH for short.  Here's how it works:
    Whenever a terminal program emits, "\\x1b]_;" it gets detected by Gate One's
    :class:`~terminal.Terminal` class (which lives in `terminal.py`) and it will
    execute whatever callback is registered for SOESH.  Inside of Gate One this
    callback will always be :func:`gateone.TerminalWebSocket.esc_opt_handler`.
    """
    message = {'go:notice':
     "You just executed the Example plugin's optional escape sequence handler!"}
    self.write_message(message)

def example_command_hook(self, command):
    """
    This demonstrates how to modify Gate One's configured 'command' before it is
    executed.  It will replace any occurrance of %EXAMPLE% with 'foo'.  So if
    'command = "some_script.sh %EXAMPLE%"' in your server.conf it would be
    transformed to "some_script.sh foo" before being executed when a user opens
    a new terminal.
    """
    return command.replace(r'%EXAMPLE%', 'foo')

# SOESH allows plugins to attach actions that will be called whenever a terminal
# encounters the

# Without this 'hooks' dict your plugin might as well not exist from Gate One's
# perspective.
hooks = {
    'Web': [(r"/example", ExampleHandler)],
    'WebSocket': {
        'terminal:example_action': example_websocket_action
    },
    'Command': example_command_hook,
    'Escape': example_opt_esc_handler,
    'Environment': {
        'EXAMPLE_VAR': 'This was set via the Example plugin'
    }
}

########NEW FILE########
__FILENAME__ = html
# -*- coding: utf-8 -*-
#
#       Copyright 2011 Liftoff Software Corporation
#

# TODO: Complete this docstring...
__doc__ = """\
html.py - A plugin for Gate One that adds a special escape sequence that allows
for the raw output of HTML in the terminal (so the browser can use it to format
text).

Here's an example::

    echo -e "\\x90;HTML|<span style="font-family:serif">\\x90HTML Fomatted Output\\x90;HTML|</span>\\x90"

The begin and end markers to output raw HTML into a terminal are:

    Begin HTML: `\\x90;HTML|`
    End HTML: `\\x90`

Whatever gets placed between those two values will be output directly to the
user's browser.

.. note:: The HTML will be stored as a single character in the terminal screen.  So no matter how long the HTML is it will only take up a single character block at the current cursor location.

Hooks
-----
This Python plugin file implements the following hooks::

    hooks = {
        'Events': {
            'terminal:add_terminal_callbacks': add_html_handler
        }
    }

Docstrings
----------
"""

# Meta
__version__ = '1.1'
__version_info__ = (1, 1)
__license__ = "GNU AGPLv3 or Proprietary (see LICENSE.txt)"
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'

import os, re, logging
import terminal
from gateone.core.locale import get_translation

_ = get_translation()

class HTMLOutput(terminal.FileType):
    """
    A subclass of :class:`FileType` that allows HTML output to pass through to
    the browser.  It can be used like so:

    .. ansi-block::

        \x1b[1;34muser\x1b[0m@modern-host\x1b[1;34m:~ $\x1b[0m echo -e "\x90;HTML|<span style='font-family: serif; font-weight: bold;'>\x90This will be wrapped in a span\x90;HTML|</span>\x90"

    .. note:: This :class:`FileType` does its best to prevent XSS attacks.  If you find any way to execute scripts via this mechanism please let us know!  https://github.com/liftoff/GateOne/issues/
    """
    name = _("Raw HTML")
    mimetype = "text/html"
    suffix = ".html"
    re_html_tag = re.compile( # This matches HTML tags (if used correctly)
     b"(?i)<\/?\w+((\s+\w+(\s*=\s*(?:\".*?\"|'.*?'|[^'\">\s]+))?)+\s*|\s*)\/?>")
    re_header = re.compile(b'.*\x90;HTML\|', re.DOTALL)
    re_capture = re.compile(b'(\x90;HTML\|.+?\x90)', re.DOTALL)
    # Why have a tag whitelist?  So programs like 'wall' don't enable XSS
    # exploits.
    tag_whitelist = set([
        'a', 'abbr', 'aside', 'audio', 'bdi', 'bdo', 'blockquote', 'canvas',
        'caption', 'code', 'col', 'colgroup', 'data', 'dd', 'del',
        'details', 'div', 'dl', 'dt', 'em', 'figcaption', 'figure', 'h1',
        'h2', 'h3', 'h4', 'h5', 'h6', 'hr', 'i', 'img', 'ins', 'kbd', 'li',
        'mark', 'ol', 'p', 'pre', 'q', 'rp', 'rt', 'ruby', 's', 'samp',
        'small', 'source', 'span', 'strong', 'sub', 'summary', 'sup',
        'time', 'track', 'u', 'ul', 'var', 'video', 'wbr'
    ])
    # This will match things like 'onmouseover=' ('on<whatever>=')
    on_events_re = re.compile(b'.*\s+(on[a-z]+\s*=).*')

    def __init__(self, path="", **kwargs):
        """
        **path:** (optional) The path to a file or directory where the file
        should be stored.  If *path* is a directory a random filename will be
        chosen.
        """
        self.path = path
        self.file_obj = None

    # Test with: echo -e "\x90;HTML|<span style='font-family: serif; font-weight: bold;'>\x90This will be wrapped in a span\x90;HTML|</span>\x90"
    def capture(self, data, term):
        """
        Captures the raw HTML and stores it in a temporary location returning
        that file object.
        """
        logging.debug('HTMLOutput.capture() len(data) %s' % len(data))
        import tempfile
        # A bit of output cleanup
        html = str(data).replace('\r\n', '\n')
        # Get rid of the '\x90;HTML|' and '\x90' parts
        html = html[7:-1]
        for tag in self.re_html_tag.finditer(html):
            tag_lower = tag.group().lower()
            short_tag = tag_lower.split()[0].lstrip('</').rstrip('>')
            if short_tag not in self.tag_whitelist:
                error_msg = _(
                    "HTML Plugin: Sorry but the '%s' tag is not allowed."
                    % short_tag)
                term.send_message(error_msg)
                html = u"\u2421" # Replace with the  char
                break
            # Also make sure the tag can't execute any JavaScript
            if "javascript:" in tag_lower:
                error_msg = _(
                   "HTML Plugin: Sorry but using 'javascript:' is not allowed.")
                term.send_message(error_msg)
                html = u"\u2421"
                break
            # on<whatever> events are not allowed (just another XSS vuln)
            if self.on_events_re.search(tag_lower):
                error_msg = _(
                    "HTML Plugin: Sorry but using JavaScript events is not "
                    "allowed.")
                term.send_message(error_msg)
                html = u"\u2421"
                break
            # Flash sucks
            if "fscommand" in tag_lower:
                error_msg = _(
                    "HTML Plugin: Sorry but using 'FSCommand' is not allowed.")
                term.send_message(error_msg)
                html = u"\u2421"
                break
            # I'd be impressed if an attacker tried this one (super obscure)
            if "seeksegmenttime" in tag_lower:
                error_msg = _(
                    "HTML Plugin: Sorry but using 'seekSegmentTime' is not "
                    "allowed.")
                term.send_message(error_msg)
                html = u"\u2421"
                break
            # Yes we'll protect IE users from themselves...
            if "vbscript:" in tag_lower:
                error_msg = _(
                   "HTML Plugin: Sorry but using 'vbscript:' is not allowed.")
                term.send_message(error_msg)
                html = u"\u2421"
                break
        if self.path:
            if os.path.exists(self.path):
                if os.path.isdir(self.path):
                    # Assume that a path was given for a reason and use a
                    # NamedTemporaryFile instead of TemporaryFile.
                    self.file_obj = tempfile.NamedTemporaryFile(
                        suffix=self.suffix, dir=self.path)
                    # Update self.path to use the new, actual file path
                    self.path = self.file_obj.name
                else:
                    self.file_obj = open(self.path, 'rb+')
        else:
            self.file_obj = tempfile.TemporaryFile()
            self.path = self.file_obj.name
        # Store the HTML in a temporary file
        self.file_obj.write(html.encode('UTF-8'))
        self.file_obj.flush()
        self.file_obj.seek(0) # Go back to the start
        # Advance the cursor so the next character doesn't overwrite our ref
        term.cursor_right()
        return self.file_obj

    def html(self):
        """
        Returns :attr:`self.file_obj` as raw HTML.
        """
        if not self.file_obj:
            return u""
        self.file_obj.seek(0) # Just to be safe
        html_out = self.file_obj.read()
        self.file_obj.seek(0) # I keep things tidy
        return html_out.decode('UTF-8')

def add_html_handler(self, term, multiplex, callback_id):
    """
    Adds the HTMLOutput :class:`FileType` to the terminal emulator.
    """
    # Add our HTMLOutput FileType to the terminal's magic
    multiplex.term.add_magic(HTMLOutput)

hooks = {
    'Events': {
        'terminal:add_terminal_callbacks': add_html_handler
    }
}

########NEW FILE########
__FILENAME__ = logging_plugin
# -*- coding: utf-8 -*-
#
#       Copyright 2013 Liftoff Software Corporation
#
# NOTE:  Named logging_plugin.py instead of "logging.py" to avoid conflicts
#        with the existing logging module

# TODO: Fix the flat log viewing format.  Doesn't look quite right.
# TODO: Write search functions.
# TODO: Add some search indexing capabilities so that search will be fast.
# TODO: Write a handler that displays a page where users can drag & drop .golog files to have them played back in their browser.

__doc__ = """\
logging_plugin.py - A plugin for Gate One that provides logging-related
functionality.

Hooks
-----
This Python plugin file implements the following hooks::

    hooks = {
        'WebSocket': {
            'logging_get_logs': enumerate_logs,
            'logging_get_log_flat': retrieve_log_flat,
            'logging_get_log_playback': retrieve_log_playback,
            'logging_get_log_file': save_log_playback,
        },
        'Events': {
            'terminal:authenticate': send_logging_css_template
        }
    }

Docstrings
----------
"""

# Meta
__version__ = '1.0'
__license__ = "GNU AGPLv3 or Proprietary (see LICENSE.txt)"
__version_info__ = (1, 0)
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'

# Python stdlib
import os
import logging
import time
import re
from multiprocessing import Process, Queue

# Our stuff
from gateone import GATEONE_DIR
from gateone.auth.authorization import applicable_policies
from gateone.applications.terminal.logviewer import flatten_log
from gateone.applications.terminal.logviewer import render_log_frames
from termio import get_or_update_metadata
from gateone.core.utils import json_encode
from gateone.core.locale import get_translation

_ = get_translation()

# Tornado stuff
import tornado.template
import tornado.ioloop

# TODO: Make the log retrieval functions work incrementally as logs are read so they don't have to be stored entirely in memory before being sent to the client.

# Globals
PLUGIN_PATH = os.path.split(__file__)[0] # Path to this plugin's directory
SEPARATOR = u"\U000f0f0f" # The character used to separate frames in the log
PROCS = {} # For tracking/cancelling background processes
# Matches Gate One's special optional escape sequence (ssh plugin only)
RE_OPT_SSH_SEQ = re.compile(
    r'.*\x1b\]_\;(ssh\|.+?)(\x07|\x1b\\)', re.MULTILINE|re.DOTALL)
# Matches an xterm title sequence
RE_TITLE_SEQ = re.compile(
    r'.*\x1b\][0-2]\;(.+?)(\x07|\x1b\\)', re.DOTALL|re.MULTILINE)

# Helper functions
def get_256_colors(self):
    """
    Returns the rendered 256-color CSS.
    """
    colors_256_path = self.render_256_colors()
    mtime = os.stat(colors_256_path).st_mtime
    cached_filename = "%s:%s" % (colors_256_path.replace('/', '_'), mtime)
    cache_dir = self.ws.settings['cache_dir']
    cached_file_path = os.path.join(cache_dir, cached_filename)
    if os.path.exists(cached_file_path):
        with open(cached_file_path) as f:
            colors_256 = f.read()
    else:
        # Debug mode is enabled
        with open(os.path.join(cache_dir, '256_colors.css')) as f:
            colors_256 = f.read()
    return colors_256

# WebSocket commands (not the same as handlers)
def enumerate_logs(self, limit=None):
    """
    Calls _enumerate_logs() via a :py:class:`multiprocessing.Process` so it
    doesn't cause the :py:class:`~tornado.ioloop.IOLoop` to block.

    Log objects will be returned to the client one at a time by sending
    'logging_log' actions to the client over the WebSocket (*self*).
    """
    self.term_log.debug("enumerate_logs(%s, %s)" % (self, limit))
    # Sometimes IOLoop detects multiple events on the fd before we've finished
    # doing a get() from the queue.  This variable is used to ensure we don't
    # send the client duplicates:
    results = []
    # NOTE: self.policy represents the user's specific settings
    if self.policy['session_logging'] == False:
        message = {'go:notice': _(
            "NOTE: User session logging is disabled.  To enable it, set "
            "'session_logging = True' in your server.conf.")}
        self.write_message(message)
        return # Nothing left to do
    view_logs = self.policy.get('view_logs', True)
    if not view_logs:
        # TODO: Make it so that users don't even see the log viewer if they don't have this setting
        message = {'go:notice': _(
            "NOTE: Your access to the log viewer has been restricted.")}
        self.write_message(message)
        return # Nothing left to do
    user = self.current_user['upn']
    users_dir = os.path.join(self.ws.settings['user_dir'], user) # "User's dir"
    io_loop = tornado.ioloop.IOLoop.current()
    global PROCS
    if user not in PROCS:
        PROCS[user] = {}
    else: # Cancel anything that's already running
        fd = PROCS[user]['queue']._reader.fileno()
        if fd in io_loop._handlers:
            io_loop.remove_handler(fd)
        if PROCS[user]['process']:
            try:
                PROCS[user]['process'].terminate()
            except OSError:
                # process was already terminated...  Nothing to do
                pass
    PROCS[user]['queue'] = q = Queue()
    PROCS[user]['process'] = Process(
        target=_enumerate_logs, args=(q, user, users_dir, limit))
    def send_message(fd, event):
        """
        Sends the log enumeration result to the client.  Necessary because
        IOLoop doesn't pass anything other than *fd* and *event* when it handles
        file descriptor events.
        """
        message = q.get()
        #self.term_log.debug('message: %s' % message)
        if message == 'complete':
            io_loop.remove_handler(fd)
            total_bytes = 0
            logs_dir = os.path.join(users_dir, "logs")
            log_files = os.listdir(logs_dir)
            for log in log_files:
                log_path = os.path.join(logs_dir, log)
                total_bytes += os.stat(log_path).st_size
            out_dict = {
                'total_logs': len(log_files),
                'total_bytes': total_bytes
            }
            # This signals to the client that we're done
            message = {'terminal:logging_logs_complete': out_dict}
            self.write_message(message)
            return
        message = json_encode(message)
        if message not in results:
            # Keep track of how many/how much
            if results:
                results.pop() # No need to keep old stuff hanging around
            results.append(message)
            self.write_message(message)
    # This is kind of neat:  multiprocessing.Queue() instances have an
    # underlying fd that you can access via the _reader:
    io_loop.add_handler(q._reader.fileno(), send_message, io_loop.READ)
    # We tell the IOLoop to watch this fd to see if data is ready in the queue.
    PROCS[user]['process'].start()

def _enumerate_logs(queue, user, users_dir, limit=None):
    """
    Enumerates all of the user's logs and sends the client a "logging_logs"
    message with the result.

    If *limit* is given, only return the specified logs.  Works just like
    `MySQL <http://en.wikipedia.org/wiki/MySQL>`_: limit="5,10" will retrieve
    logs 5-10.
    """
    logs_dir = os.path.join(users_dir, "logs")
    log_files = os.listdir(logs_dir)
    log_files = [a for a in log_files if a.endswith('.golog')] # Only gologs
    log_files.sort() # Should put them in order by date
    log_files.reverse() # Make the newest ones first
    out_dict = {}
    for log in log_files:
        log_path = os.path.join(logs_dir, log)
        logging.debug("Getting metadata from: %s" % log_path)
        try:
            metadata = get_or_update_metadata(log_path, user)
        except EOFError:
            continue # Something wrong with this log; skip
        if not metadata:
            # Broken log file -- may be being written to
            continue # Just skip it
        metadata['size'] = os.stat(log_path).st_size
        out_dict['log'] = metadata
        message = {'terminal:logging_log': out_dict}
        queue.put(message)
        # If we go too quick sometimes the IOLoop will miss a message
        time.sleep(0.01)
    queue.put('complete')

def retrieve_log_flat(self, settings):
    """
    Calls :func:`_retrieve_log_flat` via a :py:class:`multiprocessing.Process`
    so it doesn't cause the :py:class:`~tornado.ioloop.IOLoop` to block.

    :arg dict settings: A dict containing the *log_filename*, *colors*, and *theme* to use when generating the HTML output.

    Here's the details on *settings*:

    :arg settings['log_filename']: The name of the log to display.
    :arg settings['colors']: The CSS color scheme to use when generating output.
    :arg settings['theme']: The CSS theme to use when generating output.
    :arg settings['where']: Whether or not the result should go into a new window or an iframe.
    """
    settings['container'] = self.ws.container
    settings['prefix'] = self.ws.prefix
    settings['user'] = user = self.current_user['upn']
    settings['users_dir'] = os.path.join(self.ws.settings['user_dir'], user)
    settings['gateone_dir'] = GATEONE_DIR
    settings['256_colors'] = get_256_colors(self)
    io_loop = tornado.ioloop.IOLoop.current()
    global PROCS
    if user not in PROCS:
        PROCS[user] = {}
    else: # Cancel anything that's already running
        fd = PROCS[user]['queue']._reader.fileno()
        if fd in io_loop._handlers:
            io_loop.remove_handler(fd)
        if PROCS[user]['process']:
            try:
                PROCS[user]['process'].terminate()
            except OSError:
                # process was already terminated...  Nothing to do
                pass
    PROCS[user]['queue'] = q = Queue()
    PROCS[user]['process'] = Process(
        target=_retrieve_log_flat, args=(q, settings))
    def send_message(fd, event):
        """
        Sends the log enumeration result to the client.  Necessary because
        IOLoop doesn't pass anything other than *fd* and *event* when it handles
        file descriptor events.
        """
        io_loop.remove_handler(fd)
        message = q.get()
        self.write_message(message)
    # This is kind of neat:  multiprocessing.Queue() instances have an
    # underlying fd that you can access via the _reader:
    io_loop.add_handler(q._reader.fileno(), send_message, io_loop.READ)
    # We tell the IOLoop to watch this fd to see if data is ready in the queue.
    PROCS[user]['process'].start()

def _retrieve_log_flat(queue, settings):
    """
    Writes the given *log_filename* to *queue* in a flat format equivalent to::

        ./logviewer.py --flat log_filename

    *settings* - A dict containing the *log_filename*, *colors_css*, and
    *theme_css* to use when generating the HTML output.
    """
    out_dict = {
        'result': "",
        'log': "",
        'metadata': {},
    }
    # Local variables
    out = []
    spanstrip = re.compile(r'\s+\<\/span\>$')
    user = settings['user']
    users_dir = settings['users_dir']
    log_filename = settings['log_filename']
    logs_dir = os.path.join(users_dir, "logs")
    log_path = os.path.join(logs_dir, log_filename)
    if os.path.exists(log_path):
        out_dict['metadata'] = get_or_update_metadata(log_path, user)
        out_dict['metadata']['filename'] = log_filename
        out_dict['result'] = "Success"
        from io import BytesIO
        # Use the terminal emulator to create nice HTML-formatted output
        from terminal import Terminal
        term = Terminal(rows=100, cols=300, em_dimensions=0)
        io_obj = BytesIO()
        flatten_log(log_path, io_obj)
        io_obj.seek(0)
        # Needed to emulate an actual term
        flattened_log = io_obj.read().replace(b'\n', b'\r\n')
        # NOTE: Using chunking below to emulate how a stream might actually be
        # written to the terminal emulator.  This is to prevent the emulator
        # from thinking that any embedded files (like PDFs) are never going to
        # end.
        def chunker(s, n):
            """Produce `n`-character chunks from `s`."""
            for start in range(0, len(s), n):
                yield s[start:start+n]
        for chunk in chunker(flattened_log, 499):
            term.write(chunk)
        scrollback, screen = term.dump_html()
        # Join them together
        log_lines = scrollback + screen
        # rstrip the lines
        log_lines = [a.rstrip() for a in log_lines]
        # Fix things like "<span>whatever [lots of whitespace]    </span>"
        for i, line in enumerate(log_lines):
            out.append(spanstrip.sub("</span>", line))
        out_dict['log'] = out
        term.clear_screen() # Ensure the function below works...
        term.close_captured_fds() # Force clean up open file descriptors
    else:
        out_dict['result'] = _("ERROR: Log not found")
    message = {'terminal:logging_log_flat': out_dict}
    queue.put(message)

def retrieve_log_playback(self, settings):
    """
    Calls :func:`_retrieve_log_playback` via a
    :py:class:`multiprocessing.Process` so it doesn't cause the
    :py:class:`~tornado.ioloop.IOLoop` to block.
    """
    settings['container'] = self.ws.container
    settings['prefix'] = self.ws.prefix
    settings['user'] = user = self.current_user['upn']
    settings['users_dir'] = os.path.join(self.ws.settings['user_dir'], user)
    settings['gateone_dir'] = GATEONE_DIR
    settings['256_colors'] = get_256_colors(self)
    io_loop = tornado.ioloop.IOLoop.current()
    global PROCS
    if user not in PROCS:
        PROCS[user] = {}
    else: # Cancel anything that's already running
        fd = PROCS[user]['queue']._reader.fileno()
        if fd in io_loop._handlers:
            io_loop.remove_handler(fd)
        if PROCS[user]['process']:
            try:
                PROCS[user]['process'].terminate()
            except OSError:
                # process was already terminated...  Nothing to do
                pass
    PROCS[user]['queue'] = q = Queue()
    PROCS[user]['process'] = Process(
        target=_retrieve_log_playback, args=(q, settings))
    def send_message(fd, event):
        """
        Sends the log enumeration result to the client.  Necessary because
        IOLoop doesn't pass anything other than *fd* and *event* when it handles
        file descriptor events.
        """
        io_loop.remove_handler(fd)
        message = q.get()
        self.write_message(message)
    # This is kind of neat:  multiprocessing.Queue() instances have an
    # underlying fd that you can access via the _reader:
    io_loop.add_handler(q._reader.fileno(), send_message, io_loop.READ)
    PROCS[user]['process'].start()

def _retrieve_log_playback(queue, settings):
    """
    Writes a JSON-encoded message to the client containing the log in a
    self-contained HTML format similar to::

        ./logviewer.py log_filename

    *settings* - A dict containing the *log_filename*, *colors*, and *theme* to
    use when generating the HTML output.

    :arg settings['log_filename']: The name of the log to display.
    :arg settings['colors_css']: The CSS color scheme to use when generating output.
    :arg settings['theme_css']: The entire CSS theme <style> to use when generating output.
    :arg settings['where']: Whether or not the result should go into a new window or an iframe.

    The output will look like this::

        {
            'result': "Success",
            'log': <HTML rendered output>,
            'metadata': {<metadata of the log>}
        }

    It is expected that the client will create a new window with the result of
    this method.
    """
    #print("Running retrieve_log_playback(%s)" % settings);
    if 'where' not in settings: # Avoids a KeyError if it is missing
        settings['where'] = None
    out_dict = {
        'result': "",
        'html': "", # Will be replace with the rendered template
        'metadata': {},
        'where': settings['where'] # Just gets passed as-is back to the client
    }
    # Local variables
    user = settings['user']
    users_dir = settings['users_dir']
    container = settings['container']
    prefix = settings['prefix']
    log_filename = settings['log_filename']
    # Important paths
    # NOTE: Using os.path.join() in case Gate One can actually run on Windows
    # some day.
    logs_dir = os.path.join(users_dir, "logs")
    log_path = os.path.join(logs_dir, log_filename)
    template_path = os.path.join(PLUGIN_PATH, 'templates')
    # recording format:
    # {"screen": [log lines], "time":"2011-12-20T18:00:01.033Z"}
    # Actual method logic
    if os.path.exists(log_path):
        # First we setup the basics
        out_dict['metadata'] = get_or_update_metadata(log_path, user)
        out_dict['metadata']['filename'] = log_filename
        try:
            rows = out_dict['metadata']['rows']
            cols = out_dict['metadata']['columns']
        except KeyError:
        # Log was created before rows/cols metadata was included via termio.py
        # Use some large values to ensure nothing wraps and hope for the best:
            rows = 40
            cols = 500
        out_dict['result'] = "Success" # TODO: Add more error checking
        # NOTE: Using Loader() directly here because I was getting strange EOF
        # errors trying to do it the other way :)
        loader = tornado.template.Loader(template_path)
        playback_template = loader.load('playback_log.html')
        preview = 'false'
        if settings['where']:
            preview = 'true'
            recording = render_log_frames(log_path, rows, cols, limit=50)
        else:
            recording = render_log_frames(log_path, rows, cols)
        playback_html = playback_template.generate(
            prefix=prefix,
            container=container,
            theme=settings['theme_css'],
            colors=settings['colors_css'],
            colors_256=settings['256_colors'],
            preview=preview,
            recording=json_encode(recording)
        )
        if not isinstance(playback_html, str):
            playback_html = playback_html.decode('utf-8')
        out_dict['html'] = playback_html
    else:
        out_dict['result'] = _("ERROR: Log not found")
    message = {'terminal:logging_log_playback': out_dict}
    queue.put(message)

def save_log_playback(self, settings):
    """
    Calls :func:`_save_log_playback` via a :py:class:`multiprocessing.Process`
    so it doesn't cause the :py:class:`~tornado.ioloop.IOLoop` to block.
    """
    settings['container'] = self.ws.container
    settings['prefix'] = self.ws.prefix
    settings['user'] = user = self.current_user['upn']
    settings['users_dir'] = os.path.join(self.ws.settings['user_dir'], user)
    settings['gateone_dir'] = GATEONE_DIR
    settings['256_colors'] = get_256_colors(self)
    q = Queue()
    global PROC
    PROC = Process(target=_save_log_playback, args=(q, settings))
    PROC.daemon = True # We don't care if this gets terminated mid-process.
    io_loop = tornado.ioloop.IOLoop.current()
    def send_message(fd, event):
        """
        Sends the log enumeration result to the client.  Necessary because
        IOLoop doesn't pass anything other than *fd* and *event* when it handles
        file descriptor events.
        """
        io_loop.remove_handler(fd)
        message = q.get()
        self.write_message(message)
    # This is kind of neat:  multiprocessing.Queue() instances have an
    # underlying fd that you can access via the _reader:
    io_loop.add_handler(q._reader.fileno(), send_message, io_loop.READ)
    PROC.start()
    return

def _save_log_playback(queue, settings):
    """
    Writes a JSON-encoded message to the client containing the log in a
    self-contained HTML format similar to::

        ./logviewer.py log_filename

    The difference between this function and :py:meth:`_retrieve_log_playback`
    is that this one instructs the client to save the file to disk instead of
    opening it in a new window.

    :arg settings['log_filename']: The name of the log to display.
    :arg settings['colors']: The CSS color scheme to use when generating output.
    :arg settings['theme']: The CSS theme to use when generating output.
    :arg settings['where']: Whether or not the result should go into a new window or an iframe.

    The output will look like this::

        {
            'result': "Success",
            'data': <HTML rendered output>,
            'mimetype': 'text/html'
            'filename': <filename of the log recording>
        }

    It is expected that the client will create a new window with the result of
    this method.
    """
    #print("Running retrieve_log_playback(%s)" % settings);
    out_dict = {
        'result': "Success",
        'mimetype': 'text/html',
        'data': "", # Will be replace with the rendered template
    }
    # Local variables
    user = settings['user']
    users_dir = settings['users_dir']
    container = settings['container']
    prefix = settings['prefix']
    log_filename = settings['log_filename']
    short_logname = log_filename.split('.golog')[0]
    out_dict['filename'] = "%s.html" % short_logname
    # Important paths
    logs_dir = os.path.join(users_dir, "logs")
    log_path = os.path.join(logs_dir, log_filename)
    #templates_path = os.path.join(gateone_dir, 'templates')
    #colors_path = os.path.join(templates_path, 'term_colors')
    #themes_path = os.path.join(templates_path, 'themes')
    template_path = os.path.join(PLUGIN_PATH, 'templates')
    # recording format:
    # {"screen": [log lines], "time":"2011-12-20T18:00:01.033Z"}
    # Actual method logic
    if os.path.exists(log_path):
        # Next we render the theme and color templates so we can pass them to
        # our final template
        out_dict['metadata'] = get_or_update_metadata(log_path, user)
        try:
            rows = out_dict['metadata']['rows']
            cols = out_dict['metadata']['columns']
        except KeyError:
        # Log was created before rows/cols metadata was included via termio.py
        # Use some large values to ensure nothing wraps and hope for the best:
            rows = 40
            cols = 500
        # NOTE: 'colors' are customizable but colors_256 is universal.  That's
        # why they're separate.
        # Lastly we render the actual HTML template file
        # NOTE: Using Loader() directly here because I was getting strange EOF
        # errors trying to do it the other way :)
        loader = tornado.template.Loader(template_path)
        playback_template = loader.load('playback_log.html')
        recording = render_log_frames(log_path, rows, cols)
        preview = 'false'
        playback_html = playback_template.generate(
            prefix=prefix,
            container=container,
            theme=settings['theme_css'],
            colors=settings['colors_css'],
            colors_256=settings['256_colors'],
            preview=preview,
            recording=json_encode(recording),
        )
        out_dict['data'] = playback_html
    else:
        out_dict['result'] = _("ERROR: Log not found")
    message = {'go:save_file': out_dict}
    queue.put(message)

# Temporarily disabled while I work around the problem of gzip files not being
# downloadable over the websocket.
#def get_log_file(self, log_filename):
    #"""
    #Returns the given *log_filename* (as a regular file) so the user can save it
    #to disk.
    #"""
    #user = self.current_user['upn']
    #logging.debug("%s: get_log_file(%s)" % (user, log_filename))
    #users_dir = os.path.join(self.ws.settings['user_dir'], user) # "User's dir"
    #users_log_dir = os.path.join(users_dir, 'logs')
    #log_path = os.path.join(users_log_dir, log_filename)
    #out_dict = {'result': 'Success'}
    #if os.path.exists(log_path):
        #with open(log_path) as f:
            #out_dict['data'] = f.read()
    #else:
        #out_dict['result'] = _(
            #'SSH Plugin Error: Log not found at %s' % log_path)
    #message = {'save_file': out_dict}
    #self.write_message(message)

def session_logging_check(self):
    """
    Attached to the `terminal:session_logging_check` WebSocket action; replies
    with `terminal:logging_sessions_disabled` if terminal session logging is
    disabled.

    .. note::

        The `terminal:logging_sessions_disabled` message just has the client
        remove the "Log Viewer" button so they don't get confused with an
        always-empty log viewer.
    """
    policy = applicable_policies(
        'terminal', self.current_user, self.ws.prefs)
    session_logging = policy.get('session_logging', True)
    if not session_logging:
        message = {'terminal:logging_sessions_disabled': True}
        self.write_message(message)

def send_logging_css_template(self):
    """
    Sends our logging.css template to the client using the 'load_style'
    WebSocket action.  The rendered template will be saved in Gate One's
    'cache_dir'.
    """
    css_path = os.path.join(PLUGIN_PATH, 'templates', 'logging.css')
    self.ws.render_and_send_css(css_path)

hooks = {
    'WebSocket': {
        'terminal:logging_get_logs': enumerate_logs,
        'terminal:logging_get_log_flat': retrieve_log_flat,
        'terminal:logging_get_log_playback': retrieve_log_playback,
        'terminal:logging_get_log_file': save_log_playback,
        'terminal:session_logging_check': session_logging_check,
    },
    'Events': {
        'terminal:authenticate': send_logging_css_template
    }
}

########NEW FILE########
__FILENAME__ = notice
# -*- coding: utf-8 -*-
#
#       Copyright 2011 Liftoff Software Corporation
#

# TODO: Complete this docstring...
__doc__ = """\
notice.py - A plugin for Gate One that adds an escape sequence handler that will
tell the client browser to display a message whenever said escape sequence is
encountered.  Any terminal program can emit the following escape sequence to
display a message in the browser::

    \\x1b]_;notice|<the message>\\x07

.. note that the above example has double slashes...  Don't do that in your actual code.  They're just there to make sure it shows up properly in the HTML documentation.

Very straightforward and also very powerful.

Hooks
-----
This Python plugin file implements the following hooks::

    hooks = {
        'Escape': notice_esc_seq_handler,
    }

Docstrings
----------
"""

# Meta
__version__ = '1.0'
__license__ = "GNU AGPLv3 or Proprietary (see LICENSE.txt)"
__version_info__ = (1, 0)
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'

from gateone.core.log import go_logger

# Special optional escape sequence handler (see docs on how it works)
def notice_esc_seq_handler(self, message, term=None, multiplex=None):
    """
    Handles text passed from the special optional escape sequance handler to
    display a *message* to the connected client (browser).  It can be invoked
    like so:

    .. ansi-block::

        $ echo -e "\033]_;notice|Text passed to some_function()\007"

    .. seealso::

        :class:`app_terminal.TerminalApplication.opt_esc_handler` and
        :func:`terminal.Terminal._opt_handler`
    """
    if not hasattr(self, 'notice_log'):
        self.notice_log = go_logger(
            'gateone.terminal.notice', plugin='notice', **self.log_metadata)
    self.notice_log.info(
        "Notice Plugin: %s" % message, metadata={'term': term, 'text': message})
    message = "Term {term}: {message}".format(term=term, message=message)
    message = {'go:notice': message}
    self.write_message(message)

hooks = {
    'Escape': notice_esc_seq_handler,
}

########NEW FILE########
__FILENAME__ = playback
# -*- coding: utf-8 -*-
#
#       Copyright 2011 Liftoff Software Corporation
#

__doc__ = """\
playback.py - A plugin for Gate One that adds support for saving and playing
back session recordings.

.. note:: Yes this only contains one function and it is exposed to clients through a WebSocket hook.

Hooks
-----
This Python plugin file implements the following hooks::

    hooks = {
        'WebSocket': {
            'playback_save_recording': save_recording,
        }
    }

Docstrings
----------
"""

# Meta
__version__ = '1.0'
__license__ = "GNU AGPLv3 or Proprietary (see LICENSE.txt)"
__version_info__ = (1, 0)
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'

# Python stdlib
import os
from gateone.core.locale import get_translation

_ = get_translation()

# Globals
PLUGIN_PATH = os.path.split(__file__)[0]

def get_256_colors(self):
    """
    Returns the rendered 256-color CSS.
    """
    colors_256_path = self.render_256_colors()
    mtime = os.stat(colors_256_path).st_mtime
    cached_filename = "%s:%s" % (colors_256_path.replace('/', '_'), mtime)
    cache_dir = self.ws.settings['cache_dir']
    cached_file_path = os.path.join(cache_dir, cached_filename)
    if os.path.exists(cached_file_path):
        with open(cached_file_path) as f:
            colors_256 = f.read()
    else:
        # Debug mode is enabled
        with open(os.path.join(cache_dir, '256_colors.css')) as f:
            colors_256 = f.read()
    return colors_256

def save_recording(self, settings):
    """
    Handles uploads of session recordings and returns them to the client in a
    self-contained HTML file that will auto-start playback.

    ..note:: The real crux of the code that handles this is in the template.
    """
    import tornado.template
    from datetime import datetime
    now = datetime.now().strftime('%Y%m%d%H%m%S') # e.g. '20120208200222'
    out_dict = {
        'result': 'Success',
        'filename': 'GateOne_recording-%s.html' % now,
        'data': None,
        'mimetype': 'text/html'
    }
    recording = settings["recording"]
    container = settings["container"]
    prefix = settings["prefix"]
    theme_css = settings['theme_css']
    colors_css = settings['colors_css']
    colors_256 = get_256_colors(self)
    templates_path = os.path.join(PLUGIN_PATH, "templates")
    recording_template_path = os.path.join(
        templates_path, "self_contained_recording.html")
    with open(recording_template_path) as f:
        recording_template_data = f.read()
    recording_template = tornado.template.Template(recording_template_data)
    rendered_recording = recording_template.generate(
        recording=recording,
        container=container,
        prefix=prefix,
        theme=theme_css,
        colors=colors_css,
        colors_256=colors_256
    )
    out_dict['data'] = rendered_recording
    message = {'go:save_file': out_dict}
    self.write_message(message)

hooks = {
    'WebSocket': {
        'terminal:playback_save_recording': save_recording,
    }
}

########NEW FILE########
__FILENAME__ = ssh_connect
#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
#       Copyright 2013 Liftoff Software Corporation
#
from __future__ import unicode_literals

# TODO: Make it so that a username can have an @ sign in it.

__doc__ = """\
ssh_connect.py - Opens an interactive SSH session with the given arguments and
sets the window title to user@host.
"""

# Meta
__version__ = '1.2'
__license__ = "AGPLv3 or Proprietary (see LICENSE.txt)"
__version_info__ = (1, 2)
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'

# Import Python stdlib stuff
import os, sys, readline, signal
from concurrent import futures
from optparse import OptionParser
# i18n support stuff
import gettext
gettext.bindtextdomain('ssh_connect', 'i18n')
gettext.textdomain('ssh_connect')
_ = gettext.gettext

if bytes != str: # Python 3
    raw_input = input

APPLICATION_PATH = os.path.split(__file__)[0] # Path to our application

# Disable ESC autocomplete for local paths (prevents information disclosure)
readline.parse_and_bind('esc: none')

# Globals
POSIX = 'posix' in sys.builtin_module_names
wrapper_script = """\
#!/bin/sh
# This variable is for easy retrieval later
SSH_SOCKET='{socket}'
trap "rm -f {temp}" EXIT
{cmd}
echo '[Press Enter to close this terminal]'
read waitforuser
rm -f {temp} # Cleanup
exit 0
"""
# We have the little "wait for user" bit so users can see the ouput of a
# session before it got closed (can be lots of useful information).

def took_too_long():
    """
    Called when :meth:`main` takes too long to run its course (idle timeout
    before any connection was made).
    """
    timeout_script = os.path.join(APPLICATION_PATH, 'timeout.sh')
    sys.stdout.flush()
    # Calling execv() so we can quit the main process to reduce memory usage
    os.execv('/bin/sh', ['-c', timeout_script])
    os._exit(0)

def mkdir_p(path):
    """Pythonic version of mkdir -p"""
    try:
        os.makedirs(path)
    except OSError as exc: # Python >2.5
        import errno
        if exc.errno == errno.EEXIST:
            pass
        else: raise

def which(binary, path=None):
    """
    Returns the full path of *binary* (string) just like the 'which' command.
    Optionally, a *path* (colon-delimited string) may be given to use instead of
    os.environ['PATH'].
    """
    if path:
        paths = path.split(':')
    else:
        paths = os.environ['PATH'].split(':')
    for path in paths:
        if not os.path.exists(path):
            continue
        files = os.listdir(path)
        if binary in files:
            return os.path.join(path, binary)
    return None

def short_hash(to_shorten):
    """
    Converts *to_shorten* into a really short hash depenendent on the length of
    *to_shorten*.  The result will be safe for use as a file name.

    .. note::

        Collisions are possible but *highly* unlikely because of how this
        method is used.
    """
    import base64, hashlib
    hashed = hashlib.sha1(to_shorten.encode('utf-8'))
    # Take the first eight characters to create a shortened version.
    return base64.urlsafe_b64encode(hashed.digest())[:8].decode('utf-8')

def valid_hostname(hostname, allow_underscore=False):
    """
    Returns True if the given *hostname* is valid according to RFC rules.  Works
    with Internationalized Domain Names (IDN) and optionally, hostnames with an
    underscore (if *allow_underscore* is True).

    The rules for hostnames:

        * Must be less than 255 characters.
        * Individual labels (separated by dots) must be <= 63 characters.
        * Only the ASCII alphabet (A-Z) is allowed along with dashes (-) and dots (.).
        * May not start with a dash or a dot.
        * May not end with a dash.
        * If an IDN, when converted to Punycode it must comply with the above.

    IP addresses will be validated according to their well-known specifications.
    (from http://stackoverflow.com/questions/2532053/validate-a-hostname-string)

    Examples::

        >>> valid_hostname('foo.bar.com.') # Standard FQDN
        True
        >>> valid_hostname('2foo') # Short hostname
        True
        >>> valid_hostname('-2foo') # No good:  Starts with a dash
        False
        >>> valid_hostname('host_a') # No good: Can't have underscore
        False
        >>> valid_hostname('host_a', allow_underscore=True) # Now it'll validate
        True
        >>> valid_hostname('.jp') # Example valid IDN
        True
    """
    # Convert to Punycode if an IDN
    try:
        hostname = hostname.encode('idna')
    except UnicodeError: # Can't convert to Punycode: Bad hostname
        return False
    try:
        hostname = str(hostname, 'UTF-8')
    except TypeError: # Python 2.6+.  Just ignore
        pass
    if len(hostname) > 255:
        return False
    if hostname[-1:] == ".": # Strip the tailing dot if present
        hostname = hostname[:-1]
    import re
    allowed = re.compile("(?!-)[A-Z\d-]{1,63}(?<!-)$", re.IGNORECASE)
    if allow_underscore:
        allowed = re.compile("(?!-)[_A-Z\d-]{1,63}(?<!-)$", re.IGNORECASE)
    return all(allowed.match(x) for x in hostname.split("."))

def valid_ip(ipaddr):
    """
    Returns True if *ipaddr* is a valid IPv4 or IPv6 address.
    (from http://stackoverflow.com/questions/319279/how-to-validate-ip-address-in-python)
    """
    import socket
    if ':' in ipaddr: # IPv6 address
        try:
            socket.inet_pton(socket.AF_INET6, ipaddr)
            return True
        except socket.error:
            return False
    else:
        try:
            socket.inet_pton(socket.AF_INET, ipaddr)
            return True
        except socket.error:
            return False

def get_identities(users_ssh_dir, only_defaults=False):
    """
    Returns a list of identities stored in the user's '.ssh' directory.  It does
    this by examining os.environ['GO_USER'] os.environ['GO_USER_DIR'].  If
    *only_defaults* is True and if a '.default_ids' file exists only identities
    listed within it will be returned.
    """
    identities = []
    if os.path.exists(users_ssh_dir):
        ssh_files = os.listdir(users_ssh_dir)
        defaults_present = False
        defaults = []
        if only_defaults and '.default_ids' in ssh_files:
            defaults_present = True
            with open(os.path.join(users_ssh_dir, '.default_ids')) as f:
                defaults = f.read().splitlines()
            # Fix empty entries
            defaults = [a for a in defaults if os.path.exists(
                os.path.join(users_ssh_dir, a))]
            # Reduce absolute paths to short names (for easy matching)
            defaults = [os.path.split(a)[1] for a in defaults]
        for f in ssh_files:
            if f.endswith('.pub'):
                # If there's a public key there's probably a private one...
                identity = f[:-4] # Will be the same name minus '.pub'
                if identity in ssh_files:
                    identities.append(os.path.join(users_ssh_dir, identity))
    if defaults_present:
        # Only include identities marked as default
        identities = [a for a in identities if os.path.split(a)[1] in defaults]
    elif only_defaults:
        return []
    return identities

def openssh_connect(
        user,
        host,
        port=22,
        config=None,
        command=None,
        password=None,
        env=None,
        socket=None,
        sshfp=False,
        randomart=False,
        identities=None,
        additional_args=None,
        debug=False):
    """
    Starts an interactive SSH session to the given host as the given user on the
    given port.

    If *command* isn't given, the equivalent of "which ssh" will be used to
    determine the full path to the ssh executable.  Otherwise *command* will be
    used.

    If a password is given, that will be passed to SSH when prompted.

    If *env* (dict) is given, that will be used for the shell env when opening
    the SSH connection.

    If *socket* (a file path) is given, this will be passed to the SSH command
    as -S<socket>.  If the socket does not exist, ssh's Master mode switch will
    be set (-M) automatically.  This allows sessions to be duplicated
    automatically.

    If *sshfp* resolves to True, SSHFP (DNS-based host verification) support
    will be enabled.

    If *randomart* resolves to True, the VisualHostKey (randomart hash) option
    will be enabled to display randomart when the connection is made.

    If *identities* given (may be a list or just a single string), it/those will
    be passed to the ssh command to use when connecting (e.g. -i/identity/path).

    If *additional_args* is given this value (or values if it is a list) will be
    added to the arguments passed to the ssh command.

    If *debug* is ``True`` then '-vvv' will be passed to the ssh command.
    """
    try:
        int(port)
    except ValueError:
        print(_("The port must be an integer < 65535"))
        sys.exit(1)
    import tempfile, io
    # NOTE: Figure out if we really want to use the env forwarding feature
    if not env: # Unless we enable SendEnv in ssh these will do nothing
        env = {
            'TERM': 'xterm',
            'LANG': 'en_US.UTF-8',
        }
    try:
        # Get the default rows/cols right from the start
        env['LINES'] = os.environ['LINES']
        env['COLUMNS'] = os.environ['COLUMNS']
        # Also pass on some useful (but harmless) Gate One-specific vars:
        env['GO_TERM'] = os.environ['GO_TERM']
        env['GO_LOCATION'] = os.environ['GO_LOCATION']
        env['GO_SESSION'] = os.environ['GO_SESSION']
    except KeyError:
        pass # These variables aren't set
    # Get the user's ssh directory
    if 'GO_USER' in os.environ: # Try to use Gate One's provided user first
        go_user = os.environ['GO_USER']
    else: # Fall back to the executing user (for testing outside of Gate One)
        go_user = os.environ['USER']
    if 'GO_USER_DIR' in os.environ:
        users_dir = os.path.join(os.environ['GO_USER_DIR'], go_user)
        if isinstance(users_dir, bytes):
            users_dir = users_dir.decode('utf-8')
        users_ssh_dir = os.path.join(users_dir, '.ssh')
    else: # Fall back to using the default OpenSSH location for ssh stuff
        if POSIX:
            users_dir = os.environ['HOME']
            if isinstance(users_dir, bytes):
                users_dir = users_dir.decode('utf-8')
            users_ssh_dir = os.path.join(users_dir, '.ssh')
        else:
            # Assume Windows.  TODO: Double-check this is the right default path
            users_ssh_dir = os.path.join(os.environ['USERPROFILE'], '.ssh')
    if not os.path.exists(users_ssh_dir):
        mkdir_p(users_ssh_dir)
    ssh_config_path = os.path.join(users_ssh_dir, 'config')
    if not os.path.exists(ssh_config_path):
        # Create it (an empty one so ssh doesn't error out)
        with open(ssh_config_path, 'w') as f:
            f.write('\n')
    args = [
        "-x", # No X11 forwarding, thanks :)
        "-F'%s'" % ssh_config_path, # It's OK if it doesn't exist
        # This is so people won't have to worry about user management when
        # running one-Gate One-per-server...
        "-oNoHostAuthenticationForLocalhost=yes",
        # This ensure's that the executing user's identity won't be used:
        "-oIdentitiesOnly=yes",
        # This ensures the other end can tell we're a Gate One terminal and
        # possibly use the session ID with plugins (could be interesting).
        "-oSendEnv='GO_TERM GO_LOCATION GO_SESSION'",
        "-p", str(port),
        "-l", user,
    ]
    if debug:
        args.append('-vvv')
    # If we're given specific identities use them exclusively
    if identities:
        if isinstance(identities, (unicode, str)):
            # Only one identity present, turn it into a list
            if os.path.sep not in identities:
                # Turn the short identity name into an absolute path
                identities = os.path.join(users_ssh_dir, identities)
            identities = [identities] # Make it a list
    else:
        # No identities given.  Get them from the user's dir (if any)
        identities = get_identities(users_ssh_dir, only_defaults=True)
    # Now make sure we use them in the connection...
    if identities:
        print(_(
            "The following SSH identities are being used for this "
            "connection:"))
        for identity in identities:
            if os.path.sep not in identity:
                # Turn the short identity name into an absolute path
                identity = os.path.join(users_ssh_dir, identity)
            args.insert(3, "-i%s" % identity)
            print(_("\t\x1b[1m%s\x1b[0m" % os.path.split(identity)[1]))
        args.insert(3, # Make sure we're using publickey auth first
        "-oPreferredAuthentications='publickey,keyboard-interactive,password'"
        )
    else:
        args.insert(
            3, # Don't use publickey
            "-oPreferredAuthentications='keyboard-interactive,password'"
        )
    if sshfp:
        args.insert(3, "-oVerifyHostKeyDNS=yes")
    if randomart:
        args.insert(3, "-oVisualHostKey=yes")
    if not command:
        if 'PATH' in env:
            command = which("ssh", path=env['PATH'])
        else:
            env['PATH'] = os.environ['PATH']
            command = which("ssh")
    if '[' in host: # IPv6 address
        # Have to remove the brackets which is silly.  See bug:
        #   https://bugzilla.mindrot.org/show_bug.cgi?id=1602
        host = host.strip('[]')
    if socket:
        # Only set Master mode if we don't have a socket for this session.
        # This allows us to duplicate a session without having to code
        # anything special to pre-recognize this condition in gateone.py or
        # gateone.js.  It makes everything automagical :)
        socket_path = socket.replace(r'%r', user) # Replace just like ssh does
        socket_path = socket_path.replace(r'%h', host)
        socket_path = socket_path.replace(r'%p', str(port))
        # The %SHORT_SOCKET% replacement is special: It replaces the equivalent
        # of ssh's %r@%h:%p with a shortened hash of the same value.  For
        # example: user@somehost:22 would become 'ud6U2Q'.  This is to avoid the
        # potential of a really long FQDN (%h) resulting in a "ControlPath too
        # long" error with the ssh command.
        user_at_host_port = "%s@%s:%s" % (user, host, port)
        hashed = short_hash(user_at_host_port)
        socket_path = socket_path.replace(r'%SHORT_SOCKET%', hashed)
        if not os.path.exists(socket_path):
            args.insert(0, "-M")
        else:
            print("\x1b]0;%s@%s (child)\007" % (user, host))
            print(_(
                "\x1b]_;notice|Existing ssh session detected for ssh://%s@%s:%s;"
                " utilizing existing tunnel.\007" % (user, host, port)
            ))
        socket = socket.replace(r'%SHORT_SOCKET%', hashed)
        socket_arg = "-S'%s'" % socket
        # Also make sure the base directory exists
        basedir = os.path.split(socket)[0]
        mkdir_p(basedir)
        os.chmod(basedir, 0o700) # 0700 for good security practices
        args.insert(1, socket_arg) # After -M so it is easier to see in ps
    if additional_args:
        if isinstance(additional_args, (list, tuple)):
            args.extend(additional_args)
        else:
            args.extend(additional_args.split())
    args.insert(0, command) # Command has to go first
    args.append(host) # Host should be last
    if password:
        # Create a temporary script to use with SSH_ASKPASS
        temp = tempfile.NamedTemporaryFile(delete=False)
        os.chmod(temp.name, 0o700)
        temp.write(('#!/bin/sh\necho "{0}"\n'.format(password)).encode('utf-8'))
        temp.close()
        env['SSH_ASKPASS'] = temp.name
        env['DISPLAY'] = ':9999' # TODO: Get this using the user's actual X11
        # This removes the temporary file in a timely manner
        from subprocess import Popen
        Popen("sleep 15 && /bin/rm -f %s" % temp.name, shell=True)
        # 15 seconds should be enough even for slow connections/servers
        # It's a tradeoff:  Lower number, more secure.  Higher number, less
        # likely to fail
    script_path = None
    if 'GO_TERM' in os.environ.keys():
        term = os.environ['GO_TERM']
        location = os.environ['GO_LOCATION']
        if socket:
            # Emit our special optional escape sequence to tell ssh.py the path
            # to the SSH socket
            print("\x1b]_;ssh|set;ssh_socket;{0}\007".format(socket))
        if 'GO_SESSION_DIR' in os.environ.keys():
            # Save a file indicating our session is attached to GO_TERM
            ssh_session = 'ssh:%s:%s:%s@%s:%s' % (
                location, term, user, host, port)
            script_path = os.path.join(
                os.environ['GO_SESSION_DIR'],
                os.environ['GO_SESSION'], ssh_session)
    if not script_path:
        # Just use a generic temp file
        temp = tempfile.NamedTemporaryFile(prefix="ssh_connect", delete=False)
        script_path = "%s" % temp.name
        temp.close() # Will be written to below
    if password:
        # SSH_ASKPASS needs some special handling
        # Make sure setsid gets set in our shell script
        args.insert(0, 'exec setsid')
    # Create our little shell script to wrap the SSH command
    cmd = ""
    for arg in args:
        if isinstance(arg, bytes):
            cmd += arg.decode('utf-8') + ' '
        else:
            cmd += arg + ' '
    script = wrapper_script.format(
        socket=socket,
        cmd=cmd,
        temp=script_path)
    # This whole if/else block is here to enable users running Python 2.7 to
    # remove the 'from __future__ import unicode_literals' line to work around
    # this bug: http://bugs.python.org/issue9161
    if isinstance(script, bytes):
        with io.open(script_path, 'wb') as f:
            f.write(script) # Save it to disk
    else:
        with io.open(script_path, 'w', encoding='utf-8') as f:
            f.write(script) # Save it to disk
    # NOTE: We wrap in a shell script so we can execute it and immediately quit.
    # By doing this instead of keeping ssh_connect.py running we can save a lot
    # of memory (depending on how many terminals are open).
    os.chmod(script_path, 0o700) # 0700 for good security practices
    # Execute then immediately quit so we don't use up any more memory than we
    # need.
    os.execvpe('/bin/sh', [
        '-c', script_path, '&&', 'rm', '-f', script_path], env)
    os._exit(0)

def telnet_connect(user, host, port=23, env=None):
    """
    Starts an interactive Telnet session to the given host as the given user on
    the given port.  *user* may be None, False, or an empty string.

    If *env* (dict) is given it will be set before excuting the telnet command.

    .. note:: Some telnet servers don't support sending the username in the connection.  In these cases it will simply ask for it after the connection is established.
    """
    try:
        int(port)
    except ValueError:
        print(_("The port must be an integer < 65535"))
        sys.exit(1)
    import tempfile
    if not env:
        env = {
            'TERM': 'xterm',
            'LANG': 'en_US.UTF-8',
        }
    # Get the default rows/cols right from the start
    try:
        env['LINES'] = os.environ['LINES']
        env['COLUMNS'] = os.environ['COLUMNS']
    except KeyError:
        pass # These variables aren't set
    if 'PATH' in env:
        command = which("telnet", path=env['PATH'])
    else:
        env['PATH'] = os.environ['PATH']
        command = which("telnet", path=env['PATH'])
    if not command: # telnet command not found
        print(_(
            'Error: Could not find telnet binary in path %r' % (env['PATH'])))
        sys.exit(1)
    args = [host, str(port)]
    if user:
        args.insert(0, user)
        args.insert(0, "-l")
    args.insert(0, command) # Command has to go first
    script_path = None
    if 'GO_TERM' in os.environ.keys():
        if 'GO_SESSION_DIR' in os.environ.keys():
            # Save a file indicating our session is attached to GO_TERM
            term = os.environ['GO_TERM']
            telnet_session = 'telnet:%s:%s@%s:%s' % (term, user, host, port)
            script_path = os.path.join(
                os.environ['GO_SESSION_DIR'], telnet_session)
    if not script_path:
        # Just use a generic temp file
        temp = tempfile.NamedTemporaryFile(prefix="ssh_connect", delete=False)
        script_path = "%s" % temp.name
        temp.close() # Will be written to below
    # Create our little shell script to wrap the SSH command
    cmd = ""
    for arg in args:
        if isinstance(arg, bytes):
            cmd += arg.decode('utf-8') + ' '
        else:
            cmd += arg + ' '
    script = wrapper_script.format(
        socket="NO SOCKET",
        cmd=cmd,
        temp=script_path)
    with open(script_path, 'w') as f:
        f.write(script) # Save it to disk
    # NOTE: We wrap in a shell script so we can execute it and immediately quit.
    # By doing this instead of keeping ssh_connect.py running we can save a lot
    # of memory (depending on how many terminals are open).
    os.chmod(script_path, 0o700) # 0700 for good security practices
    os.execvpe(script_path, [], env)
    os._exit(0)

def parse_url(url):
    """
    Parses a URL like, 'ssh://user@host:22' and returns a dict of::

        {
            'scheme': scheme,
            'user': user,
            'host': host,
            'port': port,
            'password': password,
            'identities': identities,
            'debug': debug
        }

    .. note:: 'web+ssh://' URLs are also supported.

    If an ssh URL is given without a username, os.environ['GO_USER'] will be
    used and if that doesn't exist it will fall back to os.environ['USER'].

    SSH Identities may be specified as a query string:

        ssh://user@host:22/?identities=id_rsa,id_ecdsa

    .. note::

        *password* and *identities* may be returned as None and [],
        respectively if not provided.
    """
    identities = set()
    debug = False
    import socket
    try:
        from urlparse import urlparse, parse_qs, uses_query
        if 'ssh' not in uses_query: # Only necessary in Python 2.X
            uses_query.append('ssh')
    except ImportError: # Python 3
        from urllib.parse import urlparse, parse_qs
    parsed = urlparse(url)
    if parsed.query:
        q_attrs = parse_qs(parsed.query)
        for ident in q_attrs.get('identities', identities):
            identities.update(ident.split(','))
        debug = q_attrs.get('debug', False)
        if debug: # Passing anything turns on debug
            debug = True
    if parsed.port:
        port = parsed.port
    else:
        port = socket.getservbyname(parsed.scheme, 'tcp')
    # Commented these out so that users can enter an arbitrary username.  It is
    # more user-friendly this way since users won't have to have multiple
    # bookmarks to the same host just to connect with different usernames.
    #elif os.environ.get('GO_USER'):
        #username = os.environ['GO_USER']
    #elif os.environ.get('USER'):
        #username = os.environ['USER']
    #return (o.scheme, username, o.hostname, port, o.password, identities)
    return {
        'scheme': parsed.scheme,
        'user': parsed.username,
        'host': parsed.hostname,
        'port': port,
        'password': parsed.password,
        'identities': identities,
        'debug': debug
    }

def bad_chars(chars):
    """
    Returns ``False`` if the given *chars* are OK, ``True`` if there's bad
    characters present (i.e. shell exec funny business).

    .. note::

        This is to prevent things like "ssh://user@host && <malicious commands>"
    """
    import re
    bad_chars = re.compile('.*[\$\n\!\;&` |<>].*')
    if bad_chars.match(chars):
        return True
    return False

def main():
    """
    Parse command line arguments and execute ssh_connect()
    """
    usage = (
        #'Usage:\n'
            '\t%prog [options] <user> <host> [port]\n'
        '...or...\n'
            '\t%prog [options] <ssh://user@host[:port]>'
    )
    parser = OptionParser(usage=usage, version=__version__)
    parser.disable_interspersed_args()
    try:
        parser.add_option("-c", "--command",
            dest="command",
            default='ssh',
            help=_("Path to the ssh command.  Default: 'ssh' (which usually means "
                "/usr/bin/ssh)."),
            metavar="'<filepath>'"
        )
    except TypeError:
        print(
            "ERROR: You're using an older version of Python that has a bug "
            "with the OptionParser module (see "
            "http://bugs.python.org/issue9161).")
        print(
            "To resolve this problem you have two options:\n"
            " * Edit this script (%s) and remove this line (at the top):\n"
            "    from __future__ import unicode_literals\n"
            " * Upgrade your version of Python to the latest."
            % APPLICATION_PATH)
        raw_input(_("[Press Enter to close this terminal]"))
        sys.exit(1)
    parser.add_option("-a", "--args",
        dest="additional_args",
        default=None,
        help=_("Any additional arguments that should be passed to the ssh "
             "command.  It is recommended to wrap these in quotes."),
        metavar="'<args>'"
    )
    parser.add_option("-S",
        dest="socket",
        default=None,
        help=_("Path to the control socket for connection sharing (see master "
              "mode and 'man ssh')."),
        metavar="'<filepath>'"
    )
    parser.add_option("--sshfp",
        dest="sshfp",
        default=False,
        action="store_true",
        help=_("Enable the use of SSHFP in verifying host keys. See:  "
              "http://en.wikipedia.org/wiki/SSHFP#SSHFP")
    )
    parser.add_option("--randomart",
        dest="randomart",
        default=False,
        action="store_true",
        help=_("Enable the VisualHostKey (randomart hash host key) option when "
              "connecting.")
    )
    parser.add_option("--logo",
        dest="logo",
        default=False,
        action="store_true",
        help=_("Display the logo image inline in the terminal.")
    )
    parser.add_option("--logo_path",
        dest="logo_path",
        default=None,
        help=_("Provide the logo path (implies --logo).")
    )
    parser.add_option("--default_host",
        dest="default_host",
        default="localhost",
        help=_("The default host that will be used for outbound connections if "
               "no hostname is provided.  Default: localhost"),
        metavar="'<hostname>'"
    )
    parser.add_option("--default_port",
        dest="default_port",
        default='22',
        help=_("The default port that will be used for outbound connections if "
               "no port is provided.  Default: 22"),
        metavar="'<port>'"
    )
    parser.add_option("--auth_only",
        dest="auth_only",
        default=False,
        help=_("Skip asking for host information (hostname and port) and ask for "
            "credentials only (you probably want to use --default_host and "
            "--default_port as well).")
    )
    (options, args) = parser.parse_args()
    if options.logo_path:
        options.logo = True
    # NOTE: This also means you can't use these characters in things like
    #       usernames or passwords (if using autoConnectURL).
    try:
        if len(args) == 1:
            parsed = parse_url(args[0])
            if parsed['scheme'] == 'telnet':
                telnet_connect(parsed['user'], parsed['host'], parsed['port'])
            else:
                openssh_connect(parsed['user'], parsed['host'], parsed['port'],
                    command=options.command,
                    password=parsed['password'],
                    sshfp=options.sshfp,
                    randomart=options.randomart,
                    identities=parsed.get('identities', []),
                    additional_args=options.additional_args,
                    socket=options.socket,
                    debug=parsed.get('debug', False)
                )
        elif len(args) == 2: # No port given, assume 22
            openssh_connect(args[0], args[1], options.default_port,
                command=options.command,
                sshfp=options.sshfp,
                randomart=options.randomart,
                additional_args=options.additional_args,
                socket=options.socket
            )
        elif len(args) == 3:
            openssh_connect(args[0], args[1], args[2],
                command=options.command,
                sshfp=options.sshfp,
                randomart=options.randomart,
                additional_args=options.additional_args,
                socket=options.socket
            )
    except Exception:
        pass # Something ain't right.  Try the interactive entry method...
    password = None
    try:
        identities = []
        protocol = None
        script_dir = os.path.dirname(os.path.abspath(__file__))
        logo_path = os.path.join(script_dir, 'logo.png')
        logo = None
        # Only show the logo image if running inside Gate One
        if options.logo:
            if options.logo_path:
                if options.logo_path.startswith(os.sep):
                    logo_path = options.logo_path
                else:
                    logo_path = os.path.join(script_dir, options.logo_path)
            if 'GO_TERM' in os.environ.keys() and os.path.exists(logo_path):
                with open(logo_path) as f:
                    logo = f.read()
                    # stdout instead of print so we don't get an extra newline
                    sys.stdout.write(logo)
        url = None
        user = None
        port = None
        validated = False
        debug = False
        invalid_hostname_err = _(
            'Error:  You must enter a valid hostname or IP address.')
        invalid_port_err = _(
            'Error:  You must enter a valid port (1-65535).')
        invalid_user_err = _(
            'Error:  You must enter a valid username.')
        default_host_str = " [%s]" % options.default_host
        default_port_str = "Port [%s]" % options.default_port
        if options.default_host == "":
            default_host_str = ""
        # Set a pre-connection title
        print("\x1b]0;SSH Connect\007")
        if options.auth_only:
            url = options.default_host
        while not validated:
            if not url:
                url = raw_input(_(
                   "[Press Shift-F1 for help]\n\nHost/IP or ssh:// URL%s: " %
                   default_host_str))
            if bad_chars(url):
                raw_input(invalid_hostname_err)
                url = None
                continue
            if not url:
                if options.default_host:
                    host = options.default_host
                    protocol = 'ssh'
                    validated = True
                else:
                    raw_input(invalid_hostname_err)
                    continue
            elif url.find('://') >= 0:
                parsed = parse_url(url)
                protocol = parsed['scheme']
                user = parsed['user']
                host = parsed['host']
                port = parsed['port']
                password = parsed['password']
                identities = parsed.get('identities', [])
                debug = parsed.get('debug', False)
            else:
                # Always assume SSH unless given a telnet:// URL
                protocol = 'ssh'
                host = url
            if valid_hostname(host, allow_underscore=True):
                validated = True
            else:
                # Double-check: It might be an IPv6 address
                # IPv6 addresses must be wrapped in brackets:
                if '[' in host and ']' in host:
                    no_brackets = host.strip('[]')
                    if valid_ip(no_brackets):
                        validated = True
                    else:
                        url = None
                        raw_input(invalid_hostname_err)
                else:
                    url = None
                    raw_input(invalid_hostname_err)
        validated = False
        if options.auth_only:
            port = options.default_port
        while not validated:
            if not port:
                port = raw_input(_("%s: " % default_port_str))
                if not port:
                    port = options.default_port
            try:
                port = int(port)
                if port <= 65535 and port > 1:
                    validated = True
                else:
                    port = None
                    raw_input(invalid_port_err)
            except ValueError:
                port = None
                raw_input(invalid_port_err)
        validated = False
        while not validated:
            if not user:
                user = raw_input("User: ")
                if not user:
                    continue
            if bad_chars(user):
                raw_input(invalid_user_err)
                user = None
            else:
                validated = True
        if protocol == 'ssh':
            print(_('Connecting to ssh://%s@%s:%s' % (user, host, port)))
            # Set title
            print("\x1b]0;ssh://%s@%s\007" % (user, host))
            # Special escape handler (so the rest of the plugin knows the
            # connect string)
            connect_string = "{0}@{1}:{2}".format(user, host, port)
            print(
                "\x1b]_;ssh|set;connect_string;{0}\007".format(connect_string))
            openssh_connect(user, host, port,
                command=options.command,
                password=password,
                sshfp=options.sshfp,
                randomart=options.randomart,
                identities=identities,
                additional_args=options.additional_args,
                socket=options.socket,
                debug=debug
            )
        elif protocol == 'telnet':
            if user:
                print(_('Connecting to telnet://%s@%s:%s' % (user, host, port)))
                # Set title
                print("\x1b]0;telnet://%s@%s\007" % (user, host))
            else:
                print(_('Connecting to telnet://%s:%s' % (host, port)))
                # Set title
                print("\x1b]0;telnet://%s\007" % host)
            telnet_connect(user, host, port)
        else:
            print(_('Unknown protocol "%s"' % protocol))
    except (EOFError):
        sys.exit(1) # User probably just pressed Ctrl-D
    except Exception as e: # Catch all
        print(_("Got Exception: %s" % e))
        import traceback
        traceback.print_exc(file=sys.stdout)
        print("Please open up a new issue at https://github.com/liftoff"
                "/GateOne/issues and paste the above information.")
        raw_input(_("[Press any key to close this terminal]"))
        sys.exit(1)

if __name__ == "__main__":
    exit_message = _("\nUser requested exit.  Quitting...")
    signal.signal(signal.SIGCHLD, signal.SIG_IGN) # No zombies
    executor = futures.ThreadPoolExecutor(max_workers=2)
    try:
        future = executor.submit(main)
        done, not_done = futures.wait([future], timeout=120)
        executor.shutdown(wait=False)
        if not_done:
            took_too_long()
        else:
            if isinstance(future.exception(), SystemExit):
                print(exit_message)
    except (KeyboardInterrupt, EOFError):
        print(exit_message)
        os._exit(1)

########NEW FILE########
__FILENAME__ = ssh
# -*- coding: utf-8 -*-
#
#       Copyright 2011 Liftoff Software Corporation
#

# TODO: Complete this docstring...
__doc__ = """\
ssh.py - A plugin for Gate One that adds additional SSH-specific features.

Hooks
-----
This Python plugin file implements the following hooks::

    hooks = {
        'Web': [(r"/ssh", KnownHostsHandler)],
        'WebSocket': {
            'ssh_get_connect_string': get_connect_string,
            'ssh_execute_command': ws_exec_command,
            'ssh_get_identities': get_identities,
            'ssh_get_public_key': get_public_key,
            'ssh_get_private_key': get_private_key,
            'ssh_get_host_fingerprint': get_host_fingerprint,
            'ssh_gen_new_keypair': generate_new_keypair,
            'ssh_store_id_file': store_id_file,
            'ssh_delete_identity': delete_identity,
            'ssh_set_default_identities': set_default_identities
        },
        'Escape': opt_esc_handler,
        'Events': {
            'terminal:authenticate': send_css_template,
            'terminal:authenticate': create_user_ssh_dir
        }
    }

Docstrings
----------
"""

# Meta
__version__ = '1.1'
__version_info__ = (1, 1)
__license__ = "GNU AGPLv3 or Proprietary (see LICENSE.txt)"
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'

# Python stdlib
import os, re
from datetime import datetime, timedelta
from functools import partial

# Our stuff
from gateone.core.server import BaseHandler
from gateone.core.utils import mkdir_p, shell_command, which
from gateone.core.utils import noop, bind
from gateone.core.locale import get_translation
from gateone.core.log import go_logger

_ = get_translation()

# Tornado stuff
import tornado.web
import tornado.ioloop

# Globals
ssh_log = go_logger("gateone.terminal.ssh", plugin='ssh')
OPENSSH_VERSION = None
DROPBEAR_VERSION = None
PLUGIN_PATH = os.path.split(__file__)[0] # Path to this plugin's directory
OPEN_SUBCHANNELS = {}
SUBCHANNEL_TIMEOUT = timedelta(minutes=5) # How long to wait before auto-closing
READY_STRING = "GATEONE_SSH_EXEC_CMD_CHANNEL_READY"
READY_MATCH = re.compile("^%s$" % READY_STRING, re.MULTILINE)
OUTPUT_MATCH = re.compile(
    "^{rs}.+^{rs}$".format(rs=READY_STRING), re.MULTILINE|re.DOTALL)
VALID_PRIVATE_KEY = valid = re.compile(
    r'^-----BEGIN [A-Z]+ PRIVATE KEY-----.*-----END [A-Z]+ PRIVATE KEY-----$',
    re.MULTILINE|re.DOTALL)
TIMER = None # Used to store temporary, cancellable timeouts
# TODO: make execute_command() a user-configurable option...  So it will automatically run whatever command(s) the user likes whenever they connect to a given server.  Differentiate between when they connect and when they start up a master or slave channel.
# TODO: Make it so that equivalent KnownHostsHandler functionality works over the WebSocket.

# Exceptions
class SSHMultiplexingException(Exception):
    """
    Called when there's a failure trying to open a sub-shell via OpenSSH's
    `Master mode <http://en.wikibooks.org/wiki/OpenSSH/Cookbook/Multiplexing>`_
    multiplexing capability.
    """
    pass

class SSHExecutionException(Exception):
    """
    Called when there's an error trying to execute a command in the slave.
    """
    pass

class SSHKeygenException(Exception):
    """
    Called when there's an error trying to generate a public/private keypair.
    """
    pass

class SSHKeypairException(Exception):
    """
    Called when there's an error trying to save public/private keypair or
    certificate.
    """
    pass

class SSHPassphraseException(Exception):
    """
    Called when we try to generate/decode something that requires a passphrase
    but no passphrase was given.
    """
    pass

def get_ssh_dir(self):
    """
    Given a :class:`gateone.TerminalWebSocket` (*self*) instance, return the
    current user's ssh directory

    .. note:: If the user's ssh directory doesn't start with a . (dot) it will be renamed.
    """
    user = self.current_user['upn']
    users_dir = os.path.join(self.ws.settings['user_dir'], user) # "User's dir"
    old_ssh_dir = os.path.join(users_dir, 'ssh')
    users_ssh_dir = os.path.join(users_dir, '.ssh')
    if os.path.exists(old_ssh_dir):
        if not os.path.exists(users_ssh_dir):
            self.ssh_log.info(_(
                "Renaming %s's 'ssh' directory to '.ssh'." % user))
            os.rename(old_ssh_dir, users_ssh_dir)
        else:
            self.ssh_log.warning(_(
                "Both an 'ssh' and '.ssh' directory exist for user %s.  "
                "Using the .ssh directory." % user))
    return users_ssh_dir

def open_sub_channel(self, term):
    """
    Opens a sub-channel of communication by executing a new shell on the SSH
    server using OpenSSH's `Master mode <http://en.wikibooks.org/wiki/OpenSSH/Cookbook/Multiplexing>`_
    capability (it spawns a new slave) and returns the resulting
    :class:`termio.Multiplex` instance.  If a slave has already been opened for
    this purpose it will re-use the existing channel.
    """
    term = int(term)
    global OPEN_SUBCHANNELS
    if term in OPEN_SUBCHANNELS and OPEN_SUBCHANNELS[term].isalive():
        # Use existing sub-channel (much faster this way)
        return OPEN_SUBCHANNELS[term]
    self.ssh_log.info("Opening SSH sub-channel", metadata={'term': term})
    # NOTE: When connecting a slave via ssh you can't tell it to execute a
    # command like you normally can (e.g. 'ssh user@host <some command>').  This
    # is why we're using the termio.Multiplex.expect() functionality below...
    session = self.ws.session
    session_dir = self.ws.settings['session_dir']
    session_path = os.path.join(session_dir, session)
    if not session_path:
        raise SSHMultiplexingException(_(
            "SSH Plugin: Unable to open slave sub-channel."))
    socket_path = self.loc_terms[term]['ssh_socket']
    # Interesting: When using an existing socket you don't need to give it all
    # the same options as you used to open it but you still need to give it
    # *something* in place of the hostname or it will report a syntax error and
    # print out the help.  So that's why I've put 'go_ssh_remote_cmd' below.
    # ...but I could have just used 'foo' :)
    if not socket_path:
        raise SSHMultiplexingException(_(
            "SSH Plugin: Unable to open slave sub-channel."))
    users_ssh_dir = get_ssh_dir(self)
    ssh_config_path = os.path.join(users_ssh_dir, 'config')
    if not os.path.exists(ssh_config_path):
        # Create it (an empty one so ssh doesn't error out)
        with open(ssh_config_path, 'w') as f:
            f.write('\n')
    # Hopefully 'go_ssh_remote_cmd' will be a clear enough indication of
    # what is going on by anyone that has to review the logs...
    ssh = which('ssh')
    ssh_command = "%s -x -S'%s' -F'%s' go_ssh_remote_cmd" % (
        ssh, socket_path, ssh_config_path)
    OPEN_SUBCHANNELS[term] = m = self.new_multiplex(
        ssh_command, "%s (sub)" % term)
    # Using huge numbers here so we don't miss much (if anything) if the user
    # executes something like "ps -ef".
    m.spawn(rows=100, cols=200) # Hopefully 100/200 lines/cols is enough
    # ...if it isn't, well, that's not really what this is for :)
    # Set the term title so it gets a proper name in the logs
    m.writeline(u'echo -e "\\033]0;Term %s sub-channel\\007"' % term)
    return m

def wait_for_prompt(term, cmd, errorback, callback, m_instance, matched):
    """
    Called by :func:`termio.Multiplex.expect` inside of :func:`execute_command`,
    clears the screen and executes *cmd*.  Also, sets an
    :func:`~termio.Multiplex.expect` to call :func:`get_cmd_output` when the
    end of the command output is detected.
    """
    ssh_log.debug('wait_for_prompt()')
    m_instance.term.clear_screen() # Makes capturing just what we need easier
    getoutput = partial(get_cmd_output, term, errorback, callback)
    m_instance.expect(OUTPUT_MATCH,
        getoutput, errorback=errorback, preprocess=False, timeout=10)
    # Run our command immediately followed by our separation/ready string
    m_instance.writeline((
        u'echo -e "{rs}"; ' # Echo the first READY_STRING
        u'{cmd}; ' # Execute the command in question
        u'echo -e "{rs}"' # READY_STRING again so we can capture the between
    ).format(rs=READY_STRING, cmd=cmd))

def get_cmd_output(term, errorback, callback, m_instance, matched):
    """
    Captures the output of the command executed inside of
    :func:`wait_for_prompt` and calls *callback* if it isn't `None`.
    """
    ssh_log.debug('get_cmd_output()')
    cmd_out = [a.rstrip() for a in m_instance.dump() if a.rstrip()]
    capture = False
    out = []
    for line in cmd_out:
        if not capture and line.startswith(READY_STRING):
            capture = True
        elif capture:
            if READY_STRING in line:
                break
            out.append(line)
    # This is just a silly trick to get the shell timing out/terminating itself
    # after a timout (so we don't keep the sub-channel open forever).  It is
    # easier than starting a timeout thread, timer, IOLoop.add_timeout(), etc
    # (I tried all those and it seemed to result in m_instance never getting
    # cleaned up properly by the garbage collector--it would leak memory)
    m_instance.unexpect() # Clear out any existing patterns (i.e. keepalive ;)
    m_instance.expect( # Add our inactivity timeout
        "^SUB-CHANNEL INACTIVITY TIMEOUT$", # ^ and $ to prevent accidents ;)
        noop, # Don't need to do anything since this should never match
        errorback=timeout_sub_channel,
        preprocess=False,
        timeout=SUBCHANNEL_TIMEOUT)
    m_instance.scheduler.start() # To ensure the timeout occurs
    cmd_out = "\n".join(out)
    if callback:
        callback(cmd_out, None)

def terminate_sub_channel(m_instance):
    """
    Calls `m_instance.terminate()` and deletes it from `OPEN_SUBCHANNELS`.
    """
    ssh_log.info(
        "Closing SSH sub-channel", metadata={'term': repr(m_instance.term_id)})
    global OPEN_SUBCHANNELS
    m_instance.terminate()
    # Find the Multiplex object inside of OPEN_SUBCHANNELS and remove it
    for key, value in list(OPEN_SUBCHANNELS.items()):
        # This will be something like: {1: <Multiplex instance>}
        if hash(value) == hash(m_instance):
            # This is necessary so the interpreter can properly collect garbage:
            del OPEN_SUBCHANNELS[key]

def timeout_sub_channel(m_instance):
    """
    Called when the sub-channel times out by way of an
    :class:`termio.Multiplex.expect` pattern that should never match anything.
    """
    ssh_log.info(
        _("SSH sub-channel closed due to inactivity."),
        metadata={'term': repr(m_instance.term_id)})
    terminate_sub_channel(m_instance)

def got_error(self, m_instance, match=None, term=None, cmd=None):
    """
    Called if :func:`execute_command` encounters a problem/timeout.

    *match* is here in case we want to use it for a positive match of an error.
    """
    self.ssh_log.error(_(
        "%s: Got an error trying to capture output inside of "
        "execute_command() running: %s" % (m_instance.user, m_instance.cmd)))
    self.ssh_log.debug("output before error: %s" % m_instance.dump())
    terminate_sub_channel(m_instance)
    if self:
        message = {
            'terminal:sshjs_cmd_output': {
                'cmd': cmd,
                'term': term,
                'output': None,
                'result': _(
                    'Error: Timeout exceeded or command failed to execute.')
            }
        }
        self.write_message(message)

def execute_command(self, term, cmd, callback=None):
    """
    Execute the given command (*cmd*) on the given *term* using the existing
    SSH tunnel (taking advantage of `Master mode <http://en.wikibooks.org/wiki/OpenSSH/Cookbook/Multiplexing>`_)
    and call *callback* with the output of said command and the current
    :class:`termio.Multiplex` instance as arguments like so::

        callback(output, m_instance)

    If *callback* is not provided then the command will be executed and any
    output will be ignored.

    .. note:: This will not result in a new terminal being opened on the client--it simply executes a command and returns the result using the existing SSH tunnel.
    """
    self.ssh_log.info(
        "Executing command on SSH sub-channel: %s" % cmd,
        metadata={'term': term, 'command': cmd})
    try:
        m = open_sub_channel(self, term)
    except SSHMultiplexingException as e:
        self.ssh_log.error(_(
            "%s: Got an error trying to open sub-channel on term %s..." %
            (self.current_user['upn'], term)))
        # Try to send an error response to the client
        message = {
            'terminal:sshjs_cmd_output': {
                'term': term,
                'cmd': cmd,
                'output': None,
                'result': str(e)
            }
        }
        try:
            self.write_message(message)
        except: # This is really just a last-ditch thing
            pass
        return
    # NOTE: We can assume the IOLoop is started and automatically calling read()
    m.unexpect() # Clear out any existing patterns (if existing sub-channel)
    m.term.clear_screen() # Clear the screen so nothing mucks up our regexes
    # Check to make sure we've got a proper prompt by executing an echo
    # statement and waiting for it to complete.  This is more reliable than
    # using a regular expression to match a shell prompt (which could be set
    # to anything).  It also gives us a clear indication as to where the command
    # output begins and ends.
    errorback = partial(got_error, self, term=term, cmd=cmd)
    wait = partial(wait_for_prompt, term, cmd, errorback, callback)
    m.expect(READY_MATCH,
        callback=wait, errorback=errorback, preprocess=False, timeout=10)
    self.ssh_log.debug("Waiting for READY_MATCH inside execute_command()")
    m.writeline(u'echo -e "\\n%s"' % READY_STRING)

def send_result(self, term, cmd, output, m_instance):
    """
    Called by :func:`ws_exec_command` when the output of the executed command
    has been captured successfully.  Writes a message to the client with the
    command's output and some relevant metadata.
    """
    message = {
        'terminal:sshjs_cmd_output': {
            'term': term,
            'cmd': cmd,
            'output': output,
            'result': 'Success'
        }
    }
    self.write_message(message)

def ws_exec_command(self, settings):
    """
    Takes the necessary variables from *settings* and calls :func:`execute_command`.

    *settings* should be a dict that contains a 'term' and a 'cmd' to execute.

    .. tip:: This function can be used to quickly execute a command and return its result from the client over an existing SSH connection without requiring the user to enter their password!  See execRemoteCmd() in ssh.js.
    """
    term = settings['term']
    cmd = settings['cmd']
    send = partial(send_result, self, term, cmd)
    try:
        execute_command(self, term, cmd, send)
    except SSHExecutionException as e:
        message = {
            'terminal:sshjs_cmd_output': {
                'term': term,
                'cmd': cmd,
                'output': None,
                'result': 'Error: %s' % e
            }
        }
        self.write_message(message)

# Handlers
class KnownHostsHandler(BaseHandler):
    """
    This handler allows the client to view, edit, and upload the known_hosts
    file associated with their user account.
    """
    @tornado.web.authenticated
    def get(self):
        """
        Determine what the user is asking for and call the appropriate method.
        """ # NOTE: Just dealing with known_hosts for now but keys are next
        get_kh = self.get_argument('known_hosts', None)
        if get_kh:
            self._return_known_hosts()

    @tornado.web.authenticated
    def post(self):
        """
        Determine what the user is updating by checking the given arguments and
        proceed with the update.
        """
        known_hosts = self.get_argument('known_hosts', None)
        if known_hosts:
            kh = self.request.body
            self._save_known_hosts(kh)

    def _return_known_hosts(self):
        """Returns the user's known_hosts file in text/plain format."""
        user = self.current_user['upn']
        ssh_log.debug("known_hosts requested by %s" % user)
        users_dir = os.path.join(self.settings['user_dir'], user) # "User's dir"
        users_ssh_dir = os.path.join(users_dir, '.ssh')
        kh_path = os.path.join(users_ssh_dir, 'known_hosts')
        known_hosts = ""
        if os.path.exists(kh_path):
            known_hosts = open(kh_path).read()
        self.set_header ('Content-Type', 'text/plain')
        self.write(known_hosts)

    def _save_known_hosts(self, known_hosts):
        """Save the given *known_hosts* file."""
        user = self.current_user['upn']
        users_dir = os.path.join(self.settings['user_dir'], user) # "User's dir"
        users_ssh_dir = os.path.join(users_dir, '.ssh')
        kh_path = os.path.join(users_ssh_dir, 'known_hosts')
        # Letting Tornado's exception handler deal with errors here
        f = open(kh_path, 'w')
        f.write(known_hosts)
        f.close()
        self.write("success")

"""
WebSocket Commands
------------------
"""
# WebSocket commands (not the same as handlers)
def get_connect_string(self, term):
    """
    Attached to the (server-side) `terminal:ssh_get_connect_string` WebSocket
    action; writes the connection string associated with *term* to the WebSocket
    like so::

        {'terminal:sshjs_reconnect': {*term*: <connection string>}}

    In ssh.js we attach a WebSocket action to 'terminal:sshjs_reconnect'
    that assigns the connection string sent by this function to
    `GateOne.Terminal.terminals[*term*]['sshConnectString']`.
    """
    # This is the first function that normally gets called when a user uses SSH
    # so it's a good time to update the logger with extra metadata
    self.ssh_log = go_logger(
        "gateone.terminal.ssh", plugin='ssh', **self.log_metadata)
    term = int(term)
    if term not in self.loc_terms:
        return # Nothing to do (already closed)
    self.ssh_log.debug("get_connect_string()", metadata={'term': term})
    connect_string = self.loc_terms[term].get('ssh_connect_string', None)
    if connect_string:
        message = {
            'terminal:sshjs_reconnect': {
                'term': term,
                'connect_string': connect_string
            }
        }
        self.write_message(message)

def get_key(self, name, public):
    """
    Returns the private SSH key associated with *name* to the client.  If
    *public* is `True`, returns the public key to the client.
    """
    if not isinstance(name, (str, unicode)):
        error_msg = _(
            'SSH Plugin Error: Invalid name given, %s' % repr(name))
        message = {'go:save_file': {'result': error_msg}}
        self.write_message(message)
        return
    if public and not name.endswith('.pub'):
        name += '.pub'
    out_dict = {
        'result': None, # Yet
        'filename': name,
        'data': None,
        'mimetype': 'text/plain'
    }
    users_ssh_dir = get_ssh_dir(self)
    key_path = os.path.join(users_ssh_dir, name)
    if os.path.exists(key_path):
        with open(key_path) as f:
            out_dict['data'] = f.read()
        out_dict['result'] = 'Success'
    else:
        out_dict['result'] = _(
            'SSH Plugin Error: Public key not found at %s' % key_path)
    message = {'go:save_file': out_dict}
    self.write_message(message)
    return out_dict

def get_public_key(self, name):
    """
    Returns the user's public key file named *name*.
    """
    get_key(self, name, True)

def get_private_key(self, name):
    """
    Returns the user's private key file named *name*.
    """
    get_key(self, name, False)

def get_host_fingerprint(self, settings):
    """
    Returns a the hash of the given host's public key by making a remote
    connection to the server (not just by looking at known_hosts).
    """
    out_dict = {}
    if 'port' not in settings:
        port = 22
    else:
        port = settings['port']
    if 'host' not in settings:
        out_dict['result'] = _("Error:  You must supply a 'host'.")
        message = {'terminal:sshjs_display_fingerprint': out_dict}
        self.write_message(message)
    else:
        host = settings['host']
    self.ssh_log.debug(
        "get_host_fingerprint(%s:%s)" % (host, port),
        metadata={'host': host, 'port': port})
    out_dict.update({
        'result': 'Success',
        'host': host,
        'fingerprint': None
    })
    ssh = which('ssh')
    command = "%s -p %s -oUserKnownHostsFile=none -F. %s" % (ssh, port, host)
    m = self.new_multiplex(
        command,
        'get_host_key',
        logging=False) # Logging is false so we don't make tons of silly logs
    def grab_fingerprint(m_instance, match):
        out_dict['fingerprint'] = match.splitlines()[-1][:-1]
        m_instance.terminate()
        message = {'terminal:sshjs_display_fingerprint': out_dict}
        self.write_message(message)
        del m_instance
    def errorback(m_instance):
        leftovers = [a.rstrip() for a in m_instance.dump() if a.strip()]
        out_dict['result'] = _(
            "Error: Could not determine the fingerprint of %s:%s... '%s'"
            % (host, port, "\n".join(leftovers)))
        m_instance.terminate() # Don't leave stuff hanging around!
        message = {'terminal:sshjs_display_fingerprint': out_dict}
        self.write_message(message)
        del m_instance
    # "The authenticity of host 'localhost (127.0.0.1)' can't be established.\r\nECDSA key fingerprint is 83:f5:b1:f1:d3:8c:b8:fe:d3:be:e5:dd:95:a5:ba:73.\r\nAre you sure you want to continue connecting (yes/no)? "
    m.expect('\n.+fingerprint .+\n',
        grab_fingerprint, errorback=errorback, preprocess=False)
    m.spawn()
    # OpenSSH output example:
    # ECDSA key fingerprint is 28:46:86:3a:c6:f9:63:b8:90:e1:09:69:f2:1d:c8:ce.
    # Dropbear output example:
    # (fingerprint md5 fa:a1:5b:4f:e5:ab:fe:e6:1f:1f:74:20:d7:35:67:c2)

def generate_new_keypair(self, settings):
    """
    Calls :func:`openssh_generate_new_keypair` or
    :func:`dropbear_generate_new_keypair` depending on what's available on the
    system.
    """
    self.ssh_log.debug('generate_new_keypair()')
    users_ssh_dir = get_ssh_dir(self)
    name = 'id_ecdsa'
    keytype = None
    bits = None
    passphrase = ''
    comment = ''
    if 'name' in settings:
        name = settings['name']
    if 'keytype' in settings:
        keytype = settings['keytype']
    if 'bits' in settings:
        bits = settings['bits']
    if 'passphrase' in settings:
        passphrase = settings['passphrase']
    if 'comment' in settings:
        comment = settings['comment']
    log_metadata = {
        'name': name,
        'keytype': keytype,
        'bits': bits,
        'comment': comment
    }
    self.ssh_log.info("Generating new SSH keypair", metadata=log_metadata)
    if which('ssh-keygen'): # Prefer OpenSSH
        openssh_generate_new_keypair(
            self,
            name, # Name to use when generating the keypair
            users_ssh_dir, # Path to save it
            keytype=keytype,
            passphrase=passphrase,
            bits=bits,
            comment=comment
        )
    elif which('dropbearkey'):
        dropbear_generate_new_keypair(self,
            name, # Name to use when generating the keypair
            users_ssh_dir, # Path to save it
            keytype=keytype,
            passphrase=passphrase,
            bits=bits,
            comment=comment)

def errorback(self, m_instance):
    self.ssh_log.error(_("Keypair generation failed."))
    print(m_instance.dump())
    m_instance.terminate()
    message = {
        'terminal:sshjs_keygen_complete': {
            'result': _("There was a problem generating SSH keys: %s"
                        % m_instance.dump()),
        }
    }
    self.write_message(message)

def overwrite(m_instance, match):
    """
    Called if we get asked to overwrite an existing keypair.
    """
    ssh_log.debug('overwrite()')
    m_instance.writeline('y')

def enter_passphrase(passphrase, m_instance, match):
    ssh_log.debug("entering passphrase...")
    m_instance.writeline('%s' % passphrase)

def finished(self, m_instance, fingerprint):
    self.ssh_log.info(
        _("Keypair generation complete"), metadata={'fingerprint': fingerprint})
    message = {
        'terminal:sshjs_keygen_complete': {
            'result': 'Success',
            'fingerprint': fingerprint
        }
    }
    m_instance.terminate()
    self.write_message(message)

def openssh_generate_new_keypair(self, name, path,
        keytype=None, passphrase="", bits=None, comment=""):
    """
    Generates a new private and public key pair--stored in the user's directory
    using the given *name* and other optional parameters (using OpenSSH).

    If *keytype* is given, it must be one of "ecdsa", "rsa" or "dsa" (case
    insensitive).  If *keytype* is "rsa" or "ecdsa", *bits* may be specified to
    specify the size of the key.

    .. note:: Defaults to generating a 521-byte ecdsa key if OpenSSH is version 5.7+. Otherwise a 2048-bit rsa key will be used.
    """
    self.ssh_log.debug('openssh_generate_new_keypair()')
    openssh_version = shell_command('ssh -V')[1]
    ssh_major_version = int(
        openssh_version.split()[0].split('_')[1].split('.')[0])
    key_path = os.path.join(path, name)
    ssh_minor_version = int(
        openssh_version.split()[0].split('_')[1].split('.')[1][0])
    ssh_version = "%s.%s" % (ssh_major_version, ssh_minor_version)
    ssh_version = float(ssh_version)
    if not keytype:
        if ssh_version >= 5.7:
            keytype = "ecdsa"
        else:
            keytype = "rsa"
    else:
        keytype = keytype.lower()
    if not bits and keytype == "ecdsa":
        bits = 521 # Not a typo: five-hundred-twenty-one bits
    elif not bits and keytype == "rsa":
        bits = 2048
    if not passphrase: # This just makes sure False and None end up as ''
        passphrase = ''
    hostname = os.uname()[1]
    if not comment:
        now = datetime.now().isoformat()
        comment = "Generated by Gate One on %s %s" % (hostname, now)
    ssh_keygen_path = which('ssh-keygen')
    command = (
        "%s "       # Path to ssh-keygen
        "-b %s "    # bits
        "-t %s "    # keytype
        "-C '%s' "  # comment
        "-f '%s'"   # Key path
        % (ssh_keygen_path, bits, keytype, comment, key_path)
    )
    self.ssh_log.debug("Keygen command: %s" % command)
    m = self.new_multiplex(command, "gen_ssh_keypair")
    call_errorback = partial(errorback, self)
    m.expect('^Overwrite.*',
        overwrite, optional=True, preprocess=False, timeout=10)
    passphrase_handler = partial(enter_passphrase, passphrase)
    m.expect('^Enter passphrase',
        passphrase_handler,
        errorback=call_errorback,
        preprocess=False,
        timeout=10)
    m.expect('^Enter same passphrase again',
        passphrase_handler,
        errorback=call_errorback,
        preprocess=False,
        timeout=10)
    finalize = partial(finished, self)
    # The regex below captures the md5 fingerprint which tells us the
    # operation was successful.
    m.expect(
        '(([0-9a-f][0-9a-f]\:){15}[0-9a-f][0-9a-f])',
        finalize,
        errorback=call_errorback,
        preprocess=False,
        timeout=15 # Key generation can take a little while
    )
    m.spawn()

def dropbear_generate_new_keypair(self, name, path,
        keytype=None, passphrase="", bits=None, comment=""):
    """
    .. note:: Not implemented yet
    """
    pass

def openssh_generate_public_key(self, path, passphrase=None, settings=None):
    """
    Generates a public key from the given private key at *path*.  If a
    *passphrase* is provided, it will be used to generate the public key (if
    necessary).
    """
    self.ssh_log.debug('openssh_generate_public_key()')
    ssh_keygen_path = which('ssh-keygen')
    pubkey_path = "%s.pub" % path
    command = (
        "%s "       # Path to ssh-keygen
        "-f '%s' "  # Key path
        "-y "       # Output public key to stdout
        "2>&1 "     # Redirect stderr to stdout so we can catch failures
        "> '%s'"    # Redirect stdout to the public key path
        % (ssh_keygen_path, path, pubkey_path)
    )
    import termio
    m = termio.Multiplex(command)
    def request_passphrase(*args, **kwargs):
        "Called if this key requires a passphrase.  Ask the client to provide"
        message = {'terminal:sshjs_ask_passphrase': settings}
        self.write_message(message)
    def bad_passphrase(m_instance, match):
        "Called if the user entered a bad passphrase"
        settings['bad'] = True
        request_passphrase()
    if passphrase:
        m.expect('^Enter passphrase',
            "%s\n" % passphrase, optional=True, preprocess=False, timeout=5)
        m.expect('^load failed',
            bad_passphrase, optional=True, preprocess=False, timeout=5)
    elif settings:
        m.expect('^Enter passphrase',
            request_passphrase, optional=True, preprocess=False, timeout=5)
    def atexit(child, exitstatus):
        "Raises an SSHKeygenException if the *exitstatus* isn't 0"
        if exitstatus != 0:
            print(m.dump)
            raise SSHKeygenException(_(
                "Error generating public key from private key at %s" % path))
    m.spawn(exitfunc=atexit)
    #exitstatus, output = shell_command(command)
    #if exitstatus != 0:
        #raise SSHKeygenException(_(
            #"Error generating public key from private key at %s" % path))

# ssh-kegen example for reference:
    #$ ssh-keygen -b 521 -t ecdsa "Testing" -f /tmp/testkey
    #Generating public/private ecdsa key pair.
    #Enter passphrase (empty for no passphrase):
    #Enter same passphrase again:
    #Your identification has been saved in /tmp/testkey.
    #Your public key has been saved in /tmp/testkey.pub.
    #The key fingerprint is:
    #6b:13:4b:5d:80:bd:21:70:33:f5:b9:15:78:75:08:9a Testing
    #The key's randomart image is:
    #+--[ECDSA  521]---+
    #|      ..++o .o.oo|
    #|       .ooo=..o..|
    #|         .Eo+..  |
    #|         ... o   |
    #|        S . .    |
    #|       . +       |
    #|        =        |
    #|       . .       |
    #|                 |
    #+-----------------+

# dropbearkey example for reference:

    #root@router:~# dropbearkey -t dss -f /tmp/testing
    #Will output 1024 bit dss secret key to '/tmp/testing'
    #Generating key, this may take a while...
    #Public key portion is:
    #ssh-dss AAAAB3NzaC1kc3MAAACBAJ5jU4izsZtJKEojw7gIcc6e3U4X6OENN6081YxSAanfTbKjR0V3Ho6aui2z8o039BVH4S5cVD51vEEvDjirKStM2aMvdrVZkjGH1iOMWY4MQrCl4EqMr7rWikeiZJN6BJ+xmPBUyZuicVDFkBwqC+dKgxml0RTpa7TYBWvp403XAAAAFQDg6vb3afaKM9+DvBW7I4xPxF8a8QAAAIEAjcNHYFrqcWK9lSsw2Oy+w1PEWQuxvWydXXk3MQyiZ/PYaeU/138iCB2pW1fgCksx5CHF8dgtQ7AsFv32gBlxuDgX3EYtPYR0wGJqyU7w9+qaq1T02zmDfW4k2WDfMNz+QWFYHuKzC/aeuEC0BRTLyPVQMHLNAd/F5beCqlIPRPcAAACAfUy1+yNgK2svox6aJRqtpxbMSPDRNTRMAjeTkCeLopesZFYbPvms2c19WkIk2qD9aw3gIxsR4wO+kkvI4BtOs8dXQWS+bc+svJbIYOqmPFo89BJHfbP9wvMhfTlp1uH9LxAG6ZiHHz5fseUgTrwYkSw1beUprikxlca8lQm5v7g= root@RouterStationPro
    #Fingerprint: md5 c6:f9:f2:95:b8:40:ac:f3:53:f1:39:e9:57:a0:58:18

# TODO: Get this validating uploaded keys.
def store_id_file(self, settings):
    """
    Stores the given *settings['private']* and/or *settings['public']* keypair
    in the user's ssh directory as *settings['name']* and/or
    *settings['name']*.pub, respectively.  Either file can be saved independent
    of each other (in case this function needs to be called multiple times to
    save each respective file).

    Also, a *settings['certificate']* may be provided to be saved along
    with the private and public keys.  It will be saved as
    *settings['name']*-cert.pub.

    .. note::

        I've found the following website helpful in understanding how to use
        OpenSSH with SSL certificates:
        http://blog.habets.pp.se/2011/07/OpenSSH-certificates

    .. tip::

        Using signed-by-a-CA certificates is very handy because allows you to
        revoke the user's SSH key(s).  e.g. If they left the company.
    """
    self.ssh_log.debug('store_id_file()')
    out_dict = {'result': 'Success'}
    global TIMER
    try:
        name = settings.get('name', None)
        if not name:
            raise SSHKeypairException(_("You must specify a valid *name*."))
        name = os.path.splitext(name)[0] # Remove .txt, .pub, etc
        private = settings.get('private', None)
        public = settings.get('public', None)
        certificate = settings.get('certificate', None)
        passphrase = settings.get('passphrase', None)
        if not private and not public and not certificate:
            raise SSHKeypairException(_("No files were given to save!"))
        users_ssh_dir = get_ssh_dir(self)
        private_key_path = os.path.join(users_ssh_dir, name)
        # Strip any .pub or .txt from the end of the public key
        if name.endswith('.pub'):
            public_key_name = name # Get rid of the extra .pub
        public_key_name = name + '.pub'
        public_key_path = os.path.join(users_ssh_dir, public_key_name)
        certificate_name = name + '-cert.pub'
        if name.endswith('-cert.pub'):
            certificate_name = name # Don't need an extra -cert.pub at the end
        certificate_path = os.path.join(users_ssh_dir, certificate_name)
        if private:
            # Fix Windows newlines
            private = private.replace('\r\n', '\n')
            if VALID_PRIVATE_KEY.match(private):
                with open(private_key_path, 'w') as f:
                    f.write(private)
                # Without this you get a warning:
                os.chmod(private_key_path, 0o600)
            else:
                self.write_message({'go:notice': _(
                    "ERROR: Private key is not valid.")})
                return
        if public:
            # Fix Windows newlines
            public = public.replace('\r\n', '\n')
            with open(public_key_path, 'w') as f:
                f.write(public)
            # Now remove the timer that will generate the public key from the
            # private key if it is set.
            if TIMER:
                self.ssh_log.debug(_(
                    "Got public key, cancelling public key generation timer."))
                io_loop = tornado.ioloop.IOLoop.current()
                io_loop.remove_timeout(TIMER)
                TIMER = None
            get_ids = partial(get_identities, self, None)
            io_loop.add_timeout(timedelta(seconds=2), get_ids)
        elif private: # No biggie, generate one
            # Only generate a new public key if one isn't uploaded within 2
            # seconds (should be plenty of time since they're typically sent
            # simultaneously but inside different WebSocket messages).
            self.ssh_log.debug(_(
                "Only received a private key.  Setting timeout to generate the "
                "public key if not received within 3 seconds."))
            io_loop = tornado.ioloop.IOLoop.current()
            deadline = timedelta(seconds=2)
            def generate_public_key(): # I love closures
                openssh_generate_public_key(self,
                    private_key_path, passphrase, settings=settings)
                get_ids = partial(get_identities, self, None)
                io_loop.add_timeout(timedelta(seconds=2), get_ids)
            # This gets removed if the public key is uploaded
            TIMER = io_loop.add_timeout(deadline, generate_public_key)
        if certificate:
            # Fix Windows newlines
            certificate = certificate.replace('\r\n', '\n')
            with open(certificate_path, 'w') as f:
                f.write(certificate)
    except Exception as e:
        out_dict['result'] = _("Error saving keys: %s" % e)
    message = {
        'terminal:sshjs_save_id_complete': out_dict
    }
    self.write_message(message)

def delete_identity(self, name):
    """
    Removes the identity associated with *name*.  For example if *name* is
    'testkey', 'testkey' and 'testkey.pub' would be removed from the user's
    ssh directory (and 'testkey-cert.pub' if present).
    """
    self.ssh_log.info(
        'Deleting SSH identity: %s' % name, metadata={'name': name})
    out_dict = {'result': 'Success'}
    users_ssh_dir = get_ssh_dir(self)
    private_key_path = os.path.join(users_ssh_dir, name)
    public_key_path = os.path.join(users_ssh_dir, name+'.pub')
    certificate_path = os.path.join(users_ssh_dir, name+'-cert.pub')
    try:
        if os.path.exists(private_key_path):
            os.remove(private_key_path)
        if os.path.exists(public_key_path):
            os.remove(public_key_path)
        if os.path.exists(certificate_path):
            os.remove(certificate_path)
    except Exception as e:
        out_dict['result'] = _("Error deleting keypair: %s" % e)
    message = {
        'terminal:sshjs_delete_identity_complete': out_dict
    }
    self.write_message(message)

def get_identities(self, *anything):
    """
    Sends a message to the client with a list of the identities stored on the
    server for the current user.

    *anything* is just there because the client needs to send *something* along
    with the 'action'.
    """
    self.ssh_log.debug('get_identities()')
    out_dict = {'result': 'Success'}
    users_ssh_dir = get_ssh_dir(self)
    out_dict['identities'] = []
    ssh_keygen_path = which('ssh-keygen')
    # TODO:  Switch this from using ssh-keygen to determine the keytype to using the string inside the public key.
    try:
        if os.path.exists(users_ssh_dir):
            ssh_files = os.listdir(users_ssh_dir)
            for f in ssh_files:
                if f.endswith('.pub'):
                    # Double-check there's also a private key...
                    identity = f[:-4] # Will be the same name minus '.pub'
                    if identity in ssh_files:
                        id_path = os.path.join(users_ssh_dir, identity)
                        pub_key_path = os.path.join(users_ssh_dir, f)
                        public_key_contents = open(pub_key_path).read()
                        comment = ' '.join(public_key_contents.split(' ')[2:])
                        if public_key_contents.startswith('ecdsa'):
                            keytype = 'ECDSA'
                        elif public_key_contents.startswith('ssh-dss'):
                            keytype = 'DSA'
                        elif public_key_contents.startswith('ssh-rsa'):
                            keytype = 'RSA'
                        else:
                            keytype = 'Unknown'
                        keygen_cmd = "'%s' -vlf '%s'" % (
                            ssh_keygen_path, id_path)
                        retcode, key_info = shell_command(keygen_cmd)
                        # This will just wind up as an empty string if the
                        # version of ssh doesn't support randomart:
                        randomart = '\n'.join(key_info.splitlines()[1:])
                        bits = key_info.split()[0]
                        fingerprint = key_info.split()[1]
                        retcode, bubblebabble = shell_command(
                            "'%s' -Bf '%s'" % (ssh_keygen_path, id_path))
                        bubblebabble = bubblebabble.split()[1]
                        certinfo = ''
                        cert_path = "'%s-cert.pub'" % id_path
                        if os.path.exists(cert_path):
                            retcode, certinfo = shell_command(
                            "'%s' -Lf '%s'" % (ssh_keygen_path, cert_path))
                        certinfo = ' '.join(certinfo.split(' ')[1:])
                        fixed_certinfo = ''
                        for i, line in enumerate(certinfo.splitlines()):
                            if i == 0:
                                line = line.lstrip()
                            fixed_certinfo += line.replace('    ', ' ')
                            fixed_certinfo += '\n'
                        id_obj = {
                            'name': identity,
                            'public': public_key_contents,
                            'keytype': keytype,
                            'bubblebabble': bubblebabble,
                            'fingerprint': fingerprint,
                            'randomart': randomart,
                            'certinfo': fixed_certinfo,
                            'bits': bits,
                            'comment': comment.rstrip(),
                        }
                        out_dict['identities'].append(id_obj)
        # Figure out which identities are defaults
        default_ids = []
        default_ids_exists = False
        users_ssh_dir = get_ssh_dir(self)
        default_ids_path = os.path.join(users_ssh_dir, '.default_ids')
        if os.path.exists(default_ids_path):
            default_ids_exists = True
            with open(default_ids_path) as f:
                default_ids = f.read().splitlines() # Why not readlines()? \n
        # Convert any absolute paths inside default_ids to just the short names
        default_ids = [os.path.split(a)[1] for a in default_ids]
        if default_ids_exists:
            for i, id_obj in enumerate(out_dict['identities']):
                if id_obj['name'] in default_ids:
                    out_dict['identities'][i]['default'] = True
                else:
                    out_dict['identities'][i]['default'] = False
    except Exception as e:
        error_msg = _("Error getting identities: %s" % e)
        self.ssh_log.error(error_msg)
        out_dict['result'] = error_msg
    message = {
        'terminal:sshjs_identities_list': out_dict
    }
    self.write_message(message)

def set_default_identities(self, identities):
    """
    Given a list of *identities*, mark them as defaults to use in all outbound
    SSH connections by writing them to `<user's ssh dir>/.default_ids`.  If
    *identities* is empty, no identities will be used in outbound connections.

    .. note::

        Whenever this function is called it will overwrite whatever is in
        `.default_ids`.
    """
    if isinstance(identities, list): # Ignore anything else
        users_ssh_dir = get_ssh_dir(self)
        default_ids_path = os.path.join(users_ssh_dir, '.default_ids')
        with open(default_ids_path, 'w') as f:
            f.write('\n'.join(identities) + '\n') # Need that trailing newline

def set_ssh_socket(self, term, path):
    """
    Given a *term* and *path*, sets
    ``self.loc_terms[term]['ssh_socket'] = path``.
    """
    self.ssh_log.debug("set_ssh_socket(): %s, %s" % (term, path))
    term = int(term)
    if term in self.loc_terms:
        self.loc_terms[term]['ssh_socket'] = path
        self.save_term_settings(term, {'ssh_socket': path})

def set_ssh_connect_string(self, term, connect_string):
    """
    Given a *term* and *connect_string*, sets
    ``self.loc_terms[term]['ssh_connect_string'] = connect_string``.
    """
    self.ssh_log.debug(
        'set_ssh_connect_string: %s, %s' % (term, connect_string))
    term = int(term)
    if term in self.loc_terms:
        self.loc_terms[term]['ssh_connect_string'] = connect_string
        self.save_term_settings(term, {'ssh_connect_string': connect_string})
    message = {'terminal:sshjs_connect': connect_string}
    self.write_message(message)

# Special optional escape sequence handler (see docs on how it works)
def opt_esc_handler(self, text, term=None, multiplex=None):
    """
    Handles text passed from the special optional escape sequance handler.  We
    use it to tell ssh.js what the SSH connection string is so it can use that
    information to duplicate sessions (if the user so desires).  For reference,
    the specific string which will call this function from a terminal app is::

        \\x1b]_;ssh|<whatever>\\x07

    .. seealso::

        :class:`gateone.TerminalWebSocket.esc_opt_handler` and
        :func:`terminal.Terminal._opt_handler`
    """
    supported_assignments = {
        'ssh_socket': set_ssh_socket,
        'connect_string': set_ssh_connect_string
    }
    if text.startswith('set;'):
        values = text.split(';')
        assignment = values[1]
        data = values[2:]
        func = supported_assignments.get(assignment, None)
        if func:
            func(self, term, *data)
        return

def create_user_ssh_dir(self):
    """
    To be called by the 'Auth' hook that gets called after the user is done
    authenticating, ensures that the `<user's dir>/ssh` directory exists.
    """
    self.ssh_log.debug("create_user_ssh_dir()")
    user = self.current_user['upn']
    users_dir = os.path.join(self.ws.settings['user_dir'], user) # "User's dir"
    ssh_dir = os.path.join(users_dir, '.ssh')
    try:
        mkdir_p(ssh_dir)
    except OSError as e:
        self.ssh_log.error(_("Error creating user's ssh directory: %s\n" % e))

def send_ssh_css_template(self):
    """
    Sends our ssh.css template to the client using the 'load_style'
    WebSocket action.  The rendered template will be saved in Gate One's
    'cache_dir'.
    """
    css_path = os.path.join(PLUGIN_PATH, 'templates', 'ssh.css')
    self.render_and_send_css(css_path)

def initialize(self):
    """
    Called inside of :meth:`TerminalApplication.initialize` shortly after the
    WebSocket is instantiated.  Attaches our two `terminal:authenticate` events
    (to create the user's .ssh dir and send our CSS template) and ensures that
    the ssh_connect.py script is executable.
    """
    ssh_connect_path = os.path.join(PLUGIN_PATH, 'scripts', 'ssh_connect.py')
    if os.path.exists(ssh_connect_path):
        import stat
        st = os.stat(ssh_connect_path)
        if not bool(st.st_mode & stat.S_IXOTH):
            try:
                os.chmod(ssh_connect_path, 0o755)
            except OSError:
                ssh_log.error(_(
                    "Could not set %s as executable.  You will need to 'chmod "
                    "a+x' that script manually.") % ssh_connect_path)
                user_msg = _(
                    "Error loading SSH plugin:  The ssh_connect.py script is "
                    "not executable.  See the logs for more details.")
                send_msg = partial(self.ws.send_message, user_msg)
                events = ["terminal:authenticate", "terminal:new_terminal"]
                self.on(events, send_msg)
    self.ssh_log = go_logger("gateone.terminal.ssh", plugin='ssh')
    # NOTE:  Why not use the 'Events' hook for these?  You can't attach two
    # functions to the same event via that mechanism because it's a dict
    # (one would override the other).
    # An alternative would be to write a single function say, on_auth() that
    # calls both of these functions then assign it to 'terminal:authenticate' in
    # the 'Events' hook.  I think this way is better since it is more explicit.
    self.on('terminal:authenticate', bind(send_ssh_css_template, self))
    self.on('terminal:authenticate', bind(create_user_ssh_dir, self))

hooks = {
    'Web': [(r"/ssh", KnownHostsHandler)],
    'WebSocket': {
        'terminal:ssh_get_connect_string': get_connect_string,
        'terminal:ssh_execute_command': ws_exec_command,
        'terminal:ssh_get_identities': get_identities,
        'terminal:ssh_get_public_key': get_public_key,
        'terminal:ssh_get_private_key': get_private_key,
        'terminal:ssh_get_host_fingerprint': get_host_fingerprint,
        'terminal:ssh_gen_new_keypair': generate_new_keypair,
        'terminal:ssh_store_id_file': store_id_file,
        'terminal:ssh_delete_identity': delete_identity,
        'terminal:ssh_set_default_identities': set_default_identities,
    },
    'Escape': opt_esc_handler,
}

# Certificate information (as output by ssh-keygen) for reference:
#
#$ ssh-keygen -Lf id_rsa-cert.pub
#id_rsa-cert.pub:
        #Type: ssh-rsa-cert-v01@openssh.com user certificate
        #Public key: RSA-CERT 80:57:2c:18:f9:86:ab:8b:64:27:db:6f:5e:03:3f:d9
        #Signing CA: RSA 86:25:b0:73:67:0f:51:2e:a7:96:63:08:fb:d6:69:94
        #Key ID: "user_riskable"
        #Serial: 0
        #Valid: from 2012-01-08T13:38:00 to 2013-01-06T13:39:27
        #Principals:
                #riskable
        #Critical Options: (none)
        #Extensions:
                #permit-agent-forwarding
                #permit-port-forwarding
                #permit-pty
                #permit-user-rc
                #permit-X11-forwarding


# NOTE: *message['identities'][0]* - An associative array conaining the key's metadata.  For example:
#
#{
    #'name': "testid",
    #'public': "ecdsa-sha2-nistp521 AAAAE2VjZHNhLXNoYTItbmlzdHA1MjEAAAAIbmlzdHA1MjEAAACFBAChqFprVjC0MKe3qpjjc+WdANOHMgcUl46dJxZ+s5soBTkO6thcJDAbFb36lg3YyzZi/PtDJV5CPp8Mv1SUXUYBqgFZJFBqWwkB0O1ohjtEVzC8+ybrY+hP0zLqykglhOi+6W66HgFwjJGn56uGE7s8UpnSRKtqGq2USyme5gopYlytTw== Generated by Gate One on somehost",
    #'keytype': "ecdsa",
    #'bubblebabble': "xevol-budez-difod-zumif-zofos-vezis-rilep-febel-tufok-lugud-dyxex",
    #'fingerprint': "0e:69:0a:9e:2e:26:2b:91:23:3d:95:4b:65:31:a9:6f",
    #'randomart': "+--[ECDSA  521]---+\n|      oo         |\n|      +.         |\n|     =           |\n|    =  .         |\n| o.o o+ S        |\n|=.oo.oEo         |\n|.oo...  .        |\n|+o               |\n|=o.              |\n+-----------------+",
    #'certinfo': "",
    #'bits': 521,
    #'comment': "Generated by Gate One on somehost",
#}

########NEW FILE########
__FILENAME__ = policy
# -*- coding: utf-8 -*-
#
#       Copyright 2013 Liftoff Software Corporation
#
from __future__ import unicode_literals

__doc__ = """\
policy.py - A module containing the Terminal application's policy functions.
"""

# Meta
__license__ = "AGPLv3 or Proprietary (see LICENSE.txt)"
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'

from functools import partial
from gateone import SESSIONS
from gateone.core.locale import get_translation
from gateone.core.log import go_logger
from gateone.auth.authorization import applicable_policies

term_log = go_logger("gateone.terminal")

# Localization support
_ = get_translation()

def policy_new_terminal(cls, policy):
    """
    Called by :func:`terminal_policies`, returns True if the user is
    authorized to execute :func:`new_terminal` and applies any configured
    restrictions (e.g. max_dimensions).  Specifically, checks to make sure the
    user is not in violation of their applicable policies (e.g. max_terms).
    """
    instance = cls.instance
    session = instance.ws.session
    auth_log = instance.ws.auth_log
    if not session:
        return False
    try:
        term = cls.f_args[0]['term']
    except (KeyError, IndexError):
        # new_terminal got bad *settings*.  Deny
        return False
    user = instance.current_user
    open_terminals = 0
    locations = SESSIONS[session]['locations']
    if term in instance.loc_terms:
        # Terminal already exists (reattaching) or was shared by someone else
        return True
    for loc in locations.values():
        for t, term_obj in loc['terminal'].items():
            if t in instance.loc_terms:
                if user == term_obj['user']:
                    # Terms shared by others don't count
                    if user['upn'] == 'ANONYMOUS':
                        # ANONYMOUS users are all the same so we have to use
                        # the session ID
                        if session == term_obj['user']['session']:
                            open_terminals += 1
                    else:
                        open_terminals += 1
    # Start by determining the limits
    max_terms = 0 # No limit
    if 'max_terms' in policy:
        max_terms = policy['max_terms']
    max_cols = 0
    max_rows = 0
    if 'max_dimensions' in policy:
        max_cols = policy['max_dimensions']['columns']
        max_rows = policy['max_dimensions']['rows']
    if max_terms:
        if open_terminals >= max_terms:
            auth_log.error(_(
                "%s denied opening new terminal.  The 'max_terms' policy limit "
                "(%s) has been reached for this user." % (
                user['upn'], max_terms)))
            # Let the client know this term is no more (after a timeout so the
            # can complete its newTerminal stuff beforehand).
            term_ended = partial(instance.term_ended, term)
            instance.add_timeout("500", term_ended)
            cls.error = _(
                "Server policy dictates that you may only open %s terminal(s) "
                % max_terms)
            return False
    if max_cols:
        if int(cls.f_args['columns']) > max_cols:
            cls.f_args['columns'] = max_cols # Reduce to max size
    if max_rows:
        if int(cls.f_args['rows']) > max_rows:
            cls.f_args['rows'] = max_rows # Reduce to max size
    return True

def policy_has_write_permission(cls, policy, term):
    """
    Returns True if the user has write access to the given *term*.
    """
    instance = cls.instance
    function_name = cls.function.__name__
    auth_log = instance.ws.auth_log
    user = instance.current_user
    if not user:
        return False # Broadcast viewers can't write to anything
    term_obj = instance.loc_terms.get(term, None)
    if not term_obj:
        return True # Term doesn't exist anymore--just let it fall through
    if 'share_id' in term_obj:
        # This is a shared terminal.  Check if the user is in the 'write' list
        shared = instance.ws.persist['terminal']['shared']
        share_obj = shared[term_obj['share_id']]
        if user['upn'] in share_obj['write']:
            return True
        elif share_obj['write'] in ['AUTHENTICATED', 'ANONYMOUS']:
            return True
        elif isinstance(share_obj['write'], list):
            # Iterate and check each item
            for allowed in share_obj['write']:
                if allowed == user['upn']:
                    return True
                elif allowed in ['AUTHENTICATED', 'ANONYMOUS']:
                    return True
        auth_log.error(
            _("{upn} denied executing {function_name} by policy (not owner "
              "of terminal or does not have write access).").format(
                  upn=user['upn'], function_name=function_name))
        return False
    return True

def policy_write_check_dict(cls, policy):
    """
    Called by :func:`terminal_policies`, returns True if the user is
    authorized to resize the terminal in question.  This version of the write
    check expects that the *term* be provided in a dictionary that's provided
    as the first argument to the decorated function.
    """
    try:
        term = int(cls.f_args[0]['term'])
    except (KeyError, IndexError):
        # Function got bad args.  Deny
        return False
    return policy_has_write_permission(cls, policy, term)

def policy_write_check_arg(cls, policy):
    """
    Called by :func:`terminal_policies`, returns True if the user is
    authorized to resize the terminal in question.  This version of the write
    check expects that the *term* be provided as the first argument passed to
    the decorated function.
    """
    try:
        term = int(cls.f_args[0])
    except (KeyError, IndexError):
        # Function got bad args.  Deny
        return False
    return policy_has_write_permission(cls, policy, term)

def policy_share_terminal(cls, policy):
    """
    Called by :func:`terminal_policies`, returns True if the user is
    authorized to execute :func:`share_terminal`.
    """
    auth_log = cls.instance.ws.auth_log
    user = cls.instance.current_user
    try:
        cls.f_args[0]['term']
    except (KeyError, IndexError):
        # share_terminal got bad *settings*.  Deny
        return False
    can_share = policy.get('share_terminals', True)
    if not can_share:
        auth_log.error(_(
            "%s denied sharing terminal by policy." % user['upn']))
        return False
    return True

def policy_char_handler(cls, policy):
    """
    Called by :func:`terminal_policies`, returns True if the user is
    authorized to write to the current (or specified) terminal.
    """
    error_msg = _("You do not have permission to write to this terminal.")
    cls.error = error_msg
    instance = cls.instance
    try:
        term = cls.f_args[1]
    except IndexError:
        # char_handler didn't get 'term' as a non-keyword argument.  Try kword:
        try:
            term = cls.f_kwargs['term']
        except KeyError:
            # No 'term' was given at all.  Use current_term
            term = instance.current_term
    # Make sure the term is an int
    term = int(term)
    if term not in instance.loc_terms:
        return True # Terminal was probably just closed
    term_obj = instance.loc_terms[term]
    user = instance.current_user
    if user['upn'] == term_obj['user']['upn']:
        # UPN match...  Double-check ANONYMOUS
        if user['upn'] == 'ANONYMOUS':
            # All users will be ANONYMOUS so we need to check their session ID
            if user['session'] == term_obj['user']['session']:
                return True
        # TODO: Think about adding an administrative lock feature here
        else:
            return True # Users can always write to their own terminals
    if 'share_id' in term_obj:
        # This is a shared terminal.  Check if the user is in the 'write' list
        shared = instance.ws.persist['terminal']['shared']
        share_obj = shared[term_obj['share_id']]
        if user['upn'] in share_obj['write']:
            return True
        elif share_obj['write'] in ['AUTHENTICATED', 'ANONYMOUS']:
            return True
        elif isinstance(share_obj['write'], list):
            # Iterate and check each item
            for allowed in share_obj['write']:
                if allowed == user['upn']:
                    return True
                elif allowed in ['AUTHENTICATED', 'ANONYMOUS']:
                    return True
        # TODO: Handle regexes and lists of regexes here
    return False

def terminal_policies(cls):
    """
    This function gets registered under 'terminal' in the
    :attr:`ApplicationWebSocket.security` dict and is called by the
    :func:`require` decorator by way of the :class:`policies` sub-function. It
    returns True or False depending on what is defined in the settings dir and
    what function is being called.

    This function will keep track of and place limmits on the following:

        * The number of open terminals.
        * How big each terminal may be.
        * Who may view or write to a shared terminal.

    If no 'terminal' policies are defined this function will always return True.
    """
    instance = cls.instance # TerminalApplication instance
    function = cls.function # Wrapped function
    #f_args = cls.f_args     # Wrapped function's arguments
    #f_kwargs = cls.f_kwargs # Wrapped function's keyword arguments
    policy_functions = {
        'new_terminal': policy_new_terminal,
        'resize': policy_write_check_dict,
        'set_term_encoding': policy_write_check_dict,
        'set_term_keyboard_mode': policy_write_check_dict,
        'swap_terminals': policy_write_check_dict,
        'move_terminal': policy_write_check_dict,
        'kill_terminal': policy_write_check_arg,
        'reset_terminal': policy_write_check_arg,
        'manual_title': policy_write_check_dict,
        'share_terminal': policy_share_terminal,
        'char_handler': policy_char_handler
    }
    auth_log = instance.ws.auth_log
    user = instance.current_user
    policy = applicable_policies('terminal', user, instance.ws.prefs)
    if not policy: # Empty RUDict
        return True # A world without limits!
    # Start by determining if the user can even login to the terminal app
    if 'allow' in policy:
        if not policy['allow']:
            auth_log.error(_(
                "%s denied access to the Terminal application by policy."
                % user['upn']))
            return False
    if function.__name__ in policy_functions:
        return policy_functions[function.__name__](cls, policy)
    return True # Default to permissive if we made it this far

########NEW FILE########
__FILENAME__ = term_utils
# -*- coding: utf-8 -*-
#
#       Copyright 2013 Liftoff Software Corporation
#

__doc__ = """\
This module simply provides a collection of utility functions for the Terminal
application
"""

# Meta
__license__ = "AGPLv3 or Proprietary (see LICENSE.txt)"
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'

# Standard library imports
import os, io

# Gate One imports
from gateone.core.utils import json_encode
from gateone.core.configuration import RUDict
from gateone.core.locale import get_translation
from gateone.core.log import go_logger

# 3rd party imports
from tornado.escape import json_decode
from tornado.options import options

APPLICATION_PATH = os.path.split(__file__)[0] # Path to our application
term_log = go_logger("gateone.terminal")

# Localization support
_ = get_translation()

def save_term_settings(term, location, session, settings):
    """
    Saves the *settings* associated with the given *term*, *location*, and
    *session* in the 'term_settings.json' file inside the user's session
    directory.

    When complete the given *callback* will be called (if given).
    """
    if not session:
        return # Just a viewer of a broadcast terminal
    term = str(term) # JSON wants strings as keys
    term_settings = RUDict()
    term_settings[location] = {term: settings}
    session_dir = options.session_dir
    session_dir = os.path.join(session_dir, session)
    settings_path = os.path.join(session_dir, 'term_settings.json')
    # First we read in the existing settings and then update them.
    if os.path.exists(settings_path):
        with io.open(settings_path, encoding='utf-8') as f:
            term_settings.update(json_decode(f.read()))
        term_settings[location][term].update(settings)
    with io.open(settings_path, 'w', encoding='utf-8') as f:
        f.write(json_encode(term_settings))

def restore_term_settings(location, session):
    """
    Returns the terminal settings associated with the given *location* that are
    stored in the user's session directory.
    """
    if not session:
        return # Just a viewer of a broadcast terminal
    session_dir = options.session_dir
    session_dir = os.path.join(session_dir, session)
    settings_path = os.path.join(session_dir, 'term_settings.json')
    if not os.path.exists(settings_path):
        return # Nothing to do
    with io.open(settings_path, encoding='utf-8') as f:
        try:
            settings = json_decode(f.read())
        except ValueError:
            # Something wrong with the file.  Remove it
            term_log.error(_(
                "Error decoding {0}.  File will be removed.").format(
                    settings_path))
            os.remove(settings_path)
            return {}
    return settings

########NEW FILE########
__FILENAME__ = woff_info
#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
#       Copyright 2013 Liftoff Software Corporation

# Meta
__version__ = '1.0'
__version_info__ = (1, 0)
__license__ = "AGPLv3 or Proprietary (see LICENSE.txt)"

__doc__ = """\
.. _woff_info.py:

Provides a number of functions that can be used to extract the 'name' data from
.woff (web font) files.

.. note::

    In most cases .woff files have the metadata stripped (to save space) which
    is why this module only grabs the 'name' records from the snft (font data)
    tables.

Example::

    >>> from pprint import pprint
    >>> from woff_info import woff_name_data
    >>> woff_path = '/opt/gateone/applications/terminal/static/fonts/ubuntumono-normal.woff'
    >>> pprint(woff_info(woff_path))
    {'Compatible Full': 'Ubuntu Mono',
    'Copyright': 'Copyright 2011 Canonical Ltd.  Licensed under the Ubuntu Font Licence 1.0',
    'Designer': 'Dalton Maag Ltd',
    'Designer URL': 'http://www.daltonmaag.com/',
    'Font Family': 'Ubuntu Mono',
    'Font Subfamily': 'Regular',
    'Full Name': 'Ubuntu Mono',
    'ID': 'Ubuntu Mono Regular Version 0.80',
    'Manufacturer': 'Dalton Maag Ltd',
    'Postscript Name': 'UbuntuMono-Regular',
    'Preferred Family': 'Ubuntu Mono',
    'Preferred Subfamily': 'Regular',
    'Trademark': 'Ubuntu and Canonical are registered trademarks of Canonical Ltd.',
    'Vendor URL': 'http://www.daltonmaag.com/',
    'Version': 'Version 0.80'}

This script can also be executed on the command line to display the name
information for any given WOFF file:

.. ansi-block::

    \x1b[1;34muser\x1b[0m@modern-host\x1b[1;34m:~ $\x1b[0m ./woff_info static/fonts/ubuntumono-normal.woff
    {
        "Compatible Full": "Ubuntu Mono",
        "Copyright": "Copyright 2011 Canonical Ltd.  Licensed under the Ubuntu Font Licence 1.0",
        "Designer": "Dalton Maag Ltd",
        "Designer URL": "http://www.daltonmaag.com/",
        "Font Family": "Ubuntu Mono",
        "Font Subfamily": "Regular",
        "Full Name": "Ubuntu Mono",
        "ID": "Ubuntu Mono Regular Version 0.80",
        "Manufacturer": "Dalton Maag Ltd",
        "Postscript Name": "UbuntuMono-Regular",
        "Preferred Family": "Ubuntu Mono",
        "Preferred Subfamily": "Regular",
        "Trademark": "Ubuntu and Canonical are registered trademarks of Canonical Ltd.",
        "Vendor URL": "http://www.daltonmaag.com/",
        "Version": "Version 0.80"
    }

..note::

    The command line output is JSON so it can be easily used by other programs.
"""

import sys, struct, zlib, functools

def memoize(obj):
    cache = obj.cache = {}
    @functools.wraps(obj)
    def memoizer(*args, **kwargs):
        key = str(args) + str(kwargs)
        if key not in cache:
            cache[key] = obj(*args, **kwargs)
        return cache[key]
    return memoizer

# Try using Gate One's memoize decorator (with self-expiry!)
try:
    from gateone.core.utils import memoize
except ImportError:
    pass # No big, use the one above

# Globals
ENCODING_MAP = {
    0: 'ascii',
    1: 'latin-1',
    2: 'iso-8859-1'
}

NAME_ID_MAP = { # For human-readable names
    0: u"Copyright",
    1: u"Font Family",
    2: u"Font Subfamily",
    3: u"ID",
    4: u"Full Name",
    5: u"Version",
    6: u"Postscript Name",
    7: u"Trademark",
    8: u"Manufacturer",
    9: u"Designer",
    10: u"Description",
    11: u"Vendor URL",
    12: u"Designer URL",
    13: u"License Description",
    14: u"License URL",
    15: u"Reserved",
    16: u"Preferred Family",
    17: u"Preferred Subfamily",
    18: u"Compatible Full",
    19: u"Sample Text",
    20: u"Postscript CID",
    21: u"WWS Family Name",
    22: u"WWS Subfamily Name",
    #200: u"???" # Liberation Mono uses this, "Webfont 1.0" is the value but
    # what is ID 200 supposed to be?  Webfont version?
    #201: u"???" # Liberation Mono also uses this.  Looks like a date of some
    # sort.  Creation date, perhaps?
}

NAME_HEADER_FORMAT = """
    format:         H
    count:          H
    offset:         H
"""

NAME_RECORD_FORMAT = """
    platform_id:    H
    encoding:       H
    language:       H
    name_id:        H
    length:         H
    offset:         H
"""

HEADER_FORMAT = """
    signature:      4s
    flavor:         4s
    length:         L
    numTables:      H
    reserved:       H
    totalSfntSize:  L
    majorVersion:   H
    minorVersion:   H
    metaOffset:     L
    metaLength:     L
    metaOrigLength: L
    privOffset:     L
    privLength:     L
"""

DIRECTORY_FORMAT = """
    tag:            4s
    offset:         L
    compLength:     L
    origLength:     L
    origChecksum:   L
"""

class BadWoff(Exception):
    """
    Raised when the name data cannot be extracted from a a .woff file (for
    whatever reason).
    """
    pass

# Much of this code was copied from the W3C WOFF validator.py:
#   http://dev.w3.org/webfonts/WOFF/tools/validator/
# ...which is covered by the W3C's own MIT-like license:
#   http://www.w3.org/Consortium/Legal/2002/copyright-software-20021231

# This was inspired by Just van Rossum's sstruct module.
# http://fonttools.svn.sourceforge.net/svnroot/fonttools/trunk/Lib/sstruct.py

def struct_unpack(format, data):
    keys, format_string = _struct_get_format(format)
    size = struct.calcsize(format_string)
    values = struct.unpack(format_string, data[:size])
    unpacked = {}
    for index, key in enumerate(keys):
        value = values[index]
        unpacked[key] = value
    return unpacked, data[size:]

def struct_calc_size(format):
    keys, format_string = _struct_get_format(format)
    return struct.calcsize(format_string)

_struct_format_cache = {}

def _struct_get_format(format):
    if format not in _struct_format_cache:
        keys = []
        format_string = [">"] # always big endian
        for line in format.strip().splitlines():
            line = line.split("#", 1)[0].strip()
            if not line:
                continue
            key, format_char = line.split(":")
            key = key.strip()
            format_char = format_char.strip()
            keys.append(key)
            format_string.append(format_char)
        _struct_format_cache[format] = (keys, "".join(format_string))
    return _struct_format_cache[format]

HEADER_SIZE = struct_calc_size(HEADER_FORMAT)

def unpack_header(data):
    return struct_unpack(HEADER_FORMAT, data)[0]

def unpack_directory(data):
    header = unpack_header(data)
    numTables = header["numTables"]
    data = data[HEADER_SIZE:]
    directory = []
    for index in range(numTables):
        table, data = struct_unpack(DIRECTORY_FORMAT, data)
        directory.append(table)
    return directory

def unpack_table_data(data):
    directory = unpack_directory(data)
    tables = {}
    for entry in directory:
        tag = entry["tag"]
        offset = entry["offset"]
        origLength = entry["origLength"]
        compLength = entry["compLength"]
        if offset > len(data) or offset < 0 or (offset + compLength) < 0:
            tableData = ""
        elif offset + compLength > len(data):
            tableData = data[offset:]
        else:
            tableData = data[offset:offset+compLength]
        if compLength < origLength:
            try:
                td = zlib.decompress(tableData)
                tableData = td
            except zlib.error:
                tableData = None
        tables[tag] = tableData
    return tables

def unpack_name_data(data):
    header, remaining_data = struct_unpack(NAME_HEADER_FORMAT, data)
    count = header["count"]
    storage_offset = header["offset"]
    name_records = []
    for index in range(count):
        record, remaining_data = struct_unpack(
            NAME_RECORD_FORMAT, remaining_data)
        # Add the strings to the table
        offset = storage_offset + record['offset']
        end = offset + record['length']
        # Remove any null chars from the string (they can have lots)
        record['string'] = data[offset:end].replace(b'\x00', b'')
        # Now make sure the string is unicode
        encoding = ENCODING_MAP[record['encoding']]
        try:
            record['string'] = record['string'].decode(encoding)
        except UnicodeDecodeError:
            # Sometimes the listed encoding is incorrect.  Fall back to latin-1
            # (which covers the most common non-ascii characters such as the
            # copyright symbol: \xa9)
            record['string'] = record['string'].decode('latin-1')
        name_records.append(record)
    return name_records

def woff_name_data(path):
    """
    Returns the 'name' table data from the .woff font file at the given *path*.

    .. note:: Only returns the English language stuff.
    """
    with open(path, 'rb') as f:
        table_data = unpack_table_data(f.read())
    if b'name' not in table_data:
        raise BadWoff("WOFF file is invalid")
    name_data = unpack_name_data(table_data[b'name'])
    name_dict = {}
    for record in name_data:
        if record['language'] == 0: # English
            name_id = record['name_id']
            del record['name_id'] # To reduce redundancy
            name_dict[name_id] = record
    if not name_dict:
        # Fallback to using the first language we find
        language = None
        for record in name_data:
            if not language:
                language = record['language']
            if record['language'] == language:
                name_id = record['name_id']
                del record['name_id'] # To reduce redundancy
                name_dict[name_id] = record
    return name_dict

@memoize
def woff_info(path):
    """
    Returns a dictionary containing the English-language name (string) data
    from the WOFF file at the given *path*.
    """
    name_dict = woff_name_data(path)
    human_name_dict = {}
    for name_id, record in name_dict.items():
        human_name = NAME_ID_MAP.get(name_id, 'Unknown Name ID: %s' % name_id)
        human_name_dict[human_name] = record['string']
    return human_name_dict

if __name__ == "__main__":
    import json
    if len(sys.argv) < 2:
        print("Usage: %s <woff file>" % sys.argv[0])
        sys.exit(1)
    path = sys.argv[1]
    try:
        print(json.dumps(woff_info(path), indent=4, sort_keys=True))
    except BadWoff as e:
        print("Could not decode name table (metadata) from %s" % path)
        sys.exit(1)

########NEW FILE########
__FILENAME__ = async
# -*- coding: utf-8 -*-
#
#       Copyright 2013 Liftoff Software Corporation
#
# For license information see LICENSE.txt

# Meta
__license__ = "AGPLv3 or Proprietary (see LICENSE.txt)"
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'

try:
    from concurrent import futures
except ImportError:
    print("ERROR: You're missing the concurrent.futures module.")
    print("To install it:")
    print('\tsudo pip install futures')
    import sys
    sys.exit(1)
import pickle, signal, os, logging
from functools import wraps
from datetime import datetime, timedelta
from itertools import count
from collections import Iterable
from functools import partial
from gateone.core.utils import AutoExpireDict, convert_to_timedelta
from tornado.ioloop import IOLoop
from tornado.ioloop import PeriodicCallback as PC

# Localization support
from gateone.core.locale import get_translation
_ = get_translation()

# A global to old memoized results (so multiple instances can share)
MEMO = {}
PID = os.getpid() # So we can tell if we're in the parent process or not
ONE_CALLS = {} # Tracks functions in progress for call_one()

def restart_executor(fn):
    """
    A decorator that ensures the executor is started inside the wrapped instance
    of `AsyncRunner`.
    """
    @wraps(fn)
    def wrapper(self, *args, **kwargs):
        if not self.running:
            self.run()
        self.restart_shutdown_timeout()
        return fn(self, *args, **kwargs)
    return wrapper

def safe_call(function, *args, **kwargs):
    """
    If we're not in the main process, sets the default signal handler
    (`signal.SIG_DFL`) for the ``SIGINT`` signal before calling *function*
    using the given *args* and *kwargs*.  Otherwise *function* will just be
    called and returned normally.

    The point being to prevent loads of unnecessary tracebacks from being
    printed to stdout when the user executes a :kbd:`Ctrl-C` on a running
    gateone.py process.

    ..  note::

        This function is only meant to be used to wrap calls made inside of
        `MultiprocessRunner` instances.
    """
    if os.getpid() != PID:
        signal.signal(signal.SIGINT, signal.SIG_DFL)
    return function(*args, **kwargs)

def done_callback(future, callback):
    """
    Adds the given *callback* via ``future.add_done_callback()`` or
    ``io_loop.add_done_callback()`` depending on whether or not the
    IOLoop is currently running.  This allows `AsyncRunner` instances to be
    debugged in an interactive interpreter without having to start up the
    IOLoop.
    """
    io_loop = IOLoop.current()
    if io_loop._running:
        io_loop.add_future(future, callback)
    else:
        future.add_done_callback(callback)

def append_results(results, function, *args, **kwargs):
    """
    Calls *function* with the given *args* and *kwargs* then appends the result
    to *results* (which must be a list).  If we're not in the main process the
    given *function* will be called using `safe_call`.
    """
    if os.getpid() != PID:
        results.append(safe_call(function, *args, **kwargs))
    else:
        results.append(function(*args, **kwargs))

def callback_when_complete(futures, callback):
    """
    Calls *callback* after all *futures* (list) have completed running.
    """
    counter = count(1)
    io_loop = IOLoop.current()
    results = []
    def add_one(f):
        c = counter.next()
        results.append(f.result())
        if c >= len(futures):
            return callback(results)
    for future in futures:
        io_loop.add_future(future, add_one)

def _cleanup_queue(identifier, future=None):
    """
    Deletes `ONE_CALLS[identifier]` if `ONE_CALLS[identifier]['queue']` is
    empty.
    """
    if identifier in ONE_CALLS:
        if not ONE_CALLS[identifier]['queue']:
            del ONE_CALLS[identifier]

def _call_complete(self, identifier, f=None):
    """
    Used by `AsyncRunner.call_one`; removes the given *identifier* from the
    global `ONE_CALLS` dict if there are no more calls remaining.  Otherwise
    the call count will be decremented by one.
    """
    if identifier in ONE_CALLS and ONE_CALLS[identifier]['queue']:
        if ONE_CALLS[identifier]['future'].done():
            # Submit the next function in the queue
            (function, args,
                kwargs, callback) = ONE_CALLS[identifier]['queue'].popleft()
            if not self.running: # Just in case (it happens, actually)
                self.run()
            self.restart_shutdown_timeout()
            future = self.executor.submit(safe_call, function, *args, **kwargs)
            ONE_CALLS[identifier]['future'] = future
            if callback:
                done_callback(future, lambda f: callback(f.result()))
            completed = partial(_cleanup_queue, identifier)
            done_callback(ONE_CALLS[identifier]['future'], completed)
            # Try again when complete
            call_again = partial(_call_complete, self, identifier)
            done_callback(ONE_CALLS[identifier]['future'], call_again)
    else:
        _cleanup_queue(identifier)

def _cache_result(future, args_string):
    """
    Saves *future.result()* in the `MEMO` dict using *args_string* as the key.
    """
    MEMO[args_string] = future.result()

class AsyncRunner(object):
    """
    A base class to execute functions in an asynchronous manner.  Caches results
    so that future calls to the same functions with the same arguments will
    be returned instantly.

    If no calls are made using the `AsyncRunner` instance after 30 seconds
    (default) it will shut down ``self.executor`` and clear the results
    (memoization) cache to save memory.  The executor will restarted
    automatically on-demand as needed.

    The length of time to wait before shutting down can be specified via the
    *timeout* keyword argument::

        >>> runner = AsyncRunner(timeout="2m")

    The *timeout* value may be specified as a `datetime.timedelta` object or
    a string such as, "2m" or "1h" (will be passed to
    :meth:`utils.convert_to_timedelta`)

    The interval in which the cache is checked for expiration can be controlled
    via the *interval* keyword argument::

        >>> runner = AsyncRunner(interval="30s") # This is the default

    Under most circumstances you won't want to bother changing it but if you do
    it takes the same format as *timeout*.
    """
    def __init__(self, **kwargs):
        self.io_loop = IOLoop.current()
        self.executor = None
        self.shutdown_timeout = None
        self.timeout = kwargs.pop('timeout', None)
        if not self.timeout:
            self.timeout = timedelta(seconds=30)
        if not isinstance(self.timeout, timedelta):
            self.timeout = convert_to_timedelta(self.timeout)
        self.interval = kwargs.pop('interval', None)
        if not self.interval:
            self.interval = "30s"
        global MEMO # Use a global so that instances can share the cache
        if not MEMO:
            MEMO = AutoExpireDict(timeout=self.timeout, interval=self.interval)

    def run(self):
        """
        This method must be overridden by subclasses of `AsyncRunner`.  It must
        start (or re-create) ``self.executor`` when called.
        """
        raise NotImplementedError

    @property
    def running(self):
        """
        This property must be overridden by subclasses of `AsyncRunner`.  It
        must return ``True`` if the executor is running, ``False`` if not.
        """
        raise NotImplementedError

    def shutdown(self, wait=False):
        """
        Calls :meth:`self.executor.shutdown(wait)` and removes and waiting
        timeouts.
        """
        if self.shutdown_timeout:
            self.io_loop.remove_timeout(self.shutdown_timeout)
        if self.running:
            logging.debug(_("Shutting down %s" % repr(self)))
            self.executor.shutdown(wait=wait)
        import gc
        gc.collect()

    def restart_shutdown_timeout(self):
        """
        Restarts the shutdown timeout that calls ``self.executor.shutdown()``.
        """
        if self.shutdown_timeout:
            self.io_loop.remove_timeout(self.shutdown_timeout)
        self.shutdown_timeout = self.io_loop.add_timeout(
            self.timeout, self.shutdown)

    def __del__(self):
        """
        Shuts down ``self.executor`` and clears the memoization cache.
        """
        global MEMO
        MEMO = {} # Enables garbage collection of the AutoExpireDict
        self.shutdown()

    @restart_executor
    def call(self, function, *args, **kwargs):
        """
        Executes *function* with *args* and *kwargs*.  Calls are automatically
        memoized and recalled from a cache unless ``memoize=False`` is passed as
        a keyword argument.

        If 'callback' is passed as a keyword argument (*kwargs*) it will be
        called with the result when complete.
        """
        string = ""
        callback = kwargs.pop('callback', None)
        memoize = kwargs.pop('memoize', True)
        if memoize:
            if hasattr(function, '__name__'):
                string = function.__name__
            string += pickle.dumps(args, 0) + pickle.dumps(kwargs, 0)
            if string in MEMO:
                f = futures.Future() # Emulate a completed Future()
                if callback:
                    f.set_result(callback(MEMO[string]))
                else:
                    f.set_result(MEMO[string])
                return f
        future = self.executor.submit(safe_call, function, *args, **kwargs)
        if callback:
            done_callback(future, lambda f: callback(f.result()))
        if memoize:
            done_callback(future, lambda f: _cache_result(f, string))
        return future

    @restart_executor
    def call_singleton(self, function, identifier, *args, **kwargs):
        """
        Executes *function* if no other function with the given *identifier*
        is already running.  If a function is currently running with the given
        *identifier* the passed *function* will be called when the first
        function is complete.

        In other words, functions called via this method will be executed in
        sequence with each function being called after the first is complete.

        The function will be passed any given *args* and *kwargs* just like
        :meth:`AsyncRunner.call`.

        If 'callback' is passed as a keyword argument (*kwargs*) it will be
        called with the result when complete.
        """
        callback = kwargs.pop('callback', None)
        if identifier in ONE_CALLS:
            ONE_CALLS[identifier]['queue'].append(
                (function, args, kwargs, callback))
        else:
            from collections import deque
            future = self.executor.submit(safe_call, function, *args, **kwargs)
            ONE_CALLS[identifier] = {
                'future': future,
                'queue': deque()
            }
            if callback:
                done_callback(
                    ONE_CALLS[identifier]['future'],
                    lambda f: callback(f.result()))
            completed = partial(_call_complete, self, identifier)
            done_callback(ONE_CALLS[identifier]['future'], completed)
        return ONE_CALLS[identifier]['future']

    @restart_executor
    def map(self, function, *iterables, **kwargs):
        """
        Calls *function* for every item in *iterables* then calls *callback* (
        if provided as a keyword argument via *kwargs*) with a list containing
        the results when complete.  The results list will be in the order in
        which *iterables* was passed to *function* (not random or based on how
        long they took to complete).

        Any additional *kwargs* will be passed to the *function* with each
        iteration of *iterables*.
        """
        callback = kwargs.pop('callback', None)
        futures = []
        for i in iterables:
            futures.append(self.executor.submit(
                safe_call, function, i, **kwargs))
        if callback:
            callback_when_complete(futures, callback)
        return futures

# The stuff below needs to be converted to use the new self-restarting executor
# style of AsyncRunner.  It's a work-in-progress (I know what to do--just not a
# priority at the moment since these functions aren't used yet).

    #@restart_executor
    #def argchain(self, functions, callback=None):
        #"""
        #Like `AsyncRunner.map` but will pass the result of each function
        #in *functions* as the argument to the next function in the chain.  Calls
        #*callback* when the chain of functions has completed executing.
        #Equivalent to::

            #func_list = [func1, func2, func3]
            #for func in func_list:
                #result = func1()
                #result = func2(result)
                #result = func3(result)
                ## ...and so on
            #return result

        #If a function returns a list or tuple that will be passed as the only
        #argument to the next function in the chain but if that fails with a
        #TypeError an attempt will be made at calling the next function by
        #passing the result as *args.  Equivalent to::

            #def foo(a, b):
                #return (a+1, b+1)

            #def bar(x, y):
                #return (x+10, b+10)

            #def baz(m, n):
                #return (m*10, n*10)

            #result = foo(1, 1) # First func is always executed without args
            #for func in (bar, baz):
                #result = bar(*result)
                #result = baz(*result)
            #return result

        #.. note::

            #Uses the `tornado.concurrent.run_on_executor` decorator to work in
            #a non-blocking fashion.
        #"""
        #result = None
        #for i, function in enumerate(functions):
            #if i == 0:
                #result = function()
            #else:
                #try:
                    #result = function(result)
                #except TypeError:
                    ## Try passing the result as args
                    #result = function(*result)
        #if callback:
            #callback(result)
        #return result

    #@restart_executor
    #def multicall(self, functions, callback=None, counter=count(start=1)):
        #"""
        #Calls every function in *functions* and calls *callback* when all
        #functions are complete.  The *functions* will be called in paralell
        #according to the *max_workers* parameter of this class.
        #"""
        #futures = []
        #results = []
        #def gather_results(f):
            #c = counter.__next__()
            #results.append(f.result())
            #if c == len(functions):
                #if callback:
                    #callback(results)
        #for function in functions:
            #future = self.executor.submit(function)
            #futures.append(future)
            #self.io_loop.add_future(future, gather_results)
        #return futures

class ThreadedRunner(AsyncRunner):
    """
    A class that can be used to execute functions in an asynchronous fashion
    using threads.  Useful for long-running functions that aren't CPU bound.
    """
    def __init__(self, max_workers=10, **kwargs):
        super(ThreadedRunner, self).__init__(**kwargs)
        self.max_workers = max_workers

    def run(self):
        logging.debug(
            _("Starting the ThreadedRunner executor with %s worker threads.")
            % self.max_workers)
        self.executor = futures.ThreadPoolExecutor(max_workers=self.max_workers)

    @property
    def running(self):
        if not self.executor:
            return False
        ibrunning = True
        if self.executor._shutdown:
            ibrunning = False
        return ibrunning

class MultiprocessRunner(AsyncRunner):
    """
    A class that can be used to execute functions in an asynchronous fashion
    using multiple processes.  Useful for long-running functions are mostly CPU
    bound or may use a lot of memory.

    .. warn:: Only works when all objects used by the function(s) are picklable!
    """
    # Enforce singleton on the executor since there's only so many cores
    executor_instance = None
    # Keep track of all our instances so we only shut down once:
    running_instances = set()

    # NOTE: Why is there no default for max_workers below?  Because if it is set
    # to `None` concurrent.futures.ProcessPoolExecutor will automatically use an
    # appropriate number of workers using multiprocessing.cpu_count().
    def __init__(self, max_workers=None, **kwargs):
        super(MultiprocessRunner, self).__init__(**kwargs)
        self.max_workers = max_workers

    def run(self):
        cls = MultiprocessRunner
        started = False
        if self not in cls.running_instances:
            cls.running_instances.add(self)
        if not cls.executor_instance:
            self.executor = futures.ProcessPoolExecutor(
                max_workers=self.max_workers)
            cls.executor_instance = self
            started = True
        elif not cls.executor_instance.running:
            cls.executor_instance.executor = futures.ProcessPoolExecutor(
                max_workers=self.max_workers)
            started = True
        self.executor = cls.executor_instance.executor
        if started:
            workers = self.executor._max_workers # Derived from cpu_count()
            logging.debug(
                _("Starting the MultiprocessRunner executor with %s worker "
                "processes.") % workers)

    @property
    def running(self):
        if not self.executor:
            return False
        ibrunning = True
        if self.executor._shutdown_thread:
            ibrunning = False
        return ibrunning

    def shutdown(self, wait=False):
        """
        An override of `AsyncRunner.shutdown` that is aware of the number of
        running instances so we don't shut down the executor while another
        instance is using it (Remember: This class enforces a singleton
        pattern--only one instance of the executor is allowed).

        .. note::

            The executor will only be shut down when this method is called for
            each instance of `MultiprocessRunner` that exists.
        """
        cls = MultiprocessRunner
        if not cls:
            return # Never got a chance to start; ignore
        if self.shutdown_timeout:
            self.io_loop.remove_timeout(self.shutdown_timeout)
        if self in cls.running_instances:
            cls.running_instances.remove(self)
        if not cls.running_instances:
            if self.running:
                logging.info(_(
                    "Shutting down the MultiprocessRunner executor."))
                self.executor.shutdown(wait=wait)
        import gc
        gc.collect()

class PeriodicCallback(object):
    """
    A wrapper that uses either `tornado.ioloop.PeriodicCallback` or
    `threading.Timer` to call functions at a specified interval depending on
    whether or not there's a running instance of `tornado.ioloop.IOLoop`.

    .. note::

        The purpose of this class is primarily for debugging things in an
        interactive Python interpreter.  It is expected that in production
        you will be using a running `~tornado.ioloop.IOLoop`.
    """
    def __init__(self, callback, callback_time, io_loop=None):
        self.callback = callback
        self.callback_time = callback_time
        self.io_loop = io_loop or IOLoop.current()
        if self.io_loop._running:
            # Use a regular PeriodicCallback
            self._pc = PC(callback, callback_time, io_loop)
        else:
            from threading import Timer
            # NOTE: PeriodicCallback uses ms while Timer uses seconds
            def callback_wrapper():
                "Runs the callback and restarts the Timer so it will run again"
                self.callback()
                self._pc = Timer(callback_time / 1000, callback_wrapper)
                if self._running:
                    self._pc.start()
            self._pc = Timer(callback_time / 1000, callback_wrapper)
        self._running = False

    def start(self):
        """Starts the timer."""
        self._running = True
        self._pc.start() # Timer() and PeriodicCallback() both use start()

    def stop(self):
        """Stops the timer."""
        self._running = False
        if isinstance(self._pc, PC): # PeriodicCallback()
            self._pc.stop()
        else: # Timer()
            self._pc.cancel()

class MatchAll(set):
    """Universal set - match everything"""
    def __contains__(self, item):
        return True

class Every(object):
    """
    A data structure that returns ``True`` in ``__contains__()`` checks if it's
    time for the schedule to run based on when it was created and it's interval
    attribute(s).  It is meant to be used with the `Scheduler` as an easy way
    to keep the code very simple.  Only `Schedule` or `Scheduler` instances
    would ever use it.  You use it like so::

        >>> every = Every(minutes=5)

    You can specify an `Every` object to begin at a specific time by providing a
    `datetime.datetime` object as the 'start' like so::

        >>> every = Every(minutes=5, start=datetime.datetime(2014, 3, 25, 12, 0, 0))

    This would result in the ``every`` object matching a ``__contains__`` check
    every five minutes starting on the 25th of March, 2014 at noon.

    How to use::

        >>> every = Every(minutes=5)
        >>> 1 in every
        False
        >>> # Wait five minutes
        >>> 1 in every # Doesn't matter what you check
        True
        >>> # ...and at that point the last_run time would reset
    """
    intervals = {
        'years': 31536000,
        'months': 2592000, # 30 days
        'days': 86400,
        'hours': 3600,
        'minutes': 60,
        'seconds': 1
    }
    def __init__(self, **kwargs):
        self.last_run = datetime.now()
        self.interval = None # Will be in seconds
        self.years = None
        self.months = None
        self.days = None
        self.hours = None
        self.minutes = None
        self.seconds = None
        # Set the given keyword arguments as attributes of this object
        for key, value in kwargs.items():
            if key in self.intervals:
                # Store the interval type for reference later (could be useful):
                setattr(self, key, value)
                # Set the actual interval in seconds:
                self.interval = self.intervals[key] * value
            elif key == 'start':
                if not isinstance(value, datetime):
                    raise TypeError(
                        "The 'start' keyword argument only accepts "
                        "datetime.datetime objects")
                self.last_run = value
            else:
                raise TypeError("Invalid keyword: %s" % key)

    def check(self):
        """
        Returns ``True`` if ``self.interval`` has passed.
        """
        return self.__contains__(1) # Could pass anything

    def __contains__(self, item):
        elapsed = datetime.now() - self.last_run
        if elapsed.total_seconds() > self.interval:
            self.last_run = datetime.now()
            return True
        return False

class Schedule(object):
    """
    A data structure to represent a scheduled task.
    """
    valid_attrs = [
        'years', 'months', 'days', 'hours', 'minutes', 'seconds', 'weekdays']
    def __init__(self, funcs, identifier, repeat=0, **kwargs):
        self.last_ran = None
        self.identifier = identifier
        self.repeat = repeat
        if not isinstance(funcs, list):
            funcs = [funcs] # Make it a list
        self.funcs = funcs
        if not kwargs:
            # Empty schedules are OK...  They will either run every time a check
            # is made or every n years, days, hours, etc when using every()
            for attr in self.valid_attrs:
                if not getattr(self, attr):
                    setattr(self, attr, MatchAll())
            return
        # Set the given keyword arguments as attributes of this object
        for key, value in kwargs.items():
            if key in self.valid_attrs:
                # Convert to set
                if isinstance(value, (int, long)):
                    value = set([value])  # Single item
                if isinstance(value, Iterable):
                    value = set([a for a in value])
                if key == 'weekdays':
                    if 0 in value:
                        # Sunday is the 7th day per datetime.now().isoweekday()
                        value.remove(0)
                        value.add(7)
                setattr(self, key, value)
            else:
                raise TypeError("Invalid keyword: %s" % key)
        # Use the MatchAll catch-all for any unspecified time attributes
        for attr in self.valid_attrs:
            if not getattr(self, attr):
                setattr(self, attr, MatchAll())

    def add_task(self, funcs):
        """
        Adds the given *funcs* to this schedule.
        """
        if not isinstance(funcs, list):
            funcs = [funcs] # Make it a list
        self.funcs.append(funcs)

    def every(self, **kwargs):
        """
        Sets the schedule of this `Schedule` object to run every *n* years,
        months, days, hours, minutes, or seconds depending on the given
        *kwargs*.  Example usage::

            scheduler.schedule(some_func, 'some_func').every(minutes=5)
            # NOTE: The above works because scheduler.schedule returns the
            # created Schedule instance.

        This kind of scheduling will be based on when the `Schedule` object is
        created rather than fixed times.
        """
        for key, value in kwargs.items():
            if key in self.valid_attrs:
                setattr(self, key, Every(**{key: value}))
            else:
                raise TypeError("Invalid keyword: %s" % key)
        return self

    def __call__(self):
        """
        Calls all the functions inside of ``self.funcs``.

        .. note:: This makes `Schedule` objects callable; e.g. 'sched()'
        """
        for func in self.funcs:
            func()
        self.last_ran = datetime.now()

    def __getattr__(self, key):
        """
        An override to make sure we return `None` for unset time-specific
        attributes (in case they weren't provided when the `Schedule` object
        was created).
        """
        if key in self.valid_attrs:
            try:
                return super(Schedule, self).__getattr__(key)
            except AttributeError:
                return None
        return super(Schedule, self).__getattr__(key)

class Scheduler(object):
    """
    A class that can be used to schedule tasks to run at specific days/times
    (like cron).  It creates a `PeriodicCallback` using the (optional)
    *interval* and calls each scheduled function if it's time has come.

    If no *runner* is provided, tasks executed by the scheduler will be run via
    an internal instance of `ThreadedRunner` which will default to using 10
    workers.
    """
    def __init__(self, interval='1s', io_loop=None, runner=None):
        if isinstance(interval, basestring):
            interval = convert_to_timedelta(interval)
            interval = interval.total_seconds() * 1000
        if not runner:
            runner = ThreadedRunner()
        self.runner = runner
        self._running = False
        self.interval = interval
        self.io_loop = io_loop or IOLoop.current()
        self._pc = PeriodicCallback(
            self._schedule_check, self.interval, io_loop)
        self._id_counter = count(start=1) # For generating unique IDs
        self._schedules = {}

    def schedule(self, funcs, identifier=None, **kwargs):
        """
        Schedules the given *funcs* to run at the times specified by the keyword
        arguments.  Returns a `Schedule` object that controls when things will
        be called.

        .. note::

            The *funcs* argument may be provided as an iterable or as a single
            function.

        Time-specific keyword arguments can be one or all of these:

            * years
            * months
            * days
            * weekdays
            * hours
            * minutes
            * seconds

        They can be specified as either a single integer or an iterable of
        integers.

        .. note::

            The *weekdays* keyword argument uses ISO standard weekday integers
            where 1 is Monday and 7 is Sunday.  A 0 may also be used to
            represent Sunday (which is not an ISO standard).

        Alternatively, the following (boolean) keyword arguments may be used to
        simplify scheduling tasks:

            * monthly
            * weekly
            * daily
            * hourly

        Tasks scheduled this way will be run on the hour that the specified time
        passes.  In other words, hourly would run at X:00, daily runs at 0:00,
        and monthly will run on the first day of the month at 0:00.  Weekly
        scheduled tasks will run every Sunday at midnight.

        .. note::

            If an *identifier* is not specified a unique ID will be generated.

        Example usage::

            >>> scheduler = Scheduler()
            >>> def myfunc(): print("Ran myfunc() at %s" % datetime.now())
            >>> # Run twice an hour at X:00:00 and X:30:00
            >>> sched_obj = scheduler.schedule(myfunc, minutes=set([0,30]))
            >>> # Run every day at midnight:
            >>> sched_obj = scheduler.schedule(myfunc, daily=True)

        For periodic calls (every N days, minutes, etc) you can use the
        :meth:`Schedule.every` method::

            >>> # Run every five minutes
            >>> sched_obj = scheduler.schedule(myfunc).every(minutes=5)

        .. note::

            When using ``every()`` you don't need to provide any keyword
            arguments to the ``schedule()`` method.
        """
        if not identifier:
            identifier = self._id_counter.next()
        # Convert the convenience keyword arguments to their datetime equivalent
        if 'monthly' in kwargs:
            kwargs.pop('monthly') # Remove it
            kwargs['days'] = 0    # Run on the first day of the month
            kwargs['hours'] = 0   # ...at midnight
            kwargs['minutes'] = 0 # ...on the hour
            kwargs['seconds'] = 0  # at this specific second
        if 'daily' in kwargs:
            kwargs.pop('daily')
            kwargs['hours'] = 0   # Run at midnight
            kwargs['minutes'] = 0 # ...on the hour
            kwargs['seconds'] = 0  # at this specific second
        if 'hourly' in kwargs:
            kwargs.pop('hourly')
            kwargs['minutes'] = 0  # Run every hour on the hour
            kwargs['seconds'] = 0  # at this specific second
        if 'weekly' in kwargs:
            kwargs.pop('weekly')
            kwargs['weekdays'] = 7 # Run every Sunday
            kwargs['hours'] = 0    # ...at midnight
            kwargs['minutes'] = 0  # ...on the hour
        sched = Schedule(funcs, identifier, **kwargs)
        self._schedules.update({identifier: sched})
        return sched

    def reschedule(self, identifier, **kwargs):
        """
        Reschedules the function associaated with the given *identifier* to run
        at the time specified by the keyword arguments.  If no keyword arguments
        are provided the scheduled function will be removed (unscheduled).
        """
        funcs = self._schedules[identifier].funcs
        del self._schedules[identifier]
        self.schedule(funcs, identifier, **kwargs)

    def unschedule(self, identifier):
        """
        Removes the function associated with the given *identifier* from
        ``self._schedules``.  Example usage::

            sched_obj = scheduler.schedule(myfunc, 'some_id', daily=True)
            # Now unschedule it:
            scheduler.unschedule('some_id')

        Alternatively you can use the auto-generated identifier assigned to the
        `Schedule` object::

            scheduler.unschedule(sched_obj.identifier)
        """
        del self._schedules[identifier]

    def remove(self, identifier):
        """
        An alias to `Scheduler.unschedule`.
        """
        self.unschedule(identifier)

    def add_task(self, funcs, identifier):
        """
        Adds the given *funcs* to the scheduled task associated with the given
        *identifier*.  *funcs* may be a single function or a list of functions.
        """
        self._schedules[identifier].add_task(funcs)

    def start(self):
        """Starts the scheduler."""
        logging.debug("Starting Scheduler")
        if not self._running:
            self._running = True
            self._pc.start() # Timer() and PeriodicCallback() both use start()

    def stop(self):
        """Stops the scheduler."""
        logging.debug("Stopping Scheduler")
        if self._running:
            self._running = False
            self._pc.stop()

    def _schedule_check(self):
        """
        Iterates over ``self._schedules`` and executes any scheduled tasks who's
        time has come.
        """
        now = datetime.now()
        for schedule in self._schedules.values():
            if ((now.second       in schedule.seconds) and
                (now.minute       in schedule.minutes) and
                (now.hour         in schedule.hours)   and
                (now.day          in schedule.days)    and
                (now.month        in schedule.months)  and
                (now.isoweekday() in schedule.weekdays)):
                self.runner.call(schedule) # Call the scheduled task(s)

########NEW FILE########
__FILENAME__ = authentication
# -*- coding: utf-8 -*-
#
#       Copyright 2013 Liftoff Software Corporation
#

# Meta
__license__ = "AGPLv3 or Proprietary (see LICENSE.txt)"
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'

__doc__ = """\
.. _auth.py:

Authentication
==============
This module contains Gate One's authentication classes.  They map to Gate One's
--auth configuration option like so:

=============== ===================
--auth=none     NullAuthHandler
--auth=kerberos KerberosAuthHandler
--auth=google   GoogleAuthHandler
--auth=pam      PAMAuthHandler
--auth=api      APIAuthHandler
=============== ===================

.. note:: API authentication is handled inside of :ref:`gateone.py`

None or Anonymous
-----------------
By default Gate One will not authenticate users.  This means that user sessions
will be tied to their browser cookie and users will not be able to resume their
sessions from another computer/browser.  Most useful for situations where
session persistence and logging aren't important.

*All* users will show up as ANONYMOUS using this authentication type.

Kerberos
--------
Kerberos authentication utilizes GSSAPI for Single Sign-on (SSO) but will fall
back to HTTP Basic authentication if GSSAPI auth fails.  This authentication
type can be integrated into any Kerberos infrastructure including Windows
Active Directory.

It is great for both transparent authentication and being able to tie sessions
and logs to specific users within your organization (compliance).

.. note::

    The sso.py module itself has extensive documentation on this authentication
    type.

Google Authentication
---------------------
If you want persistent user sessions but don't care to run your own
authentication infrastructure this authentication type is for you.  Assuming,
of course, that your Gate One server and clients will have access to the
Internet.

.. note::

    This authentication type is perfect if you're using Chromebooks (Chrome OS
    devices).

API Authentication
------------------
API-based authentication is actually handled in gateone.py but we still need
*something* to exist at the /auth URL that will always return the
'unauthenticated' response.  This ensures that no one can authenticate
themselves by visiting that URL manually.

Docstrings
==========
"""

# Import stdlib stuff
import os, re, logging
try:
    from urllib import quote
except ImportError: # Python 3
    from urllib.parse import quote

# Import our own stuff
from gateone.core.utils import mkdir_p, generate_session_id
from gateone.core.utils import convert_to_timedelta
from gateone.core.utils import total_seconds
from gateone.core.locale import get_translation
from gateone.core.log import go_logger

# 3rd party imports
import tornado.web
import tornado.auth
import tornado.escape
import tornado.httpclient

# Localization support
_ = get_translation()

# Globals
GATEONE_DIR = os.path.dirname(os.path.abspath(__file__))
SETTINGS_CACHE = {} # Lists of settings files and their modification times
# The security stuff below is a work-in-progress.  Likely to change all around.

auth_log = go_logger('gateone.auth')

# Helper functions
def additional_attributes(user, settings_dir=None):
    """
    Given a *user* dict, return a dict containing any additional attributes
    defined in Gate One's attribute repositories.

    .. note::

        This function doesn't actually work yet (support for attribute repos
        like LDAP is forthcoming).
    """
    # Doesn't do anything yet
    if not settings_dir:
        settings_dir = os.path.join(GATEONE_DIR, 'settings')
    return user


# Authentication classes
class BaseAuthHandler(tornado.web.RequestHandler):
    """The base class for all Gate One authentication handlers."""
    def set_default_headers(self):
        self.set_header('Server', 'GateOne')

    def get_current_user(self):
        """Tornado standard method--implemented our way."""
        expiration = self.settings.get('auth_timeout', "14d")
        # Need the expiration in days (which is a bit silly but whatever):
        expiration = (
            float(total_seconds(convert_to_timedelta(expiration)))
            / float(86400))
        user_json = self.get_secure_cookie(
            "gateone_user", max_age_days=expiration)
        if not user_json: return None
        user = tornado.escape.json_decode(user_json)
        # Add the IP attribute
        user['ip_address'] = self.request.remote_ip
        return user

    def user_login(self, user):
        """
        Called immediately after a user authenticates successfully.  Saves
        session information in the user's directory.  Expects *user* to be a
        dict containing a 'upn' value representing the username or
        userPrincipalName. e.g. 'user@REALM' or just 'someuser'.  Any additional
        values will be attached to the user object/cookie.
        """
        logging.debug("user_login(%s)" % user['upn'])
        user.update(additional_attributes(user))
        # Make a directory to store this user's settings/files/logs/etc
        try:
            user_dir = os.path.join(self.settings['user_dir'], user['upn'])
            if not os.path.exists(user_dir):
                logging.info(_("Creating user directory: %s" % user_dir))
                mkdir_p(user_dir)
                os.chmod(user_dir, 0o700)
        except UnicodeEncodeError:
            logging.error(_(
                "You're trying to use non-ASCII user information on a system "
                "that has the locale set to ASCII (or similar).  Please change"
                "your system's locale to something that supports Unicode "
                "characters. "))
            return
        session_file = os.path.join(user_dir, 'session')
        session_file_exists = os.path.exists(session_file)
        if session_file_exists:
            session_data = open(session_file).read()
            try:
                session_info = tornado.escape.json_decode(session_data)
            except ValueError: # Something wrong with the file
                session_file_exists = False # Overwrite it below
        if not session_file_exists:
            with open(session_file, 'w') as f:
                # Save it so we can keep track across multiple clients
                session_info = {
                    'session': generate_session_id(),
                }
                session_info.update(user)
                session_info_json = tornado.escape.json_encode(session_info)
                f.write(session_info_json)
        self.set_secure_cookie(
            "gateone_user", tornado.escape.json_encode(session_info))

    def user_logout(self, user, redirect=None):
        """
        Called immediately after a user logs out, cleans up the user's session
        information and optionally, redirects them to *redirect* (URL).
        """
        logging.debug("user_logout(%s)" % user)
        if not redirect:
            # Try getting it from the query string
            redirect = self.get_argument("redirect", None)
        if redirect:
            self.write(redirect)
            self.finish()
        else:
            self.write(self.settings['url_prefix'])
            self.finish()

class NullAuthHandler(BaseAuthHandler):
    """
    A handler for when no authentication method is chosen (i.e. --auth=none).
    With this handler all users will show up as "ANONYMOUS".
    """
    @tornado.web.asynchronous
    def get(self):
        """
        Sets the 'gateone_user' cookie with a new random session ID
        (*go_session*) and sets *go_upn* to 'ANONYMOUS'.
        """
        user = {'upn': 'ANONYMOUS'}
        check = self.get_argument("check", None)
        if check:
            # This lets any origin check if the user has been authenticated
            # (necessary to prevent "not allowed ..." XHR errors)
            self.set_header('Access-Control-Allow-Origin', '*')
            if not self.get_current_user():
                self.user_login(user)
            self.write('authenticated')
            self.finish()
            return
        logout = self.get_argument("logout", None)
        if logout:
            self.clear_cookie('gateone_user')
            self.user_logout(user['upn'])
            return
        # This takes care of the user's settings dir and their session info
        self.user_login(user)
        next_url = self.get_argument("next", None)
        if next_url:
            self.redirect(next_url)
        else:
            self.redirect(self.settings['url_prefix'])

    def user_login(self, user):
        """
        This is an override of BaseAuthHandler since anonymous auth is special.
        Generates a unique session ID for this user and saves it in a browser
        cookie.  This is to ensure that anonymous users can't access each
        other's sessions.
        """
        logging.debug("NullAuthHandler.user_login(%s)" % user['upn'])
        # Make a directory to store this user's settings/files/logs/etc
        user_dir = os.path.join(self.settings['user_dir'], user['upn'])
        if not os.path.exists(user_dir):
            logging.info(_("Creating user directory: %s" % user_dir))
            mkdir_p(user_dir)
            os.chmod(user_dir, 0o700)
        session_info = {
            'session': generate_session_id()
        }
        session_info.update(user)
        self.set_secure_cookie(
            "gateone_user", tornado.escape.json_encode(session_info))

class APIAuthHandler(BaseAuthHandler):
    """
    A handler that always reports 'unauthenticated' since API-based auth doesn't
    use auth handlers.
    """
    @tornado.web.asynchronous
    def get(self):
        """
        Deletes the 'gateone_user' cookie and handles some other situations for
        backwards compatibility.
        """
        # Get rid of the cookie no matter what (API auth doesn't use cookies)
        user = self.current_user
        self.clear_cookie('gateone_user')
        check = self.get_argument("check", None)
        if check:
            # This lets any origin check if the user has been authenticated
            # (necessary to prevent "not allowed ..." XHR errors)
            self.set_header('Access-Control-Allow-Origin', '*')
            logout = self.get_argument("logout", None)
            if logout:
                self.user_logout(user['upn'])
                return
        logging.debug('APIAuthHandler: user is NOT authenticated')
        self.write('unauthenticated')
        self.finish()

class GoogleAuthHandler(BaseAuthHandler, tornado.auth.GoogleMixin):
    """
    Google authentication handler using Tornado's built-in GoogleMixin (fairly
    boilerplate).
    """
    @tornado.web.asynchronous
    def get(self):
        """
        Sets the 'user' cookie with an appropriate *upn* and *session* and any
        other values that might be attached to the user object given to us by
        Google.
        """
        check = self.get_argument("check", None)
        if check:
            self.set_header ('Access-Control-Allow-Origin', '*')
            user = self.get_current_user()
            if user:
                logging.debug('GoogleAuthHandler: user is authenticated')
                self.write('authenticated')
            else:
                logging.debug('GoogleAuthHandler: user is NOT authenticated')
                self.write('unauthenticated')
            self.finish()
            return
        logout_url = "https://accounts.google.com/Logout"
        logout = self.get_argument("logout", None)
        if logout:
            user = self.get_current_user()['upn']
            self.clear_cookie('gateone_user')
            self.user_logout(user, logout_url)
            return
        if self.get_argument("openid.mode", None):
            self.get_authenticated_user(self._on_auth)
            return
        self.authenticate_redirect(
            ax_attrs=["name", "email", "language", "username"])

    def _on_auth(self, user):
        """
        Just a continuation of the get() method (the final step where it
        actually sets the cookie).
        """
        if not user:
            raise tornado.web.HTTPError(500, _("Google auth failed"))
        # NOTE: Google auth 'user' will be a dict like so:
        # user = {
        #     'locale': u'en-us',
        #     'first_name': u'Dan',
        #     'last_name': u'McDougall',
        #     'name': u'Dan McDougall',
        #     'email': u'daniel.mcdougall@liftoffsoftware.com'}
        user['upn'] = user['email'] # Use the email for the upn
        self.user_login(user)
        next_url = self.get_argument("next", None)
        if next_url:
            self.redirect(next_url)
        else:
            self.redirect(self.settings['url_prefix'])

class SSLAuthHandler(BaseAuthHandler):
    """
    SSL Certificate-based  authentication handler.  Can only be used if the
    ``ca_certs`` option is set along with ``ssl_auth=required`` or
    ``ssl_auth=optional``.
    """
    def initialize(self):
        """
        Print out helpful error messages if the requisite settings aren't
        configured.
        """
        self.require_setting("ca_certs", "CA Certificates File")
        self.require_setting("ssl_auth", "SSL Authentication ('required')")

    def _convert_certificate(self, cert):
        """
        Converts the certificate format returned by get_ssl_certificate() into
        a format more suitable for a user dict.
        """
        import re
        # Can't have any of these in the upn because we name a directory with it
        bad_chars = re.compile(r'[\/\\\$\;&`\!\*\?\|<>\n]')
        user = {'notAfter': cert['notAfter']} # This one is the most direct
        for item in cert['subject']:
            for key, value in item:
                user.update({key: value})
        cn = user['commonName'] # Use the commonName as the UPN
        cn = bad_chars.sub('.', cn) # Replace bad chars with dots
        # Try to use the 'issuer' to add more depth to the CN
        if 'issuer' in cert: # This will only be there if you're using Python 3
            for item in cert['issuer']:
                for key, value in item:
                    if key == 'organizationName':
                        # Yeah this can get long but that's OK (it's better than
                        # conflicts)
                        cn = "%s@%s" % (cn, value)
                        break
                        # Should wind up as something like this:
                        #   John William Smith-Doe@ACME Widget Corporation, LLC
                        # So that would be used in the users dir like so:
                        #   /opt/gateone/users/John William Smith-Doe... etc
        user['upn'] = cn
        return user

    @tornado.web.asynchronous
    def get(self):
        """
        Sets the 'user' cookie with an appropriate *upn* and *session* and any
        other values that might be attached to the user's client SSL
        certificate.
        """
        check = self.get_argument("check", None)
        if check:
            self.set_header ('Access-Control-Allow-Origin', '*')
            user = self.get_current_user()
            if user:
                logging.debug('SSLAuthHandler: user is authenticated')
                self.write('authenticated')
            else:
                logging.debug('SSLAuthHandler: user is NOT authenticated')
                self.write('unauthenticated')
            self.finish()
            return
        logout = self.get_argument("logout", None)
        if logout:
            user = self.get_current_user()['upn']
            self.clear_cookie('gateone_user')
            self.user_logout(user)
            return
        # Extract the user's information from their certificate
        cert = self.request.get_ssl_certificate()
        bincert = self.request.get_ssl_certificate(binary_form=True)
        open('/tmp/cert.der', 'w').write(bincert)
        user = self._convert_certificate(cert)
        # This takes care of the user's settings dir and their session info
        self.user_login(user)
        next_url = self.get_argument("next", None)
        if next_url:
            self.redirect(next_url)
        else:
            self.redirect(self.settings['url_prefix'])

# Add our KerberosAuthHandler if sso is available
KerberosAuthHandler = None
try:
    from gateone.auth.sso import KerberosAuthMixin
    class KerberosAuthHandler(BaseAuthHandler, KerberosAuthMixin):
        """
        Handles authenticating users via Kerberos/GSSAPI/SSO.
        """
        @tornado.web.asynchronous
        def get(self):
            """
            Checks the user's request header for the proper Authorization data.
            If it checks out the user will be logged in via _on_auth().  If not,
            the browser will be redirected to login.
            """
            check = self.get_argument("check", None)
            self.set_header('Access-Control-Allow-Origin', '*')
            if check:
                user = self.get_current_user()
                if user:
                    logging.debug('KerberosAuthHandler: user is authenticated')
                    self.write('authenticated')
                else:
                    logging.debug('KerberosAuthHandler: user is NOT authenticated')
                    self.write('unauthenticated')
                self.finish()
                return
            logout = self.get_argument("logout", None)
            if logout:
                user = self.get_current_user()
                self.clear_cookie('gateone_user')
                self.user_logout(user)
                return
            auth_header = self.request.headers.get('Authorization')
            if auth_header:
                self.get_authenticated_user(self._on_auth)
                return
            self.authenticate_redirect()

        def _on_auth(self, user):
            if not user:
                raise tornado.web.HTTPError(500, _("Kerberos auth failed"))
            logging.debug(_("KerberosAuthHandler user: %s" % user))
            user = {'upn': user}
            # This takes care of the user's settings dir and their session info
            self.user_login(user)
            # TODO: Add some LDAP or local DB lookups here to add more detail to user objects
            next_url = self.get_argument("next", None)
            if next_url:
                self.redirect(next_url)
            else:
                self.redirect(self.settings['url_prefix'])
except ImportError:
    pass # No SSO available.

# Add our PAMAuthHandler if it's available
PAMAuthHandler = None
try:
    from gateone.auth.pam import PAMAuthMixin
    class PAMAuthHandler(BaseAuthHandler, PAMAuthMixin):
        """
        Handles authenticating users via PAM.
        """
        @tornado.web.asynchronous
        def get(self):
            """
            Checks the user's request header for the proper Authorization data.
            If it checks out the user will be logged in via _on_auth().  If not,
            the browser will be redirected to login.
            """
            check = self.get_argument("check", None)
            self.set_header('Access-Control-Allow-Origin', '*')
            if check:
                user = self.get_current_user()
                if user:
                    logging.debug('PAMAuthHandler: user is authenticated')
                    self.write('authenticated')
                else:
                    logging.debug('PAMAuthHandler: user is NOT authenticated')
                    self.write('unauthenticated')
                    self.get_authenticated_user(self._on_auth)
                self.finish()
                return
            logout = self.get_argument("logout", None)
            if logout:
                user = self.get_current_user()
                self.clear_cookie('gateone_user')
                self.user_logout(user)
                return
            auth_header = self.request.headers.get('Authorization')
            if auth_header:
                self.get_authenticated_user(self._on_auth)
                return
            self.authenticate_redirect()

        def _on_auth(self, user):
            if not user:
                raise tornado.web.HTTPError(500, _("PAM auth failed"))
            user = {'upn': user}
            # This takes care of the user's settings dir and their session info
            self.user_login(user)
            logging.debug(_("PAMAuthHandler user: %s" % user))
            next_url = self.get_argument("next", None)
            if next_url:
                self.redirect(next_url)
            else:
                self.redirect(self.settings['url_prefix'])
except ImportError:
    pass # No PAM auth available.

class CASAuthHandler(BaseAuthHandler):
    """
    CAS authentication handler.
    """
    cas_user_regex = re.compile(r'<cas:user>(.*)</cas:user>')
    def initialize(self):
        """
        Print out helpful error messages if the requisite settings aren't
        configured.

        NOTE: It won't hurt anything to override this method in your
        RequestHandler.
        """
        self.require_setting("cas_server", _("CAS Server URL"))
        # The cas_version is optional

    @tornado.web.asynchronous
    def get(self):
        """
        Sets the 'user' cookie with an appropriate *upn* and *session* and any
        other values that might be attached to the user object given to us by
        Google.
        """
        self.base_url = "{protocol}://{host}:{port}{url_prefix}".format(
            protocol=self.request.protocol,
            host=self.request.host,
            port=self.settings['port'],
            url_prefix=self.settings['url_prefix'])
        check = self.get_argument("check", None)
        if check:
            self.set_header ('Access-Control-Allow-Origin', '*')
            user = self.get_current_user()
            if user:
                logging.debug('CASAuthHandler: user is authenticated')
                self.write('authenticated')
            else:
                logging.debug('CASAuthHandler: user is NOT authenticated')
                self.write('unauthenticated')
            self.finish()
            return
        logout_url = "%s/logout" % self.settings.get('cas_server')
        logout = self.get_argument("logout", None)
        if logout:
            user = self.get_current_user()['upn']
            self.clear_cookie('gateone_user')
            self.user_logout(user, logout_url)
            return
        server_ticket = self.get_argument('ticket', None)
        if server_ticket:
            return self.get_authenticated_user(server_ticket)
        return self.authenticate_redirect()

    def authenticate_redirect(self, callback=None):
        """
        Redirects to the authentication URL for this CAS service.

        After authentication, the service will redirect back to the given
        callback URI with additional parameters.

        We request the given attributes for the authenticated user by
        default (name, email, language, and username). If you don't need
        all those attributes for your app, you can request fewer with
        the ax_attrs keyword argument.
        """
        cas_server = self.settings.get('cas_server')
        if not cas_server.endswith('/'):
            cas_server += '/'
        service_url = "%sauth" % self.base_url
        redirect_url = '%slogin?service=%s' % (cas_server, quote(service_url))
        logging.debug("Redirecting to CAS URL: %s" % redirect_url)
        self.redirect(redirect_url)
        if callback:
            callback()

    def get_authenticated_user(self, server_ticket):
        """
        Requests the user's information from the CAS server using the given
        *server_ticket* and calls ``self._on_auth`` with the resulting user
        dict.
        """
        cas_version = self.settings.get('cas_version', 2)
        cas_server = self.settings.get('cas_server')
        ca_certs = self.settings.get('cas_ca_certs', None)
        if not cas_server.endswith('/'):
            cas_server += '/'
        service_url = "%sauth" % self.base_url
        #validate the ST
        validate_suffix = 'proxyValidate'
        if cas_version == 1:
            validate_suffix = 'validate'
        validate_url = (
            cas_server +
            validate_suffix +
            '?service=' +
            quote(service_url) +
            '&ticket=' +
            quote(server_ticket)
        )
        logging.debug("Fetching CAS URL: %s" % validate_url)
        validate_cert = False
        if ca_certs:
            validate_cert = True
        http_client = tornado.httpclient.AsyncHTTPClient()
        http_client.fetch(
            validate_url, validate_cert=validate_cert, callback=self._on_auth)

    def _on_auth(self, response):
        """
        Just a continuation of the get() method (the final step where it
        actually sets the cookie).
        """
        userid = None
        match = self.cas_user_regex.search(response.body)
        if match:
            userid = match.groups()[0]
        if not userid:
            raise tornado.web.HTTPError(500, _("CAS authentication failed"))
        # NOTE: Do we ever get anything more than the userid from a CAS server?
        # Needs more research and probably proper XML parsing...
        user = {'upn': userid}
        self.user_login(user)
        next_url = self.get_argument("next", None)
        if next_url:
            self.redirect(next_url)
        else:
            self.redirect(self.settings['url_prefix'])

########NEW FILE########
__FILENAME__ = authorization
# -*- coding: utf-8 -*-
#
#       Copyright 2013 Liftoff Software Corporation
#

# Meta
__license__ = "AGPLv3 or Proprietary (see LICENSE.txt)"
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'

__doc__ = """\
.. _authorization.py:

Authorization
==============
This module contains Gate One's authorization helpers.

Docstrings
==========
"""

# Import stdlib stuff
import os, logging, re

# Import our own stuff
from gateone.core.utils import noop
from gateone.core.utils import memoize
from gateone.core.configuration import RUDict
from gateone.core.locale import get_translation
from gateone.core.log import go_logger

# Localization support
_ = get_translation()

# Globals
GATEONE_DIR = os.path.dirname(os.path.abspath(__file__))

auth_log = go_logger('gateone.auth')

# Authorization stuff
@memoize
def applicable_policies(application, user, policies):
    """
    Given an *application* and a *user* object, returns the merged/resolved
    policies from the given *policies* :class:`RUDict`.

    .. note:: Policy settings always start with '*', 'user', or 'group'.
    """
    # Start with the default policy
    try:
        policy = RUDict(policies['*'][application].copy())
    except KeyError:
        # No default policy--not good but not mandatory
        policy = RUDict()
    for key, value in policies.items():
        if key == '*':
            continue # Default policy was already handled
        if application not in value:
            continue # No sense processing inapplicable stuff
        # Handle users and their properties first
        if key.startswith('user=') or key.startswith('user.upn='):
            # UPNs are very straightforward
            upn = key.split('=', 1)[1]
            if re.match(upn, user['upn']):
                policy.update(value[application])
        elif key.startswith('user.'):
            # An attribute check (e.g. 'user.ip_address=10.1.1.1')
            attribute = key.split('.', 1)[1] # Get rid of the 'user.' part
            attribute, must_match = attribute.split('=', 1)
            if attribute in user:
                if re.match(must_match, user[attribute]):
                    policy.update(value[application])
        # TODO: Group stuff here (need attribute repo stuff first)
    return policy

class require(object):
    """
    A decorator to add authorization requirements to any given function or
    method using condition classes. Condition classes are classes with check()
    methods that return True if the condition is met.

    Example of using @require with is_user()::

        @require(is_user('administrator'))
        def admin_index(self):
            return 'Hello, Administrator!'

    This would only allow the user, 'administrator' access to the index page.
    In this example the *condition* is the `is_user` function which checks that
    the logged-in user's username (aka UPN) is 'administrator'.
    """
    def __init__(self, *conditions):
        self.conditions = conditions

    def __call__(self, f):
        conditions = self.conditions
        # The following only gets run when the wrapped method is called
        def wrapped_f(self, *args, **kwargs):
            # Now check the conditions
            for condition in conditions:
                # Conditions don't have access to self directly so we use the
                # 'self' associated with the user's open connection to update
                # the condition's 'instance' attribute
                condition.instance = self
                # This lets the condition know what it is being applied to:
                condition.function = f
                condition.f_args = args
                condition.f_kwargs = kwargs
                if not condition.check():
                    if hasattr(self, 'current_user') and self.current_user:
                        if 'upn' in self.current_user:
                            auth_log.error(_(
                                '{"ip_address": "%s"} %s -> %s '
                                'failed requirement: %s' % (
                                self.request.remote_ip,
                                self.current_user['upn'],
                                f.__name__, str(condition))))
                    else:
                        auth_log.error(_(
                            '{"ip_address": "%s"} unknown user -> %s '
                            'failed requirement: %s' % (
                            self.request.remote_ip, f.__name__, str(condition))
                        ))
                    # Try to notify the client of their failings
                    msg = _("ERROR: %s" % condition.error)
                    try:
                        if hasattr(self, 'send_message'):
                            self.send_message(msg)
                        elif hasattr(self, 'ws'): # Inside an app, use ws
                            self.ws.send_message(msg)
                    except AttributeError:
                        # This can happen if the client disconnects in the
                        # middle of this operation.  Ignore.
                        pass
                    return noop
            return f(self, *args, **kwargs)
        return wrapped_f

class authenticated(object):
    """
    A condition class to be used with the @require decorator that returns True
    if the user is authenticated.

    .. note::

        Only meant to be used with WebSockets.  `tornado.web.RequestHandler`
        instances can use `@tornado.web.authenticated`
    """
    error = _("Only valid users may access this function")
    def __str__(self):
        return "authenticated"

    def __init__(self):
        # These are just here as reminders that (they will be set when called)
        self.instance = None
        self.function = None
        self.f_args = None
        self.f_kwargs = None

    def check(self):
        if not self.instance.current_user:
            return False
        return True

class is_user(object):
    """
    A condition class to be used with the @require decorator that returns True
    if the given username/UPN matches what's in `self._current_user`.
    """
    error = _("You are not authorized to perform this action")
    def __str__(self):
        return "is_user: %s" % self.upn

    def __init__(self, upn): # NOTE: upn is the username (aka userPrincipalName)
        self.upn = upn
        self.instance = None
        self.function = None
        self.f_args = None
        self.f_kwargs = None

    def check(self):
        user = self.instance.current_user
        if user and 'upn' in user:
            logging.debug("Checking if %s == %s" % (user['upn'], self.upn))
            return self.upn == user['upn']
        else:
            return False

class policies(object):
    """
    A condition class to be used with the @require decorator that returns True
    if all the given conditions are within the limits specified in Gate One's
    settings (e.g. 50limits.conf).  Here's an example::

        @require(authenticated(), policies('terminal'))
        def new_terminal(self, settings):
            # Actual function would be here
            pass

    That would apply all policies that are configured for the 'terminal'
    application.  It works like this:

    The :class:`~app_terminal.TerminalApplication` application registers its
    name and policy-checking function inside of
    :meth:`~app_terminal.TerminalApplication.initialize` like so::

        self.ws.security.update({'terminal': terminal_policies})

    Whenever a function decorated with ``@require(policies('terminal'))`` is
    called the registered policy-checking function (e.g.
    :func:`app_terminal.terminal_policies`) will be called, passing the current
    instance of :class:`policies` as the only argument.

    It is then up to the policy-checking function to make a determination as to
    whether or not the user is allowed to execute the decorated function and
    must return `True` if allowed.  Also note that the policy-checking function
    will be able to make modifications to the function and its arguments if the
    security policies warrant it.

    .. note::

        If you write your own policy-checking function (like
        :func:`terminal_policies`) it is often a good idea to send a
        notification to the user indicating why they've been denied.  You can
        do this with the :meth:`instance.send_message` method.
    """
    # NOTE:  In the future if we wish to use this function with Gate One itself
    # (as opposed to just a GOApplication) the 'app' will need to be 'gateone'.
    error = _("Your ability to perform this action has been restricted")
    def __str__(self):
        return "policies: %s" % self.app

    def __init__(self, app):
        self.app = app
        self.instance = None
        self.function = None
        self.f_args = None
        self.f_kwargs = None

    def check(self):
        security = self.instance.security
        if self.app in security:
            # Let the application's registered 'security' function make its own
            # determination.
            return security[self.app](self)
        return True # Nothing is registered for this application so it's OK

########NEW FILE########
__FILENAME__ = ctypes_pam
# -*- coding: utf-8 -*-
# Original version (pam-0.1.3) 2007 Chris AtLee <chris@atlee.ca>
# This version (modifications)  2013 Liftoff Software Corporation
# Licensed under the MIT license:
#   http://www.opensource.org/licenses/mit-license.php
# This is a modified version of pam-0.1.3 that adds support for
# pam_set_item (specificallly, to support setting a PAM_TTY)

# Meta
__license__ = "MIT"
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'

__doc__ = """\
.. _gopam.py:

PAM Authentication Module for Python
====================================
Provides an authenticate function that will allow the caller to authenticate
a user against the Pluggable Authentication Modules (PAM) on the system.

Implemented using ctypes, so no compilation is necessary.
"""

__all__ = ['authenticate']

from ctypes import CDLL, POINTER, Structure, CFUNCTYPE, cast, pointer, sizeof
from ctypes import c_void_p, c_uint, c_char_p, c_char, c_int
from ctypes.util import find_library

LIBPAM = CDLL(find_library("pam"))
LIBC = CDLL(find_library("c"))

CALLOC = LIBC.calloc
CALLOC.restype = c_void_p
CALLOC.argtypes = [c_uint, c_uint]

STRDUP = LIBC.strdup
STRDUP.argstypes = [c_char_p]
STRDUP.restype = POINTER(c_char) # NOT c_char_p !!!!

# Various constants
PAM_PROMPT_ECHO_OFF = 1
PAM_PROMPT_ECHO_ON = 2
PAM_ERROR_MSG = 3
PAM_TEXT_INFO = 4
# pam_set_item and pam_get_item constants:
PAM_SERVICE =       1    # The service name
PAM_USER =          2    # The user name
PAM_TTY =           3    # The tty name
PAM_RHOST =         4    # The remote host name
PAM_CONV =          5    # The pam_conv structure
PAM_AUTHTOK =       6    # The authentication token (password)
PAM_OLDAUTHTOK =    7    # The old authentication token
PAM_RUSER =         8    # The remote user name
PAM_USER_PROMPT =   9    # the prompt for getting a username
# These are Linux-specific pam_set_item/pam_get_item constants:
PAM_FAIL_DELAY =   10    # app supplied function to override failure
PAM_XDISPLAY =     11    # X display name
PAM_XAUTHDATA =    12    # X server authentication data
PAM_AUTHTOK_TYPE = 13    # The type for pam_get_authtok

class PamHandle(Structure):
    """wrapper class for pam_handle_t"""
    _fields_ = [("handle", c_void_p)]

    def __init__(self):
        Structure.__init__(self)
        self.handle = 0

class PamMessage(Structure):
    """wrapper class for pam_message structure"""
    _fields_ = [("msg_style", c_int), ("msg", c_char_p)]

    def __repr__(self):
        return "<PamMessage %i '%s'>" % (self.msg_style, self.msg)

class PamResponse(Structure):
    """wrapper class for pam_response structure"""
    _fields_ = [("resp", c_char_p), ("resp_retcode", c_int)]

    def __repr__(self):
        return "<PamResponse %i '%s'>" % (self.resp_retcode, self.resp)

CONV_FUNC = CFUNCTYPE(
    c_int,
    c_int,
    POINTER(POINTER(PamMessage)),
    POINTER(POINTER(PamResponse)),
    c_void_p)

class PamConv(Structure):
    """wrapper class for pam_conv structure"""
    _fields_ = [("conv", CONV_FUNC), ("appdata_ptr", c_void_p)]

PAM_START = LIBPAM.pam_start
PAM_START.restype = c_int
PAM_START.argtypes = [c_char_p, c_char_p, POINTER(PamConv), POINTER(PamHandle)]

PAM_AUTHENTICATE = LIBPAM.pam_authenticate
PAM_AUTHENTICATE.restype = c_int
PAM_AUTHENTICATE.argtypes = [PamHandle, c_int]

PAM_SET_ITEM = LIBPAM.pam_set_item
PAM_SET_ITEM.restype = c_int
PAM_SET_ITEM.argtypes = [PamHandle, c_int, c_char_p]

def authenticate(username, password, service='login', tty="console", **kwargs):
    """
    Returns True if the given username and password authenticate for the
    given service.  Returns False otherwise.

    :param string username: The username to authenticate.
    :param string password: The password in plain text.
    :param string service:

        The PAM service to authenticate against.  Defaults to 'login'.

    :param string tty:

        Name of the TTY device to use when authenticating.  Defaults to
        'console' (to allow root).

    If additional keyword arguments are provided they will be passed to
    PAM_SET_ITEM() like so::

        PAM_SET_ITEM(handle, <keyword mapped to PAM_whatever>, <value>)

    Where the keyword will be automatically converted to a PAM_whatever constant
    if present in this file.  Example::

        authenticate(user, pass, PAM_RHOST="myhost")

    ...would result in::

        PAM_SET_ITEM(handle, 4, "myhost") # PAM_RHOST (4) taken from the global
    """
    encoding = 'utf-8'
    if not isinstance(password, bytes):
        password = password.encode(encoding)
    if not isinstance(username, bytes):
        username = username.encode(encoding)
    if not isinstance(service, bytes):
        service = service.encode(encoding)
    if not isinstance(tty, bytes):
        tty = tty.encode(encoding)
    @CONV_FUNC
    def my_conv(n_messages, messages, p_response, app_data):
        """
        Simple conversation function that responds to any prompt where the echo
        is off with the supplied password.
        """
        # Create an array of n_messages response objects
        addr = CALLOC(n_messages, sizeof(PamResponse))
        p_response[0] = cast(addr, POINTER(PamResponse))
        for i in range(n_messages):
            if messages[i].contents.msg_style == PAM_PROMPT_ECHO_OFF:
                pw_copy = STRDUP(password)
                p_response.contents[i].resp = cast(pw_copy, c_char_p)
                p_response.contents[i].resp_retcode = 0
        return 0
    handle = PamHandle()
    conv = PamConv(my_conv, 0)
    retval = PAM_START(service, username, pointer(conv), pointer(handle))
    PAM_SET_ITEM(handle, PAM_TTY, tty)
    for key, value in kwargs.items():
        if key.startswith('PAM_') and key in globals():
            if isinstance(value, str):
                value = value.encode(encoding)
            PAM_SET_ITEM(handle, globals()[key], value)
    if retval != 0:
        # TODO: This is not an authentication error, something
        # has gone wrong starting up PAM
        return False
    retval = PAM_AUTHENTICATE(handle, 0)
    return retval == 0

def pam_service_exists(service):
    """
    Returns ``True`` if the given *service* can be found in the system's PAM
    configuration.
    """
    if os.path.isdir('/etc/pam.d'):
        # Modern PAM implementation.  Services are named after files.
        if service in os.listdir('/etc/pam.d/'):
            return True
    else:
        # Old-school PAM implementation (Solaris, AIX, etc).
        services = [] # He's making a list, and checkin' it twice.
        for line in open('/etc/pam.conf'):
            if line.startswith('#'): # It's a comment
                continue
            _service = line.split()[0]
            if _service not in services:
                services.append(_service)
        if service in services:
            return True
    return False

if __name__ == "__main__":
    # Do a little test.  Make a little love.  Get down tonight!
    import os, sys, getpass
    print("\x1b[1mTesting PAM authentication\x1b[0m")
    if os.getuid() != 0:
        print( # Print in bold/yellow
            "\x1b[1;33mWarning: You're not root.  This means you'll only be "
            "able to test authenticating your own user ({0}).\x1b[0m"
            .format(getpass.getuser()))
    service = raw_input("PAM Service [login]: ")
    if not service:
        service = 'login'
    if not pam_service_exists(service):
        print(
            "\x1b[1;33mWarning: The given service, '{0}' could not be found in "
            "this system's PAM configuration.  This means the 'other' service "
            "will be used.\x1b[0m".format(service))
    getting_user = True
    while getting_user:
        user = raw_input("Username [{0}]: ".format(getpass.getuser()))
        getting_user = False
        if not user:
            user = getpass.getuser()
        if os.getuid() != 0 and user != getpass.getuser():
            getting_user = True
            print(
                "ERROR: I told you that you can only authenticate as yourself "
                "(since you're not root).")
            print(
                "Try again but this time just hit the enter key or actually "
                "type out your own username.")
    password = getpass.getpass()
    try:
        result = authenticate(user, password)
        if result:
            print("SUCCESS:  PAM authentication definitely works.")
        else:
            print(
                "FAIL:  Authentication failed.  Did you enter your password "
                "correctly?")
            print(
                "If this keeps happening you either need some caffeine or you "
                "need to check the system logs to see why the authentication "
                "is failing.")
    except Exception as e:
        print("EPIC FAIL:  Something horrible went wrong.  Exception message:")
        print(e)
        print("Here's the traceback:")
        import traceback
        traceback.print_exc(file=sys.stdout)

########NEW FILE########
__FILENAME__ = pam
# -*- coding: utf-8 -*-
#
#       Copyright 2013 Liftoff Software Corporation
#
#   Thanks to Alan Schmitz for contributing the original version of this module!

# Meta
__license__ = "AGPLv3 or Proprietary (see LICENSE.txt)"
__doc__ = """
.. _pam.py:

PAM Authentication Module for Gate One
======================================

This authentication module is built on top of :ref:`ctypes-pam` which is
included with Gate One.

It was originally written by Alan Schmitz (but has changed quite a bit).

The only non-obvious aspect of this module is that the pam_realm setting is only
used when the user is asked to authenticate and when the user's information is
stored in the 'users' directory.  It isn't actually used in any part of the
authentication (PAM doesn't take a "realm" setting).
"""

# Standard library modules
import base64, logging

# Our modules
try:
    from .ctypes_pam import authenticate
except Exception as e:
    raise ImportError(
        "Failed to import ctypes_pam module. PAM auth support will be disabled."
        "  Exception: %s" % e)

# 3rd party modules
import tornado.httpserver
import tornado.ioloop
import tornado.web


class PAMAuthMixin(tornado.web.RequestHandler):
    """
    This is used by `PAMAuthHandler` in :ref:`auth.py` to authenticate users via
    PAM.
    """
    def initialize(self):
        """
        Print out helpful error messages if the requisite settings aren't
        configured.
        """
        self.require_setting("pam_realm", "PAM Realm")
        self.require_setting("pam_service", "PAM Service")

    def get_authenticated_user(self, callback):
        """
        Processes the client's Authorization header and call
        ``self.auth_basic()``
        """
        auth_header = self.request.headers.get('Authorization')
        if auth_header and auth_header.startswith('Basic '):
            self.auth_basic(auth_header, callback)

    def auth_basic(self, auth_header, callback):
        """
        Perform Basic authentication using ``self.settings['pam_realm']``.
        """
        auth_decoded = base64.decodestring(auth_header[6:].encode('ascii'))
        username, password = auth_decoded.decode('utf-8').split(':', 1)
        try:
            result = authenticate(
                username,
                password,
                service=self.settings['pam_service'],
                tty=b"console",
                PAM_RHOST=self.request.remote_ip) # RHOST so it shows up in logs
            if not result:
                return self.authenticate_redirect()
        except Exception as e: # Basic auth failed
            if self.settings['debug']:
                logging.debug(e)
            return self.authenticate_redirect()
        # NOTE: Basic auth just gives us the username without the @REALM part
        #       so we have to add it:
        user = "%s@%s" % (username, self.settings['pam_realm'])
        callback(user)

    def authenticate_redirect(self):
        """
        Informs the browser that this resource requires authentication (status
        code 401) which should prompt the browser to reply with credentials.

        The browser will be informed that we support Basic auth.
        """
        if self._headers_written:
            raise Exception('Headers have already been written')
        self.set_status(401)
        self.add_header(
            "WWW-Authenticate",
            'Basic realm="%s"' % self.settings['pam_realm']
        )
        self.finish()
        return False

########NEW FILE########
__FILENAME__ = sso
# -*- coding: utf-8 -*-
#
#       Copyright 2013 Liftoff Software Corporation
#

# Meta
__license__ = "AGPLv3 or Proprietary (see LICENSE.txt)"
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'

__doc__ = """\
.. _sso.py:

About The SSO Module
====================
sso.py is a Tornado Single Sign-On (SSO) authentication module that implements
GSSAPI authentication via python-kerberos (import kerberos).  If "Negotiate"
authentication (GSSAPI SSO) fails it will gracefully fall back to "Basic" auth
(authenticating a given username/password against your Kerberos realm).

For this module to work you must add 'sso_realm' and 'sso_service' to your
Tornado application's settings.  See the docstring of the KerberosAuthMixin for
how to do this.

This module should work with regular MIT Kerberos implementations as well as
Active Directory (Heimdal is untested but should work fine).  If you're
experiencing trouble it is recommended that you set debug=True in your
application settings.  This will enable printing of Kerberos exception messages.

Troubleshooting
---------------

If your browser asks you for a password (i.e. SSO failed) there's probably
something wrong with your Kerberos configuration on either the client or the
server (usually it's a problem with forward/reverse DNS resolution or an
incorrect or missing service principal in your keytab).

If you're using Active Directory, make sure that there's an HTTP
servicePrincipalName (SPN) matching the FQDN of the host running your Tornado
server.  For example:  HTTP/somehost.somedomain.com@CORP.MYCOMPANY.COM
You may also want a short hostname SPN: HTTP/somehost@CORP.MYCOMPANY.COM

Also make sure that the service principal is in upper case as most clients (
web browsers) will auto-capitalize the principal when verifying the server.

Here's some things to test in order to find problems with your Kerberos config:

Try these from both the client and the server (NOTE: Assuming both are Unix):
kinit -p <user@REALM> # To verify you can authenticate via Kerberos (at all)
nslookup <server FQDN> # To verify the IP address reverse maps properly (below)
nslookup <IP address that 'server FQDN' resolves to>
kvno HTTP/somehost.somedomain.com # To verify your service principal

Remember: Kerberos is heavily dependent on DNS to verify the server and client
are who they claim to be.

I find that it is useful to get GSSAPI authentication working with OpenSSH first
before I attempt to get a custom service principal working with other
applications.  This is because SSH uses the HOST/ prinicipal which is often
taken care of automatically via most Kerberos management tools (including AD).
If you can get SSO working with SSH you can get SSO working with anything else.

Class Docstrings
================
"""

# Standard library modules
import os, logging, base64

# Import our own stuff
from gateone.core.locale import get_translation
# Enable localization support
_ = get_translation()

# 3rd party modules
import tornado.httpserver
import tornado.ioloop
import tornado.web
import kerberos

# NOTE: For some reason if I set this as just an 'object' it doesn't work.
class KerberosAuthMixin(tornado.web.RequestHandler):
    """
    Authenticates users via Kerberos-based Single Sign-On.  Requires that you
    define 'sso_realm' and 'sso_service' in your Tornado Application settings.
    For example::

        settings = dict(
            cookie_secret="iYR123qg4UUdsgf4CRung6BFUBhizAciid8oq1YfJR3gN",
            static_path=os.path.join(os.path.dirname(__file__), "static"),
            gzip=True,
            login_url="/auth",
            debug=True,
            sso_realm="EXAMPLE.COM",
            sso_service="HTTP" # Should pretty much always be HTTP
        )

    NOTE: If you're using 'HTTP' as the service it must be in all caps or it
    might not work with some browsers/clients (which auto-capitalize all
    services).

    To implement this mixin::

        from sso import KerberosAuthMixin
        class KerberosAuthHandler(tornado.web.RequestHandler, KerberosAuthMixin):

            def get(self):
                auth_header = self.request.headers.get('Authorization')
                if auth_header:
                    self.get_authenticated_user(self._on_auth)
                    return
                self.authenticate_redirect()

            def _on_auth(self, user):
                if not user:
                    raise tornado.web.HTTPError(500, "Kerberos auth failed")
                self.set_secure_cookie("user", tornado.escape.json_encode(user))
                print("KerberosAuthHandler user: %s" % user) # To see what you get
                next_url = self.get_argument("next", None) # To redirect properly
                if next_url:
                    self.redirect(next_url)
                else:
                    self.redirect("/")
    """
    def initialize(self):
        """
        Print out helpful error messages if the requisite settings aren't
        configured.

        NOTE: It won't hurt anything to override this method in your
        RequestHandler.
        """
        self.require_setting("sso_realm", _("Kerberos/GSSAPI Single Sign-On"))
        self.require_setting("sso_service", _("Kerberos/GSSAPI Single Sign-On"))

    def get_authenticated_user(self, callback):
        """
        Processes the client's Authorization header and calls
        self.auth_negotiate() or self.auth_basic() depending on what headers
        were provided by the client.
        """
        keytab = self.settings.get('sso_keytab', None)
        if keytab:
            # The kerberos module does not take a keytab as a parameter when
            # performing authentication but you can still specify it via an
            # environment variable:
            os.environ['KRB5_KTNAME'] = keytab
        auth_header = self.request.headers.get('Authorization')
        if auth_header and auth_header.startswith('Negotiate'):
            self.auth_negotiate(auth_header, callback)
        elif auth_header and auth_header.startswith('Basic '):
            self.auth_basic(auth_header, callback)

    def auth_negotiate(self, auth_header, callback):
        """
        Perform Negotiate (GSSAPI/SSO) authentication via Kerberos.
        """
        auth_str = auth_header.split()[1]
        # Initialize Kerberos Context
        context = None
        try:
            result, context = kerberos.authGSSServerInit(
                self.settings['sso_service'])
            if result != 1:
                raise tornado.web.HTTPError(500, _("Kerberos Init failed"))
            result = kerberos.authGSSServerStep(context, auth_str)
            if result == 1:
                gssstring = kerberos.authGSSServerResponse(context)
            else: # Fall back to Basic auth
                self.auth_basic(auth_header, callback)
            # NOTE: The user we get from Negotiate is a full UPN (user@REALM)
            user = kerberos.authGSSServerUserName(context)
        except kerberos.GSSError as e:
            logging.error(_("Kerberos Error: %s" % e))
            raise tornado.web.HTTPError(500, _("Kerberos Init failed"))
        finally:
            if context:
                kerberos.authGSSServerClean(context)
        self.set_header('WWW-Authenticate', "Negotiate %s" % gssstring)
        callback(user)

    def auth_basic(self, auth_header, callback):
        """
        Perform Basic authentication using Kerberos against
        `self.settings['sso_realm']`.
        """
        auth_decoded = base64.decodestring(auth_header[6:])
        username, password = auth_decoded.split(':', 2)
        try:
            kerberos.checkPassword(
                username,
                password,
                self.settings['sso_service'],
                self.settings['sso_realm'])
        except Exception as e: # Basic auth failed
            if self.settings['debug']:
                print(e) # Very useful for debugging Kerberos errors
            return self.authenticate_redirect()
        # NOTE: Basic auth just gives us the username without the @REALM part
        #       so we have to add it:
        user = "%s@%s" % (username, self.settings['sso_realm'])
        callback(user)

    def authenticate_redirect(self):
        """
        Informs the browser that this resource requires authentication (status
        code 401) which should prompt the browser to reply with credentials.

        The browser will be informed that we support both Negotiate (GSSAPI/SSO)
        and Basic auth.
        """
        # NOTE: I know this isn't technically a redirect but I wanted to make
        # this process as close as possible to how things work in tornado.auth.
        if self._headers_written:
            raise Exception(_('Headers have already been written'))
        self.set_status(401)
        self.add_header("WWW-Authenticate", "Negotiate")
        self.add_header(
            "WWW-Authenticate",
            'Basic realm="%s"' % self.settings['sso_realm']
        )
        self.finish()
        return False

########NEW FILE########
__FILENAME__ = configuration
# -*- coding: utf-8 -*-
#
#       Copyright 2013 Liftoff Software Corporation

# Meta
__license__ = "AGPLv3 or Proprietary (see LICENSE.txt)"
__doc__ = """
.. _settings.py:

Settings Module for Gate One
============================

This module contains functions that deal with Gate One's options/settings
"""

import os, sys, io, re, socket, tempfile, logging
from gateone import GATEONE_DIR
from .log import FACILITIES
from gateone.core.log import go_logger
from tornado import locale
from tornado.escape import json_decode
from tornado.options import define, options, Error

# Locale stuff (can't use .locale since .locale uses this module)
# Default to using the environment's locale with en_US fallback
temp_locale = locale.get(os.environ.get('LANG', 'en_US').split('.')[0])
_ = temp_locale.translate
del temp_locale

logger = go_logger(None)
comments_re = re.compile(
    r'//.*?$|/\*.*?\*/|\'(?:\\.|[^\\\'])*\'|"(?:\\.|[^\\"])*"',
    re.DOTALL | re.MULTILINE
)
trailing_commas_re = re.compile(
    r'(,)\s*}(?=([^"\\]*(\\.|"([^"\\]*\\.)*[^"\\]*"))*[^"]*$)')

class SettingsError(Exception):
    """
    Raised when we encounter an error parsing .conf files in the settings dir.
    """
    pass

class RUDict(dict):
    """
    A dict that will recursively update keys and values in a safe manner so that
    sub-dicts will be merged without one clobbering the other.

    .. note::

        This class (mostly) taken from `here
        <http://stackoverflow.com/questions/6256183/combine-two-dictionaries-of-dictionaries-python>`_
    """
    def __init__(self, *args, **kw):
        super(RUDict,self).__init__(*args, **kw)

    def update(self, E=None, **F):
        if E is not None:
            if 'keys' in dir(E) and callable(getattr(E, 'keys')):
                for k in E:
                    if k in self:  # Existing ...must recurse into both sides
                        self.r_update(k, E)
                    else: # Doesn't currently exist, just update
                        self[k] = E[k]
            else:
                for (k, v) in E:
                    self.r_update(k, {k:v})

        for k in F:
            self.r_update(k, {k:F[k]})

    def r_update(self, key, other_dict):
        if isinstance(self[key], dict) and isinstance(other_dict[key], dict):
            od = RUDict(self[key])
            nd = other_dict[key]
            od.update(nd)
            self[key] = od
        else:
            self[key] = other_dict[key]

    def __repr__(self):
        """
        Returns the `RUDict` as indented json to better resemble how it looks in
        a .conf file.
        """
        import json # Tornado's json_encode doesn't do indentation
        return json.dumps(self, indent=4)

    def __str__(self):
        """
        Just returns `self.__repr__()` with an extra newline at the end.
        """
        return self.__repr__() + "\n"

# Utility functions (copied from utils.py so we don't have an import paradox)
def generate_session_id():
    """
    Returns a random, 45-character session ID.  Example:

    .. code-block:: python

        >>> generate_session_id()
        "NzY4YzFmNDdhMTM1NDg3Y2FkZmZkMWJmYjYzNjBjM2Y5O"
        >>>
    """
    import base64, uuid
    from tornado.escape import utf8
    session_id = base64.b64encode(
        utf8(uuid.uuid4().hex + uuid.uuid4().hex))[:45]
    if bytes != str: # Python 3
        return str(session_id, 'UTF-8')
    return session_id

def mkdir_p(path):
    """
    Pythonic version of "mkdir -p".  Example equivalents::

        >>> mkdir_p('/tmp/test/testing') # Does the same thing as...
        >>> from subprocess import call
        >>> call('mkdir -p /tmp/test/testing')

    .. note:: This doesn't actually call any external commands.
    """
    import errno
    try:
        os.makedirs(path)
    except OSError as exc:
        if exc.errno == errno.EEXIST:
            pass
        else: raise

# Settings and options-related functions
# NOTE:  "options" refer to command line arguments (for the most part) while
# "settings" refers to the .conf files.
def define_options(installed=True):
    """
    Calls `tornado.options.define` for all of Gate One's command-line options.

    If *installed* is ``False`` the defaults will be set under the assumption
    that the user is non-root and running Gate One out of a download/cloned
    directory.
    """
    # NOTE: To test this function interactively you must import tornado.options
    # and call tornado.options.parse_config_file(*some_config_path*).  After you
    # do that the options will wind up in tornado.options.options
    global user_locale
    # Default to using the shell's LANG variable as the locale
    try:
        default_locale = os.environ['LANG'].split('.')[0]
    except KeyError: # $LANG isn't set
        default_locale = "en_US"
    user_locale = locale.get(default_locale)
    # NOTE: The locale setting above is only for the --help messages.
    # Simplify the auth option help message
    auths = "none, api, google, ssl"
    from gateone.auth.authentication import PAMAuthHandler, KerberosAuthHandler
    if KerberosAuthHandler:
        auths += ", kerberos"
    if PAMAuthHandler:
        auths += ", pam"
    # Simplify the syslog_facility option help message
    facilities = list(FACILITIES.keys())
    facilities.sort()
    # Figure out the default origins
    default_origins = [
        'localhost',
        '127.0.0.1',
    ]
    # Used both http and https above to demonstrate that both are acceptable
    try:
        additional_origins = socket.gethostbyname_ex(socket.gethostname())
    except socket.gaierror:
        # Couldn't get any IPs from the hostname
        additional_origins = []
    for host in additional_origins:
        if isinstance(host, str):
            default_origins.append('%s' % host)
        else: # It's a list
            for _host in host:
                default_origins.append('%s' % _host)
    default_origins = ";".join(default_origins)
    config_default = os.path.join(os.path.sep, "opt", "gateone", "server.conf")
    # NOTE: --settings_dir deprecates --config
    settings_base = os.path.join(os.path.sep, 'etc', 'gateone')
    settings_default = os.path.join(settings_base, 'conf.d')
    port_default = 443
    log_default = os.path.join(
        os.path.sep, "var", "log", 'gateone', 'gateone.log')
    user_dir_default = os.path.join(
        os.path.sep, "var", "lib", "gateone", "users")
    pid_default = os.path.join(os.path.sep, "var", "run", 'gateone.pid')
    session_dir_default = os.path.join(tempfile.gettempdir(), 'gateone')
    cache_dir_default = os.path.join(tempfile.gettempdir(), 'gateone_cache')
    if os.getuid() != 0: # Not root?  Use $HOME/.gateone/ for everything
        home = os.path.expanduser('~')
        user_dir_default = os.path.join(home, '.gateone')
        settings_default = os.path.join(user_dir_default, 'conf.d')
        port_default = 10443
        log_default = os.path.join(user_dir_default, 'logs', 'gateone.log')
        pid_default = os.path.join(user_dir_default, 'gateone.pid')
        session_dir_default = os.path.join(user_dir_default, 'sessions')
        cache_dir_default = os.path.join(user_dir_default, 'cache')
    if not installed:
        # Running inside the download directory?  Change various defaults to
        # work inside of this directory
        here = os.path.dirname(os.path.abspath(__file__))
        settings_base = os.path.normpath(os.path.join(here, '..', '..'))
        settings_default = os.path.join(settings_base, 'conf.d')
        port_default = 10443
        log_default = os.path.join(settings_base, 'logs', 'gateone.log')
        user_dir_default = os.path.join(settings_base, 'users')
        pid_default = os.path.join(settings_base, 'gateone.pid')
        session_dir_default = os.path.join(settings_base, 'sessions')
        cache_dir_default = os.path.join(settings_base, 'cache')
    options.log_file_prefix = log_default
    ssl_dir = os.path.join(settings_base, 'ssl')
    define("version",
        type=bool,
        group='gateone',
        help=_("Display version information."),
    )
    define("config",
        default=config_default,
        group='gateone',
        help=_("DEPRECATED.  Use --settings_dir."),
        type=basestring,
    )
    define("settings_dir",
        default=settings_default,
        group='gateone',
        help=_("Path to the settings directory."),
        type=basestring
    )
    define(
        "cache_dir",
        default=cache_dir_default,
        group='gateone',
        help=_(
            "Path where Gate One should store temporary global files (e.g. "
            "rendered templates, CSS, JS, etc)."),
        type=basestring
    )
    define(
        "debug",
        default=False,
        group='gateone',
        help=_("Enable debugging features such as auto-restarting when files "
               "are modified.")
    )
    define("cookie_secret", # 45 chars is, "Good enough for me" (cookie joke =)
        default=None,
        group='gateone',
        help=_("Use the given 45-character string for cookie encryption."),
        type=basestring
    )
    define("command",
        default=None,
        group='gateone',
        help=_(
            "DEPRECATED: Use the 'commands' option in the terminal settings."),
        type=basestring
    )
    define("address",
        default="",
        group='gateone',
        help=_("Run on the given address.  Default is all addresses (IPv6 "
               "included).  Multiple address can be specified using a semicolon"
               " as a separator (e.g. '127.0.0.1;::1;10.1.1.100')."),
        type=basestring)
    define("port",
           default=port_default,
           group='gateone',
           help=_("Run on the given port."),
           type=int)
    define(
        "enable_unix_socket",
        default=False,
        group='gateone',
        help=_("Enable Unix socket support."),
        type=bool)
    define(
        "unix_socket_path",
        default="/tmp/gateone.sock",
        group='gateone',
        help=_("Path to the Unix socket (if --enable_unix_socket=True)."),
        type=basestring)
    # Please only use this if Gate One is running behind something with SSL:
    define(
        "disable_ssl",
        default=False,
        group='gateone',
        help=_("If enabled, Gate One will run without SSL (generally not a "
               "good idea).")
    )
    define(
        "certificate",
        default=os.path.join(ssl_dir, "certificate.pem"),
        group='gateone',
        help=_("Path to the SSL certificate.  Will be auto-generated if none is"
               " provided."),
        type=basestring
    )
    define(
        "keyfile",
        default=os.path.join(ssl_dir, "keyfile.pem"),
        group='gateone',
        help=_("Path to the SSL keyfile.  Will be auto-generated if none is"
               " provided."),
        type=basestring
    )
    define(
        "ca_certs",
        default=None,
        group='gateone',
        help=_("Path to a file containing any number of concatenated CA "
               "certificates in PEM format.  They will be used to authenticate "
               "clients if the 'ssl_auth' option is set to 'optional' or "
               "'required'."),
        type=basestring
    )
    define(
        "ssl_auth",
        default='none',
        group='gateone',
        help=_("Enable the use of client SSL (X.509) certificates as a "
               "secondary authentication factor (the configured 'auth' type "
               "will come after SSL auth).  May be one of 'none', 'optional', "
               "or 'required'.  NOTE: Only works if the 'ca_certs' option is "
               "configured."),
        type=basestring
    )
    define(
        "user_dir",
        default=user_dir_default,
        group='gateone',
        help=_("Path to the location where user files will be stored."),
        type=basestring
    )
    define(
        "user_logs_max_age",
        default="30d",
        group='gateone',
        help=_("Maximum amount of length of time to keep any given user log "
                "before it is removed."),
        type=basestring
    )
    define(
        "session_dir",
        default=session_dir_default,
        group='gateone',
        help=_(
            "Path to the location where session information will be stored."),
        type=basestring
    )
    define(
        "syslog_facility",
        default="daemon",
        group='gateone',
        help=_("Syslog facility to use when logging to syslog (if "
               "syslog_session_logging is enabled).  Must be one of: %s."
               % ", ".join(facilities)),
        type=basestring
    )
    define(
        "session_timeout",
        default="5d",
        group='gateone',
        help=_("Amount of time that a session is allowed to idle before it is "
        "killed.  Accepts <num>X where X could be one of s, m, h, or d for "
        "seconds, minutes, hours, and days.  Set to '0' to disable the ability "
        "to resume sessions."),
        type=basestring
    )
    define(
        "new_api_key",
        default=False,
        group='gateone',
        help=_("Generate a new API key that an external application can use to "
               "embed Gate One."),
    )
    define(
        "auth",
        default="none",
        group='gateone',
        help=_("Authentication method to use.  Valid options are: %s" % auths),
        type=basestring
    )
    # This is to prevent replay attacks.  Gate One only keeps a "working memory"
    # of API auth objects for this amount of time.  So if the Gate One server is
    # restarted we don't have to write them to disk as anything older than this
    # setting will be invalid (no need to check if it has already been used).
    define(
        "api_timestamp_window",
        default="30s", # 30 seconds
        group='gateone',
        help=_(
            "How long before an API authentication object becomes invalid.  "),
        type=basestring
    )
    define(
        "sso_realm",
        default=None,
        group='gateone',
        help=_("Kerberos REALM (aka DOMAIN) to use when authenticating clients."
               " Only relevant if Kerberos authentication is enabled."),
        type=basestring
    )
    define(
        "sso_service",
        default='HTTP',
        group='gateone',
        help=_("Kerberos service (aka application) to use. Defaults to HTTP. "
               "Only relevant if Kerberos authentication is enabled."),
        type=basestring
    )
    define(
        "pam_realm",
        default=os.uname()[1],
        group='gateone',
        help=_("Basic auth REALM to display when authenticating clients.  "
        "Default: hostname.  "
        "Only relevant if PAM authentication is enabled."),
        # NOTE: This is only used to show the user a REALM at the basic auth
        #       prompt and as the name in the GATEONE_DIR+'/users' directory
        type=basestring
    )
    define(
        "pam_service",
        default='login',
        group='gateone',
        help=_("PAM service to use.  Defaults to 'login'. "
               "Only relevant if PAM authentication is enabled."),
        type=basestring
    )
    define(
        "embedded",
        default=False,
        group='gateone',
        help=_(
            "When embedding Gate One, this option is available to templates.")
    )
    define(
        "locale",
        default=default_locale,
        group='gateone',
        help=_("The locale (e.g. pt_PT) Gate One should use for translations."
             "  If not provided, will default to $LANG (which is '%s' in your "
             "current shell), or en_US if not set."
             % os.environ.get('LANG', 'not set').split('.')[0]),
        type=basestring
    )
    define("js_init",
        default="",
        group='gateone',
        help=_("A JavaScript object (string) that will be used when running "
               "GateOne.init() inside index.html.  "
               "Example: --js_init=\"{scheme: 'white'}\" would result in "
               "GateOne.init({scheme: 'white'})"),
        type=basestring
    )
    define(
        "https_redirect",
        default=False,
        group='gateone',
        help=_("If enabled, a separate listener will be started on port 80 that"
               " redirects users to the configured port using HTTPS.")
    )
    define(
        "url_prefix",
        default="/",
        group='gateone',
        help=_("An optional prefix to place before all Gate One URLs. e.g. "
               "'/gateone/'.  Use this if Gate One will be running behind a "
               "reverse proxy where you want it to be located at some sub-"
               "URL path."),
        type=basestring
    )
    define(
        "origins",
        default=default_origins,
        group='gateone',
        help=_("A semicolon-separated list of origins you wish to allow access "
               "to your Gate One server over the WebSocket.  This value must "
               "contain the hostnames and FQDNs (e.g. foo;foo.bar;) users will"
               " use to connect to your Gate One server as well as the "
               "hostnames/FQDNs of any sites that will be embedding Gate One. "
               "Alternatively, '*' may be  specified to allow access from "
               "anywhere."),
        type=basestring
    )
    define(
        "pid_file",
        default=pid_default,
        group='gateone',
        help=_(
            "Define the path to the pid file.  Default: /var/run/gateone.pid"),
        type=basestring
    )
    define(
        "uid",
        default=str(os.getuid()),
        group='gateone',
        help=_(
            "Drop privileges and run Gate One as this user/uid."),
        type=basestring
    )
    define(
        "gid",
        default=str(os.getgid()),
        group='gateone',
        help=_(
            "Drop privileges and run Gate One as this group/gid."),
        type=basestring
    )
    define(
        "api_keys",
        default="",
        group='gateone',
        help=_("The 'key:secret,...' API key pairs you wish to use (only "
               "applies if using API authentication)"),
        type=basestring
    )
    define(
        "combine_js",
        default="",
        group='gateone',
        help=_(
            "Combines all of Gate One's JavaScript files into one big file and "
            "saves it at the given path (e.g. ./gateone.py "
            "--combine_js=/tmp/gateone.js)"),
        type=basestring
    )
    define(
        "combine_css",
        default="",
        group='gateone',
        help=_(
            "Combines all of Gate One's CSS Template files into one big file "
            "and saves it at the given path (e.g. ./gateone.py "
            "--combine_css=/tmp/gateone.css)."),
        type=basestring
    )
    define(
        "combine_css_container",
        default="gateone",
        group='gateone',
        help=_(
            "Use this setting in conjunction with --combine_css if the <div> "
            "where Gate One lives is named something other than #gateone"),
        type=basestring
    )

def settings_template(path, **kwargs):
    """
    Renders and returns the Tornado template at *path* using the given *kwargs*.

    .. note:: Any blank lines in the rendered template will be removed.
    """
    from tornado.template import Template
    with io.open(path, mode='r', encoding='utf-8') as f:
        template_data = f.read()
    t = Template(template_data)
    # NOTE: Tornado returns templates as bytes, not unicode.  That's why we need
    # the decode() below...
    rendered = t.generate(**kwargs).decode('utf-8')
    out = ""
    for line in rendered.splitlines():
        if line.strip():
            out += line + "\n"
    return out

def parse_commands(commands):
    """
    Given a list of *commands* (which can include arguments) such as::

        ['ls', '--color="always"', '-lh', 'ps', '--context', '-ef']

    Returns an `OrderedDict` like so::

        OrderedDict([
            ('ls', ['--color="always"', '-ltrh']),
            ('ps', ['--context', '-ef'])
        ])
    """
    try:
        from collections import OrderedDict
    except ImportError: # Python <2.7 didn't have OrderedDict in collections
        from ordereddict import OrderedDict
    out = OrderedDict()
    command = OrderedDict()
    for item in commands:
        if item.startswith('-'):
            out[command].append(item)
        else:
            command = item
            out[command] = []
    return out

def generate_server_conf(installed=True):
    """
    Generates a fresh settings/10server.conf file using the arguments provided
    on the command line to override defaults.

    If *installed* is ``False`` the defaults will be set under the assumption
    that the user is non-root and running Gate One out of a download/cloned
    directory.
    """
    logger.info(_(
        u"Gate One settings are incomplete.  A new settings/10server.conf"
        u" will be generated."))
    auth_settings = {} # Auth stuff goes in 20authentication.conf
    all_setttings = options_to_settings(options) # NOTE: options is global
    settings_path = options.settings_dir
    server_conf_path = os.path.join(settings_path, '10server.conf')
    if os.path.exists(server_conf_path):
        logger.error(_(
            "You have a 10server.conf but it is either invalid (syntax "
            "error) or missing essential settings."))
        sys.exit(1)
    config_defaults = all_setttings['*']['gateone']
    # Don't need this in the actual settings file:
    del config_defaults['settings_dir']
    non_options = [
        # These are things that don't really belong in settings
        'new_api_key', 'help', 'kill', 'config'
    ]
    # Don't need non-options in there either:
    for non_option in non_options:
        if non_option in config_defaults:
            del config_defaults[non_option]
    # Generate a new cookie_secret
    config_defaults['cookie_secret'] = generate_session_id()
    # Separate out the authentication settings
    authentication_options = [
        # These are here only for logical separation in the .conf files
        'api_timestamp_window', 'auth', 'pam_realm', 'pam_service',
        'sso_keytab', 'sso_realm', 'sso_service', 'ssl_auth'
    ]
    # Provide some kerberos (sso) defaults
    auth_settings['sso_realm'] = "EXAMPLE.COM"
    auth_settings['sso_keytab'] = None # Allow /etc/krb5.conf to control it
    for key, value in list(config_defaults.items()):
        if key in authentication_options:
            auth_settings.update({key: value})
            del config_defaults[key]
        if key == 'origins':
            # As a convenience to the user, add any --port to the origins
            if config_defaults['port'] not in [80, 443]:
                for i, origin in enumerate(list(value)):
                    value[i] = "{origin}:{port}".format(
                        origin=origin, port=config_defaults['port'])
    # Make sure we have a valid log_file_prefix
    if config_defaults['log_file_prefix'] == None:
        web_log_dir = os.path.join(os.path.sep, "var", "log", "gateone")
        if installed:
            here = os.path.dirname(os.path.abspath(__file__))
            web_log_dir = os.path.normpath(
                os.path.join(here, '..', '..', 'logs'))
        web_log_path = os.path.join(web_log_dir, 'gateone.log')
        config_defaults['log_file_prefix'] = web_log_path
    else:
        web_log_dir = os.path.split(config_defaults['log_file_prefix'])[0]
    if not os.path.exists(web_log_dir):
        # Make sure the directory exists
        mkdir_p(web_log_dir)
    if not os.path.exists(config_defaults['log_file_prefix']):
        # Make sure the file is present
        io.open(
            config_defaults['log_file_prefix'],
            mode='w', encoding='utf-8').write(u'')
    auth_conf_path = os.path.join(settings_path, '20authentication.conf')
    template_path = os.path.join(
        GATEONE_DIR, 'templates', 'settings', '10server.conf')
    new_settings = settings_template(
        template_path, settings=config_defaults)
    with io.open(server_conf_path, mode='w') as s:
        s.write(u"// This is Gate One's main settings file.\n")
        s.write(new_settings)
    new_auth_settings = settings_template(
        template_path, settings=auth_settings)
    with io.open(auth_conf_path, mode='w') as s:
        s.write(u"// This is Gate One's authentication settings file.\n")
        s.write(new_auth_settings)

# NOTE: After Gate One 1.2 is officially released this function will be removed:
def convert_old_server_conf():
    """
    Converts old-style server.conf files to the new settings/10server.conf
    format.
    """
    settings = RUDict()
    auth_settings = RUDict()
    terminal_settings = RUDict()
    api_keys = RUDict({"*": {"gateone": {"api_keys": {}}}})
    terminal_options = [ # These are now terminal-app-specific setttings
        'command', 'dtach', 'session_logging', 'session_logs_max_age',
        'syslog_session_logging'
    ]
    authentication_options = [
        # These are here only for logical separation in the .conf files
        'api_timestamp_window', 'auth', 'pam_realm', 'pam_service',
        'sso_realm', 'sso_service', 'ssl_auth'
    ]
    with io.open(options.config) as f:
        # Regular server-wide settings will go in 10server.conf by default.
        # These settings can actually be spread out into any number of .conf
        # files in the settings directory using whatever naming convention
        # you want.
        settings_path = options.settings_dir
        server_conf_path = os.path.join(settings_path, '10server.conf')
        # Using 20authentication.conf for authentication settings
        auth_conf_path = os.path.join(
            settings_path, '20authentication.conf')
        terminal_conf_path = os.path.join(settings_path, '50terminal.conf')
        api_keys_conf = os.path.join(settings_path, '30api_keys.conf')
        # NOTE: Using a separate file for authentication stuff for no other
        #       reason than it seems like a good idea.  Don't want one
        #       gigantic config file for everything (by default, anyway).
        logger.info(_(
            "Old server.conf file found.  Converting to the new format as "
            "%s, %s, and %s" % (
                server_conf_path, auth_conf_path, terminal_conf_path)))
        for line in f:
            if line.startswith('#'):
                continue
            key = line.split('=', 1)[0].strip()
            value = eval(line.split('=', 1)[1].strip())
            if key in terminal_options:
                if key == 'command':
                    # Fix the path to ssh_connect.py if present
                    if 'ssh_connect.py' in value:
                        value = value.replace(
                            '/plugins/', '/applications/terminal/plugins/')
                if key == 'session_logs_max_age':
                    # This is now user_logs_max_age.  Put it in 'gateone'
                    settings.update({'user_logs_max_age': value})
                terminal_settings.update({key: value})
            elif key in authentication_options:
                auth_settings.update({key: value})
            elif key == 'origins':
                # Convert to the new format (a list with no http://)
                origins = value.split(';')
                converted_origins = []
                for origin in origins:
                    # The new format doesn't bother with http:// or https://
                    if origin == '*':
                        converted_origins.append(origin)
                        continue
                    origin = origin.split('://')[1]
                    if origin not in converted_origins:
                        converted_origins.append(origin)
                settings.update({key: converted_origins})
            elif key == 'api_keys':
                # Move these to the new location/format (30api_keys.conf)
                for pair in value.split(','):
                    api_key, secret = pair.split(':')
                    if bytes == str:
                        api_key = api_key.decode('UTF-8')
                        secret = secret.decode('UTF-8')
                    api_keys['*']['gateone']['api_keys'].update(
                        {api_key: secret})
                # API keys can be written right away
                with io.open(api_keys_conf, 'w') as conf:
                    msg = _(
                        u"// This file contains the key and secret pairs "
                        u"used by Gate One's API authentication method.\n")
                    conf.write(msg)
                    conf.write(unicode(api_keys))
            else:
                settings.update({key: value})
        template_path = os.path.join(
            GATEONE_DIR, 'templates', 'settings', '10server.conf')
        new_settings = settings_template(template_path, settings=settings)
        if not os.path.exists(server_conf_path):
            with io.open(server_conf_path, 'w') as s:
                s.write(_(u"// This is Gate One's main settings file.\n"))
                s.write(new_settings)
        new_auth_settings = settings_template(
            template_path, settings=auth_settings)
        if not os.path.exists(auth_conf_path):
            with io.open(auth_conf_path, 'w') as s:
                s.write(_(
                    u"// This is Gate One's authentication settings file.\n"))
                s.write(new_auth_settings)
        # Terminal uses a slightly different template; it converts 'command'
        # to the new 'commands' format.
        template_path = os.path.join(
            GATEONE_DIR, 'templates', 'settings', '50terminal.conf')
        new_term_settings = settings_template(
            template_path, settings=terminal_settings)
        if not os.path.exists(terminal_conf_path):
            with io.open(terminal_conf_path, 'w') as s:
                s.write(_(
                    u"// This is Gate One's Terminal application settings "
                    u"file.\n"))
                s.write(new_term_settings)
    # Rename the old server.conf so this logic doesn't happen again
    os.rename(options.config, "%s.old" % options.config)

def apply_cli_overrides(go_settings):
    """
    Updates *go_settings* in-place with values given on the command line.
    """
    # Figure out which options are being overridden on the command line
    arguments = []
    non_options = [
        # These are things that don't really belong in settings
        'new_api_key', 'help', 'kill', 'config', 'combine_js', 'combine_css',
        'combine_css_container'
    ]
    for arg in list(sys.argv)[1:]:
        if not arg.startswith('-'):
            break
        else:
            arguments.append(arg.lstrip('-').split('=', 1)[0])
    go_settings['cli_overrides'] = arguments
    for argument in arguments:
        if argument in non_options:
            continue
        if argument in list(options):
            go_settings[argument] = options[argument]
    # Update Tornado's options from our settings.
    # NOTE: For options given on the command line this step should be redundant.
    for key, value in go_settings.items():
        if key in non_options:
            continue
        if key in list(options):
            if key in ('origins', 'api_keys'):
                # These two settings are special and taken care of elsewhere
                continue
            try:
                setattr(options, key, value)
            except Error:
                if isinstance(value, str):
                    if str == bytes: # Python 2
                        setattr(options, key, unicode(value))
                else:
                    setattr(options, key, str(value))

def remove_comments(json_like):
    """
    Removes C-style comments from *json_like* and returns the result.
    """
    def replacer(match):
        s = match.group(0)
        if s[0] == '/': return ""
        return s
    return comments_re.sub(replacer, json_like)

def remove_trailing_commas(json_like):
    """
    Removes trailing commas from *json_like* and returns the result.
    """
    return trailing_commas_re.sub("}", json_like)

def get_settings(path, add_default=True):
    """
    Reads any and all *.conf files containing JSON (JS-style comments are OK)
    inside *path* and returns them as an :class:`RUDict`.  Optionally, *path*
    may be a specific file (as opposed to just a directory).

    By default, all returned :class:`RUDict` objects will include a '*' dict
    which indicates "all users".  This behavior can be skipped by setting the
    *add_default* keyword argument to `False`.
    """
    settings = RUDict()
    if add_default:
        settings['*'] = {}
    # Using an RUDict so that subsequent .conf files can safely override
    # settings way down the chain without clobbering parent keys/dicts.
    if os.path.isdir(path):
        settings_files = [a for a in os.listdir(path) if a.endswith('.conf')]
        settings_files.sort()
    else:
        if not os.path.exists(path):
            raise IOError(_("%s does not exist" % path))
        settings_files = [path]
    for fname in settings_files:
        # Use this file to update settings
        if os.path.isdir(path):
            filepath = os.path.join(path, fname)
        else:
            filepath = path
        with io.open(filepath, encoding='utf-8') as f:
            # Remove comments
            almost_json = remove_comments(f.read())
            proper_json = remove_trailing_commas(almost_json)
            # Remove blank/empty lines
            proper_json = os.linesep.join([
                s for s in proper_json.splitlines() if s.strip()])
            try:
                settings.update(json_decode(proper_json))
            except ValueError as e:
                # Something was wrong with the JSON (syntax error, usually)
                logging.error(
                    "Error decoding JSON in settings file: %s"
                    % os.path.join(path, fname))
                logging.error(e)
                # Let's try to be as user-friendly as possible by pointing out
                # *precisely* where the error occurred (if possible)...
                try:
                    line_no = int(str(e).split(': line ', 1)[1].split()[0])
                    column = int(str(e).split(': line ', 1)[1].split()[2])
                    for i, line in enumerate(proper_json.splitlines()):
                        if i == line_no-1:
                            print(
                                line[:column] +
                                _(" <-- Something went wrong right here (or "
                                  "right above it)")
                            )
                            break
                        else:
                            print(line)
                    raise SettingsError()
                except (ValueError, IndexError):
                    print(_(
                        "Got an exception trying to display precisely where "
                        "the problem was.  This usually happens when you've "
                        "used single quotes (') instead of double quotes (\")."
                    ))
                    # Couldn't parse the exception message for line/column info
                    pass # No big deal; the user will figure it out eventually
    return settings

def options_to_settings(options):
    """
    Converts the given Tornado-style *options* to new-style settings.  Returns
    an :class:`RUDict` containing all the settings.
    """
    settings = RUDict({'*': {'gateone': {}, 'terminal': {}}})
    # In the new settings format some options have moved to the terminal app.
    # These settings are below and will be placed in the 'terminal' sub-dict.
    terminal_options = [
        'command', 'dtach', 'session_logging', 'session_logs_max_age',
        'syslog_session_logging'
    ]
    non_options = [
        # These are things that don't really belong in settings
        'new_api_key', 'help', 'kill', 'config'
    ]
    for key, value in options.items():
        if key in terminal_options:
            settings['*']['terminal'].update({key: value})
        elif key in non_options:
            continue
        else:
            if key == 'origins':
                #if value == '*':
                    #continue
                # Convert to the new format (a list with no http://)
                origins = value.split(';')
                converted_origins = []
                for origin in origins:
                    if '://' in origin:
                        # The new format doesn't bother with http:// or https://
                        origin = origin.split('://')[1]
                        if origin not in converted_origins:
                            converted_origins.append(origin)
                    elif origin not in converted_origins:
                        converted_origins.append(origin)
                settings['*']['gateone'].update({key: converted_origins})
            elif key == 'api_keys':
                if not value:
                    continue
                # API keys/secrets are now a dict instead of a string
                settings['*']['gateone']['api_keys'] = {}
                for pair in value.split(','):
                    api_key, secret = pair.split(':', 1)
                    if bytes == str: # Python 2
                        api_key = api_key.decode('UTF-8')
                        secret = secret.decode('UTF-8')
                    settings['*']['gateone']['api_keys'].update(
                        {api_key: secret})
            else:
                settings['*']['gateone'].update({key: value})
    return settings

def combine_javascript(path, settings_dir=None):
    """
    Combines all application and plugin .js files into one big one; saved to the
    given *path*.  If given, *settings_dir* will be used to determine which
    applications and plugins should be included in the dump based on what is
    enabled.
    """
    if not settings_dir:
        settings_dir = os.path.join(GATEONE_DIR, 'settings')
    all_settings = get_settings(settings_dir)
    enabled_plugins = []
    enabled_applications = []
    if 'gateone' in all_settings['*']:
        # The check above will fail in first-run situations
        enabled_plugins = all_settings['*']['gateone'].get(
            'enabled_plugins', [])
        enabled_applications = all_settings['*']['gateone'].get(
            'enabled_applications', [])
    plugins_dir = os.path.join(GATEONE_DIR, 'plugins')
    pluginslist = os.listdir(plugins_dir)
    pluginslist.sort()
    applications_dir = os.path.join(GATEONE_DIR, 'applications')
    appslist = os.listdir(applications_dir)
    appslist.sort()
    with io.open(path, 'w') as f:
        # Start by adding gateone.js
        gateone_js = os.path.join(GATEONE_DIR, 'static', 'gateone.js')
        with io.open(gateone_js) as go_js:
            f.write(go_js.read() + '\n')
        # Gate One plugins
        for plugin in pluginslist:
            if enabled_plugins and plugin not in enabled_plugins:
                continue
            static_dir = os.path.join(plugins_dir, plugin, 'static')
            if os.path.isdir(static_dir):
                filelist = os.listdir(static_dir)
                filelist.sort()
                for filename in filelist:
                    filepath = os.path.join(static_dir, filename)
                    if filename.endswith('.js'):
                        with io.open(filepath) as js_file:
                            f.write(js_file.read() + u'\n')
        # Gate One applications
        for application in appslist:
            if enabled_applications:
                # Only export JS of enabled apps
                if application not in enabled_applications:
                    continue
            static_dir = os.path.join(GATEONE_DIR,
                'applications', application, 'static')
            plugins_dir = os.path.join(
                applications_dir, application, 'plugins')
            if os.path.isdir(static_dir):
                filelist = os.listdir(static_dir)
                filelist.sort()
                for filename in filelist:
                    filepath = os.path.join(static_dir, filename)
                    if filename.endswith('.js'):
                        with io.open(filepath) as js_file:
                            f.write(js_file.read() + u'\n')
            app_settings = all_settings['*'].get(application, None)
            enabled_app_plugins = []
            if app_settings:
                enabled_app_plugins = app_settings.get(
                    'enabled_plugins', [])
            if os.path.isdir(plugins_dir):
                pluginslist = os.listdir(plugins_dir)
                pluginslist.sort()
                # Gate One application plugins
                for plugin in pluginslist:
                    # Only export JS of enabled app plugins
                    if enabled_app_plugins:
                        if plugin not in enabled_app_plugins:
                            continue
                    static_dir = os.path.join(plugins_dir, plugin, 'static')
                    if os.path.isdir(static_dir):
                        filelist = os.listdir(static_dir)
                        filelist.sort()
                        for filename in filelist:
                            filepath = os.path.join(static_dir, filename)
                            if filename.endswith('.js'):
                                with io.open(filepath) as js_file:
                                    f.write(js_file.read() + u'\n')
        f.flush()

def combine_css(path, container, settings_dir=None, log=True):
    """
    Combines all application and plugin .css template files into one big one;
    saved to the given *path*.  Templates will be rendered using the given
    *container* as the replacement for templates use of '#{{container}}'.

    If given, *settings_dir* will be used to determine which applications and
    plugins should be included in the dump based on what is enabled.

    If *log* is ``False`` messages indicating where the files
    have been saved will not be logged (useful when rendering CSS for
    programatic use).
    """
    if container.startswith('#'): # This is just in case (don't want ##gateone)
        container = container.lstrip('#')
    if not settings_dir:
        settings_dir = os.path.join(GATEONE_DIR, 'settings')
    all_settings = get_settings(settings_dir)
    enabled_plugins = []
    enabled_applications = []
    embedded = False
    url_prefix = '/'
    if 'gateone' in all_settings['*']:
        # The check above will fail in first-run situations
        enabled_plugins = all_settings['*']['gateone'].get(
            'enabled_plugins', [])
        enabled_applications = all_settings['*']['gateone'].get(
            'enabled_applications', [])
        embedded = all_settings['*']['gateone'].get('embedded', False)
        url_prefix = all_settings['*']['gateone'].get('url_prefix', False)
    plugins_dir = os.path.join(GATEONE_DIR, 'plugins')
    pluginslist = os.listdir(plugins_dir)
    pluginslist.sort()
    applications_dir = os.path.join(GATEONE_DIR, 'applications')
    appslist = os.listdir(applications_dir)
    appslist.sort()
    global_themes_dir = os.path.join(GATEONE_DIR, 'templates', 'themes')
    themes = os.listdir(global_themes_dir)
    theme_writers = {}
    for theme in themes:
        combined_theme_path = "%s_theme_%s" % (
            path.split('.css')[0], theme)
        theme_writers[theme] = io.open(combined_theme_path, 'w')
        themepath = os.path.join(global_themes_dir, theme)
        with io.open(themepath) as css_file:
            theme_writers[theme].write(css_file.read())
    # NOTE: We skip gateone.css because that isn't used when embedding
    with io.open(path, 'w') as f:
        # Gate One plugins
        # TODO: Add plugin theme files to this
        for plugin in pluginslist:
            if enabled_plugins and plugin not in enabled_plugins:
                continue
            css_dir = os.path.join(plugins_dir, plugin, 'templates')
            if os.path.isdir(css_dir):
                filelist = os.listdir(css_dir)
                filelist.sort()
                for filename in filelist:
                    filepath = os.path.join(css_dir, filename)
                    if filename.endswith('.css'):
                        with io.open(filepath) as css_file:
                            f.write(css_file.read() + u'\n')
        # Gate One applications
        for application in appslist:
            if enabled_applications:
                # Only export CSS of enabled apps
                if application not in enabled_applications:
                    continue
            css_dir = os.path.join(GATEONE_DIR,
                'applications', application, 'templates')
            subdirs = []
            plugins_dir = os.path.join(
                applications_dir, application, 'plugins')
            if os.path.isdir(css_dir):
                filelist = os.listdir(css_dir)
                filelist.sort()
                for filename in filelist:
                    filepath = os.path.join(css_dir, filename)
                    if filename.endswith('.css'):
                        with io.open(filepath) as css_file:
                            f.write(css_file.read() + u'\n')
                    elif os.path.isdir(filepath):
                        subdirs.append(filepath)
            while subdirs:
                subdir = subdirs.pop()
                filelist = os.listdir(subdir)
                filelist.sort()
                for filename in filelist:
                    filepath = os.path.join(subdir, filename)
                    if filename.endswith('.css'):
                        with io.open(filepath) as css_file:
                            combined = css_file.read() + u'\n'
                            if os.path.split(subdir)[1] == 'themes':
                                theme_writers[filename].write(combined)
                            else:
                                f.write(combined)
                    elif os.path.isdir(filepath):
                        subdirs.append(filepath)
            app_settings = all_settings['*'].get(application, None)
            enabled_app_plugins = []
            if app_settings:
                enabled_app_plugins = app_settings.get(
                    'enabled_plugins', [])
            if os.path.isdir(plugins_dir):
                pluginslist = os.listdir(plugins_dir)
                pluginslist.sort()
                # Gate One application plugins
                for plugin in pluginslist:
                    # Only export JS of enabled app plugins
                    if enabled_app_plugins:
                        if plugin not in enabled_app_plugins:
                            continue
                    css_dir = os.path.join(
                        plugins_dir, plugin, 'templates')
                    if os.path.isdir(css_dir):
                        filelist = os.listdir(css_dir)
                        filelist.sort()
                        for filename in filelist:
                            filepath = os.path.join(css_dir, filename)
                            if filename.endswith('.css'):
                                with io.open(filepath) as css_file:
                                    f.write(css_file.read() + u'\n')
                            elif os.path.isdir(os.path.join(
                                css_dir, filename)):
                                subdirs.append(filepath)
                    while subdirs:
                        subdir = subdirs.pop()
                        filelist = os.listdir(subdir)
                        filelist.sort()
                        for filename in filelist:
                            filepath = os.path.join(subdir, filename)
                            if filename.endswith('.css'):
                                with io.open(filepath) as css_file:
                                    with io.open(filepath) as css_file:
                                        combined = css_file.read() + u'\n'
                                        _dir = os.path.split(subdir)[1]
                                        if _dir == 'themes':
                                            theme_writers[filename].write(
                                                combined)
                                        else:
                                            f.write(combined)
                            elif os.path.isdir(filepath):
                                subdirs.append(filepath)
        f.flush()
    for writer in theme_writers.values():
        writer.flush()
        writer.close()
    # Now render the templates
    asis = lambda x: x # Used to disable autoescape
    import tornado.template
    loader = tornado.template.Loader(os.path.split(path)[0], autoescape="asis")
    template = loader.load(path)
    css_data = template.generate(
        asis=asis,
        container=container,
        url_prefix=url_prefix,
        embedded=embedded)
    # Overwrite it with the rendered version
    with io.open(path, 'wb') as f:
        f.write(css_data)
    if log:
        logging.info(_(
            "Non-theme CSS has been combined and saved to: %s" % path))
    for theme in theme_writers.keys():
        combined_theme_path = "%s_theme_%s" % (
            path.split('.css')[0], theme)
        template = loader.load(combined_theme_path)
        css_data = template.generate(
            asis=asis,
            container=container,
            url_prefix=url_prefix,
            embedded=embedded)
        with io.open(combined_theme_path, 'wb') as f:
            f.write(css_data)
        if log:
            logging.info(_(
                "The %s theme CSS has been combined and saved to: %s"
                % (theme.split('.css')[0], combined_theme_path)))

########NEW FILE########
__FILENAME__ = locale
# -*- coding: utf-8 -*-
#
#       Copyright 2013 Liftoff Software Corporation

# Meta
__license__ = "AGPLv3 or Proprietary (see LICENSE.txt)"
__doc__ = """
.. _locale.py:

Locale Module for Gate One
==========================

This module contains functions that deal with Gate One's locale, localization,
and internationalization features.
"""

import os
from .configuration import get_settings
from tornado.options import options
from tornado import locale

# FUTURE:
#from pkg_resources import resource_listdir
#langs = resource_listdir('gateone', 'i18n')

def get_translation(settings_dir=None):
    """
    Looks inside Gate One's settings to determine the configured locale and
    returns a matching locale.get_translation function.  If no locale is set
    (e.g. first time running Gate One) the local `$LANG` environment variable
    will be used.

    This function is meant to be used like so::

        >>> from gateone.core.locale import get_translation
        >>> _ = get_translation()
    """
    if not settings_dir:
        # Check the tornado options object first
        if hasattr(options, 'settings_dir'):
            settings_dir = options.settings_dir
        else: # Fall back to the default settings dir
            settings_dir = os.path.join(os.path.sep, 'etc', 'gateone' 'conf.d')
    # If none of the above worked we can always just use en_US:
    locale_str = os.environ.get('LANG', 'en_US').split('.')[0]
    try:
        settings = get_settings(settings_dir)
        gateone_settings = settings['*'].get('gateone', None)
        if gateone_settings: # All these checks are necessary for early startup
            locale_str = settings['*']['gateone'].get('locale', locale_str)
    except IOError: # server.conf doesn't exist (yet).
        # Fall back to os.environ['LANG']
        # Already set above
        pass
    user_locale = locale.get(locale_str)
    return user_locale.translate

########NEW FILE########
__FILENAME__ = log
# -*- coding: utf-8 -*-
#
#       Copyright 2013 Liftoff Software Corporation

# Meta
__license__ = "AGPLv3 or Proprietary (see LICENSE.txt)"
__doc__ = """
.. _log.py:

Logging Module for Gate One
===========================

This module contains a number of pre-defined loggers for use within Gate One:

    ==========  =============================================================
    Name        Description
    ==========  =============================================================
    go_log      Used for logging internal Gate One events.
    auth_log    Used for logging authentication and authorization events.
    msg_log     Used for logging messages sent to/from users.
    ==========  =============================================================

Applications may also use their own loggers for differentiation purposes.  Such
loggers should be prefixed with 'gateone.app.' like so::

    >>> import logging
    >>> logger = logging.getLogger("gateone.app.myapp")

Additional loggers may be defined within a `GOApplication` with additional
prefixing::

    >>> xfer_log = logging.getLogger("gateone.app.myapp.xfer")
    >>> lookup_log = logging.getLogger("gateone.app.myapp.lookup")

.. note::

    This module does not cover session logging within the Terminal application.
    That is a built-in feature of the `termio` module.
"""

import os.path, sys, logging, json
from .utils import mkdir_p
from tornado.options import options
from tornado.log import LogFormatter

LOGS = set() # Holds a list of all our log paths so we can fix permissions
# These should match what's in the syslog module (hopefully not platform-dependent)
FACILITIES = {
    'auth': 32,
    'cron': 72,
    'daemon': 24,
    'kern': 0,
    'local0': 128,
    'local1': 136,
    'local2': 144,
    'local3': 152,
    'local4': 160,
    'local5': 168,
    'local6': 176,
    'local7': 184,
    'lpr': 48,
    'mail': 16,
    'news': 56,
    'syslog': 40,
    'user': 8,
    'uucp': 64
}

# Exceptions
class UnknownFacility(Exception):
    """
    Raised if `string_to_syslog_facility` is given a string that doesn't match
    a known syslog facility.
    """
    pass

class JSONAdapter(logging.LoggerAdapter):
    """
    A `logging.LoggerAdapter` that prepends keyword argument information to log
    entries.  Expects the passed in dict-like object which will be included.
    """
    def process(self, msg, kwargs):
        extra = self.extra.copy()
        if 'metadata' in kwargs:
            extra.update(kwargs.pop('metadata'))
        if extra:
            json_data = json.dumps(extra, sort_keys=True, ensure_ascii=False)
            line = u'{json_data} {msg}'.format(json_data=json_data, msg=msg)
        else:
            line = msg
        return (line, kwargs)

def string_to_syslog_facility(facility):
    """
    Given a string (*facility*) such as, "daemon" returns the numeric
    syslog.LOG_* equivalent.
    """
    if facility.lower() in FACILITIES:
        return FACILITIES[facility.lower()]
    else:
        raise UnknownFacility(
            "%s does not match a known syslog facility" % repr(facility))

def go_logger(name, **kwargs):
    """
    Returns a new `logging.Logger` instance using the given *name*
    pre-configured to match Gate One's usual logging output.  The given *name*
    will automatically be prefixed with 'gateone.' if it is not already.  So if
    *name* is 'app.foo' the `~logging.Logger` would end up named
    'gateone.app.foo'.  If the given *name* is already prefixed with 'gateone.'
    it will be left as-is.

    The log will be saved in the same location as Gate One's configured
    `log_file_prefix` using the given *name* with the following convention:

        ``gateone/logs/<modified *name*>.log``

    The file name will be modified like so:

        * It will have the 'gateone' portion removed (since it's redundant).
        * Dots will be replaced with dashes (-).

    Examples::

        >>> auth_logger = go_logger('gateone.auth.terminal')
        >>> auth_logger.info('test1')
        >>> app_logger = go_logger('gateone.app.terminal')
        >>> app_logger.info('test2')
        >>> import os
        >>> os.lisdir('/opt/gateone/logs')
        ['auth.log', 'auth-terminal.log', 'app-terminal.log' 'webserver.log']

    If any *kwargs* are given they will be JSON-encoded and included in the log
    message after the date/metadata like so::

        >>> auth_logger.info('test3', {"user": "bob", "ip": "10.1.1.100"})
        [I 130828 15:00:56 app.py:10] {"user": "bob", "ip": "10.1.1.100"} test3
    """
    logger = logging.getLogger(name)
    if '--help' in sys.argv:
        # Skip log file creation if the user is just getting help on the CLI
        return logger
    if not options.log_file_prefix or options.logging.upper() == 'NONE':
        # Logging is disabled but we still have to return the adapter so that
        # passing metadata to the logger won't throw exceptions
        return JSONAdapter(logger, kwargs)
    if name == None:
        # root logger; leave it alone
        LOGS.add(options.log_file_prefix)
        return logger
    # Remove any existing handlers on the logger
    logger.handlers = []
    logger.setLevel(getattr(logging, options.logging.upper()))
    if options.log_file_prefix:
        if name:
            basepath = os.path.split(options.log_file_prefix)[0]
            filename = name.replace('.', '-') + '.log'
            path = os.path.join(basepath, filename)
        else:
            path = options.log_file_prefix
            basepath = os.path.split(options.log_file_prefix)[0]
        if not os.path.isdir(basepath):
            mkdir_p(basepath)
        LOGS.add(path)
        channel = logging.handlers.RotatingFileHandler(
            filename=path,
            maxBytes=options.log_file_max_size,
            backupCount=options.log_file_num_backups)
        channel.setFormatter(LogFormatter(color=False))
        logger.addHandler(channel)
    logger = JSONAdapter(logger, kwargs)
    return logger

########NEW FILE########
__FILENAME__ = server
#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
#       Copyright 2013 Liftoff Software Corporation
#
# For license information see LICENSE.txt

# Meta
__version__ = '1.2.0'
__version_info__ = (1, 2, 0)
__license__ = "AGPLv3" # ...or proprietary (see LICENSE.txt)
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'
__commit__ = "20140516085214" # Gets replaced by git (holds the date/time)

# NOTE: Docstring includes reStructuredText markup for use with Sphinx.
__doc__ = '''\
.. _gateone.py:

Gate One
========
Gate One is a web-based terminal emulator written in Python using the Tornado
web framework.  This module runs the primary daemon process and acts as a
central controller for all running terminals and terminal programs.  It supports
numerous configuration options and can also be called with the --kill switch
to kill all running terminal programs (if using dtach--otherwise they die on
their own when gateone.py is stopped).

Dependencies
------------
Gate One requires Python 2.6+ but runs best with Python 2.7+.  It also depends
on the following 3rd party Python modules:

 * `Tornado <http://www.tornadoweb.org/>`_ 3.1+ - A non-blocking web server framework that powers FriendFeed.

The following modules are optional and can provide Gate One with additional
functionality:

 * `pyOpenSSL <https://launchpad.net/pyopenssl>`_ 0.10+ - An OpenSSL module/wrapper for Python.  Only used to generate self-signed SSL keys and certificates.  If pyOpenSSL isn't available Gate One will fall back to using the 'openssl' command to generate self-signed certificates.
 * `kerberos <http://pypi.python.org/pypi/kerberos>`_ 1.0+ - A high-level Kerberos interface for Python.  Only necessary if you plan to use the Kerberos authentication module.
 * `python-pam <http://packages.debian.org/lenny/python-pam>`_ 0.4.2+ - A Python module for interacting with PAM (the Pluggable Authentication Module present on nearly every Unix).  Only necessary if you plan to use PAM authentication.
 * `PIL (Python Imaging Library) <http://www.pythonware.com/products/pil/>`_ 1.1.7+ - A Python module for manipulating images.  **Alternative:** `Pillow <https://github.com/python-imaging/Pillow>`_ 2.0+ - A "friendly fork" of PIL that works with Python 3.
 * `mutagen <https://code.google.com/p/mutagen/>`_ 1.21+ - A Python module to handle audio metadata.  Makes it so that if you ``cat music_file.ogg`` in a terminal you'll get useful track/tag information.

With the exception of python-pam, all required and optional modules can usually be installed via one of these commands:

    .. ansi-block::

        \x1b[1;34muser\x1b[0m@modern-host\x1b[1;34m:~ $\x1b[0m sudo pip install --upgrade tornado pyopenssl kerberos pillow mutagen

...or:

    .. ansi-block::

        \x1b[1;34muser\x1b[0m@legacy-host\x1b[1;34m:~ $\x1b[0m sudo easy_install tornado pyopenssl kerberos pillow mutagen

.. note:: The use of pip is recommended.  See http://www.pip-installer.org/en/latest/installing.html if you don't have it.

The python-pam module is available in most Linux distribution repositories.  Simply executing one of the following should take care of it:

    .. ansi-block::

        \x1b[1;34muser\x1b[0m@debian-or-ubuntu-host\x1b[1;34m:~ $\x1b[0m sudo apt-get install python-pam

    .. ansi-block::

        \x1b[1;34muser\x1b[0m@redhat-host\x1b[1;34m:~ $\x1b[0m sudo yum install python-pam

    .. ansi-block::

        \x1b[1;34muser\x1b[0m@gentoo-host\x1b[1;34m:~ $\x1b[0m sudo emerge python-pam

    .. ansi-block::

        \x1b[1;34muser\x1b[0m@suse-host\x1b[1;34m:~ $\x1b[0m sudo yast -i python-pam

Settings
--------
Most of Gate One's options can be controlled by command line switches or via
.conf files in the settings directory.  If you haven't configured Gate One
before a number of .conf files will be automatically generated using defaults
and/or the command line switches provided the first time you run `gateone.py`.

Settings in the various `settings/*.conf` files are JSON-formatted:

.. note::

    Technically, JSON doesn't allow comments but Gate One's .conf files do.

.. code-block:: javascript

    { // You can use single-line comments like this
    /*
    Or multi-line comments like this.
    */
        "*": { // The * here designates this as "default" values
            "gateone": { // Settings in this dict are specific to the "gateone" app
                "address": "10.0.0.100", // A string value
                "log_file_num_backups": 10, // An integer value
                // Here's an example list:
                "origins": ["localhost", "127.0.0.1", "10.0.0.100"],
                "https_redirect": false, // Booleans are all lower case
                "log_to_stderr": null // Same as `None` in Python (also lower case)
                // NOTE: No comma after last item
            },
            "terminal": { // Example of a different application's settings
                "default_command": "SSH", // <-- don't leave traling commas like this!
                ... // So on and so forth
            }
        }
    }

.. note::

    You *must* use double quotes ("") to define strings.  Single quotes *can* be
    used inside double quotes, however.  `"example": "of 'single' quotes"`  To
    escape a double-quote inside a double quote use three slashes:
    `"\\\\\\\\\\\\"foo\\\\\\\\\\\\""`

.. All those slashes above are so Sphinx won't mangle it in HTML.

You can have as many .conf files in your settings directory as you like.  When
Gate One runs it reads all files in alphanumeric order and combines all settings
into a single Python dictionary.  Files loaded last will override settings from
earlier files.  Example:

.. topic:: 20example.conf

    .. code-block:: javascript

        {
            "*": {
                "terminal": {
                    "session_logging": true,
                    "default_command": "SSH"
                }
            }
        }

.. topic:: 99override.conf

    .. code-block:: javascript

        {
            "*": {
                "terminal": {
                    "default_command": "my_override"
                }
            }
        }

If Gate One loaded the above example .conf files the resulting dict would be:

.. topic:: Merged settings

    .. code-block:: javascript

        {
            "*": {
                "terminal": {
                    "session_logging": true,
                    "default_command": "my_override"
                }
            }
        }

.. note::

    These settings are loaded using the `~utils.RUDict` (Recusive Update Dict)
    class.

There are a few important differences between the configuration file and
command line switches in regards to boolean values (True/False).  A switch such
as `--debug` is equivalent to ``"debug" = true`` in 10server.conf:

.. code-block:: javascript

    "debug" = true // Booleans are all lower case (not in quotes)

.. tip::

    Use `--setting=True`, `--setting=False`, or `--setting=None` to avoid
    confusion.

.. note::

    The following values in 10server.conf are case sensitive: `true`, `false`
    and `null` (and should not be placed in quotes).

Running gateone.py with the `--help` switch will print the usage information as
well as descriptions of what each configurable option does:

.. ansi-block::

    \x1b[1;31mroot\x1b[0m@host\x1b[1;34m:~ $\x1b[0m gateone --help
    Usage: /usr/local/bin/gateone [OPTIONS]

    Options:

    --helpshow this help information

    /usr/local/lib/python2.7/dist-packages/tornado/log.py options:

    --log_file_max_sizemax size of log files before rollover
    (default 100000000)
    --log_file_num_backupsnumber of log files to keep (default 10)
    --log_file_prefix=PATHPath prefix for log files. Note that if you
    are running multiple tornado processes,
    log_file_prefix must be different for each
    of them (e.g. include the port number)
    --log_to_stderrSend log output to stderr (colorized if
    possible). By default use stderr if
    --log_file_prefix is not set and no other
    logging is configured.
    --logging=debug|info|warning|error|none
    Set the Python log level. If 'none', tornado
    won't touch the logging configuration.
    (default info)

    gateone options:

    --addressRun on the given address.  Default is all
    addresses (IPv6 included).  Multiple address
    can be specified using a semicolon as a
    separator (e.g. '127.0.0.1;::1;10.1.1.100').
    --api_keysThe 'key:secret,...' API key pairs you wish
    to use (only applies if using API
    authentication)
    --api_timestamp_windowHow long before an API authentication object
    becomes invalid.   (default 30s)
    --authAuthentication method to use.  Valid options
    are: none, api, google, ssl, kerberos, pam
    (default none)
    --ca_certsPath to a file containing any number of
    concatenated CA certificates in PEM format.
    They will be used to authenticate clients if
    the 'ssl_auth' option is set to 'optional'
    or 'required'.
    --cache_dirPath where Gate One should store temporary
    global files (e.g. rendered templates, CSS,
    JS, etc). (default /tmp/gateone_cache)
    --certificatePath to the SSL certificate.  Will be auto-
    generated if none is provided. (default
    /etc/gateone/ssl/certificate.pem)
    --combine_cssCombines all of Gate One's CSS Template
    files into one big file and saves it at the
    given path (e.g. gateone
    --combine_css=/tmp/gateone.css).
    --combine_css_containerUse this setting in conjunction with
    --combine_css if the <div> where Gate One
    lives is named something other than #gateone
    (default gateone)
    --combine_jsCombines all of Gate One's JavaScript files
    into one big file and saves it at the given
    path (e.g. gateone
    --combine_js=/tmp/gateone.js)
    --commandDEPRECATED: Use the 'commands' option in the
    terminal settings.
    --configDEPRECATED.  Use --settings_dir. (default
    /opt/gateone/server.conf)
    --cookie_secretUse the given 45-character string for cookie
    encryption.
    --debugEnable debugging features such as auto-
    restarting when files are modified. (default
    False)
    --disable_sslIf enabled, Gate One will run without SSL
    (generally not a good idea). (default False)
    --embeddedWhen embedding Gate One, this option is
    available to templates. (default False)
    --enable_unix_socketEnable Unix socket support. (default False)
    --gidDrop privileges and run Gate One as this
    group/gid. (default 0)
    --https_redirectIf enabled, a separate listener will be
    started on port 80 that redirects users to
    the configured port using HTTPS. (default
    False)
    --js_initA JavaScript object (string) that will be
    used when running GateOne.init() inside
    index.html.  Example: --js_init="{scheme:
    'white'}" would result in
    GateOne.init({scheme: 'white'})
    --keyfilePath to the SSL keyfile.  Will be auto-
    generated if none is provided. (default
    /etc/gateone/ssl/keyfile.pem)
    --localeThe locale (e.g. pt_PT) Gate One should use
    for translations.  If not provided, will
    default to $LANG (which is 'en_US' in your
    current shell), or en_US if not set.
    (default en_US)
    --new_api_keyGenerate a new API key that an external
    application can use to embed Gate One.
    (default False)
    --originsA semicolon-separated list of origins you
    wish to allow access to your Gate One server
    over the WebSocket.  This value must contain
    the hostnames and FQDNs (e.g. foo;foo.bar;)
    users will use to connect to your Gate One
    server as well as the hostnames/FQDNs of any
    sites that will be embedding Gate One.
    Alternatively, '*' may be  specified to
    allow access from anywhere. (default localho
    st;127.0.0.1;enterprise.lan;enterprise;local
    host;enterprise.lan;enterprise;enterprise.ex
    ample.com;127.0.0.1;10.1.1.100)
    --pam_realmBasic auth REALM to display when
    authenticating clients.  Default: hostname.
    Only relevant if PAM authentication is
    enabled. (default enterprise)
    --pam_servicePAM service to use.  Defaults to 'login'.
    Only relevant if PAM authentication is
    enabled. (default login)
    --pid_fileDefine the path to the pid file.  Default:
    /var/run/gateone.pid (default
    /var/run/gateone.pid)
    --portRun on the given port. (default 443)
    --session_dirPath to the location where session
    information will be stored. (default
    /tmp/gateone)
    --session_timeoutAmount of time that a session is allowed to
    idle before it is killed.  Accepts <num>X
    where X could be one of s, m, h, or d for
    seconds, minutes, hours, and days.  Set to
    '0' to disable the ability to resume
    sessions. (default 5d)
    --settings_dirPath to the settings directory. (default
    /etc/gateone/conf.d)
    --ssl_authEnable the use of client SSL (X.509)
    certificates as a secondary authentication
    factor (the configured 'auth' type will come
    after SSL auth).  May be one of 'none',
    'optional', or 'required'.  NOTE: Only works
    if the 'ca_certs' option is configured.
    (default none)
    --sso_realmKerberos REALM (aka DOMAIN) to use when
    authenticating clients. Only relevant if
    Kerberos authentication is enabled.
    --sso_serviceKerberos service (aka application) to use.
    Defaults to HTTP. Only relevant if Kerberos
    authentication is enabled. (default HTTP)
    --syslog_facilitySyslog facility to use when logging to
    syslog (if syslog_session_logging is
    enabled).  Must be one of: auth, cron,
    daemon, kern, local0, local1, local2,
    local3, local4, local5, local6, local7, lpr,
    mail, news, syslog, user, uucp. (default
    daemon)
    --uidDrop privileges and run Gate One as this
    user/uid. (default 0)
    --unix_socket_pathPath to the Unix socket (if
    --enable_unix_socket=True). (default
    /tmp/gateone.sock)
    --url_prefixAn optional prefix to place before all Gate
    One URLs. e.g. '/gateone/'.  Use this if
    Gate One will be running behind a reverse
    proxy where you want it to be located at
    some sub-URL path. (default /)
    --user_dirPath to the location where user files will
    be stored. (default /var/lib/gateone/users)
    --user_logs_max_ageMaximum amount of length of time to keep any
    given user log before it is removed.
    (default 30d)
    --version                        Display version information.

    terminal options:

    --dtachWrap terminals with dtach. Allows sessions
    to be resumed even if Gate One is stopped
    and started (which is a sweet feature).
    (default True)
    --killKill any running Gate One terminal processes
    including dtach'd processes. (default False)
    --session_loggingIf enabled, logs of user sessions will be
    saved in <user_dir>/<user>/logs.  Default:
    Enabled (default True)
    --syslog_session_loggingIf enabled, logs of user sessions will be
    written to syslog. (default False)

    x11 options:

    --xorg_confIf provided, will use the specified
    xorg.conf file when spawning instances of
    Xorg. (default /etc/gateone/x11/xorg.conf)

.. note::

    Some of these options (e.g. log_file_prefix) are inherent to the
    Tornado framework.  You won't find them anywhere in gateone.py.

File Paths
----------
Gate One stores its files, temporary session information, and persistent user
data in the following locations (Note: Many of these are configurable):

==================  ==========================================================================================
File/Directory      Description
==================  ==========================================================================================
authpam.py          Contains the PAM authentication Mixin used by auth.py.
auth.py             Authentication classes.
babel_gateone.cfg   Pybabel configuration for generating localized translations of Gate One's strings.
certificate.pem     The default certificate Gate One will use in SSL communications.
docs/               Gate One's documentation.
gateone.py          Gate One's primary executable/script. Also, the file containing this documentation.
gopam.py            PAM (Authentication) Python module (used by authpam.py).
i18n/               Gate One's internationalization (i18n) support and locale/translation files.
keyfile.pem         The default private key used with SSL communications.
logviewer.py        A utility to view Gate One session logs.
plugins/            (Global) Plugins go here in the form of ./plugins/<plugin name>/<plugin files|directories>
settings/           All Gate One settings files live here (.conf files).
sso.py              A Kerberos Single Sign-on module for Tornado (used by auth.py)
static/             Non-dynamic files that get served to clients (e.g. gateone.js, gateone.css, etc).
templates/          Tornado template files such as index.html.
tests/              Various scripts and tools to test Gate One's functionality.
utils.py            Various supporting functions.
users/              Persistent user data in the form of ./users/<username>/<user-specific files>
users/<user>/logs   This is where session logs get stored if session_logging is set.
/tmp/gateone        Temporary session data in the form of /tmp/gateone/<session ID>/<files>
/tmp/gateone_cache  Used to store cached files such as minified JavaScript and CSS.
==================  ==========================================================================================

Running
-------
Executing Gate One is as simple as:

.. ansi-block::

    \x1b[1;31mroot\x1b[0m@host\x1b[1;34m:~ $\x1b[0m gateone

.. note::

    By default Gate One will run on port 443 which requires root on most
    systems.  Use `--port=(something higher than 1024)` for non-root users.

Applications and Plugins
------------------------
Gate One supports both *applications* and *plugins*.  The difference is mostly
architectural.  Applications go in the `gateone/applications` directory while
(global) plugins reside in `gateone/plugins`.  The scope of application code
applies only to the application wheras global Gate One plugin code will apply
to Gate One itself and all applications.

.. note:: Applications may have plugins of their own (e.g. terminal/plugins).

Gate One applications and plugins can be written using any combination of the
following:

 * Python
 * JavaScript
 * CSS

Applications and Python plugins can integrate with Gate One in a number ways:

 * Adding or overriding request handlers to provide custom URLs (with a given regex).
 * Adding or overriding methods in `GOApplication` to handle asynchronous WebSocket "actions".
 * Adding or overriding events via the :meth:`on`, :meth:`off`, :meth:`once`, and :meth:`trigger` functions.
 * Delivering custom content to clients (e.g. JavaScript and CSS templates).

JavaScript and CSS plugins will be delivered over the WebSocket and cached at
the client by way of a novel synchronization mechanism.  Once JavaScript and CSS
assets have been delivered they will only ever have to be re-delivered to
clients if they have been modified (on the server).  This mechanism is extremely
bandwidth efficient and should allow clients to load Gate One content much more
quickly than traditional HTTP GET requests.

.. tip::

    If you install the `cssmin` and/or `slimit` Python modules all JavaScript
    and CSS assets will be automatically minified before being delivered to
    clients.

Class Docstrings
================
'''

# Standard library modules
import os
import sys
import re
import io
import logging
import time
import socket
import pty
import atexit
import ssl
import hashlib
from functools import partial
from datetime import datetime, timedelta
try:
    from urlparse import urlparse
except ImportError: # Python 3.X
    from urllib import parse as urlparse

# This is used as a way to ensure users get a friendly message about missing
# dependencies:
MISSING_DEPS = []
# This is needed before other globals for certain checks:
from gateone import GATEONE_DIR

tornado_version = "" # Placeholder in case Tornado import fails below

# Tornado modules (yeah, we use all this stuff)
try:
    import tornado.httpserver
    import tornado.ioloop
    import tornado.options
    import tornado.web
    import tornado.log
    import tornado.auth
    import tornado.template
    import tornado.netutil
    from tornado.websocket import WebSocketHandler, WebSocketClosedError
    from tornado.escape import json_decode
    from tornado.options import options
    from tornado import locale
    from tornado import version as tornado_version
    from tornado import version_info as tornado_version_info
except (ImportError, NameError):
    MISSING_DEPS.append('tornado >= 3.2')

if 'tornado >= 3.2' not in MISSING_DEPS:
    if tornado_version_info[0] < 3:
        MISSING_DEPS.append('tornado >= 3.2')
    if tornado_version_info[0] < 3 and tornado_version_info[1] < 2:
        MISSING_DEPS.append('tornado >= 3.2')

if MISSING_DEPS:
    print("\x1b[31;1mERROR:\x1b[0m: This host is missing dependencies:")
    for dep in MISSING_DEPS:
        print("    %s" % dep)
    modules = [a.split()[0] for a in MISSING_DEPS]
    print("\x1b[1m  sudo pip install --upgrade %s\x1b[0m." %
        ' '.join(MISSING_DEPS))
    sys.exit(1)

# We want this turned on right away
tornado.log.enable_pretty_logging()

# Our own modules
from gateone import SESSIONS, PERSIST
from gateone.auth.authentication import NullAuthHandler, KerberosAuthHandler
from gateone.auth.authentication import GoogleAuthHandler, APIAuthHandler
from gateone.auth.authentication import CASAuthHandler, PAMAuthHandler
from gateone.auth.authentication import SSLAuthHandler
from gateone.auth.authorization import require, authenticated, policies
from gateone.auth.authorization import applicable_policies
from .utils import generate_session_id, mkdir_p, touch
from .utils import gen_self_signed_ssl, get_plugins, load_modules
from .utils import merge_handlers, none_fix, convert_to_timedelta, short_hash
from .utils import json_encode, recursive_chown, ChownError, get_or_cache
from .utils import write_pid, read_pid, remove_pid, drop_privileges
from .utils import check_write_permissions, get_applications, valid_hostname
from .utils import total_seconds, MEMO
from .configuration import apply_cli_overrides, define_options, SettingsError
from .configuration import get_settings
from onoff import OnOffMixin

# Setup our base loggers (these get overwritten in main())
from gateone.core.log import go_logger, LOGS
logger = go_logger(None)
auth_log = go_logger('gateone.auth')
msg_log = go_logger('gateone.message')
client_log = go_logger('gateone.client')

# Setup the locale functions before anything else
locale.set_default_locale('en_US')
user_locale = None # Replaced with the actual user locale object in __main__
def _(string):
    """
    Wraps user_locale.translate so we don't get errors if loading a locale fails
    (or we output a message before it is initialized).
    """
    if user_locale:
        return user_locale.translate(string)
    else:
        return string

from gateone.async import MultiprocessRunner, ThreadedRunner
try:
    CPU_ASYNC = MultiprocessRunner()
except NotImplementedError:
    # System doesn't support multiprocessing (for whatever reason).
    CPU_ASYNC = ThreadedRunner() # Fake it using threads
IO_ASYNC = ThreadedRunner()

# Globals
CMD = None # Will be overwritten by options.command
TIMEOUT = timedelta(days=5) # Gets overridden by options.session_timeout
# SESSION_WATCHER be replaced with a tornado.ioloop.PeriodicCallback that
# watches for sessions that have timed out and takes care of cleaning them up.
SESSION_WATCHER = None
CLEANER = None # Log and leftover session data cleaner PeriodicCallback
FILE_CACHE = {}
APPLICATIONS = {}
PLUGINS = {}
PLUGIN_WS_CMDS = {} # Gives plugins the ability to extend/enhance ApplicationWebSocket
PLUGIN_HOOKS = {} # Gives plugins the ability to hook into various things.
PLUGIN_AUTH_HOOKS = [] # For plugins to register functions to be called after a
                       # user successfully authenticates
PLUGIN_ENV_HOOKS = {} # Allows plugins to add environment variables that will be
                      # available to all executed commands.
# Gate One registers a handler for for terminal.py's CALLBACK_OPT special escape
# sequence callback.  Whenever this escape sequence is encountered, Gate One
# will parse the sequence's contained characters looking for the following
# format:
#   <plugin name>|<whatever>
# The <whatever> part will be passed to any plugin matching <plugin name> if the
# plugin has 'Escape': <function> registered in its hooks.
PLUGIN_ESC_HANDLERS = {}
# This is used to store plugin terminal hooks that are called when a new
# terminal is created (so a plugin could override/attach callbacks to the
# multiplex or terminal emulator instances).  NOTE: This is specifically for
# adding to the terminal emulator's CALLBACK_* capability.  For modifying the
# terminal emulator instance directly see PLUGIN_NEW_TERM_HOOKS.
PLUGIN_TERM_HOOKS = {}
# The NEW_TERM hooks are called at the end of ApplicationWebSocket.new_terminal()
# with 'self' and the new instance of the terminal emulator as the only
# arguments.  It's a more DIY/generic version of PLUGIN_TERM_HOOKS.
PLUGIN_NEW_TERM_HOOKS = []
# 'Command' hooks get called before a new Multiplex instance is created inside
# of ApplicationWebSocket.new_multiplex().  They are passed the 'command' and must
# return a string that will be used as the replacement 'command'.  This allows
# plugin authors to modify the configured 'command' before it is executed
PLUGIN_COMMAND_HOOKS = []
# 'Multiplex' hooks get called at the end of ApplicationWebSocket.new_multiplex()
# with the instance of ApplicationWebSocket and the new instance of Multiplex as
# the only arguments, respectively.
PLUGIN_NEW_MULTIPLEX_HOOKS = []

# Secondary locale setup
locale_dir = os.path.join(GATEONE_DIR, 'i18n')
locale.load_gettext_translations(locale_dir, 'gateone')
# NOTE: The locale gets set in __main__

def cleanup_user_logs():
    """
    Cleans up all user logs (everything in the user's 'logs' directory and
    subdirectories that ends in 'log') older than the `user_logs_max_age`
    setting.  The log directory is assumed to be:

        *user_dir*/<user>/logs

    ...where *user_dir* is whatever Gate One happens to have configured for
    that particular setting.
    """
    logging.debug("cleanup_user_logs()")
    disabled = timedelta(0) # If the user sets user_logs_max_age to "0"
    settings = get_settings(options.settings_dir)
    user_dir = settings['*']['gateone']['user_dir']
    if 'user_dir' in options: # NOTE: options is global
        user_dir = options.user_dir
    default = "30d"
    max_age_str = settings['*']['gateone'].get('user_logs_max_age', default)
    if 'user_logs_max_age' in list(options):
        max_age_str = options.user_logs_max_age
    max_age = convert_to_timedelta(max_age_str)
    def descend(path):
        """
        Descends *path* removing logs it finds older than `max_age` and calls
        :func:`descend` on any directories.
        """
        for fname in os.listdir(path):
            log_path = os.path.join(path, fname)
            if os.path.isdir(log_path):
                descend(log_path)
                continue
            if not log_path.endswith('log'):
                continue
            mtime = time.localtime(os.stat(log_path).st_mtime)
            # Convert to a datetime object for easier comparison
            mtime = datetime.fromtimestamp(time.mktime(mtime))
            if datetime.now() - mtime > max_age:
                # The log is older than max_age, remove it
                logger.info(_("Removing log due to age (>%s old): %s" % (
                    max_age_str, log_path)))
                os.remove(log_path)
    if max_age != disabled:
        for user in os.listdir(user_dir):
            logs_path = os.path.abspath(os.path.join(user_dir, user, 'logs'))
            if not os.path.exists(logs_path):
                # Nothing to do
                continue
            descend(logs_path)

def cleanup_old_sessions():
    """
    Cleans up old session directories inside the `session_dir`.  Any directories
    found that are older than the `auth_timeout` (global gateone setting) will
    be removed.  The modification time is what will be checked.
    """
    logging.debug("cleanup_old_sessions()")
    disabled = timedelta(0) # If the user sets auth_timeout to "0"
    settings = get_settings(options.settings_dir)
    expiration_str = settings['*']['gateone'].get('auth_timeout', "14d")
    expiration = convert_to_timedelta(expiration_str)
    if expiration != disabled:
        for session in os.listdir(options.session_dir):
            # If it's in the SESSIONS dict it's still valid for sure
            if session not in SESSIONS:
                if len(session) != 45:
                    # Sessions are always 45 characters long.  This check allows
                    # us to skip the 'broadcast' file which also lives in the
                    # session_dir.  Why not just check for 'broacast'?  Just in
                    # case we put something else there in the future.
                    continue
                session_path = os.path.join(options.session_dir, session)
                mtime = time.localtime(os.stat(session_path).st_mtime)
                # Convert to a datetime object for easier comparison
                mtime = datetime.fromtimestamp(time.mktime(mtime))
                if datetime.now() - mtime > expiration:
                    import shutil
                    from .utils import kill_session_processes
                    # The log is older than expiration, remove it and kill any
                    # processes that may be remaining.
                    kill_session_processes(session)
                    logger.info(_(
                        "Removing old session files due to age (>%s old): %s" %
                        (expiration_str, session_path)))
                    shutil.rmtree(session_path, ignore_errors=True)

def clean_up():
    """
    Regularly called via the `CLEANER` `~torando.ioloop.PeriodicCallback`, calls
    `cleanup_user_logs` and `cleanup_old_sessions`.

    .. note::

        How often this function gets called can be controlled by adding a
        `cleanup_interval` setting to 10server.conf ('gateone' section).
    """
    cleanup_user_logs()
    cleanup_old_sessions()

def policy_send_user_message(cls, policy):
    """
    Called by :func:`gateone_policies`, returns True if the user is
    authorized to send messages to other users and if applicable, all users
    (broadcasts).
    """
    error_msg = _("You do not have permission to send messages to %s.")
    try:
        upn = cls.f_args[0]['upn']
    except (KeyError, IndexError):
        # send_user_message got bad *settings*.  Deny
        return False
    # TODO: Add a mechanism that allows users to mute other users here.
    if upn == 'AUTHENTICATED':
        cls.error = error_msg % "all users at once"
    else:
        cls.error = error_msg % upn
    return policy.get('send_user_messages', True)

def policy_broadcast(cls, policy):
    """
    Called by :func:`gateone_policies`, returns True if the user is
    authorized to broadcast messages using the
    :meth:`ApplicationWebSocket.broadcast` method.  It makes this determination
    by checking the `['gateone']['send_broadcasts']` policy.
    """
    cls.error = _("You do not have permission to broadcast messages.")
    return policy.get('send_broadcasts', False) # Default deny

def policy_list_users(cls, policy):
    """
    Called by :func:`gateone_policies`, returns True if the user is
    authorized to retrieve a list of the users currently connected to the Gate
    One server via the :meth:`ApplicationWebSocket.list_server_users` method.
    It makes this determination by checking the `['gateone']['list_users']`
    policy.
    """
    cls.error = _("You do not have permission to list connected users.")
    return policy.get('list_users', True)

def gateone_policies(cls):
    """
    This function gets registered under 'gateone' in the
    :attr:`ApplicationWebSocket.security` dict and is called by the
    :func:`require` decorator by way of the :class:`policies` sub-function. It
    returns True or False depending on what is defined in the settings dir and
    what function is being called.

    This function will keep track of and place limits on the following:

        * Who can send messages to other users (including broadcasts).
        * Who can retrieve a list of connected users.
    """
    instance = cls.instance # ApplicationWebSocket instance
    function = cls.function # Wrapped function
    #f_args = cls.f_args     # Wrapped function's arguments
    #f_kwargs = cls.f_kwargs # Wrapped function's keyword arguments
    policy_functions = {
        'send_user_message': policy_send_user_message,
        'broadcast': policy_broadcast,
        'list_server_users': policy_list_users
    }
    user = instance.current_user
    policy = applicable_policies('gateone', user, instance.ws.policies)
    if not policy: # Empty RUDict
        return True # A world without limits!
    if function.__name__ in policy_functions:
        return policy_functions[function.__name__](cls, policy)
    return True # Default to permissive if we made it this far

@atexit.register # I love this feature!
def kill_all_sessions(timeout=False):
    """
    Calls all 'kill_session_callbacks' attached to all `SESSIONS`.

    If *timeout* is ``True``, emulate a session timeout event in order to
    *really* kill any user sessions (to ensure things like dtach processes get
    killed too).
    """
    logging.debug(_("Killing all sessions..."))
    for session in list(SESSIONS.keys()):
        if timeout:
            if "timeout_callbacks" in SESSIONS[session]:
                if SESSIONS[session]["timeout_callbacks"]:
                    for callback in SESSIONS[session]["timeout_callbacks"]:
                        callback(session)
        else:
            if "kill_session_callbacks" in SESSIONS[session]:
                if SESSIONS[session]["kill_session_callbacks"]:
                    for callback in SESSIONS[session]["kill_session_callbacks"]:
                        callback(session)

@atexit.register
def shutdown_async():
    """
    Shuts down our asynchronous processes/threads.  Specifically, calls
    ``CPU_ASYNC.shutdown()`` and ``IO_ASYNC.shutdown()``.
    """
    logging.debug(_("Shutting down asynchronous processes/threads..."))
    CPU_ASYNC.shutdown(wait=False)
    IO_ASYNC.shutdown(wait=False)

def timeout_sessions():
    """
    Loops over the SESSIONS dict killing any sessions that haven't been used
    for the length of time specified in *TIMEOUT* (global).  The value of
    *TIMEOUT* can be set in 10server.conf or specified on the command line via
    the *session_timeout* value.

    Applications and plugins can register functions to be called when a session
    times out by attaching them to the user's session inside the `SESSIONS`
    dict under 'timeout_callbacks'.  The best place to do this is inside of the
    application's `authenticate()` function or by attaching them to the
    `go:authenticate` event.  Examples::

        # Imagine this is inside an application's authenticate() method:
        sess = SESSIONS[self.ws.session]
        # Pretend timeout_session() is a function we wrote to kill stuff
        if timeout_session not in sess["timeout_session"]:
            sess["timeout_session"].append(timeout_session)

    .. note::

        This function is meant to be called via Tornado's
        :meth:`~tornado.ioloop.PeriodicCallback`.
    """
    disabled = timedelta(0) # If the user sets session_timeout to "0"
    # Commented because it is a bit noisy.  Uncomment to debug this mechanism.
    #if TIMEOUT != disabled:
        #logging.debug("timeout_sessions() TIMEOUT: %s" % TIMEOUT)
    #else :
        #logging.debug("timeout_sessions() TIMEOUT: disabled")
    try:
        if not SESSIONS: # Last client has timed out
            logger.info(_("All user sessions have terminated."))
            global SESSION_WATCHER
            if SESSION_WATCHER:
                SESSION_WATCHER.stop() # Stop ourselves
                SESSION_WATCHER = None # So authenticate() will know to start it
            # Reload gateone.py to free up memory (CPython can be a bit
            # overzealous in keeping things cached).  In theory this isn't
            # necessary due to Gate One's prodigous use of dynamic imports but
            # in reality people will see an idle gateone.py eating up 30 megs of
            # RAM and wonder, "WTF...  No one has connected in weeks."
            logger.info(_("The last idle session has timed out. Reloading..."))
            try:
                os.execv(sys.executable, [sys.executable] + sys.argv)
            except OSError:
                # Mac OS X versions prior to 10.6 do not support execv in
                # a process that contains multiple threads.
                os.spawnv(os.P_NOWAIT, sys.executable,
                    [sys.executable] + sys.argv)
                sys.exit(0)
        for session in list(SESSIONS.keys()):
            if "last_seen" not in SESSIONS[session]:
                # Session is in the process of being created.  We'll check it
                # the next time timeout_sessions() is called.
                continue
            if SESSIONS[session]["last_seen"] == 'connected':
                # Connected sessions do not need to be checked for timeouts
                continue
            if TIMEOUT == disabled or \
                datetime.now() > SESSIONS[session]["last_seen"] + TIMEOUT:
                # Kill the session
                logger.info(_("{session} timeout.".format(session=session)))
                if "timeout_callbacks" in SESSIONS[session]:
                    if SESSIONS[session]["timeout_callbacks"]:
                        for callback in SESSIONS[session]["timeout_callbacks"]:
                            callback(session)
                del SESSIONS[session]
    except Exception as e:
        logger.error(_(
            "Exception encountered in timeout_sessions(): {exception}".format(
                exception=e)
        ))
        import traceback
        traceback.print_exc(file=sys.stdout)

# Classes
class StaticHandler(tornado.web.StaticFileHandler):
    """
    An override of :class:`tornado.web.StaticFileHandler` to ensure that the
    Access-Control-Allow-Origin header gets set correctly.  This is necessary in
    order to support embedding Gate One into other web-based applications.

    .. note::

        Gate One performs its own origin checking so header-based access
        controls at the client are unnecessary.
    """
    # This is the only function we need to override thanks to the thoughtfulness
    # of the Tornado devs.
    def set_extra_headers(self, path):
        """
        Adds the Access-Control-Allow-Origin header to allow cross-origin
        access to static content for applications embedding Gate One.
        Specifically, this is necessary in order to support loading fonts
        from different origins.

        Also sets the 'X-UA-Compatible' header to 'IE=edge' to enforce IE 10+
        into standards mode when content is loaded from intranet sites.
        """
        self.set_header('X-UA-Compatible', 'IE=edge')
        # Allow access to our static content from any page:
        self.set_header('Access-Control-Allow-Origin', '*')
        self.set_header('Server', 'GateOne')
        self.set_header('License', __license__)

    def options(self, path=None):
        """
        Replies to OPTIONS requests with the usual stuff (200 status, Allow
        header, etc).  Since this is just the static file handler we don't
        include any extra information.
        """
        self.set_status(200)
        self.set_header('Access-Control-Allow-Origin', '*')
        self.set_header('Allow', 'HEAD,GET,POST,OPTIONS')
        self.set_header('Server', 'GateOne')
        self.set_header('License', __license__)

class BaseHandler(tornado.web.RequestHandler):
    """
    A base handler that all Gate One RequestHandlers will inherit methods from.

    Provides the :meth:`get_current_user` method, sets default headers, and
    provides a default :meth:`options` method that can be used for monitoring
    purposes and also for enumerating useful information about this Gate One
    server (see below for more info).
    """
    def set_default_headers(self):
        """
        An override of :meth:`tornado.web.RequestHandler.set_default_headers`
        (which is how Tornado wants you to set default headers) that
        adds/overrides the following headers:

            :Server: 'GateOne'
            :X-UA-Compatible: 'IE=edge' (forces IE 10+ into Standards mode)
        """
        # Force IE 10 into Standards Mode:
        self.set_header('X-UA-Compatible', 'IE=edge')
        self.set_header('Server', 'GateOne')
        self.set_header('License', __license__)

    def get_current_user(self):
        """Tornado standard method--implemented our way."""
        # NOTE: self.current_user is actually an @property that calls
        #       self.get_current_user() and caches the result.
        expiration = self.settings.get('auth_timeout', "14d")
        # Need the expiration in days (which is a bit silly but whatever):
        expiration = (
            float(total_seconds(convert_to_timedelta(expiration)))
            / float(86400))
        user_json = self.get_secure_cookie(
            "gateone_user", max_age_days=expiration)
        if user_json:
            user = json_decode(user_json)
            user['ip_address'] = self.request.remote_ip
            if user and 'upn' not in user:
                return None
            return user

    def options(self, path=None):
        """
        Replies to OPTIONS requests with the usual stuff (200 status, Allow
        header, etc) but also includes some useful information in the response
        body that lists which authentication API features we support in
        addition to which applications are installed.  The response body is
        conveniently JSON-encoded:

        .. ansi-block::

            \x1b[1;34muser\x1b[0m@modern-host\x1b[1;34m:~ $\x1b[0m curl -k \
            -X OPTIONS https://gateone.company.com/ | python -mjson.tool
            % Total% Received % XferdAverage SpeedTimeTimeTimeCurrent
            DloadUploadTotalSpentLeftSpeed
            1001581001580067930 --:--:-- --:--:-- --:--:--7181
            {
            "applications": [
            "File Transfer",
            "Terminal",
            "X11"
            ],
            "auth_api": {
            "hmacs": [
            "HMAC-SHA1",
            "HMAC-SHA256",
            "HMAC-SHA384",
            "HMAC-SHA512"
            ],
            "versions": [
            "1.0"
            ]
            }
            }

        .. note::

            The 'Server' header does not supply the version information.  This
            is intentional as it amounts to an unnecessary information
            disclosure.  We don't need to make an attacker's job any easier.
        """
        settings = get_settings(options.settings_dir)
        enabled_applications = settings['*']['gateone'].get(
            'enabled_applications', [])
        if not enabled_applications:
            # List all installed apps
            for app in APPLICATIONS:
                enabled_applications.append(app.name.lower())
        self.set_status(200)
        self.set_header('Access-Control-Allow-Origin', '*')
        self.set_header('Allow', 'HEAD,GET,POST,OPTIONS')
        self.set_header('License', __license__)
        features_dict = {
            "auth_api": {
                'versions': ['1.0'],
                'hmacs': [
                    'HMAC-SHA1', 'HMAC-SHA256', 'HMAC-SHA384', 'HMAC-SHA512']
            },
            "applications": enabled_applications
        }
        self.write(features_dict)

class HTTPSRedirectHandler(BaseHandler):
    """
    A handler to redirect clients from HTTP to HTTPS.  Only used if
    `https_redirect` is True in Gate One's settings.
    """
    def get(self):
        """Just redirects the client from HTTP to HTTPS"""
        port = self.settings['port']
        url_prefix = self.settings['url_prefix']
        host = self.request.headers.get('Host', 'localhost')
        self.redirect(
            'https://%s:%s%s' % (host, port, url_prefix))

class DownloadHandler(BaseHandler):
    """
    A :class:`tornado.web.RequestHandler` to serve up files that wind up in a
    given user's `session_dir` in the 'downloads' directory.  Generally speaking
    these files are generated by the terminal emulator (e.g. cat somefile.pdf)
    but it can be used by applications and plugins as a way to serve up
    all sorts of (temporary/transient) files to users.
    """
    # NOTE:  This is a modified version of torando.web.StaticFileHandler
    @tornado.web.authenticated
    def get(self, path, include_body=True):
        session_dir = self.settings['session_dir']
        user = self.current_user
        if user and 'session' in user:
            session = user['session']
        else:
            logger.error(_("DownloadHandler: Could not determine use session"))
            return # Something is wrong
        filepath = os.path.join(session_dir, session, 'downloads', path)
        abspath = os.path.abspath(filepath)
        if not os.path.exists(abspath):
            self.set_status(404)
            self.write(self.get_error_html(404))
            return
        if not os.path.isfile(abspath):
            raise tornado.web.HTTPError(403, "%s is not a file", path)
        import stat, mimetypes
        stat_result = os.stat(abspath)
        modified = datetime.fromtimestamp(stat_result[stat.ST_MTIME])
        self.set_header("Last-Modified", modified)
        mime_type, encoding = mimetypes.guess_type(abspath)
        if mime_type:
            self.set_header("Content-Type", mime_type)
        # Set the Cache-Control header to private since this file is not meant
        # to be public.
        self.set_header("Cache-Control", "private")
        # Add some additional headers
        self.set_header('Access-Control-Allow-Origin', '*')
        # Check the If-Modified-Since, and don't send the result if the
        # content has not been modified
        ims_value = self.request.headers.get("If-Modified-Since")
        if ims_value is not None:
            import email.utils
            date_tuple = email.utils.parsedate(ims_value)
            if_since = datetime.fromtimestamp(time.mktime(date_tuple))
            if if_since >= modified:
                self.set_status(304)
                return
        # Finally, deliver the file
        with io.open(abspath, "rb") as file:
            data = file.read()
            hasher = hashlib.sha1()
            hasher.update(data)
            self.set_header("Etag", '"%s"' % hasher.hexdigest())
            if include_body:
                self.write(data)
            else:
                assert self.request.method == "HEAD"
                self.set_header("Content-Length", len(data))

    def get_error_html(self, status_code, **kwargs):
        self.require_setting("static_url")
        if status_code in [404, 500, 503, 403]:
            filename = os.path.join(self.settings['static_url'], '%d.html' % status_code)
            if os.path.exists(filename):
                with io.open(filename, 'r') as f:
                    data = f.read()
                return data
        import httplib
        return "<html><title>%(code)d: %(message)s</title>" \
                "<body class='bodyErrorPage'>%(code)d: %(message)s</body></html>" % {
            "code": status_code,
            "message": httplib.responses[status_code],
        }

class MainHandler(BaseHandler):
    """
    Renders index.html which loads Gate One.

    Will include the minified version of gateone.js if available as
    gateone.min.js.
    """
    @tornado.web.authenticated
    @tornado.web.addslash
    # TODO: Get this auto-minifying gateone.js
    def get(self):
        # Set our server header so it doesn't say TornadoServer/<version>
        hostname = os.uname()[1]
        location = self.get_argument("location", "default")
        prefs = self.get_argument("prefs", None)
        gateone_js = "%sstatic/gateone.js" % self.settings['url_prefix']
        minified_js_abspath = os.path.join(GATEONE_DIR, 'static')
        minified_js_abspath = os.path.join(
            minified_js_abspath, 'gateone.min.js')
        js_init = self.settings['js_init']
        # Use the minified version if it exists
        if options.logging.lower() != 'debug':
            if os.path.exists(minified_js_abspath):
                gateone_js = (
                    "%sstatic/gateone.min.js" % self.settings['url_prefix'])
        template_path = os.path.join(GATEONE_DIR, 'templates')
        index_path = os.path.join(template_path, 'index.html')
        head_html = ""
        body_html = ""
        for plugin, hooks in PLUGIN_HOOKS.items():
            if 'HTML' in hooks:
                if 'head' in hooks['HTML']:
                    if hooks['HTML']['head']:
                        for item in hooks['HTML']['head']:
                            head_html += "%s\n" % item
                if 'body' in hooks['HTML']:
                    if hooks['HTML']['body']:
                        for item in hooks['HTML']['body']:
                            body_html += "%s\n" % item
        self.render(
            index_path,
            hostname=hostname,
            gateone_js=gateone_js,
            location=location,
            js_init=js_init,
            url_prefix=self.settings['url_prefix'],
            head=head_html,
            body=body_html,
            prefs=prefs
        )

class GOApplication(OnOffMixin):
    """
    The base from which all Gate One Applications will inherit.  Applications
    are expected to be written like so::

        class SomeApplication(GOApplication):
            def initialize(self):
                "Called when the Application is instantiated."
                initialize_stuff()
                # Here's some good things to do in an initialize() function...
                # Register a policy-checking function:
                self.ws.security.update({'some_app': policy_checking_func})
                # Register some WebSocket actions (note the app:action naming convention)
                self.ws.actions.update({
                    'some_app:do_stuff': self.do_stuff,
                    'some_app:do_other_stuff': self.do_other_stuff
                })
            def open(self):
                "Called when the connection is established."
                # Setup whatever is necessary for session tracking and whatnot.
            def authenticate(self):
                "Called when the user *successfully* authenticates."
                # Here's the best place to instantiate things, send the user
                # JavaScript/CSS files, and similar post-authentication details.
            def on_close(self):
                "Called when the connection is closed."
                # This is a good place to halt any background/periodic operations.

    GOApplications will be automatically imported into Gate One and registered
    appropriately as long as they follow the following conventions:

        * The application and its module(s) should live inside its own directory inside the 'applications' directory.  For example, `/opt/gateone/applications/some_app/some_app.py`
        * Subclasses of `GOApplication` must be added to an `apps` global (list) inside of the application's module(s) like so: `apps = [SomeApplication]` (usually a good idea to put that at the very bottom of the module).

    .. note::

        All .py modules inside of the application's main directory will be
        imported even if they do not contain or register a `GOApplication`.

    .. tip::

        You can add command line arguments to Gate One by calling
        :func:`tornado.options.define` anywhere in your application's global
        namespace.  This works because the :func:`~tornado.options.define`
        function registers options in Gate One's global namespace (as
        `tornado.options.options`) and Gate One imports application modules
        before it evaluates command line arguments.
    """
    # You'll want to override these values in your own app:
    info = {
        'name': "Unknown App",
        'description': (
            "The application developer has yet to provide a description.")
    }
    # NOTE: The above 'info' dict will be sent to the client.
    # NOTE: The icon value will be replaced with the actual icon data.
    def __init__(self, ws):
        self.ws = ws # WebSocket instance
        self.current_user = ws.current_user
        # Setup some shortcuts to make things more natural and convenient
        self.write_message = ws.write_message
        self.write_binary = ws.write_binary
        self.render_and_send_css = ws.render_and_send_css
        self.render_style = ws.render_style
        self.send_css = ws.send_css
        self.send_js = ws.send_js
        self.close = ws.close
        self.security = ws.security
        self.request = ws.request
        self.settings = ws.settings
        self.io_loop = tornado.ioloop.IOLoop.current()
        self.cpu_async = CPU_ASYNC
        self.io_async = IO_ASYNC

    def __repr__(self):
        return "GOApplication: %s" % self.__class__

    def __str__(self):
        return self.info['name']

    def initialize(self):
        """
        Called by :meth:`ApplicationWebSocket.open` after __init__().
        GOApplications can override this function to perform their own actions
        when the Application is initialized (happens just before the WebSocket
        is opened).
        """
        pass

    def open(self):
        """
        Called by :meth:`ApplicationWebSocket.open` after the WebSocket is
        opened.  GOApplications can override this function to perform their own
        actions when the WebSocket is opened.
        """
        pass

    def on_close(self):
        """
        Called by :meth:`ApplicationWebSocket.on_close` after the WebSocket is
        closed.  GOApplications can override this function to perform their own
        actions when the WebSocket is closed.
        """
        pass

    def add_handler(self, pattern, handler, **kwargs):
        """
        Adds the given *handler* (`tornado.web.RequestHandler`) to the Tornado
        Application (`self.ws.application`) to handle URLs matching *pattern*.
        If given, *kwargs* will be added to the `tornado.web.URLSpec` when the
        complete handler is assembled.

        .. note::

            If the *pattern* does not start with the configured `url_prefix` it
            will be automatically prepended.
        """
        logging.debug("Adding handler: (%s, %s)" % (pattern, handler))
        url_prefix = self.ws.settings['url_prefix']
        if not pattern.startswith(url_prefix):
            if pattern.startswith('/'):
                # Get rid of the / (it will be in the url_prefix)
                pattern = pattern.lstrip('/')
        spec = tornado.web.URLSpec(pattern, handler, kwargs)
        # Why the Tornado devs didn't give us a simple way to do this is beyond
        # me.
        self.ws.application.handlers[0][1].append(spec)

    def add_timeout(self, timeout, func):
        """
        A convenience function that calls the given *func* after *timeout* using
        ``self.io_loop.add_timeout()`` (which uses
        :meth:`tornado.ioloop.IOLoop.add_timeout`).

        The given *timeout* may be a `datetime.timedelta` or a string compatible
        with `utils.convert_to_timedelta` such as, "5s" or "10m".
        """
        if isinstance(timeout, basestring):
            timeout = convert_to_timedelta(timeout)
        self.io_loop.add_timeout(timeout, func)

class ApplicationWebSocket(WebSocketHandler, OnOffMixin):
    """
    The main WebSocket interface for Gate One, this class is setup to call
    WebSocket 'actions' which are methods registered in `self.actions`.
    Methods that are registered this way will be exposed and directly callable
    over the WebSocket.
    """
    instances = set()
    # These three attributes handle watching files for changes:
    watched_files = {}     # Format: {<file path>: <modification time>}
    file_update_funcs = {} # Format: {<file path>: <function called on update>}
    file_watcher = None    # Will be replaced with a PeriodicCallback
    prefs = {} # Gets updated with every call to initialize()
    def __init__(self, application, request, **kwargs):
        self.user = None
        self.actions = {
            'go:ping': self.pong,
            'go:log': self.log_message,
            'go:authenticate': self.authenticate,
            'go:get_theme': self.get_theme,
            'go:get_js': self.get_js,
            'go:enumerate_themes': self.enumerate_themes,
            'go:file_request': self.file_request,
            'go:cache_cleanup': self.cache_cleanup,
            'go:send_user_message': self.send_user_message,
            'go:broadcast': self.broadcast,
            'go:list_users': self.list_server_users,
            'go:get_locations': self.get_locations,
            'go:set_location': self.set_location,
            'go:set_locale': self.set_locale,
            'go:debug': self.debug,
        }
        # Setup some instance-specific loggers that we can later update with
        # more metadata
        self.io_loop = tornado.ioloop.IOLoop.current()
        self.logger = go_logger(None)
        self.sync_log = go_logger('gateone.sync')
        self.msg_log = go_logger('gateone.message')
        self.auth_log = go_logger('gateone.auth')
        self.client_log = go_logger('gateone.client')
        self._events = {}
        self.session = None # Just a placeholder; gets set in authenticate()
        self.locations = {} # Just a placeholder; gets set in authenticate()
        self.location = None # Just a placeholder; gets set in authenticate()
        # This is used to keep track of used API authentication signatures so
        # we can prevent replay attacks.
        self.prev_signatures = []
        self.origin_denied = True # Only allow valid origins
        self.file_cache = FILE_CACHE # So applications and plugins can reference
        self.persist = PERSIST # So applications and plugins can reference
        self.apps = [] # Gets filled up by self.initialize()
        # The security dict stores applications' various policy functions
        self.security = {}
        self.container = ""
        self.prefix = ""
        self.latency_count = 12 # Starts at 12 so the first ping is logged
        self.pinger = None # Replaced with a PeriodicCallback inside open()
        self.timestamps = [] # Tracks/averages client latency
        self.latency = 0 # Keeps a running average
        WebSocketHandler.__init__(self, application, request, **kwargs)

    @classmethod
    def file_checker(cls):
        """
        A `Tornado.IOLoop.PeriodicCallback` that regularly checks all files
        registered in the `ApplicationWebSocket.watched_files` dict for changes.

        If changes are detected the corresponding function(s) in
        `ApplicationWebSocket.file_update_funcs` will be called.
        """
        #logging.debug("file_checker()") # Noisy so I've commented it out
        if not SESSIONS:
            # No connected sessions; no point in watching files
            cls.file_watcher.stop()
            # Also remove the broadcast file so we know to start up the
            # file_watcher again if a user connects.
            session_dir = options.session_dir
            broadcast_file = os.path.join(session_dir, 'broadcast') # Default
            broadcast_file = cls.prefs['*']['gateone'].get(
                'broadcast_file', broadcast_file) # If set, use that
            del cls.watched_files[broadcast_file]
            del cls.file_update_funcs[broadcast_file]
            os.remove(broadcast_file)
        for path, mtime in list(cls.watched_files.items()):
            if not os.path.exists(path):
                # Someone deleted something they shouldn't have
                logger.error(_(
                    "{path} has been removed.  Removing from file "
                    "checker.".format(path=path)))
                del cls.watched_files[path]
                del cls.file_update_funcs[path]
                continue
            current_mtime = os.stat(path).st_mtime
            if current_mtime == mtime:
                continue
            try:
                cls.watched_files[path] = current_mtime
                cls.file_update_funcs[path]()
            except Exception as e:
                logger.error(_(
                    "Exception encountered trying to execute the file update "
                    "function for {path}...".format(path=path)))
                logger.error(e)
                if options.logging == 'debug':
                    import traceback
                    traceback.print_exc(file=sys.stdout)

    @classmethod
    def watch_file(cls, path, func):
        """
        A classmethod that registers the given file *path* and *func* in
        `ApplicationWebSocket.watched_files` and
        `ApplicationWebSocket.file_update_funcs`, respectively.  The given
        *func* will be called (by `ApplicationWebSocket.file_checker`) whenever
        the file at *path* is modified.
        """
        logging.debug("watch_file('{path}', {func}())".format(
            path=path, func=func.__name__))
        cls.watched_files.update({path: os.stat(path).st_mtime})
        cls.file_update_funcs.update({path: func})

    @classmethod
    def load_prefs(cls):
        """
        Loads all of Gate One's settings from `options.settings_dir` into
        ``cls.prefs``.

        .. note::

            This ``classmethod`` gets called automatically whenever a change is
            detected inside Gate One's ``settings_dir``.
        """
        logger.info(_(
            "Settings have been modified.  Reloading from %s"
            % options.settings_dir))
        prefs = get_settings(options.settings_dir)
        # Only overwrite our settings if everything is proper
        if 'gateone' not in prefs['*']:
            # NOTE: get_settings() records its own errors too
            logger.info(_("Settings have NOT been loaded."))
            return
        cls.prefs = prefs
        # Reset the memoization dict so that everything using
        # applicable_policies() gets the latest & greatest settings
        MEMO.clear()

    @classmethod
    def broadcast_file_update(cls):
        """
        Called when there's an update to the `broadcast_file` (e.g.
        `<session_dir>/broadcast`); broadcasts its contents to all connected
        users.  The message will be displayed via the
        :js:meth:`GateOne.Visual.displayMessage` function at the client and can
        be formatted with HTML.  For this reason it is important to strictly
        control write access to the broadcast file.

        .. note::

            Under normal circumstances only root (or the owner of the
            gateone.py process) can enter and/or write to files inside
            Gate One's `session_dir` directory.

        The path to the broadcast file can be configured via the
        `broadcast_file` setting which can be placed anywhere under the
        'gateone' application/scope (e.g. inside 10server.conf).  The setting
        isn't there by default but you can simply add it if you wish:

        .. code-block:: javascript

            "broadcast_file": "/whatever/path/you/want/broadcast"

        .. tip::

            Want to broadcast a message to all the users currently connected to
            Gate One?  Just `sudo echo "your message" > /tmp/gateone/broadcast`.
        """
        session_dir = options.session_dir
        broadcast_file = os.path.join(session_dir, 'broadcast')
        broadcast_file = cls.prefs['*']['gateone'].get(
            'broadcast_file', broadcast_file)
        with io.open(broadcast_file) as f:
            message = f.read()
        if message:
            message = message.rstrip()
            metadata = {'clients': []}
            for instance in cls.instances:
                try: # Only send to users that have authenticated
                    user = instance.current_user
                except AttributeError:
                    continue
                user_info = {
                    'upn': user['upn'],
                    'ip_address': user['ip_address']
                }
                metadata['clients'].append(user_info)
            msg_log.info(
                "Broadcast (via broadcast_file): %s" % message,
                metadata=metadata)
            message_dict = {'go:user_message': message}
            cls._deliver(message_dict, upn="AUTHENTICATED")
            io.open(broadcast_file, 'w').write(u'') # Empty it out

    def initialize(self, apps=None, **kwargs):
        """
        This gets called by the Tornado framework when `ApplicationWebSocket` is
        instantiated.  It will be passed the list of *apps* (Gate One
        applications) that are assigned inside the :class:`GOApplication`
        object.  These :class:`GOApplication`s will be instantiated and stored
        in `self.apps`.

        These *apps* will be mutated in-place so that `self` will refer to the
        current instance of :class:`ApplicationWebSocket`.  Kind of like a
        dynamic mixin.
        """
        logging.debug('ApplicationWebSocket.initialize(%s)' % apps)
        # Make sure we have all prefs ready for checking
        cls = ApplicationWebSocket
        cls.prefs = get_settings(options.settings_dir)
        if not os.path.exists(self.settings['cache_dir']):
            mkdir_p(self.settings['cache_dir'])
        for plugin_name, hooks in PLUGIN_HOOKS.items():
            if 'Events' in hooks:
                for event, callback in hooks['Events'].items():
                    self.on(event, callback)
        self.on("go:authenticate", self.send_extra)
        # Setup some actions to take place after the user authenticates
        # Send our plugin .js and .css files to the client
        send_plugin_static_files = partial(
            self.send_plugin_static_files, os.path.join(GATEONE_DIR, 'plugins'))
        self.on("go:authenticate", send_plugin_static_files)
        # Tell the client about any existing locations where applications may be
        # storing things like terminal instances and whatnot:
        self.on("go:authenticate", self.get_locations)
        # This is so the client knows what applications it can use:
        self.on("go:authenticate", self.list_applications)
        # This starts up the PeriodicCallback that watches sessions for timeouts
        # and cleans them up (if not already started):
        self.on("go:authenticate", self._start_session_watcher)
        # This starts up the PeriodicCallback that watches and cleans up old
        # user logs (anything in gateone/users/<user>/logs):
        self.on("go:authenticate", self._start_cleaner)
        # This starts up the file watcher PeriodicCallback:
        self.on("go:authenticate", self._start_file_watcher)
        # This ensures that sessions will timeout immediately if session_timeout
        # is set to 0:
        self.on("go:close", timeout_sessions)
        if not apps:
            return
        for app in apps:
            instance = app(self)
            self.apps.append(instance)
            logging.debug("Initializing %s" % instance)
            if hasattr(instance, 'initialize'):
                instance.initialize()

    def send_extra(self):
        """
        Sends any extra JS/CSS files placed in Gate One's 'static/extra'
        directory.  Can be useful if you want to use Gate One's file
        synchronization and caching capabilities in your app.

        .. note::

            You may have to create the 'static/extra' directory before putting
            files in there.
        """
        extra_path = os.path.join(GATEONE_DIR, 'static', 'extra')
        if not os.path.isdir(extra_path):
            return # Nothing to do
        for filename in os.listdir(extra_path):
            filepath = os.path.join(extra_path, filename)
            if filename.endswith('.js'):
                self.send_js(filepath)
            elif filename.endswith('.css'):
                self.send_css(filepath)

    def allow_draft76(self):
        """
        By overriding this function we're allowing the older version of the
        WebSockets protocol.  As long as communications happens over SSL there
        shouldn't be any security concerns with this.  This is mostly to support
        iOS Safari.
        """
        return True

    def get_current_user(self):
        """
        Mostly identical to the function of the same name in MainHandler.  The
        difference being that when API authentication is enabled the WebSocket
        will expect and perform its own auth of the client.
        """
        if self.user:
            return self.user
        expiration = self.settings.get('auth_timeout', "14d")
        # Need the expiration in days (which is a bit silly but whatever):
        expiration = (
            float(total_seconds(convert_to_timedelta(expiration)))
            / float(86400))
        user_json = self.get_secure_cookie(
            "gateone_user", max_age_days=expiration)
        if not user_json:
            if not self.settings['auth']:
                # This can happen if the user's browser isn't allowing
                # persistent cookies (e.g. incognito mode)
                return {'upn': 'ANONYMOUS', 'session': generate_session_id()}
            return None
        user = json_decode(user_json)
        user['ip_address'] = self.request.remote_ip
        return user

    def write_binary(self, message):
        """
        Writes the given *message* to the WebSocket in binary mode (opcode
        0x02).  Binary WebSocket messages are handled differently from regular
        messages at the client (they use a completely different 'action'
        mechanism).  For more information see the JavaScript developer
        documentation.
        """
        self.write_message(message, binary=True)

    def valid_origin(self, origin):
        """
        Checks if the given *origin* matches what's been set in Gate One's
        "origins" setting (usually in 10server.conf).  The *origin* will first
        be checked for an exact match in the "origins" setting but if that fails
        each valid origin will be evaluated as a regular expression (if it's not
        a valid hostname) and the given *origin* will be checked against that.

        Returns ``True`` if *origin* is valid.

        .. note::

            If '*' is in the "origins" setting (anywhere) all origins will be
            allowed.
        """
        valid = False
        if 'origins' in self.settings.get('cli_overrides', ''):
            # If given on the command line, always use those origins
            valid_origins = self.settings['origins']
        else:
            # Why have this separate?  So you can change origins on-the-fly by
            # modifying 10server.conf (or whatever other conf you put it in).
            valid_origins = self.prefs['*']['gateone'].get('origins', [])
        if '*' in valid_origins:
            valid = True
        elif origin in valid_origins:
            valid = True
        if not valid:
            # Treat the list of valid origins as regular expressions
            for check_origin in valid_origins:
                if valid_hostname(check_origin):
                    continue # Valid hostnames aren't regular expressions
                match = re.match(check_origin, origin)
                if match:
                    valid = True
                    break
        return valid

    def open(self):
        """
        Called when a new WebSocket is opened.  Will deny access to any
        origin that is not defined in `self.settings['origin']`.  Also sends
        any relevant localization data (JavaScript) to the client and calls the
        :meth:`open` method of any and all enabled Applications.

        This method kicks off the process that sends keepalive pings/checks to
        the client (A `~tornado.ioloop.PeriodicCallback` set as `self.pinger`).

        This method also sets the following instance attributes:

            * `self.client_id`: Unique identifier for this instance.
            * `self.base_url`: The base URL (e.g. https://foo.com/gateone/) used to access Gate One.
            * `self.origin`: A shortcut to reference the client's origin.

        Triggers the `go:open` event.

        .. note::

            `self.settings` comes from the Tornado framework and includes most
            command line arguments and the settings from the `settings_dir` that
            fall under the "gateone" scope.  It is not the same thing as
            `self.prefs` which includes *all* of Gate One's settings (including
            settings for other applications and scopes).
        """
        cls = ApplicationWebSocket
        cls.instances.add(self)
        if hasattr(self, 'set_nodelay'):
            # New feature of Tornado 3.1 that can reduce latency:
            self.set_nodelay(True)
        if 'Origin' in self.request.headers:
            origin = self.request.headers['Origin']
        elif 'Sec-Websocket-Origin' in self.request.headers: # Old version
            origin = self.request.headers['Sec-Websocket-Origin']
        origin = origin.lower() # hostnames are case-insensitive
        origin = origin.split('://', 1)[1]
        self.origin = origin
        client_address = self.request.remote_ip
        logging.debug("open() origin: %s" % origin)
        if not self.valid_origin(origin):
            self.origin_denied = True
            denied_msg = _('Access denied for origin: %s') % origin
            auth_log.error(denied_msg)
            self.write_message(denied_msg)
            self.write_message(_(
                "If you feel this is incorrect you just have to add '%s' to"
                " the 'origins' option in your Gate One settings (e.g. "
                "inside your 10server.conf).  See the docs for details.")
                % origin)
            self.close()
            return
        self.origin_denied = False
        # client_id is unique to the browser/client whereas session_id is unique
        # to the user.  It isn't used much right now but it will be useful in
        # the future once more stuff is running over WebSockets.
        self.client_id = generate_session_id()
        self.base_url = "{protocol}://{host}:{port}{url_prefix}".format(
            protocol=self.request.protocol,
            host=self.request.host,
            port=self.settings['port'],
            url_prefix=self.settings['url_prefix'])
        user = self.current_user
        # NOTE: self.current_user will call self.get_current_user() and set
        # self._current_user the first time it is used.
        metadata = {'ip_address': client_address}
        if user and 'upn' in user:
            # Update our loggers to include the user metadata
            metadata['upn'] = user['upn']
            # NOTE: NOT using self.auth_log() here on purpose:
            auth_log.info( # Use global auth_log so we're not redundant
                _("WebSocket opened (%s %s) via origin %s.") % (
                    user['upn'], client_address, origin))
        else:
            # NOTE: NOT using self.auth_log() here on purpose:
            auth_log.info(_(
                '{"ip_address": "%s"} WebSocket opened (unknown user).')
            % client_address)
        # NOTE: These get updated with more metadata inside of authenticate():
        self.logger = go_logger(None, **metadata)
        self.sync_log = go_logger('gateone.sync', **metadata)
        self.auth_log = go_logger('gateone.auth', **metadata)
        self.msg_log = go_logger('gateone.message', **metadata)
        self.client_log = go_logger('gateone.client', **metadata)
        if user and 'upn' not in user: # Invalid user info
            # NOTE: NOT using self.auth_log() here on purpose:
            auth_log.error(_(
                '{"ip_address": "%s"} Unauthenticated WebSocket attempt.'
                ) % client_address)
            # In case this is a legitimate client that simply had its auth info
            # expire/go bad, tell it to re-auth by calling the appropriate
            # action on the other side.
            message = {'go:reauthenticate': True}
            self.write_message(json_encode(message))
            self.close() # Close the WebSocket
        # NOTE: By getting the prefs with each call to open() we make
        #       it possible to make changes inside the settings dir without
        #       having to restart Gate One (just need to wait for users to
        #       eventually re-connect or reload the page).
        # NOTE: Why store prefs in the class itself?  No need for redundancy.
        if 'cache_dir' not in cls.prefs['*']['gateone']:
            # Set the cache dir to a default if not set in the prefs
            cache_dir = self.settings['cache_dir']
            cls.prefs['*']['gateone']['cache_dir'] = cache_dir
            if self.settings['debug']:
                # Clean out the cache_dir every page reload when in debug mode
                for fname in os.listdir(cache_dir):
                    filepath = os.path.join(cache_dir, fname)
                    os.remove(filepath)
        # NOTE: This is here so that the client will have all the necessary
        # strings *before* the calls to various init() functions.
        self.send_js_translation()
        additional_files = [
            'gateone_utils_extra.js',
            'gateone_visual_extra.js',
            'gateone_input.js',
            'gateone_misc.js'
        ]
        for js_file in additional_files:
            self.send_js(os.path.join(GATEONE_DIR, 'static', js_file))
        for app in self.apps:
            if hasattr(app, 'open'):
                app.open() # Call applications' open() functions (if any)
        # Ping the client every 5 seconds so we can keep track of latency and
        # ensure firewalls don't close the connection.
        def send_ping():
            try:
                self.ping(str(int(time.time() * 1000)).encode('utf-8'))
            except (WebSocketClosedError, AttributeError):
                # Connection closed
                self.pinger.stop()
                del self.pinger
        send_ping()
        interval = 5000 # milliseconds
        self.pinger = tornado.ioloop.PeriodicCallback(send_ping, interval)
        self.pinger.start()
        self.trigger("go:open")

    def on_message(self, message):
        """
        Called when we receive a message from the client.  Performs some basic
        validation of the message, decodes it (JSON), and finally calls an
        appropriate WebSocket action (registered method) with the message
        contents.
        """
        # This is super useful when debugging:
        logging.debug("message: %s" % repr(message))
        if self.origin_denied:
            self.auth_log.error(_("Message rejected due to invalid origin."))
            self.close() # Close the WebSocket
        message_obj = None
        try:
            message_obj = json_decode(message) # JSON FTW!
            if not isinstance(message_obj, dict):
                self.write_message(_("'Error: Message bust be a JSON dict.'"))
                return
        except ValueError: # We didn't get JSON
            self.write_message(_("'Error: We only accept JSON here.'"))
            return
        if message_obj:
            for key, value in message_obj.items():
                if key in PLUGIN_WS_CMDS:
                    try: # Plugins first so they can override behavior
                        PLUGIN_WS_CMDS[key](value, tws=self)
                        # tws==ApplicationWebSocket
                    except (KeyError, TypeError, AttributeError) as e:
                        self.logger.error(_(
                            "Error running plugin WebSocket action: %s" % key))
                else:
                    try:
                        if value is None:
                            self.actions[key]()
                        else:
                            # Try, try again
                            self.actions[key](value)
                    except (KeyError, TypeError, AttributeError) as e:
                        import traceback
                        for frame in traceback.extract_tb(sys.exc_info()[2]):
                            fname, lineno, fn, text = frame
                        self.logger.error(_(
                         "Error/Unknown WebSocket action, %s: %s (%s line %s)" %
                         (key, e, fname, lineno)))
                        if self.settings['logging'] == 'debug':
                            traceback.print_exc(file=sys.stdout)

    def on_close(self):
        """
        Called when the client terminates the connection.  Also calls the
        :meth:`on_close` method of any and all enabled Applications.

        Triggers the `go:close` event.
        """
        logging.debug("on_close()")
        ApplicationWebSocket.instances.discard(self)
        user = self.current_user
        client_address = self.request.remote_ip
        if user and user['session'] in SESSIONS:
            if self.client_id in SESSIONS[user['session']]['client_ids']:
                SESSIONS[user['session']]['client_ids'].remove(self.client_id)
            # This check is so we don't accidentally timeout a user's session if
            # the server has session_timeout=0 and the user still has a browser
            # connected at a different location:
            if not SESSIONS[user['session']]['client_ids']:
                # Update 'last_seen' with a datetime object for accuracy
                SESSIONS[user['session']]['last_seen'] = datetime.now()
        if user and 'upn' in user:
            self.auth_log.info(
                _("WebSocket closed (%s %s).") % (user['upn'], client_address))
        else:
            self.auth_log.info(_("WebSocket closed (unknown user)."))
        if self.pinger:
            self.pinger.stop()
        # Call applications' on_close() functions (if any)
        for app in self.apps:
            if hasattr(app, 'on_close'):
                app.on_close()
        self.trigger("go:close")

    def on_pong(self, timestamp):
        """
        Records the latency of clients (from the server's perspective) via a
        log message.

        .. note::

            This is the ``pong`` specified in the WebSocket protocol itself.
            The `pong` method is a Gate One-specific implementation.
        """
        self.latency_count += 1
        latency = int(time.time() * 1000) - int(timestamp)
        if latency < 0:
            return # Something went wrong; skip this one
        self.timestamps.append(latency)
        if len(self.timestamps) > 10:
            self.timestamps.pop(0)
        self.latency = sum(self.timestamps)/len(self.timestamps)
        if self.latency_count > 12: # Only log once a minute
            self.latency_count = 0
            self.logger.info(_("WebSocket Latency: {0}ms").format(self.latency))

    def pong(self, timestamp):
        """
        Attached to the `go:ping` WebSocket action; responds to a client's
        ``ping`` by returning the value (*timestamp*) that was sent.  This
        allows the client to measure the round-trip time of the WebSocket.

        .. note::

            This is a WebSocket action specific to Gate One. It
        """
        message = {'go:pong': timestamp}
        self.write_message(json_encode(message))

    @require(policies('gateone'))
    def log_message(self, log_obj):
        """
        Attached to the `go:log` WebSocket action; logs the given *log_obj* via
        :meth:`ApplicationWebSocket.client_log`.  The *log_obj* should be a
        dict (JSON object, really) in the following format::

            {
                "level": "info", # Optional
                "message": "Actual log message here"
            }

        If a "level" is not given the "info" level will be used.

        *Supported Levels:* "info", "error", "warning", "debug", "fatal",
        "critical".

        .. note::

            The "critical" and "fatal" log levels both use the
            `logging.Logger.critical` method.
        """
        if not self.current_user:
            return # Don't let unauthenticated users log messages.
            # NOTE:  We're not using the authenticated() check here so we don't
            # end up logging a zillion error messages when an unauthenticated
            # user's client has debug logging enabled.
        if "message" not in log_obj:
            return # Nothing to do
        log_obj["level"] = log_obj.get("level", "info") # Default to "info"
        loggers = {
            "info": self.client_log.info,
            "warning": self.client_log.warning,
            "error": self.client_log.error,
            "debug": self.client_log.debug,
            "fatal": self.client_log.critical, # Python doesn't use "fatal"
            "critical": self.client_log.critical,
        }
        if isinstance(log_obj["message"], bytes):
            log_msg = log_obj["message"]
        else:
            log_msg = log_obj["message"].encode('utf-8')
        loggers[log_obj["level"].lower()](
            "Client Logging: {0}".format(log_msg))

    def api_auth(self, auth_obj):
        """
        If the *auth_obj* dict validates, returns the user dict and sets
        ``self.current_user``.  If it doesn't validate, returns ``False``.

        This function also takes care of creating the user's directory if it
        does not exist and creating/updating the user's 'session' file (which
        just stores metadata related to their session).

        Example usage::

            auth_obj = {
                'api_key': 'MjkwYzc3MDI2MjhhNGZkNDg1MjJkODgyYjBmN2MyMTM4M',
                'upn': 'joe@company.com',
                'timestamp': '1323391717238',
                'signature': <gibberish>,
                'signature_method': 'HMAC-SHA1',
                'api_version': '1.0'
            }
            result = self.api_auth(auth_obj)

        .. seealso:: :ref:`api-auth` documentation.

        Here's a rundown of the required *auth_obj* parameters:

            :api_key:
                The first half of what gets generated when you run
                ``gateone --new_api_key`` (the other half is the secret).
            :upn:
                The userPrincipalName (aka username) of the user being
                authenticated.
            :timestamp:
                A 13-digit "time since the epoch" JavaScript-style timestamp.
                Both integers and strings are accepted.
                Example JavaScript: ``var timestamp = new Date().getTime()``
            :signature:
                The HMAC signature of the combined *api_key*, *upn*, and
                *timestamp*; hashed using the secret associated with the given
                *api_key*.
            :signature_method:
                The hashing algorithm used to create the *signature*.  Currently
                this must be one of "HMAC-SHA1", "HMAC-SHA256", "HMAC-SHA384",
                or "HMAC-SHA512"
            :api_version:
                Which version of the authentication API to use when performing
                authentication.  Currently the only supported version is '1.0'.

        .. note::

            Any additional key/value pairs that are included in the *auth_obj*
            will be assigned to the ``self.current_user`` object.  So if you're
            embedding Gate One and wish to associate extra metadata with the
            user you may do so via the API authentication process.
        """
        from .utils import create_signature
        reauth = {'go:reauthenticate': True}
        api_key = auth_obj.get('api_key', None)
        if not api_key:
            self.auth_log.error(_(
                'API AUTH: Invalid API authentication object (missing api_key).'
            ))
            self.write_message(json_encode(reauth))
            return False
        upn = auth_obj['upn']
        timestamp = str(auth_obj['timestamp']) # str in case integer
        signature = auth_obj['signature']
        signature_method = auth_obj['signature_method']
        api_version = auth_obj['api_version']
        supported_hmacs = {
            'HMAC-SHA1': hashlib.sha1,
            'HMAC-SHA256': hashlib.sha256,
            'HMAC-SHA384': hashlib.sha384,
            'HMAC-SHA512': hashlib.sha512,
        }
        if signature_method not in supported_hmacs:
            self.auth_log.error(_(
                    'API AUTH: Unsupported API auth '
                    'signature method: %s' % signature_method))
            self.write_message(json_encode(reauth))
            return False
        hmac_algo = supported_hmacs[signature_method]
        if api_version != "1.0":
            self.auth_log.error(_(
                    'API AUTH: Unsupported API version:'
                    '%s' % api_version))
            self.write_message(json_encode(reauth))
            return False
        try:
            secret = self.settings['api_keys'][api_key]
        except KeyError:
            self.auth_log.error(_(
                'API AUTH: API Key not found.'))
            self.write_message(json_encode(reauth))
            return False
# TODO: Make API version 1.1 that signs *all* attributes--not just the known ones
        # Check the signature against existing API keys
        sig_check = create_signature(
            secret, api_key, upn, timestamp, hmac_algo=hmac_algo)
        if sig_check != signature:
            self.auth_log.error(_('API AUTH: Signature check failed.'))
            self.write_message(json_encode(reauth))
            return False
        # Everything matches (great!) so now we do due diligence
        # by checking the timestamp against the
        # api_timestamp_window setting and whether or not we've
        # already used it (to prevent replay attacks).
        if signature in self.prev_signatures:
            self.auth_log.error(_(
                "API AUTH: replay attack detected!  User: "
                "%s, Remote IP: %s, Origin: %s" % (
                upn, self.request.remote_ip, self.origin)))
            message = {'go:notice': _(
                'API AUTH: Replay attack detected!  This '
                'event has been logged.')}
            self.write_message(json_encode(message))
            return
        window = self.settings['api_timestamp_window']
        then = datetime.fromtimestamp(int(timestamp)/1000)
        time_diff = datetime.now() - then
        if time_diff > window:
            self.auth_log.error(_(
                "API AUTH: Authentication failed due to an expired auth "
                "object.  If you just restarted the server this is "
                "normal (users just need to reload the page).  If "
                " this problem persists it could be a problem with "
                "the server's clock (either this server or the "
                "server(s) embedding Gate One)."
            ))
            message = {'go:notice': _(
                'AUTH FAILED: Authentication object timed out. '
                'Try reloading this page (F5).')}
            self.write_message(json_encode(message))
            message = {'go:notice': _(
                'AUTH FAILED: If the problem persists after '
                'reloading this page please contact your server'
                ' administrator to notify them of the issue.')}
            self.write_message(json_encode(message))
            return False
        logging.debug(_("API Authentication Successful"))
        self.prev_signatures.append(signature) # Prevent replays
        # Attach any additional provided keys/values to the user
        # object so applications embedding Gate One can use
        # them in their own plugins and whatnot.
        user = {}
        known_params = [
            'api_key',
            'api_version',
            'timestamp',
            'signature',
            'signature_method'
        ]
        for key, value in auth_obj.items():
            if key not in known_params:
                user[key] = value
        # user dicts need a little extra attention for IPs...
        user['ip_address'] = self.request.remote_ip
        # Force-set the current user:
        self._current_user = user
        # Make a directory to store this user's settings/files/logs/etc
        user_dir = os.path.join(self.settings['user_dir'], user['upn'])
        if not os.path.exists(user_dir):
            self.logger.info(_("Creating user directory: %s" % user_dir))
            mkdir_p(user_dir)
            os.chmod(user_dir, 0o770)
        session_file = os.path.join(user_dir, 'session')
        if os.path.exists(session_file):
            with io.open(session_file) as f:
                session_data = f.read()
            user['session'] = json_decode(session_data)['session']
        else:
            user['session'] = generate_session_id()
            session_info_json = json_encode(user)
            with io.open(session_file, 'w') as f:
                # Save it so we can keep track across multiple clients
                f.write(session_info_json)
        return user

    def authenticate(self, settings):
        """
        Authenticates the client by first trying to use the 'gateone_user'
        cookie or if Gate One is configured to use API authentication it will
        use *settings['auth']*.  Additionally, it will accept
        *settings['container']* and *settings['prefix']* to apply those to the
        equivalent properties (`self.container` and `self.prefix`).

        If *settings['url']* is provided it will be used to update
        `self.base_url` (so that we can correct for situations where Gate One
        is running behind a reverse proxy with a different protocol/URL than
        what the user used to connect).

        .. note::

            'container' refers to the element on which Gate One was initialized
            at the client (e.g. `#gateone`).  'prefix' refers to the string that
            will be prepended to all Gate One element IDs when added to the web
            page (to avoid namespace conflicts).  Both these values are only
            used when generating CSS templates.

        If *settings['location']* is something other than 'default' all new
        application instances will be associated with the given (string) value.
        These applications will be treated separately so they can exist in a
        different browser tab/window.

        Triggers the `go:authenticate` event.
        """
        logging.debug("authenticate(): %s" % settings)
        # Make sure the client is authenticated if authentication is enabled
        reauth = {'go:reauthenticate': True}
        user = self.current_user # Just a shortcut to keep lines short
        auth_method = self.settings.get('auth', None)
        if auth_method and auth_method != 'api':
            # Regular, non-API authentication
            if settings['auth']:
                # Try authenticating with the given (encrypted) 'auth' value
                expiration = self.settings.get('auth_timeout', "14d")
                expiration = (
                    float(total_seconds(convert_to_timedelta(expiration)))
                    / float(86400))
                auth_data = self.get_secure_cookie("gateone_user",
                    value=settings['auth'], max_age_days=expiration)
                # NOTE:  This will override whatever is in the cookie.
                # Why?  Because we'll eventually transition to not using cookies
                if auth_data:
                    # Force-set the current user
                    self._current_user = json_decode(auth_data)
                    # Add/update the user's IP address
                    self._current_user['ip_address'] = self.request.remote_ip
                    user = self.current_user
            try:
                if not user:
                    self.auth_log.error(_("Unauthenticated WebSocket attempt."))
                    # This usually happens when the cookie_secret gets changed
                    # resulting in "Invalid cookie..." errors.  If we tell the
                    # client to re-auth the problem should correct itself.
                    self.write_message(json_encode(reauth))
                    return
                elif user and user['upn'] == 'ANONYMOUS':
                    self.auth_log.error(_("Unauthenticated WebSocket attempt."))
                    # This can happen when a client logs in with no auth type
                    # configured and then later the server is configured to use
                    # authentication.  The client must be told to re-auth:
                    self.write_message(json_encode(reauth))
                    return
            except KeyError: # 'upn' wasn't in user
                # Force them to authenticate
                self.write_message(json_encode(reauth))
                #self.close() # Close the WebSocket
        elif auth_method and auth_method == 'api':
            if 'auth' in list(settings.keys()):
                if not isinstance(settings['auth'], dict):
                    settings['auth'] = json_decode(settings['auth'])
                user = self.api_auth(settings['auth'])
                if not user:
                    # The api_auth() function takes care of logging/notification
                    return
        else: # Anonymous auth
            # Double-check there isn't a user set in the cookie (i.e. we have
            # recently changed Gate One's settings).  If there is, force it
            # back to ANONYMOUS.
            if settings['auth']:
                cookie_data = None
                if isinstance(settings['auth'], basestring):
                    # The client is trying to authenticate using the
                    # 'gateone_user' parameter in localStorage.
                    # Authenticate/decode the encoded auth info
                    expiration = self.settings.get('auth_timeout', "14d")
                    expiration = (
                        float(total_seconds(convert_to_timedelta(expiration)))
                        / float(86400))
                    cookie_data = self.get_secure_cookie("gateone_user",
                        value=settings['auth'], max_age_days=expiration)
                    # NOTE: The above doesn't actually touch any cookies
                else:
                    # Someone is attempting to perform API-based authentication
                    # but this server isn't configured with 'auth = "api"'.
                    # Let's be real user-friendly and point out this mistake
                    # with a helpful error message...
                    self.auth_log.error(_(
                        "Client tried to use API-based authentication but this "
                        "server is configured with 'auth = \"{0}\"'.  Did you "
                        "forget to set '\"auth\": \"api\"' in the settings?"
                        ).format(self.settings['auth']))
                    message = {'go:notice': _(
                        "AUTHENTICATION ERROR: Server is not configured to "
                        "perform API-based authentication.  Did someone forget "
                        "to set '\"auth\": \"api\"' in the settings?")}
                    self.write_message(json_encode(message))
                    return
                if cookie_data:
                    user = json_decode(cookie_data)
            if not user:
                # Generate a new session/anon user
                # Also store/update their session info in localStorage
                user = {
                    'upn': 'ANONYMOUS',
                    'session': generate_session_id()
                }
                encoded_user = self.create_signed_value(
                    'gateone_user', tornado.escape.json_encode(user))
                session_message = {'go:gateone_user': encoded_user}
                self.write_message(json_encode(session_message))
                self._current_user['ip_address'] = self.request.remote_ip
                self._current_user = user
            if user['upn'] != 'ANONYMOUS':
                # Gate One server's auth config probably changed
                self.write_message(json_encode(reauth))
                return
        if self.current_user and 'session' in self.current_user:
            self.session = self.current_user['session']
        else:
            self.auth_log.error(_("Authentication failed for unknown user"))
            message = {'go:notice': _('AUTHENTICATION ERROR: User unknown')}
            self.write_message(json_encode(message))
            self.write_message(json_encode(reauth))
            return
        try:
            # Execute any post-authentication hooks that plugins have registered
            if PLUGIN_AUTH_HOOKS:
                for auth_hook in PLUGIN_AUTH_HOOKS:
                    auth_hook(self, self.current_user, self.settings)
        except Exception as e:
            self.logger.error(_("Exception in registered Auth hook: %s" % e))
        # Locations are used to differentiate between different tabs/windows
        self.location = settings.get('location', 'default')
        # Update our loggers to include the user metadata
        metadata = {
            'upn': user['upn'],
            'ip_address': self.request.remote_ip,
            'location': self.location
        }
        self.logger = go_logger(None, **metadata)
        self.sync_log = go_logger('gateone.sync', **metadata)
        self.auth_log = go_logger('gateone.auth', **metadata)
        self.msg_log = go_logger('gateone.message', **metadata)
        self.client_log = go_logger('gateone.client', **metadata)
        # Apply the container/prefix settings (if present)
        self.container = settings.get('container', self.container)
        self.prefix = settings.get('prefix', self.prefix)
        # Update self.base_url if a url was given
        url = settings.get('url', None)
        if url:
            orig_base_url = self.base_url
            parsed = urlparse(url)
            port = parsed.port
            if not port:
                port = 443
                if parsed.scheme == 'http':
                    port = 80
            self.base_url = "{protocol}://{host}:{port}{url_prefix}".format(
                protocol=parsed.scheme,
                host=parsed.hostname,
                port=port,
                url_prefix=parsed.path)
            if orig_base_url != self.base_url:
                self.logger.info(_(
                    "Proxy in use: Client URL differs from server."))
        # NOTE: NOT using self.auth_log() here on purpose (this log message
        # should stay consistent for easier auditing):
        auth_log.info(
            _(u"User {upn} authenticated successfully via origin {origin}"
              u" (location: {location}).").format(
                  upn=user['upn'], origin=self.origin, location=self.location))
        # This check is to make sure there's no existing session so we don't
        # accidentally clobber it.
        if self.session not in SESSIONS:
            # Start a new session:
            SESSIONS[self.session] = {
                'client_ids': [self.client_id],
                'last_seen': 'connected',
                'user': self.current_user,
                'kill_session_callbacks': [
                    partial(self.send_message,
                        _("Please wait while the server is restarted..."))
                ],
                'timeout_callbacks': [],
                # Locations are virtual containers that indirectly correlate
                # with browser windows/tabs.  The point is to allow things like
                # opening/moving applications/terminals in/to new windows/tabs.
                'locations': {self.location: {}}
            }
        else:
            SESSIONS[self.session]['last_seen'] = 'connected'
            SESSIONS[self.session]['client_ids'].append(self.client_id)
            if self.location not in SESSIONS[self.session]['locations']:
                SESSIONS[self.session]['locations'][self.location] = {}
        # A shortcut:
        self.locations = SESSIONS[self.session]['locations']
        # Call applications' authenticate() functions (if any)
        for app in self.apps:
            # Set the current user for convenient access
            app.current_user = self.current_user
            if hasattr(app, 'authenticate'):
                app.authenticate()
        # This is just so the client has a human-readable point of reference:
        message = {'go:set_username': self.current_user['upn']}
        self.write_message(json_encode(message))
        self.trigger('go:authenticate')

    def _start_session_watcher(self, restart=False):
        """
        Starts up the `SESSION_WATCHER` (assigned to that global)
        :class:`~tornado.ioloop.PeriodicCallback` that regularly checks for user
        sessions that have timed out via the :func:`timeout_sessions` function
        and cleans them up (shuts down associated processes).

        The interval in which it performs this check is controlled via the
        `session_timeout_check_interval` setting. This setting is not included
        in Gate One's 10server.conf by default but can be added if needed to
        override the default value of 30 seconds.  Example:

        .. code-block:: javascript

            {
                "*": {
                    "gateone": {
                        "session_timeout_check_interval": "30s"
                    }
                }
            }
        """
        global SESSION_WATCHER
        if not SESSION_WATCHER or restart:
            interval = self.prefs['*']['gateone'].get(
                'session_timeout_check_interval', "30s") # 30s default
            td = convert_to_timedelta(interval)
            interval = total_seconds(td) * 1000 # milliseconds
            SESSION_WATCHER = tornado.ioloop.PeriodicCallback(
                timeout_sessions, interval)
            SESSION_WATCHER.start()

    def _start_cleaner(self):
        """
        Starts up the `CLEANER` (assigned to that global)
        `~tornado.ioloop.PeriodicCallback` that regularly checks for and
        deletes expired user logs (e.g. terminal session logs or anything in the
        `<user_dir>/<user>/logs` dir) and old session directories via the
        :func:`cleanup_user_logs` and :func:`cleanup_old_sessions` functions.

        The interval in which it performs this check is controlled via the
        `cleanup_interval` setting. This setting is not included in Gate One's
        10server.conf by default but can be added if needed to override the
        default value of 5 minutes.  Example:

        .. code-block:: javascript

            {
                "*": {
                    "gateone": {
                        "cleanup_interval": "5m"
                    }
                }
            }
        """
        global CLEANER
        if not CLEANER:
            default_interval = 5*60*1000 # 5 minutes
            # NOTE: This interval isn't in the settings by default because it is
            # kind of obscure.  No reason to clutter things up.
            interval = self.prefs['*']['gateone'].get(
                'cleanup_interval', default_interval)
            td = convert_to_timedelta(interval)
            interval = ((
                td.microseconds +
                (td.seconds + td.days * 24 * 3600) *
                10**6) / 10**6) * 1000
            CLEANER = tornado.ioloop.PeriodicCallback(clean_up, interval)
            CLEANER.start()

    def _start_file_watcher(self):
        """
        Starts up the :attr:`ApplicationWebSocket.file_watcher`
        `~tornado.ioloop.PeriodicCallback` (which regularly calls
        :meth:`ApplicationWebSocket.file_checker` and immediately starts it
        watching the broadcast file for changes (if not already watching it).

        The path to the broadcast file defaults to '*settings_dir*/broadcast'
        but can be changed via the 'broadcast_file' setting.  This setting is
        not included in Gate One's 10server.conf by default but can be added if
        needed to overrided the default value.  Example:

        .. code-block:: javascript

            {
                "*": {
                    "gateone": {
                        "broadcast_file": "/some/path/to/broadcast"
                    }
                }
            }

        .. tip::

            You can send messages to all users currently connected to the Gate
            One server by writing text to the broadcast file.  Example:
            `sudo echo "Server will be rebooted as part of regularly scheduled
            maintenance in 5 minutes.  Pleas save your work." >
            /tmp/gateone/broadcast`

        The interval in which it performs this check is controlled via the
        `file_check_interval` setting. This setting is not included in
        Gate One's 10server.conf by default but can be added if needed to
        override the default value of 5 seconds.  Example:

        .. code-block:: javascript

            {
                "*": {
                    "gateone": {
                        "file_check_interval": "5s"
                    }
                }
            }
        """
        cls = ApplicationWebSocket
        broadcast_file = os.path.join(self.settings['session_dir'], 'broadcast')
        broadcast_file = self.prefs['*']['gateone'].get(
            'broadcast_file', broadcast_file)
        if broadcast_file not in cls.watched_files:
            # No broadcast file means the file watcher isn't running
            touch(broadcast_file)
            interval = self.prefs['*']['gateone'].get(
                'file_check_interval', "5s")
            td = convert_to_timedelta(interval)
            interval = ((
                td.microseconds +
                (td.seconds + td.days * 24 * 3600) *
                10**6) / 10**6) * 1000
            cls.watch_file(broadcast_file, cls.broadcast_file_update)
            io_loop = tornado.ioloop.IOLoop.current()
            cls.file_watcher = tornado.ioloop.PeriodicCallback(
                cls.file_checker, interval, io_loop=io_loop)
            cls.file_watcher.start()
        if options.settings_dir not in cls.watched_files:
            cls.watch_file(options.settings_dir, cls.load_prefs)

    def list_applications(self):
        """
        Sends a message to the client indiciating which applications and
        sub-applications are available to the user.

        .. note::

            What's the difference between an "application" and a
            "sub-application"?  An "application" is a `GOApplication` like
            `app_terminal.TerminalApplication` while a "sub-application" would
            be something like "SSH" or "nethack" which runs inside the parent
            application.
        """
        policy = applicable_policies("gateone", self.current_user, self.prefs)
        enabled_applications = policy.get('enabled_applications', [])
        enabled_applications = [a.lower() for a in enabled_applications]
        applications = []
        if not enabled_applications: # Load all apps
            for app in self.apps: # Use the app's name attribute
                info_dict = app.info.copy() # Make a copy so we can change it
                applications.append(info_dict)
        else:
            for app in self.apps: # Use the app's name attribute
                info_dict = app.info.copy() # Make a copy so we can change it
                if info_dict['name'].lower() in enabled_applications:
                    applications.append(info_dict)
        applications.sort()
        message = {'go:applications': applications}
        self.write_message(json_encode(message))

    @require(policies('gateone'))
    def set_location(self, location):
        """
        Attached to the `go:set_location` WebSocket action.  Sets
        ``self.location`` to the given value.

        This mechanism can be used by applications embedding Gate One to
        create/control groups of application resources (e.g. terminals) that
        each reside in unique virtual 'locations'.  Use this function to change
        locations on-the-fly without having to re-authenticate the user.

        .. note::

            If this location is new, ``self.locations[*location*]`` will be
            created automatically.
        """
        if location not in self.locations:
            self.locations[location] = {}
        self.location = location
        self.trigger("go:set_location", location)

    @require(authenticated(), policies('gateone'))
    def get_locations(self):
        """
        Attached to the `go:get_locations` WebSocket action.  Sends a message to
        the client (via the `go:locations` WebSocket action) with a dict
        containing location information for the connected user.
        """
        location_data = {}
        for location, apps in self.locations.items():
            location_data[location] = {}
            for name, values in apps.items():
                location_data[location][name] = {}
                for item, vals in values.items():
                    # This would be something like:
                    #  location     name     item     metadata
                    # {'default': {'terminal' {1: {'title': 'foo'}}}}
                    location_data[location][name][item] = {}
                    title = vals.get('title', 'Unknown')
                    location_data[location][name][item]['title'] = title
                    command = vals.get('command', 'Unknown')
                    location_data[location][name][item]['command'] = command
                    created = vals.get('created', 'Unknown')
                    if not isinstance(created, str):
                        # Convert it to a JavaScript-style timestamp
                        created = int(time.mktime(created.timetuple())) * 1000
                    location_data[location][name][item]['created'] = created
        message = {'go:locations': location_data}
        self.write_message(message)
        self.trigger("go:get_locations")

    def render_style(self, style_path, force=False, **kwargs):
        """
        Renders the CSS template at *style_path* using *kwargs* and returns the
        path to the rendered result.  If the given style has already been
        rendered the existing cache path will be returned.

        If *force* is ``True`` the stylesheet will be rendered even if it
        already exists (cached).

        This method also cleans up older versions of the same rendered template.
        """
        cache_dir = self.settings['cache_dir']
        if not isinstance(cache_dir, str):
            cache_dir = cache_dir.decode('utf-8')
        if not isinstance(style_path, str):
            style_path = style_path.decode('utf-8')
        mtime = os.stat(style_path).st_mtime
        shortened_path = short_hash(style_path)
        rendered_filename = 'rendered_%s_%s' % (shortened_path, int(mtime))
        rendered_path = os.path.join(cache_dir, rendered_filename)
        if not os.path.exists(rendered_path) or force:
            style_css = self.render_string(
                style_path,
                **kwargs
            )
            # NOTE: Tornado templates are always rendered as bytes.  That is why
            # we're using 'wb' below...
            with io.open(rendered_path, 'wb') as f:
                f.write(style_css)
            # Remove older versions of the rendered template if present
            for fname in os.listdir(cache_dir):
                if fname == rendered_filename:
                    continue
                elif shortened_path in fname:
                    # Older version present.
                    # Remove it (and it's minified counterpart).
                    os.remove(os.path.join(cache_dir, fname))
        return rendered_path

# TODO:  Get this checking the modification time of all theme files and only
#        rendering/sending a new theme if something has changed.
    def get_theme(self, settings):
        """
        Sends the theme stylesheets matching the properties specified in
        *settings* to the client.  *settings* must contain the following:

            * **container** - The element Gate One resides in (e.g. 'gateone')
            * **prefix** - The string being used to prefix all elements (e.g. 'go\_')
            * **theme** - The name of the CSS theme to be retrieved.

        .. note::

            This will send the theme files for all applications and plugins that
            have a matching stylesheet in their 'templates' directory.
        """
        self.logger.debug('get_theme(%s)' % settings)
        send_css = self.prefs['*']['gateone'].get('send_css', True)
        if not send_css:
            if not hasattr('logged_css_message', self):
                self.logger.info(_(
                    "send_css is false; will not send JavaScript."))
            # So we don't repeat this message a zillion times in the logs:
            self.logged_css_message = True
            return
        self.sync_log.info('Sync Theme: %s' % settings['theme'])
        use_client_cache = self.prefs['*']['gateone'].get(
            'use_client_cache', True)
        templates_path = os.path.join(GATEONE_DIR, 'templates')
        themes_path = os.path.join(templates_path, 'themes')
        go_url = settings['go_url'] # Used to prefix the url_prefix
        if not go_url.endswith('/'):
            go_url += '/'
        container = settings["container"]
        prefix = settings["prefix"]
        theme = settings["theme"]
        template_args = dict(
            container=container,
            prefix=prefix,
            url_prefix=go_url,
            embedded=self.settings['embedded']
        )
        out_dict = {'files': []}
        theme_filename = "%s.css" % theme
        theme_path = os.path.join(themes_path, theme_filename)
        template_loaders = tornado.web.RequestHandler._template_loaders
        # This wierd little bit empties Tornado's template cache:
        for web_template_path in template_loaders:
            template_loaders[web_template_path].reset()
        rendered_path = self.render_style(
            theme_path, **template_args)
        filename = os.path.split(rendered_path)[1]
        theme_files = []
        theme_files.append(rendered_path)
        # Now enumerate all applications/plugins looking for their own
        # implementations of this theme (must have same name).
        plugins_dir = os.path.join(GATEONE_DIR, 'plugins')
        # Find plugin's theme-specific CSS files
        for plugin in os.listdir(plugins_dir):
            plugin_dir = os.path.join(plugins_dir, plugin)
            themes_dir = os.path.join(plugin_dir, 'templates', 'themes')
            theme_css_file = os.path.join(themes_dir, theme_filename)
            if not os.path.exists(theme_css_file):
                continue
            rendered_path = self.render_style(
                theme_css_file, **template_args)
            theme_files.append(rendered_path)
        # Find application's theme-specific CSS files
        applications_dir = os.path.join(GATEONE_DIR, 'applications')
        for app in os.listdir(applications_dir):
            app_dir = os.path.join(applications_dir, app)
            themes_dir = os.path.join(app_dir, 'templates', 'themes')
            theme_css_file = os.path.join(themes_dir, theme_filename)
            if not os.path.exists(theme_css_file):
                continue
            rendered_path = self.render_style(
                theme_css_file, **template_args)
            theme_files.append(rendered_path)
            # Find application plugin's theme-specific CSS files
            plugins_dir = os.path.join(app_dir, 'plugins')
            if not os.path.exists(plugins_dir):
                continue
            for plugin in os.listdir(plugins_dir):
                plugin_dir = os.path.join(plugins_dir, plugin)
                themes_dir = os.path.join(plugin_dir, 'templates', 'themes')
                theme_css_file = os.path.join(themes_dir, theme_filename)
                if not os.path.exists(theme_css_file):
                    continue
                rendered_path = self.render_style(
                    theme_css_file, **template_args)
                theme_files.append(rendered_path)
        # Combine the theme files into one
        filename = 'theme.css'
        filename_hash = hashlib.md5(
            filename.encode('utf-8')).hexdigest()[:10]
        cache_dir = self.settings['cache_dir']
        cached_theme_path = os.path.join(cache_dir, filename)
        new_theme_path = os.path.join(cache_dir, filename+'.new')
        with io.open(new_theme_path, 'wb') as f:
            for path in theme_files:
                f.write(io.open(path, 'rb').read())
        with open(new_theme_path, 'rb') as f:
            new = f.read()
        old = ''
        if os.path.exists(cached_theme_path):
            with open(cached_theme_path, 'rb') as f:
                old = f.read()
        if new != old:
            # They're different.  Replace the old one...
            os.rename(new_theme_path, cached_theme_path)
        else:
            # Clean up
            os.remove(new_theme_path)
        mtime = os.stat(cached_theme_path).st_mtime
        if self.settings['debug']:
            # This makes sure that the files are always re-downloaded
            mtime = time.time()
        kind = 'css'
        out_dict['files'].append({
            'filename': filename,
            'hash': filename_hash,
            'mtime': mtime,
            'kind': kind,
            'element_id': 'theme'
        })
        self.file_cache[filename_hash] = {
            'filename': filename,
            'kind': kind,
            'path': cached_theme_path,
            'mtime': mtime,
            'element_id': 'theme'
        }
        if use_client_cache:
            message = {'go:file_sync': out_dict}
            self.write_message(message)
        else:
            self.file_request(filename_hash, use_client_cache=use_client_cache)

    @require(authenticated())
    def get_js(self, filename):
        """
        Attempts to find the specified *filename* file in Gate One's static
        directories (GATEONE_DIR/static/ and each plugin's respective 'static'
        dir).

        In the event that a plugin's JavaScript file has the same name as a file
        in GATEONE_DIR/static/ the plugin's copy of the file will take
        precedence.  This is to allow plugins to override defaults.

        .. note::

            This will alow authenticated clients to download whatever file they
            want that ends in .js inside of /static/ directories.
        """
        self.logger.info('get_js(%s)' % filename)
        out_dict = {'result': 'Success', 'filename': filename, 'data': None}
        js_files = {} # Key:value == 'somefile.js': '/full/path/to/somefile.js'
        static_dir = os.path.join(GATEONE_DIR, 'static')
        for f in os.listdir(static_dir):
            if f.endswith('.js'):
                js_file_path = os.path.join(static_dir, f)
                js_files.update({f: js_file_path})
        # Build a list of plugins
        plugins = []
        plugins_dir = os.path.join(GATEONE_DIR, 'plugins')
        for f in os.listdir(plugins_dir):
            if os.path.isdir(os.path.join(plugins_dir, f)):
                plugins.append(f)
        # Add each found JS file to the respective dict
        for plugin in plugins:
            plugin_static_path = os.path.join(plugins_dir, plugin, 'static')
            if os.path.exists(plugin_static_path):
                for f in os.listdir(plugin_static_path):
                    if f.endswith('.js'):
                        js_file_path = os.path.join(plugin_static_path, f)
                        js_files.update({f: js_file_path})
        if filename in list(js_files.keys()):
            with io.open(js_files[filename], encoding='utf-8') as f:
                out_dict['data'] = f.read()
        message = {'go:load_js': out_dict}
        self.write_message(message)

    def cache_cleanup(self, message):
        """
        Attached to the `go:cache_cleanup` WebSocket action; rifles through the
        given list of *message['filenames']* from the client and sends a
        `go:cache_expired` WebSocket action to the client with a list of files
        that no longer exist in `self.file_cache` (so it can clean them up).
        """
        logging.debug("cache_cleanup(%s)" % message)
        filenames = message['filenames']
        kind = message['kind']
        expired = []
        for filename_hash in filenames:
            if filename_hash not in self.file_cache:
                expired.append(filename_hash)
        if not expired:
            logging.debug(_(
                "No expired %s files at client %s" %
                (kind, self.request.remote_ip)))
            return
        logging.debug(_(
            "Requesting deletion of expired files at client %s: %s" % (
            self.request.remote_ip, filenames)))
        message = {'go:cache_expired': message}
        self.write_message(message)
        # Also clean up stale files in the cache while we're at it
        newest_files = {}
        for filename_hash, file_obj in list(self.file_cache.items()):
            filename = file_obj['filename']
            if filename not in newest_files:
                newest_files[filename] = file_obj
                newest_files[filename]['filename_hash'] = filename_hash
            if file_obj['mtime'] > newest_files[filename]['mtime']:
                # Delete then replace the stale one
                stale_hash = newest_files[filename]['filename_hash']
                del self.file_cache[stale_hash]
                newest_files[file_obj['filename']] = file_obj
            if file_obj['mtime'] < newest_files[filename]['mtime']:
                del self.file_cache[filename_hash] # Stale

    def file_request(self, files_or_hash, use_client_cache=True):
        """
        Attached to the `go:file_request` WebSocket action; minifies, caches,
        and finally sends the requested file to the client.  If
        *use_client_cache* is `False` the client will be instructed not to cache
        the file.  Example message from the client requesting a file:

        .. code-block:: javascript

            GateOne.ws.send(JSON.stringify({
                'go:file_request': {'some_file.js'}}));

        .. note:: In reality 'some_file.js' will be a unique/unguessable hash.

        Optionally, *files_or_hash* may be given as a list or tuple and all the
        requested files will be sent.

        Files will be cached after being minified until a file is modified or
        Gate One is restarted.

        If the `slimit` module is installed JavaScript files will be minified
        before being sent to the client.

        If the `cssmin` module is installed CSS files will be minified before
        being sent to the client.
        """
        self.sync_log.debug(
            "file_request(%s, use_client_cache=%s)" % (
                files_or_hash, use_client_cache))
        if isinstance(files_or_hash, (list, tuple)):
            for filename_hash in files_or_hash:
                self.file_request(
                    filename_hash, use_client_cache=use_client_cache)
            return
        else:
            filename_hash = files_or_hash
        if filename_hash not in self.file_cache:
            error_msg = _('File Request Error: File not found ({0})').format(
                filename_hash)
            self.logger.warning(error_msg)
            out_dict = {
                'result': error_msg,
                'filename': filename_hash
            }
            self.write_message({'go:load_js': out_dict})
            return
        # Get the file info out of the file_cache so we can send it
        element_id = self.file_cache[filename_hash].get('element_id', None)
        path = self.file_cache[filename_hash]['path']
        filename = self.file_cache[filename_hash]['filename']
        kind = self.file_cache[filename_hash]['kind']
        mtime = self.file_cache[filename_hash]['mtime']
        requires = self.file_cache[filename_hash].get('requires', None)
        media = self.file_cache[filename_hash].get('media', 'screen')
        url_prefix = self.settings['url_prefix']
        self.sync_log.info("Sending: {0}".format(filename))
        out_dict = {
            'result': 'Success',
            'cache': use_client_cache,
            'mtime': mtime,
            'filename': filename,
            'hash': filename_hash,
            'kind': kind,
            'element_id': element_id,
            'requires': requires,
            'media': media
        }
        cache_dir = self.settings['cache_dir']
        def send_file(result):
            """
            Adds our minified data to the out_dict and sends it to the
            client.
            """
            out_dict['data'] = result
            if kind == 'js':
                source_url = None
                if 'gateone/applications/' in path:
                    application = path.split('applications/')[1].split('/')[0]
                    if 'plugins' in path:
                        static_path = path.split("%s/plugins/" % application)[1]
                        # /terminal/ssh/static/
                        source_url = "%s%s/%s" % (
                            url_prefix, application, static_path)
                    else:
                        static_path = path.split("%s/static/" % application)[1]
                        source_url = "%s%s/static/%s" % (
                            url_prefix, application, static_path)
                elif 'gateone/plugins/' in path:
                    plugin_name = path.split(
                        'gateone/plugins/')[1].split('/')[0]
                    static_path = path.split("%s/static/" % plugin_name)[1]
                    source_url = "%splugins/%s/static/%s" % (
                        url_prefix, plugin_name, static_path)
                if source_url:
                    out_dict['data'] += "\n//# sourceURL={source_url}\n".format(
                        source_url=source_url)
                message = {'go:load_js': out_dict}
            elif kind == 'css':
                out_dict['css'] = True # So loadStyleAction() knows what to do
                message = {'go:load_style': out_dict}
            elif kind == 'theme':
                out_dict['theme'] = True
                message = {'go:load_theme': out_dict}
            try:
                self.write_message(message)
            except (WebSocketClosedError, AttributeError):
                pass # WebSocket closed before we got a chance to send this
        if self.settings['debug']:
            result = get_or_cache(cache_dir, path, minify=False)
            send_file(result)
        else:
            # NOTE: We disable memoization below because get_or_cache() does its
            # own check to see if processing the file is necessary.
            CPU_ASYNC.call(get_or_cache, cache_dir, path,
                           minify=True, callback=send_file, memoize=False)

    def send_js_or_css(self, paths_or_fileobj, kind,
            element_id=None, requires=None, media="screen", filename=None):
        """
        Initiates a file synchronization of the given *paths_or_fileobj* with
        the client to ensure it has the latest version of the file(s).

        The *kind* argument must be one of 'js' or 'css' to indicate JavaScript
        or CSS, respectively.

        Optionally, *element_id* may be provided which will be assigned to the
        <script> or <style> tag that winds up being created (only works with
        single files).

        Optionally, a *requires* string or list/tuple may be given which will
        ensure that the given file gets loaded after any dependencies.

        Optionally, a *media* string may be provided to specify the 'media='
        value when creating a <style> tag to hold the given CSS.

        Optionally, a *filename* string may be provided which will be used
        instead of the name of the actual file when file synchronization occurs.
        This is useful for multi-stage processes (e.g. rendering templates)
        where you wish to preserve the original filename.  Just be aware that
        if you do this the given *filename* must be unique.

        .. note:

            If the slimit module is installed it will be used to minify the JS
            before being sent to the client.
        """
        if kind == 'js':
            send_js = self.prefs['*']['gateone'].get('send_js', True)
            if not send_js:
                if not hasattr('logged_js_message', self):
                    self.logger.info(_(
                        "send_js is false; will not send JavaScript."))
                # So we don't repeat this message a zillion times in the logs:
                self.logged_js_message = True
                return
        elif kind == 'css':
            send_css = self.prefs['*']['gateone'].get('send_css', True)
            if not send_css:
                if not hasattr('logged_css_message', self):
                    self.logger.info(_("send_css is false; will not send CSS."))
                # So we don't repeat this message a zillion times in the logs:
                self.logged_css_message = True
        use_client_cache = self.prefs['*']['gateone'].get(
            'use_client_cache', True)
        if requires and not isinstance(requires, (tuple, list)):
            requires = [requires] # This makes the logic simpler at the client
        if isinstance(paths_or_fileobj, (tuple, list)):
            out_dict = {'files': []}
            for file_obj in paths_or_fileobj:
                if isinstance(file_obj, basestring):
                    path = file_obj
                    if not filename:
                        filename = os.path.split(path)[1]
                else:
                    file_obj.seek(0) # Just in case
                    path = file_obj.name
                    if not filename:
                        filename = os.path.split(file_obj.name)[1]
                self.sync_log.info(
                    "Sync check: {filename}".format(filename=filename))
                mtime = os.stat(path).st_mtime
                filename_hash = hashlib.md5(
                    filename.encode('utf-8')).hexdigest()[:10]
                self.file_cache[filename_hash] = {
                    'filename': filename,
                    'kind': kind,
                    'path': path,
                    'mtime': mtime,
                    'element_id': element_id,
                    'requires': requires,
                    'media': media # NOTE: Ignored if JS
                }
                if self.settings['debug']:
                    # This makes sure that the files are always re-downloaded
                    mtime = time.time()
                out_dict['files'].append({
                    'filename': filename,
                    'hash': filename_hash,
                    'mtime': mtime,
                    'kind': kind,
                    'requires': requires,
                    'element_id': element_id,
                    'media': media # NOTE: Ignored if JS
                })
            if use_client_cache:
                message = {'go:file_sync': out_dict}
                self.write_message(message)
            else:
                files = [a['filename'] for a in out_dict['files']]
                self.file_request(files, use_client_cache=use_client_cache)
            return # No further processing is necessary
        elif isinstance(paths_or_fileobj, basestring):
            path = paths_or_fileobj
            if not filename:
                filename = os.path.split(path)[1]
        else:
            paths_or_fileobj.seek(0) # Just in case
            path = paths_or_fileobj.name
            if not filename:
                filename = os.path.split(paths_or_fileobj.name)[1]
        self.sync_log.info(
            "Sync check: {filename}".format(filename=filename))
        # NOTE: The .split('.') above is so the hash we generate is always the
        # same.  The tail end of the filename will have its modification date.
        # Cache the metadata for sync
        mtime = os.stat(path).st_mtime
        logging.debug('send_js_or_css(%s) (mtime: %s)' % (path, mtime))
        if not os.path.exists(path):
            self.logger.error(_("send_js_or_css(): File not found: %s" % path))
            return
        # Use a hash of the filename because these names can get quite long.
        # Also, we don't want to reveal the file structure on the server.
        filename_hash = hashlib.md5(
            filename.encode('utf-8')).hexdigest()[:10]
        self.file_cache[filename_hash] = {
            'filename': filename,
            'kind': kind,
            'path': path,
            'mtime': mtime,
            'element_id': element_id,
            'requires': requires,
            'media': media # NOTE: Ignored if JS
        }
        if self.settings['debug']:
            # This makes sure that the files are always re-downloaded
            mtime = time.time()
        out_dict = {'files': [{
            'filename': filename,
            'hash': filename_hash,
            'mtime': mtime,
            'kind': kind,
            'requires': requires,
            'element_id': element_id,
            'media': media # NOTE: Ignored if JS
        }]}
        if use_client_cache:
            message = {'go:file_sync': out_dict}
            self.write_message(message)
        else:
            files = [a['filename'] for a in out_dict['files']]
            self.file_request(files, use_client_cache=use_client_cache)

    def send_js(self, path, **kwargs):
        """
        A shortcut for ``self.send_js_or_css(path, 'js', **kwargs)``.
        """
        self.send_js_or_css(path, 'js', **kwargs)

    def send_css(self, path, **kwargs):
        """
        A shortcut for ``self.send_js_or_css(path, 'css', **kwargs)``
        """
        self.send_js_or_css(path, 'css', **kwargs)

    def wrap_and_send_js(self, js_path, exports={}, **kwargs):
        """
        Wraps the JavaScript code at *js_path* in a (JavaScript) sandbox which
        exports whatever global variables are provided via *exports* then
        minifies, caches, and sends the result to the client.

        The provided *kwargs* will be passed to the
        `ApplicationWebSocket.send_js` method.

        The *exports* dict needs to be in the following format::

            exports = {
                "global": "export_name"
            }

        For example, if you wanted to use underscore.js but didn't want to
        overwrite the global ``_`` variable (if already being used by a parent
        web application)::

            exports = {"_": "GateOne._"}
            self.wrap_and_send_js('/path/to/underscore.js', exports)

        This would result in the "_" global being exported as "GateOne._".  In
        other words, this is what will end up at the bottom of the wrapped
        JavaScript just before the end of the sandbox:

        .. code-block:: javascript

            window.GateOne._ = _;

        This method should make it easy to include any given JavaScript library
        without having to worry (as much) about namespace conflicts.

        .. note::

            You don't have to prefix your export with 'GateOne'.  You can export
            the global with whatever name you like.
        """
        if not os.path.exists(js_path):
            self.sync_log.error(_("File does not exist: {0}").format(js_path))
            return
        cache_dir = self.settings['cache_dir']
        mtime = os.stat(js_path).st_mtime
        filename = os.path.split(js_path)[1]
        script = {'name': filename}
        filepath_hash = hashlib.md5(
            js_path.encode('utf-8')).hexdigest()[:10]
        # Store the file info in the file_cache just in case we need to
        # reference the original (non-rendered) path later:
        self.file_cache[filepath_hash] = {
            'filename': filename,
            'kind': 'js',
            'path': js_path,
            'mtime': mtime,
        }
        rendered_filename = 'rendered_%s_%s' % (filepath_hash, int(mtime))
        rendered_path = os.path.join(cache_dir, rendered_filename)
        if os.path.exists(rendered_path):
            self.send_js(rendered_path, filename=filename, **kwargs)
            return
        libwrapper = os.path.join(GATEONE_DIR, 'templates', 'libwrapper.js')
        with io.open(js_path, 'rb') as f:
            script['source'] = f.read()
        template_loaders = tornado.web.RequestHandler._template_loaders
        # This wierd little bit empties Tornado's template cache:
        for web_template_path in template_loaders:
            template_loaders[web_template_path].reset()
        rendered = self.render_string(
            libwrapper,
            script=script,
            exports=exports
        )
        with io.open(rendered_path, 'wb') as f:
            f.write(rendered)
        self.send_js(rendered_path, filename=filename, **kwargs)
        # Remove older versions of the rendered template if present
        for fname in os.listdir(cache_dir):
            if fname == rendered_filename:
                continue
            elif filepath_hash in fname:
                # Older version present.
                # Remove it (and it's minified counterpart).
                os.remove(os.path.join(cache_dir, fname))
        return rendered_path

    def render_and_send_css(self,
            css_path, element_id=None, media="screen", **kwargs):
        """
        Renders, caches (in the `cache_dir`), and sends a stylesheet template at
        the given *css_path*.  The template will be rendered with the following
        keyword arguments::

            container = self.container
            prefix = self.prefix
            url_prefix = self.settings['url_prefix']
            **kwargs

        Returns the path to the rendered template.

        .. note::

            If you want to serve Gate One's CSS via a different mechanism
            (e.g. nginx) this functionality can be completely disabled by adding
            `"send_css": false` to gateone/settings/10server.conf
        """
        send_css = self.prefs['*']['gateone'].get('send_css', True)
        if not send_css:
            if not hasattr('logged_css_message', self):
                self.logger.info(_("send_css is false; will not send CSS."))
            # So we don't repeat this message a zillion times in the logs:
            self.logged_css_message = True
            return
        if not os.path.exists(css_path):
            self.sync_log.error(_("File does not exist: {0}").format(css_path))
            return
        cache_dir = self.settings['cache_dir']
        mtime = os.stat(css_path).st_mtime
        filename = os.path.split(css_path)[1]
        filepath_hash = hashlib.md5(css_path.encode('utf-8')).hexdigest()[:10]
        # Store the file info in the file_cache just in case we need to
        # reference the original (non-rendered) path later:
        self.file_cache[filepath_hash] = {
            'filename': filename,
            'kind': 'css',
            'path': css_path,
            'mtime': mtime,
        }
        rendered_filename = 'rendered_%s_%s' % (filepath_hash, int(mtime))
        rendered_path = os.path.join(cache_dir, rendered_filename)
        if os.path.exists(rendered_path):
            self.send_css(rendered_path,
                element_id=element_id, media=media, filename=filename)
            return
        template_loaders = tornado.web.RequestHandler._template_loaders
        # This wierd little bit empties Tornado's template cache:
        for web_template_path in template_loaders:
            template_loaders[web_template_path].reset()
        rendered = self.render_string(
            css_path,
            container=self.container,
            prefix=self.prefix,
            url_prefix=self.settings['url_prefix'],
            **kwargs
        )
        with io.open(rendered_path, 'wb') as f:
            f.write(rendered)
        self.send_css(rendered_path,
            element_id=element_id, media=media, filename=filename)
        # Remove older versions of the rendered template if present
        for fname in os.listdir(cache_dir):
            if fname == rendered_filename:
                continue
            elif filepath_hash in fname:
                # Older version present.
                # Remove it (and it's minified counterpart).
                os.remove(os.path.join(cache_dir, fname))
        return rendered_path

    def send_plugin_static_files(self,
        plugins_dir, application=None, requires=None):
        """
        Sends all plugin .js and .css files to the client that exist inside
        *plugins_dir*.  Optionally, if *application* is given the policies that
        apply to the current user for that application will be used to determine
        whether or not a given plugin's static files will be sent.

        If *requires* is given it will be passed along to `self.send_js()`.

        .. note::

            If you want to serve Gate One's JavaScript via a different mechanism
            (e.g. nginx) this functionality can be completely disabled by adding
            `"send_js": false` to gateone/settings/10server.conf
        """
        logging.debug('send_plugin_static_files(%s)' % plugins_dir)
        send_js = self.prefs['*']['gateone'].get('send_js', True)
        if not send_js:
            if not hasattr('logged_js_message', self):
                self.logger.info(_(
                    "send_js is false; will not send JavaScript."))
            # So we don't repeat this message a zillion times in the logs:
            self.logged_js_message = True
            return
        policy = applicable_policies(application, self.current_user, self.prefs)
        globally_enabled_plugins = policy.get('enabled_plugins', [])
        # This controls the client-side plugins that will be sent
        allowed_client_side_plugins = policy.get('user_plugins', [])
        # Remove non-globally-enabled plugins from user_plugins (if set)
        if globally_enabled_plugins and list(allowed_client_side_plugins):
            for p in allowed_client_side_plugins:
                if p not in globally_enabled_plugins:
                    del allowed_client_side_plugins[p]
        elif globally_enabled_plugins and not allowed_client_side_plugins:
            allowed_client_side_plugins = globally_enabled_plugins
        # Build a list of plugins
        plugins = []
        if not os.path.exists(plugins_dir):
            return # Nothing to do
        for f in os.listdir(plugins_dir):
            if os.path.isdir(os.path.join(plugins_dir, f)):
                if allowed_client_side_plugins:
                    if f in allowed_client_side_plugins:
                        plugins.append(f)
                else:
                    plugins.append(f)
        # Add each found JS file to the respective dict
        for plugin in plugins:
            plugin_static_path = os.path.join(plugins_dir, plugin, 'static')
            if os.path.exists(plugin_static_path):
                static_files = os.listdir(plugin_static_path)
                static_files.sort()
                for f in static_files:
                    if f.endswith('.js'):
                        js_file_path = os.path.join(plugin_static_path, f)
                        self.send_js(js_file_path, requires=requires)
                    elif f.endswith('.css'):
                        css_file_path = os.path.join(plugin_static_path, f)
                        self.send_css(css_file_path, filename=f)

# TODO:  Add support for a setting that can control which themes are visible to users.
    def enumerate_themes(self):
        """
        Returns a JSON-encoded object containing the installed themes and text
        color schemes.
        """
        templates_path = os.path.join(GATEONE_DIR, 'templates')
        themes_path = os.path.join(templates_path, 'themes')
        # NOTE: This is temporary until this logic is moved to the terminal app:
        colors_path = os.path.join(GATEONE_DIR,
            'applications', 'terminal', 'templates', 'term_colors')
        themes = os.listdir(themes_path)
        themes = [a.replace('.css', '') for a in themes]
        colors = os.listdir(colors_path)
        colors = [a.replace('.css', '') for a in colors]
        message = {'go:themes_list': {'themes': themes, 'colors': colors}}
        self.write_message(message)

    @require(authenticated())
    def set_locale(self, message):
        """
        Sets the client's locale to *message['locale']*.
        """
        self.prefs['*']['gateone']['locale'] = message['locale']
        self.send_js_translation()

    def send_js_translation(self, path=None):
        """
        Sends a message to the client containing a JSON-encoded table of strings
        that have been translated to the user's locale.

        If a *path* is given it will be used to send the client that file.  If
        more than one JSON translation is sent to the client the new translation
        will be merged into the existing one.

        .. note::

            Translation files must be the result of a
            `pojson /path/to/translation.po` conversion.
        """
        chosen_locale = self.prefs['*']['gateone'].get('locale', 'en_US')
        json_translation = os.path.join(
            GATEONE_DIR,
            'i18n',
            chosen_locale,
            'LC_MESSAGES',
            'gateone_js.json')
        if path:
            if os.path.exists(path):
                with io.open(path, 'r', encoding="utf-8") as f:
                    decoded = json_decode(f.read())
                    message = {'go:register_translation': decoded}
                    self.write_message(message)
            else:
                self.logger.error(
                    _("Translation file, %s could not be found") % path)
        elif os.path.exists(json_translation):
            with io.open(json_translation, 'r', encoding="utf-8") as f:
                decoded = json_decode(f.read())
                message = {'go:register_translation': decoded}
                self.write_message(message)

# NOTE: This is not meant to be a chat application.  That'll come later :)
#       The real purpose of send_user_message() and broadcast() are for
#       programmatic use.  For example, when a user shares a terminal and it
#       would be appropriate to notify certain users that the terminal is now
#       available for them to connect.
    @require(authenticated(), policies('gateone'))
    def send_user_message(self, settings):
        """
        Sends the given *settings['message']* to the given *settings['upn']*.

        if *upn* is 'AUTHENTICATED' all users will get the message.  Example:

        .. code-block:: javascript

            var obj = {"message": "This is a test", "upn": "joe@company.com"}
            GateOne.ws.send(JSON.stringify({"go:send_user_message": obj}));
        """
        if 'message' not in settings:
            self.send_message(_("Error: No message to send."))
            return
        if 'upn' not in settings:
            self.send_message(_("Error: Missing UPN."))
            return
        metadata = {"to": settings["upn"]}
        self.msg_log.info(
            _("User Message: {0}").format(settings["message"]),
            metadata=metadata)
        self.send_message(settings['message'], upn=settings['upn'])
        self.trigger('go:send_user_message', settings)

    def send_message(self, message, session=None, upn=None):
        """
        Sends the given *message* to the client using the `go:user_message`
        WebSocket action at the currently-connected client.

        If *upn* is provided the *message* will be sent to all users with a
        matching 'upn' value.

        If *session* is provided the message will be sent to all users with a
        matching session ID.  This is useful in situations where all users share
        the same 'upn' (i.e. ANONYMOUS).

        if *upn* is 'AUTHENTICATED' all users will get the message.
        """
        message_dict = {'go:user_message': message}
        if upn:
            ApplicationWebSocket._deliver(message_dict, upn=upn)
        elif session:
            ApplicationWebSocket._deliver(message_dict, session=session)
        else: # Just send to the currently-connected client
            self.write_message(message_dict)
        self.trigger('go:send_message', message, upn, session)

    @require(authenticated(), policies('gateone'))
    def broadcast(self, message):
        """
        Attached to the `go:broadcast` WebSocket action; sends the given
        *message* (string) to all connected, authenticated users.  Example
        usage:

        .. code-block:: javascript

            GateOne.ws.send(JSON.stringify({"go:broadcast": "This is a test"}));
        """
        self.msg_log.info("Broadcast: %s" % message)
        from .utils import strip_xss # Prevent XSS attacks
        message, bad_tags = strip_xss(message, replacement="entities")
        self.send_message(message, upn="AUTHENTICATED")
        self.trigger('go:broadcast', message)

    @require(authenticated(), policies('gateone'))
    def list_server_users(self):
        """
        Returns a list of users currently connected to the Gate One server to
        the client via the 'go:user_list' WebSocket action.  Only users with the
        'list_users' policy are allowed to execute this action.  Example:

        .. code-block:: javascript

            GateOne.ws.send(JSON.stringify({"go:list_users": null}));

        That would send a JSON message to the client like so::

            {
                "go:user_list": [
                    {"upn": "user@enterprise", "ip_address": "10.0.1.11"},
                    {"upn": "bsmith@enterprise", "ip_address": "10.0.2.15"}
                ]
            }
        """
        users = ApplicationWebSocket._list_connected_users()
        logging.debug('list_server_users(): %s' % repr(users))
        # Remove things that users should not see such as their session ID
        filtered_users = []
        policy = applicable_policies('gateone', self.current_user, self.prefs)
        allowed_fields = policy.get('user_list_fields', False)
        # If not set, just strip the session ID
        if not allowed_fields:
            allowed_fields = ('upn', 'ip_address')
        for user in users:
            if not user: # Broadcast client (view-only situation)
                continue
            user_dict = {}
            for key, value in user.items():
                if key in allowed_fields:
                    user_dict[key] = value
            filtered_users.append(user_dict)
        message = {'go:user_list': filtered_users}
        self.write_message(json_encode(message))
        self.trigger('go:user_list', filtered_users)

    @classmethod
    def _deliver(cls, message, upn="AUTHENTICATED", session=None):
        """
        Writes the given *message* (string) to all users matching *upn* using
        the write_message() function.  If *upn* is not provided or is
        "AUTHENTICATED", will send the *message* to all users.

        Alternatively a *session* ID may be specified instead of a *upn*.  This
        is useful when more than one user shares a UPN (i.e. ANONYMOUS).
        """
        logging.debug("_deliver(%s, upn=%s, session=%s)" %
            (message, upn, session))
        for instance in cls.instances:
            try: # Only send to users that have authenticated
                user = instance.current_user
            except (WebSocketClosedError, AttributeError):
                continue
            if session and user and user.get('session', None) == session:
                instance.write_message(message)
            elif upn == "AUTHENTICATED":
                instance.write_message(message)
            elif user and upn == user.get('upn', None):
                instance.write_message(message)

    @classmethod
    def _list_connected_users(cls):
        """
        Returns a tuple of user objects representing the users that are
        currently connected (and authenticated) to this Gate One server.
        """
        logging.debug("_list_connected_users()")
        out = []
        for instance in cls.instances:
            try: # We only care about authenticated users
                out.append(instance.current_user)
            except AttributeError:
                continue
        return tuple(out)

    @require(authenticated(), policies('gateone'))
    def debug(self):
        """
        Imports Python's Garbage Collection module (gc) and displays various
        information about the current state of things inside of Gate One.

        .. note:: Can only be called from a JavaScript console like so...

        .. code-block:: javascript

            GateOne.ws.send(JSON.stringify({'go:debug': null}));
        """
        # NOTE: Making a debug-specific logger but logging using info() so that
        # the log messages show up even if I don't have logging set to debug.
        # Since this debugging function is only ever called manually there's no
        # need to use debug() logging.
        metadata = {
            'upn': self.current_user['upn'],
            'ip_address': self.request.remote_ip,
            'location': self.location
        }
        debug_logger = go_logger("gateone.debugging", **metadata)
        import gc
        #gc.set_debug(gc.DEBUG_UNCOLLECTABLE|gc.DEBUG_OBJECTS)
        gc.set_debug(
            gc.DEBUG_UNCOLLECTABLE | gc.DEBUG_INSTANCES | gc.DEBUG_OBJECTS)
        # Using pprint for some things below instead of the logger because they
        # just won't look right if they go to the logs.
        from pprint import pprint
        pprint(gc.garbage)
        debug_logger.info("Debug: gc.collect(): %s" % gc.collect())
        pprint(gc.garbage)
        print("SESSIONS:")
        pprint(SESSIONS)
        print("PERSIST:")
        pprint(PERSIST)
        try:
            from pympler import asizeof
            debug_logger.info(
                "Debug: Size of SESSIONS dict: %s" % asizeof.asizeof(SESSIONS))
        except ImportError:
            pass # No biggie
        try:
            # NOTE: For this Heapy stuff to work best you have to make more then
            # one call to this function (just do it at regular intervals).
            from guppy import hpy
            if not hasattr(self, 'hp'):
                self.hp = hpy()
                self.hp.setrelheap() # We only want to track NEW stuff
            print("Heap:")
            h = self.hp.heap()
            print(h)
            # Uncomment this to troubleshoot memory leaks.  If any exist this
            # loop will shine a light on them:
            #print("Heap Details (up to top 10):")
            #for i in range(10):
                #try:
                    #print(h.byrcs[i].byid)
                #except IndexError:
                    #break
        except ImportError:
            pass # Oh well

class ErrorHandler(tornado.web.RequestHandler):
    """
    Generates an error response with status_code for all requests.
    """
    def __init__(self, application, request, status_code):
        tornado.web.RequestHandler.__init__(self, application, request)
        self.set_status(status_code)

    def get_error_html(self, status_code, **kwargs):
        self.set_header('Server', 'GateOne')
        self.set_header('License', __license__)
        self.require_setting("static_url")
        if status_code in [404, 500, 503, 403]:
            filename = os.path.join(
                self.settings['static_url'], '%d.html' % status_code)
            if os.path.exists(filename):
                with io.open(filename, 'rb') as f:
                    data = f.read()
                return data
        import httplib
        return "<html><title>%(code)d: %(message)s</title>" \
           "<body class='bodyErrorPage'>%(code)d: %(message)s</body></html>" % {
               "code": status_code,
               "message": httplib.responses[status_code],
        }

    def prepare(self):
        raise tornado.web.HTTPError(self._status_code)

class GateOneApp(tornado.web.Application):
    def __init__(self, settings, **kwargs):
        """
        Setup our Tornado application...  Everything in *settings* will wind up
        in the Tornado settings dict so as to be accessible under self.settings.
        """
        global PLUGIN_WS_CMDS
        global PLUGIN_COMMAND_HOOKS
        global PLUGIN_ESC_HANDLERS
        global PLUGIN_AUTH_HOOKS
        global PLUGIN_TERM_HOOKS
        global PLUGIN_NEW_TERM_HOOKS
        global PLUGIN_NEW_MULTIPLEX_HOOKS
        global PLUGIN_ENV_HOOKS
        # Base settings for our Tornado app
        static_url = os.path.join(GATEONE_DIR, "static")
        tornado_settings = dict(
            cookie_secret=settings['cookie_secret'],
            static_url=static_url,
            static_url_prefix="%sstatic/" % settings['url_prefix'],
            gzip=True,
            login_url="%sauth" % settings['url_prefix']
        )
        # Make sure all the provided settings wind up in self.settings
        for k, v in settings.items():
            tornado_settings[k] = v
        # Setup the configured authentication type
        AuthHandler = NullAuthHandler # Default
        if 'auth' in settings and settings['auth']:
            if settings['auth'] == 'kerberos' and KerberosAuthHandler:
                AuthHandler = KerberosAuthHandler
            elif settings['auth'] == 'pam' and PAMAuthHandler:
                AuthHandler = PAMAuthHandler
            elif settings['auth'] == 'google':
                AuthHandler = GoogleAuthHandler
            elif settings['auth'] == 'cas':
                AuthHandler = CASAuthHandler
            elif settings['auth'] == 'ssl':
                AuthHandler = SSLAuthHandler
            elif settings['auth'] == 'api':
                AuthHandler = APIAuthHandler
            auth_log.info(_("Using %s authentication") % settings['auth'])
        else:
            auth_log.info(_(
                "No authentication method configured. All users will be "
                "ANONYMOUS"))
        docs_path = os.path.join(GATEONE_DIR, 'docs')
        docs_path = os.path.join(docs_path, 'build')
        docs_path = os.path.join(docs_path, 'html')
        url_prefix = settings['url_prefix']
        if not url_prefix.endswith('/'):
            # Make sure there's a trailing slash
            url_prefix = "%s/" % url_prefix
        # Make the / optional in the regex so it works with the @addslash
        # decorator.  e.g. "/whatever/" would become "/whatever/?"
        index_regex = "%s?" % url_prefix
        # Setup our URL handlers
        handlers = [
            (index_regex, MainHandler),
            (r"%sws" % url_prefix,
                ApplicationWebSocket, dict(apps=APPLICATIONS)),
            (r"%sauth" % url_prefix, AuthHandler),
            (r"%sdownloads/(.*)" % url_prefix, DownloadHandler),
            (r"%sdocs/(.*)" % url_prefix, tornado.web.StaticFileHandler, {
                "path": docs_path,
                "default_filename": "index.html"
            })
        ]
        if 'web_handlers' in kwargs:
            for handler_tuple in kwargs['web_handlers']:
                regex = handler_tuple[0]
                handler = handler_tuple[1]
                kwargs = {}
                try:
                    kwargs = handler_tuple[2]
                except IndexError:
                    pass # No kwargs for this handler
                # Make sure the regex is prefix with the url_prefix
                if not regex.startswith(url_prefix):
                    regex = "%s%s" % (url_prefix, regex)
                handlers.append((regex, handler, kwargs))
        # Override the default static handler to ensure the headers are set
        # to allow cross-origin requests.
        handlers.append(
            (r"%sstatic/(.*)" % url_prefix, StaticHandler, {"path": static_url}
        ))
        # Hook up the hooks
        for plugin_name, hooks in PLUGIN_HOOKS.items():
            if 'Web' in hooks:
                # Apply the plugin's Web handlers
                fixed_hooks = []
                if isinstance(hooks['Web'], (list, tuple)):
                    for h in hooks['Web']:
                        # h == (regex, Handler)
                        if not h[0].startswith(url_prefix): # Fix it
                            h = (url_prefix + h[0].lstrip('/'), h[1])
                            fixed_hooks.append(h)
                        else:
                            fixed_hooks.append(h)
                else:
                    if not hooks['Web'][0].startswith(url_prefix): # Fix it
                        hooks['Web'] = (
                            url_prefix + hooks['Web'][0].lstrip('/'),
                            hooks['Web'][1]
                        )
                        fixed_hooks.append(hooks['Web'])
                    else:
                        fixed_hooks.append(hooks['Web'])
                handlers.extend(fixed_hooks)
            if 'WebSocket' in hooks:
                # Apply the plugin's WebSocket commands
                print("hooks['WebSocket']: %s" % hooks['WebSocket'])
                PLUGIN_WS_CMDS.update(hooks['WebSocket'])
            if 'Escape' in hooks:
                # Apply the plugin's Escape handler
                PLUGIN_ESC_HANDLERS.update({plugin_name: hooks['Escape']})
            if 'Auth' in hooks:
                # Apply the plugin's post-authentication functions
                if isinstance(hooks['Auth'], (list, tuple)):
                    PLUGIN_AUTH_HOOKS.extend(hooks['Auth'])
                else:
                    PLUGIN_AUTH_HOOKS.append(hooks['Auth'])
            if 'Command' in hooks:
                # Apply the plugin's 'Command' hooks (called by new_multiplex)
                if isinstance(hooks['Command'], (list, tuple)):
                    PLUGIN_COMMAND_HOOKS.extend(hooks['Command'])
                else:
                    PLUGIN_COMMAND_HOOKS.append(hooks['Command'])
            if 'Multiplex' in hooks:
                # Apply the plugin's Multiplex hooks (called by new_multiplex)
                if isinstance(hooks['Multiplex'], (list, tuple)):
                    PLUGIN_NEW_MULTIPLEX_HOOKS.extend(hooks['Multiplex'])
                else:
                    PLUGIN_NEW_MULTIPLEX_HOOKS.append(hooks['Multiplex'])
            if 'Terminal' in hooks:
                # Apply the plugin's Terminal hooks (called by new_terminal)
                PLUGIN_TERM_HOOKS.update(hooks['Terminal'])
            if 'TermInstance' in hooks:
                # Apply the plugin's TermInstance hooks (called by new_terminal)
                if isinstance(hooks['TermInstance'], (list, tuple)):
                    PLUGIN_NEW_TERM_HOOKS.extend(hooks['TermInstance'])
                else:
                    PLUGIN_NEW_TERM_HOOKS.append(hooks['TermInstance'])
            if 'Environment' in hooks:
                PLUGIN_ENV_HOOKS.update(hooks['Environment'])
            if 'Init' in hooks:
                # Call the plugin's initialization functions
                hooks['Init'](tornado_settings)
        # Include JS-only and CSS-only plugins (for logging purposes)
        js_plugins = [a.split(os.path.sep)[2] for a in PLUGINS['js']]
        # NOTE: JS and CSS files are normally sent after the user authenticates
        #       via ApplicationWebSocket.send_plugin_static_files()
        # Add static handlers for all the JS plugins (primarily for source URLs)
        for js_plugin in js_plugins:
            js_plugin_path = os.path.join(
                GATEONE_DIR, 'plugins', js_plugin, 'static')
            handlers.append((
                r"%splugins/%s/static/(.*)" % (url_prefix, js_plugin),
                StaticHandler,
                {"path": js_plugin_path}
            ))
        # This removes duplicate handlers for the same regex, allowing plugins
        # to override defaults:
        handlers = merge_handlers(handlers)
        css_plugins = []
        for css_path in css_plugins:
            name = css_path.split(os.path.sep)[-1].split('.')[0]
            name = os.path.splitext(name)[0]
            css_plugins.append(name)
        plugin_list = list(set(PLUGINS['py'] + js_plugins + css_plugins))
        plugin_list.sort() # So there's consistent ordering
        logger.info(_("Loaded global plugins: %s") % ", ".join(plugin_list))
        tornado.web.Application.__init__(self, handlers, **tornado_settings)

def set_license():
    """
    Sets the __license__ global based on what can be found in `GATEONE_DIR`.
    """
    license_path = os.path.join(GATEONE_DIR, '.license')
    if os.path.exists(license_path):
        with io.open(license_path, 'r', encoding='utf-8') as f:
            license = f.read()
            if license:
                global __license__
                __license__ = license.strip()

def main(installed=True):
    global _
    global PLUGINS
    global APPLICATIONS
    set_license()
    define_options(installed=installed)
    # Before we do anything else we need the get the settings_dir argument (if
    # given) so we can make sure we're handling things accordingly.
    settings_dir = options.settings_dir # Set the default
    for arg in sys.argv:
        if arg.startswith('--settings_dir'):
            settings_dir = arg.split('=', 1)[1]
    if not os.path.isdir(settings_dir) and '--help' not in sys.argv:
        # Try to create it
        try:
            mkdir_p(settings_dir)
        except:
            logging.error(_(
               "Could not find/create settings directory at %s" % settings_dir))
            sys.exit(1)
    try:
        all_settings = get_settings(settings_dir)
    except SettingsError as e:
        # The error will be logged to stdout inside all_settings
        sys.exit(2)
    enabled_plugins = []
    enabled_applications = []
    cli_commands = {} # Holds CLI commands provided by plugins/applications
    go_settings = {}
    if 'gateone' in all_settings['*']:
        # The check above will fail in first-run situations
        enabled_plugins = all_settings['*']['gateone'].get(
            'enabled_plugins', [])
        enabled_plugins = [a.lower() for a in enabled_plugins]
        enabled_applications = all_settings['*']['gateone'].get(
            'enabled_applications', [])
        enabled_applications = [a.lower() for a in enabled_applications]
        go_settings = all_settings['*']['gateone']
    PLUGINS = get_plugins(os.path.join(GATEONE_DIR, 'plugins'), enabled_plugins)
    imported = load_modules(PLUGINS['py'])
    for plugin in imported:
        try:
            PLUGIN_HOOKS.update({plugin.__name__: plugin.hooks})
            if 'commands' in plugin.hooks:
                cli_commands.update(plugin.hooks['commands'])
        except AttributeError:
            pass # No hooks--probably just a supporting .py file.
    APPLICATIONS = get_applications(
        os.path.join(GATEONE_DIR, 'applications'), enabled_applications)
    # NOTE: load_modules() imports all the .py files in applications.  This
    # means that applications can place calls to tornado.options.define()
    # anywhere in their .py files and they should automatically be usable by the
    # user at this point in the startup process.
    app_modules = load_modules(APPLICATIONS)
    # Check if the user is running a command as opposed to passing arguments
    # so we can set the log_file_prefix to something innocuous so as to prevent
    # IOError exceptions from Tornado's parse_command_line() below...
    if [a for a in sys.argv[1:] if not a.startswith('-')]:
        options.log_file_prefix = None
    # Having parse_command_line() after loading applications in case an
    # application has additional calls to define().
    try:
        commands = tornado.options.parse_command_line()
    except IOError:
        print(_("Could not write to the log: %s") % options.log_file_prefix)
        print(_(
            "You probably want to provide a different destination via "
            "--log_file_prefix=/path/to/gateone.log"))
        sys.exit(2)
    # NOTE: Here's how settings/command line args works:
    #       * The 'options' object gets set from the arguments on the command
    #         line (parse_command_line() above).
    #       * 'go_settings' gets set from the stuff in the 'settings_dir'
    #       * Once both are parsed (on their own) we overwrite 'go_settings'
    #         with what was given on the command line.
    #       * Once 'go_settings' has been adjusted we overwrite 'options' with
    #         any settings that directly correlate with command line options.
    #         This ensures that the 'options' object (which controls Tornado'
    #         settings) gets the stuff from 'settings_dir' if not provided on
    #         the command line.
    # TODO: Add a way for applications/plugins to add to this list:
    non_options = [
        # These are things that don't really belong in settings
        'new_api_key', 'help', 'kill', 'config', 'combine_js', 'combine_css',
        'combine_css_container'
    ]
    # Figure out which options are being overridden on the command line
    apply_cli_overrides(go_settings)
    arguments = []
    for arg in list(sys.argv)[1:]:
        if not arg.startswith('-'):
            break
        else:
            arguments.append(arg.lstrip('-').split('=', 1)[0])
    # TODO: Get this outputting installed plugins and versions as well
    if options.version:
        print("\x1b[1mGate One:\x1b[0m")
        print("\tVersion: %s (%s)" % (__version__, __commit__))
        print("\x1b[1mInstalled Applications:\x1b[0m")
        for app in app_modules:
            if hasattr(app, 'apps'):
                for _app in app.apps:
                    if hasattr(_app, 'info'):
                        name = _app.info.get('name', None)
                        ver = _app.info.get('version', 'Unknown')
                        if hasattr(ver, '__call__'):
                            # It's a function; grab its output (cool feature)
                            ver = ver()
                        if name:
                            print("\t%s Version: %s" % (name, ver))
        sys.exit(0)
    # Turn any API keys provided on the command line into a dict
    api_keys = {}
    if 'api_keys' in arguments:
        if options.api_keys:
            for pair in options.api_keys.split(','):
                api_key, secret = pair.split(':')
                if bytes == str:
                    api_key = api_key.decode('UTF-8')
                    secret = secret.decode('UTF-8')
                api_keys.update({api_key: secret})
        go_settings['api_keys'] = api_keys
    # Setting the log level using go_settings requires an additional step:
    if options.logging.upper() != 'NONE':
        logging.getLogger().setLevel(getattr(logging, options.logging.upper()))
    else:
        logging.disable(logging.CRITICAL)
    logger = go_logger(None)
    APPLICATIONS = [] # Replace it with a list of actual class instances
    web_handlers = []
    # Convert the old server.conf to the new settings file format and save it
    # as a number of distinct .conf files to keep things better organized.
    # NOTE: This logic will go away some day as it only applies when moving from
    #       Gate One 1.1 (or older) to newer versions.
    if os.path.exists(options.config):
        from .configuration import convert_old_server_conf
        convert_old_server_conf()
    if 'gateone' not in all_settings['*']:
        # User has yet to create a 10server.conf (or equivalent)
        all_settings['*']['gateone'] = {} # Will be filled out below
    # If you want any missing config file entries re-generated just delete the
    # cookie_secret line...
    if 'cookie_secret' not in go_settings or not go_settings['cookie_secret']:
        # Generate a default 10server.conf with a random cookie secret
        # NOTE: This will also generate a new 10server.conf if it is missing.
        from .configuration import generate_server_conf
        generate_server_conf(installed=installed)
        # Make sure these values get updated
        all_settings = get_settings(options.settings_dir)
        go_settings = all_settings['*']['gateone']
    for module in app_modules:
        try:
            if hasattr(module, 'apps'):
                APPLICATIONS.extend(module.apps)
            if hasattr(module, 'init'):
                module.init(all_settings)
            if hasattr(module, 'web_handlers'):
                web_handlers.extend(module.web_handlers)
            if hasattr(module, 'commands'):
                cli_commands.update(module.commands)
        except AttributeError:
            # No apps--probably just a supporting .py file.
            # Uncomment if you can't figure out why your app isn't loading:
            #print("Error initializing module: %s" % module)
            #import traceback
            #traceback.print_exc(file=sys.stdout)
            pass
    if commands: # Optional CLI functionality provided by plugins/applications
        from .configuration import parse_commands
        parsed_commands = parse_commands(commands)
        for command, args in list(parsed_commands.items()):
            if command not in cli_commands:
                logger.warning(_("Unknown CLI command: '%s'") % (command))
            else:
                cli_commands[command](commands[1:])
        sys.exit(0)
    logging.info(_("Imported applications: {0}".format(
        ', '.join([a.info['name'] for a in APPLICATIONS]))))
    # Change the uid/gid strings into integers
    try:
        uid = int(go_settings['uid'])
    except ValueError:
        import pwd
        # Assume it's a username and grab its uid
        uid = pwd.getpwnam(go_settings['uid']).pw_uid
    try:
        gid = int(go_settings['gid'])
    except ValueError:
        import grp
        # Assume it's a group name and grab its gid
        gid = grp.getgrnam(go_settings['gid']).gr_gid
    if uid == 0 and os.getuid() != 0:
        # Running as non-root; set uid/gid to the current user
        logging.info(_("Running as non-root; will not drop privileges."))
        uid = os.getuid()
        gid = os.getgid()
    if not os.path.exists(go_settings['user_dir']): # Make our user_dir
        try:
            mkdir_p(go_settings['user_dir'])
        except OSError:
            import pwd
            logging.error(_(
                "Gate One could not create %s.  Please ensure that user,"
                " %s has permission to create this directory or create it "
                "yourself and make user, %s its owner."
                % (go_settings['user_dir'],
                repr(pwd.getpwuid(os.geteuid())[0]),
                repr(pwd.getpwuid(os.geteuid())[0]))))
            sys.exit(1)
        # If we could create it we should be able to adjust its permissions:
        os.chmod(go_settings['user_dir'], 0o770)
    if not check_write_permissions(uid, go_settings['user_dir']):
        # Try correcting this first
        try:
            recursive_chown(go_settings['user_dir'], uid, gid)
        except (ChownError, OSError) as e:
            logging.error(_(
                "Failed to recursively change permissions of user_dir: %s, "
                "uid: %s, gid: %s" % (go_settings['user_dir'], uid, gid)))
            logging.error(e)
            sys.exit(1)
    if not os.path.exists(go_settings['session_dir']): # Make our session_dir
        try:
            mkdir_p(go_settings['session_dir'])
        except OSError:
            logging.error(_(
                "Error: Gate One could not create %s.  Please ensure that user,"
                " %s has permission to create this directory or create it "
                "yourself and make user, %s its owner." % (
                go_settings['session_dir'],
                repr(pwd.getpwuid(os.geteuid())[0]),
                repr(pwd.getpwuid(os.geteuid())[0]))))
            sys.exit(1)
        os.chmod(go_settings['session_dir'], 0o770)
    if not check_write_permissions(uid, go_settings['session_dir']):
        # Try correcting it
        try:
            recursive_chown(go_settings['session_dir'], uid, gid)
        except (ChownError, OSError) as e:
            logging.error("session_dir: %s, uid: %s, gid: %s" % (
                go_settings['session_dir'], uid, gid))
            logging.error(e)
            sys.exit(1)
    # Re-do the locale in case the user supplied something as --locale
    user_locale = locale.get(go_settings['locale'])
    _ = user_locale.translate # Also replaces our wrapper so no more .encode()
    # Create the log dir if not already present (NOTE: Assumes we're root)
    log_dir = os.path.split(go_settings['log_file_prefix'])[0]
    if options.logging.upper() != 'NONE':
        if not os.path.exists(log_dir):
            try:
                mkdir_p(log_dir)
            except OSError:
                logging.error(_(
                    "\x1b[1;31mERROR:\x1b[0m Could not create %s for "
                    "log_file_prefix: %s"
                    % (log_dir, go_settings['log_file_prefix']
                )))
                logging.error(_(
                    "You probably want to change this option, run Gate "
                    "One as root, or create that directory and give the proper "
                    "user ownership of it."))
                sys.exit(1)
        if not check_write_permissions(uid, log_dir):
            # Try to correct it
            try:
                recursive_chown(log_dir, uid, gid)
            except (ChownError, OSError) as e:
                logging.error(
                    "log_dir: %s, uid: %s, gid: %s" % (log_dir, uid, gid))
                logging.error(e)
                sys.exit(1)
        # Now fix the permissions on each log (no need to check)
        for log_file in LOGS:
            if not os.path.exists(log_file):
                touch(log_file)
            try:
                recursive_chown(log_file, uid, gid)
            except (ChownError, OSError) as e:
                logging.error(
                    "log_file: %s, uid: %s, gid: %s" % (log_dir,uid, gid))
                logging.error(e)
                sys.exit(1)
    if options.new_api_key:
        # Generate a new API key for an application to use and save it to
        # settings/30api_keys.conf.
        from .configuration import RUDict
        api_key = generate_session_id()
        # Generate a new secret
        secret = generate_session_id()
        api_keys_conf = os.path.join(options.settings_dir, '30api_keys.conf')
        new_keys = {api_key: secret}
        api_keys = RUDict({"*": {"gateone": {"api_keys": {}}}})
        if os.path.exists(api_keys_conf):
            api_keys = get_settings(api_keys_conf)
        api_keys.update({"*": {"gateone": {"api_keys": new_keys}}})
        with io.open(api_keys_conf, 'w', encoding='utf-8') as conf:
            msg = _(
                u"// This file contains the key and secret pairs used by Gate "
                u"One's API authentication method.\n")
            conf.write(msg)
            conf.write(unicode(api_keys))
        logging.info(_(u"A new API key has been generated: %s" % api_key))
        logging.info(_(
            u"This key can now be used to embed Gate One into other "
            u"applications."))
        sys.exit(0)
    if options.combine_js:
        from .configuration import combine_javascript
        combine_javascript(options.combine_js, options.settings_dir)
        sys.exit(0)
    if options.combine_css:
        from .configuration import combine_css
        combine_css(
            options.combine_css,
            options.combine_css_container,
            options.settings_dir)
        sys.exit(0)
    # Display the version in case someone sends in a log for for support
    logging.info(_("Version: %s (%s)" % (__version__, __commit__)))
    logging.info(_("Tornado version %s" % tornado_version))
    # Set our global session timeout
    global TIMEOUT
    TIMEOUT = convert_to_timedelta(go_settings['session_timeout'])
    # Fix the url_prefix if the user forgot the trailing slash
    if not go_settings['url_prefix'].endswith('/'):
        go_settings['url_prefix'] += '/'
    # Convert the origins into a list if overridden via the command line
    if 'origins' in arguments:
        if ';' in options.origins:
            origins = options.origins.lower().split(';')
            real_origins = []
            for origin in origins:
                if '://' in origin:
                    origin = origin.split('://')[1]
                if origin not in real_origins:
                    real_origins.append(origin)
            go_settings['origins'] = real_origins
    logging.info(_(
        "Connections to this server will be allowed from the following"
        " origins: '%s'") % " ".join(go_settings['origins']))
    # Normalize certain settings
    go_settings['api_timestamp_window'] = convert_to_timedelta(
        go_settings['api_timestamp_window'])
    go_settings['auth'] = none_fix(go_settings['auth'])
    go_settings['settings_dir'] = settings_dir
    # Check to make sure we have a certificate and keyfile and generate fresh
    # ones if not.
    if not go_settings['disable_ssl']:
        if not os.path.exists(go_settings['keyfile']):
            ssl_base = os.path.split(go_settings['keyfile'])[0]
            if not os.path.exists(ssl_base):
                mkdir_p(ssl_base)
            logging.info(_("No SSL private key found.  One will be generated."))
            gen_self_signed_ssl(path=ssl_base)
        if not os.path.exists(go_settings['certificate']):
            ssl_base = os.path.split(go_settings['certificate'])[0]
            logging.info(_("No SSL certificate found.  One will be generated."))
            gen_self_signed_ssl(path=ssl_base)
    # When logging=="debug" it will display all user's keystrokes so make sure
    # we warn about this.
    if go_settings['logging'] == "debug":
        logging.warning(_(
            "Logging is set to DEBUG.  Be aware that this will record the "
            "keystrokes of all users.  Don't be evil!"))
    ssl_auth = go_settings.get('ssl_auth', 'none').lower()
    if ssl_auth == 'required':
        # Convert to an integer using the ssl module
        cert_reqs = ssl.CERT_REQUIRED
    elif ssl_auth == 'optional':
        cert_reqs = ssl.CERT_OPTIONAL
    else:
        cert_reqs = ssl.CERT_NONE
    # Instantiate our Tornado web server
    ssl_options = {
        "certfile": go_settings['certificate'],
        "keyfile": go_settings['keyfile'],
        "cert_reqs": cert_reqs
    }
    ca_certs = go_settings.get('ca_certs', None)
    if ca_certs:
        ssl_options['ca_certs'] = ca_certs
    disable_ssl = go_settings.get('disable_ssl', False)
    if disable_ssl:
        proto = "http://"
        ssl_options = None
    else:
        proto = "https://"
    # Fill out our settings with command line args if any are missing
    for option in list(options):
        if option in non_options:
            continue # These don't belong
        if option not in go_settings:
            go_settings[option] = options[option]
    https_server = tornado.httpserver.HTTPServer(
        GateOneApp(settings=go_settings, web_handlers=web_handlers),
        ssl_options=ssl_options)
    https_redirect = tornado.web.Application(
        [(r".*", HTTPSRedirectHandler),],
        port=go_settings['port'],
        url_prefix=go_settings['url_prefix']
    )
    tornado.web.ErrorHandler = ErrorHandler
    if go_settings['auth'] == 'pam':
        if uid != 0 or os.getuid() != 0:
            logger.warning(_(
                "PAM authentication is configured but you are not running Gate"
                " One as root.  If the pam_service you've selected (%s) is "
                "configured to use pam_unix.so for 'auth' (i.e. authenticating "
                "against /etc/passwd and /etc/shadow) Gate One will not be able"
                " to authenticate all users.  It will only be able to "
                "authenticate the user that owns the gateone.py process." %
                go_settings['pam_service']))
    try: # Start your engines!
        if go_settings.get('enable_unix_socket', False):
            https_server.add_socket(
                tornado.netutil.bind_unix_socket(
                    go_settings['unix_socket_path']))
            logger.info(_("Listening on Unix socket '{socketpath}'".format(
                socketpath=go_settings['unix_socket_path'])))
        address = none_fix(go_settings['address'])
        if address:
            for addr in address.split(';'):
                if addr: # Listen on all given addresses
                    if go_settings['https_redirect']:
                        if go_settings['disable_ssl']:
                            logger.error(_(
                            "You have https_redirect *and* disable_ssl enabled."
                            "  Please pick one or the other."))
                            sys.exit(1)
                        logger.info(_(
                            "http://{addr}:80/ will be redirected to...".format(
                                addr=addr)
                        ))
                        https_redirect.listen(port=80, address=addr)
                    logger.info(_(
                        "Listening on {proto}{address}:{port}/".format(
                            proto=proto, address=addr, port=go_settings['port'])
                    ))
                    https_server.listen(port=go_settings['port'], address=addr)
        elif address == '':
            # Listen on all addresses (including IPv6)
            if go_settings['https_redirect']:
                if go_settings['disable_ssl']:
                    logger.error(_(
                        "You have https_redirect *and* disable_ssl enabled."
                        "  Please pick one or the other."))
                    sys.exit(1)
                logger.info(_("http://*:80/ will be redirected to..."))
                https_redirect.listen(port=80, address="")
            logger.info(_(
                "Listening on {proto}*:{port}/".format(
                    proto=proto, port=go_settings['port'])))
            try: # Listen on all IPv4 and IPv6 addresses
                https_server.listen(port=go_settings['port'], address="")
            except socket.error: # Fall back to all IPv4 addresses
                https_server.listen(port=go_settings['port'], address="0.0.0.0")
        # NOTE:  To have Gate One *not* listen on a TCP/IP address you may set
        #        address=None
        # Check to see what group owns /dev/pts and use that for supl_groups
        # First we have to make sure there's at least one pty present
        tempfd1, tempfd2 = pty.openpty()
        # Now check the owning group (doesn't matter which one so we use 0)
        ptm = '/dev/ptm' if os.path.exists('/dev/ptm') else '/dev/ptmx'
        tty_gid = os.stat(ptm).st_gid
        # Close our temmporary pty/fds so we're not wasting them
        os.close(tempfd1)
        os.close(tempfd2)
        if uid != os.getuid():
            drop_privileges(uid, gid, [tty_gid])
        write_pid(go_settings['pid_file'])
        pid = read_pid(go_settings['pid_file'])
        logger.info(_("Process running with pid " + pid))
        tornado.ioloop.IOLoop.instance().start()
    except socket.error as e:
        import errno, pwd
        if not address: address = "0.0.0.0"
        if e.errno == errno.EADDRINUSE: # Address/port already in use
            logging.error(_(
                "Could not listen on {address}:{port} (address:port is already "
                "in use by another application).").format(
                    address=address, port=options.port))
        elif e.errno == errno.EACCES:
            logging.error(_(
                "User '{user}' does not have permission to create a process "
                "listening on {address}:{port}.  Typically only root can use "
                "ports < 1024.").format(
                    user=pwd.getpwuid(uid)[0],
                    address=address,
                    port=options.port))
        else:
            logging.error(_(
                "An error was encountered trying to listen on "
                "{address}:{port}...").format(
                    address=address, port=options.port))
        logging.error(_("Exception was: {0}").format(e.args))
    except KeyboardInterrupt: # ctrl-c
        logger.info(_("Caught KeyboardInterrupt.  Killing sessions..."))
    finally:
        tornado.ioloop.IOLoop.instance().stop()
        import shutil
        logger.info(_(
            "Clearing cache_dir: {0}").format(go_settings['cache_dir']))
        shutil.rmtree(go_settings['cache_dir'], ignore_errors=True)
        remove_pid(go_settings['pid_file'])
        logger.info(_("pid file removed."))

if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = utils
# -*- coding: utf-8 -*-
#
#       Copyright 2013 Liftoff Software Corporation
#
# For license information see LICENSE.txt

__doc__ = """\
.. _utils.py:

Gate One Utility Functions and Classes
======================================
"""

# Meta
__license__ = "AGPLv3 or Proprietary (see LICENSE.txt)"
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'

# Import stdlib stuff
import os
import signal
import sys
import random
import re
import io
import errno
import logging
import mimetypes
import fcntl
import hmac, hashlib
from datetime import datetime, timedelta
from functools import partial
try:
    import cPickle as pickle
except ImportError:
    import pickle # Python 3

# Import 3rd party stuff
from tornado import locale
from tornado.escape import json_encode as _json_encode
from tornado.escape import to_unicode
from tornado.ioloop import IOLoop, PeriodicCallback

# Globals
MACOS = os.uname()[0] == 'Darwin'
OPENBSD = os.uname()[0] == 'OpenBSD'
CSS_END = re.compile('\.css.*?$')
JS_END = re.compile('\.js.*?$')
# This is used by the raw() function to show control characters
REPLACEMENT_DICT = {
    0: u'^@',
    1: u'^A',
    2: u'^B',
    3: u'^C',
    4: u'^D',
    5: u'^E',
    6: u'^F',
    7: u'^G',
    8: u'^H',
    9: u'^I',
    #10: u'^J', # Newline (\n)
    11: u'^K',
    12: u'^L',
    #13: u'^M', # Carriage return (\r)
    14: u'^N',
    15: u'^O',
    16: u'^P',
    17: u'^Q',
    18: u'^R',
    19: u'^S',
    20: u'^T',
    21: u'^U',
    22: u'^V',
    23: u'^W',
    24: u'^X',
    25: u'^Y',
    26: u'^Z',
    27: u'^[',
    28: u'^\\',
    29: u'^]',
    30: u'^^',
    31: u'^_',
    127: u'^?',
}
SEPARATOR = u"\U000f0f0f" # The character used to separate frames in the log
# Default to using the environment's locale with en_US fallback
temp_locale = locale.get(os.environ.get('LANG', 'en_US').split('.')[0])
_ = temp_locale.translate
del temp_locale
# The above is necessary because gateone.py won't have read in its settings
# until after this file has loaded.  So get_settings() won't work properly
# until later in the module loading process.  This lets us display translated
# error messages in the event that Gate One never completed loading.

# Exceptions
class MimeTypeFail(Exception):
    """
    Raised by `create_data_uri` if the mimetype of a file could not be guessed.
    """
    pass

class SSLGenerationError(Exception):
    """
    Raised by `gen_self_signed_ssl` if an error is encountered generating a
    self-signed SSL certificate.
    """
    pass

class ChownError(Exception):
    """
    Raised by `recursive_chown` if an OSError is encountered while trying to
    recursively chown a directory.
    """
    pass

class AutoExpireDict(dict):
    """
    An override of Python's `dict` that expires keys after a given
    *_expire_timeout* timeout (`datetime.timedelta`).  The default expiration
    is one hour.  It is used like so::

        >>> expiring_dict = AutoExpireDict(timeout=timedelta(minutes=10))
        >>> expiring_dict['somekey'] = 'some value'
        >>> # You can see when this key was created:
        >>> print(expiring_dict.creation_times['somekey'])
        2013-04-15 18:44:18.224072

    10 minutes later your key will be gone::

        >>> 'somekey' in expiring_dict
        False

    The 'timeout' may be be given as a `datetime.timedelta` object or a string
    like, "1d", "30s" (will be passed through the `convert_to_timedelta`
    function).

    By default `AutoExpireDict` will check for expired keys every 30 seconds but
    this can be changed by setting the 'interval'::

        >>> expiring_dict = AutoExpireDict(interval=5000) # 5 secs
        >>> # Or to change it after you've created one:
        >>> expiring_dict.interval = "10s"

    The 'interval' may be an integer, a `datetime.timedelta` object, or a string
    such as '10s' or '5m' (will be passed through the `convert_to_timedelta`
    function).

    If there are no keys remaining the `tornado.ioloop.PeriodicCallback` (
    ``self._key_watcher``) that checks expiration will be automatically stopped.
    As soon as a new key is added it will be started back up again.

    .. note::

        Only works if there's a running instances of `tornado.ioloop.IOLoop`.
    """
    def __init__(self, *args, **kwargs):
        self.io_loop = IOLoop.current()
        self.creation_times = {}
        if 'timeout' in kwargs:
            self.timeout = kwargs.pop('timeout')
        if 'interval' in kwargs:
            self.interval = kwargs.pop('interval')
        super(AutoExpireDict, self).__init__(*args, **kwargs)
        # Set the start time on every key
        for k in self.keys():
            self.creation_times[k] = datetime.now()
        self._key_watcher = PeriodicCallback(
            self._timeout_checker, self.interval, io_loop=self.io_loop)
        self._key_watcher.start() # Will shut down at the next interval if empty

    @property
    def timeout(self):
        """
        A `property` that controls how long a key will last before being
        automatically removed.  May be be given as a `datetime.timedelta`
        object or a string like, "1d", "30s" (will be passed through the
        `convert_to_timedelta` function).
        """
        if not hasattr(self, "_timeout"):
            self._timeout = timedelta(hours=1) # Default is 1-hour timeout
        return self._timeout

    @timeout.setter
    def timeout(self, value):
        if isinstance(value, basestring):
            value = convert_to_timedelta(value)
        self._timeout = value

    @property
    def interval(self):
        """
        A `property` that controls how often we check for expired keys.  May be
        given as milliseconds (integer), a `datetime.timedelta` object, or a
        string like, "1d", "30s" (will be passed through the
        `convert_to_timedelta` function).
        """
        if not hasattr(self, "_interval"):
            self._interval = 10000 # Default is every 10 seconds
        return self._interval

    @interval.setter
    def interval(self, value):
        if isinstance(value, basestring):
            value = convert_to_timedelta(value)
        if isinstance(value, timedelta):
            value = total_seconds(value) * 1000 # PeriodicCallback uses ms
        self._interval = value
        # Restart the PeriodicCallback
        if hasattr(self, '_key_watcher'):
            self._key_watcher.stop()
        self._key_watcher = PeriodicCallback(
            self._timeout_checker, value, io_loop=self.io_loop)

    def renew(self, key):
        """
        Resets the timeout on the given *key*; like it was just created.
        """
        self.creation_times[key] = datetime.now() # Set/renew the start time
        # Start up the key watcher if it isn't already running
        if not self._key_watcher._running:
            self._key_watcher.start()

    def __setitem__(self, key, value):
        """
        An override that tracks when keys are updated.
        """
        super(AutoExpireDict, self).__setitem__(key, value) # Set normally
        self.renew(key) # Set/renew the start time

    def __delitem__(self, key):
        """
        An override that makes sure *key* gets removed from
        ``self.creation_times`` dict.
        """
        del self.creation_times[key]
        super(AutoExpireDict, self).__delitem__(key)

    def __del__(self):
        """
        Ensures that our `tornado.ioloop.PeriodicCallback`
        (``self._key_watcher``) gets stopped.
        """
        self._key_watcher.stop()

    def update(self, *args, **kwargs):
        """
        An override that calls ``self.renew()`` for every key that gets updated.
        """
        super(AutoExpireDict, self).update(*args, **kwargs)
        for key, value in kwargs.items():
            self.renew(key)

    def clear(self):
        """
        An override that empties ``self.creation_times`` and calls
        ``self._key_watcher.stop()``.
        """
        super(AutoExpireDict, self).clear()
        self.creation_times.clear()
        # Shut down the key watcher right away
        self._key_watcher.stop()

    def _timeout_checker(self):
        """
        Walks ``self`` and removes keys that have passed the expiration point.
        """
        if not self.creation_times:
            self._key_watcher.stop() # Nothing left to watch
        for key, starttime in list(self.creation_times.items()):
            if datetime.now() - starttime > self.timeout:
                del self[key]

MEMO = {}
class memoize(object):
    """
    A memoization decorator that works with multiple arguments as well as
    unhashable arguments (e.g. dicts).  It also self-expires any memoized
    calls after the timedelta specified via *timeout*.

    If a *timeout* is not given memoized information will be discared after five
    minutes.

    .. note:: Expiration checks will be performed every 30 seconds.
    """
    def __init__(self, fn, timeout=None):
        self.fn = fn
        if not timeout:
            timeout = timedelta(minutes=5)
        global MEMO # Use a global so that instances can share the cache
        if not MEMO:
            MEMO = AutoExpireDict(timeout=timeout, interval="30s")

    def __call__(self, *args, **kwargs):
        string = pickle.dumps(args, 0) + pickle.dumps(kwargs, 0)
        if string not in MEMO:
            # Commented out because it is REALLY noisy.  Uncomment to debug
            #logging.debug("memoize cache miss (%s)" % self.fn.__name__)
            MEMO[string] = self.fn(*args, **kwargs)
        #else:
            #logging.debug("memoize cache hit (%s)" % self.fn.__name__)
        return MEMO[string]

# Functions
def noop(*args, **kwargs):
    """Do nothing (i.e. "No Operation")"""
    pass

def debug_info(name, *args, **kwargs):
    """
    This function returns a string like this::

        >>> debug_info('some_function', 5, 10, foo="bar")
        'some_function(5, 10, foo="bar")'

    Primarily aimed at debugging.
    """
    out = name + "("
    for arg in args:
        out += "{0}, ".format(repr(arg))
    for k, v in kwargs.items():
        out += '{0}={1}, '.format(k, repr(v))
    return out.rstrip().rstrip(',') + ")"

def write_pid(path):
    """Writes our PID to *path*."""
    try:
        pid = os.getpid()
        with io.open(path, mode='w', encoding='utf-8') as pidfile:
            # Get a non-blocking exclusive lock
            fcntl.flock(pidfile.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
            pidfile.seek(0)
            pidfile.truncate(0)
            pidfile.write(unicode(pid))
    except:
        logging.error(_("Could not write PID file: %s") % path)
        raise # This raises the original exception
    finally:
        try:
            pidfile.close()
        except:
            pass

def read_pid(path):
    """Reads our current PID from *path*."""
    return str(io.open(path, mode='r', encoding='utf-8').read())

def remove_pid(path):
    """Removes the PID file at *path*."""
    try:
        os.remove(path)
    except:
        pass

def shell_command(cmd, timeout_duration=5):
    """
    Resets the SIGCHLD signal handler (if necessary), executes *cmd* via
    :func:`~commands.getstatusoutput`, then re-enables the SIGCHLD handler (if
    it was set to something other than SIG_DFL).  Returns the result of
    :func:`~commands.getstatusoutput` which is a tuple in the form of::

        (exitstatus, output)

    If the command takes longer than *timeout_duration* seconds, it will be
    auto-killed and the following will be returned::

        (255, _("ERROR: Timeout running shell command"))
    """
    from commands import getstatusoutput
    existing_handler = signal.getsignal(signal.SIGCHLD)
    default = (255, _("ERROR: Timeout running shell command"))
    if existing_handler != 0: # Something other than default
        # Reset it to default so getstatusoutput will work properly
        try:
            signal.signal(signal.SIGCHLD, signal.SIG_DFL)
        except ValueError:
            # "Signal only works in the main thread" - no big deal.  This just
            # means we never needed to call signal in the first place.
            pass
    result = timeout_func(
        getstatusoutput,
        args=(cmd,),
        default=default,
        timeout_duration=timeout_duration
    )
    try:
        signal.signal(signal.SIGCHLD, existing_handler)
    except ValueError:
        # Like above, signal only works from within the main thread but our use
        # of it here would only matter if we were in the main thread.
        pass
    return result

def json_encode(obj):
    """
    On some platforms (CentOS 6.2, specifically) `tornado.escape.json_decode`
    doesn't seem to work just right when it comes to returning unicode strings.
    This is just a wrapper that ensures that the returned string is unicode.
    """
    return to_unicode(_json_encode(obj))

def gen_self_signed_ssl(path=None):
    """
    Generates a self-signed SSL certificate using `pyOpenSSL` or the `openssl <http://www.openssl.org/docs/apps/openssl.html>`_ command depending on
    what's available,  The resulting key/certificate will use the RSA algorithm
    at 4096 bits.
    """
    try:
        import OpenSSL
        # Direct OpenSSL library calls are better than executing commands...
        gen_self_signed_func = gen_self_signed_pyopenssl
    except ImportError:
        gen_self_signed_func = gen_self_signed_openssl
    try:
        gen_self_signed_func(path=path)
    except SSLGenerationError as e:
        logging.error(_(
            "Error generating self-signed SSL key/certificate: %s" % e))

def gen_self_signed_openssl(path=None):
    """
    This method will generate a secure self-signed SSL key/certificate pair
    (using the `openssl <http://www.openssl.org/docs/apps/openssl.html>`_
    command) saving the result as 'certificate.pem' and 'keyfile.pem' to *path*.
    If *path* is not given the result will be saved in the current working
    directory.  The certificate will be valid for 10 years.

    .. note:: The self-signed certificate will utilize 4096-bit RSA encryption.
    """
    if not path:
        path = os.path.abspath(os.curdir)
    keyfile_path = os.path.join(path, "keyfile.pem")
    certfile_path = os.path.join(path, "certificate.pem")
    subject = (
        '-subj "/OU=%s (Self-Signed)/CN=Gate One/O=Liftoff Software"' %
        os.uname()[1] # Hostname
    )
    gen_command = (
        "openssl genrsa -aes256 -out %s.tmp -passout pass:password 4096" %
        keyfile_path
    )
    decrypt_key_command = (
        "openssl rsa -in {0}.tmp -passin pass:password -out {0}".format(
            keyfile_path)
    )
    csr_command = (
        "openssl req -new -key %s -out temp.csr %s" % (
            keyfile_path, subject)
    )
    cert_command = (
        "openssl x509 -req "    # Create a new x509 certificate
        "-days 3650 "           # That lasts 10 years
        "-in temp.csr "         # Using the CSR we just generated
        "-signkey %s "          # Sign it with keyfile.pem that we just created
        "-out %s"               # Save it as certificate.pem
    )
    cert_command = cert_command % (keyfile_path, certfile_path)
    logging.debug(_(
        "Generating private key with command: %s" % gen_command))
    exitstatus, output = shell_command(gen_command, 30)
    if exitstatus != 0:
        error_msg = _(
            "An error occurred trying to create private SSL key:\n%s" % output)
        if os.path.exists('%s.tmp' % keyfile_path):
            os.remove('%s.tmp' % keyfile_path)
        raise SSLGenerationError(error_msg)
    logging.debug(_(
        "Decrypting private key with command: %s" % decrypt_key_command))
    exitstatus, output = shell_command(decrypt_key_command, 30)
    if exitstatus != 0:
        error_msg = _(
            "An error occurred trying to decrypt private SSL key:\n%s" % output)
        if os.path.exists('%s.tmp' % keyfile_path):
            os.remove('%s.tmp' % keyfile_path)
        raise SSLGenerationError(error_msg)
    logging.debug(_(
        "Creating CSR with command: %s" % csr_command))
    exitstatus, output = shell_command(csr_command, 30)
    if exitstatus != 0:
        error_msg = _(
            "An error occurred trying to create CSR:\n%s" % output)
        if os.path.exists('%s.tmp' % keyfile_path):
            os.remove('%s.tmp' % keyfile_path)
        if os.path.exists('temp.csr'):
            os.remove('temp.csr')
        raise SSLGenerationError(error_msg)
    logging.debug(_(
        "Generating self-signed certificate with command: %s" % gen_command))
    exitstatus, output = shell_command(cert_command, 30)
    if exitstatus != 0:
        error_msg = _(
            "An error occurred trying to create certificate:\n%s" % output)
        if os.path.exists('%s.tmp' % keyfile_path):
            os.remove('%s.tmp' % keyfile_path)
        if os.path.exists('temp.csr'):
            os.remove('temp.csr')
        if os.path.exists(certfile_path):
            os.remove(certfile_path)
        raise SSLGenerationError(error_msg)
    # Clean up unnecessary leftovers
    os.remove('%s.tmp' % keyfile_path)
    os.remove('temp.csr')

def gen_self_signed_pyopenssl(notAfter=None, path=None):
    """
    This method will generate a secure self-signed SSL key/certificate pair
    (using `pyOpenSSL`) saving the result as 'certificate.pem' and 'keyfile.pem'
    in *path*.  If *path* is not given the result will be saved in the current
    working directory.  By default the certificate will be valid for 10 years
    but this can be overridden by passing a valid timestamp via the
    *notAfter* argument.

    Examples::

        >>> gen_self_signed_ssl(60 * 60 * 24 * 365) # 1-year certificate
        >>> gen_self_signed_ssl() # 10-year certificate

    .. note:: The self-signed certificate will utilize 4096-bit RSA encryption.
    """
    try:
        import OpenSSL
    except ImportError:
        error_msg = _(
            "Error: You do not have pyOpenSSL installed.  Please install "
            "it (sudo pip install pyopenssl.")
        raise SSLGenerationError(error_msg)
    if not path:
        path = os.path.abspath(os.curdir)
    keyfile_path = "%s/keyfile.pem" % path
    certfile_path = "%s/certificate.pem" % path
    pkey = OpenSSL.crypto.PKey()
    pkey.generate_key(OpenSSL.crypto.TYPE_RSA, 4096)
    # Save the key as 'keyfile.pem':
    with io.open(keyfile_path, mode='wb') as f:
        f.write(OpenSSL.crypto.dump_privatekey(
            OpenSSL.crypto.FILETYPE_PEM, pkey))
    cert = OpenSSL.crypto.X509()
    cert.set_serial_number(random.randint(0, sys.maxint))
    cert.gmtime_adj_notBefore(0)
    if notAfter:
        cert.gmtime_adj_notAfter(notAfter)
    else:
        cert.gmtime_adj_notAfter(60 * 60 * 24 * 3650)
    cert.get_subject().CN = '*'
    cert.get_subject().O = 'Gate One Certificate'
    cert.get_issuer().CN = 'Untrusted Authority'
    cert.get_issuer().O = 'Self-Signed'
    cert.set_pubkey(pkey)
    cert.sign(pkey, 'sha512')
    with io.open(certfile_path, mode='wb') as f:
        f.write(OpenSSL.crypto.dump_certificate(
            OpenSSL.crypto.FILETYPE_PEM, cert))

def none_fix(val):
    """
    If *val* is a string that utlimately means 'none', return None.  Otherwise
    return *val* as-is.  Examples::

        >>> none_fix('none')
        None
        >>> none_fix('0')
        None
        >>> none_fix('whatever')
        'whatever'
    """
    if isinstance(val, basestring) and val.lower() in ['none', '0', 'no']:
        return None
    else:
        return val

def str2bool(val):
    """
    Converts strings like, 'false', 'true', '0', and '1' into their boolean
    equivalents (in Python).  If no logical match is found, return False.
    Examples::

        >>> str2bool('false')
        False
        >>> str2bool('1')
        True
        >>> str2bool('whatever')
        False
    """
    if isinstance(val, basestring) and val.lower() in ['1', 'true', 'yes']:
        return True
    else:
        return False

def generate_session_id():
    """
    Returns a random, 45-character session ID.  Example:

    .. code-block:: python

        >>> generate_session_id()
        "NzY4YzFmNDdhMTM1NDg3Y2FkZmZkMWJmYjYzNjBjM2Y5O"
        >>>
    """
    import base64, uuid
    from tornado.escape import utf8
    session_id = base64.b64encode(
        utf8(uuid.uuid4().hex + uuid.uuid4().hex))[:45]
    if bytes != str: # Python 3
        return str(session_id, 'UTF-8')
    return session_id

def mkdir_p(path):
    """
    Pythonic version of "mkdir -p".  Example equivalents::

        >>> mkdir_p('/tmp/test/testing') # Does the same thing as...
        >>> from subprocess import call
        >>> call('mkdir -p /tmp/test/testing')

    .. note:: This doesn't actually call any external commands.
    """
    try:
        os.makedirs(path)
    except OSError as exc:
        if exc.errno == errno.EEXIST:
            pass
        else:
            logging.error(_("Could not create directory: %s") % path)
            raise # The original exception

def cmd_var_swap(cmd, **kwargs):
    """
    Returns *cmd* with %variable% replaced with the keys/values passed in via
    *kwargs*.  This function is used by Gate One's Terminal application to
    swap the following Gate One variables in defined terminal 'commands':

        ==============  ==============
        %SESSION%       *session*
        %SESSION_DIR%   *session_dir*
        %SESSION_HASH%  *session_hash*
        %USERDIR%       *user_dir*
        %USER%          *user*
        %TIME%          *time*
        ==============  ==============

    This allows for unique or user-specific values to be swapped into command
    line arguments like so::

        ssh_connect.py -M -S '%SESSION%/%SESSION%/%r@%L:%p'

    Could become::

        ssh_connect.py -M -S '/tmp/gateone/NWI0YzYxNzAwMTA3NGYyZmI0OWJmODczYmQyMjQwMDYwM/%r@%L:%p'

    Here's an example::

        >>> cmd = "echo '%FOO% %BAR%'"
        >>> cmd_var_swap(cmd, foo="FOOYEAH,", bar="BAR NONE!")
        "echo 'FOOYEAH, BAR NONE!'"

    .. note::

        The variables passed into this function via *kwargs* are case
        insensitive.  `cmd_var_swap(cmd, session=var)` would produce the same
        output as `cmd_var_swap(cmd, SESSION=var)`.
    """
    for key, value in kwargs.items():
        if isinstance(key, bytes):
            key = key.decode('utf-8')
        if isinstance(value, bytes):
            value = value.decode('utf-8')
        key = unicode(key) # Force to string in case of things like integers
        value = unicode(value)
        cmd = cmd.replace(u'%{key}%'.format(key=key.upper()), value)
    return cmd

def short_hash(to_shorten):
    """
    Converts *to_shorten* into a really short hash depenendent on the length of
    *to_shorten*.  The result will be safe for use as a file name.

    .. note::

        Collisions are possible but *highly* unlikely because of how this method
        is typically used.
    """
    import base64
    hashed = hashlib.sha1(to_shorten.encode('utf-8'))
    # Take the first eight characters to create a shortened version.
    hashed = base64.urlsafe_b64encode(hashed.digest())[:8].decode('utf-8')
    if hashed.startswith('-'):
        hashed = hashed.replace('-', 'A', 1)
    return hashed

def random_words(n=1):
    """
    Returns *n* random English words (as a tuple) from the `english_wordlist.txt`
    file (bundled with Gate One).
    """
    from pkg_resources import resource_string
    words = resource_string(
        'gateone', 'static/english_wordlist.txt').split('\n')
    out_words = []
    for i in range(n):
        out_words.append(words[random.randint(0, len(words))].lower())
    return tuple(out_words)

def get_process_tree(parent_pid):
    """
    Returns a list of child pids that were spawned from *parent_pid*.

    .. note:: Will include parent_pid in the output list.
    """
    parent_pid = str(parent_pid) # Has to be a string
    ps = which('ps')
    retcode, output = shell_command('%s -ef' % ps)
    out = [parent_pid]
    pidmap = []
    # Construct the pidmap:
    for line in output.splitlines():
        split_line = line.split()
        pid = split_line[1]
        ppid = split_line[2]
        pidmap.append((pid, ppid))
    def walk_pids(pidmap, checkpid):
        """
        Recursively walks the given *pidmap* and updates the *out* variable with
        the child pids of *checkpid*.
        """
        for pid, ppid in pidmap:
            if ppid == checkpid:
                out.append(pid)
                walk_pids(pidmap, pid)
    walk_pids(pidmap, parent_pid)
    return out

def kill_dtached_proc(session, location, term):
    """
    Kills the dtach processes associated with the given *session* that matches
    the given *location* and *term*.  All the dtach'd sub-processes will be
    killed as well.
    """
    logging.debug('kill_dtached_proc(%s, %s, %s)' % (session, location, term))
    dtach_socket_name = 'dtach_{location}_{term}'.format(
        location=location, term=term)
    to_kill = []
    for f in os.listdir('/proc'):
        pid_dir = os.path.join('/proc', f)
        if os.path.isdir(pid_dir):
            try:
                pid = int(f)
            except ValueError:
                continue # Not a PID
            try:
                with open(os.path.join(pid_dir, 'cmdline')) as f:
                    cmdline = f.read()
                if cmdline and session in cmdline:
                    if dtach_socket_name in cmdline:
                        to_kill.append(pid)
            except Exception:
                pass # Already dead, no big deal.
    for pid in to_kill:
        kill_pids = get_process_tree(pid)
        for _pid in kill_pids:
            _pid = int(_pid)
            try:
                os.kill(_pid, signal.SIGTERM)
            except OSError:
                pass # Process already died.  Not a problem.

def kill_dtached_proc_bsd(session, location, term):
    """
    A BSD-specific implementation of `kill_dtached_proc` since Macs don't have
    /proc.  Seems simpler than :func:`kill_dtached_proc` but actually having to
    call a subprocess is less efficient (due to the sophisticated signal
    handling required by :func:`shell_command`).
    """
    logging.debug('kill_dtached_proc_bsd(%s, %s)' % (session, term))
    ps = which('ps')
    if MACOS:
        psopts = "-ef"
    elif OPENBSD:
        psopts = "-aux"
    cmd = (
        "%s %s | "
        "grep %s/dtach_%s_%s | " # Match our exact session/location/term combo
        "grep -v grep | " # Get rid of grep from the results (if present)
        "awk '{print $2}' " % (ps, psopts, session, location, term) # Just PID
    )
    logging.debug('kill cmd: %s' % cmd)
    exitstatus, output = shell_command(cmd)
    for line in output.splitlines():
        pid_to_kill = line.strip() # Get rid of trailing newline
        for pid in get_process_tree(pid_to_kill):
            try:
                os.kill(int(pid), signal.SIGTERM)
            except OSError:
                pass # Process already died.  Not a problem.

def killall(session_dir, pid_file):
    """
    Kills all running Gate One terminal processes including any detached dtach
    sessions.

    :session_dir: The path to Gate One's session directory.
    :pid_file: The path to Gate One's PID file
    """
    if not os.path.exists(session_dir):
        logging.info("No lieutenant, your processes are already dead.")
        return # Nothing to do
    sessions = os.listdir(session_dir)
    for f in os.listdir('/proc'):
        pid_dir = os.path.join('/proc', f)
        if os.path.isdir(pid_dir):
            try:
                pid = int(f)
                if pid == os.getpid():
                    continue # It would be suicide!
            except ValueError:
                continue # Not a PID
            cmdline_path = os.path.join(pid_dir, 'cmdline')
            if os.path.exists(cmdline_path):
                try:
                    with io.open(cmdline_path, mode='r', encoding='utf-8') as f:
                        cmdline = f.read()
                except IOError:
                    # Can happen if a process ended as we were looking at it
                    continue
            for session in sessions:
                if session in cmdline:
                    try:
                        os.kill(pid, signal.SIGTERM)
                    except OSError:
                        pass # PID is already dead--great
    try:
        go_pid = int(io.open(pid_file, mode='r', encoding='utf-8').read())
    except:
        logging.warning(_(
            "Could not open pid_file (%s).  You *may* have to kill gateone.py "
            "manually (probably not)." % pid_file))
        return
    try:
        os.kill(go_pid, signal.SIGTERM)
    except OSError:
        pass # PID is already dead--great

def killall_bsd(session_dir, pid_file=None):
    """
    A BSD-specific version of `killall` since Macs don't have /proc.

    .. note::

        *pid_file* is not used by this function.  It is simply here to provide
        compatibility with `killall`.
    """
    # TODO: See if there's a better way to keep track of subprocesses so we
    # don't have to enumerate the process table at all.
    logging.debug('killall_bsd(%s)' % session_dir)
    sessions = os.listdir(session_dir)
    if MACOS:
        psopts = "-ef"
    elif OPENBSD:
        psopts = "-aux"
    for session in sessions:
        cmd = (
            "ps %s | "
            "grep %s | " # Limit to those matching the session
            "grep -v grep | " # Get rid of grep from the results (if present)
            "awk '{print $2}' | " # Just the PID please
            "xargs kill" % (psopts, session) # Kill em'
        )
        logging.debug('killall cmd: %s' % cmd)
        exitstatus, output = shell_command(cmd)

def kill_session_processes(session):
    """
    Kills all processes that match a given *session* (which is a unique,
    45-character string).
    """
    psopts = "aux"
    if MACOS:
        psopts = "-ef"
    elif OPENBSD:
        psopts = "-aux"
    cmd = (
        "ps %s | "
        "grep %s | " # Limit to those matching the session
        "grep -v grep | " # Get rid of grep from the results (if present)
        "awk '{print $2}' | " # Just the PID please
        "xargs kill" % (psopts, session) # Kill em'
    )
    logging.debug('kill_session_processes cmd: %s' % cmd)
    exitstatus, output = shell_command(cmd)

def get_applications(application_dir, enabled=None):
    """
    Adds applications' Python files to `sys.path` (if necessary) and returns a
    list containing the name of each application.  If given, only applications
    in the *enabled* list will be returned.
    """
    out_list = []
    for directory in os.listdir(application_dir):
        application = directory.lower()
        directory = os.path.join(application_dir, directory) # Make absolute
        module_path = 'gateone.applications.%s' % application
        if not os.path.isdir(directory):
            continue
        if enabled and application not in enabled:
            continue
        application_files = os.listdir(directory)
        if "__init__.py" in application_files:
            out_list.append(module_path) # Just need the base
        else: # Look for .py files
            for app_file in application_files:
                if app_file.endswith('.py'):
                    app_path = os.path.join(directory, app_file)
                    sys.path.insert(0, directory)
                    (basename, ext) = os.path.splitext(app_path)
                    basename = basename.split('/')[-1]
                    module_path = "%s.%s" % (module_path, basename)
                    out_list.append(module_path)
    # Sort alphabetically so the order in which they're applied can
    # be controlled somewhat predictably
    out_list.sort()
    return out_list

def get_plugins(plugin_dir, enabled=None, basepath=None):
    """
    Adds plugins' Python files to `sys.path` and returns a dictionary of
    JavaScript, CSS, and Python files contained in *plugin_dir* like so::

        {
            'js': [ // NOTE: These would be be inside *plugin_dir*/static
                'happy_plugin/static/whatever.js',
                'ssh/static/ssh.js',
            ],
            'css': [
                'bookmarks/static/bookmarks.css',
                'ssh/templates/ssh.css'
            ],
            // NOTE: CSS URLs will require '&container=<container>' and '&prefix=<prefix>' to load.
            'py': [ // NOTE: These will get added to sys.path
                'happy_plugin',
                'ssh'
            ],
        }

    \*.js files inside of *plugin_dir*/<the plugin>/static will get automatically
    added to Gate One's index.html like so:

    .. code-block:: html

        {% for jsplugin in jsplugins %}
            <script type="text/javascript" src="{{jsplugin}}"></script>
        {% end %}

    \*.css files will get imported automatically by GateOne.init()

    Optionally, a list of *enabled* (Python) plugins may be provided and only
    those plugins will be added to the 'py' portion of the returned dict.

    Optionally, if a *basepath* is given imported plugin modules will be
    imported like so:

        <basepath>.plugin_module_name

    For example::

        get_plugins(
            "/path/to/gateone/applications/terminal/plugins",
            basepath="gateone.application.terminal.plugins")
    """
    out_dict = {'js': [], 'css': [], 'py': []}
    if not os.path.exists(plugin_dir):
        return out_dict
    for directory in os.listdir(plugin_dir):
        directory = directory.lower()
        if enabled and directory not in enabled:
            continue
        plugin = directory
        module_path_list = os.path.normpath(plugin_dir).split(os.path.sep)
        # Find the *last* directory named 'gateone'
        for i, _dir in enumerate(module_path_list):
            if _dir == 'gateone': # If we ever change the name... Fix this
                go_index = i
        module_base = '.'.join(module_path_list[go_index:])
        module_path = '%s.%s' % (module_base, plugin)
        http_static_path = '%s/static' % plugin
        http_template_path = '%s/templates' % plugin
        directory = os.path.join(plugin_dir, directory) # Make absolute
        if not os.path.isdir(directory):
            continue # This is not a plugin
        plugin_files = os.listdir(directory)
        if "__init__.py" in plugin_files:
            out_dict['py'].append(module_path) # Just need the base
        else: # Look for .py files
            for plugin_file in plugin_files:
                if plugin_file.endswith('.py'):
                    plugin_path = os.path.join(directory, plugin_file)
                    sys.path.insert(0, directory)
                    (basename, ext) = os.path.splitext(plugin_path)
                    basename = basename.split('/')[-1]
                    out_dict['py'].append(basename)
        for plugin_file in plugin_files:
            if plugin_file == 'static':
                static_dir = os.path.join(directory, plugin_file)
                for static_file in os.listdir(static_dir):
                    if static_file.endswith('.js'):
                        http_path = os.path.join(http_static_path, static_file)
                        out_dict['js'].append(http_path)
                    elif static_file.endswith('.css'):
                        http_path = os.path.join(http_static_path, static_file)
                        out_dict['css'].append(http_path)
            if plugin_file == 'templates':
                templates_dir = os.path.join(directory, plugin_file)
                for template_file in os.listdir(templates_dir):
                    if template_file.endswith('.css'):
                        http_path = os.path.join(
                            http_template_path, template_file)
                        out_dict['css'].append(http_path)
    # Sort all plugins alphabetically so the order in which they're applied can
    # be controlled somewhat predictably
    out_dict['py'].sort()
    out_dict['js'].sort()
    out_dict['css'].sort()
    return out_dict

def load_modules(modules):
    """
    Given a list of Python *modules*, imports them.

    .. note::  Assumes they're all in `sys.path`.
    """
    logging.debug("load_modules(%s)" % modules)
    out_list = []
    for module in modules:
        imported = __import__(module, None, None, [''])
        out_list.append(imported)
    return out_list

def merge_handlers(handlers):
    """
    Takes a list of Tornado *handlers* like this::

        [
            (r"/", MainHandler),
            (r"/ws", TerminalWebSocket),
            (r"/auth", AuthHandler),
            (r"/style", StyleHandler),
                ...
            (r"/style", SomePluginHandler),
        ]

    ...and returns a list with duplicate handlers removed; giving precedence to
    handlers with higher indexes.  This allows plugins to override Gate One's
    default handlers.  Given the above, this is what would be returned::

        [
            (r"/", MainHandler),
            (r"/ws", TerminalWebSocket),
            (r"/auth", AuthHandler),
                ...
            (r"/style", SomePluginHandler),
        ]

    This example would replace the default "/style" handler with
    SomePluginHandler; overriding Gate One's default StyleHandler.
    """
    out_list = []
    regexes = []
    handlers.reverse()
    for handler in handlers:
        if handler[0] not in regexes:
            regexes.append(handler[0])
            out_list.append(handler)
    out_list.reverse()
    return out_list

# NOTE: This function has been released under the Apache 2.0 license.
# See: http://code.activestate.com/recipes/577894-convert-strings-like-5d-and-60s-to-timedelta-objec/
def convert_to_timedelta(time_val):
    """
    Given a *time_val* (string) such as '5d', returns a `datetime.timedelta`
    object representing the given value (e.g. `timedelta(days=5)`).  Accepts the
    following '<num><char>' formats:

    =========   ============ =========================
    Character   Meaning      Example
    =========   ============ =========================
    (none)      Milliseconds '500' -> 500 Milliseconds
    s           Seconds      '60s' -> 60 Seconds
    m           Minutes      '5m'  -> 5 Minutes
    h           Hours        '24h' -> 24 Hours
    d           Days         '7d'  -> 7 Days
    M           Months       '2M'  -> 2 Months
    y           Years        '10y' -> 10 Years
    =========   ============ =========================

    Examples::

        >>> convert_to_timedelta('7d')
        datetime.timedelta(7)
        >>> convert_to_timedelta('24h')
        datetime.timedelta(1)
        >>> convert_to_timedelta('60m')
        datetime.timedelta(0, 3600)
        >>> convert_to_timedelta('120s')
        datetime.timedelta(0, 120)
    """
    try:
        num = int(time_val)
        return timedelta(milliseconds=num)
    except ValueError:
        pass
    num = int(time_val[:-1])
    if time_val.endswith('s'):
        return timedelta(seconds=num)
    elif time_val.endswith('m'):
        return timedelta(minutes=num)
    elif time_val.endswith('h'):
        return timedelta(hours=num)
    elif time_val.endswith('d'):
        return timedelta(days=num)
    elif time_val.endswith('M'):
        return timedelta(days=(num*30))  # Yeah this is approximate
    elif time_val.endswith('y'):
        return timedelta(days=(num*365)) # Sorry, no leap year support

def convert_to_bytes(size_val):
    """
    Given a *size_val* (string) such as '100M', returns an integer representing
    an equivalent amount of bytes.  Accepts the following '<num><char>' formats:

    =========== ==========  ==================================
    Character   Meaning     Example
    =========== ==========  ==================================
    B (or none) Bytes       '100' or '100b' -> 100
    K           Kilobytes   '1k' -> 1024
    M           Megabytes   '1m' -> 1048576
    G           Gigabytes   '1g' -> 1073741824
    T           Terabytes   '1t' -> 1099511627776
    P           Petabytes   '1p' -> 1125899906842624
    E           Exabytes    '1e' -> 1152921504606846976
    Z           Zettabytes  '1z' -> 1180591620717411303424L
    Y           Yottabytes  '7y' -> 1208925819614629174706176L
    =========== ==========  ==================================

    .. note::

        If no character is given the *size_val* will be assumed to be in bytes.

    .. tip::

        All characters will be converted to upper case before conversion
        (case-insensitive).

    Examples::

        >>> convert_to_bytes('2M')
        2097152
        >>> convert_to_bytes('2g')
        2147483648
    """
    symbols = "BKMGTPEZY"
    letter = size_val[-1:].strip().upper()
    if letter.isdigit(): # Assume bytes
        letter = 'B'
        num = size_val
    else:
        num = size_val[:-1]
    assert num.isdigit() and letter in symbols
    num = float(num)
    prefix = {symbols[0]:1}
    for i, size_val in enumerate(symbols[1:]):
        prefix[size_val] = 1 << (i+1)*10
    return int(num * prefix[letter])

def total_seconds(td):
    """
    Given a timedelta (*td*) return an integer representing the equivalent of
    Python 2.7's :meth:`datetime.timdelta.total_seconds`.
    """
    return (((
        td.microseconds +
        (td.seconds + td.days * 24 * 3600) * 10**6) / 10**6))

def process_opt_esc_sequence(chars):
    """
    Parse the *chars* passed from :class:`terminal.Terminal` by way of the
    special, optional escape sequence handler (e.g. '<plugin>|<text>') into a
    tuple of (<plugin name>, <text>).  Here's an example::

        >>> process_opt_esc_sequence('ssh|user@host:22')
        ('ssh', 'user@host:22')
    """
    plugin = None
    text = ""
    try:
        plugin, text = chars.split('|')
    except Exception:
        pass # Something went horribly wrong!
    return (plugin, text)

def raw(text, replacement_dict=None):
    """
    Returns *text* as a string with special characters replaced by visible
    equivalents using *replacement_dict*.  If *replacement_dict* is None or
    False the global REPLACEMENT_DICT will be used.  Example::

        >>> test = '\\x1b]0;Some xterm title\x07'
        >>> print(raw(test))
        '^[]0;Some title^G'
    """
    if not replacement_dict:
        replacement_dict = REPLACEMENT_DICT
    out = u''
    for char in text:
        charnum = ord(char)
        if charnum in replacement_dict.keys():
            out += replacement_dict[charnum]
        else:
            out += char
    return out

def create_data_uri(filepath, mimetype=None):
    """
    Given a file at *filepath*, return that file as a data URI.

    Raises a `MimeTypeFail` exception if the mimetype could not be guessed.
    """
    import base64
    if not mimetype:
        mimetype = mimetypes.guess_type(filepath)[0]
    if not mimetype:
        raise MimeTypeFail("Could not guess mime type of: %s" % filepath)
    with io.open(filepath, mode='rb') as f:
        data = f.read()
    encoded = base64.b64encode(data).decode('ascii').replace('\n', '')
    if len(encoded) > 65000:
        logging.warn(
            "WARNING: Data URI > 65,000 characters.  You're pushing it buddy!")
    data_uri = "data:%s;base64,%s" % (mimetype, encoded)
    return data_uri

def human_readable_bytes(nbytes):
    """
    Returns *nbytes* as a human-readable string in a similar fashion to how it
    would be displayed by `ls -lh` or `df -h`.
    """
    K, M, G, T = 1 << 10, 1 << 20, 1 << 30, 1 << 40
    if nbytes >= T:
        return '%.1fT' % (float(nbytes)/T)
    elif nbytes >= G:
        return '%.1fG' % (float(nbytes)/G)
    elif nbytes >= M:
        return '%.1fM' % (float(nbytes)/M)
    elif nbytes >= K:
        return '%.1fK' % (float(nbytes)/K)
    else:
        return '%d' % nbytes

def which(binary, path=None):
    """
    Returns the full path of *binary* (string) just like the 'which' command.
    Optionally, a *path* (colon-delimited string) may be given to use instead of
    `os.environ['PATH']`.
    """
    if path:
        paths = path.split(':')
    else:
        paths = os.environ['PATH'].split(':')
    for path in paths:
        if not os.path.exists(path):
            continue
        files = os.listdir(path)
        if binary in files:
            return os.path.join(path, binary)
    return None

def touch(path):
    """
    Emulates the 'touch' command by creating the file at *path* if it does not
    exist.  If the file exist its modification time will be updated.
    """
    with io.open(path, 'ab'):
        os.utime(path, None)

def timeout_func(func, args=(), kwargs={}, timeout_duration=10, default=None):
    """
    Sets a timeout on the given function, passing it the given args, kwargs,
    and a *default* value to return in the event of a timeout.  If *default* is
    a function that function will be called in the event of a timeout.
    """
    import threading
    class InterruptableThread(threading.Thread):
        def __init__(self):
            threading.Thread.__init__(self)
            self.result = None

        def run(self):
            try:
                self.result = func(*args, **kwargs)
            except:
                self.result = default

    it = InterruptableThread()
    it.start()
    it.join(timeout_duration)
    if it.isAlive():
        if hasattr(default, '__call__'):
            return default()
        else:
            return default
    else:
        return it.result

def valid_hostname(hostname, allow_underscore=False):
    """
    Returns True if the given *hostname* is valid according to RFC rules.  Works
    with Internationalized Domain Names (IDN) and optionally, hostnames with an
    underscore (if *allow_underscore* is True).

    The rules for hostnames:

        * Must be less than 255 characters.
        * Individual labels (separated by dots) must be <= 63 characters.
        * Only the ASCII alphabet (A-Z) is allowed along with dashes (-) and dots (.).
        * May not start with a dash or a dot.
        * May not end with a dash.
        * If an IDN, when converted to Punycode it must comply with the above.

    IP addresses will be validated according to their well-known specifications.

    Examples::

        >>> valid_hostname('foo.bar.com.') # Standard FQDN
        True
        >>> valid_hostname('2foo') # Short hostname
        True
        >>> valid_hostname('-2foo') # No good:  Starts with a dash
        False
        >>> valid_hostname('host_a') # No good: Can't have underscore
        False
        >>> valid_hostname('host_a', allow_underscore=True) # Now it'll validate
        True
        >>> valid_hostname(u'.jp') # Example valid IDN
        True
    """
    # Convert to Punycode if an IDN
    if isinstance(hostname, str):
        try:
            hostname = hostname.encode('idna')
        except UnicodeError: # Can't convert to Punycode: Bad hostname
            return False
    if len(hostname) > 255:
        return False
    if hostname[-1:] == b".": # Strip the tailing dot if present
        hostname = hostname[:-1]
    allowed = re.compile(b"(?!-)[A-Z\d-]{1,63}(?<!-)$", re.IGNORECASE)
    if allow_underscore:
        allowed = re.compile(b"(?!-)[_A-Z\d-]{1,63}(?<!-)$", re.IGNORECASE)
    return all(allowed.match(x) for x in hostname.split(b"."))

def recursive_chown(path, uid, gid):
    """Emulates 'chown -R *uid*:*gid* *path*' in pure Python"""
    error_msg = _(
        "Error: Gate One does not have the ability to recursively chown %s to "
        "uid %s/gid %s.  Please ensure that user, %s has write permission to "
        "the directory.")
    try:
        os.chown(path, uid, gid)
    except OSError as e:
        import pwd
        if e.errno in [errno.EACCES, errno.EPERM]:
            raise ChownError(error_msg % (path, uid, gid,
                repr(pwd.getpwuid(os.geteuid())[0])))
        else:
            raise
    for root, dirs, files in os.walk(path):
        for momo in dirs:
            _path = os.path.join(root, momo)
            try:
                os.chown(_path, uid, gid)
            except OSError as e:
                import pwd
                if e.errno in [errno.EACCES, errno.EPERM]:
                    raise ChownError(error_msg % (
                        _path, uid, gid, repr(pwd.getpwuid(os.geteuid())[0])))
                else:
                    raise
        for momo in files:
            _path = os.path.join(root, momo)
            try:
                os.chown(_path, uid, gid)
            except OSError as e:
                import pwd
                if e.errno in [errno.EACCES, errno.EPERM]:
                    raise ChownError(error_msg % (
                        _path, uid, gid, repr(pwd.getpwuid(os.geteuid())[0])))
                else:
                    raise

def check_write_permissions(user, path):
    """
    Returns `True` if the given *user* has write permissions to *path*.  *user*
    can be a UID (int) or a username (string).
    """
    import pwd, grp, stat
    # Get the user's complete passwd record
    if isinstance(user, int):
        user = pwd.getpwuid(user)
    else:
        user = pwd.getpwnam(user)
    if user.pw_uid == 0:
        return True # Assume root can write to everything (NFS notwithstanding)
    groups = [] # A combination of user's primary GID and supplemental groups
    for group in grp.getgrall():
        if user.pw_name in group.gr_mem:
            groups.append(group.gr_gid)
        if group.gr_gid == user.pw_gid:
            groups.append(group.gr_gid)
    st = os.stat(path)
    other_write = bool(st.st_mode & stat.S_IWOTH)
    if other_write:
        return True # Read/write world!
    owner_write = bool(st.st_mode & stat.S_IWUSR)
    if st.st_uid == user.pw_uid and owner_write:
        return True # User can write to their own file
    group_write = bool(st.st_mode & stat.S_IWGRP)
    if st.st_gid in groups and group_write:
        return True # User belongs to a group that can write to the file
    return False

def bind(function, self):
    """
    Will return *function* with *self* bound as the first argument.  Allows one
    to write functions like this::

        def foo(self, whatever):
            return whatever

    ...outside of the construct of a class.
    """
    return partial(function, self)

def minify(path_or_fileobj, kind):
    """
    Returns *path_or_fileobj* as a minified string.  *kind* should be one of
    'js' or 'css'.  Works with JavaScript and CSS files using `slimit` and
    `cssmin`, respectively.
    """
    out = None
    # Optional:  If slimit is installed Gate One will use it to minify JS and CSS
    try:
        import slimit
    except ImportError:
        slimit = None
        #logging.warning(_(
            #"slimit module not found.  JavaScript will not be minified."))
        #logging.info(_("To install slimit:  sudo pip install slimit"))
    try:
        import cssmin
    except ImportError:
        cssmin = None
        #logging.warning(_(
            #"cssmin module not found.  CSS will not be minified."))
        #logging.info(_("To install cssmin:  sudo pip install cssmin"))
    if isinstance(path_or_fileobj, basestring):
        filename = os.path.split(path_or_fileobj)[1]
        with io.open(path_or_fileobj, mode='r', encoding='utf-8') as f:
            data = f.read()
    else:
        filename = os.path.split(path_or_fileobj.name)[1]
        data = path_or_fileobj.read()
    out = data
    if slimit and kind == 'js':
        try:
            out = slimit.minify(data)
            logging.debug(_(
                "(saved ~%s bytes minifying %s)" % (
                    (len(data) - len(out), filename)
                )
            ))
        except Exception:
            logging.error(_("slimit failed trying to minify %s") % filename)
            import traceback
            traceback.print_exc(file=sys.stdout)
        del slimit # Don't need this anymore
    elif cssmin and kind == 'css':
        out = cssmin.cssmin(data)
        logging.debug(_(
            "(saved ~%s bytes minifying %s)" % (
                (len(data) - len(out), filename)
            )
        ))
        del cssmin # Don't need this anymore
    return out

# This is so we can have the argument below be 'minify' (user friendly)
_minify = minify

def get_or_cache(cache_dir, path, minify=True):
    """
    Given a *path*, returns the cached version of that file.  If the file has
    yet to be cached, cache it and return the result.  If *minify* is `True`
    (the default), the file will be minified as part of the caching process (if
    possible).
    """
    # Need to store the original file's modification time in the filename
    # so we can tell if the original changed in the event that Gate One is
    # restarted.
    # Also, we're using the full path in the cached filename in the event
    # that two files have the same name but at different paths.
    mtime = os.stat(path).st_mtime
    shortened_path = short_hash(path)
    cached_filename = "%s:%s" % (shortened_path, mtime)
    cached_file_path = os.path.join(cache_dir, cached_filename)
    # Check if the file has changed since last time and use the cached
    # version if it makes sense to do so.
    if os.path.exists(cached_file_path):
        with io.open(cached_file_path, mode='r', encoding='utf-8') as f:
            data = f.read()
    elif minify:
        # Using regular expressions here because rendered filenames often end
        # like this: .css_1357311277
        # Hopefully this is a good enough classifier.
        if JS_END.search(path):
            kind = 'js'
        elif CSS_END.search(path):
            kind = 'css'
        else: # Just cache it as-is; no minification
            kind = False
        if kind:
            data = _minify(path, kind)
            # Cache it
            with io.open(cached_file_path, mode='w', encoding='utf-8') as f:
                f.write(data)
        else:
            with io.open(path, mode='r', encoding='utf-8') as f:
                data = f.read()
    else:
        with io.open(path, mode='r', encoding='utf-8') as f:
            data = f.read()
    # Clean up old versions of this file (if present)
    for fname in os.listdir(cache_dir):
        if fname == cached_filename:
            continue
        elif fname.startswith(shortened_path):
            # Older version present.  Remove it.
            os.remove(os.path.join(cache_dir, fname))
    return data

def drop_privileges(uid='nobody', gid='nogroup', supl_groups=None):
    """
    Drop privileges by changing the current process owner/group to
    *uid*/*gid* (both may be an integer or a string).  If *supl_groups* (list)
    is given the process will be assigned those values as its effective
    supplemental groups.  If *supl_groups* is None it will default to using
    'tty' as the only supplemental group.  Example::

        drop_privileges('gateone', 'gateone', ['tty'])

    This would change the current process owner to gateone/gateone with 'tty' as
    its only supplemental group.

    .. note::

        On most Unix systems users must belong to the 'tty' group to create new
        controlling TTYs which is necessary for 'pty.fork()' to work.

    .. tip::

        If you get errors like, "OSError: out of pty devices" it likely means
        that your OS uses something other than 'tty' as the group owner of the
        devpts filesystem.  'mount | grep pts' will tell you the owner (look for
        gid=<owner>).
    """
    import pwd, grp
    human_supl_groups = []
    running_uid = uid
    running_gid = gid
    if not isinstance(uid, int):
        # Get the uid/gid from the name
        running_uid = pwd.getpwnam(uid).pw_uid
    if not isinstance(gid, int):
        running_gid = grp.getgrnam(gid).gr_gid
    if supl_groups:
        for i, group in enumerate(list(supl_groups)):
            # Just update in-place
            if not isinstance(group, int):
                supl_groups[i] = grp.getgrnam(group).gr_gid
            human_supl_groups.append(grp.getgrgid(supl_groups[i]).gr_name)
        try:
            os.setgroups(supl_groups)
        except OSError as e:
            logging.error(_('Could not set supplemental groups: %s' % e))
            exit()
    # Try setting the new uid/gid
    try:
        os.setgid(running_gid)
    except OSError as e:
        logging.error(_('Could not set effective group id: %s' % e))
        exit()
    try:
        os.setuid(running_uid)
    except OSError as e:
        logging.error(_('Could not set effective user id: %s' % e))
        exit()
    # Ensure a very convervative umask
    new_umask = 0o77
    os.umask(new_umask)
    # Fix some basic/known environment variables
    pwd_obj = pwd.getpwuid(running_uid)
    os.environ['USER'] = pwd_obj.pw_name
    os.environ['LOGNAME'] = pwd_obj.pw_name
    os.environ['HOME'] = pwd_obj.pw_dir
    os.environ['SHELL'] = pwd_obj.pw_shell
    final_gid = os.getgid()
    logging.info(_(
        'Running as user/group, "%s/%s" with the following supplemental groups:'
        ' %s' % (pwd_obj.pw_name, grp.getgrgid(final_gid)[0],
                 ",".join(human_supl_groups))
    ))

def strip_xss(html, whitelist=None, replacement=u"\u2421"):
    """
    This function returns a tuple containing:

        * *html* with all non-whitelisted HTML tags replaced with *replacement*.  Any tags that contain JavaScript, VBScript, or other known XSS/executable functions will also be removed.
        * A list containing the tags that were removed.

    If *whitelist* is not given the following will be used::

        whitelist = set([
            'a', 'abbr', 'aside', 'audio', 'bdi', 'bdo', 'blockquote', 'canvas',
            'caption', 'code', 'col', 'colgroup', 'data', 'dd', 'del',
            'details', 'div', 'dl', 'dt', 'em', 'figcaption', 'figure', 'h1',
            'h2', 'h3', 'h4', 'h5', 'h6', 'hr', 'i', 'img', 'ins', 'kbd', 'li',
            'mark', 'ol', 'p', 'pre', 'q', 'rp', 'rt', 'ruby', 's', 'samp',
            'small', 'source', 'span', 'strong', 'sub', 'summary', 'sup',
            'time', 'track', 'u', 'ul', 'var', 'video', 'wbr'
        ])

    Example::

        >>> html = '<span>Hello, exploit: <img src="javascript:alert(\"pwned!\")"></span>'
        >>> strip_xss(html)
        (u'<span>Hello, exploit: \u2421</span>', ['<img src="javascript:alert("pwned!")">'])

    .. note:: The default *replacement* is the unicode  character (u"\u2421").

    If *replacement* is "entities" bad HTML tags will be encoded into HTML
    entities.  This allows things like <script>'whatever'</script> to be
    displayed without execution (which would be much less annoying to users that
    were merely trying to share a code example).  Here's an example::

        >>> html = '<span>Hello, exploit: <img src="javascript:alert(\"pwned!\")"></span>'
        >>> strip_xss(html, replacement="entities")
        ('<span>Hello, exploit: &lt;span&gt;Hello, exploit: &lt;img src="javascript:alert("pwned!")"&gt;&lt;/span&gt;</span>',
         ['<img src="javascript:alert("pwned!")">'])
        (u'<span>Hello, exploit: \u2421</span>', ['<img src="javascript:alert("pwned!")">'])

    .. note::

        This function should work to protect against all `the XSS examples at
        OWASP <https://www.owasp.org/index.php/XSS_Filter_Evasion_Cheat_Sheet>`_.
        Please `let us know <https://github.com/liftoff/GateOne/issues>`_ if
        you find something we missed.
    """
    re_html_tag = re.compile( # This matches HTML tags (if used correctly)
      "(?i)<\/?\w+((\s+\w+(\s*=\s*(?:\".*?\"|'.*?'|[^'\">\s]+))?)+\s*|\s*)\/?>")
    # This will match things like 'onmouseover=' ('on<whatever>=')
    on_events_re = re.compile('.*\s+(on[a-z]+\s*=).*')
    if not whitelist:
        # These are all pretty safe and covers most of what users would want in
        # terms of formatting and sharing media (images, audio, video, etc).
        whitelist = set([
            'a', 'abbr', 'aside', 'audio', 'bdi', 'bdo', 'blockquote', 'canvas',
            'caption', 'code', 'col', 'colgroup', 'data', 'dd', 'del',
            'details', 'div', 'dl', 'dt', 'em', 'figcaption', 'figure', 'h1',
            'h2', 'h3', 'h4', 'h5', 'h6', 'hr', 'i', 'img', 'ins', 'kbd', 'li',
            'mark', 'ol', 'p', 'pre', 'q', 'rp', 'rt', 'ruby', 's', 'samp',
            'small', 'source', 'span', 'strong', 'sub', 'summary', 'sup',
            'time', 'track', 'u', 'ul', 'var', 'video', 'wbr'
        ])
    bad_tags = []
    for tag in re_html_tag.finditer(html):
        tag = tag.group()
        tag_lower = tag.lower()
        short_tag = tag_lower.split()[0].lstrip('</').rstrip('>')
        if short_tag not in whitelist:
            bad_tags.append(tag)
            continue
        # Make sure the tag can't execute any JavaScript
        if "javascript:" in tag_lower:
            bad_tags.append(tag)
            continue
        # on<whatever> events are not allowed (just another XSS vuln)
        if on_events_re.search(tag_lower):
            bad_tags.append(tag)
            continue
        # Flash sucks
        if "fscommand" in tag_lower:
            bad_tags.append(tag)
            continue
        # I'd be impressed if an attacker tried this one (super obscure)
        if "seeksegmenttime" in tag_lower:
            bad_tags.append(tag)
            continue
        # Yes we'll protect IE users from themselves...
        if "vbscript:" in tag_lower:
            bad_tags.append(tag)
            continue
    if replacement == "entities":
        import cgi
        for bad_tag in bad_tags:
            escaped = cgi.escape(html).encode('ascii', 'xmlcharrefreplace')
            html = html.replace(bad_tag, escaped)
    else:
        for bad_tag in bad_tags:
            html = html.replace(bad_tag, replacement)
    return (html, bad_tags)

def create_signature(*parts, **kwargs):
    """
    Creates an HMAC signature using the given *parts* and *kwargs*.  The first
    argument **must** be the 'secret' followed by any arguments that are to be
    part of the hash.  The only *kwargs* that is used is 'hmac_algo'.
    'hmac_algo' may be any HMAC algorithm present in the hashlib module.  If not
    provided, `hashlib.sha1` will be used.  Example usage::

        create_signature(
            'secret',
            'some-api-key',
            '1234567890123',
            'user@somehost',
            hmac_algo=hashlib.sha1)

    .. note::

        The API 'secret' **must** be the first argument.  Also, the order
        *does* matter.
    """
    secret = parts[0]
    secret = str(secret).encode('utf-8') # encode() because hmac takes bytes
    parts = parts[1:]
    hmac_algo = kwargs.get('hmac_algo', hashlib.sha1) # Default to sha1
    hash = hmac.new(secret, digestmod=hmac_algo)
    for part in parts:
        part = str(part).encode('utf-8') # str() in case of an int
        hash.update(part)
    return hash.hexdigest()

# Misc
if MACOS or OPENBSD: # Apply BSD-specific stuff
    kill_dtached_proc = kill_dtached_proc_bsd
    killall = killall_bsd

########NEW FILE########
__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# Gate One documentation build configuration file, created by
# sphinx-quickstart on Thu Sep 29 19:26:51 2011.

import sys, os, logging

# Use Tornado's pretty color log formatter
from tornado.log import LogFormatter
logger = logging.getLogger()
# Always set to debug because who else would be building the docs except a
# developer/sysadmin/geek?
logger.setLevel(getattr(logging, "DEBUG"))
for handler in list(logger.handlers): # Remove any existing log handlers
    if isinstance(handler, logging.StreamHandler):
        logger.handlers.remove(handler)
channel = logging.StreamHandler() # This ensures we're using Tornado's
channel.setFormatter(LogFormatter())
logger.addHandler(channel)

def bold(text):
    "Prints out *text* in bold inside a terminal"
    print("\x1b[1m{0}\x1b[0m".format(text))

# Check for dependencies
try:
    import sphinxcontrib.autojs
except ImportError:
    logging.error(
        "To build Gate One's docs you need the sphinxcontrib.autojs extension.")
    logging.info(
        "Liftoff Software maintains a fork of sphinxcontrib.autojs that "
        "includes additional fixes and ehancements (we submit pull requests but"
        " they can take time to make it back to the main repo) that can be "
        "cloned here:  https://github.com/liftoff/sphinxcontrib-autojs")
    bold("To fix this problem just do this:\n")
    bold(
        "    git clone "
        "https://github.com/liftoff/sphinxcontrib-autojs.git")
    bold("    cd sphinxcontrib-autojs; sudo python setup.py install")
    sys.exit(1)

try:
    import sphinxcontrib.ansi
except ImportError:
    logging.error(
        "To build Gate One's docs you need the sphinxcontrib.ansi extension.")
    bold("To fix this problem just do this:\n")
    bold("    sudo pip install sphinxcontrib-ansi")
    sys.exit(1)

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
sys.path.insert(0, os.path.abspath('../../../'))
# Insert plugins too
for plugin_dir in os.listdir(os.path.abspath('../../plugins')):
    sys.path.append(os.path.abspath('../../plugins/%s' % plugin_dir))
# Insert application modules:
for app in os.listdir(os.path.abspath('../../applications')):
    app_dir = os.path.abspath('../../applications/%s' % app)
    if not os.path.isdir(app_dir):
        continue
    sys.path.append(app_dir)
    # ...and each of the application's plugins (if it has any):
    plugins_dir = os.path.join(app_dir, 'plugins')
    if os.path.exists(plugins_dir):
        for plugin_dir in os.listdir(plugins_dir):
            plugin_path = os.path.join(plugins_dir, plugin_dir)
            sys.path.append(plugin_path)

import gateone # So we can grab the version
# -- General configuration -----------------------------------------------------

# This is for using my custom stylesheet with the ANSI extension
def setup(app):
    app.add_stylesheet('ansi.css')

# If your documentation needs a minimal Sphinx version, state it here.
needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = [
    'sphinx.ext.autodoc',
    'sphinx.ext.todo',
    'sphinx.ext.ifconfig',
    'sphinx.ext.viewcode',
    'sphinx.ext.intersphinx',
    'sphinxcontrib.ansi', # Displays text codes as they would appear in a shell
    'sphinxcontrib.autojs', # Lets us use docstring-like syntax in JS
]
try:
    # Add the googleanalytics extension if available
    import sphinxcontrib.googleanalytics
    extensions.append('sphinxcontrib.googleanalytics')
    googleanalytics_id = 'UA-29645087-2' # DM: Made this just for the docs
    googleanalytics_enabled = True
except ImportError:
    logging.info("FYI: You're missing the sphinxcontrib.googleanalytics module")

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'Gate One'
copyright = u'2013, Liftoff Software Corporation'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
version = release = gateone.__version__

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

primary_domain = 'py'
default_role = 'py:obj'

autodoc_member_order = "bysource"
autoclass_content = "both"

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = []

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'manni'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []

# Include TODOs in the docs.
todo_include_todos = True

# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = "Gate One v%s" % gateone.__version__

# A shorter title for the navigation bar.  Default is the same as html_title.
html_short_title = "Gate One Documentation"

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
html_logo = 'Images/ls_logo_1inch_300dpi.png'

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
html_favicon = 'Images/favicon.png'

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
html_use_smartypants = False

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'GateOneDoc'

html_output_encoding = 'utf-8'

# -- Options for LaTeX output --------------------------------------------------

# The paper size ('letter' or 'a4').
#latex_paper_size = 'letter'

# The font size ('10pt', '11pt' or '12pt').
#latex_font_size = '10pt'

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'GateOne.tex', u'Gate One Documentation',
   u'Liftoff Software Corporation', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Additional stuff for the LaTeX preamble.
#latex_preamble = ''

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'gateone', u'Gate One Documentation',
     [u'Liftoff Software Corporation'], 1)
]


# -- Options for Epub output ---------------------------------------------------

# Bibliographic Dublin Core info.
epub_title = u'Gate One'
epub_author = u'Dan McDougall'
epub_publisher = u'Liftoff Software Corporation'
epub_copyright = u'2011, Liftoff Software Corporation'

# The language of the text. It defaults to the language option
# or en if the language is not set.
#epub_language = ''

# The scheme of the identifier. Typical schemes are ISBN or URL.
#epub_scheme = ''

# The unique identifier of the text. This can be a ISBN number
# or the project homepage.
#epub_identifier = ''

# A unique identification for the text.
#epub_uid = ''

# HTML files that should be inserted before the pages created by sphinx.
# The format is a list of tuples containing the path and title.
#epub_pre_files = []

# HTML files shat should be inserted after the pages created by sphinx.
# The format is a list of tuples containing the path and title.
#epub_post_files = []

# A list of files that should not be packed into the epub file.
#epub_exclude_files = []

# The depth of the table of contents in toc.ncx.
#epub_tocdepth = 3

# Allow duplicate toc entries.
#epub_tocdup = True

# -- Intersphinx stuff ---------------------------------------------------------
intersphinx_mapping = {
    #'python': ('http://docs.python.org/2.7', None),
    #'tornado': ('http://www.tornadoweb.org/en/stable/', None)
}

# Make PHP syntax highlighting work
from sphinx.highlighting import lexers
from pygments.lexers.web import PhpLexer
lexers['php'] = PhpLexer(startinline=True)

########NEW FILE########
__FILENAME__ = chatdemo
#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Copyright 2009 Facebook
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.

# NOTE:  This is a modified version of the 'chat' demo application included in
# the Tornado framework tarball.

# TODO: Write a nice long docstring for this and make sure it shows up in the
#       regular Gate One documentation.

import sys
import logging
import time
import json
import tornado.auth
import tornado.escape
import tornado.ioloop
import tornado.options
import tornado.web
import os.path
import uuid

from tornado.options import define, options

define("port", default=8000, help="Run on the given port", type=int)

class Application(tornado.web.Application):
    def __init__(self):
        handlers = [
            (r"/", MainHandler),
            (r"/auth/login", AuthLoginHandler),
            (r"/auth/logout", AuthLogoutHandler),
            (r"/a/message/new", MessageNewHandler),
            (r"/a/message/updates", MessageUpdatesHandler),
        ]
        settings = dict(
            cookie_secret=u"MjkwYzc3MDI2MjhhNGZkNDg1MjJkODgyYjBmN2MyMTM4M",
            login_url="/auth/login",
            template_path=os.path.join(os.path.dirname(__file__), "templates"),
            static_path=os.path.join(os.path.dirname(__file__), "static"),
            xsrf_cookies=True,
            debug=True,
            autoescape="xhtml_escape"
        )
        tornado.web.Application.__init__(self, handlers, **settings)


class BaseHandler(tornado.web.RequestHandler):
    def get_current_user(self):
        user_json = self.get_secure_cookie("user")
        if not user_json: return None
        return tornado.escape.json_decode(user_json)


class MainHandler(BaseHandler):
    @tornado.web.authenticated
    def get(self):
        user = self.get_current_user()
        api_key = self.settings['cookie_secret']
        upn = user['email']
        # Make a note that this is a quick way to generate a JS-style epoch:
        timestamp = str(int(time.time()) * 1000)
        auth_obj = {
            'api_key': api_key, # Whatever is in server.conf
            'upn': upn, # e.g. user@gmail.com
            'timestamp': timestamp,
            #'signature': <gibberish>, # We update the sig below
            'signature_method': 'HMAC-SHA1', # Won't change (for now)
            'api_version': '1.0' # Won't change (for now)
        }
        secret = 'secret' # Whatever is in server.conf for our API key
        # For this app I'm using the convenient _create_signature() method but
        # it is trivial to implement the same exact thing in just about any
        # language. Here's the function (so you don't have to look it up =):
        #
        # def _create_signature(secret, *parts):
        #    hash = hmac.new(utf8(secret), digestmod=hashlib.sha1)
        #    for part in parts: hash.update(utf8(part))
        #    return utf8(hash.hexdigest())
        #
        # Real simple: HMAC-SHA1 hash the three parts using 'secret'.  The utf8
        # function just ensures that the encoding is UTF-8.  In most cases you
        # won't have to worry about stuff like that since these values will most
        # likely just be ASCII.
        signature = tornado.web._create_signature(
            secret,
            api_key,
            upn,
            timestamp
        ).decode('utf-8')
        auth_obj.update({'signature': signature})
        auth = json.dumps(auth_obj)
        self.render(
            "index.html",
            messages=MessageMixin.cache,
            auth=auth
        )

class MessageMixin(object):
    waiters = set()
    cache = []
    cache_size = 200

    def wait_for_messages(self, callback, cursor=None):
        cls = MessageMixin
        if cursor:
            index = 0
            for i in xrange(len(cls.cache)):
                index = len(cls.cache) - i - 1
                if cls.cache[index]["id"] == cursor: break
            recent = cls.cache[index + 1:]
            if recent:
                callback(recent)
                return
        cls.waiters.add(callback)

    def cancel_wait(self, callback):
        cls = MessageMixin
        cls.waiters.remove(callback)

    def new_messages(self, messages):
        cls = MessageMixin
        logging.info("Sending new message to %r listeners", len(cls.waiters))
        for callback in cls.waiters:
            try:
                callback(messages)
            except:
                logging.error("Error in waiter callback", exc_info=True)
        cls.waiters = set()
        cls.cache.extend(messages)
        if len(cls.cache) > self.cache_size:
            cls.cache = cls.cache[-self.cache_size:]

class MessageNewHandler(BaseHandler, MessageMixin):
    @tornado.web.authenticated
    def post(self):
        message = {
            "id": str(uuid.uuid4()),
            "from": self.current_user["first_name"],
            "body": self.get_argument("body"),
        }
        message["html"] = self.render_string("message.html", message=message)
        if self.get_argument("next", None):
            self.redirect(self.get_argument("next"))
        else:
            self.write(message)
        self.new_messages([message])

class MessageUpdatesHandler(BaseHandler, MessageMixin):
    @tornado.web.authenticated
    @tornado.web.asynchronous
    def post(self):
        cursor = self.get_argument("cursor", None)
        self.wait_for_messages(self.on_new_messages,
                               cursor=cursor)

    def on_new_messages(self, messages):
        # Closed client connection
        if self.request.connection.stream.closed():
            return
        self.finish(dict(messages=messages))

    def on_connection_close(self):
        self.cancel_wait(self.on_new_messages)


class AuthLoginHandler(BaseHandler, tornado.auth.GoogleMixin):
    @tornado.web.asynchronous
    def get(self):
        if self.get_argument("openid.mode", None):
            self.get_authenticated_user(self.async_callback(self._on_auth))
            return
        self.authenticate_redirect(ax_attrs=["name","email"])

    def _on_auth(self, user):
        if not user:
            raise tornado.web.HTTPError(500, "Google auth failed")
        self.set_secure_cookie("user", tornado.escape.json_encode(user))
        self.redirect("/")

class AuthLogoutHandler(BaseHandler):
    def get(self):
        self.clear_cookie("user")
        self.write("You are now logged out")

def main():
    tornado.options.parse_command_line()
    app = Application()
    app.listen(options.port, ssl_options={
        "certfile": os.path.join(os.getcwd(), "certificate.pem"),
        "keyfile": os.path.join(os.getcwd(), "keyfile.pem"),
    })
    print("For this to work you must add the following to Gate One's "
          "settings/20authentication.conf (under the 'gateone' section):")
    print('\n    "auth": "api"\n')
    # Using the cookie_secret as the API key here:
    print(u'You will also want to add the following to your 30api_keys.conf '
           '(or just create a new file with this info inside it):')
    print('''
{
    "*": {
        "gateone": {
            "api_keys": {
                "MjkwYzc3MDI2MjhhNGZkNDg1MjJkODgyYjBmN2MyMTM4M": "secret"
            }
        }
    }
}''')
    print("\n...and restart Gate One for the change to take effect.")
    # NOTE: Gate One will actually generate a nice and secure secret when you
    # use --new_api_key option.  Using 'secret' here to demonstrate that it can
    # be whatever you want.
    print("Listening on 0.0.0.0:%s" % options.port)
    tornado.ioloop.IOLoop.instance().start()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        sys.exit(0)

########NEW FILE########
__FILENAME__ = hello_embedded_world
#!/usr/bin/env python

__version__ = '1.0'
__license__ = "Apache 2.0" # Do what you want with this code but don't sue me :)
__version_info__ = (1, 0)
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'

__doc__ = """\
hello_embedded
==============
This is a self-running tutorial demonstrating how to embed Gate One into any
given web application.  Simply run ./hello_embedded.py and connect to it in your
web browser.  If your Gate One server is running on the same host you can
change the port by passing, '--port=<something other than 443>' as a command
line argument to hello_embedded.py.

The code that makes up hello_embedded.py is just a boilerplate Tornado web
server.  All the interesting parts are contained in the static/index.html
directory.

.. note:: Why not just put the tutorial in the regular Gate One docs?  Because in order for the tutorial to work it must be run from a web server (file:// URLs won't work).  Gate One's documentation is made to work completely offline (you can even make a PDF out of it).
"""

import os, sys

import tornado.httpserver
import tornado.ioloop
import tornado.options
import tornado.web

from tornado.options import define, options

define("port", default=443, help="Listen on this port", type=int)
define("address", default='127.0.0.1', help="Listen on this address", type=str)

class MainHandler(tornado.web.RequestHandler):
    def get(self):
        index_html = open('static/index.html').read()
        self.write(index_html)

def main():
    tornado.options.parse_command_line()
    application = tornado.web.Application([
            (r"/", MainHandler),
        ],
        static_path=os.path.join(os.path.dirname(__file__), "static"),
        debug=True
    )
    https_server = tornado.httpserver.HTTPServer(
        application, ssl_options={
        "certfile": os.path.join(os.getcwd(), "certificate.pem"),
        "keyfile": os.path.join(os.getcwd(), "keyfile.pem"),
    })
    print("Now listening on https://%s:%s" % (options.address, options.port))
    https_server.listen(address=options.address, port=options.port)
    tornado.ioloop.IOLoop.instance().start()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        sys.exit(0)

########NEW FILE########
__FILENAME__ = inlined_matplotlib
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import sys
import matplotlib
matplotlib.use('Agg')
from matplotlib.backends.backend_agg import FigureCanvasAgg
from matplotlib.figure import Figure
import pylab

fig = Figure()
canvas = FigureCanvasAgg(fig)
ax = fig.add_subplot(111)
x = pylab.randn(1000)
ax.hist(x, 100)
ax.set_title('Gate One Inline Matplotlib Test')
canvas.print_figure(sys.stdout)

########NEW FILE########
__FILENAME__ = inlined_pydot
#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
An example of using pydot to print out a PNG file to stdout using Python.

NOTE:  It should display a diagram of Gate One's architecture.
"""

import pydot
graph = pydot.Dot(graph_type='digraph', bgcolor="transparent", rankdir='TB')
cluster1 = pydot.Cluster('standalone', label='Single Gate One Server', style="filled", fillcolor="#304568", fontcolor="white")
cluster2 = pydot.Cluster('perserver', label='Alternate: Gate One On Each Host', style="filled", fillcolor="#304568", fontcolor="white")
gateone = pydot.Node("Gate One", style="filled", fillcolor="#222222", fontcolor="white")
server1 = pydot.Node("Server1", style="filled", fillcolor="white", shape='rectangle')
server2 = pydot.Node("Server2", style="filled", fillcolor="white", shape='rectangle')
serverX = pydot.Node("ServerX", style="filled", fillcolor="white", shape='rectangle')
browsers = pydot.Node("Web Browser", style="filled", fillcolor="#F4FFCC", fontcolor="black")
cluster1.add_node(gateone)
cluster1.add_node(server1)
cluster1.add_node(server2)
cluster1.add_node(serverX)
cluster1.add_node(browsers)
graph.add_subgraph(cluster1)
graph.add_edge(pydot.Edge(gateone, server1, label='SSH', fontcolor='green', fontname='Ubuntu', color='green'))
graph.add_edge(pydot.Edge(gateone, server2, label='SSH', fontcolor='green', fontname='Ubuntu', color='green'))
graph.add_edge(pydot.Edge(gateone, serverX, label='Telnet', fontcolor='red', fontname='Ubuntu', color='red'))
graph.add_edge(pydot.Edge(gateone, browsers, label='HTTPS', fontcolor='#76ABFF', fontname='Ubuntu', color='#76ABFF'))
graph.add_edge(pydot.Edge(browsers, gateone, color='#76ABFF'))
gateone1 = pydot.Node("Gate One on Server1\n/bin/login", style="filled", fillcolor="#999999", fontcolor="black", shape='rectangle')
gateone2 = pydot.Node("Gate One on Server2\n/usr/bin/custom.sh", style="filled", fillcolor="#999999", fontcolor="black", shape='rectangle')
gateone3 = pydot.Node("Gate One on ServerX\n/opt/legacy/app", style="filled", fillcolor="#999999", fontcolor="black", shape='rectangle')
cluster2.add_node(gateone1)
cluster2.add_node(gateone2)
cluster2.add_node(gateone3)
graph.add_subgraph(cluster2)
graph.add_edge(pydot.Edge(gateone1, browsers, label='HTTPS', fontcolor='#76ABFF', fontname='Ubuntu', color='#76ABFF'))
graph.add_edge(pydot.Edge(browsers, gateone1, color='#76ABFF'))
graph.add_edge(pydot.Edge(gateone2, browsers, label='HTTPS', fontcolor='#76ABFF', fontname='Ubuntu', color='#76ABFF'))
graph.add_edge(pydot.Edge(browsers, gateone2, color='#76ABFF'))
graph.add_edge(pydot.Edge(gateone3, browsers, label='HTTPS', fontcolor='#76ABFF', fontname='Ubuntu', color='#76ABFF'))
graph.add_edge(pydot.Edge(browsers, gateone3, color='#76ABFF'))

print(graph.create_png('png'))
# This works too if your platform has /proc:
# graph.write_png('/proc/self/fd/0') # Write to stdout
########NEW FILE########
__FILENAME__ = test_terminal
#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
#       Copyright 2011 Liftoff Software Corporation
#

# Meta
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'

"""
Tests the terminal module.  This whole thing is a huge TODO.
"""

# Import Python built-ins
import os, sys, unittest, time
from pprint import pprint
cwd = os.getcwd()
terminal_dir = os.path.abspath(os.path.join(cwd, '../'))
sys.path.append(terminal_dir)
import terminal

# Globals
ROWS = 56
COLS = 210

# Unit Tests
class Test1Coding(unittest.TestCase):
    """
    Tests for various coding issues/errors in the terminal module.
    """
    def test_1_parsing_performance(self):
        "\033[1mRunning Performance Test 1\033[0;0m"
        term = terminal.Terminal(ROWS, COLS)
        start = time.time()
        for i, x in enumerate(xrange(4)):
            with open('saved_stream.txt') as stream:
                for char in stream.read():
                    term.write(char)
            print(i)
        end = time.time()
        elapsed = end - start
        print('It took %0.2fms to process the input' % (elapsed*1000.0))
        pprint(term.dump_html())

    #def test_2_parsing_performance(self):
        #"\033[1mRunning Performance Test 2\033[0;0m"
        #term = terminal.Terminal(ROWS, COLS)
        #start = time.time()
        #with open('saved_stream.txt') as stream:
            #for i, x in enumerate(xrange(5)):
                #term.write(stream.read())
                #stream.seek(0)
                #print(i)
        #end = time.time()
        #elapsed = end - start
        #print('It took %0.2fms to process the input' % (elapsed*1000.0))



if __name__ == "__main__":
    print("Date & Time:\t\t\t%s" % time.ctime())
    unittest.main()

########NEW FILE########
__FILENAME__ = test_term_renditions
#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
#       Copyright 2011 Liftoff Software Corporation
#
# For license information see LICENSE.txt

# Meta
__version__ = '0.9'
__license__ = "AGPLv3 or Proprietary (see LICENSE.txt)"
__version_info__ = (0, 9)
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'

__doc__ = """\
The Terminal Rendition Test Script
==================================
Outputs a number of tables representing each state that a character may have in
a VT-style terminal.

.. todo:: Attach a screenshot of what it should look like.
"""
from collections import OrderedDict

STYLE_NAMES = {
    1: '\x1b[1mESC[1m (Bold)      \x1b[0m',
    2: '\x1b[1mESC[2m (Dim)       \x1b[0m',
    3: '\x1b[1mESC[3m (Italic)    \x1b[0m',
    4: '\x1b[1mESC[4m (Underline) \x1b[0m',
    5: '\x1b[1mESC[5m (Blink)     \x1b[0m',
    6: '\x1b[1mESC[6m (Fast Blink)\x1b[0m',
    7: '\x1b[1mESC[7m (Reverse)   \x1b[0m',
    8: '\x1b[1mESC[8m (Hidden)    \x1b[0m',
    9: '\x1b[1mESC[9m (Strike)    \x1b[0m',
}
FANCY_STYLE_NAMES = {
    51: '\x1b[1mESC[51m (Frame)      \x1b[0m',
    52: '\x1b[1mESC[52m (Encircle)   \x1b[0m',
    53: '\x1b[1mESC[53m (Overline)   \x1b[0m',
    60: '\x1b[1mESC[60m (RightLine)  \x1b[0m',
    61: '\x1b[1mESC[61m (Right2xLine)\x1b[0m',
    62: '\x1b[1mESC[61m (LeftLine)   \x1b[0m',
    63: '\x1b[1mESC[63m (Left2xLine) \x1b[0m',
}
FOREGROUND_NAMES = {
    30: 'Black  ',
    31: 'Red    ',
    32: 'Green  ',
    33: 'Yellow ',
    34: 'Blue   ',
    35: 'Magenta',
    36: 'Cyan   ',
    37: 'White  '
}
BACKGROUND_NAMES = {
    40: 'Black  ',
    41: 'Red    ',
    42: 'Green  ',
    43: 'Yellow ',
    44: 'Blue   ',
    45: 'Magenta',
    46: 'Cyan   ',
    47: 'White  '
}
BRIGHT_FOREGROUND_NAMES = {
    90: 'Black  ',
    91: 'Red    ',
    92: 'Green  ',
    93: 'Yellow ',
    94: 'Blue   ',
    95: 'Magenta',
    96: 'Cyan   ',
    97: 'White  '
}
BRIGHT_BACKGROUND_NAMES = {
    100: 'Black  ',
    101: 'Red    ',
    102: 'Green  ',
    103: 'Yellow ',
    104: 'Blue   ',
    105: 'Magenta',
    106: 'Cyan   ',
    107: 'White  '
}

def foregrounds_str():
    """
    Returns all the foreground colors (as a string) in their actual color:
        'Black Red Green Yellow Blue Magenta Cyan White'
    """
    out = ""
    foregrounds = ["\x1b[%sm" % (f+30) for f in xrange(8)]
    for i, foreground in enumerate(foregrounds):
        out += "%s%s\x1b[0m " % (foreground, FOREGROUND_NAMES[i+30])
    return out.rstrip() # Remove trailing whitespace

def backgrounds_str():
    """
    Returns all the background colors (as a string) in their actual color:
        'Black Red Green Yellow Blue Magenta Cyan White'
    """
    out = ""
    backgrounds = ["\x1b[%sm" % (f+40) for f in xrange(8)]
    for i, background in enumerate(backgrounds):
        out += "%s%s\x1b[0m " % (background, BACKGROUND_NAMES[i+40])
    return out.rstrip() # Remove trailing whitespace

def color_combos_8():
    """
    Prints out a table of all the 8-color background/foreground combinations:

        * Plain (no bold, italic, etc)
        * Bold
        * Dim
        * Italic
        * Underline
        * Blink
        * Fast blink
        * Reverse (aka "Inverse Video")
        * Hidden
        * Strikethrough
    """
    out = "ALL STYLES (0-9) + 8-COLOR FOREGROUNDS (30-37) AND BACKGROUNDS (40-47)\n"
    foregrounds = ["\x1b[%sm" % (f+30) for f in xrange(8)]
    backgrounds = ["\x1b[%sm" % (f+40) for f in xrange(8)]
    styles = ["\x1b[%sm" % f for f in xrange(1, 10)]
    out += "%s\n" % ("" * 56)
    out += "\x1b[1mESC[0m (Plain)     \x1b[0m"
    for i, foreground in enumerate(foregrounds):
        out += "%s%s\x1b[0m" % (foreground, FOREGROUND_NAMES[i+30])
    out += "\n"
    for i, background in enumerate(backgrounds):
        out += "Background: %s\x1b[0m" % (BACKGROUND_NAMES[i+40])
        for i, foreground in enumerate(foregrounds):
            out += "%s%s%s\x1b[0m" % (background, foreground, FOREGROUND_NAMES[i+30])
        out += "\n"
    for i, style in enumerate(styles, 1):
        out += "%s" % STYLE_NAMES[i]
        for i, foreground in enumerate(foregrounds):
            out += "%s%s%s\x1b[0m" % (style, foreground, FOREGROUND_NAMES[i+30])
        out += "\n"
        for i, background in enumerate(backgrounds):
            out += "Background: %s\x1b[0m" % (BACKGROUND_NAMES[i+40])
            for i, foreground in enumerate(foregrounds):
                out += "%s%s%s%s\x1b[0m" % (style, background, foreground, FOREGROUND_NAMES[i+30])
            out += "\n"
    out += "%s\n" % ("" * 56)
    return out

def color_combos_16():
    """
    Prints out a table of all the bright (16-color) background/foreground
    combinations:

        * Plain (no bold, italic, etc)
        * Bold
        * Dim
        * Italic
        * Underline
        * Blink
        * Fast blink
        * Reverse (aka "Inverse Video")
        * Hidden
        * Strikethrough
    """
    out = "ALL STYLES (0-9) + BRIGHT FOREGROUNDS (90-97) AND BRIGHT BACKGROUNDS (100-107)\n"
    foregrounds = ["\x1b[%sm" % (f+90) for f in xrange(8)]
    backgrounds = ["\x1b[%sm" % (f+100) for f in xrange(8)]
    styles = ["\x1b[%sm" % f for f in xrange(1, 10)]
    out += "%s\n" % ("" * 56)
    out += "\x1b[1mESC[0m (Plain)     \x1b[0m"
    for i, foreground in enumerate(foregrounds):
        out += "%s%s\x1b[0m" % (foreground, BRIGHT_FOREGROUND_NAMES[i+90])
    out += "\n"
    for i, background in enumerate(backgrounds):
        out += "Background: %s\x1b[0m" % (BRIGHT_BACKGROUND_NAMES[i+100])
        for i, foreground in enumerate(foregrounds):
            out += "%s%s%s\x1b[0m" % (background, foreground, BRIGHT_FOREGROUND_NAMES[i+90])
        out += "\n"
    for i, style in enumerate(styles, 1):
        out += "%s" % STYLE_NAMES[i]
        for i, foreground in enumerate(foregrounds):
            out += "%s%s%s\x1b[0m" % (style, foreground, BRIGHT_FOREGROUND_NAMES[i+90])
        out += "\n"
        for i, background in enumerate(backgrounds):
            out += "Background: %s\x1b[0m" % (BRIGHT_BACKGROUND_NAMES[i+100])
            for i, foreground in enumerate(foregrounds):
                out += "%s%s%s%s\x1b[0m" % (style, background, foreground, BRIGHT_FOREGROUND_NAMES[i+90])
            out += "\n"
    out += "%s\n" % ("" * 56)
    return out

def fancy_styles():
    """
    Prints out a table of all the fancy styles Gate One supports:

        * Frame
        * Encircle
        * Overline
        * Right Line
        * Right Double-line
        * Left Line
        * Left Double-line
    """
    out = "ALL FANCY STYLES (51-53, 60-63) + 8-COLOR FOREGROUNDS (30-37) AND BACKGROUNDS (40-47)\n"
    foregrounds = ["\x1b[%sm" % (f+30) for f in xrange(8)]
    backgrounds = ["\x1b[%sm" % (f+40) for f in xrange(8)]
    out += "%s\n" % ("" * 56)
    for num, name in FANCY_STYLE_NAMES.items():
        out += "%s" % name
        for i, foreground in enumerate(foregrounds):
            out += "\x1b[%sm%s%s\x1b[0m" % (num, foreground, FOREGROUND_NAMES[i+30])
        out += "\n"
        for i, background in enumerate(backgrounds):
            out += "Background: %s  \x1b[0m" % (BACKGROUND_NAMES[i+40])
            for i, foreground in enumerate(foregrounds):
                out += "\x1b[%sm%s%s%s\x1b[0m" % (num, background, foreground, FOREGROUND_NAMES[i+30])
            out += "\n"
    out += "%s\n" % ("" * 56)
    return out


# A HUGE thank you to Micah Elliott (http://MicahElliott.com) for posting these
# values here: https://gist.github.com/719710

colors_256 = {
    # 8-color equivalents:
     0: "000000",
     1: "800000",
     2: "008000",
     3: "808000",
     4: "000080",
     5: "800080",
     6: "008080",
     7: "c0c0c0",
    # "Bright" (16-color) equivalents:
     8: "808080",
     9: "ff0000",
    10: "00ff00",
    11: "ffff00",
    12: "0000ff",
    13: "ff00ff",
    14: "00ffff",
    15: "ffffff",
    # The rest of the 256-colors:
    16: "000000",
    17: "00005f",
    18: "000087",
    19: "0000af",
    20: "0000d7",
    21: "0000ff",
    22: "005f00",
    23: "005f5f",
    24: "005f87",
    25: "005faf",
    26: "005fd7",
    27: "005fff",
    28: "008700",
    29: "00875f",
    30: "008787",
    31: "0087af",
    32: "0087d7",
    33: "0087ff",
    34: "00af00",
    35: "00af5f",
    36: "00af87",
    37: "00afaf",
    38: "00afd7",
    39: "00afff",
    40: "00d700",
    41: "00d75f",
    42: "00d787",
    43: "00d7af",
    44: "00d7d7",
    45: "00d7ff",
    46: "00ff00",
    47: "00ff5f",
    48: "00ff87",
    49: "00ffaf",
    50: "00ffd7",
    51: "00ffff",
    52: "5f0000",
    53: "5f005f",
    54: "5f0087",
    55: "5f00af",
    56: "5f00d7",
    57: "5f00ff",
    58: "5f5f00",
    59: "5f5f5f",
    60: "5f5f87",
    61: "5f5faf",
    62: "5f5fd7",
    63: "5f5fff",
    64: "5f8700",
    65: "5f875f",
    66: "5f8787",
    67: "5f87af",
    68: "5f87d7",
    69: "5f87ff",
    70: "5faf00",
    71: "5faf5f",
    72: "5faf87",
    73: "5fafaf",
    74: "5fafd7",
    75: "5fafff",
    76: "5fd700",
    77: "5fd75f",
    78: "5fd787",
    79: "5fd7af",
    80: "5fd7d7",
    81: "5fd7ff",
    82: "5fff00",
    83: "5fff5f",
    84: "5fff87",
    85: "5fffaf",
    86: "5fffd7",
    87: "5fffff",
    88: "870000",
    89: "87005f",
    90: "870087",
    91: "8700af",
    92: "8700d7",
    93: "8700ff",
    94: "875f00",
    95: "875f5f",
    96: "875f87",
    97: "875faf",
    98: "875fd7",
    99: "875fff",
    100: "878700",
    101: "87875f",
    102: "878787",
    103: "8787af",
    104: "8787d7",
    105: "8787ff",
    106: "87af00",
    107: "87af5f",
    108: "87af87",
    109: "87afaf",
    110: "87afd7",
    111: "87afff",
    112: "87d700",
    113: "87d75f",
    114: "87d787",
    115: "87d7af",
    116: "87d7d7",
    117: "87d7ff",
    118: "87ff00",
    119: "87ff5f",
    120: "87ff87",
    121: "87ffaf",
    122: "87ffd7",
    123: "87ffff",
    124: "af0000",
    125: "af005f",
    126: "af0087",
    127: "af00af",
    128: "af00d7",
    129: "af00ff",
    130: "af5f00",
    131: "af5f5f",
    132: "af5f87",
    133: "af5faf",
    134: "af5fd7",
    135: "af5fff",
    136: "af8700",
    137: "af875f",
    138: "af8787",
    139: "af87af",
    140: "af87d7",
    141: "af87ff",
    142: "afaf00",
    143: "afaf5f",
    144: "afaf87",
    145: "afafaf",
    146: "afafd7",
    147: "afafff",
    148: "afd700",
    149: "afd75f",
    150: "afd787",
    151: "afd7af",
    152: "afd7d7",
    153: "afd7ff",
    154: "afff00",
    155: "afff5f",
    156: "afff87",
    157: "afffaf",
    158: "afffd7",
    159: "afffff",
    160: "d70000",
    161: "d7005f",
    162: "d70087",
    163: "d700af",
    164: "d700d7",
    165: "d700ff",
    166: "d75f00",
    167: "d75f5f",
    168: "d75f87",
    169: "d75faf",
    170: "d75fd7",
    171: "d75fff",
    172: "d78700",
    173: "d7875f",
    174: "d78787",
    175: "d787af",
    176: "d787d7",
    177: "d787ff",
    178: "d7af00",
    179: "d7af5f",
    180: "d7af87",
    181: "d7afaf",
    182: "d7afd7",
    183: "d7afff",
    184: "d7d700",
    185: "d7d75f",
    186: "d7d787",
    187: "d7d7af",
    188: "d7d7d7",
    189: "d7d7ff",
    190: "d7ff00",
    191: "d7ff5f",
    192: "d7ff87",
    193: "d7ffaf",
    194: "d7ffd7",
    195: "d7ffff",
    196: "ff0000",
    197: "ff005f",
    198: "ff0087",
    199: "ff00af",
    200: "ff00d7",
    201: "ff00ff",
    202: "ff5f00",
    203: "ff5f5f",
    204: "ff5f87",
    205: "ff5faf",
    206: "ff5fd7",
    207: "ff5fff",
    208: "ff8700",
    209: "ff875f",
    210: "ff8787",
    211: "ff87af",
    212: "ff87d7",
    213: "ff87ff",
    214: "ffaf00",
    215: "ffaf5f",
    216: "ffaf87",
    217: "ffafaf",
    218: "ffafd7",
    219: "ffafff",
    220: "ffd700",
    221: "ffd75f",
    222: "ffd787",
    223: "ffd7af",
    224: "ffd7d7",
    225: "ffd7ff",
    226: "ffff00",
    227: "ffff5f",
    228: "ffff87",
    229: "ffffaf",
    230: "ffffd7",
    231: "ffffff",
    # Grayscale:
    232: "080808",
    233: "121212",
    234: "1c1c1c",
    235: "262626",
    236: "303030",
    237: "3a3a3a",
    238: "444444",
    239: "4e4e4e",
    240: "585858",
    241: "626262",
    242: "6c6c6c",
    243: "767676",
    244: "808080",
    245: "8a8a8a",
    246: "949494",
    247: "9e9e9e",
    248: "a8a8a8",
    249: "b2b2b2",
    250: "bcbcbc",
    251: "c6c6c6",
    252: "d0d0d0",
    253: "dadada",
    254: "e4e4e4",
    255: "eeeeee"
}

def color_combos_256():
    """
    Prints out a table of all the 256-color background/foreground combinations:

        * Plain (no bold, italic, etc)
        * Bold
        * Dim
        * Italic
        * Underline
        * Blink
        * Fast blink
        * Reverse (aka "Inverse Video")
        * Hidden
        * Strikethrough
    """
    out = "ALL STYLES (0-9) + XTERM'S 256 COLORS (LOTS TO SHOW SO SLIGHTLY MESSY)\n"
    colors = [c for c in colors_256.keys()]
    bg_colors_seq = ["\x1b[48;5;%sm" % c for c in colors_256.keys()]
    fg_colors_seq = ["\x1b[38;5;%sm" % c for c in colors_256.keys()]
    colors.sort() # Put them in order
    styles = ["\x1b[%sm" % f for f in xrange(1, 10)]
    for i, style in enumerate(styles, 1):
        out += "%s" % STYLE_NAMES[i]
        for n, color in enumerate(colors):
            out += "%s%s%s\x1b[0m" % (style, bg_colors_seq[color], colors_256[n])
        out += "\n"
    for i, style in enumerate(styles, 1):
        out += "%s" % STYLE_NAMES[i]
        for n, color in enumerate(colors):
            out += "%s%s%s\x1b[0m" % (style, fg_colors_seq[color], colors_256[n])
        out += "\n"
    out += "\n"
    return out

if __name__ == "__main__":
    from time import sleep
    print("WARNING!  THIS CAN TAX EVEN A POWERFUL MACHINE!")
    print("EVEN THE BEST OF BROWSERS CRAWL WITH THIS MANY LITTLE DETAILS!")
    print("IF YOUR SYSTEM BECOMES UNRESPONSIVE TRY CLOSING THIS TERMINAL")
    print("...starting test in 5 seconds...")
    sleep(5)
    for line in color_combos_8().split('\n'):
        print(line)
        sleep(0.15)
    for line in color_combos_16().split('\n'):
        print(line)
        sleep(0.15)
    for line in fancy_styles().split('\n'):
        print(line)
        sleep(0.15)
    print(color_combos_256())
########NEW FILE########
__FILENAME__ = onoff
#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
#       Copyright 2011 Liftoff Software Corporation
#
# For license information see LICENSE.txt

# Meta
__version__ = '1.0.1'
__version_info__ = (1, 0, 1)
__license__ = "Apache 2.0 (see LICENSE.txt)"
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'


import sys, logging

if bytes != str: # Python 3
    unicode = str # Necessary for a type check below

class OnOffMixin(object):
    """
    A mixin to add :func:`on`, :func:`off`, and :func:`trigger` event handling
    methods to any class.

    For an example, let's pretend we've got a basic WebSocket server that can
    perform a number of functions based on the incoming message::

        class ActionWebSocket(WebSocketHandler):
            def open(self):
                print("WebSocket opened")

            def on_message(self, message):
                if message == 'hello':
                    self.hello()
                elif message == 'ping':
                    self.pong()

            def on_close(self):
                print("WebSocket closed")

            def pong(self, timestamp):
                self.write_message('pong')

            def hello(self):
                self.write_message('Hey there!')

    This works OK for the most simple of stuff.  We could use string parsing of
    various sorts (startswith(), json, etc) to differentiate messages from each
    other but our conditionals will quickly grow into a giant mess.

    Here's a better way::

        class ActionWebSocket(WebSocketHandler, OnOffMixin):
            "Calls an appropriate 'action' based on the incoming message."
            def __init__(self): # Ignoring parent __init__() for ths example
                self.on("ping", self.pong)
                self.on("hello", self.heythere)

            def open(self):
                print("WebSocket opened")

            def on_message(self, message):
                # Assume a json-encoded dict like {"ping": null}
                message_obj = json.loads(message)
                for key, value in message_obj.items():
                    self.trigger(key, value)

            def on_close(self):
                print("WebSocket closed")

            def pong(self, timestamp):
                self.write_message('pong')

            def heythere(self):
                self.write_message('Hey there!')

    In the above example we used the `OnOffMixin` to add :func:`on`,
    :func:`off`, and :func:`trigger` methods to our `ActionWebSocket` class.
    """
    def on(self, events, callback, times=None):
        """
        Registers the given *callback* with the given *events* (string or list
        of strings) that will get called whenever the given *event* is triggered
        (using :meth:`self.trigger`).

        If *times* is given the *callback* will only be fired that many times
        before it is automatically removed from :attr:`self._on_off_events`.
        """
        # Make sure our _on_off_events dict is present (if first invokation)
        if not hasattr(self, '_on_off_events'):
            self._on_off_events = {}
        if isinstance(events, (str, unicode)):
            events = [events]
        callback_obj = {
            'callback': callback,
            'times': times,
            'calls': 0
        }
        for event in events:
            if event not in self._on_off_events:
                self._on_off_events.update({event: [callback_obj.copy()]})
            else:
                self._on_off_events[event].append(callback_obj.copy())

    def off(self, events, callback):
        """
        Removes the given *callback* from the given *events* (string or list of
        strings).
        """
        if isinstance(events, (str, unicode)):
            events = [events]
        for event in events:
            for callback_obj in self._on_off_events[event]:
                if callback_obj['callback'] == callback:
                    try:
                        del self._on_off_events[event]
                    except KeyError:
                        pass # Nothing to do

    def once(self, events, callback):
        """
        A shortcut for `self.on(events, callback, 1)`
        """
        self.on(events, callback, 1)

    def trigger(self, events, *args, **kwargs):
        """
        Fires the given *events* (string or list of strings).  All callbacks
        associated with these *events* will be called and if their respective
        objects have a *times* value set it will be used to determine when to
        remove the associated callback from the event.

        If given, callbacks associated with the given *events* will be called
        with *args* and *kwargs*.
        """
        # Make sure our _on_off_events dict is present (if first invokation)
        if not hasattr(self, '_on_off_events'):
            self._on_off_events = {}
        if not hasattr(self, 'exc_info'):
            self.exc_info = None
        logging.debug(
            "OnOffMixin.triggering event(s): %s (args: %s, kwargs: %s)"
            % (events, args, kwargs))
        if isinstance(events, (str, unicode)):
            events = [events]
        for event in events:
            if event in self._on_off_events:
                for callback_obj in self._on_off_events[event]:
                    try:
                        callback_obj['callback'](*args, **kwargs)
                    except TypeError as e:
                        self.exc_info = sys.exc_info() # Save it just in case
                        if hasattr(callback_obj['callback'], '__name__'):
                            logging.warning(
                                "trigger() failed trying to call %s.  "
                                "Attempting to call with automatic 'self' "
                                "applied..." %
                                callback_obj['callback'].__name__)
                        try:
                            callback_obj['callback'](self, *args, **kwargs)
                            logging.warning(
                                "You probably want to update your code to bind "
                                "'self' to that function using "
                                "functools.partial()")
                        except TypeError as ee:
                            # The callback in question had its own TypeError
                            # Pass it on...
                            raise self.exc_info[1], None, self.exc_info[2]
                    callback_obj['calls'] += 1
                    if callback_obj['calls'] == callback_obj['times']:
                        self.off(event, callback_obj['callback'])

########NEW FILE########
__FILENAME__ = run_gateone
#!/usr/bin/python

"""
This script is meant for users that wish to run Gate One out of this (GateOne)
directory (as opposed to running setup.py).  If you plan to (or already ran)
setup.py please use the 'gateone' script which gets installed in your $PATH
automatically.
"""

import os, sys

WORKING_DIR = os.path.dirname(os.path.abspath(__file__))

# Insert the path to this script's directory so that the Python interpreter can
# import gateone, termio, terminal, and onoff:
sys.path.insert(0, WORKING_DIR)

from gateone.core.server import main

main(installed=False)

########NEW FILE########
__FILENAME__ = terminal
# -*- coding: utf-8 -*-
#
#       Copyright 2011 Liftoff Software Corporation
#

# Meta
__version__ = '1.1'
__version_info__ = (1, 1)
__license__ = "AGPLv3 or Proprietary (see LICENSE.txt)"
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'

__doc__ = """\
About This Module
=================
This crux of this module is the Terminal class which is a pure-Python
implementation of the quintessential Unix terminal emulator.  It does its best
to emulate an xterm and along with that comes support for the majority of the
relevant portions of ECMA-48.  This includes support for emulating varous VT-*
terminal types as well as the "linux" terminal type.

The Terminal class's VT-* emulation support is not complete but it should
suffice for most terminal emulation needs (e.g. all your typical command line
programs should work wonderfully).  If something doesn't look quite right or you
need support for certain modes added please feel free to open a ticket on Gate
One's issue tracker:  https://github.com/liftoff/GateOne/issues

Note that Terminal was written from scratch in order to be as fast as possible.
It is extensively commented and implements some interesting patterns in order to
maximize execution speed (most notably for things that loop).  Some bits of code
may seem "un-Pythonic" and/or difficult to grok but understand that this is
probably due to optimizations.  If you know "a better way" please feel free to
submit a patch, open a ticket, or send us an email.  There's a reason why open
source software is a superior development model!

Supported Emulation Types
-------------------------
Without any special mode settings or parameters Terminal should effectively
emulate the following terminal types:

 * xterm (the most important one)
 * ECMA-48/ANSI X3.64
 * Nearly all the VT-* types:  VT-52, VT-100, VT-220, VT-320, VT-420, and VT-520
 * Linux console ("linux")

If you want Terminal to support something else or it's missing a feature from
any given terminal type please `let us know <https://github.com/liftoff/GateOne/issues/new>`_.
We'll implement it!

What Terminal Doesn't Do
------------------------
The Terminal class is meant to emulate the display portion of a given terminal.
It does not translate keystrokes into escape sequences or special control
codes--you'll have to take care of that in your application (or at the
client-side like Gate One).  It does, however, keep track of many
keystroke-specific modes of operation such as Application Cursor Keys and the G0
and G1 charset modes *with* callbacks that can be used to notify your
application when such things change.

Special Considerations
----------------------
Many methods inside Terminal start with an underscore.  This was done to
indicate that such methods shouldn't be called directly (from a program that
imported the module).  If it was thought that a situation might arise where a
method could be used externally by a controlling program, the underscore was
omitted.

Asynchronous Use
----------------
To support asynchronous usage (and make everything faster), Terminal was written
to support extensive callbacks that are called when certain events are
encountered.  Here are the events and their callbacks:

.. _callback_constants:

====================================    ================================================================================
Callback Constant (ID)                  Called when...
====================================    ================================================================================
:attr:`terminal.CALLBACK_SCROLL_UP`     The terminal is scrolled up (back).
:attr:`terminal.CALLBACK_CHANGED`       The screen is changed/updated.
:attr:`terminal.CALLBACK_CURSOR_POS`    The cursor position changes.
:attr:`terminal.CALLBACK_DSR`           A Device Status Report (DSR) is requested (via the DSR escape sequence).
:attr:`terminal.CALLBACK_TITLE`         The terminal title changes (xterm-style)
:attr:`terminal.CALLBACK_BELL`          The bell character (^G) is encountered.
:attr:`terminal.CALLBACK_OPT`           The special optional escape sequence is encountered.
:attr:`terminal.CALLBACK_MODE`          The terminal mode setting changes (e.g. use alternate screen buffer).
:attr:`terminal.CALLBACK_MESSAGE`       The terminal needs to send the user a message (without messing with the screen).
====================================    ================================================================================

Note that CALLBACK_DSR is special in that it in most cases it will be called with arguments.  See the code for examples of how and when this happens.

Also, in most cases it is unwise to override CALLBACK_MODE since this method is primarily meant for internal use within the Terminal class.

Using Terminal
--------------
Gate One makes extensive use of the Terminal class and its callbacks.  So that's
a great place to look for specific examples (gateone.py and termio.py,
specifically).  Having said that, implementing Terminal is pretty
straightforward::

    >>> import terminal
    >>> term = terminal.Terminal(24, 80)
    >>> term.write("This text will be written to the terminal screen.")
    >>> term.dump()
    [u'This text will be written to the terminal screen.                               ',
    <snip>
    u'                                                                                ']

Here's an example with some basic callbacks:

    >>> def mycallback():
    ...     "This will be called whenever the screen changes."
    ...     print("Screen update! Perfect time to dump the terminal screen.")
    ...     print(term.dump()[0]) # Only need to see the top line for this demo =)
    ...     print("Just dumped the screen.")
    >>> import terminal
    >>> term = terminal.Terminal(24, 80)
    >>> term.callbacks[term.CALLBACK_CHANGED] = mycallback
    >>> term.write("This should result in mycallback() being called")
    Screen update! Perfect time to dump the terminal screen.
    This should result in mycallback() being called
    Just dumped the screen.

.. note:: In testing Gate One it was determined that it is faster to perform the conversion of a terminal screen to HTML on the server side than it is on the client side (via JavaScript anyway).

About The Scrollback Bufffer
----------------------------
The Terminal class implements a scrollback buffer.  Here's how it works:
Whenever a :meth:`Terminal.scroll_up` event occurs, the line (or lines) that
will be removed from the top of the screen will be placed into
:attr:`Terminal.scrollback_buf`. Then whenever :meth:`Terminal.dump_html` is
called the scrollback buffer will be returned along with the screen output and
reset to an empty state.

Why do this?  In the event that a very large :meth:`Terminal.write` occurs (e.g.
'ps aux'), it gives the controlling program the ability to capture what went
past the screen without some fancy tracking logic surrounding
:meth:`Terminal.write`.

More information about how this works can be had by looking at the
:meth:`Terminal.dump_html` function itself.

.. note:: There's more than one function that empties :attr:`Terminal.scrollback_buf` when called.  You'll just have to have a look around =)

Class Docstrings
================
"""

# Import stdlib stuff
import os, sys, re, logging, base64, codecs, unicodedata, tempfile, struct
from io import BytesIO
from array import array
from datetime import datetime, timedelta
from functools import partial
from collections import defaultdict
try:
    from collections import OrderedDict
except ImportError: # Python <2.7 didn't have OrderedDict in collections
    try:
        from ordereddict import OrderedDict
    except ImportError:
        logging.error(
            "Error: Could not import OrderedDict.  Please install it:")
        logging.error("\tsudo pip install ordereddict")
        logging.error(
            "...or download it from http://pypi.python.org/pypi/ordereddict")
        sys.exit(1)
from itertools import imap, izip

# Inernationalization support
_ = str # So pyflakes doesn't complain
import gettext
gettext.install('terminal')

# Globals
_logged_pil_warning = False # Used so we don't spam the user with warnings
_logged_mutagen_warning = False # Ditto
CALLBACK_SCROLL_UP = 1    # Called after a scroll up event (new line)
CALLBACK_CHANGED = 2      # Called after the screen is updated
CALLBACK_CURSOR_POS = 3   # Called after the cursor position is updated
# <waives hand in air> You are not concerned with the number 4
CALLBACK_DSR = 5          # Called when a DSR requires a response
# NOTE: CALLBACK_DSR must accept 'response' as either the first argument or
#       as a keyword argument.
CALLBACK_TITLE = 6        # Called when the terminal sets the window title
CALLBACK_BELL = 7         # Called after ASCII_BEL is encountered.
CALLBACK_OPT = 8 # Called when we encounter the optional ESC sequence
# NOTE: CALLBACK_OPT must accept 'chars' as either the first argument or as
#       a keyword argument.
CALLBACK_MODE = 9 # Called when the terminal mode changes (e.g. DECCKM)
CALLBACK_RESET = 10 # Called when a terminal reset (^[[!p) is encountered
CALLBACK_LEDS = 11 # Called when the state of the LEDs changes
# Called when the terminal emulator encounters a situation where it wants to
# tell the user about something (say, an error decoding an image) without
# interfering with the terminal's screen.
CALLBACK_MESSAGE = 12

# These are for HTML output:
RENDITION_CLASSES = defaultdict(lambda: None, {
    0: 'reset', # Special: Return everything to defaults
    1: 'bold',
    2: 'dim',
    3: 'italic',
    4: 'underline',
    5: 'blink',
    6: 'fastblink',
    7: 'reverse',
    8: 'hidden',
    9: 'strike',
    10: 'fontreset', # NOTE: The font renditions don't do anything right now
    11: 'font11', # Mostly because I have no idea what they are supposed to look
    12: 'font12', # like.
    13: 'font13',
    14: 'font14',
    15: 'font15',
    16: 'font16',
    17: 'font17',
    18: 'font18',
    19: 'font19',
    20: 'fraktur',
    21: 'boldreset',
    22: 'dimreset',
    23: 'italicreset',
    24: 'underlinereset',
    27: 'reversereset',
    28: 'hiddenreset',
    29: 'strikereset',
    # Foregrounds
    30: 'f0', # Black
    31: 'f1', # Red
    32: 'f2', # Green
    33: 'f3', # Yellow
    34: 'f4', # Blue
    35: 'f5', # Magenta
    36: 'f6', # Cyan
    37: 'f7', # White
    38: '', # 256-color support uses this like so: \x1b[38;5;<color num>sm
    39: 'foregroundreset', # Special: Set FG to default
    # Backgrounds
    40: 'b0', # Black
    41: 'b1', # Red
    42: 'b2', # Green
    43: 'b3', # Yellow
    44: 'b4', # Blue
    45: 'b5', # Magenta
    46: 'b6', # Cyan
    47: 'b7', # White
    48: '', # 256-color support uses this like so: \x1b[48;5;<color num>sm
    49: 'backgroundreset', # Special: Set BG to default
    51: 'frame',
    52: 'encircle',
    53: 'overline',
    60: 'rightline',
    61: 'rightdoubleline',
    62: 'leftline',
    63: 'leftdoubleline',
    # aixterm colors (aka '16 color support').  They're supposed to be 'bright'
    # versions of the first 8 colors (hence the 'b').
    # 'Bright' Foregrounds
    90: 'bf0', # Bright black (whatever that is =)
    91: 'bf1', # Bright red
    92: 'bf2', # Bright green
    93: 'bf3', # Bright yellow
    94: 'bf4', # Bright blue
    95: 'bf5', # Bright magenta
    96: 'bf6', # Bright cyan
    97: 'bf7', # Bright white
# TODO:  Handle the ESC sequence that sets the colors from 90-87 (e.g. ESC]91;orange/brown^G)
    # 'Bright' Backgrounds
    100: 'bb0', # Bright black
    101: 'bb1', # Bright red
    102: 'bb2', # Bright green
    103: 'bb3', # Bright yellow
    104: 'bb4', # Bright blue
    105: 'bb5', # Bright magenta
    106: 'bb6', # Bright cyan
    107: 'bb7' # Bright white
})
# Generate the dict of 256-color (xterm) foregrounds and backgrounds
for i in xrange(256):
    RENDITION_CLASSES[(i+1000)] = "fx%s" % i
    RENDITION_CLASSES[(i+10000)] = "bx%s" % i
del i # Cleanup

RESET_CLASSES = set([
    'backgroundreset',
    'boldreset',
    'dimreset',
    'italicreset',
    'underlinereset',
    'reversereset',
    'hiddenreset',
    'strikereset',
    'resetfont'
])

try:
    unichr(0x10000) # Will throw a ValueError on narrow Python builds
    SPECIAL = 1048576 # U+100000 or unichr(SPECIAL) (start of Plane 16)
except:
    SPECIAL = 63561

def handle_special(e):
    """
    Used in conjunction with :py:func:`codecs.register_error`, will replace
    special ascii characters such as 0xDA and 0xc4 (which are used by ncurses)
    with their Unicode equivalents.
    """
    # TODO: Get this using curses special characters when appropriate
    #curses_specials = {
        ## NOTE: When $TERM is set to "Linux" these end up getting used by things
        ##       like ncurses-based apps.  In other words, it makes a whole lot
        ##       of ugly look pretty again.
        #0xda: u'', # ACS_ULCORNER
        #0xc0: u'', # ACS_LLCORNER
        #0xbf: u'', # ACS_URCORNER
        #0xd9: u'', # ACS_LRCORNER
        #0xb4: u'', # ACS_RTEE
        #0xc3: u'', # ACS_LTEE
        #0xc1: u'', # ACS_BTEE
        #0xc2: u'', # ACS_TTEE
        #0xc4: u'', # ACS_HLINE
        #0xb3: u'', # ACS_VLINE
        #0xc5: u'', # ACS_PLUS
        #0x2d: u'', # ACS_S1
        #0x5f: u'', # ACS_S9
        #0x60: u'', # ACS_DIAMOND
        #0xb2: u'', # ACS_CKBOARD
        #0xf8: u'', # ACS_DEGREE
        #0xf1: u'', # ACS_PLMINUS
        #0xf9: u'', # ACS_BULLET
        #0x3c: u'', # ACS_LARROW
        #0x3e: u'', # ACS_RARROW
        #0x76: u'', # ACS_DARROW
        #0x5e: u'', # ACS_UARROW
        #0xb0: u'', # ACS_BOARD
        #0x0f: u'', # ACS_LANTERN
        #0xdb: u'', # ACS_BLOCK
    #}
    specials = {
# Note to self:  Why did I bother with these overly descriptive comments?  Ugh
# I've been staring at obscure symbols far too much lately _
        128: u'', # Euro sign
        129: u'', # Unknown (Using non-breaking spaces for all unknowns)
        130: u'', # Single low-9 quotation mark
        131: u'', # Latin small letter f with hook
        132: u'', # Double low-9 quotation mark
        133: u'', # Horizontal ellipsis
        134: u'', # Dagger
        135: u'', # Double dagger
        136: u'', # Modifier letter circumflex accent
        137: u'', # Per mille sign
        138: u'', # Latin capital letter S with caron
        139: u'', # Single left-pointing angle quotation
        140: u'', # Latin capital ligature OE
        141: u'', # Unknown
        142: u'', # Latin captial letter Z with caron
        143: u'', # Unknown
        144: u'', # Unknown
        145: u'', # Left single quotation mark
        146: u'', # Right single quotation mark
        147: u'', # Left double quotation mark
        148: u'', # Right double quotation mark
        149: u'', # Bullet
        150: u'', # En dash
        151: u'', # Em dash
        152: u'', # Small tilde
        153: u'', # Trade mark sign
        154: u'', # Latin small letter S with caron
        155: u'', #  Single right-pointing angle quotation mark
        156: u'', # Latin small ligature oe
        157: u'', # Upper-case slashed zero--using same as empty set (216)
        158: u'', # Latin small letter z with caron
        159: u'', # Latin capital letter Y with diaeresis
        160: u'', # Non-breaking space
        161: u'', # Inverted exclamation mark
        162: u'', # Cent sign
        163: u'', # Pound sign
        164: u'', # Currency sign
        165: u'', # Yen sign
        166: u'', # Pipe, Broken vertical bar
        167: u'', # Section sign
        168: u'', # Spacing diaeresis - umlaut
        169: u'', # Copyright sign
        170: u'', # Feminine ordinal indicator
        171: u'', # Left double angle quotes
        172: u'', # Not sign
        173: u"\u00AD", # Soft hyphen
        174: u'', # Registered trade mark sign
        175: u'', # Spacing macron - overline
        176: u'', # Degree sign
        177: u'', # Plus-or-minus sign
        178: u'', # Superscript two - squared
        179: u'', # Superscript three - cubed
        180: u'', # Acute accent - spacing acute
        181: u'', # Micro sign
        182: u'', # Pilcrow sign - paragraph sign
        183: u'', # Middle dot - Georgian comma
        184: u'', # Spacing cedilla
        185: u'', # Superscript one
        186: u'', # Masculine ordinal indicator
        187: u'', # Right double angle quotes
        188: u'', # Fraction one quarter
        189: u'', # Fraction one half
        190: u'', # Fraction three quarters
        191: u'', # Inverted question mark
        192: u'', # Latin capital letter A with grave
        193: u'', # Latin capital letter A with acute
        194: u'', # Latin capital letter A with circumflex
        195: u'', # Latin capital letter A with tilde
        196: u'', # Latin capital letter A with diaeresis
        197: u'', # Latin capital letter A with ring above
        198: u'', # Latin capital letter AE
        199: u'', # Latin capital letter C with cedilla
        200: u'', # Latin capital letter E with grave
        201: u'', # Latin capital letter E with acute
        202: u'', # Latin capital letter E with circumflex
        203: u'', # Latin capital letter E with diaeresis
        204: u'', # Latin capital letter I with grave
        205: u'', # Latin capital letter I with acute
        206: u'', # Latin capital letter I with circumflex
        207: u'', # Latin capital letter I with diaeresis
        208: u'', # Latin capital letter ETH
        209: u'', # Latin capital letter N with tilde
        210: u'', # Latin capital letter O with grave
        211: u'', # Latin capital letter O with acute
        212: u'', # Latin capital letter O with circumflex
        213: u'', # Latin capital letter O with tilde
        214: u'', # Latin capital letter O with diaeresis
        215: u'', # Multiplication sign
        216: u'', # Latin capital letter O with slash (aka "empty set")
        217: u'', # Latin capital letter U with grave
        218: u'', # Latin capital letter U with acute
        219: u'', # Latin capital letter U with circumflex
        220: u'', # Latin capital letter U with diaeresis
        221: u'', # Latin capital letter Y with acute
        222: u'', # Latin capital letter THORN
        223: u'', # Latin small letter sharp s - ess-zed
        224: u'', # Latin small letter a with grave
        225: u'', # Latin small letter a with acute
        226: u'', # Latin small letter a with circumflex
        227: u'', # Latin small letter a with tilde
        228: u'', # Latin small letter a with diaeresis
        229: u'', # Latin small letter a with ring above
        230: u'', # Latin small letter ae
        231: u'', # Latin small letter c with cedilla
        232: u'', # Latin small letter e with grave
        233: u'', # Latin small letter e with acute
        234: u'', # Latin small letter e with circumflex
        235: u'', # Latin small letter e with diaeresis
        236: u'', # Latin small letter i with grave
        237: u'', # Latin small letter i with acute
        238: u'', # Latin small letter i with circumflex
        239: u'', # Latin small letter i with diaeresis
        240: u'', # Latin small letter eth
        241: u'', # Latin small letter n with tilde
        242: u'', # Latin small letter o with grave
        243: u'', # Latin small letter o with acute
        244: u'', # Latin small letter o with circumflex
        245: u'', # Latin small letter o with tilde
        246: u'', # Latin small letter o with diaeresis
        247: u'', # Division sign
        248: u'', # Latin small letter o with slash
        249: u'', # Latin small letter u with grave
        250: u'', # Latin small letter u with acute
        251: u'', # Latin small letter u with circumflex
        252: u'', # Latin small letter u with diaeresis
        253: u'', # Latin small letter y with acute
        254: u'', # Latin small letter thorn
        255: u'', # Latin small letter y with diaeresis
    }
    # I left this in its odd state so I could differentiate between the two
    # in the future.
    chars = e.object
    if bytes == str: # Python 2
        # Convert e.object to a bytearray for an easy switch to integers.
        # It is quicker than calling ord(char) on each char in e.object
        chars = bytearray(e.object)
        # NOTE: In Python 3 when you iterate over bytes they appear as integers.
        #       So we don't need to convert to a bytearray in Python 3.
    if isinstance(e, (UnicodeEncodeError, UnicodeTranslateError)):
        s = [u'%s' % specials[c] for c in chars[e.start:e.end]]
        return ''.join(s), e.end
    else:
        s = [u'%s' % specials[c] for c in chars[e.start:e.end]]
        return ''.join(s), e.end
codecs.register_error('handle_special', handle_special)

# TODO List:
#
#   * We need unit tests!
#   * Add a function that can dump the screen with text renditions represented as their usual escape sequences so applications that try to perform screen-scraping can match things like '\x1b[41mAuthentication configuration' without having to find specific character positions and then examining the renditions on that line.

# Helper functions
def _reduce_renditions(renditions):
    """
    Takes a list, *renditions*, and reduces it to its logical equivalent (as
    far as renditions go).  Example::

        [0, 32, 0, 34, 0, 32]

    Would become::

        [0, 32]

    Other Examples::

        [0, 1, 36, 36]      ->  [0, 1, 36]
        [0, 30, 42, 30, 42] ->  [0, 30, 42]
        [36, 32, 44, 42]    ->  [32, 42]
        [36, 35]            ->  [35]
    """
    out_renditions = []
    foreground = None
    background = None
    for rend in renditions:
        if rend < 29:
            if rend not in out_renditions:
                out_renditions.append(rend)
        elif rend > 29 and rend < 40:
            # Regular 8-color foregrounds
            foreground = rend
        elif rend > 39 and rend < 50:
            # Regular 8-color backgrounds
            background = rend
        elif rend > 91 and rend < 98:
            # 'Bright' (16-color) foregrounds
            foreground = rend
        elif rend > 99 and rend < 108:
            # 'Bright' (16-color) backgrounds
            background = rend
        elif rend > 1000 and rend < 10000:
            # 256-color foregrounds
            foreground = rend
        elif rend > 10000 and rend < 20000:
            # 256-color backgrounds
            background = rend
        else:
            out_renditions.append(rend)
    if foreground:
        out_renditions.append(foreground)
    if background:
        out_renditions.append(background)
    return out_renditions

def unicode_counter():
    """
    A generator that returns incrementing Unicode characters that can be used as
    references inside a Unicode array.  For example::

        >>> counter = unicode_counter()
        >>> mapping_dict = {}
        >>> some_array = array('u')
        >>> # Pretend 'marker ...' below is a reference to something important
        >>> for i, c in enumerate(u'some string'):
        ...     if c == u' ': # Mark the location of spaces
        ...         # Perform some operation where we need to save a value
        ...         result = some_evaluation(i, c)
        ...         # Save some memory by storing a reference to result instead
        ...         # of the same result over and over again
        ...         if result not in mapping_dict.values():
        ...             marker = counter.next()
        ...             some_array.append(marker)
        ...             mapping_dict[marker] = result
        ...         else: # Find the existing reference so we can use it again
        ...             for k, v in mapping_dict.items():
        ...                 if v == result: # Use the existing value
        ...                     some_array.append(k)
        ...     else:
        ...         some_array.append('\x00') # \x00 == "not interesting" placeholder
        >>>

    Now we could iterate over 'some string' and some_array simultaneously using
    zip(u'some string', some_array) to access those reference markers when we
    encountered the correct position.  This can save a lot of memory if you need
    to store objects in memory that have a tendancy to repeat (e.g. text
    rendition lists in a terminal).

    .. note:: Meant to be used inside the renditions array to reference text rendition lists such as `[0, 1, 34]`.
    """
    n = 1000 # Start at 1000 so we can use lower characters for other things
    while True:
        yield unichr(n)
        if n == 65535: # The end of unicode in narrow builds of Python
            n = 0 # Reset
        else:
            n += 1

# NOTE:  Why use a unicode array() to store references instead of just a regular array()?  Two reasons:  1) Large namespace.  2) Only need to use one kind of array for everything (convenience).  It is also a large memory savings over "just using a list with references to items in a dict."
def pua_counter():
    """
    A generator that returns a Unicode Private Use Area (PUA) character starting
    at the beginning of Plane 16 (U+100000); counting up by one with each
    successive call.  If this is a narrow Python build the tail end of Plane 15
    will be used as a fallback (with a lot less characters).

    .. note:: Meant to be used as references to non-text objects in the screen array() (since it can only contain unicode characters)
    """
    if SPECIAL == 1048576: # Not a narrow build of Python
        n = SPECIAL # U+100000 or unichr(SPECIAL) (start of Plane 16)
        while True:
            yield unichr(n)
            if n == 1114111:
                n = SPECIAL # Reset--would be impressive to make it this far!
            else:
                n += 1
    else:
        # This Python build is 'narrow' so we have to settle for less
        # Hopefully no real-world terminal will actually want to use one of
        # these characters.  In my research I couldn't find a font that used
        # them.  Please correct me if I'm wrong!
        n = SPECIAL # u'\uf849'
        while True:
            yield unichr(n)
            if n == 63717: # The end of nothing-but-block-chars in Plane 15
                n = SPECIAL # Reset
            else:
                n += 1

def convert_to_timedelta(time_val):
    """
    Given a *time_val* (string) such as '5d', returns a `datetime.timedelta`
    object representing the given value (e.g. `timedelta(days=5)`).  Accepts the
    following '<num><char>' formats:

    =========   ============ =========================
    Character   Meaning      Example
    =========   ============ =========================
    (none)      Milliseconds '500' -> 500 Milliseconds
    s           Seconds      '60s' -> 60 Seconds
    m           Minutes      '5m'  -> 5 Minutes
    h           Hours        '24h' -> 24 Hours
    d           Days         '7d'  -> 7 Days
    M           Months       '2M'  -> 2 Months
    y           Years        '10y' -> 10 Years
    =========   ============ =========================

    Examples::

        >>> convert_to_timedelta('7d')
        datetime.timedelta(7)
        >>> convert_to_timedelta('24h')
        datetime.timedelta(1)
        >>> convert_to_timedelta('60m')
        datetime.timedelta(0, 3600)
        >>> convert_to_timedelta('120s')
        datetime.timedelta(0, 120)
    """
    try:
        num = int(time_val)
        return timedelta(milliseconds=num)
    except ValueError:
        pass
    num = int(time_val[:-1])
    if time_val.endswith('s'):
        return timedelta(seconds=num)
    elif time_val.endswith('m'):
        return timedelta(minutes=num)
    elif time_val.endswith('h'):
        return timedelta(hours=num)
    elif time_val.endswith('d'):
        return timedelta(days=num)
    elif time_val.endswith('M'):
        return timedelta(days=(num*30))  # Yeah this is approximate
    elif time_val.endswith('y'):
        return timedelta(days=(num*365)) # Sorry, no leap year support

def total_seconds(td):
    """
    Given a timedelta (*td*) return an integer representing the equivalent of
    Python 2.7's :meth:`datetime.timdelta.total_seconds`.
    """
    return (((
        td.microseconds +
        (td.seconds + td.days * 24 * 3600) * 10**6) / 10**6))

# NOTE:  This is something I'm investigating as a way to use the new go_async
# module.  A work-in-progress.  Ignore for now...
def spanify_screen(state_obj):
    """
    Iterates over the lines in *screen* and *renditions*, applying HTML
    markup (span tags) where appropriate and returns the result as a list of
    lines. It also marks the cursor position via a <span> tag at the
    appropriate location.
    """
    #logging.debug("_spanify_screen()")
    results = []
    # NOTE: Why these duplicates of self.* and globals?  Local variable
    # lookups are faster--especially in loops.
    #special = SPECIAL
    rendition_classes = RENDITION_CLASSES
    html_cache = state_obj['html_cache']
    screen = state_obj['screen']
    renditions = state_obj['renditions']
    renditions_store = state_obj['renditions_store']
    cursorX = state_obj['cursorX']
    cursorY = state_obj['cursorY']
    show_cursor = state_obj['show_cursor']
    class_prefix = state_obj['class_prefix']
    #captured_files = state_obj['captured_files']
    spancount = 0
    current_classes = set()
    prev_rendition = None
    foregrounds = ('f0','f1','f2','f3','f4','f5','f6','f7')
    backgrounds = ('b0','b1','b2','b3','b4','b5','b6','b7')
    html_entities = {"&": "&amp;", '<': '&lt;', '>': '&gt;'}
    cursor_span = '<span class="%scursor">' % class_prefix
    for linecount, line_rendition in enumerate(izip(screen, renditions)):
        line = line_rendition[0]
        rendition = line_rendition[1]
        combined = (line + rendition).tounicode()
        if html_cache and combined in html_cache:
            # Always re-render the line with the cursor (or just had it)
            if cursor_span not in html_cache[combined]:
                # Use the cache...
                results.append(html_cache[combined])
                continue
        if not len(line.tounicode().rstrip()) and linecount != cursorY:
            results.append(line.tounicode())
            continue # Line is empty so we don't need to process renditions
        outline = ""
        if current_classes:
            outline += '<span class="%s%s">' % (
                class_prefix,
                (" %s" % class_prefix).join(current_classes))
        charcount = 0
        for char, rend in izip(line, rendition):
            rend = renditions_store[rend] # Get actual rendition
            #if ord(char) >= special: # Special stuff =)
                ## Obviously, not really a single character
                #if char in captured_files:
                    #outline += captured_files[char].html()
                    #continue
            changed = True
            if char in "&<>":
                # Have to convert ampersands and lt/gt to HTML entities
                char = html_entities[char]
            if rend == prev_rendition:
                # Shortcut...  So we can skip all the logic below
                changed = False
            else:
                prev_rendition = rend
            if changed and rend:
                classes = imap(rendition_classes.get, rend)
                for _class in classes:
                    if _class and _class not in current_classes:
                        # Something changed...  Start a new span
                        if spancount:
                            outline += "</span>"
                            spancount -= 1
                        if 'reset' in _class:
                            if _class == 'reset':
                                current_classes = set()
                                if spancount:
                                    for i in xrange(spancount):
                                        outline += "</span>"
                                    spancount = 0
                            else:
                                reset_class = _class.split('reset')[0]
                                if reset_class == 'foreground':
                                    # Remove any foreground classes
                                    [current_classes.pop(i) for i, a in
                                    enumerate(current_classes) if a in
                                    foregrounds
                                    ]
                                elif reset_class == 'background':
                                    [current_classes.pop(i) for i, a in
                                    enumerate(current_classes) if a in
                                    backgrounds
                                    ]
                                else:
                                    try:
                                        current_classes.remove(reset_class)
                                    except KeyError:
                                        # Trying to reset something that was
                                        # never set.  Ignore
                                        pass
                        else:
                            if _class in foregrounds:
                                [current_classes.pop(i) for i, a in
                                enumerate(current_classes) if a in
                                foregrounds
                                ]
                            elif _class in backgrounds:
                                [current_classes.pop(i) for i, a in
                                enumerate(current_classes) if a in
                                backgrounds
                                ]
                            current_classes.add(_class)
                if current_classes:
                    outline += '<span class="%s%s">' % (
                        class_prefix,
                        (" %s" % class_prefix).join(current_classes))
                    spancount += 1
            if linecount == cursorY and charcount == cursorX: # Cursor
                if show_cursor:
                    outline += '<span class="%scursor">%s</span>' % (
                        class_prefix, char)
                else:
                    outline += char
            else:
                outline += char
            charcount += 1
        if outline:
            # Make sure all renditions terminate at the end of the line
            for whatever in xrange(spancount):
                outline += "</span>"
            results.append(outline)
            if html_cache:
                html_cache[combined] = outline
        else:
            results.append(None) # null is shorter than 4 spaces
        # NOTE: The client has been programmed to treat None (aka null in
        #       JavaScript) as blank lines.
    for whatever in xrange(spancount): # Bit of cleanup to be safe
        results[-1] += "</span>"
    return (html_cache, results)

# Exceptions
class InvalidParameters(Exception):
    """
    Raised when `Terminal` is passed invalid parameters.
    """
    pass

# Classes
class AutoExpireDict(dict):
    """
    An override of Python's `dict` that expires keys after a given
    *_expire_timeout* timeout (`datetime.timedelta`).  The default expiration
    is one hour.  It is used like so::

        >>> expiring_dict = AutoExpireDict(timeout=timedelta(minutes=10))
        >>> expiring_dict['somekey'] = 'some value'
        >>> # You can see when this key was created:
        >>> print(expiring_dict.creation_times['somekey'])
        2013-04-15 18:44:18.224072

    10 minutes later your key will be gone::

        >>> 'somekey' in expiring_dict
        False

    The 'timeout' may be be given as a `datetime.timedelta` object or a string
    like, "1d", "30s" (will be passed through the `convert_to_timedelta`
    function).

    By default `AutoExpireDict` will check for expired keys every 30 seconds but
    this can be changed by setting the 'interval'::

        >>> expiring_dict = AutoExpireDict(interval=5000) # 5 secs
        >>> # Or to change it after you've created one:
        >>> expiring_dict.interval = "10s"

    The 'interval' may be an integer, a `datetime.timedelta` object, or a string
    such as '10s' or '5m' (will be passed through the `convert_to_timedelta`
    function).

    If there are no keys remaining the `tornado.ioloop.PeriodicCallback` (
    ``self._key_watcher``) that checks expiration will be automatically stopped.
    As soon as a new key is added it will be started back up again.

    .. note::

        Only works if there's a running instances of `tornado.ioloop.IOLoop`.
    """
    def __init__(self, *args, **kwargs):
        self.io_loop = IOLoop.current()
        self.creation_times = {}
        if 'timeout' in kwargs:
            self.timeout = kwargs.pop('timeout')
        if 'interval' in kwargs:
            self.interval = kwargs.pop('interval')
        super(AutoExpireDict, self).__init__(*args, **kwargs)
        # Set the start time on every key
        for k in self.keys():
            self.creation_times[k] = datetime.now()
        self._key_watcher = PeriodicCallback(
            self._timeout_checker, self.interval, io_loop=self.io_loop)
        self._key_watcher.start() # Will shut down at the next interval if empty

    @property
    def timeout(self):
        """
        A `property` that controls how long a key will last before being
        automatically removed.  May be be given as a `datetime.timedelta`
        object or a string like, "1d", "30s" (will be passed through the
        `convert_to_timedelta` function).
        """
        if not hasattr(self, "_timeout"):
            self._timeout = timedelta(hours=1) # Default is 1-hour timeout
        return self._timeout

    @timeout.setter
    def timeout(self, value):
        if isinstance(value, basestring):
            value = convert_to_timedelta(value)
        self._timeout = value

    @property
    def interval(self):
        """
        A `property` that controls how often we check for expired keys.  May be
        given as milliseconds (integer), a `datetime.timedelta` object, or a
        string like, "1d", "30s" (will be passed through the
        `convert_to_timedelta` function).
        """
        if not hasattr(self, "_interval"):
            self._interval = 10000 # Default is every 10 seconds
        return self._interval

    @interval.setter
    def interval(self, value):
        if isinstance(value, basestring):
            value = convert_to_timedelta(value)
        if isinstance(value, timedelta):
            value = total_seconds(value) * 1000 # PeriodicCallback uses ms
        self._interval = value
        # Restart the PeriodicCallback
        if hasattr(self, '_key_watcher'):
            self._key_watcher.stop()
        self._key_watcher = PeriodicCallback(
            self._timeout_checker, value, io_loop=self.io_loop)

    def renew(self, key):
        """
        Resets the timeout on the given *key*; like it was just created.
        """
        self.creation_times[key] = datetime.now() # Set/renew the start time
        # Start up the key watcher if it isn't already running
        if not self._key_watcher._running:
            self._key_watcher.start()

    def __setitem__(self, key, value):
        """
        An override that tracks when keys are updated.
        """
        super(AutoExpireDict, self).__setitem__(key, value) # Set normally
        self.renew(key) # Set/renew the start time

    def __delitem__(self, key):
        """
        An override that makes sure *key* gets removed from
        ``self.creation_times`` dict.
        """
        del self.creation_times[key]
        super(AutoExpireDict, self).__delitem__(key)

    def __del__(self):
        """
        Ensures that our `tornado.ioloop.PeriodicCallback`
        (``self._key_watcher``) gets stopped.
        """
        self._key_watcher.stop()

    def update(self, *args, **kwargs):
        """
        An override that calls ``self.renew()`` for every key that gets updated.
        """
        super(AutoExpireDict, self).update(*args, **kwargs)
        for key, value in kwargs.items():
            self.renew(key)

    def clear(self):
        """
        An override that empties ``self.creation_times`` and calls
        ``self._key_watcher.stop()``.
        """
        super(AutoExpireDict, self).clear()
        self.creation_times.clear()
        # Shut down the key watcher right away
        self._key_watcher.stop()

    def _timeout_checker(self):
        """
        Walks ``self`` and removes keys that have passed the expiration point.
        """
        if not self.creation_times:
            self._key_watcher.stop() # Nothing left to watch
        for key, starttime in list(self.creation_times.items()):
            if datetime.now() - starttime > self.timeout:
                del self[key]

# AutoExpireDict only works if Tornado is present.
# Don't use the HTML_CACHE if Tornado isn't available.
try:
    from tornado.ioloop import IOLoop, PeriodicCallback
    HTML_CACHE = AutoExpireDict(timeout=timedelta(minutes=1), interval=30000)
except ImportError:
    HTML_CACHE = None

class FileType(object):
    """
    An object to hold the attributes of a supported file capture/output type.
    """
    # These attributes are here to prevent AttributeErrors if not overridden
    thumbnail = None
    html_template = "" # Must be overridden
    html_icon_template = "" # Must be overridden
    # This is for things like PDFs which can contain other FileTypes:
    is_container = False # Must be overridden
    helper = None # Optional function to be called when a capture is started
    original_file = None # Can be used when the file is modified
    def __init__(self,
        name, mimetype, re_header, re_capture, suffix="", path="", linkpath="", icondir=None):
        """
        **name:** Name of the file type.
        **mimetype:** Mime type of the file.
        **re_header:** The regex to match the start of the file.
        **re_capture:** The regex to carve the file out of the stream.
        **suffix:** (optional) The suffix to be appended to the end of the filename (if one is generated).
        **path:** (optional) The path to a file or directory where the file should be stored.  If *path* is a directory a random filename will be chosen.
        **linkpath:** (optional) The path to use when generating a link in HTML output.
        **icondir:** (optional) A path to look for a relevant icon to display when generating HTML output.
        """
        self.name = name
        self.mimetype = mimetype
        self.re_header = re_header
        self.re_capture = re_capture
        self.suffix = suffix
        # A path just in case something needs to access it outside of Python:
        self.path = path
        self.linkpath = linkpath
        self.icondir = icondir
        self.file_obj = None

    def __repr__(self):
        return "<%s>" % self.name

    def __str__(self):
        "Override if the defined file type warrants a text-based output."
        return self.__repr__()

    def __del__(self):
        """
        Make sure that self.file_obj gets closed/deleted.
        """
        logging.debug("FileType __del__(): Closing/deleting temp file(s)")
        try:
            self.file_obj.close() # Ensures it gets deleted
        except AttributeError:
            pass # Probably never got opened properly (bad file); no big
        try:
            self.original_file.close()
        except AttributeError:
            pass # Probably never got opened/saved properly

    def raw(self):
        self.file_obj.seek(0)
        data = open(self.file_obj).read()
        self.file_obj.seek(0)
        return data

    def html(self):
        """
        Returns the object as an HTML-formatted string.  Must be overridden.
        """
        raise NotImplementedError

    def capture(self, data, term_instance=None):
        """
        Stores *data* as a temporary file and returns that file's object.
        *term_instance* can be used by overrides of this function to make
        adjustments to the terminal emulator after the *data* is captured e.g.
        to make room for an image.
        """
        # Remove the extra \r's that the terminal adds:
        data = data.replace(b'\r\n', b'\n')
        logging.debug("capture() len(data): %s" % len(data))
        # Write the data to disk in a temporary location
        self.file_obj = tempfile.TemporaryFile()
        self.file_obj.write(data)
        self.file_obj.flush()
        # Leave it open
        return self.file_obj

    def close(self):
        """
        Closes :attr:`self.file_obj`
        """
        try:
            self.file_obj.close()
        except AttributeError:
            pass # file object never got created properly (probably missing PIL)

class ImageFile(FileType):
    """
    A subclass of :class:`FileType` for images (specifically to override
    :meth:`self.html` and :meth:`self.capture`).
    """
    def capture(self, data, term_instance):
        """
        Captures the image contained within *data*.  Will use *term_instance*
        to make room for the image in the terminal screen.

        .. note::  Unlike :class:`FileType`, *term_instance* is mandatory.
        """
        logging.debug('ImageFile.capture()')
        global _logged_pil_warning
        Image = False
        try:
            from PIL import Image
        except ImportError:
            if _logged_pil_warning:
                return
            _logged_pil_warning = True
            logging.warning(_(
                "Could not import the Python Imaging Library (PIL).  "
                "Images will not be displayed in the terminal."))
            logging.info(_(
                "TIP: Pillow is a 'friendly fork' of PIL that has been updated "
                "to work with Python 3 (also works in Python 2.X).  You can "
                "install it with:  pip install --upgrade pillow"))
            return # No PIL means no images.  Don't bother wasting memory.
        if _logged_pil_warning:
            _logged_pil_warning = False
            logging.info(_(
                "Good job installing PIL!  Terminal image suppport has been "
                "re-enabled.  Aren't dynamic imports grand?"))
        #open('/tmp/lastimage.img', 'w').write(data) # Use for debug
        # Image file formats don't usually like carriage returns:
        data = data.replace(b'\r\n', b'\n') # shell adds an extra /r
        i = BytesIO(data)
        try:
            im = Image.open(i)
        except (AttributeError, IOError) as e:
            # i.e. PIL couldn't identify the file
            message = _("PIL couldn't process the image (%s)" % e)
            logging.error(message)
            term_instance.send_message(message)
            return # Don't do anything--bad image
        # Save a copy of the data so the user can have access to the original
        if self.path:
            if os.path.exists(self.path):
                if os.path.isdir(self.path):
                    self.original_file = tempfile.NamedTemporaryFile(
                        suffix=self.suffix, dir=self.path)
                    self.original_file.write(data)
                    self.original_file.flush()
                    self.original_file.seek(0) # Just in case
        # Resize the image to be small enough to fit within a typical terminal
        if im.size[0] > 640 or im.size[1] > 480:
            im.thumbnail((640, 480), Image.ANTIALIAS)
        # Get the current image location and reference so we can move it around
        img_Y = term_instance.cursorY
        img_X = term_instance.cursorX
        ref = term_instance.screen[img_Y][img_X]
        if term_instance.em_dimensions:
            # Make sure the image will fit properly in the screen
            width = im.size[0]
            height = im.size[1]
            if height <= term_instance.em_dimensions['height']:
                # Fits within a line.  No need for a newline
                num_chars = int(width/term_instance.em_dimensions['width'])
                # Move the cursor an equivalent number of characters
                term_instance.cursor_right(num_chars)
            else:
                # This is how many newlines the image represents:
                newlines = int(height/term_instance.em_dimensions['height'])
                term_instance.screen[img_Y][img_X] = u' ' # Empty old location
                term_instance.cursorX = 0
                term_instance.newline() # Start with a newline
                if newlines > term_instance.cursorY:
                    # Shift empty lines at the bottom to the top to kinda sorta
                    # make room for the images so the user doesn't have to
                    # scroll (hey, it works!)
                    for i in xrange(newlines):
                        line = term_instance.screen.pop()
                        rendition = term_instance.renditions.pop()
                        term_instance.screen.insert(0, line)
                        term_instance.renditions.insert(0, rendition)
                        if term_instance.cursorY < (term_instance.rows - 1):
                            term_instance.cursorY += 1
                # Save the new image location
                term_instance.screen[
                    term_instance.cursorY][term_instance.cursorX] = ref
                term_instance.newline() # Follow-up newline
        elif term_instance.em_dimensions == None:
            # No way to calculate the number of lines the image will take
            term_instance.screen[img_Y][img_X] = u' ' # Empty old location
            term_instance.cursorY = term_instance.rows - 1 # Move to the end
            # ... so it doesn't get cut off at the top
            # Save the new image location
            term_instance.screen[
                term_instance.cursorY][term_instance.cursorX] = ref
            # Make some space at the bottom too just in case
            term_instance.newline()
            term_instance.newline()
        else:
            # When em_dimensions are set to 0 assume the user intentionally
            # wants things to be sized as inline as possible.
            term_instance.newline()
        # Write the captured image to disk
        if self.path:
            if os.path.exists(self.path):
                if os.path.isdir(self.path):
                    # Assume that a path was given for a reason and use a
                    # NamedTemporaryFile instead of TemporaryFile.
                    self.file_obj = tempfile.NamedTemporaryFile(
                        suffix=self.suffix, dir=self.path)
                    # Update self.path to use the new, actual file path
                    self.path = self.file_obj.name
                else:
                    self.file_obj = open(self.path, 'rb+')
        else:
            self.file_obj = tempfile.TemporaryFile(suffix=self.suffix)
        try:
            im.save(self.file_obj, im.format)
        except (AttributeError, IOError):
            # PIL was compiled without (complete) support for this format
            logging.error(_(
                "PIL is missing support for this image type (%s).  You probably"
                " need to install zlib-devel and libjpeg-devel then re-install "
                "it with 'pip install --upgrade PIL' or 'pip install "
                "--upgrade Pillow'" % self.name))
            try:
                self.file_obj.close() # Can't do anything with it
            except AttributeError:
                pass # File was probably just never opened/saved properly
            return None
        self.file_obj.flush()
        self.file_obj.seek(0) # Go back to the start
        return self.file_obj

    def html(self):
        """
        Returns :attr:`self.file_obj` as an <img> tag with the src set to a
        data::URI.
        """
        try:
            from PIL import Image
        except ImportError:
            return # Warnings will have already been printed by this point
        if not self.file_obj:
            return u""
        self.file_obj.seek(0)
        try:
            im = Image.open(self.file_obj)
        except IOError:
            # i.e. PIL couldn't identify the file
            return u"<i>Error displaying image</i>"
        self.file_obj.seek(0)
        # Need to encode base64 to create a data URI
        encoded = base64.b64encode(self.file_obj.read())
        data_uri = "data:image/{type};base64,{encoded}".format(
            type=im.format.lower(), encoded=encoded.decode('utf-8'))
        link = "%s/%s" % (self.linkpath, os.path.split(self.path)[1])
        if self.original_file:
            link = "%s/%s" % (
                self.linkpath, os.path.split(self.original_file.name)[1])
        if self.thumbnail:
            return self.html_icon_template.format(
                link=link,
                src=data_uri,
                width=im.size[0],
                height=im.size[1])
        return self.html_template.format(
            link=link, src=data_uri, width=im.size[0], height=im.size[1])

class PNGFile(ImageFile):
    """
    An override of :class:`ImageFile` for PNGs to hard-code the name, regular
    expressions, mimetype, and suffix.
    """
    name = _("PNG Image")
    mimetype = "image/png"
    suffix = ".png"
    re_header = re.compile(b'.*\x89PNG\r', re.DOTALL)
    re_capture = re.compile(b'(\x89PNG\r.+?IEND\xaeB`\x82)', re.DOTALL)
    html_template = (
        '<a target="_blank" href="{link}" '
        'title="Click to open the original file in a new window (full size)">'
        '<img src="{src}" width="{width}" height="{height}">'
        '</a>'
    )

    def __init__(self, path="", linkpath="", **kwargs):
        """
        **path:** (optional) The path to a file or directory where the file
        should be stored.  If *path* is a directory a random filename will be
        chosen.
        """
        self.path = path
        self.linkpath = linkpath
        self.file_obj = None
        # Images will be displayed inline so no icons unless overridden:
        self.html_icon_template = self.html_template

class JPEGFile(ImageFile):
    """
    An override of :class:`ImageFile` for JPEGs to hard-code the name, regular
    expressions, mimetype, and suffix.
    """
    name = _("JPEG Image")
    mimetype = "image/jpeg"
    suffix = ".jpeg"
    re_header = re.compile(
        b'.*\xff\xd8\xff.+JFIF\x00|.*\xff\xd8\xff.+Exif\x00', re.DOTALL)
    re_capture = re.compile(b'(\xff\xd8\xff.+?\xff\xd9)', re.DOTALL)
    html_template = (
        '<a target="_blank" href="{link}" '
        'title="Click to open the original file in a new window (full size)">'
        '<img src="{src}" width="{width}" height="{height}">'
        '</a>'
    )
    def __init__(self, path="", linkpath="", **kwargs):
        """
        **path:** (optional) The path to a file or directory where the file
        should be stored.  If *path* is a directory a random filename will be
        chosen.
        """
        self.path = path
        self.linkpath = linkpath
        self.file_obj = None
        # Images will be displayed inline so no icons unless overridden:
        self.html_icon_template = self.html_template

class SoundFile(FileType):
    """
    A subclass of :class:`FileType` for sound files (e.g. .wav).  Overrides
    :meth:`self.html` and :meth:`self.capture`.
    """
    # NOTE: I disabled autoplay on these sounds because it causes the browser to
    # play back the sound with every screen update!  Press return a few times
    # and the sound will play a few times; annoying!
    html_template = (
        '<audio controls>'
        '<source src="{src}" type="{mimetype}">'
        'Your browser does not support this audio format.'
        '</audio>'
    )
    display_metadata = None # Can be overridden to send a message to the user
    def capture(self, data, term_instance):
        """
        Captures the sound contained within *data*.  Will use *term_instance*
        to make room for the embedded sound control in the terminal screen.

        .. note::  Unlike :class:`FileType`, *term_instance* is mandatory.
        """
        logging.debug('SoundFile.capture()')
        # Fix any carriage returns (generated by the shell):
        data = data.replace(b'\r\n', b'\n')
        # Make some room for the audio controls:
        term_instance.newline()
        # Write the captured image to disk
        if self.path:
            if os.path.exists(self.path):
                if os.path.isdir(self.path):
                    # Assume that a path was given for a reason and use a
                    # NamedTemporaryFile instead of TemporaryFile.
                    self.file_obj = tempfile.NamedTemporaryFile(
                        suffix=self.suffix, dir=self.path)
                    # Update self.path to use the new, actual file path
                    self.path = self.file_obj.name
                else:
                    self.file_obj = open(self.path, 'rb+')
        else:
            self.file_obj = tempfile.TemporaryFile(suffix=self.suffix)
        self.file_obj.write(data)
        self.file_obj.flush()
        self.file_obj.seek(0) # Go back to the start
        if self.display_metadata:
            self.display_metadata(term_instance)
        return self.file_obj

    def html(self):
        """
        Returns :attr:`self.file_obj` as an <img> tag with the src set to a
        data::URI.
        """
        if not self.file_obj:
            return u""
        self.file_obj.seek(0)
        # Need to encode base64 to create a data URI
        encoded = base64.b64encode(self.file_obj.read())
        data_uri = "data:{mimetype};base64,{encoded}".format(
            mimetype=self.mimetype, encoded=encoded.decode('utf-8'))
        link = "%s/%s" % (self.linkpath, os.path.split(self.path)[1])
        if self.original_file:
            link = "%s/%s" % (
                self.linkpath, os.path.split(self.original_file.name)[1])
        if self.thumbnail:
            return self.html_icon_template.format(
                link=link,
                src=data_uri,
                icon=self.thumbnail,
                mimetype=self.mimetype)
        return self.html_template.format(
            link=link, src=data_uri, mimetype=self.mimetype)

class WAVFile(SoundFile):
    """
    An override of :class:`SoundFile` for WAVs to hard-code the name, regular
    expressions, mimetype, and suffix.  Also, a :func:`helper` function is
    provided that adjusts the `self.re_capture` regex so that it precisely
    matches the WAV file being captured.
    """
    name = _("WAV Sound")
    mimetype = "audio/x-wav"
    suffix = ".wav"
    re_header = re.compile(b'RIFF....WAVEfmt', re.DOTALL)
    re_capture = re.compile(b'(RIFF....WAVEfmt.+?\r\n)', re.DOTALL)
    re_wav_header = re.compile(b'(RIFF.{40})', re.DOTALL)
    def __init__(self, path="", linkpath="", **kwargs):
        """
        **path:** (optional) The path to a file or directory where the file
        should be stored.  If *path* is a directory a random filename will be
        chosen.
        """
        self.path = path
        self.linkpath = linkpath
        self.file_obj = None
        self.sent_message = False
        # Sounds will be displayed inline so no icons unless overridden:
        self.html_icon_template = self.html_template

    def helper(self, term_instance):
        """
        Called at the start of a WAV file capture.  Calculates the length of the
        file and modifies `self.re_capture` with laser precision.
        """
        data = term_instance.capture
        self.wav_header = struct.unpack(
            '4si4s4sihhiihh4si', self.re_wav_header.match(data).group())
        self.wav_length = self.wav_header[1] + 8
        if not self.sent_message:
            channels = "mono"
            if self.wav_header[6] == 2:
                channels = "stereo"
            if self.wav_length != self.wav_header[12] + 44:
                # Corrupt WAV file
                message = _("WAV File is corrupted: Header data mismatch.")
                term_instance.send_message(message)
                term_instance.cancel_capture = True
            message = _("WAV File: %skHz (%s)" % (self.wav_header[7], channels))
            term_instance.send_message(message)
            self.sent_message = True
        # Update the capture regex with laser precision:
        self.re_capture = re.compile(
            b'(RIFF....WAVE.{%s})' % (self.wav_length-12), re.DOTALL)

class OGGFile(SoundFile):
    """
    An override of :class:`SoundFile` for OGGs to hard-code the name, regular
    expressions, mimetype, and suffix.
    """
    name = _("OGG Sound")
    mimetype = "audio/ogg"
    suffix = ".ogg"
    # NOTE: \x02 below marks "start of stream" (\x04 is "end of stream")
    re_header = re.compile(b'OggS\x00\x02', re.DOTALL)
    # NOTE: This should never actually match since it will be replaced by the
    # helper() function:
    re_capture = re.compile(b'(OggS\x00\x02.+OggS\x00\x04\r\n)', re.DOTALL)
    re_ogg_header = re.compile(b'(OggS\x00\x02.{21})', re.DOTALL)
    re_last_segment = re.compile(b'(OggS\x00\x04.{21})', re.DOTALL)
    def __init__(self, path="", linkpath="", **kwargs):
        """
        **path:** (optional) The path to a file or directory where the file
        should be stored.  If *path* is a directory a random filename will be
        chosen.
        """
        self.path = path
        self.linkpath = linkpath
        self.file_obj = None
        self.sent_message = False
        # Sounds will be displayed inline so no icons unless overridden:
        self.html_icon_template = self.html_template

    def helper(self, term_instance):
        """
        Called at the start of a OGG file capture.  Calculates the length of the
        file and modifies `self.re_capture` with laser precision.  Returns
        `True` if the entire ogg has been captured.
        """
        data = term_instance.capture
        last_segment_header = self.re_last_segment.search(data)
        if not last_segment_header:
            #print("No last segment header yet")
            #print(repr(data.split('OggS')[-1]))
            #print('-----------------------------')
            return # Haven't reached the end of the OGG yet
        else:
            last_segment_header = last_segment_header.group()
        # This decodes the OGG page header
        (oggs, version, type_flags, position,
             serial, sequence, crc, segments) = struct.unpack(
                "<4sBBqIIiB", last_segment_header)
        # Figuring out the length of the last set of segments is a little bit
        # involved...
        lacing_size = 0
        lacings = []
        last_segment_header = re.search( # Include the segment table
            b'(OggS\x00\x04.{%s})' % (21+segments), data, re.DOTALL).group()
        lacing_bytes = last_segment_header[27:][:segments]
        for c in map(ord, lacing_bytes):
            lacing_size += c
            if c < 255:
                lacings.append(lacing_size)
                lacing_size = 0
        segment_size = 27 # Initial header size
        segment_size += sum(ord(e) for e in last_segment_header[27:])
        segment_size += len(lacings)
        # Update the capture regex with laser precision:
        self.re_capture = re.compile(
            b'(OggS\x00\x02\x00.+OggS\x00\x04..{%s})'
            % (segment_size), re.DOTALL)
        return True

    def display_metadata(self, term_instance):
        """
        Sends a message to the user that displays the OGG file metadata.  Things
        like ID3 tags, bitrate, channels, etc.
        """
        if not self.sent_message:
            global _logged_mutagen_warning
            try:
                import mutagen.oggvorbis
            except ImportError:
                if not _logged_mutagen_warning:
                    _logged_mutagen_warning = True
                    logging.warning(_(
                        "Could not import the mutagen Python module.  "
                        "Displaying audio file metadata will be disabled."))
                    logging.info(_(
                        "TIP: Install mutagen:  sudo pip install mutagen"))
                return
            oggfile = mutagen.oggvorbis.Open(self.file_obj.name)
            message = "<pre>%s</pre>" % oggfile.pprint()
            term_instance.send_message(message)
            self.sent_message = True

class PDFFile(FileType):
    """
    A subclass of :class:`FileType` for PDFs (specifically to override
    :meth:`self.html`).  Has hard-coded name, mimetype, suffix, and regular
    expressions.  This class will also utilize :attr:`self.icondir` to look for
    an icon named, 'pdf.svg'.  If found it will be utilized by
    :meth:`self.html` when generating output.
    """
    name = _("PDF Document")
    mimetype = "application/pdf"
    suffix = ".pdf"
    re_header = re.compile(br'.*%PDF-[0-9]\.[0-9]{1,2}.+?obj', re.DOTALL)
    re_capture = re.compile(br'(%PDF-[0-9]\.[0-9]{1,2}.+%%EOF)', re.DOTALL)
    icon = "pdf.svg" # Name of the file inside of self.icondir
    # NOTE:  Using two separate links below so the whitespace doesn't end up
    # underlined.  Looks much nicer this way.
    html_icon_template = (
        '<span class="pdfcontainer"><a class="pdflink" target="_blank" '
        'href="{link}">{icon}</a><br>'
        '   <a class="pdflink" href="{link}">{name}</a></span>')
    html_template = (
        '<span class="pdfcontainer"><a target="_blank" href="{link}">{name}</a>'
        '</span>')
    is_container = True

    def __init__(self, path="", linkpath="", icondir=None):
        """
        **path:** (optional) The path to the file.
        **linkpath:** (optional) The path to use when generating a link in HTML output.
        **icondir:** (optional) A path to look for a relevant icon to display when generating HTML output.
        """
        self.path = path
        self.linkpath = linkpath
        self.icondir = icondir
        self.file_obj = None
        self.thumbnail = None

    def generate_thumbnail(self):
        """
        If available, will use ghostscript (gs) to generate a thumbnail of this
        PDF in the form of an <img> tag with the src set to a data::URI.
        """
        from commands import getstatusoutput
        thumb = tempfile.NamedTemporaryFile()
        params = [
            'gs', # gs must be in your path
            '-dPDFFitPage',
            '-dPARANOIDSAFER',
            '-dBATCH',
            '-dNOPAUSE',
            '-dNOPROMPT',
            '-dMaxBitmap=500000000',
            '-dAlignToPixels=0',
            '-dGridFitTT=0',
            '-dDEVICEWIDTH=90',
            '-dDEVICEHEIGHT=120',
            '-dORIENT1=true',
            '-sDEVICE=jpeg',
            '-dTextAlphaBits=4',
            '-dGraphicsAlphaBits=4',
            '-sOutputFile=%s' % thumb.name,
            self.path
        ]
        retcode, output = getstatusoutput(" ".join(params))
        if retcode == 0:
            # Success
            data = None
            with open(thumb.name) as f:
                data = f.read()
            thumb.close() # Make sure it gets removed now we've read it
            if data:
                encoded = base64.b64encode(data)
                data_uri = "data:image/jpeg;base64,%s" % encoded.decode('utf-8')
                return '<img src="%s">' % data_uri

    def capture(self, data, term_instance):
        """
        Stores *data* as a temporary file and returns that file's object.
        *term_instance* can be used by overrides of this function to make
        adjustments to the terminal emulator after the *data* is captured e.g.
        to make room for an image.
        """
        logging.debug("PDFFile.capture()")
        # Remove the extra \r's that the terminal adds:
        data = data.replace(b'\r\n', b'\n')
        # Write the data to disk in a temporary location
        if self.path:
            if os.path.exists(self.path):
                if os.path.isdir(self.path):
                    # Assume that a path was given for a reason and use a
                    # NamedTemporaryFile instead of TemporaryFile.
                    self.file_obj = tempfile.NamedTemporaryFile(
                        suffix=self.suffix, dir=self.path)
                    # Update self.path to use the new, actual file path
                    self.path = self.file_obj.name
                else:
                    self.file_obj = open(self.path, 'rb+')
        else:
            # Use the terminal emulator's temppath
            self.file_obj = tempfile.NamedTemporaryFile(
                suffix=self.suffix, dir=term_instance.temppath)
            self.path = self.file_obj.name
        self.file_obj.write(data)
        self.file_obj.flush()
        # Ghostscript-based thumbnail generation disabled due to its slow,
        # blocking nature.  Works great though!
        #self.thumbnail = self.generate_thumbnail()
        # TODO: Figure out a way to do non-blocking thumbnail generation
        if self.icondir:
            pdf_icon = os.path.join(self.icondir, self.icon)
            if os.path.exists(pdf_icon):
                with open(pdf_icon) as f:
                    self.thumbnail = f.read()
        if self.thumbnail:
            # Make room for our link
            img_Y = term_instance.cursorY
            img_X = term_instance.cursorX
            ref = term_instance.screen[img_Y][img_X]
            term_instance.screen[img_Y][img_X] = u' ' # No longer at this loc
            if term_instance.cursorY < 8: # Icons are about ~8 newlines high
                for line in xrange(8 - term_instance.cursorY):
                    term_instance.newline()
            # Save the new location
            term_instance.screen[
                term_instance.cursorY][term_instance.cursorX] = ref
            term_instance.newline()
        else:
            # Make room for the characters in the name, "PDF Document"
            for i in xrange(len(self.name)):
                term_instance.screen[term_instance.cursorY].pop()
        # Leave it open
        return self.file_obj

    def html(self):
        """
        Returns a link to download the PDF using :attr:`self.linkpath` for the
        href attribute.  Will use :attr:`self.html_icon_template` if
        :attr:`self.icon` can be found.  Otherwise it will just output
        :attr:`self.name` as a clickable link.
        """
        link = "%s/%s" % (self.linkpath, os.path.split(self.path)[1])
        if self.thumbnail:
            return self.html_icon_template.format(
                link=link, icon=self.thumbnail, name=self.name)
        return self.html_template.format(
            link=link, icon=self.thumbnail, name=self.name)

class NotFoundError(Exception):
    """
    Raised by :meth:`Terminal.remove_magic` if a given filetype was not found in
    :attr:`Terminal.supported_magic`.
    """
    pass

class Terminal(object):
    """
    Terminal controller class.
    """
    ASCII_NUL = 0     # Null
    ASCII_BEL = 7     # Bell (BEL)
    ASCII_BS = 8      # Backspace
    ASCII_HT = 9      # Horizontal Tab
    ASCII_LF = 10     # Line Feed
    ASCII_VT = 11     # Vertical Tab
    ASCII_FF = 12     # Form Feed
    ASCII_CR = 13     # Carriage Return
    ASCII_SO = 14     # Ctrl-N; Shift out (switches to the G0 charset)
    ASCII_SI = 15     # Ctrl-O; Shift in (switches to the G1 charset)
    ASCII_XON = 17    # Resume Transmission
    ASCII_XOFF = 19   # Stop Transmission or Ignore Characters
    ASCII_CAN = 24    # Cancel Escape Sequence
    ASCII_SUB = 26    # Substitute: Cancel Escape Sequence and replace with ?
    ASCII_ESC = 27    # Escape
    ASCII_CSI = 155   # Control Sequence Introducer (that nothing uses)
    ASCII_HTS = 210   # Horizontal Tab Stop (HTS)

    class_prefix = u'' # Prefix used with HTML output span class names
                        # (to avoid namespace conflicts)

    charsets = {
        'B': {}, # Default is USA (aka 'B')
        '0': { # Line drawing mode
            95: u' ',
            96: u'',
            97: u'',
            98: u'\t',
            99: u'\x0c',
            100: u'\r',
            101: u'\n',
            102: u'',
            103: u'',
            104: u'\n',
            105: u'\x0b',
            106: u'',
            107: u'',
            108: u'',
            109: u'',
            110: u'',
            111: u'', # All these bars and not a drink!
            112: u'',
            113: u'',
            114: u'',
            115: u'',
            116: u'',
            117: u'',
            118: u'',
            119: u'',
            120: u'',
            121: u'',
            122: u'',
            123: u'',
            124: u'',
            125: u'',
            126: u'' # Centered dot--who comes up with this stuff?!?
        }
    }

    RE_CSI_ESC_SEQ = re.compile(r'\x1B\[([?A-Za-z0-9>;@:\!]*)([A-Za-z@_])')
    RE_ESC_SEQ = re.compile(
        r'\x1b(.*\x1b\\|[ABCDEFGHIJKLMNOQRSTUVWXYZa-z0-9=<>]|[()# %*+].)')
    RE_TITLE_SEQ = re.compile(r'\x1b\][0-2]\;(.*?)(\x07|\x1b\\)')
    # The below regex is used to match our optional (non-standard) handler
    RE_OPT_SEQ = re.compile(r'\x1b\]_\;(.+?)(\x07|\x1b\\)')
    RE_NUMBERS = re.compile('\d*') # Matches any number
    RE_SIGINT = re.compile(b'.*\^C', re.MULTILINE|re.DOTALL)

    def __init__(self, rows=24, cols=80, em_dimensions=None, temppath='/tmp',
    linkpath='/tmp', icondir=None, encoding='utf-8', async=None, debug=False,
    enabled_filetypes="all"):
        """
        Initializes the terminal by calling *self.initialize(rows, cols)*.  This
        is so we can have an equivalent function in situations where __init__()
        gets overridden.

        If *em_dimensions* are provided they will be used to determine how many
        lines images will take when they're drawn in the terminal.  This is to
        prevent images that are written to the top of the screen from having
        their tops cut off.  *em_dimensions* must be a dict in the form of::

            {'height': <px>, 'width': <px>}

        The *temppath* will be used to store files that are captured/saved by
        the terminal emulator.  In conjunction with this is the *linkpath* which
        will be used when creating links to these temporary files.  For example,
        a web-based application may wish to have the terminal emulator store
        temporary files in /tmp but give clients a completely unrelated URL to
        retrieve these files (for security or convenience reasons).  Here's a
        real world example of how it works::

            >>> term = Terminal(
            ... rows=10, cols=40, temppath='/var/tmp', linkpath='/terminal')
            >>> term.write('About to write a PDF\\n')
            >>> pdf = open('/path/to/somefile.pdf').read()
            >>> term.write(pdf)
            >>> term.dump_html()
            ([u'About to write a PDF                    ',
            # <unnecessary lines of whitespace have been removed for this example>
            u'<a target="_blank" href="/terminal/tmpZoOKVM.pdf">PDF Document</a>'])

        The PDF file in question will reside in `/var/tmp` but the link was
        created as `href="/terminal/tmpZoOKVM.pdf"`.  As long as your web app
        knows to look in /var/tmp for incoming '/terminal' requests users should
        be able to retrieve their documents.

            http://yourapp.company.com/terminal/tmpZoOKVM.pdf

        The *icondir* parameter, if given, will be used to provide a relevant
        icon when outputing a link to a file.  When a supported
        :class:`FileType` is captured the instance will be given the *icondir*
        as a parameter in a manner similar to this::

            filetype_instance = filetype_class(icondir=self.icondir)

        That way when filetype_instance.html() is called it can display a nice
        icon to the user...  if that particular :class:`FileType` supports icons
        and the icon it is looking for happens to be available at *icondir*.

        If *debug* is True, the root logger will have its level set to DEBUG.

        If *enabled_filetypes* are given (iterable of strings or `FileType`
        classes) the provided file types will be enabled for this terminal.
        If not given it will default to enabling 'all' file types.  To disable
        support for all file types simply pass ``None``, ``False``, or an empty
        list.
        """
        if rows < 2 or cols < 2:
            raise InvalidParameters(_(
                "Invalid value(s) given for rows ({rows}) and/or cols "
                "({cols}).  Both must be > 1.").format(rows=rows, cols=cols))
        if em_dimensions:
            if not isinstance(em_dimensions, dict):
                raise InvalidParameters(_(
                    "The em_dimensions keyword argument must be a dict.  "
                    "Here's what was given instead: {0}").format(
                        repr(em_dimensions)))
            if 'width' not in em_dimensions or 'height' not in em_dimensions:
                raise InvalidParameters(_(
                    "The given em_dimensions dict ({0}) is missing either "
                    "'height' or 'width'").format(repr(em_dimensions)))
        if not os.path.exists(temppath):
            raise InvalidParameters(_(
                "The given temppath ({0}) does not exist.").format(temppath))
        if icondir:
            if not os.path.exists(icondir):
                logging.warning(_(
                    "The given icondir ({0}) does not exist.").format(icondir))
        if debug:
            logger = logging.getLogger()
            logger.level = logging.DEBUG
        self.temppath = temppath
        self.linkpath = linkpath
        self.icondir = icondir
        self.encoding = encoding
        self.async = async
        if enabled_filetypes == "all":
            enabled_filetypes = [
                PDFFile,
                PNGFile,
                JPEGFile,
                WAVFile,
                OGGFile,
            ]
        elif enabled_filetypes:
            for i, filetype in enumerate(list(enabled_filetypes)):
                if isinstance(filetype, basestring):
                    # Attempt to convert into a proper class with Python voodoo
                    _class = globals().get(filetype)
                    if _class:
                        enabled_filetypes[i] = _class # Update in-place
        else:
            enabled_filetypes = []
        self.enabled_filetypes = enabled_filetypes
        # This controls how often we send a message to the client when capturing
        # a special file type.  The default is to update the user of progress
        # once every 1.5 seconds.
        self.message_interval = timedelta(seconds=1.5)
        self.notified = False # Used to tell if we have notified the user before
        self.cancel_capture = False
        # Used by cursor_left() and cursor_right() to handle double-width chars:
        self.double_width_right = False
        self.double_width_left = False
        self.prev_char = u''
        self.max_scrollback = 1000 # Max number of lines kept in the buffer
        self.initialize(rows, cols, em_dimensions)

    def initialize(self, rows=24, cols=80, em_dimensions=None):
        """
        Initializes the terminal (the actual equivalent to :meth:`__init__`).
        """
        self.cols = cols
        self.rows = rows
        self.em_dimensions = em_dimensions
        self.scrollback_buf = []
        self.scrollback_renditions = []
        self.title = "Gate One"
        # This variable can be referenced by programs implementing Terminal() to
        # determine if anything has changed since the last dump*()
        self.modified = False
        self.local_echo = True
        self.insert_mode = False
        self.esc_buffer = '' # For holding escape sequences as they're typed.
        self.cursor_home = 0
        self.cur_rendition = unichr(1000) # Should always be reset ([0])
        self.init_screen()
        self.init_renditions()
        self.current_charset = 0
        self.set_G0_charset('B')
        self.set_G1_charset('B')
        self.use_g0_charset()
        # Set the default window margins
        self.top_margin = 0
        self.bottom_margin = self.rows - 1
        self.timeout_capture = None
        self.specials = {
            self.ASCII_NUL: self.__ignore,
            self.ASCII_BEL: self.bell,
            self.ASCII_BS: self.backspace,
            self.ASCII_HT: self.horizontal_tab,
            self.ASCII_LF: self.newline,
            self.ASCII_VT: self.newline,
            self.ASCII_FF: self.newline,
            self.ASCII_CR: self.carriage_return,
            self.ASCII_SO: self.use_g1_charset,
            self.ASCII_SI: self.use_g0_charset,
            self.ASCII_XON: self._xon,
            self.ASCII_CAN: self._cancel_esc_sequence,
            self.ASCII_XOFF: self._xoff,
            #self.ASCII_ESC: self._sub_esc_sequence,
            self.ASCII_ESC: self._escape,
            self.ASCII_CSI: self._csi,
        }
        self.esc_handlers = {
            # TODO: Make a different set of these for each respective emulation mode (VT-52, VT-100, VT-200, etc etc)
            '#': self._set_line_params, # Varies
            '\\': self._string_terminator, # ST
            'c': self.clear_screen, # Reset terminal
            'D': self.__ignore, # Move/scroll window up one line    IND
            'M': self.reverse_linefeed, # Move/scroll window down one line RI
            'E': self.next_line, # Move to next line NEL
            'F': self.__ignore, # Enter Graphics Mode
            'G': self.next_line, # Exit Graphics Mode
            '6': self._dsr_get_cursor_position, # Get cursor position   DSR
            '7': self.save_cursor_position, # Save cursor position and attributes   DECSC
            '8': self.restore_cursor_position, # Restore cursor position and attributes   DECSC
            'H': self._set_tabstop, # Set a tab at the current column   HTS
            'I': self.reverse_linefeed,
            '(': self.set_G0_charset, # Designate G0 Character Set
            ')': self.set_G1_charset, # Designate G1 Character Set
            'N': self.__ignore, # Set single shift 2    SS2
            'O': self.__ignore, # Set single shift 3    SS3
            '5': self._device_status_report, # Request: Device status report DSR
            '0': self.__ignore, # Response: terminal is OK  DSR
            'P': self._dcs_handler, # Device Control String  DCS
            # NOTE: = and > are ignored because the user can override/control
            # them via the numlock key on their keyboard.  To do otherwise would
            # just confuse people.
            '=': self.__ignore, # Application Keypad  DECPAM
            '>': self.__ignore, # Exit alternate keypad mode
            '<': self.__ignore, # Exit VT-52 mode
            'Z': self._csi_device_identification,
        }
        self.csi_handlers = {
            'A': self.cursor_up,
            'B': self.cursor_down,
            'C': self.cursor_right,
            'D': self.cursor_left,
            'E': self.cursor_next_line, # NOTE: Not the same as next_line()
            'F': self.cursor_previous_line,
            'G': self.cursor_horizontal_absolute,
            'H': self.cursor_position,
            'L': self.insert_line,
            'M': self.delete_line,
            #'b': self.repeat_last_char, # TODO
            'c': self._csi_device_identification, # Device status report (DSR)
            'g': self.__ignore, # TODO: Tab clear
            'h': self.set_expanded_mode,
            'i': self.__ignore, # ESC[5i is "redirect to printer", ESC[4i ends it
            'l': self.reset_expanded_mode,
            'f': self.cursor_position,
            'd': self.cursor_position_vertical, # Vertical Line Position Absolute (VPA)
            #'e': self.cursor_position_vertical_relative, # VPR TODO
            'J': self.clear_screen_from_cursor,
            'K': self.clear_line_from_cursor,
            'S': self.scroll_up,
            'T': self.scroll_down,
            's': self.save_cursor_position,
            'u': self.restore_cursor_position,
            'm': self._set_rendition,
            'n': self._csi_device_status_report, # <ESC>[6n is the only one I know of (request cursor position)
            'p': self.reset, # TODO: "!p" is "Soft terminal reset".  Also, "Set conformance level" (VT100, VT200, or VT300)
            'r': self._set_top_bottom, # DECSTBM (used by many apps)
            'q': self.set_led_state, # Seems a bit silly but you never know
            'P': self.delete_characters, # DCH Deletes the specified number of chars
            'X': self._erase_characters, # ECH Same as DCH but also deletes renditions
            'Z': self.insert_characters, # Inserts the specified number of chars
            '@': self.insert_characters, # Inserts the specified number of chars
            #'`': self._char_position_row, # Position cursor (row only)
            #'t': self.window_manipulation, # TODO
            #'z': self.locator, # TODO: DECELR "Enable locator reporting"
        }
        # Used to store what expanded modes are active
        self.expanded_modes = {
            # Important defaults
            '1': False, # Application Cursor Keys
            '7': False, # Autowrap
            '25': True, # Show Cursor
        }
        self.expanded_mode_handlers = {
            # Expanded modes take a True/False argument for set/reset
            '1': partial(self.expanded_mode_toggle, '1'),
            '2': self.__ignore, # DECANM and set VT100 mode (and lock keyboard)
            '3': self.__ignore, # 132 Column Mode (DECCOLM)
            '4': self.__ignore, # Smooth (Slow) Scroll (DECSCLM)
            '5': self.__ignore, # Reverse video (might support in future)
            '6': self.__ignore, # Origin Mode (DECOM)
            # Wraparound Mode (DECAWM):
            '7': partial(self.expanded_mode_toggle, '7'),
            '8': self.__ignore, # Auto-repeat Keys (DECARM)
            # Send Mouse X & Y on button press:
            '9': partial(self.expanded_mode_toggle, '9'),
            '12': self.__ignore, # SRM or Start Blinking Cursor (att610)
            '18': self.__ignore, # Print form feed (DECPFF)
            '19': self.__ignore, # Set print extent to full screen (DECPEX)
            '25': partial(self.expanded_mode_toggle, '25'),
            '38': self.__ignore, # Enter Tektronix Mode (DECTEK)
            '41': self.__ignore, # more(1) fix (whatever that is)
            '42': self.__ignore, # Enable Nation Replacement Character sets (DECNRCM)
            '44': self.__ignore, # Turn On Margin Bell
            '45': self.__ignore, # Reverse-wraparound Mode
            '46': self.__ignore, # Start Logging
            '47': self.toggle_alternate_screen_buffer, # Use Alternate Screen Buffer
            '66': self.__ignore, # Application keypad (DECNKM)
            '67': self.__ignore, # Backarrow key sends delete (DECBKM)
            # Send Mouse X/Y on button press and release:
            '1000': partial(self.expanded_mode_toggle, '1000'),
            # Use Hilite Mouse Tracking:
            '1001': partial(self.expanded_mode_toggle, '1001'),
            # Use Cell Motion Mouse Tracking:
            '1002': partial(self.expanded_mode_toggle, '1002'),
            # Use All Motion Mouse Tracking:
            '1003': partial(self.expanded_mode_toggle, '1003'),
            # Send FocusIn/FocusOut events:
            '1004': partial(self.expanded_mode_toggle, '1004'),
            # Enable UTF-8 Mouse Mode:
            '1005': partial(self.expanded_mode_toggle, '1005'),
            # Enable SGR Mouse Mode:
            '1006': partial(self.expanded_mode_toggle, '1006'),
            '1010': self.__ignore, # Scroll to bottom on tty output
            '1011': self.__ignore, # Scroll to bottom on key press
            '1035': self.__ignore, # Enable special modifiers for Alt and NumLock keys
            '1036': self.__ignore, # Send ESC when Meta modifies a key
            '1037': self.__ignore, # Send DEL from the editing-keypad Delete key
            '1047': self.__ignore, # Use Alternate Screen Buffer
            '1048': self.__ignore, # Save cursor as in DECSC
            # Save cursor as in DECSC and use Alternate Screen Buffer,
            # clearing it first:
            '1049': self.toggle_alternate_screen_buffer_cursor,
            '1051': self.__ignore, # Set Sun function-key mode
            '1052': self.__ignore, # Set HP function-key mode
            '1060': self.__ignore, # Set legacy keyboard emulation (X11R6)
            '1061': self.__ignore, # Set Sun/PC keyboard emulation of VT220 keyboard
        }
        self.callbacks = {
            CALLBACK_SCROLL_UP: {},
            CALLBACK_CHANGED: {},
            CALLBACK_CURSOR_POS: {},
            CALLBACK_DSR: {},
            CALLBACK_TITLE: {},
            CALLBACK_BELL: {},
            CALLBACK_OPT: {},
            CALLBACK_MODE: {},
            CALLBACK_RESET: {},
            CALLBACK_LEDS: {},
            CALLBACK_MESSAGE: {},
        }
        self.leds = {
            1: False,
            2: False,
            3: False,
            4: False
        }
        # supported_magic gets assigned via self.add_magic() below
        self.supported_magic = []
        # Dict for magic "numbers" so we can tell when a particular type of
        # file begins and ends (so we can capture it in binary form and
        # later dump it out via dump_html())
        # The format is 'beginning': 'whole'
        self.magic = OrderedDict()
        # magic_map is like magic except it is in the format of:
        #   'beginning': <filetype class>
        self.magic_map = {}
        # Supported magic (defaults)
        for filetype in self.enabled_filetypes:
            self.add_magic(filetype)
        # NOTE:  The order matters!  Some file formats are containers that can
        # hold other file formats.  For example, PDFs can contain JPEGs.  So if
        # we match JPEGs before PDFs we might make a match when we really wanted
        # to match the overall container (the PDF).
        self.matched_header = None
        # These are for saving self.screen and self.renditions so we can support
        # an "alternate buffer"
        self.alt_screen = None
        self.alt_renditions = None
        self.alt_cursorX = 0
        self.alt_cursorY = 0
        self.saved_cursorX = 0
        self.saved_cursorY = 0
        self.saved_rendition = [None]
        self.capture = b""
        self.captured_files = {}
        self.file_counter = pua_counter()
        # This is for creating a new point of reference every time there's a new
        # unique rendition at a given coordinate
        self.rend_counter = unicode_counter()
        # Used for mapping unicode chars to acutal renditions (to save memory):
        self.renditions_store = {
            u' ': [], # Nada, nothing, no rendition.  Not the same as below
            self.rend_counter.next(): [0] # Default is actually reset
        }
        self.watcher = None # Placeholder for the file watcher thread (if used)

    def add_magic(self, filetype):
        """
        Adds the given *filetype* to :attr:`self.supported_magic` and generates
        the necessary bits in :attr:`self.magic` and :attr:`self.magic_map`.

        *filetype* is expected to be a subclass of :class:`FileType`.
        """
        #logging.debug("add_magic(%s)" % filetype)
        if filetype in self.supported_magic:
            return # Nothing to do; it's already there
        self.supported_magic.append(filetype)
        # Wand ready...
        for Type in self.supported_magic:
            self.magic.update({Type.re_header: Type.re_capture})
        # magic_map is just a convenient way of performing magic, er, I
        # mean referencing filetypes that match the supported magic numbers.
        for Type in self.supported_magic:
            self.magic_map.update({Type.re_header: Type})

    def remove_magic(self, filetype):
        """
        Removes the given *filetype* from :attr:`self.supported_magic`,
        :attr:`self.magic`, and :attr:`self.magic_map`.

        *filetype* may be the specific filetype class or a string that can be
        either a filetype.name or filetype.mimetype.
        """
        found = None
        if isinstance(filetype, basestring):
            for Type in self.supported_magic:
                if Type.name == filetype:
                    found = Type
                    break
                elif Type.mimetype == filetype:
                    found = Type
                    break
        else:
            for Type in self.supported_magic:
                if Type == filetype:
                    found = Type
                    break
        if not found:
            raise NotFoundError("%s not found in supported magic" % filetype)
        self.supported_magic.remove(Type)
        del self.magic[Type.re_header]
        del self.magic_map[Type.re_header]

    def update_magic(self, filetype, mimetype):
        """
        Replaces an existing FileType with the given *mimetype* in
        :attr:`self.supported_magic` with the given *filetype*.  Example::

            >>> import terminal
            >>> term = terminal.Terminal()
            >>> class NewPDF = class(terminal.PDFile)
            >>> # Open PDFs immediately in a new window
            >>> NewPDF.html_template = "<script>window.open({link})</script>"
            >>> NewPDF.html_icon_template = NewPDF.html_template # Ignore icon
            >>> term.update_magic(NewPDF, mimetype="application/pdf")
        """
        # Find the matching magic filetype
        for i, Type in enumerate(self.supported_magic):
            if Type.mimetype == mimetype:
                break
        # Replace self.magic and self.magic_map
        del self.magic[Type.re_header]
        del self.magic_map[Type.re_header]
        self.magic.update({filetype.re_header: filetype.re_capture})
        self.magic_map.update({filetype.re_header: filetype})
        # Finally replace the existing filetype in supported_magic
        self.supported_magic[i] = filetype

    def init_screen(self):
        """
        Fills :attr:`screen` with empty lines of (unicode) spaces using
        :attr:`self.cols` and :attr:`self.rows` for the dimensions.

        .. note:: Just because each line starts out with a uniform length does not mean it will stay that way.  Processing of escape sequences is handled when an output function is called.
        """
        logging.debug('init_screen()')
        self.screen = [array('u', u' ' * self.cols) for a in xrange(self.rows)]
        # Tabstops
        self.tabstops = set(range(7, self.cols, 8))
        # Base cursor position
        self.cursorX = 0
        self.cursorY = 0
        self.rendition_set = False

    def init_renditions(self, rendition=unichr(1000)): # Match unicode_counter
        """
        Replaces :attr:`self.renditions` with arrays of *rendition* (characters)
        using :attr:`self.cols` and :attr:`self.rows` for the dimenions.
        """
        logging.debug(
            "init_renditions(%s)" % rendition.encode('unicode_escape'))
        # The actual renditions at various coordinates:
        self.renditions = [
            array('u', rendition * self.cols) for a in xrange(self.rows)]

    def init_scrollback(self):
        """
        Empties the scrollback buffers (:attr:`self.scrollback_buf` and
        :attr:`self.scrollback_renditions`).
        """
        self.scrollback_buf = []
        self.scrollback_renditions = []

    def add_callback(self, event, callback, identifier=None):
        """
        Attaches the given *callback* to the given *event*.  If given,
        *identifier* can be used to reference this callback leter (e.g. when you
        want to remove it).  Otherwise an identifier will be generated
        automatically.  If the given *identifier* is already attached to a
        callback at the given event that callback will be replaced with
        *callback*.

            :event: The numeric ID of the event you're attaching *callback* to. The :ref:`callback constants <callback_constants>` should be used as the numerical IDs.
            :callback: The function you're attaching to the *event*.
            :identifier: A string or number to be used as a reference point should you wish to remove or update this callback later.

        Returns the identifier of the callback.  to Example::

            >>> term = Terminal()
            >>> def somefunc(): pass
            >>> id = "myref"
            >>> ref = term.add_callback(term.CALLBACK_BELL, somefunc, id)

        .. note:: This allows the controlling program to have multiple callbacks for the same event.
        """
        if not identifier:
            identifier = callback.__hash__()
        self.callbacks[event][identifier] = callback
        return identifier

    def remove_callback(self, event, identifier):
        """
        Removes the callback referenced by *identifier* that is attached to the
        given *event*.  Example::

            >>> term.remove_callback(CALLBACK_BELL, "myref")
        """
        del self.callbacks[event][identifier]

    def remove_all_callbacks(self, identifier):
        """
        Removes all callbacks associated with *identifier*.
        """
        for event, identifiers in self.callbacks.items():
            try:
                del self.callbacks[event][identifier]
            except KeyError:
                pass # No match, no biggie

    def send_message(self, message):
        """
        A convenience function for calling all CALLBACK_MESSAGE callbacks.
        """
        logging.debug('send_message(%s)' % message)
        try:
            for callback in self.callbacks[CALLBACK_MESSAGE].values():
                callback(message)
        except TypeError:
            pass

    def send_update(self):
        """
        A convenience function for calling all CALLBACK_CHANGED callbacks.
        """
        #logging.debug('send_update()')
        try:
            for callback in self.callbacks[CALLBACK_CHANGED].values():
                callback()
        except TypeError:
            pass

    def send_cursor_update(self):
        """
        A convenience function for calling all CALLBACK_CURSOR_POS callbacks.
        """
        #logging.debug('send_cursor_update()')
        try:
            for callback in self.callbacks[CALLBACK_CURSOR_POS].values():
                callback()
        except TypeError:
            pass

    def reset(self, *args, **kwargs):
        """
        Resets the terminal back to an empty screen with all defaults.  Calls
        :meth:`Terminal.callbacks[CALLBACK_RESET]` when finished.

        .. note:: If terminal output has been suspended (e.g. via ctrl-s) this will not un-suspend it (you need to issue ctrl-q to the underlying program to do that).
        """
        logging.debug('reset()')
        self.leds = {
            1: False,
            2: False,
            3: False,
            4: False
        }
        self.expanded_modes = {
            # Important defaults
            '1': False,
            '7': False,
            '25': True,
        }
        self.local_echo = True
        self.title = "Gate One"
        self.esc_buffer = ''
        self.insert_mode = False
        self.rendition_set = False
        self.current_charset = 0
        self.set_G0_charset('B')
        self.set_G1_charset('B')
        self.use_g0_charset()
        self.top_margin = 0
        self.bottom_margin = self.rows - 1
        self.alt_screen = None
        self.alt_renditions = None
        self.alt_cursorX = 0
        self.alt_cursorY = 0
        self.saved_cursorX = 0
        self.saved_cursorY = 0
        self.saved_rendition = [None]
        self.init_screen()
        self.init_renditions()
        self.init_scrollback()
        try:
            for callback in self.callbacks[CALLBACK_RESET].values():
                callback()
        except TypeError:
            pass

    def __ignore(self, *args, **kwargs):
        """
        Does nothing (on purpose!).  Used as a placeholder for unimplemented
        functions.
        """
        pass

    def resize(self, rows, cols, em_dimensions=None):
        """
        Resizes the terminal window, adding or removing *rows* or *cols* as
        needed.  If *em_dimensions* are provided they will be stored in
        *self.em_dimensions* (which is currently only used by image output).
        """
        logging.debug(
            "resize(%s, %s, em_dimensions: %s)" % (rows, cols, em_dimensions))
        if em_dimensions:
            self.em_dimensions = em_dimensions
        if rows == self.rows and cols == self.cols:
            return # Nothing to do--don't mess with the margins or the cursor
        if rows < self.rows: # Remove rows from the top
            for i in xrange(self.rows - rows):
                line = self.screen.pop(0)
                # Add it to the scrollback buffer so it isn't lost forever
                self.scrollback_buf.append(line)
                rend = self.renditions.pop(0)
                self.scrollback_renditions.append(rend)
        elif rows > self.rows: # Add rows at the bottom
            for i in xrange(rows - self.rows):
                line = array('u', u' ' * self.cols)
                renditions = array('u', unichr(1000) * self.cols)
                self.screen.append(line)
                self.renditions.append(renditions)
        self.rows = rows
        self.top_margin = 0
        self.bottom_margin = self.rows - 1
        # Fix the cursor location:
        if self.cursorY >= self.rows:
            self.cursorY = self.rows - 1
        if cols > self.cols: # Add cols to the right
            for i in xrange(self.rows):
                for j in xrange(cols - self.cols):
                    self.screen[i].append(u' ')
                    self.renditions[i].append(unichr(1000))
        self.cols = cols

        # Fix the cursor location:
        if self.cursorX >= self.cols:
            self.cursorX = self.cols - 1
        self.rendition_set = False

    def _set_top_bottom(self, settings):
        """
        DECSTBM - Sets :attr:`self.top_margin` and :attr:`self.bottom_margin`
        using the provided settings in the form of '<top_margin>;<bottom_margin>'.

        .. note:: This also handles restore/set "DEC Private Mode Values".
        """
        #logging.debug("_set_top_bottom(%s)" % settings)
        # NOTE: Used by screen and vi so this needs to work and work well!
        if len(settings):
            if settings.startswith('?'):
                # This is a set/restore DEC PMV sequence
                return # Ignore (until I figure out what this should do)
            top, bottom = settings.split(';')
            self.top_margin = max(0, int(top) - 1) # These are 0-based
            if bottom:
                self.bottom_margin = min(self.rows - 1, int(bottom) - 1)
        else:
            # Reset to defaults (full screen margins)
            self.top_margin, self.bottom_margin = 0, self.rows - 1

    def get_cursor_position(self):
        """
        Returns the current cursor positition as a tuple::

            (row, col)
        """
        return (self.cursorY, self.cursorX)

    def set_title(self, title):
        """
        Sets :attr:`self.title` to *title* and executes
        :meth:`Terminal.callbacks[CALLBACK_TITLE]`
        """
        self.title = title
        try:
            for callback in self.callbacks[CALLBACK_TITLE].values():
                callback()
        except TypeError as e:
            logging.error(_("Got TypeError on CALLBACK_TITLE..."))
            logging.error(repr(self.callbacks[CALLBACK_TITLE]))
            logging.error(e)

    def get_title(self):
        """Returns :attr:`self.title`"""
        return self.title

# TODO: put some logic in these save/restore functions to walk the current
# rendition line to come up with a logical rendition for that exact spot.
    def save_cursor_position(self, mode=None):
        """
        Saves the cursor position and current rendition settings to
        :attr:`self.saved_cursorX`, :attr:`self.saved_cursorY`, and
        :attr:`self.saved_rendition`

        .. note:: Also handles the set/restore "Private Mode Settings" sequence.
        """
        if mode: # Set DEC private mode
            # TODO: Need some logic here to save the current expanded mode
            #       so we can restore it in _set_top_bottom().
            self.set_expanded_mode(mode)
        # NOTE: args and kwargs are here to make sure we don't get an exception
        #       when we're called via escape sequences.
        self.saved_cursorX = self.cursorX
        self.saved_cursorY = self.cursorY
        self.saved_rendition = self.cur_rendition

    def restore_cursor_position(self, *args, **kwargs):
        """
        Restores the cursor position and rendition settings from
        :attr:`self.saved_cursorX`, :attr:`self.saved_cursorY`, and
        :attr:`self.saved_rendition` (if they're set).
        """
        if self.saved_cursorX and self.saved_cursorY:
            self.cursorX = self.saved_cursorX
            self.cursorY = self.saved_cursorY
            self.cur_rendition = self.saved_rendition

    def _dsr_get_cursor_position(self):
        """
        Returns the current cursor positition as a DSR response in the form of::

            '\x1b<self.cursorY>;<self.cursorX>R'

        Also executes CALLBACK_DSR with the same output as the first argument.
        Example::

            self.callbacks[CALLBACK_DSR]('\x1b20;123R')
        """
        esc_cursor_pos = '\x1b%s;%sR' % (self.cursorY, self.cursorX)
        try:
            for callback in self.callbacks[CALLBACK_DSR].values():
                callback(esc_cursor_pos)
        except TypeError:
            pass
        return esc_cursor_pos

    def _dcs_handler(self, string=None):
        """
        Handles Device Control String sequences.  Unimplemented.  Probablye not
        appropriate for Gate One.  If you believe this to be false please open
        a ticket in the issue tracker.
        """
        pass
        #print("TODO: Handle this DCS: %s" % string)

    def _set_line_params(self, param):
        """
        This function handles the control sequences that set double and single
        line heights and widths.  It also handles the "screen alignment test" (
        fill the screen with Es).

        .. note::

            Double-line height text is currently unimplemented (does anything
            actually use it?).
        """
        try:
            param = int(param)
        except ValueError:
            logging.warning("Couldn't handle escape sequence #%s" % repr(param))
        if param == 8:
            # Screen alignment test
            self.init_renditions()
            self.screen = [
                array('u', u'E' * self.cols) for a in xrange(self.rows)]
        # TODO: Get this handling double line height stuff...  For kicks

    def set_G0_charset(self, char):
        """
        Sets the terminal's G0 (default) charset to the type specified by
        *char*.

        Here's the possibilities::

            0    DEC Special Character and Line Drawing Set
            A    United Kingdom (UK)
            B    United States (USASCII)
            4    Dutch
            C    Finnish
            5    Finnish
            R    French
            Q    French Canadian
            K    German
            Y    Italian
            E    Norwegian/Danish
            6    Norwegian/Danish
            Z    Spanish
            H    Swedish
            7    Swedish
            =    Swiss
        """
        #logging.debug("Setting G0 charset to %s" % repr(char))
        try:
            self.G0_charset = self.charsets[char]
        except KeyError:
            self.G0_charset = self.charsets['B']
        if self.current_charset == 0:
            self.charset = self.G0_charset

    def set_G1_charset(self, char):
        """
        Sets the terminal's G1 (alt) charset to the type specified by *char*.

        Here's the possibilities::

            0    DEC Special Character and Line Drawing Set
            A    United Kingdom (UK)
            B    United States (USASCII)
            4    Dutch
            C    Finnish
            5    Finnish
            R    French
            Q    French Canadian
            K    German
            Y    Italian
            E    Norwegian/Danish
            6    Norwegian/Danish
            Z    Spanish
            H    Swedish
            7    Swedish
            =    Swiss
        """
        #logging.debug("Setting G1 charset to %s" % repr(char))
        try:
            self.G1_charset = self.charsets[char]
        except KeyError:
            self.G1_charset = self.charsets['B']
        if self.current_charset == 1:
            self.charset = self.G1_charset

    def use_g0_charset(self):
        """
        Sets the current charset to G0.  This should get called when ASCII_SO
        is encountered.
        """
        #logging.debug(
            #"Switching to G0 charset (which is %s)" % repr(self.G0_charset))
        self.current_charset = 0
        self.charset = self.G0_charset

    def use_g1_charset(self):
        """
        Sets the current charset to G1.  This should get called when ASCII_SI
        is encountered.
        """
        #logging.debug(
            #"Switching to G1 charset (which is %s)" % repr(self.G1_charset))
        self.current_charset = 1
        self.charset = self.G1_charset

    def abort_capture(self):
        """
        A convenience function that takes care of canceling a file capture and
        cleaning up the output.
        """
        logging.debug('abort_capture()')
        self.cancel_capture = True
        self.write(b'\x00') # This won't actually get written
        self.send_update()
        self.send_message(_(u'File capture aborted.'))

    def write(self, chars, special_checks=True):
        """
        Write *chars* to the terminal at the current cursor position advancing
        the cursor as it does so.  If *chars* is not unicode, it will be
        converted to unicode before being stored in self.screen.

        if *special_checks* is True (default), Gate One will perform checks for
        special things like image files coming in via *chars*.
        """
        # NOTE: This is the slowest function in all of Gate One.  All
        # suggestions on how to speed it up are welcome!

        # Speedups (don't want dots in loops if they can be avoided)
        specials = self.specials
        esc_handlers = self.esc_handlers
        csi_handlers = self.csi_handlers
        RE_ESC_SEQ = self.RE_ESC_SEQ
        RE_CSI_ESC_SEQ = self.RE_CSI_ESC_SEQ
        magic = self.magic
        magic_map = self.magic_map
        changed = False
        # This is commented because of how noisy it is.  Uncomment to debug the
        # terminal emualtor:
        #logging.debug('handling chars: %s' % repr(chars))
        # Only perform special checks (for FileTYpe stuff) if we're given bytes.
        # Incoming unicode chars should NOT be binary data.
        if not isinstance(chars, bytes):
            special_checks = False
        if special_checks:
            before_chars = b""
            after_chars = b""
            if not self.capture:
                for magic_header in magic:
                    try:
                        if magic_header.match(chars):
                            self.matched_header = magic_header
                            self.timeout_capture = datetime.now()
                            self.progress_timer = datetime.now()
                            # Create an instance of the filetype
                            self._filetype_instance()
                            break
                    except UnicodeEncodeError:
                        # Gibberish; drop it and pretend it never happened
                        logging.debug(_(
                            "Got UnicodeEncodeError trying to check FileTypes"))
                        self.esc_buffer = ""
                        # Make it so it won't barf below
                        chars = chars.encode(self.encoding, 'ignore')
            if self.capture or self.matched_header:
                self.capture += chars
                if self.cancel_capture:
                    # Try to split the garbage from the post-ctrl-c output
                    split_capture = self.RE_SIGINT.split(self.capture)
                    after_chars = split_capture[-1]
                    self.capture = b''
                    self.matched_header = None
                    self.cancel_capture = False
                    self.write(u'^C\r\n', special_checks=False)
                    self.write(after_chars, special_checks=False)
                    return
                ref = self.screen[self.cursorY][self.cursorX]
                ft_instance = self.captured_files[ref]
                if ft_instance.helper:
                    ft_instance.helper(self)
                now = datetime.now()
                if now - self.progress_timer > self.message_interval:
                    # Send an update of the progress to the user
                    # NOTE: This message will only get sent if it takes longer
                    # than self.message_interval to capture a file.  So it is
                    # nice and user friendly:  Small things output instantly
                    # without notifications while larger files that take longer
                    # to capture will keep the user abreast of the progress.
                    ft = magic_map[self.matched_header].name
                    indicator = 'K'
                    size = float(len(self.capture))/1024 # Kb
                    if size > 1024: # Switch to Mb
                        size = size/1024
                        indicator = 'M'
                    message = _(
                        "%s: %.2f%s captured..." % (ft, size, indicator))
                    self.notified = True
                    self.send_message(message)
                    self.progress_timer = datetime.now()
                match = ft_instance.re_capture.search(self.capture)
                if match:
                    logging.debug(
                        "Matched %s format (%s, %s).  Capturing..." % (
                        self.magic_map[self.matched_header].name,
                        self.cursorY, self.cursorX))
                    split_capture = ft_instance.re_capture.split(self.capture,1)
                    before_chars = split_capture[0]
                    self.capture = split_capture[1]
                    after_chars = b"".join(split_capture[2:])
                if after_chars:
                    is_container = magic_map[self.matched_header].is_container
                    if is_container and len(after_chars) > 500:
                        # Could be more to this file.  Let's wait until output
                        # slows down before attempting to perform a match
                        logging.debug(
                            "> 500 characters after capture.  Waiting for more")
                        return
                    else:
                        # These need to be written before the capture so that
                        # the FileType.capture() method can position things
                        # appropriately.
                        if before_chars:
                            # Empty out self.capture temporarily so these chars
                            # get handled properly
                            cap_temp = self.capture
                            self.capture = b""
                            # This will overwrite our ref:
                            self.write(before_chars, special_checks=False)
                            # Put it back for the rest of the processing
                            self.capture = cap_temp
                        # Perform the capture and start anew
                        self._capture_file(ref)
                        if self.notified:
                            # Send a final notice of how big the file was (just
                            # to keep things consistent).
                            ft = magic_map[self.matched_header].name
                            indicator = 'K'
                            size = float(len(self.capture))/1024 # Kb
                            if size > 1024: # Switch to Mb
                                size = size/1024
                                indicator = 'M'
                            message = _(
                                "%s: Capture complete (%.2f%s)" % (
                                ft, size, indicator))
                            self.notified = False
                            self.send_message(message)
                        self.capture = b"" # Empty it now that is is captured
                        self.matched_header = None # Ditto
                    self.write(after_chars, special_checks=True)
                    return
                return
        # Have to convert to unicode
        try:
            chars = chars.decode(self.encoding, "handle_special")
        except UnicodeDecodeError:
            # Just in case
            try:
                chars = chars.decode(self.encoding, "ignore")
            except UnicodeDecodeError:
                logging.error(
                    _("Double UnicodeDecodeError in terminal.Terminal."))
                return
        except AttributeError:
            # In Python 3 strings don't have .decode()
            pass # Already Unicode
        for char in chars:
            charnum = ord(char)
            if charnum in specials:
                specials[charnum]()
            else:
                # Now handle the regular characters and escape sequences
                if self.esc_buffer: # We've got an escape sequence going on...
                    try:
                        self.esc_buffer += char
                        # First try to handle non-CSI ESC sequences (the basics)
                        match_obj = RE_ESC_SEQ.match(self.esc_buffer)
                        if match_obj:
                            seq_type = match_obj.group(1) # '\x1bA' -> 'A'
                            # Call the matching ESC handler
                            #logging.debug('ESC seq: %s' % seq_type)
                            if len(seq_type) == 1: # Single-character sequnces
                                esc_handlers[seq_type]()
                            else: # Multi-character stuff like '\x1b)B'
                                esc_handlers[seq_type[0]](seq_type[1:])
                            self.esc_buffer = '' # All done with this one
                            continue
                        # Next try to handle CSI ESC sequences
                        match_obj = RE_CSI_ESC_SEQ.match(self.esc_buffer)
                        if match_obj:
                            csi_values = match_obj.group(1) # e.g. '0;1;37'
                            csi_type = match_obj.group(2) # e.g. 'm'
                            #logging.debug(
                                #'CSI: %s, %s' % (csi_type, csi_values))
                            # Call the matching CSI handler
                            try:
                                csi_handlers[csi_type](csi_values)
                            except ValueError:
                            # Commented this out because it can be super noisy
                                #logging.error(_(
                                    #"CSI Handler Error: Type: %s, Values: %s" %
                                    #(csi_type, csi_values)
                                #))
                                pass
                            self.esc_buffer = ''
                            continue
                    except KeyError:
                        # No handler for this, try some alternatives
                        if self.esc_buffer.endswith('\x1b\\'):
                            self._osc_handler()
                        else:
                            logging.warning(_(
                                "Warning: No ESC sequence handler for %s"
                                % `self.esc_buffer`
                            ))
                            self.esc_buffer = ''
                    continue # We're done here
                changed = True
                if self.cursorX >= self.cols:
                    self.cursorX = 0
                    self.newline()
                    # Non-autowrap has been disabled due to issues with browser
                    # wrapping.
                    #if self.expanded_modes['7']:
                        #self.cursorX = 0
                        #self.newline()
                    #else:
                        #self.screen[self.cursorY].append(u' ') # Make room
                        #self.renditions[self.cursorY].append(u' ')
                try:
                    self.renditions[self.cursorY][
                        self.cursorX] = self.cur_rendition
                    if self.insert_mode:
                        # Insert mode dictates that we move everything to the
                        # right for every character we insert.  Normally the
                        # program itself will take care of this but older
                        # programs and shells will simply set call ESC[4h,
                        # insert the character, then call ESC[4i to return the
                        # terminal to its regular state.
                        self.insert_characters(1)
                    if charnum in self.charset:
                        char = self.charset[charnum]
                        self.screen[self.cursorY][self.cursorX] = char
                    else:
                        # Double check this isn't a unicode diacritic (accent)
                        # which simply modifies the character before it
                        if unicodedata.combining(char):
                            # This is a diacritic.  Combine it with existing:
                            current = self.screen[self.cursorY][self.cursorX]
                            combined = unicodedata.normalize(
                                'NFC', u'%s%s' % (current, char))
                            # Sometimes a joined combining char can still result
                            # a string of length > 1.  So we need to handle that
                            if len(combined) > 1:
                                for i, c in enumerate(combined):
                                    self.screen[self.cursorY][
                                        self.cursorX] = c
                                    if i < len(combined) - 1:
                                        self.cursorX += 1
                            else:
                                self.screen[self.cursorY][
                                    self.cursorX] = combined
                        else:
                            # Normal character
                            self.screen[self.cursorY][self.cursorX] = char
                except IndexError as e:
                    # This can happen when escape sequences go haywire
                    # Only log the error if debugging is enabled (because we
                    # really don't care that much 99% of the time)
                    logger = logging.getLogger()
                    if logger.level < 20:
                        logging.error(_(
                            "IndexError in write(): %s" % e))
                        import traceback, sys
                        traceback.print_exc(file=sys.stdout)
                self.cursorX += 1
                #self.cursor_right()
            self.prev_char = char
        if changed:
            self.modified = True
            # Execute our callbacks
            self.send_update()
            self.send_cursor_update()

    def flush(self):
        """
        Only here to make Terminal compatible with programs that want to use
        file-like methods.
        """
        pass

    def scroll_up(self, n=1):
        """
        Scrolls up the terminal screen by *n* lines (default: 1). The callbacks
        CALLBACK_CHANGED and CALLBACK_SCROLL_UP are called after scrolling the
        screen.

        .. note::

            This will only scroll up the region within `self.top_margin` and
            `self.bottom_margin` (if set).
        """
        #logging.debug("scroll_up(%s)" % n)
        empty_line = array('u', u' ' * self.cols) # Line full of spaces
        empty_rend = array('u', unichr(1000) * self.cols)
        for x in xrange(int(n)):
            line = self.screen.pop(self.top_margin) # Remove the top line
            self.scrollback_buf.append(line) # Add it to the scrollback buffer
            if len(self.scrollback_buf) > self.max_scrollback:
                self.init_scrollback()
                # NOTE:  This would only be the # of lines piled up before the
                # next dump_html() or dump().
            # Add it to the bottom of the window:
            self.screen.insert(self.bottom_margin, empty_line[:]) # A copy
            # Remove top line's rendition information
            rend = self.renditions.pop(self.top_margin)
            self.scrollback_renditions.append(rend)
            # Insert a new empty rendition as well:
            self.renditions.insert(self.bottom_margin, empty_rend[:])
        # Execute our callback indicating lines have been updated
        try:
            for callback in self.callbacks[CALLBACK_CHANGED].values():
                callback()
        except TypeError:
            pass
        # Execute our callback to scroll up the screen
        try:
            for callback in self.callbacks[CALLBACK_SCROLL_UP].values():
                callback()
        except TypeError:
            pass

    def scroll_down(self, n=1):
        """
        Scrolls down the terminal screen by *n* lines (default: 1). The
        callbacks CALLBACK_CHANGED and CALLBACK_SCROLL_DOWN are called after
        scrolling the screen.
        """
        #logging.debug("scroll_down(%s)" % n)
        for x in xrange(int(n)):
            self.screen.pop(self.bottom_margin) # Remove the bottom line
            empty_line = array('u', u' ' * self.cols) # Line full of spaces
            self.screen.insert(self.top_margin, empty_line) # Add it to the top
            # Remove bottom line's style information:
            self.renditions.pop(self.bottom_margin)
            # Insert a new empty one:
            empty_line = array('u', unichr(1000) * self.cols)
            self.renditions.insert(self.top_margin, empty_line)
        # Execute our callback indicating lines have been updated
        try:
            for callback in self.callbacks[CALLBACK_CHANGED].values():
                callback()
        except TypeError:
            pass

        # Execute our callback to scroll up the screen
        try:
            for callback in self.callbacks[CALLBACK_SCROLL_UP].values():
                callback()
        except TypeError:
            pass

    def insert_line(self, n=1):
        """
        Inserts *n* lines at the current cursor position.
        """
        #logging.debug("insert_line(%s)" % n)
        if not n: # Takes care of an empty string
            n = 1
        n = int(n)
        for i in xrange(n):
            self.screen.pop(self.bottom_margin) # Remove the bottom line
            # Remove bottom line's style information as well:
            self.renditions.pop(self.bottom_margin)
            empty_line = array('u', u' ' * self.cols) # Line full of spaces
            self.screen.insert(self.cursorY, empty_line) # Insert at cursor
            # Insert a new empty rendition as well:
            empty_rend = array('u', unichr(1000) * self.cols)
            self.renditions.insert(self.cursorY, empty_rend) # Insert at cursor

    def delete_line(self, n=1):
        """
        Deletes *n* lines at the current cursor position.
        """
        #logging.debug("delete_line(%s)" % n)
        if not n: # Takes care of an empty string
            n = 1
        n = int(n)
        for i in xrange(n):
            self.screen.pop(self.cursorY) # Remove the line at the cursor
            # Remove the line's style information as well:
            self.renditions.pop(self.cursorY)
            # Now add an empty line and empty set of renditions to the bottom of
            # the view
            empty_line = array('u', u' ' * self.cols) # Line full of spaces
            # Add it to the bottom of the view:
            self.screen.insert(self.bottom_margin, empty_line) # Insert at bottom
            # Insert a new empty rendition as well:
            empty_rend = array('u', unichr(1000) * self.cols)
            self.renditions.insert(self.bottom_margin, empty_rend)

    def backspace(self):
        """Execute a backspace (\\x08)"""
        self.cursor_left(1)

    def horizontal_tab(self):
        """Execute horizontal tab (\\x09)"""
        for stop in sorted(self.tabstops):
            if self.cursorX < stop:
                self.cursorX = stop + 1
                break
        else:
            self.cursorX = self.cols - 1

    def _set_tabstop(self):
        """Sets a tabstop at the current position of :attr:`self.cursorX`."""
        if self.cursorX not in self.tabstops:
            for tabstop in self.tabstops:
                if self.cursorX > tabstop:
                    self.tabstops.add(self.cursorX)
                    break

    def linefeed(self):
        """
        LF - Executes a line feed.

        .. note:: This actually just calls :meth:`Terminal.newline`.
        """
        self.newline()

    def next_line(self):
        """
        CNL - Moves the cursor down one line to the home position.  Will not
        result in a scrolling event like newline() does.

        .. note:: This is not the same thing as :meth:`Terminal.cursor_next_line` which preserves the cursor's column position.
        """
        self.cursorX = self.cursor_home
        if self.cursorY < self.rows -1:
            self.cursorY += 1

    def reverse_linefeed(self):
        """
        RI - Executes a reverse line feed: Move the cursor up one line to the
        home position.  If the cursor move would result in going past the top
        margin of the screen (upwards) this will execute a scroll_down() event.
        """
        self.cursorX = 0
        self.cursorY -= 1
        if self.cursorY < self.top_margin:
            self.scroll_down()
            self.cursorY = self.top_margin

    def newline(self):
        """
        Increases :attr:`self.cursorY` by 1 and calls :meth:`Terminal.scroll_up`
        if that action will move the curor past :attr:`self.bottom_margin`
        (usually the bottom of the screen).
        """
        cols = self.cols
        self.cursorY += 1
        if self.cursorY > self.bottom_margin:
            self.scroll_up()
            self.cursorY = self.bottom_margin
            self.clear_line()
        # Shorten the line if it is longer than the number of columns
        # NOTE: This lets us keep the width of existing lines even if the number
        # of columns is reduced while at the same time accounting for apps like
        # 'top' that merely overwrite existing lines.  If we didn't do this
        # the output from 'top' would get all messed up from leftovers at the
        # tail end of every line when self.cols had a larger value.
        if len(self.screen[self.cursorY]) >= cols:
            self.screen[self.cursorY] = self.screen[self.cursorY][:cols]
            self.renditions[self.cursorY] = self.renditions[self.cursorY][:cols]
        # NOTE: The above logic is placed inside of this function instead of
        # inside self.write() in order to reduce CPU utilization.  There's no
        # point in performing a conditional check for every incoming character
        # when the only time it will matter is when a newline is being written.

    def carriage_return(self):
        """
        Executes a carriage return (sets :attr:`self.cursorX` to 0).  In other
        words it moves the cursor back to position 0 on the line.
        """
        if self.cursorX == 0:
            return # Nothing to do
        if divmod(self.cursorX, self.cols+1)[1] == 0:
            # A carriage return at the precise end of line means the program is
            # assuming vt100-style autowrap.  Since we let the browser handle
            # that we need to discard this carriage return since we're not
            # actually making a newline.
            if self.prev_char not in [u'\x1b', u'\n']:
                # These are special cases where the underlying shell is assuming
                # autowrap so we have to emulate it.
                self.newline()
            else:
                return
        if not self.capture:
            self.cursorX = 0

    def _xon(self):
        """
        Handles the XON character (stop ignoring).

        .. note:: Doesn't actually do anything (this feature was probably meant for the underlying terminal program).
        """
        logging.debug('_xon()')
        self.local_echo = True

    def _xoff(self):
        """
        Handles the XOFF character (start ignoring)

        .. note:: Doesn't actually do anything (this feature was probably meant for the underlying terminal program).
        """
        logging.debug('_xoff()')
        self.local_echo = False

    def _cancel_esc_sequence(self):
        """
        Cancels any escape sequence currently being processed.  In other words
        it empties :attr:`self.esc_buffer`.
        """
        self.esc_buffer = ''

    def _sub_esc_sequence(self):
        """
        Cancels any escape sequence currently in progress and replaces
        :attr:`self.esc_buffer` with single question mark (?).

        .. note:: Nothing presently uses this function and I can't remember what it was supposed to be part of (LOL!).  Obviously it isn't very important.
        """
        self.esc_buffer = ''
        self.write('?')

    def _escape(self):
        """
        Handles the escape character as well as escape sequences that may end
        with an escape character.
        """
        buf = self.esc_buffer
        if buf.startswith('\x1bP') or buf.startswith('\x1b]'):
            # CSRs and OSCs are special
            self.esc_buffer += '\x1b'
        else:
            # Get rid of whatever's there since we obviously didn't know what to
            # do with it
            self.esc_buffer = '\x1b'

    def _csi(self):
        """
        Marks the start of a CSI escape sequence (which is itself a character)
        by setting :attr:`self.esc_buffer` to '\\\\x1b[' (which is the CSI
        escape sequence).
        """
        self.esc_buffer = '\x1b['

    def _filetype_instance(self):
        """
        Instantiates a new instance of the given :class:`FileType` (using
        `self.matched_header`) and stores the result in `self.captured_files`
        and creates a reference to that location at the current cursor location.
        """
        ref = self.file_counter.next()
        logging.debug("_filetype_instance(%s)" % repr(ref))
        # Before doing anything else we need to mark the current cursor
        # location as belonging to our file
        self.screen[self.cursorY][self.cursorX] = ref
        # Create an instance of the filetype we can reference
        filetype_instance = self.magic_map[self.matched_header](
            path=self.temppath,
            linkpath=self.linkpath,
            icondir=self.icondir)
        self.captured_files[ref] = filetype_instance

    def _capture_file(self, ref):
        """
        This function gets called by :meth:`Terminal.write` when the incoming
        character stream matches a value in :attr:`self.magic`.  It will call
        whatever function is associated with the matching regex in
        :attr:`self.magic_map`.  It also stores the current file capture
        reference (*ref*) at the current cursor location.
        """
        logging.debug("_capture_file(%s)" % repr(ref))
        self.screen[self.cursorY][self.cursorX] = ref
        filetype_instance = self.captured_files[ref]
        filetype_instance.capture(self.capture, self)
        # Start up an open file watcher so leftover file objects get
        # closed when they're no longer being used
        if not self.watcher or not self.watcher.isAlive():
            import threading
            self.watcher = threading.Thread(
                name='watcher', target=self._captured_fd_watcher)
            self.watcher.setDaemon(True)
            self.watcher.start()
        return

    def _captured_fd_watcher(self):
        """
        Meant to be run inside of a thread, calls
        :meth:`Terminal.close_captured_fds` until there are no more open image
        file descriptors.
        """
        logging.debug("starting _captured_fd_watcher()")
        import time
        self.quitting = False
        while not self.quitting:
            if self.captured_files:
                self.close_captured_fds()
                time.sleep(5)
            else:
                self.quitting = True
        logging.debug('_captured_fd_watcher() quitting: No more images.')

    def close_captured_fds(self):
        """
        Closes the file descriptors of any captured files that are no longer on
        the screen.
        """
        #logging.debug('close_captured_fds()') # Commented because it's kinda noisy
        if self.captured_files:
            for ref in list(self.captured_files.keys()):
                found = False
                for line in self.screen:
                    if ref in line:
                        found = True
                        break
                if self.alt_screen:
                    for line in self.alt_screen:
                        if ref in line:
                            found = True
                            break
                if not found:
                    try:
                        self.captured_files[ref].close()
                    except AttributeError:
                        pass # File already closed or never captured properly
                    del self.captured_files[ref]

    def _string_terminator(self):
        """
        Handle the string terminator (ST).

        .. note:: Doesn't actually do anything at the moment.  Probably not needed since :meth:`Terminal._escape` and/or :meth:`Terminal.bell` will end up handling any sort of sequence that would end in an ST anyway.
        """
        # NOTE: Might this just call _cancel_esc_sequence?  I need to double-check.
        pass

    def _osc_handler(self):
        """
        Handles Operating System Command (OSC) escape sequences which need
        special care since they are of indeterminiate length and end with
        either a bell (\\\\x07) or a sequence terminator (\\\\x9c aka ST).  This
        will usually be called from :meth:`Terminal.bell` to set the title of
        the terminal (just like an xterm) but it is also possible to be called
        directly whenever an ST is encountered.
        """
        # Try the title sequence first
        match_obj = self.RE_TITLE_SEQ.match(self.esc_buffer)
        if match_obj:
            self.esc_buffer = ''
            title = match_obj.group(1)
            self.set_title(title) # Sets self.title
            return
        # Next try our special optional handler sequence
        match_obj = self.RE_OPT_SEQ.match(self.esc_buffer)
        if match_obj:
            self.esc_buffer = ''
            text = match_obj.group(1)
            self._opt_handler(text)
            return
        # At this point we've encountered something unusual
        logging.warning(_("Warning: No special ESC sequence handler for %s" %
            repr(self.esc_buffer)))
        self.esc_buffer = ''

    def bell(self):
        """
        Handles the bell character and executes
        :meth:`Terminal.callbacks[CALLBACK_BELL]` (if we are not in the middle
        of an escape sequence that ends with a bell character =).  If we *are*
        in the middle of an escape sequence, calls :meth:`self._osc_handler`
        since we can be nearly certain that we're simply terminating an OSC
        sequence. Isn't terminal emulation grand? _
        """
        # NOTE: A little explanation is in order: The bell character (\x07) by
        #       itself should play a bell (pretty straighforward).  However, if
        #       the bell character is at the tail end of a particular escape
        #       sequence (string starting with \x1b]0;) this indicates an xterm
        #       title (everything between \x1b]0;...\x07).
        if not self.esc_buffer: # We're not in the middle of an esc sequence
            logging.debug('Regular bell')
            try:
                for callback in self.callbacks[CALLBACK_BELL].values():
                    callback()
            except TypeError:
                pass
        else: # We're (likely) setting a title
            self.esc_buffer += '\x07' # Add the bell char so we don't lose it
            self._osc_handler()

    def _device_status_report(self, n=None):
        """
        Returns '\\\\x1b[0n' (terminal OK) and executes:

        .. code-block:: python

            self.callbacks[CALLBACK_DSR]("\\x1b[0n")
        """
        logging.debug("_device_status_report()")
        response = u"\x1b[0n"
        try:
            for callback in self.callbacks[CALLBACK_DSR].values():
                callback(response)
        except TypeError:
            pass
        return response

    def _csi_device_identification(self, request=None):
        """
        If we're responding to ^[Z, ^[c, or ^[0c, returns '\\\\x1b[1;2c'
        (Meaning: I'm a vt220 terminal, version 1.0) and
        executes:

        .. code-block:: python

            self.callbacks[self.CALLBACK_DSR]("\\x1b[1;2c")

        If we're responding to ^[>c or ^[>0c, executes:

        .. code-block:: python

            self.callbacks[self.CALLBACK_DSR]("\\x1b[>0;271;0c")
        """
        logging.debug("_csi_device_identification(%s)" % request)
        if request and u">" in request:
            response = u"\x1b[>0;271;0c"
        else:
            response = u"\x1b[?1;2c"
        try:
            for callback in self.callbacks[CALLBACK_DSR].values():
                callback(response)
        except TypeError:
            pass
        return response

    def _csi_device_status_report(self, request=None):
        """
        Calls :meth:`self.callbacks[self.CALLBACK_DSR]` with an appropriate
        response to the given *request*.

        .. code-block:: python

            self.callbacks[self.CALLBACK_DSR](response)

        Supported requests and their responses:

            =============================    ==================
            Request                          Response
            =============================    ==================
            ^[5n (Status Report)             ^[[0n
            ^[6n (Report Cursor Position)    ^[[<row>;<column>R
            ^[15n (Printer Ready?)           ^[[10n (Ready)
            =============================    ==================
        """
        logging.debug("_csi_device_status_report(%s)" % request)
        supported_requests = [
            u"5",
            u"6",
            u"15",
        ]
        if not request:
            return # Nothing to do
        response = u""
        if request.startswith('?'):
            # Get rid of it
            request = request[1:]
        if request in supported_requests:
            if request == u"5":
                response = u"\x1b[0n"
            elif request == u"6":
                rows = self.cursorY + 1
                cols = self.cursorX + 1
                response = u"\x1b[%s;%sR" % (rows, cols)
            elif request == u"15":
                response = u"\x1b[10n"
        try:
            for callback in self.callbacks[CALLBACK_DSR].values():
                callback(response)
        except TypeError:
            pass
        return response

    def set_expanded_mode(self, setting):
        """
        Accepts "standard mode" settings.  Typically '\\\\x1b[?25h' to hide cursor.

        Notes on modes::

            '?1h' - Application Cursor Keys
            '?5h' - DECSCNM (default off): Set reverse-video mode
            '?7h' - DECAWM: Autowrap mode
            '?12h' - Local echo (SRM or Send Receive Mode)
            '?25h' - Hide cursor
            '?1000h' - Send Mouse X/Y on button press and release
            '?1001h' - Use Hilite Mouse Tracking
            '?1002h' - Use Cell Motion Mouse Tracking
            '?1003h' - Use All Motion Mouse Tracking
            '?1004h' - Send focus in/focus out events
            '?1005h' - Enable UTF-8 Mouse Mode
            '?1006h' - Enable SGR Mouse Mode
            '?1015h' - Enable urxvt Mouse Mode
            '?1049h' - Save cursor and screen
        """
        # TODO: Add support for the following:
        # * 3: 132 column mode (might be "or greater")
        # * 4: Smooth scroll (for animations and also makes things less choppy)
        # * 5: Reverse video (should be easy: just need some extra CSS)
        # * 6: Origin mode
        # * 7: Wraparound mode
        logging.debug("set_expanded_mode(%s)" % setting)
        if setting.startswith('?'):
            # DEC Private Mode Set
            setting = setting[1:] # Don't need the ?
            settings = setting.split(';')
            for setting in settings:
                try:
                    self.expanded_mode_handlers[setting](True)
                except (KeyError, TypeError):
                    pass # Unsupported expanded mode
            try:
                for callback in self.callbacks[CALLBACK_MODE].values():
                    callback(setting, True)
            except TypeError:
                pass
        else:
            # There's a couple mode settings that are just "[Nh" where N==number
            # [2h Keyboard Action Mode (AM)
            # [4h Insert Mode
            # [12h Send/Receive Mode (SRM)
            # [24h Automatic Newline (LNM)
            if setting == '4':
                self.insert_mode = True

    def reset_expanded_mode(self, setting):
        """
        Accepts "standard mode" settings.  Typically '\\\\x1b[?25l' to show
        cursor.
        """
        logging.debug("reset_expanded_mode(%s)" % setting)
        if setting.startswith('?'):
            setting = setting[1:] # Don't need the ?
            settings = setting.split(';')
            for setting in settings:
                try:
                    self.expanded_mode_handlers[setting](False)
                except (KeyError, TypeError):
                    pass # Unsupported expanded mode
            try:
                for callback in self.callbacks[CALLBACK_MODE].values():
                    callback(setting, False)
            except TypeError:
                pass
        else:
            # There's a couple mode settings that are just "[Nh" where N==number
            # [2h Keyboard Action Mode (AM)
            # [4h Insert Mode
            # [12h Send/Receive Mode (SRM)
            # [24h Automatic Newline (LNM)
            # The only one we care about is 4 (insert mode)
            if setting == '4':
                self.insert_mode = False

    def toggle_alternate_screen_buffer(self, alt):
        """
        If *alt* is True, copy the current screen and renditions to
        :attr:`self.alt_screen` and :attr:`self.alt_renditions` then re-init
        :attr:`self.screen` and :attr:`self.renditions`.

        If *alt* is False, restore the saved screen buffer and renditions then
        nullify :attr:`self.alt_screen` and :attr:`self.alt_renditions`.
        """
        #logging.debug('toggle_alternate_screen_buffer(%s)' % alt)
        if alt:
            # Save the existing screen and renditions
            self.alt_screen = self.screen[:]
            self.alt_renditions = self.renditions[:]
            # Make a fresh one
            self.clear_screen()
        else:
            # Restore the screen
            if self.alt_screen and self.alt_renditions:
                self.screen = self.alt_screen[:]
                self.renditions = self.alt_renditions[:]
            # Empty out the alternate buffer (to save memory)
            self.alt_screen = None
            self.alt_renditions = None
        # These all need to be reset no matter what
        self.cur_rendition = unichr(1000)

    def toggle_alternate_screen_buffer_cursor(self, alt):
        """
        Same as :meth:`Terminal.toggle_alternate_screen_buffer` but also
        saves/restores the cursor location.
        """
        #logging.debug('toggle_alternate_screen_buffer_cursor(%s)' % alt)
        if alt:
            self.alt_cursorX = self.cursorX
            self.alt_cursorY = self.cursorY
        else:
            self.cursorX = self.alt_cursorX
            self.cursorY = self.alt_cursorY
        self.toggle_alternate_screen_buffer(alt)

    def expanded_mode_toggle(self, mode, boolean):
        """
        Meant to be used with (simple) expanded mode settings that merely set or
        reset attributes for tracking purposes; sets `self.expanded_modes[mode]`
        to *boolean*.  Example usage::

            >>> self.expanded_mode_handlers['1000'] = partial(self.expanded_mode_toggle, 'mouse_button_events')
        """
        self.expanded_modes[mode] = boolean

    def insert_characters(self, n=1):
        """
        Inserts the specified number of characters at the cursor position.
        Overwriting whatever is already present.
        """
        #logging.debug("insert_characters(%s)" % n)
        n = int(n)
        for i in xrange(n):
            self.screen[self.cursorY].pop() # Take one down, pass it around
            self.screen[self.cursorY].insert(self.cursorX, u' ')

    def delete_characters(self, n=1):
        """
        DCH - Deletes (to the left) the specified number of characters at the
        cursor position.  As characters are deleted, the remaining characters
        between the cursor and right margin move to the left. Character
        attributes (renditions) move with the characters.  The terminal adds
        blank spaces with no visual character attributes at the right margin.
        DCH has no effect outside the scrolling margins.

        .. note:: Deletes renditions too.  You'd *think* that would be in one of the VT-* manuals...  Nope!
        """
        #logging.debug("delete_characters(%s)" % n)
        if not n: # e.g. n == ''
            n = 1
        else:
            n = int(n)
        for i in xrange(n):
            try:
                self.screen[self.cursorY].pop(self.cursorX)
                self.screen[self.cursorY].append(u' ')
                self.renditions[self.cursorY].pop(self.cursorX)
                self.renditions[self.cursorY].append(unichr(1000))
            except IndexError:
                # At edge of screen, ignore
                #print('IndexError in delete_characters(): %s' % e)
                pass

    def _erase_characters(self, n=1):
        """
        Erases (to the right) the specified number of characters at the cursor
        position.

        .. note:: Deletes renditions too.
        """
        #logging.debug("_erase_characters(%s)" % n)
        if not n: # e.g. n == ''
            n = 1
        else:
            n = int(n)
        distance = self.cols - self.cursorX
        n = min(n, distance)
        for i in xrange(n):
            self.screen[self.cursorY][self.cursorX+i] = u' '
            self.renditions[self.cursorY][self.cursorX+i] = unichr(1000)

    def cursor_left(self, n=1):
        """ESCnD CUB (Cursor Back)"""
        # Commented out to save CPU (and the others below too)
        #logging.debug('cursor_left(%s)' % n)
        n = int(n)
        # This logic takes care of double-width unicode characters
        if self.double_width_left:
            self.double_width_left = False
            return
        self.cursorX = max(0, self.cursorX - n) # Ensures positive value
        try:
            char = self.screen[self.cursorY][self.cursorX]
        except IndexError: # Cursor is past the right-edge of the screen; ignore
            char = u' ' # This is a safe default/fallback
        if unicodedata.east_asian_width(char) == 'W':
            # This lets us skip the next call (get called 2x for 2x width)
            self.double_width_left = True
        try:
            for callback in self.callbacks[CALLBACK_CURSOR_POS].values():
                callback()
        except TypeError:
            pass

    def cursor_right(self, n=1):
        """ESCnC CUF (Cursor Forward)"""
        #logging.debug('cursor_right(%s)' % n)
        if not n:
            n = 1
        n = int(n)
        # This logic takes care of double-width unicode characters
        if self.double_width_right:
            self.double_width_right = False
            return
        self.cursorX += n
        try:
            char = self.screen[self.cursorY][self.cursorX]
        except IndexError: # Cursor is past the right-edge of the screen; ignore
            char = u' ' # This is a safe default/fallback
        if unicodedata.east_asian_width(char) == 'W':
            # This lets us skip the next call (get called 2x for 2x width)
            self.double_width_right = True
        try:
            for callback in self.callbacks[CALLBACK_CURSOR_POS].values():
                callback()
        except TypeError:
            pass

    def cursor_up(self, n=1):
        """ESCnA CUU (Cursor Up)"""
        #logging.debug('cursor_up(%s)' % n)
        if not n:
            n = 1
        n = int(n)
        self.cursorY = max(0, self.cursorY - n)
        try:
            for callback in self.callbacks[CALLBACK_CURSOR_POS].values():
                callback()
        except TypeError:
            pass

    def cursor_down(self, n=1):
        """ESCnB CUD (Cursor Down)"""
        #logging.debug('cursor_down(%s)' % n)
        if not n:
            n = 1
        n = int(n)
        self.cursorY = min(self.rows, self.cursorY + n)
        try:
            for callback in self.callbacks[CALLBACK_CURSOR_POS].values():
                callback()
        except TypeError:
            pass

    def cursor_next_line(self, n):
        """ESCnE CNL (Cursor Next Line)"""
        #logging.debug("cursor_next_line(%s)" % n)
        if not n:
            n = 1
        n = int(n)
        self.cursorY = min(self.rows, self.cursorY + n)
        self.cursorX = 0
        try:
            for callback in self.callbacks[CALLBACK_CURSOR_POS].values():
                callback()
        except TypeError:
            pass

    def cursor_previous_line(self, n):
        """ESCnF CPL (Cursor Previous Line)"""
        #logging.debug("cursor_previous_line(%s)" % n)
        if not n:
            n = 1
        n = int(n)
        self.cursorY = max(0, self.cursorY - n)
        self.cursorX = 0
        try:
            for callback in self.callbacks[CALLBACK_CURSOR_POS].values():
                callback()
        except TypeError:
            pass

    def cursor_horizontal_absolute(self, n):
        """ESCnG CHA (Cursor Horizontal Absolute)"""
        if not n:
            n = 1
        n = int(n)
        self.cursorX = n - 1 # -1 because cols is 0-based
        try:
            for callback in self.callbacks[CALLBACK_CURSOR_POS].values():
                callback()
        except TypeError:
            pass

    def cursor_position(self, coordinates):
        """
        ESCnH CUP (Cursor Position).  Move the cursor to the given coordinates.

            :coordinates: Should be something like, 'row;col' (1-based) but, 'row', 'row;', and ';col' are also valid (assumes 1 on missing value).

        .. note:: If coordinates is '' (an empty string), the cursor will be moved to the top left (1;1).
        """
        # NOTE: Since this is 1-based we have to subtract 1 from everything to
        #       match how we store these values internally.
        if not coordinates:
            row, col = 0, 0
        elif ';' in coordinates:
            row, col = coordinates.split(';')
        else:
            row = coordinates
            col = 0
        try:
            row = int(row)
        except ValueError:
            row = 0
        try:
            col = int(col)
        except ValueError:
            col = 0
        # These ensure a positive integer while reducing row and col by 1:
        row = max(0, row - 1)
        col = max(0, col - 1)
        self.cursorY = row
        # The column needs special attention in case there's double-width
        # characters.
        double_width = 0
        if self.cursorY < self.rows:
            for i, char in enumerate(self.screen[self.cursorY]):
                if i == col - double_width:
                    # No need to continue further
                    break
                if unicodedata.east_asian_width(char) == 'W':
                    double_width += 1
            if double_width:
                col = col - double_width
        self.cursorX = col
        try:
            for callback in self.callbacks[CALLBACK_CURSOR_POS].values():
                callback()
        except TypeError:
            pass

    def cursor_position_vertical(self, n):
        """
        Vertical Line Position Absolute (VPA) - Moves the cursor to given line.
        """
        n = int(n)
        self.cursorY = n - 1

    def clear_screen(self):
        """
        Clears the screen.  Also used to emulate a terminal reset.

        .. note::

            The current rendition (self.cur_rendition) will be applied to all
            characters on the screen when this function is called.
        """
        logging.debug('clear_screen()')
        self.scroll_up(len(self.screen) - 1)
        self.init_screen()
        self.init_renditions(self.cur_rendition)
        self.cursorX = 0
        self.cursorY = 0

    def clear_screen_from_cursor_down(self):
        """
        Clears the screen from the cursor down (ESC[J or ESC[0J).

        .. note:: This method actually erases from the cursor position to the end of the screen.
        """
        #logging.debug('clear_screen_from_cursor_down()')
        self.clear_line_from_cursor_right()
        if self.cursorY == self.rows - 1:
            # Bottom of screen; nothing to do
            return
        self.screen[self.cursorY+1:] = [
            array('u', u' ' * self.cols) for a in self.screen[self.cursorY+1:]
        ]
        c = self.cur_rendition # Just to save space below
        self.renditions[self.cursorY+1:] = [
            array('u', c * self.cols) for a in self.renditions[self.cursorY+1:]
        ]

    def clear_screen_from_cursor_up(self):
        """
        Clears the screen from the cursor up (ESC[1J).
        """
        #logging.debug('clear_screen_from_cursor_up()')
        self.screen[:self.cursorY+1] = [
            array('u', u' ' * self.cols) for a in self.screen[:self.cursorY]
        ]
        c = self.cur_rendition
        self.renditions[:self.cursorY+1] = [
            array('u', c * self.cols) for a in self.renditions[:self.cursorY]
        ]
        self.cursorY = 0

    def clear_screen_from_cursor(self, n):
        """
        CSI *n* J ED (Erase Data).  This escape sequence uses the following rules:

        ======  =============================   ===
        Esc[J   Clear screen from cursor down   ED0
        Esc[0J  Clear screen from cursor down   ED0
        Esc[1J  Clear screen from cursor up     ED1
        Esc[2J  Clear entire screen             ED2
        ======  =============================   ===
        """
        #logging.debug('clear_screen_from_cursor(%s)' % n)
        try:
            n = int(n)
        except ValueError: # Esc[J
            n = 0
        clear_types = {
            0: self.clear_screen_from_cursor_down,
            1: self.clear_screen_from_cursor_up,
            2: self.clear_screen
        }
        try:
            clear_types[n]()
        except KeyError:
            logging.error(_("Error: Unsupported number for escape sequence J"))
        # Execute our callbacks
        try:
            for callback in self.callbacks[CALLBACK_CHANGED].values():
                callback()
        except TypeError:
            pass
        try:
            for callback in self.callbacks[CALLBACK_CURSOR_POS].values():
                callback()
        except TypeError:
            pass

    def clear_line_from_cursor_right(self):
        """
        Clears the screen from the cursor right (ESC[K or ESC[0K).
        """
        #logging.debug("clear_line_from_cursor_right()")
        saved = self.screen[self.cursorY][:self.cursorX]
        saved_renditions = self.renditions[self.cursorY][:self.cursorX]
        spaces = array('u', u' '*len(self.screen[self.cursorY][self.cursorX:]))
        renditions = array('u',
            self.cur_rendition * len(self.screen[self.cursorY][self.cursorX:]))
        self.screen[self.cursorY] = saved + spaces
        # Reset the cursor position's rendition to the end of the line
        self.renditions[self.cursorY] = saved_renditions + renditions

    def clear_line_from_cursor_left(self):
        """
        Clears the screen from the cursor left (ESC[1K).
        """
        #logging.debug("clear_line_from_cursor_left()")
        saved = self.screen[self.cursorY][self.cursorX:]
        saved_renditions = self.renditions[self.cursorY][self.cursorX:]
        spaces = array('u', u' '*len(self.screen[self.cursorY][:self.cursorX]))
        renditions = array('u',
            self.cur_rendition * len(self.screen[self.cursorY][:self.cursorX]))
        self.screen[self.cursorY] = spaces + saved
        self.renditions[self.cursorY] = renditions + saved_renditions

    def clear_line(self):
        """
        Clears the entire line (ESC[2K).
        """
        #logging.debug("clear_line()")
        self.screen[self.cursorY] = array('u', u' ' * self.cols)
        c = self.cur_rendition
        self.renditions[self.cursorY] = array('u', c * self.cols)
        self.cursorX = 0

    def clear_line_from_cursor(self, n):
        """
        CSI*n*K EL (Erase in Line).  This escape sequence uses the following
        rules:

        ======  ==============================  ===
        Esc[K   Clear screen from cursor right  EL0
        Esc[0K  Clear screen from cursor right  EL0
        Esc[1K  Clear screen from cursor left   EL1
        Esc[2K  Clear entire line               ED2
        ======  ==============================  ===
        """
        #logging.debug('clear_line_from_cursor(%s)' % n)
        try:
            n = int(n)
        except ValueError: # Esc[J
            n = 0
        clear_types = {
            0: self.clear_line_from_cursor_right,
            1: self.clear_line_from_cursor_left,
            2: self.clear_line
        }
        try:
            clear_types[n]()
        except KeyError:
            logging.error(_(
                "Error: Unsupported number for CSI escape sequence K"))
        # Execute our callbacks
        try:
            for callback in self.callbacks[CALLBACK_CHANGED].values():
                callback()
        except TypeError:
            pass
        try:
            for callback in self.callbacks[CALLBACK_CURSOR_POS].values():
                callback()
        except TypeError:
            pass

    def set_led_state(self, n):
        """
        Sets the values the dict, self.leds depending on *n* using the following
        rules:

        ======  ======================  ======
        Esc[0q  Turn off all four leds  DECLL0
        Esc[1q  Turn on LED #1          DECLL1
        Esc[2q  Turn on LED #2          DECLL2
        Esc[3q  Turn on LED #3          DECLL3
        Esc[4q  Turn on LED #4          DECLL4
        ======  ======================  ======

        .. note:: These aren't implemented in Gate One's GUI (yet) but they certainly kept track of!
        """
        logging.debug("set_led_state(%s)" % n)
        leds = n.split(';')
        for led in leds:
            led = int(led)
            if led == 0:
                self.leds[1] = False
                self.leds[2] = False
                self.leds[3] = False
                self.leds[4] = False
            else:
                self.leds[led] = True
        try:
            for callback in self.callbacks[CALLBACK_LEDS].values():
                callback(led)
        except TypeError:
            pass

    def _set_rendition(self, n):
        """
        Sets :attr:`self.renditions[self.cursorY][self.cursorX]` equal to
        *n.split(';')*.

        *n* is expected to be a string of ECMA-48 rendition numbers separated by
        semicolons.  Example::

            '0;1;31'

        ...will result in::

            [0, 1, 31]

        Note that the numbers were converted to integers and the order was
        preserved.
        """
        #logging.debug("_set_rendition(%s)" % n)
        cursorY = self.cursorY
        cursorX = self.cursorX
        if cursorX >= self.cols: # We're at the end of the row
            try:
                if len(self.renditions[cursorY]) <= cursorX:
                    # Make it all longer
                    self.renditions[cursorY].append(u' ') # Make it longer
                    self.screen[cursorY].append(u'\x00') # This needs to match
            except IndexError:
                # This can happen if the rate limiter kicks in and starts
                # cutting off escape sequences at random.
                return # Don't bother attempting to process anything else
        if cursorY >= self.rows:
            logging.error(_(
                "cursorY >= self.rows!  This is either a bug or just a symptom "
                "of the rate limiter kicking in."))
            return # Don't bother setting renditions past the bottom
        if not n: # or \x1b[m (reset)
            # First char in PUA Plane 16 is always the default:
            self.cur_rendition = unichr(1000) # Should be reset (e.g. [0])
            return # No need for further processing; save some CPU
        # Convert the string (e.g. '0;1;32') to a list (e.g. [0,1,32]
        new_renditions = [int(a) for a in n.split(';') if a != '']
        # Handle 256-color renditions by getting rid of the (38|48);5 part and
        # incrementing foregrounds by 1000 and backgrounds by 10000 so we can
        # tell them apart in _spanify_screen().
        try:
            if 38 in new_renditions:
                foreground_index = new_renditions.index(38)
                if len(new_renditions[foreground_index:]) >= 2:
                    if new_renditions[foreground_index+1] == 5:
                        # This is a valid 256-color rendition (38;5;<num>)
                        new_renditions.pop(foreground_index) # Goodbye 38
                        new_renditions.pop(foreground_index) # Goodbye 5
                        new_renditions[foreground_index] += 1000
            if 48 in new_renditions:
                background_index = new_renditions.index(48)
                if len(new_renditions[background_index:]) >= 2:
                    if new_renditions[background_index+1] == 5:
                        # This is a valid 256-color rendition (48;5;<num>)
                        new_renditions.pop(background_index) # Goodbye 48
                        new_renditions.pop(background_index) # Goodbye 5
                        new_renditions[background_index] += 10000
        except IndexError:
            # Likely that the rate limiter has caused all sorts of havoc with
            # escape sequences.  Just ignore it and halt further processing
            return
        out_renditions = []
        for rend in new_renditions:
            if rend == 0:
                out_renditions = [0]
            else:
                out_renditions.append(rend)
        if out_renditions[0] == 0:
            # If it starts with 0 there's no need to combine it with the
            # previous rendition...
            reduced = _reduce_renditions(out_renditions)
            if reduced not in self.renditions_store.values():
                new_ref_point = self.rend_counter.next()
                self.renditions_store.update({new_ref_point: reduced})
                self.cur_rendition = new_ref_point
            else: # Find the right reference point to use
                for k, v in self.renditions_store.items():
                    if reduced == v:
                        self.cur_rendition = k
            return
        new_renditions = out_renditions
        cur_rendition_list = self.renditions_store[self.cur_rendition]
        reduced = _reduce_renditions(cur_rendition_list + new_renditions)
        if reduced not in self.renditions_store.values():
            new_ref_point = self.rend_counter.next()
            self.renditions_store.update({new_ref_point: reduced})
            self.cur_rendition = new_ref_point
        else: # Find the right reference point to use
            for k, v in self.renditions_store.items():
                if reduced == v:
                    self.cur_rendition = k

    def _opt_handler(self, chars):
        """
        Optional special escape sequence handler for sequences matching
        RE_OPT_SEQ.  If CALLBACK_OPT is defined it will be called like so::

            self.callbacks[CALLBACK_OPT](chars)

        Applications can use this escape sequence to define whatever special
        handlers they like.  It works like this: If an escape sequence is
        encountered matching RE_OPT_SEQ this method will be called with the
        inbetween *chars* (e.g. \x1b]_;<chars>\x07) as the argument.

        Applications can then do what they wish with *chars*.

        .. note::

            I added this functionality so that plugin authors would have a
            mechanism to communicate with terminal applications.  See the SSH
            plugin for an example of how this can be done (there's channels of
            communication amongst ssh_connect.py, ssh.js, and ssh.py).
        """
        try:
            for callback in self.callbacks[CALLBACK_OPT].values():
                callback(chars)
        except TypeError:
            # High likelyhood that nothing is defined.  No biggie.
            pass

# NOTE:  This was something I was testing to simplify the code. It works
# (mostly) but the performance was TERRIBLE.  Still needs investigation...
    #def _classify_renditions(self):
        #"""
        #Returns ``self.renditions`` as a list of HTML classes for each position.
        #"""
        #return [[map(RENDITION_CLASSES.get, rend) for rend in map(
                #self.renditions_store.get, rendition)]
                    #for rendition in self.renditions]

    #def _spanify_line(self, line, rendition, current_classes=None, cursor=False):
        #"""
        #Returns a string containing *line* with HTML spans applied representing
        #*renditions*.
        #"""
        #outline = ""
        #reset_classes = RESET_CLASSES # TODO
        #html_entities = {"&": "&amp;", '<': '&lt;', '>': '&gt;'}
        #foregrounds = ('f0','f1','f2','f3','f4','f5','f6','f7')
        #backgrounds = ('b0','b1','b2','b3','b4','b5','b6','b7')
        #prev_rendition = None
        #if current_classes:
            #outline += '<span class="%s%s">' % (
                #self.class_prefix,
                #(" %s" % self.class_prefix).join(current_classes))
        #charcount = 0
        #for char, rend in izip(line, rendition):
            #changed = True
            #if char in "&<>":
                ## Have to convert ampersands and lt/gt to HTML entities
                #char = html_entities[char]
            #if rend == prev_rendition:
                ## Shortcut...  So we can skip all the logic below
                #changed = False
            #else:
                #prev_rendition = rend
            #if changed:
                #outline += "</span>"
                #current_classes = [a for a in rend if a and 'reset' not in a]
                ##if rend and rend[0] == 'reset':
                    ##if len(current_classes) > 1:
                        ##classes = (
                            ##" %s" % self.class_prefix).join(current_classes)
                ##else:
                #classes = (" %s" % self.class_prefix).join(current_classes)
                #if current_classes != ['reset']:
                    #outline += '<span class="%s%s">' % (
                        #self.class_prefix, classes)
            #if cursor and charcount == cursor:
                #outline += '<span class="%scursor">%s</span>' % (
                    #self.class_prefix, char)
            #else:
                #outline += char
            #charcount += 1
        #open_spans = outline.count('<span')
        #close_spans = outline.count('</span')
        #if open_spans != close_spans:
            #for i in xrange(open_spans - close_spans):
                #outline += '</span>'
        #return current_classes, outline

    #def _spanify_screen_test(self):
        #"""
        #Iterates over the lines in *screen* and *renditions*, applying HTML
        #markup (span tags) where appropriate and returns the result as a list of
        #lines. It also marks the cursor position via a <span> tag at the
        #appropriate location.
        #"""
        ##logging.debug("_spanify_screen()")
        #results = []
        ## NOTE: Why these duplicates of self.* and globals?  Local variable
        ## lookups are faster--especially in loops.
        #special = SPECIAL
        ##rendition_classes = RENDITION_CLASSES
        #html_cache = HTML_CACHE
        #has_cache = isinstance(html_cache, AutoExpireDict)
        #screen = self.screen
        #renditions = self.renditions
        #renditions_store = self.renditions_store
        #classified_renditions = self._classify_renditions()
        #cursorX = self.cursorX
        #cursorY = self.cursorY
        #show_cursor = self.expanded_modes['25']
        ##spancount = 0
        #current_classes = []
        ##prev_rendition = None
        ##foregrounds = ('f0','f1','f2','f3','f4','f5','f6','f7')
        ##backgrounds = ('b0','b1','b2','b3','b4','b5','b6','b7')
        ##html_entities = {"&": "&amp;", '<': '&lt;', '>': '&gt;'}
        #cursor_span = '<span class="%scursor">' % self.class_prefix
        #for linecount, line in enumerate(screen):
            #rendition = classified_renditions[linecount]
            #combined = (line + renditions[linecount]).tounicode()
            #if has_cache and combined in html_cache:
                ## Always re-render the line with the cursor (or just had it)
                #if cursor_span not in html_cache[combined]:
                    ## Use the cache...
                    #results.append(html_cache[combined])
                    #continue
            #if not len(line.tounicode().rstrip()) and linecount != cursorY:
                #results.append(line.tounicode())
                #continue # Line is empty so we don't need to process renditions
            #if linecount == cursorY and show_cursor:
                #current_classes, outline = self._spanify_line(
                    #line, rendition,
                    #current_classes=current_classes,
                    #cursor=cursorX)
            #else:
                #current_classes, outline = self._spanify_line(
                    #line, rendition,
                    #current_classes=current_classes,
                    #cursor=False)
            #if outline:
                #results.append(outline)
                #if html_cache:
                    #html_cache[combined] = outline
            #else:
                #results.append(None) # null is less memory than spaces
            ## NOTE: The client has been programmed to treat None (aka null in
            ##       JavaScript) as blank lines.
        #return results

    def _spanify_screen(self):
        """
        Iterates over the lines in *screen* and *renditions*, applying HTML
        markup (span tags) where appropriate and returns the result as a list of
        lines. It also marks the cursor position via a <span> tag at the
        appropriate location.
        """
        #logging.debug("_spanify_screen()")
        results = []
        # NOTE: Why these duplicates of self.* and globals?  Local variable
        # lookups are faster--especially in loops.
        special = SPECIAL
        rendition_classes = RENDITION_CLASSES
        html_cache = HTML_CACHE
        has_cache = isinstance(html_cache, AutoExpireDict)
        screen = self.screen
        renditions = self.renditions
        renditions_store = self.renditions_store
        cursorX = self.cursorX
        cursorY = self.cursorY
        show_cursor = self.expanded_modes['25']
        spancount = 0
        current_classes = set()
        prev_rendition = None
        foregrounds = ('f0','f1','f2','f3','f4','f5','f6','f7')
        backgrounds = ('b0','b1','b2','b3','b4','b5','b6','b7')
        html_entities = {"&": "&amp;", '<': '&lt;', '>': '&gt;'}
        cursor_span = '<span class="%scursor">' % self.class_prefix
        for linecount, line in enumerate(screen):
            rendition = renditions[linecount]
            line_chars = line.tounicode()
            combined = line_chars + rendition.tounicode()
            cursor_line = True if linecount == cursorY else False
            if not cursor_line and has_cache and combined in html_cache:
                # Always re-render the line with the cursor (or just had it)
                if cursor_span not in html_cache[combined]:
                    # Use the cache...
                    results.append(html_cache[combined])
                    continue
            if not len(line_chars.rstrip()) and not cursor_line:
                results.append(line_chars)
                continue # Line is empty so we don't need to process renditions
            outline = ""
            if current_classes:
                outline += '<span class="%s%s">' % (
                    self.class_prefix,
                    (" %s" % self.class_prefix).join(current_classes))
            charcount = 0
            for char, rend in izip(line, rendition):
                rend = renditions_store[rend] # Get actual rendition
                if ord(char) >= special: # Special stuff =)
                    # Obviously, not really a single character
                    if char in self.captured_files:
                        outline += self.captured_files[char].html()
                        continue
                changed = True
                if char in "&<>":
                    # Have to convert ampersands and lt/gt to HTML entities
                    char = html_entities[char]
                if rend == prev_rendition:
                    # Shortcut...  So we can skip all the logic below
                    changed = False
                else:
                    prev_rendition = rend
                if changed and rend:
                    classes = imap(rendition_classes.get, rend)
                    for _class in classes:
                        if _class and _class not in current_classes:
                            # Something changed...  Start a new span
                            if spancount:
                                outline += "</span>"
                                spancount -= 1
                            if 'reset' in _class:
                                if _class == 'reset':
                                    current_classes = set()
                                    if spancount:
                                        for i in xrange(spancount):
                                            outline += "</span>"
                                        spancount = 0
                                else:
                                    reset_class = _class.split('reset')[0]
                                    if reset_class == 'foreground':
                                        [current_classes.remove(a) for a in
                                        current_classes if a in foregrounds]
                                    elif reset_class == 'background':
                                        [current_classes.remove(a) for a in
                                        current_classes if a in backgrounds]
                                    elif reset_class in current_classes:
                                        current_classes.remove(reset_class)
                            else:
                                if _class in foregrounds:
                                    [current_classes.remove(a) for a in
                                    current_classes if a in foregrounds]
                                elif _class in backgrounds:
                                    [current_classes.remove(a) for a in
                                    current_classes if a in backgrounds]
                                current_classes.add(_class)
                    if current_classes:
                        outline += '<span class="%s%s">' % (
                            self.class_prefix,
                            (" %s" % self.class_prefix).join(current_classes))
                        spancount += 1
                if cursor_line and show_cursor and charcount == cursorX:
                    outline += '<span class="%scursor">%s</span>' % (
                        self.class_prefix, char)
                else:
                    outline += char
                charcount += 1
            if outline:
                # Make sure all renditions terminate at the end of the line
                for whatever in xrange(spancount):
                    outline += "</span>"
                results.append(outline)
                if has_cache:
                    html_cache[combined] = outline
            else:
                results.append(None) # null is shorter than spaces
            # NOTE: The client has been programmed to treat None (aka null in
            #       JavaScript) as blank lines.
        for whatever in xrange(spancount): # Bit of cleanup to be safe
            results[-1] += "</span>"
        return results

    def _spanify_scrollback(self):
        """
        Spanifies (turns renditions into `<span>` elements) everything inside
        `self.scrollback` using `self.renditions`.  This differs from
        `_spanify_screen` in that it doesn't apply any logic to detect the
        location of the cursor (to make it just a tiny bit faster).
        """
        # NOTE: See the comments in _spanify_screen() for details on this logic
        results = []
        special = SPECIAL
        html_cache = HTML_CACHE
        has_cache = isinstance(html_cache, AutoExpireDict)
        screen = self.scrollback_buf
        renditions = self.scrollback_renditions
        rendition_classes = RENDITION_CLASSES
        renditions_store = self.renditions_store
        spancount = 0
        current_classes = set()
        prev_rendition = None
        foregrounds = ('f0','f1','f2','f3','f4','f5','f6','f7')
        backgrounds = ('b0','b1','b2','b3','b4','b5','b6','b7')
        html_entities = {"&": "&amp;", '<': '&lt;', '>': '&gt;'}
        cursor_span = '<span class="%scursor">' % self.class_prefix
        for line, rendition in izip(screen, renditions):
            combined = (line + rendition).tounicode()
            if has_cache and combined in html_cache:
                # Most lines should be in the cache because they were rendered
                # while they were on the screen.
                if cursor_span not in html_cache[combined]:
                    results.append(html_cache[combined])
                    continue
            if not len(line.tounicode().rstrip()):
                results.append(line.tounicode())
                continue # Line is empty so we don't need to process renditions
            outline = ""
            if current_classes:
                outline += '<span class="%s%s">' % (
                    self.class_prefix,
                    (" %s" % self.class_prefix).join(current_classes))
            for char, rend in izip(line, rendition):
                rend = renditions_store[rend] # Get actual rendition
                if ord(char) >= special: # Special stuff =)
                    # Obviously, not really a single character
                    if char in self.captured_files:
                        outline += self.captured_files[char].html()
                        continue
                changed = True
                if char in "&<>":
                    # Have to convert ampersands and lt/gt to HTML entities
                    char = html_entities[char]
                if rend == prev_rendition:
                    changed = False
                else:
                    prev_rendition = rend
                if changed and rend != None:
                    classes = imap(rendition_classes.get, rend)
                    for _class in classes:
                        if _class and _class not in current_classes:
                            if spancount:
                                outline += "</span>"
                                spancount -= 1
                            if 'reset' in _class:
                                if _class == 'reset':
                                    current_classes = set()
                                else:
                                    reset_class = _class.split('reset')[0]
                                    if reset_class == 'foreground':
                                        [current_classes.remove(a) for a in
                                        current_classes if a in foregrounds]
                                    elif reset_class == 'background':
                                        [current_classes.remove(a) for a in
                                        current_classes if a in backgrounds]
                                    elif reset_class in current_classes:
                                        current_classes.remove(reset_class)
                            else:
                                if _class in foregrounds:
                                    [current_classes.remove(a) for a in
                                    current_classes if a in foregrounds]
                                elif _class in backgrounds:
                                    [current_classes.remove(a) for a in
                                    current_classes if a in backgrounds]
                                current_classes.add(_class)
                    if current_classes:
                        outline += '<span class="%s%s">' % (
                            self.class_prefix,
                            (" %s" % self.class_prefix).join(current_classes))
                        spancount += 1
                outline += char
            if outline:
                # Make sure all renditions terminate at the end of the line
                for whatever in xrange(spancount):
                    outline += "</span>"
                results.append(outline)
            else:
                results.append(None)
        for whatever in xrange(spancount): # Bit of cleanup to be safe
            results[-1] += "</span>"
        return results

    def dump_html(self, renditions=True):
        """
        Dumps the terminal screen as a list of HTML-formatted lines.  If
        *renditions* is True (default) then terminal renditions will be
        converted into HTML <span> elements so they will be displayed properly
        in a browser.  Otherwise only the cursor <span> will be added to mark
        its location.

        .. note::

            This places <span class="cursor">(current character)</span> around
            the cursor location.
        """
        if renditions: # i.e. Use stylized text (the default)
            screen = self._spanify_screen()
            scrollback = []
            if self.scrollback_buf:
                scrollback = self._spanify_scrollback()
        else:
            cursorX = self.cursorX
            cursorY = self.cursorY
            screen = []
            for y, row in enumerate(self.screen):
                if y == cursorY:
                    cursor_row = ""
                    for x, char in enumerate(row):
                        if x == cursorX:
                            cursor_row += (
                                '<span class="%scursor">%s</span>' % (
                                self.class_prefix, char))
                        else:
                            cursor_row += char
                    screen.append(cursor_row)
                else:
                    screen.append("".join(row))
            scrollback = [a.tounicode() for a in self.scrollback_buf]
        # Empty the scrollback buffer:
        self.init_scrollback()
        self.modified = False
        return (scrollback, screen)

# NOTE: This is a work-in-progress.  Don't use it.
    def dump_html_async(self, identifier=None, renditions=True, callback=None):
        """
        Dumps the terminal screen as a list of HTML-formatted lines.  If
        *renditions* is True (default) then terminal renditions will be
        converted into HTML <span> elements so they will be displayed properly
        in a browser.  Otherwise only the cursor <span> will be added to mark
        its location.

        .. note::

            This places <span class="cursor">(current character)</span> around
            the cursor location.
        """
        if self.async:
            state_obj = {
                'html_cache': HTML_CACHE,
                'screen': self.screen,
                'renditions': self.renditions,
                'renditions_store': self.renditions_store,
                'cursorX': self.cursorX,
                'cursorY': self.cursorY,
                'show_cursor': self.expanded_modes['25'],
                'class_prefix': self.class_prefix
            }
            self.async.call_singleton(
                spanify_screen, identifier, state_obj, callback=callback)
        else:
            scrollback, screen = self.dump_html(renditions=renditions)
            callback(scrollback, screen)

    def dump_plain(self):
        """
        Dumps the screen and the scrollback buffer as-is then empties the
        scrollback buffer.
        """
        screen = self.screen
        scrollback = self.scrollback_buf
        # Empty the scrollback buffer:
        self.init_scrollback()
        self.modified = False
        return (scrollback, screen)

    def dump_components(self):
        """
        Dumps the screen and renditions as-is, the scrollback buffer as HTML,
        and the current cursor coordinates.  Also, empties the scrollback buffer

        .. note:: This was used in some performance-related experiments but might be useful for other patterns in the future so I've left it here.
        """
        screen = [a.tounicode() for a in self.screen]
        scrollback = []
        if self.scrollback_buf:
            # Process the scrollback buffer into HTML
            scrollback = self._spanify_scrollback(
                self.scrollback_buf, self.scrollback_renditions)
        # Empty the scrollback buffer:
        self.init_scrollback()
        self.modified = False
        return (scrollback, screen, self.renditions, self.cursorY, self.cursorX)

    def dump(self):
        """
        Returns self.screen as a list of strings with no formatting.
        No scrollback buffer.  No renditions.  It is meant to be used to get a
        quick glance of what is being displayed (when debugging).

        .. note:: This method does not empty the scrollback buffer.
        """
        out = []
        for line in self.screen:
            line_out = ""
            for char in line:
                if len(char) > 1: # This is an image (or similar)
                    line_out += u'' # Use a dotted square as a placeholder
                else:
                    line_out += char
            out.append(line_out)
        self.modified = False
        return out

# This is here to make it easier for someone to produce an HTML app that uses
# terminal.py
def css_renditions(selector=None):
    """
    Returns a (long) string containing all the CSS styles in order to support
    terminal text renditions (different colors, bold, etc) in an HTML terminal
    using the dump_html() function.  If *selector* is provided, all styles will
    be prefixed with said selector like so::

        ${selector} span.f0 { color: #5C5C5C; }

    Example::

        >>> css_renditions("#gateone").splitlines()[7]
        '#gateone span.f0 { color: #5C5C5C; } /* Black */'
    """
    from string import Template
    # Try looking for the fallback CSS template in two locations:
    #   * The same directory that holds terminal.py
    #   * A 'templates' directory in the same location as terminal.py
    template_name = 'terminal_renditions_fallback.css'
    template_path = os.path.join(os.path.split(__file__)[0], template_name)
    if not os.path.exists(template_path):
        # Try looking in a 'templates' directory
        template_path = os.path.join(
            os.path.split(__file__)[0], 'templates', template_name)
    if not os.path.exists(template_path):
        raise IOError("File not found: %s" % template_name)
    with open(template_path) as f:
        css = f.read()
    renditions_template = Template(css)
    return renditions_template.substitute(selector=selector)

########NEW FILE########
__FILENAME__ = termio
# -*- coding: utf-8 -*-
#
#       Copyright 2011 Liftoff Software Corporation (http://liftoffsoftware.com)
#
# NOTE:  Commercial licenses for this software are available!
#

# TODO: See if we can spin off termio.py into its own little program that sits between Gate One and ssh_connect.py.  That way we can take advantage of multiple cores/processors (for terminal-to-HTML processing).  There's no reason why we can't write something that does what dtach does.  Just need to redirect the fd of self.cmd to a unix domain socket and os.setsid() somewhere after forking (twice maybe?).
# TODO: Make the environment variables used before launching self.cmd configurable

# Meta
__version__ = '1.2'
__version_info__ = (1, 2)
__license__ = "AGPLv3 or Proprietary (see LICENSE.txt)"
__author__ = 'Dan McDougall <daniel.mcdougall@liftoffsoftware.com>'

__doc__ = """\
About termio
============
This module provides a Multiplex class that can perform the following:

 * Fork a child process that opens a given terminal program.
 * Read and write data to and from the child process (synchronously or asynchronously).
 * Examine the output of the child process in real-time and perform actions (also asynchronously!) based on what is "expected" (aka non-blocking, pexpect-like functionality).
 * Log the output of the child process to a file and/or syslog.

The Multiplex class was built for asynchronous use in conjunction with a running
:class:`tornado.ioloop.IOLoop` instance but it can be used in a synchronous
(blocking) manner as well.  Synchronous use of this module is most likely to be
useful in an interactive Python session but if blocking doesn't matter for your
program please see the section titled, "Blocking" for tips & tricks.

Here's an example instantiating a Multiplex class::

    multiplexer = termio.Multiplex(
        'nethack',
        log_path='/var/log/myapp',
        user='bsmith@CORP',
        term_id=1,
        syslog=True
    )

.. note:: Support for event loops other than Tornado is in the works!

Then *multiplexer* can create and launch a new controlling terminal (tty)
running the given command (e.g. 'nethack')::

    env = {
        'PATH': os.environ['PATH'],
        'MYVAR': 'foo'
    }
    fd = multiplexer.spawn(80, 24, env=env)
    # The fd is returned from spawn() in case you want more low-level control.

Asynchronous input and output from the controlled program is handled via IOLoop.
It will automatically write all output from the terminal program to an instance
of self.terminal_emulator (which defaults to Gate One's `terminal.Terminal`).
So if you want to perform an action whenever the running terminal application
has output (like, say, sending a message to a client) you'll need to attach a
callback::

    def screen_update():
        'Called when new output is ready to send to the client'
        output = multiplexer.dump_html()
        socket_or_something.write(output)
    multiplexer.callbacks[multiplexer.CALLBACK_UPDATE] = screen_update

In this example, `screen_update()` will `write()` the output of
`multiplexer.dump_html()` to *socket_or_something* whenever the terminal program
has some sort of output.  You can also make calls directly to the terminal
emulator (if you're using a custom one)::

    def screen_update():
        output = multiplexer.term.my_custom_func()
        whatever.write(output)

Writing characters to the controlled terminal application is pretty
straightforward::

    multiplexer.write(u'some text')

Typically you'd pass in keystrokes or commands from your application to the
underlying program this way and the screen/terminal emulator would get updated
automatically.  If using Gate One's `terminal.Terminal()` you can also attach
callbacks to perform further actions when more specific situations are
encountered (e.g. when the window title is set via its respective escape
sequence)::

    def set_title():
        'Hypothetical title-setting function'
        print("Window title was just set to: %s" % multiplexer.term.title)
    multiplexer.term.callbacks[multiplexer.CALLBACK_TITLE] = set_title

Module Functions and Classes
============================
"""

# Stdlib imports
import os, sys, time, struct, io, gzip, re, logging, signal
from datetime import timedelta, datetime
from functools import partial
from itertools import izip
from multiprocessing import Process
from json import loads as json_decode
from json import dumps as json_encode

# Inernationalization support
_ = str # So pylint doesn't show a zillion errors about a missing _() function
import gettext
gettext.install('termio')

# Globals
SEPARATOR = u"\U000f0f0f" # The character used to separate frames in the log
# NOTE: That unicode character was carefully selected from only the finest
# of the PUA.  I hereby dub thee, "U+F0F0F0, The Separator."
POSIX = 'posix' in sys.builtin_module_names
MACOS = os.uname()[0] == 'Darwin'
# Matches Gate One's special optional escape sequence (ssh plugin only)
RE_OPT_SSH_SEQ = re.compile(
    r'.*\x1b\]_\;(ssh\|set;connect_string.+?)(\x07|\x1b\\)',
    re.MULTILINE|re.DOTALL)
# Matches an xterm title sequence
RE_TITLE_SEQ = re.compile(
    r'.*\x1b\][0-2]\;(.+?)(\x07|\x1b\\)', re.DOTALL|re.MULTILINE)
EXTRA_DEBUG = False # For those times when you need to get dirty

# Helper functions
def debug_expect(m_instance, match, pattern):
    """
    This method is used by :meth:`BaseMultiplex.expect` if :attr:`self.debug` is
    True.  It facilitates easy debugging of regular expressions.  It will print
    out precisely what was matched and where.

    .. note::  This function only works with post-process patterns.
    """
    print("%s was matched..." % repr(pattern.pattern))
    for line in m_instance.dump():
        match_obj = pattern.search(line)
        if match_obj:
            print("--->%s\n" % repr(line))
            break
        else:
            if line.strip():
                print("    %s\n" % repr(line))

def retrieve_first_frame(golog_path):
    """
    Retrieves the first frame from the given *golog_path*.
    """
    found_first_frame = None
    frame = b""
    f = gzip.open(golog_path)
    while not found_first_frame:
        frame += f.read(1) # One byte at a time
        if frame.decode('UTF-8', "ignore").endswith(SEPARATOR):
            # That's it; wrap this up
            found_first_frame = True
    distance = f.tell()
    f.close()
    return (frame.decode('UTF-8', "ignore").rstrip(SEPARATOR), distance)

def retrieve_last_frame(golog_path):
    """
    Retrieves the last frame from the given *golog_path*.  It does this by
    iterating over the log in reverse.
    """
    encoded_separator = SEPARATOR.encode('UTF-8')
    golog = gzip.open(golog_path)
    chunk_size = 1024*128
    # Seek to the end of the file (gzip objects don't support negative seeking)
    distance = chunk_size
    prev_tell = None
    while golog.tell() != prev_tell:
        prev_tell = golog.tell()
        try:
            golog.seek(distance)
        except IOError:
            return # Something wrong with the file
        distance += distance
    # Now that we're at the end, go back a bit and split from there
    golog.seek(golog.tell() - chunk_size*2)
    end_frames = golog.read().split(encoded_separator)
    if len(end_frames) > 1:
        # Very last item will be empty
        return end_frames[-2].decode('UTF-8', 'ignore')
    else:
        # Just a single frame here, return it as-is
        return end_frames[0].decode('UTF-8', 'ignore')

def get_or_update_metadata(golog_path, user, force_update=False):
    """
    Retrieves or creates/updates the metadata inside of *golog_path*.

    If *force_update* the metadata inside the golog will be updated even if it
    already exists.

    .. note::

        All logs will need "fixing" the first time they're enumerated like this
        since they won't have an end_date.  Fortunately we only need to do this
        once per golog.
    """
    logging.debug('get_or_update_metadata(%s, %s, %s)' % (golog_path, user, force_update))
    if not os.path.getsize(golog_path): # 0 bytes
        return # Nothing to do
    try:
        first_frame, distance = retrieve_first_frame(golog_path)
    except IOError:
        # Something wrong with the log...  Probably still being written to
        return
    metadata = {}
    if first_frame[14:].startswith('{'):
        # This is JSON, capture existing metadata
        metadata = json_decode(first_frame[14:])
        # end_date gets added by this function
        if not force_update and 'end_date' in metadata:
            return metadata # All done
    # '\xf3\xb0\xbc\x8f' <--UTF-8 encoded SEPARATOR (for reference)
    encoded_separator = SEPARATOR.encode('UTF-8')
    golog = gzip.open(golog_path)
    # Loop over the file in big chunks (which is faster than read() by an order
    # of magnitude)
    chunk_size = 1024*128 # 128k should be enough for a 100x300 terminal full
    # of 4-byte unicode characters. That would be one BIG frame (i.e. unlikely).
    log_data = b''
    total_frames = 0
    max_data = chunk_size * 10 # Hopefully this is enough to capture a title
    while len(log_data) < max_data:
        try:
            chunk = golog.read(chunk_size)
        except (IOError, EOFError):
            return # Something wrong with the file
        total_frames += chunk.count(encoded_separator)
        log_data += chunk
        if len(chunk) < chunk_size:
            break
    # Remove the trailing incomplete frame
    log_data = encoded_separator.join(log_data.split(encoded_separator)[:-1])
    log_data = log_data.decode('UTF-8', 'ignore')
    start_date = first_frame[:13] # Getting the start date is easy
    last_frame = retrieve_last_frame(golog_path) # This takes some work
    if not last_frame:
        return # Something wrong with log
    end_date = last_frame[:13]
    version = u"1.0"
    connect_string = None
    # Try to find the host that was connected to by looking for the SSH
    # plugin's special optional escape sequence.  It looks like this:
    #   "\x1b]_;ssh|%s@%s:%s\007"
    match_obj = RE_OPT_SSH_SEQ.match(log_data[:(chunk_size*10)])
    if match_obj:
        connect_string = match_obj.group(1).split(';')[-1]
    if not connect_string:
        # Try guessing it by looking for a title escape sequence
        match_obj = RE_TITLE_SEQ.match(log_data[:(chunk_size*10)])
        if match_obj:
            # The split() here is an attempt to remove the tail end of
            # titles like this:  'someuser@somehost: ~'
            connect_string = match_obj.group(1)
    metadata.update({
        u'user': user,
        u'start_date': start_date,
        u'end_date': end_date,
        u'frames': total_frames,
        u'version': version,
        u'connect_string': connect_string,
        u'filename': os.path.split(golog_path)[1]
    })
    # Make a *new* first_frame
    first_frame = u"%s:" % start_date
    first_frame += json_encode(metadata) + SEPARATOR
    first_frame = first_frame.encode('UTF-8')
    # Replace the first frame and re-save the log
    temp_path = "%s.tmp" % golog_path
    golog = gzip.open(golog_path) # Re-open
    new_golog = gzip.open(temp_path, 'w')
    new_golog.write(first_frame)
    # Now write out the rest of it
    count = 0
    while True:
        try:
            chunk = golog.read(chunk_size)
        except IOError:
            return # Something wrong with the file
        if count == 0:
            if chunk[14:15] == b"{": # Old/incomplete metadata
                # Need to keep reading until the next frame
                while True:
                    try:
                        chunk += golog.read(chunk_size)
                    except IOError:
                        return # Something wrong with the file
                    if encoded_separator in chunk:
                        # This removes the first frame:
                        chunk = encoded_separator.join(
                            chunk.split(encoded_separator)[1:])
                        break
        new_golog.write(chunk)
        if len(chunk) < chunk_size:
            break # Everything must come to an end
        count += 1
    # Overwrite the old log
    import shutil
    shutil.move(temp_path, golog_path)
    return metadata

# Exceptions
class Timeout(Exception):
    """
    Used by :meth:`BaseMultiplex.expect` and :meth:`BaseMultiplex.await`;
    called when a timeout is reached.
    """
    pass

class ProgramTerminated(Exception):
    """
    Called when we try to write to a process that's no longer running.
    """
    pass

# Classes
class Pattern(object):
    """
    Used by :meth:`BaseMultiplex.expect`, an object to store patterns
    (regular expressions) and their associated properties.

    .. note:: The variable *m_instance* is used below to mean the current instance of BaseMultiplex (or a subclass thereof).

    :pattern: A regular expression or iterable of regular expressions that will be checked against the output stream.

    :callback: A function that will be called when the pattern is matched.  Callbacks are called like so::

        callback(m_instance, matched_string)

        .. tip:: If you provide a string instead of a function for your *callback* it will automatically be converted into a function that writes the string to the child process.  Example::

            >>> p = Pattern('(?i)password:', 'mypassword\\n')

    :optional: Indicates that this pattern is optional.  Meaning that it isn't required to match before the next pattern in :attr:`BaseMultiplex._patterns` is checked.

    :sticky: Indicates that the pattern will not time out and won't be automatically removed from self._patterns when it is matched.

    :errorback: A function to call in the event of a timeout or if an exception is encountered.  Errorback functions are called like so::

        errorback(m_instance)

    :preprocess: Indicates that this pattern is to be checked against the incoming stream before it is processed by the terminal emulator.  Useful if you need to match non-printable characters like control codes and escape sequences.

    :timeout: A :obj:`datetime.timedelta` object indicating how long we should wait before calling :meth:`errorback`.

    :created: A :obj:`datetime.datetime` object that gets set when the Pattern is instantiated by :meth:`BaseMultiplex.expect`.  It is used to determine if and when a timeout has been reached.
    """
    def __init__(self, pattern, callback,
            optional=False,
            sticky=False,
            errorback=None,
            preprocess=False,
            timeout=30):
        self.pattern = pattern
        if isinstance(callback, (str, unicode)):
            # Convert the string to a write() call
            self.callback = lambda m, match: m.write(unicode(callback))
        else:
            self.callback = callback
        self.errorback = errorback
        self.optional = optional
        self.sticky = sticky
        self.preprocess = preprocess
        self.timeout = timeout
        self.created = datetime.now()

class BaseMultiplex(object):
    """
    A base class that all Multiplex types will inherit from.

    :cmd: *string* - The command to execute when calling :meth:`spawn`.
    :terminal_emulator: *terminal.Terminal or similar* - The terminal emulator to write to when capturing the incoming output stream from *cmd*.
    :terminal_emulator_kwargs: A dictionary of keyword arguments to be passed to the *terminal_emulator* when it is instantiated.
    :log_path: *string* - The absolute path to the log file where the output from *cmd* will be saved.
    :user: *string* - If given this gets added to the log file as metadata (to differentiate who's who).
    :term_id: *string* - The terminal identifier to associated with this instance (only used in the logs to identify terminals).
    :syslog: *boolean* - Whether or not the session should be logged using the local syslog daemon.
    :syslog_facility: *integer* - The syslog facility to use when logging messages.  All possible facilities can be found in `utils.FACILITIES` (if you need a reference other than the syslog module).
    :additional_metadata: *dict* - Anything in this dict will be included in the metadata frame of the log file.  Can only be key:value strings.
    :encoding: *string* - The encoding to use when writing or reading output.
    :debug: *boolean* - Used by the `expect` methods...  If set, extra debugging information will be output whenever a regular expression is matched.
    """
    CALLBACK_UPDATE = 1 # Screen update
    CALLBACK_EXIT = 2   # When the underlying program exits

    def __init__(self,
            cmd,
            terminal_emulator=None, # Defaults to Gate One's terminal.Terminal
            terminal_emulator_kwargs=None,
            log_path=None,
            user=None, # Only used by log output (to differentiate who's who)
            term_id=None, # Also only for syslog output for the same reason
            syslog=False,
            syslog_facility=None,
            additional_metadata=None, # Will be stored in the log (if any)
            encoding='utf-8',
            debug=False):
        self.encoding = encoding
        self.debug = debug
        self.exitfunc = None
        self.cmd = cmd
        if terminal_emulator == None:
            # Why do this?  So you could use/write your own specialty emulator.
            # Whatever you use it just has to accept 'rows' and 'cols' as
            # keyword arguments in __init__()
            from terminal import Terminal # Dynamic import to cut down on waste
            self.terminal_emulator = Terminal
        else:
            self.terminal_emulator = terminal_emulator
        self.terminal_emulator_kwargs = terminal_emulator_kwargs
        if not terminal_emulator_kwargs:
            self.terminal_emulator_kwargs = {}
        self.log_path = log_path # Logs of the terminal output wind up here
        self.log = None # Just a placeholder until it is opened
        self.syslog = syslog # See "if self.syslog:" below
        self._alive = False
        self.ratelimiter_engaged = False
        self.capture_ratelimiter = False
        self.ctrl_c_pressed = False
        self.capturing_timeout = timedelta(seconds=2)
        self.rows = 24
        self.cols = 80
        self.pid = -1 # Means "no pid yet"
        self.started = "Never"
        self._patterns = []
        self._handling_match = False
        # Setup our callbacks
        self.callbacks = { # Defaults do nothing which saves some conditionals
            self.CALLBACK_UPDATE: {},
            self.CALLBACK_EXIT: {},
        }
        # Configure syslog logging
        self.user = user
        self.term_id = term_id
        self.syslog_buffer = ''
        self.additional_metadata = additional_metadata
        if self.syslog:
            try:
                import syslog
            except ImportError:
                logging.error(_(
                    "The syslog module is required to log terminal sessions to "
                    "syslog."))
                sys.exit(1)
            if not syslog_facility:
                syslog_facility = syslog.LOG_DAEMON
            syslog_facility = syslog_facility
            # Sets up syslog messages to show up like this:
            #   Sep 28 19:45:02 <hostname> gateone: <log message>
            syslog.openlog('gateone', 0, syslog_facility)

    def __repr__(self):
        """
        Returns self.__str__()
        """
        return "<%s>" % self.__str__()

    def __str__(self):
        """
        Returns a string representation of this Multiplex instance and the
        current state of things.
        """
        started = self.started
        if started != "Never":
            started = self.started.isoformat()
        out = (
            "%s.%s:  "
            "term_id: %s, "
            "alive: %s, "
            "command: %s, "
            "started: %s"
            % (
                self.__module__,
                self.__class__.__name__,
                self.term_id,
                self._alive,
                repr(self.cmd),
                started
            )
        )
        return out

    def set_encoding(self, encoding):
        """
        Sets the encoding for the terminal emulator to *encoding*.
        """
        self.term.encoding = encoding

    def add_callback(self, event, callback, identifier=None):
        """
        Attaches the given *callback* to the given *event*.  If given,
        *identifier* can be used to reference this callback leter (e.g. when you
        want to remove it).  Otherwise an identifier will be generated
        automatically.  If the given *identifier* is already attached to a
        callback at the given event, that callback will be replaced with
        *callback*.

        *event* - The numeric ID of the event you're attaching *callback* to (e.g. Multiplex.CALLBACK_UPDATE).
        *callback* - The function you're attaching to the *event*.
        *identifier* - A string or number to be used as a reference point should you wish to remove or update this callback later.

        Returns the identifier of the callback.  to Example:

            >>> m = Multiplex('bash')
            >>> def somefunc(): pass
            >>> id = "myref"
            >>> ref = m.add_callback(m.CALLBACK_UPDATE, somefunc, id)

        .. note:: This allows the controlling program to have multiple callbacks for the same event.
        """
        if not identifier:
            identifier = callback.__hash__()
        self.callbacks[event][identifier] = callback
        return identifier

    def remove_callback(self, event, identifier):
        """
        Removes the callback referenced by *identifier* that is attached to the
        given *event*.  Example::

            m.remove_callback(m.CALLBACK_UPDATE, "myref")

        """
        try:
            del self.callbacks[event][identifier]
        except KeyError:
            pass # Doesn't exist anymore--nothing to do

    def remove_all_callbacks(self, identifier):
        """
        Removes all callbacks associated with *identifier*.
        """
        for event, identifiers in self.callbacks.items():
            try:
                del self.callbacks[event][identifier]
            except KeyError:
                pass # Doesn't exist--nothing to worry about

    def _call_callback(self, callback):
        """
        This method is here in the event that subclasses of `BaseMultiplex` need
        to call callbacks in an implementation-specific way.  It just calls
        *callback*.
        """
        callback()

    def spawn(self, rows=24, cols=80, env=None, em_dimensions=None):
        """
        This method must be overridden by suclasses of `BaseMultiplex`.  It is
        expected to execute a child process in a way that allows non-blocking
        reads to be performed.
        """
        raise NotImplementedError(_(
            "spawn() *must* be overridden by subclasses."))

    def isalive(self):
        """
        This method must be overridden by suclasses of `BaseMultiplex`.  It is
        expected to return True if the child process is still alive and False
        otherwise.
        """
        raise NotImplementedError(_(
            "isalive() *must* be overridden by subclasses."))

    def term_write(self, stream):
        """
        Writes :obj:`stream` to `BaseMultiplex.term` and also takes care of
        logging to :attr:`log_path` (if set) and/or syslog (if
        :attr:`syslog` is `True`).  When complete, will call any
        callbacks registered in :obj:`CALLBACK_UPDATE`.

        :stream: A string or bytes containing the incoming output stream from the underlying terminal program.

        .. note:: This kind of logging doesn't capture user keystrokes.  This is intentional as we don't want passwords winding up in the logs.
        """
        #logging.debug('term_write() stream: %s' % repr(stream))
        # Write to the log (if configured)
        separator = b"\xf3\xb0\xbc\x8f"
        if self.log_path:
            # Using .encode() below ensures the result will be bytes
            now = str(int(round(time.time() * 1000))).encode('UTF-8')
            if not os.path.exists(self.log_path):
                # Write the first frame as metadata
                metadata = {
                    'version': '1.0', # Log format version
                    'rows': self.rows,
                    'columns': self.cols,
                    'term_id': self.term_id,
                    'start_date': now.decode('UTF-8') # JSON needs strings
                    # NOTE: end_date should be added later when the is read for
                    # the first time by either the logviewer or the logging
                    # plugin.
                }
                # Add any extra metadata to the first frame
                if self.additional_metadata:
                    metadata.update(self.additional_metadata)
                # The hope is that we can use the first-frame-metadata paradigm
                # to store all sorts of useful information about a log.
                # NOTE: Using .encode() below to ensure it is bytes in Python 3
                metadata_frame = json_encode(metadata).encode('UTF-8')
                # Using concatenation of bytes below to ensure compatibility
                # with both Python 2 and Python 3.
                metadata_frame = now + b":" + metadata_frame + separator
                self.log = gzip.open(self.log_path, mode='a')
                self.log.write(metadata_frame)
            if not self.log: # Only comes into play if the file already exists
                self.log = gzip.open(self.log_path, mode='a')
            # NOTE: I'm using an obscure unicode symbol in order to avoid
            # conflicts.  We need to do our best to ensure that we can
            # differentiate between terminal output and our log format...
            # This should do the trick because it is highly unlikely that
            # someone would be displaying this obscure unicode symbol on an
            # actual terminal unless they were using Gate One to view a
            # Gate One log file in vim or something =)
            # "\xf3\xb0\xbc\x8f" == \U000f0f0f == U+F0F0F (Private Use Symbol)
            output = now + b":" + stream + separator
            self.log.write(output)
        # NOTE: Gate One's log format is special in that it can be used for both
        # playing back recorded sessions *or* generating syslog-like output.
        if self.syslog:
            # Try and keep it as line-line as possible so we don't end up with
            # a log line per character.
            import syslog
            if '\n' in stream:
                for line in stream.splitlines():
                    if self.syslog_buffer:
                        line = self.syslog_buffer + line
                        self.syslog_buffer = ''
                    # Sylog really doesn't like any fancy encodings
                    line = line.encode('ascii', 'xmlcharrefreplace')
                    syslog.syslog("%s %s: %s" % (
                        self.user, self.term_id, line))
            else:
                self.syslog_buffer += stream
        # Handle preprocess patterns (for expect())
        if self._patterns:
            self.preprocess(stream)
        self.term.write(stream)
        # Handle post-process patterns (for expect())
        if self._patterns:
            self.postprocess()
        if self.CALLBACK_UPDATE in self.callbacks:
            for callback in self.callbacks[self.CALLBACK_UPDATE].values():
                self._call_callback(callback)

    def preprocess(self, stream):
        """
        Handles preprocess patterns registered by :meth:`expect`.  That
        is, those patterns which have been marked with `preprocess = True`.
        Patterns marked in this way get handled *before* the terminal emulator
        processes the :obj:`stream`.

        :stream: A string or bytes containing the incoming output stream from the underlying terminal program.
        """
        preprocess_patterns = (a for a in self._patterns if a.preprocess)
        finished_non_sticky = False
        # If there aren't any preprocess patterns this won't do anything:
        for pattern_obj in preprocess_patterns:
            if finished_non_sticky and not pattern_obj.sticky:
                # We only want sticky patterns if we've already matched once
                continue
            if isinstance(pattern_obj.pattern, (list, tuple)):
                for pat in pattern_obj.pattern:
                    match = pat.search(stream)
                    if match:
                        callback = partial(
                            pattern_obj.callback, self, match.group())
                        self._call_callback(callback)
                        if not pattern_obj.sticky:
                            self.unexpect(hash(pattern_obj)) # Remove it
                            break
            else:
                match = pattern_obj.pattern.search(stream)
                if match:
                    callback = partial(
                        pattern_obj.callback, self, match.group())
                    self._call_callback(callback)
                    if not pattern_obj.sticky:
                        self.unexpect(hash(pattern_obj)) # Remove it
            if not pattern_obj.optional:
                # We only match the first non-optional pattern
                finished_non_sticky = True

    def postprocess(self):
        """
        Handles post-process patterns registered by :meth:`expect`.
        """
        # Check the terminal emulator screen for any matching patterns.
        post_patterns = (a for a in self._patterns if not a.preprocess)
        finished_non_sticky = False
        for pattern_obj in post_patterns:
            # For post-processing matches we search the terminal emulator's
            # screen as a single string.  This allows for full-screen screen
            # scraping in addition to typical 'expect-like' functionality.
            # The big difference being that with traditional expect (and
            # pexpect) you don't get to examine the program's output as it
            # would be rendered in an actual terminal.
            # By using post-processing of the text after it has been handled
            # by a terminal emulator we don't have to worry about hidden
            # characters and escape sequences that we may not be aware of or
            # could make our regular expressions much more complicated than
            # they should be.
            if finished_non_sticky and not pattern_obj.sticky:
                continue # We only want sticky patterns at this point
            # For convenience, trailing whitespace is removed from the lines
            # output from the terminal emulator.  This is so we don't have to
            # put '\w*' before every '$' to match the end of a line.
            term_lines = "\n".join(
                [a.rstrip() for a in self.term.dump()]).rstrip()
            if isinstance(pattern_obj.pattern, (list, tuple)):
                for pat in pattern_obj.pattern:
                    match = pat.search(term_lines)
                    if match:
                        self._handle_match(pattern_obj, match)
                        break
            else:
                match = pattern_obj.pattern.search(term_lines)
                if match:
                    self._handle_match(pattern_obj, match)
            if not pattern_obj.optional and not pattern_obj.sticky:
                # We only match the first non-optional pattern
                finished_non_sticky = True

    def _handle_match(self, pattern_obj, match):
        """
        Handles a matched regex detected by :meth:`postprocess`.  It calls
        :obj:`Pattern.callback` and takes care of removing it from
        :attr:`_patterns` (if it isn't sticky).
        """
        if self._handling_match:
            # Don't process anything if we're in the middle of handling a match.
            # NOTE: This can happen when there's more than one thread,
            # processes, or PeriodicCallback going on simultaneously.  It seems
            # to work better than threading.Lock()
            return
        self._handling_match = True
        callback = partial(pattern_obj.callback, self, match.group())
        self._call_callback(callback)
        if self.debug:
            # Turn on the fancy regex debugger/pretty printer
            debug_callback = partial(
                debug_expect, self, match.group(), pattern_obj.pattern)
            self._call_callback(debug_callback)
        if not pattern_obj.sticky:
            self.unexpect(hash(pattern_obj)) # Remove it
        self._handling_match = False

    def writeline(self, line=''):
        """
        Just like :meth:`write` but it writes a newline after writing *line*.

        If no *line* is given a newline will be written.
        """
        self.write(line + u'\r\n')

    def writelines(self, lines):
        """
        Writes *lines* (a list of strings) to the underlying program, appending
        a newline after each line.
        """
        if getattr(lines, '__iter__', False):
            for line in lines:
                self.write(line + u'\r\n')
        else:
            raise TypeError(_(
                "%s is not iterable (strings don't count :)" % type(lines)))

    def dump_html(self, full=False, client_id='0'):
        """
        Returns the difference of terminal lines (a list of lines, to be
        specific) and its scrollback buffer (which is also a list of lines) as a
        tuple::

            (scrollback, screen)

        If a line hasn't changed since the last dump said line will be replaced
        with an empty string in the output.

        If *full*, will return the entire screen (not just the diff).

        if *client_id* is given (string), this will be used as a unique client
        identifier for keeping track of screen differences (so you can have
        multiple clients getting their own unique diff output for the same
        Multiplex instance).
        """
        modified = True
        if client_id not in self.prev_output:
            self.prev_output[client_id] = [None for a in xrange(self.rows-1)]
        try:
            scrollback, html = ([], [])
            if self.term:
                try:
                    modified = self.term.modified
                    result = self.term.dump_html()
                    if result:
                        scrollback, html = result
                        if scrollback:
                            self.shared_scrollback = scrollback
                        # Make a copy so we can save it to prev_output later
                        preserved_html = html[:]
                except IOError as e:
                    logging.debug(_("IOError attempting self.term.dump_html()"))
                    logging.debug("%s" % e)
            if html:
                if not full:
                    count = 0
                    for line1, line2 in izip(self.prev_output[client_id], html):
                        if line1 != line2:
                            html[count] = line2 # I love updates-in-place
                        else:
                            html[count] = ''
                        count += 1
                    # Otherwise a full dump will take place
                self.prev_output.update({client_id: preserved_html})
            if not modified:
                return (self.shared_scrollback, html)
            return (scrollback, html)
        except ValueError as e:
            # This would be special...
            logging.error(_("ValueError in dump_html(): %s" % e))
            return ([], [])
        except (IOError, TypeError) as e:
            logging.error(_("Unhandled exception in dump_html(): %s" % e))
            if self.ratelimiter_engaged:
                # Caused by the program being out of control
                return([], [
                    _("<b>Program output too noisy.  Sending Ctrl-c...</b>")])
            else:
                import traceback
                traceback.print_exc(file=sys.stdout)
            return ([], [])

    def dump(self):
        """
        Dumps whatever is currently on the screen of the terminal emulator as
        a list of plain strings (so they'll be escaped and look nice in an
        interactive Python interpreter).
        """
        return self.term.dump()

    def timeout_check(self, timeout_now=False):
        """
        Iterates over :attr:`BaseMultiplex._patterns` checking each to
        determine if it has timed out.  If a timeout has occurred for a
        `Pattern` and said Pattern has an *errorback* function that function
        will be called.

        Returns True if there are still non-sticky patterns remaining.  False
        otherwise.

        If *timeout_now* is True, will force the first errorback to be called
        and will empty out self._patterns.
        """
        remaining_patterns = False
        for pattern_obj in self._patterns:
            if timeout_now:
                if pattern_obj.errorback:
                    errorback = partial(pattern_obj.errorback, self)
                    self._call_callback(errorback)
                    self.unexpect()
                    return False
            if not pattern_obj.timeout:
                # Timeouts of 0 or None mean "wait forever"
                remaining_patterns = True
                continue
            elapsed = datetime.now() - pattern_obj.created
            if elapsed > pattern_obj.timeout:
                if not pattern_obj.sticky:
                    self.unexpect(hash(pattern_obj))
                if pattern_obj.errorback:
                    errorback = partial(pattern_obj.errorback, self)
                    self._call_callback(errorback)
            elif not pattern_obj.sticky:
                remaining_patterns = True
        return remaining_patterns

    def expect(self, patterns, callback,
            optional=False,
            sticky=False,
            errorback=None,
            timeout=15,
            position=None,
            preprocess=True):
        """
        Watches the stream of output coming from the underlying terminal program
        for *patterns* and if there's a match *callback* will be called like so::

            callback(multiplex_instance, matched_string)

        .. tip:: You can provide a string instead of a *callback* function as a shortcut if you just want said string written to the child process.

        *patterns* can be a string, an :class:`re.RegexObject` (as created by
        :func:`re.compile`), or a iterator of either/or.  Returns a reference
        object that can be used to remove the registered pattern/callback at any
        time using the :meth:`unexpect` method (see below).

        .. note::  This function is non-blocking!

        .. warning::  The *timeout* value gets compared against the time :meth:`expect` was called to create it.  So don't wait too long if you're planning on using :meth:`await`!

        Here's a simple example that changes a user's password::

            >>> def write_password(m_instance, matched):
            ...     print("Sending Password... %s patterns remaining." % len(m_instance._patterns))
            ...     m_instance.writeline('somepassword')
            >>> m = Multiplex('passwd someuser') # Assumes running as root :)
            >>> m.expect('(?i)password:', write_password) # Step 1
            >>> m.expect('(?i)password:', write_password) # Step 2
            >>> print(len(m._patterns)) # To show that there's two in the queue
                2
            >>> m.spawn() # Execute the command
            >>> m.await(10) # This will block for up to 10 seconds waiting for self._patterns to be empty (not counting optional patterns)
            Sending Password... 1 patterns remaining.
            Sending Password... 0 patterns remaining.
            >>> m.isalive()
            False
            >>> # All done!

        .. tip:: The :meth:`await` method will automatically call :meth:`spawn` if not :meth:`isalive`.

        This would result in the password of 'someuser' being changed to 'somepassword'.  How is the order determined?  Every time :meth:`expect` is called it creates a new :class:`Pattern` using the given parameters and appends it to `self._patterns` (which is a list).  As each :class:`Pattern` is matched its *callback* gets called and the :class:`Pattern` is removed from `self._patterns` (unless *sticky* is `True`).  So even though the patterns and callbacks listed above were identical they will get executed and removed in the order they were created as each respective :class:`Pattern` is matched.

        .. note:: Only the first pattern, or patterns marked as *sticky* are checked against the incoming stream.  If the first non-sticky pattern is marked *optional* then the proceeding pattern will be checked (and so on).  All other patterns will sit in `self._patterns` until their predecessors are matched/removed.

        Patterns can be removed from `self._patterns` as needed by calling `unexpect(<reference>)`.  Here's an example::

            >>> def handle_accepting_ssh_key(m_instance, matched):
            ...     m_instance.writeline(u'yes')
            >>> m = Multiplex('ssh someuser@somehost')
            >>> ref1 = m.expect('(?i)Are you sure.*\(yes/no\)\?', handle_accepting_ssh_key, optional=True)
            >>> def send_password(m_instance, matched):
            ...    m_instance.unexpect(ref1)
            ...    m_instance.writeline('somepassword')
            >>> ref2 = m.expect('(?i)password:', send_password)
            >>> # spawn() and/or await() and do stuff...

        The example above would send 'yes' if asked by the SSH program to accept
        the host's public key (which would result in it being automatically
        removed from `self._patterns`).  However, if this condition isn't met
        before send_password() is called, send_password() will use the reference
        object to remove it directly.  This ensures that the pattern won't be
        accidentally matched later on in the program's execution.

        .. note:: Even if we didn't match the "Are you sure..." pattern it would still get auto-removed after its timeout was reached.

        **About pattern ordering:** The position at which the given pattern will
        be inserted in `self._patterns` can be specified via the
        *position* argument.  The default is to simply append which should be
        appropriate in most cases.

        **About Timeouts:** The *timeout* value passed to expect() will be used
        to determine how long to wait before the pattern is removed from
        self._patterns.  When this occurs, *errorback* will be called with
        current Multiplex instance as the only argument.  If *errorback* is None
        (the default) the pattern will simply be discarded with no action taken.

        .. note:: If *sticky* is True the *timeout* value will be ignored.

        **Notes about the length of what will be matched:**  The entire terminal
        'screen' will be searched every time new output is read from the
        incoming stream.  This means that the number of rows and columns of the
        terminal determines the size of the search.  So if your pattern needs to
        look for something inside of 50 lines of text you need to make sure that
        when you call `spawn` you specify at least `rows = 50`.  Example::

            >>> def handle_long_search(m_instance, matched):
            ...     do_stuff(matched)
            >>> m = Multiplex('someCommandWithLotsOfOutput.sh')
            >>> # 'begin', at least one non-newline char, 50 newlines, at least one char, then 'end':
            >>> my_regex = re.compile('begin.+[\\n]{50}.+end', re.MULTILINE)
            >>> ref = m.expect(my_regex, handle_accepting_ssh_key)
            >>> m.spawn(rows=51, cols=150)
            >>> # Call m.read(), m.spawn() or just let an event loop (e.g. Tornado's IOLoop) take care of things...

        **About non-printable characters:** If the *postprocess* argument is
        True (the default), patterns will be checked against the current screen as
        output by the terminal emulator.  This means that things like control
        codes and escape sequences will be handled and discarded by the terminal
        emulator and as such won't be available for patterns to be checked
        against.  To get around this limitation you can set *preprocess* to True
        and the pattern will be checked against the incoming stream before it is
        processed by the terminal emulator.  Example::

            >>> def handle_xterm_title(m_instance, matched):
            ...     print("Caught title: %s" % matched)
            >>> m = Multiplex('echo -e "\\033]0;Some Title\\007"')
            >>> title_seq_regex = re.compile(r'\\x1b\\][0-2]\;(.*?)(\\x07|\\x1b\\\\)')
            >>> m.expect(title_seq_regex, handle_xterm_title, preprocess=True) # <-- 'preprocess=True'
            >>> m.await()
            Caught title: Some Title
            >>>

        **Notes about debugging:** Instead of using `await` to wait for all of your patterns to be matched at once you can make individual calls to `read` to determine if your patterns are being matched in the way that you want.  For example::

            >>> def do_stuff(m_instance, matched):
            ...     print("Debug: do_stuff() got %s" % repr(matched))
            ...     # Do stuff here
            >>> m = Multiplex('someLongComplicatedOutput.sh')
            >>> m.expect('some pattern', do_stuff)
            >>> m.expect('some other pattern', do_stuff)
            >>> m.spawn()
            >>> # Instead of calling await() just call one read() at a time...
            >>> print(repr(m.read()))
            ''
            >>> print(repr(m.read())) # Oops, called read() too soon.  Try again:
            'some other pattern'
            >>> # Doh!  Looks like 'some other pattern' comes first.  Let's start over...
            >>> m.unexpect() # Called with no arguments, it empties m._patterns
            >>> m.terminate() # Tip: This will call unexpect() too so the line above really isn't necessary
            >>> m.expect('some other pattern', do_stuff) # This time this one will be first
            >>> m.expect('some pattern', do_stuff)
            >>> m.spawn()
            >>> print(repr(m.read())) # This time I waited a moment :)
            'Debug: do_stuff() got "some other pattern"'
            'some other pattern'
            >>> # Huzzah!  Now let's see if 'some pattern' matches...
            >>> print(repr(m.read()))
            'Debug: do_stuff() got "some pattern"'
            'some pattern'
            >>> # As you can see, calling read() at-will in an interactive interpreter can be very handy.

        **About asynchronous use:**  This mechanism is non-blocking (with the exception of `await`) and is meant to be used asynchronously.  This means that if the running program has no output, `read` won't result in any patterns being matched.  So you must be careful about timing *or* you need to ensure that `read` gets called either automatically when there's data to be read (IOLoop, EPoll, select, etc) or at regular intervals via a loop.  Also, if you're not calling `read` at an interval (i.e. you're using a mechanism to detect when there's output to be read before calling it e.g. IOLoop) you need to ensure that `timeout_check` is called regularly anyway or timeouts won't get detected if there's no output from the underlying program.  See the `MultiplexPOSIXIOLoop.read` override for an example of what this means and how to do it.
        """
        # Create the Pattern object before we do anything else
        if isinstance(patterns, (str, unicode)):
            # Convert to a compiled regex (assume MULTILINE and DOTALL for the
            # sanity of the ignorant)
            patterns = re.compile(patterns, re.MULTILINE|re.DOTALL)
        if isinstance(patterns, (tuple, list)):
            # Ensure that all patterns are RegexObjects
            pattern_list = []
            for pattern in patterns:
                if isinstance(pattern, str):
                    pattern = re.compile(pattern)
                    pattern_list.append(pattern)
                else:
                    pattern_list.append(pattern)
            patterns = tuple(pattern_list) # No reason to keep it as a list
        # Convert timeout to a timedelta if necessary
        if timeout: # 0 or None mean "wait forever"
            if isinstance(timeout, (str, int, float)):
                timeout = timedelta(seconds=float(timeout))
            elif not isinstance(timeout, timedelta):
                raise TypeError(_(
                    "The timeout value must be a string, integer, float, or a "
                    "timedelta object"))
        pattern_obj = Pattern(patterns, callback,
            optional=optional,
            sticky=sticky,
            errorback=errorback,
            preprocess=preprocess,
            timeout=timeout)
        if isinstance(position, int):
            self._patterns.insert(position, pattern_obj)
        else:
            self._patterns.append(pattern_obj)
        return hash(pattern_obj)

    def unexpect(self, ref=None):
        """
        Removes *ref* from self._patterns so it will no longer be checked
        against the incoming stream.  If *ref* is None (the default),
        `self._patterns` will be emptied.
        """
        if not ref:
            self._patterns = [] # Reset
            return
        for i, item in enumerate(self._patterns):
            if hash(item) == ref:
                self._patterns.pop(i)

    def await(self, timeout=15, **kwargs):
        """
        Blocks until all non-optional patterns inside self._patterns have been
        removed *or* if the given *timeout* is reached.  *timeout* may be an
        integer (in seconds) or a `datetime.timedelta` object.

        Returns True if all non-optional, non-sticky patterns were handled
        successfully.

        .. warning:: The timeouts attached to Patterns are set when they are created.  Not when when you call :meth:`await`!

        As a convenience, if :meth:`isalive` resolves to False,
        :meth:`spawn` will be called automatically with *\*\*kwargs*

        await
            To wait with expectation.
        """
        if not self.isalive():
            self.spawn(**kwargs)
        start = datetime.now()
        # Convert timeout to a timedelta if necessary
        if isinstance(timeout, (str, int, float)):
            timeout = timedelta(seconds=float(timeout))
        elif not isinstance(timeout, timedelta):
            raise TypeError(_(
                "The timeout value must be a string, integer, float, or a "
                "timedelta object"))
        remaining_patterns = True
        # This starts up the scheduler that constantly checks patterns
        output = self.read() # Remember:  read() is non-blocking
        if output and self.debug and EXTRA_DEBUG:
            print("await: %s" % repr(output))
        while remaining_patterns:
            # First we need to discount optional patterns
            remaining_patterns = False
            if not self._patterns:
                break
            for pattern in self._patterns:
                if not pattern.optional and not pattern.sticky:
                    remaining_patterns = True
                    break
            # Now check if we've timed out
            if (datetime.now() - start) > timeout:
                for pattern in self._patterns:
                    if not pattern.sticky and not pattern.optional:
                        print(
                          "We were waiting on this pattern before timeout: %s" %
                          repr(pattern.pattern.pattern))
                raise Timeout("Lingered longer than %s" % timeout.seconds)
            # Lastly we perform a read() to ensure the output is processed
            output = self.read() # Remember:  read() is non-blocking
            if output and self.debug and EXTRA_DEBUG:
                print("await: %s" % repr(output))
            time.sleep(0.01) # So we don't eat up all the CPU
        return True

    def terminate(self):
        """
        This method must be overridden by suclasses of `BaseMultiplex`.  It is
        expected to terminate/kill the child process.
        """
        raise NotImplementedError(_(
            "terminate() *must* be overridden by subclasses."))

    def _read(self, bytes=-1):
        """
        This method must be overridden by subclasses of `BaseMultiplex`.  It is
        expected that this method read the output from the running terminal
        program in a non-blocking way, pass the result into `term_write`, and
        then return the result.
        """
        raise NotImplementedError(_(
            "_read() *must* be overridden by subclasses."))

    def read(self, bytes=-1):
        """
        Calls `_read` and checks if any timeouts have been reached in
        `self._patterns`.  Returns the result of `_read`.
        """
        result = self._read(bytes)
        # Perform checks for timeouts in self._patterns (used by self.expect())
        self.timeout_check()
        return result

    def write(self):
        raise NotImplementedError(_(
            "write() *must* be overridden by subclasses."))

class MultiplexPOSIXIOLoop(BaseMultiplex):
    """
    The MultiplexPOSIXIOLoop class takes care of executing a child process on
    POSIX (aka Unix) systems and keeping track of its state via a terminal
    emulator (`terminal.Terminal` by default).  If there's a started instance
    of :class:`tornado.ioloop.IOLoop`, handlers will be added to it that
    automatically keep the terminal emulator synchronized with the output of the
    child process.

    If there's no IOLoop (or it just isn't started), terminal applications can
    be interacted with by calling `MultiplexPOSIXIOLoop.read` (to write any
    pending output to the terminal emulator) and `MultiplexPOSIXIOLoop.write`
    (which writes directly to stdin of the child).

    .. note:: `MultiplexPOSIXIOLoop.read` is non-blocking.
    """
    def __init__(self, *args, **kwargs):
        super(MultiplexPOSIXIOLoop, self).__init__(*args, **kwargs)
        from tornado import ioloop
        self.terminating = False
        self.sent_sigint = False
        self.shell_command = ['/bin/sh', '-c']
        self.use_shell = True # Controls whether or not we wrap with the above
        self.env = {}
        self.io_loop = ioloop.IOLoop.current() # Monitors child for activity
        #self.io_loop.set_blocking_signal_threshold(2, self._blocked_io_handler)
        #signal.signal(signal.SIGALRM, self._blocked_io_handler)
        self.reenable_timeout = None
        interval = 100 # A 0.1 second interval should be fast enough
        self.scheduler = ioloop.PeriodicCallback(self._timeout_checker,interval)
        self.exitstatus = None
        self._checking_patterns = False
        self.read_timeout = datetime.now()
        self.capture_limit = -1 # Huge reads by default
        self.restore_rate = None

    def __del__(self):
        """
        Makes sure that the underlying terminal program is terminated so we
        don't leave things hanging around.
        """
        logging.debug("MultiplexPOSIXIOLoop.__del__()")
        self.terminate()

    def _call_callback(self, callback):
        """
        If the IOLoop is started, adds the callback via
        :meth:`IOLoop.add_callback` to ensure it gets called at the next IOLoop
        iteration (which is thread safe).  If the IOLoop isn't started
        *callback* will get called immediately and directly.
        """
        if self.io_loop._running:
            self.io_loop.add_callback(callback)
        else:
            callback()

    def _reenable_output(self):
        """
        Restarts capturing output from the underlying terminal program by
        disengaging the rate limiter.
        """
        logging.debug("Disabling rate limiter")
        self.ratelimiter_engaged = False
        try:
            self.io_loop.add_handler(
                self.fd, self._ioloop_read_handler, self.io_loop.READ)
        except IOError:
            # Already been re-added...  Probably by write().  Ignore.
            pass

    def __reset_sent_sigint(self):
        self.sent_sigint = False

    def _blocked_io_handler(self, signum=None, frame=None, wait=None):
        """
        Handles the situation where a terminal is blocking IO (usually because
        of too much output).  This method would typically get called inside of
        `MultiplexPOSIXIOLoop._read` when the output of an fd is too noisy.

        If *wait* is given, will wait that many milliseconds long before
        disengaging the rate limiter.
        """
        if not self.isalive():
            # This can happen if terminate() gets called too fast from another
            # thread...  Strange stuff, mixing threading, signals, and
            # multiprocessing!
            return # Nothing to do
        logging.warning(_(
            "Noisy process (%s) kicked off rate limiter." % self.pid))
        if not wait:
            wait = 5000
        self.ratelimiter_engaged = True
        # CALLBACK_UPDATE is called here so the client can be made aware of the
        # fact that the rate limiter was engaged.
        for callback in self.callbacks[self.CALLBACK_UPDATE].values():
            self._call_callback(callback)
        self.io_loop.remove_handler(self.fd)
        self.reenable_timeout = self.io_loop.add_timeout(
            timedelta(milliseconds=wait), self._reenable_output)

    def spawn(self,
            rows=24, cols=80, env=None, em_dimensions=None, exitfunc=None):
        """
        Creates a new virtual terminal (tty) and executes self.cmd within it.
        Also attaches :meth:`self._ioloop_read_handler` to the IOLoop so that
        the terminal emulator will automatically stay in sync with the output of
        the child process.

        :cols: The number of columns to emulate on the virtual terminal (width)
        :rows: The number of rows to emulate (height).
        :env: Optional - A dictionary of environment variables to set when executing self.cmd.
        :em_dimensions: Optional - The dimensions of a single character within the terminal (only used when calculating the number of rows/cols images take up).
        :exitfunc: Optional - A function that will be called with the current Multiplex instance and its exit status when the child process terminates (*exitfunc(m_instance, statuscode)*).
        """
        self.started = datetime.now()
        #signal.signal(signal.SIGCHLD, signal.SIG_IGN) # No zombies allowed
        logging.debug(
            "spawn(rows=%s, cols=%s, env=%s, em_dimensions=%s)" % (
                rows, cols, repr(env), repr(em_dimensions)))
        rows = min(200, rows) # Max 200 to limit memory utilization
        cols = min(500, cols) # Max 500 for the same reason
        self.rows = rows
        self.cols = cols
        self.em_dimensions = em_dimensions
        import pty
        pid, fd = pty.fork()
        if pid == 0: # We're inside the child process
    # Close all file descriptors other than stdin, stdout, and stderr (0, 1, 2)
            try:
                # This ensures that the child doesn't get the parent's FDs
                os.closerange(3, 256)
            except OSError:
                pass
            if not env:
                env = {}
            env["COLUMNS"] = str(cols)
            env["LINES"] = str(rows)
            env["TERM"] = env.get("TERM", "xterm-256color")
            env["PATH"] = os.environ['PATH']
            env["LANG"] = os.environ.get('LANG', 'en_US.UTF-8')
            env["PYTHONIOENCODING"] = "utf_8"
            # Setup stdout to be more Gate One friendly
            import termios
            # Fix missing termios.IUTF8
            if 'IUTF8' not in termios.__dict__:
                termios.IUTF8 = 16384 # Hopefully not platform independent
            stdin = 0
            stdout = 1
            stderr = 2
            attrs = termios.tcgetattr(stdout)
            iflag, oflag, cflag, lflag, ispeed, ospeed, cc = attrs
            # Enable flow control and UTF-8 input (probably not needed)
            iflag |= (termios.IXON | termios.IXOFF | termios.IUTF8)
            # OPOST: Enable post-processing of chars (not sure if this matters)
            # INLCR: We're disabling this so we don't get \r\r\n anywhere
            oflag |= (termios.OPOST | termios.ONLCR | termios.INLCR)
            attrs = [iflag, oflag, cflag, lflag, ispeed, ospeed, cc]
            termios.tcsetattr(stdout, termios.TCSANOW, attrs)
            # Now do the same for stdin
            attrs = termios.tcgetattr(stdin)
            iflag, oflag, cflag, lflag, ispeed, ospeed, cc = attrs
            iflag |= (termios.IXON | termios.IXOFF | termios.IUTF8)
            oflag |= (termios.OPOST | termios.ONLCR | termios.INLCR)
            attrs = [iflag, oflag, cflag, lflag, ispeed, ospeed, cc]
            termios.tcsetattr(stdin, termios.TCSANOW, attrs)
            # The sleep statements below do two things:
            #   1) Ensures all the callbacks have time to be attached before
            #      the command is executed (so we can handle things like
            #      setting the title when the command first runs).
            #   2) Ensures we capture all output from the fd before it gets
            #      closed.
            import shlex
            cmd = shlex.split(self.cmd)
            if self.use_shell:
                if not isinstance(self.shell_command, list):
                    self.shell_command = shlex.split(self.shell_command)
                cmd = self.shell_command + [self.cmd + '; sleep .1']
            # This loop prevents UnicodeEncodeError exceptions:
            for k, v in env.items():
                if isinstance(v, unicode):
                    env[k] = v.encode('utf-8')
            os.dup2(stderr, stdout) # Copy stderr to stdout (equivalent to 2>&1)
            os.execvpe(cmd[0], cmd, env)
            os._exit(0)
        else: # We're inside this Python script
            logging.debug("spawn() pid: %s" % pid)
            self._alive = True
            self.fd = fd
            self.env = env
            self.exitfunc = exitfunc
            self.pid = pid
            self.time = time.time()
            try:
                self.term = self.terminal_emulator(
                    rows=rows,
                    cols=cols,
                    em_dimensions=em_dimensions,
                    encoding=self.encoding,
                    **self.terminal_emulator_kwargs
                )
            except TypeError:
                # Terminal emulator doesn't support em_dimensions.  That's OK
                self.term = self.terminal_emulator(
                    rows=rows,
                    cols=cols,
                    encoding=self.encoding,
                    **self.terminal_emulator_kwargs
                )
            # Tell our IOLoop instance to start watching the child
            self.io_loop.add_handler(
                fd, self._ioloop_read_handler, self.io_loop.READ)
            self.prev_output = {}
            self.shared_scrollback = []
            # Set non-blocking so we don't wait forever for a read()
            import fcntl
            fl = fcntl.fcntl(sys.stdin, fcntl.F_GETFL)
            fcntl.fcntl(self.fd, fcntl.F_SETFL, fl | os.O_NONBLOCK)
            # Set the size of the terminal
            resize = partial(self.resize, rows, cols, ctrl_l=False)
            self.io_loop.add_timeout(timedelta(milliseconds=100), resize)
            return fd

    def isalive(self):
        """
        Checks the underlying process to see if it is alive and sets self._alive
        appropriately.
        """
        if self._alive: # Re-check it
            try:
                os.kill(self.pid, 0) # kill -0 tells us it's still alive
                return self._alive
            except OSError:
                # Process is dead
                self._alive = False
                logging.debug(_(
                    "Child exited with status: %s" % self.exitstatus))
                self.terminate()
                return False
        else:
            return False

    def resize(self, rows, cols, em_dimensions=None, ctrl_l=True):
        """
        Resizes the child process's terminal window to *rows* and *cols* by
        first sending it a TIOCSWINSZ event and then sending ctrl-l.

        If *em_dimensions* are provided they will be updated along with the
        rows and cols.

        The sending of ctrl-l can be disabled by setting *ctrl_l* to False.
        """
        logging.debug(
            "Resizing term %s to rows: %s, cols: %s, em_dimensions=%s"
            % (self.term_id, rows, cols, em_dimensions))
        if rows < 2:
            rows = 24
        if cols < 2:
            cols = 80
        self.rows = rows
        self.cols = cols
        self.term.resize(rows, cols, em_dimensions)
        # Sometimes the resize doesn't actually apply (for whatever reason)
        # so to get around this we have to send a different value than the
        # actual value we want then send our actual value.  It's a bug outside
        # of Gate One that I have no idea how to isolate but this has proven to
        # be an effective workaround.
        import fcntl, termios
        s = struct.pack("HHHH", rows, cols, 0, 0)
        try:
            fcntl.ioctl(self.fd, termios.TIOCSWINSZ, s)
        except IOError:
            # Process already ended--no big deal
            return
        try:
            os.kill(self.pid, signal.SIGWINCH) # Send the resize signal
        except OSError:
            return # Process is dead.  Can happen when things go quickly
        if ctrl_l:
            self.write(u'\x0c') # ctrl-l

    def terminate(self):
        """
        Kill the child process associated with `self.fd`.

        .. note:: If dtach is being used this only kills the dtach process.
        """
        if not self.terminating:
            self.terminating = True
        else:
            return # Something else already called it
        logging.debug("terminate() self.pid: %s" % self.pid)
        if self.reenable_timeout:
            self.io_loop.remove_timeout(self.reenable_timeout)
        # Unset our blocked IO handler so there's no references to self hanging
        # around preventing us from freeing up memory
        try:
            self.io_loop.set_blocking_signal_threshold(None, None)
        except ValueError:
            pass # Can happen if this instance winds up in a thread
        for callback in self.callbacks[self.CALLBACK_EXIT].values():
            self._call_callback(callback)
        # This try/except block *must* come before the exitfunc logic.
        # Otherwise, if the registered exitfunc raises an exception the IOLoop
        # will never stop watching self.fd; resulting in an infinite loop of
        # exitfunc.
        try:
            self.io_loop.remove_handler(self.fd)
            os.close(self.fd)
        except (KeyError, IOError, OSError):
            # This can happen when the fd is removed by the underlying process
            # before the next cycle of the IOLoop.  Not really a problem.
            pass
        self.scheduler.stop()
        # NOTE: Without this 'del' we end up with a memory leak every time
        # a new instance of Multiplex is created.  Apparently the references
        # inside of PeriodicCallback pointing to self prevent proper garbage
        # collection.
        del self.scheduler
        try:
            os.kill(self.pid, signal.SIGTERM)
            def recheck_kill():
                if self.isalive():
                    os.kill(self.pid, signal.SIGKILL)
            # NOTE: This will delay calling of this Multiplex instance's
            #       __del__() method by the same number of seconds...
            self.io_loop.add_timeout(timedelta(seconds=3), recheck_kill)
        except OSError:
            # The process is already dead--great.
            pass
        if self.exitstatus == None:
            try:
                pid, status = os.waitpid(self.pid, 0)
                if pid: # pid is 0 if the process is still running
                    self.exitstatus = os.WEXITSTATUS(status)
            except OSError:
                # This can happen if the program closes itself very quickly
                # immediately after being executed.
                try: # Try again with -1
                    pid, status = os.waitpid(-1, os.WNOHANG)
                    if pid: # pid is 0 if the process is still running
                        self.exitstatus = os.WEXITSTATUS(status)
                except OSError:
                    logging.debug(_(
                        "Could not determine exit status for child with "
                        "PID: %s\n" % self.pid
                    ))
                    logging.debug(_("Setting self.exitstatus to 999"))
                    self.exitstatus = 999 # Seems like a good number
        if self._patterns:
            self.timeout_check(timeout_now=True)
            self.unexpect()
        # Call the exitfunc (if set)
        if self.exitfunc:
            self.exitfunc(self, self.exitstatus)
            self.exitfunc = None
        # Reset all callbacks so there's nothing to prevent GC
        self.callbacks = {
            self.CALLBACK_UPDATE: {},
            self.CALLBACK_EXIT: {},
        }
        # Commented this out so that you can see what was in the terminal
        # emulator after the process terminates.
        #del self.term
        # Kick off a process that finalizes the log (updates metadata and
        # recompresses everything to save disk space)
        if not self.log_path:
            return # No log to finalize so we're done.
        if not self.log:
            return # No log to finalize so we're done.
        self.log.close() # Write it out
        logging.info(_("Finalizing {path} (pid: {pid})").format(
            path=self.log_path, pid=self.pid))
        PROC = Process(
            target=get_or_update_metadata,
            args=(self.log_path, self.user),
            kwargs={'force_update': True})
        PROC.start()

    def _ioloop_read_handler(self, fd, event):
        """
        Read in the output of the process associated with *fd* and write it to
        `self.term`.

        :fd: The file descriptor of the child process.
        :event: An IOLoop event (e.g. IOLoop.READ).

        .. note:: This method is not meant to be called directly...  The IOLoop should be the one calling it when it detects any given event on the fd.
        """
        if event == self.io_loop.READ:
            self._call_callback(self.read)
        else: # Child died
            logging.debug(_(
                "Apparently fd %s just died (event: %s)" % (self.fd, event)))
            #if self.debug:
                #print(repr("".join([a for a in self.term.dump() if a.strip()])))
            self.terminate()

    def _read(self, bytes=-1):
        """
        Reads at most *bytes* from the incoming stream, writes the result to
        the terminal emulator using `term_write`, and returns what was read.
        If *bytes* is -1 (default) it will read `self.fd` until there's no more
        output.

        Returns the result of all that reading.

        .. note:: Non-blocking.
        """
        # Commented out because it can be really noisy.  Uncomment only if you
        # *really* need to debug this method.
        #logging.debug("MultiplexPOSIXIOLoop._read()")
        result = b""
        def restore_capture_limit():
            self.capture_limit = -1
            self.restore_rate = None
        try:
            with io.open(self.fd, 'rb', closefd=False, buffering=0) as reader:
                if bytes == -1:
                    # 2 seconds of blocking is too much.
                    timeout = timedelta(seconds=2)
                    loop_start = datetime.now()
                    if self.ctrl_c_pressed:
                        # If the user pressed Ctrl-C and the ratelimiter was
                        # engaged then we'd best discard the (possibly huge)
                        # buffer so we don't waste CPU cyles processing it.
                        reader.read(-1)
                        self.ctrl_c_pressed = False
                        return u'^C\n' # Let the user know what happened
                    if self.restore_rate:
                        # Need at least three seconds of inactivity to go back
                        # to unlimited reads
                        self.io_loop.remove_timeout(self.restore_rate)
                        self.restore_rate = self.io_loop.add_timeout(
                            timedelta(seconds=6), restore_capture_limit)
                    while True:
                        updated = reader.read(self.capture_limit)
                        if not updated:
                            break
                        result += updated
                        self.term_write(updated)
                        if self.ratelimiter_engaged or self.capture_ratelimiter:
                            break # Only allow one read per IOLoop loop
                        if self.capture_limit == 2048:
                            # Block for a little while: Enough to keep things
                            # moving but not fast enough to slow everyone else
                            # down
                            self._blocked_io_handler(wait=1000)
                            break
                        if datetime.now() - loop_start > timeout:
                            # Engage the rate limiter
                            if self.term.capture:
                                self.capture_ratelimiter = True
                                self.capture_limit = 65536
                                # Make sure we eventually get back to defaults:
                                self.io_loop.add_timeout(
                                    timedelta(seconds=10),
                                    restore_capture_limit)
                                # NOTE: The capture_ratelimiter doesn't remove
                                # self.fd from the IOLoop (that's the diff)
                            else:
                                # Set the capture limit to a smaller value so
                                # when we re-start output again the noisy
                                # program won't be able to take over again.
                                self.capture_limit = 2048
                                self.restore_rate = self.io_loop.add_timeout(
                                    timedelta(seconds=6),
                                    restore_capture_limit)
                                self._blocked_io_handler()
                            break
                elif bytes:
                    result = reader.read(bytes)
                    self.term_write(result)
        except IOError as e:
            # IOErrors can happen when self.fd is closed before we finish
            # reading from it.  Not a big deal.
            pass
        except OSError as e:
            logging.error("Got exception in read: %s" % repr(e))
        # This can be useful in debugging:
        #except Exception as e:
            #import traceback
            #logging.error(
                #"Got unhandled exception in read (???): %s" % repr(e))
            #traceback.print_exc(file=sys.stdout)
            #if self.isalive():
                #self.terminate()
        if self.debug:
            if result:
                print("_read(): %s" % repr(result))
        return result

    def _timeout_checker(self):
        """
        Runs `timeout_check` and if there are no more non-sticky
        patterns in :attr:`self._patterns`, stops :attr:`scheduler`.
        """
        if not self._checking_patterns:
            self._checking_patterns = True
            remaining_patterns = self.timeout_check()
            if not remaining_patterns:
                # No reason to keep the PeriodicCallback going
                logging.debug("Stopping self.scheduler (no remaining patterns)")
                try:
                    self.scheduler.stop()
                except AttributeError:
                # Now this is a neat trick:  The way IOLoop works with its
                # stack_context thingamabob the scheduler doesn't actualy end up
                # inside the MultiplexPOSIXIOLoop instance inside of this
                # instance of _timeout_checker() *except* inside the main
                # thread.  It is absolutely wacky but it works and works well :)
                    pass
            self._checking_patterns = False

    def read_raw(self, bytes=-1):
        """
        Reads the output from the underlying fd and returns the result.

        .. note: This method does not send the output to the terminal emulator.
        """
        result = ""
        try:
            with io.open(self.fd, 'rb', closefd=False,buffering=1024) as reader:
                result = reader.read(bytes)
        except IOError as e:
            # IOErrors can happen when self.fd is closed before we finish
            # reading from it.  Not a big deal.
            pass
        except OSError as e:
            logging.error("Got exception in read: %s" % repr(e))
        return result

    def read(self, bytes=-1):
        """
        .. note:: This is an override of `BaseMultiplex.read` in order to take advantage of the IOLoop for ensuring `BaseMultiplex.expect` patterns timeout properly.

        Calls `_read` and checks if any timeouts have been reached
        in :attr:`self._patterns`.  Returns the result of :meth:`_read`.  This
        is an override of `BaseMultiplex.read` that will create a
        :class:`tornado.ioloop.PeriodicCallback` (as `self.scheduler`) that
        executes :attr:`timeout_check` at a regular interval.  The
        `PeriodicCallback` will automatically cancel itself if there are no more
        non-sticky patterns in :attr:`self._patterns`.
        """
        # 50ms basic output rate limit on everything
        rate_wait = timedelta(milliseconds=50)
        if datetime.now() - self.read_timeout > rate_wait:
            result = self._read(bytes)
            self.read_timeout = datetime.now()
            remaining_patterns = self.timeout_check()
            if remaining_patterns and not self.scheduler._running:
                # Start 'er up in case we don't get any more output
                logging.debug("Starting self.scheduler to check for timeouts")
                self.scheduler.start()
            self.isalive() # This just ensures the exitfunc is called (if necessary)
            try:
                pid, status = os.waitpid(self.pid, os.WNOHANG)
            except OSError:
                # Process is dead; call terminate() to clean things up
                self.terminate()
                return result
            if pid: # pid is 0 if the process is still running
                self.exitstatus = os.WEXITSTATUS(status)
            return result

    def _write(self, chars):
        """
        Writes *chars* to `self.fd` (pretty straightforward).  If IOError or
        OSError exceptions are encountered, will run `terminate`.  All other
        exceptions are logged but no action will be taken.
        """
        #logging.debug("MultiplexPOSIXIOLoop._write(%s)" % repr(chars))
        try:
            with io.open(
                self.fd, 'wt', encoding='UTF-8', closefd=False) as writer:
                    writer.write(chars)
            if self.ratelimiter_engaged:
                if u'\x03' in chars: # Ctrl-C
                    # This will force self._read() to discard the buffer
                    self.ctrl_c_pressed = True
                # Reattach the fd so the user can continue immediately
                self._reenable_output()
        except OSError as e:
            logging.error(_(
                "Encountered error writing to terminal program: %s") % e)
            if self.isalive():
                self.terminate()
        except IOError as e:
            # We can safely ignore most of these...  They tend to crop up when
            # writing big chunks of data to dtach'd terminals.
            if not 'raw write()' in e.message:
                logging.error("write() exception: %s" % e)
        except Exception as e:
            logging.error("write() exception: %s" % e)

    def write(self, chars):
        """
        Calls `_write(*chars*)` via `_call_callback` to ensure thread safety.
        """
        if not self.isalive():
            raise ProgramTerminated(_("Child process is not running."))
        write = partial(self._write, chars)
        self._call_callback(write)

# Here's an example of how termio compares to pexpect:
#import pexpect
#child = pexpect.spawn ('ftp ftp.openbsd.org')
#child.expect ('Name .*: ')
#child.sendline ('anonymous')
#child.expect ('Password:')
#child.sendline ('noah@example.com')
#child.expect ('ftp> ')
#child.sendline ('cd pub')
#child.expect('ftp> ')
#child.sendline ('get ls-lR.gz')
#child.expect('ftp> ')
#child.sendline ('bye')
# NOTE: Every expect() in the above example is a blocking call.

# This is the same thing, rewritten using termio:
#import termio
#child = termio.Multiplex('ftp ftp.openbsd.org', debug=True)
## Expectations come first
#child.expect('Name .*:', "anonymous\n")
#child.expect('Password:', 'user@company.com\n')
#child.expect('ftp>$', 'cd pub\n')
#child.expect('ftp>$', 'get ls-lR.gz\n')
#child.expect('ftp>$', 'bye\n')
#child.await() # Blocks until all patterns have been matched or a timeout
# NOTE: If this code were called inside of an already-started IOLoop there would
# be no need to call await(). Everything would be asynchronous and non-blocking.

def spawn(cmd, rows=24, cols=80, env=None, em_dimensions=None, *args, **kwargs):
    """
    A shortcut to::

        m = Multiplex(cmd, *args, **kwargs)
        m.spawn(rows, cols, env)
        return m
    """
    m = Multiplex(cmd, *args, **kwargs)
    m.spawn(rows, cols, env, em_dimensions=em_dimensions)
    return m

def getstatusoutput(cmd, **kwargs):
    """
    Emulates Python's commands.getstatusoutput() function using a Multiplex
    instance.

    Optionally, any additional keyword arguments (\*\*kwargs) provided will be
    passed to the spawn() command.
    """
    # NOTE: This function is primarily here to provide an example of how to use
    # termio.Multiplex instances in a traditional, blocking manner.
    output = ""
    m = Multiplex(cmd)
    m.spawn(**kwargs)
    while m.isalive():
        result = m.read()
        if result:
            output += result
        time.sleep(0.01) # Reduce CPU overhead
    return (m.exitstatus, output)

if POSIX:
    Multiplex = MultiplexPOSIXIOLoop
else:
    raise NotImplementedError(_(
        "termio currently only works on Unix platforms."))

########NEW FILE########
