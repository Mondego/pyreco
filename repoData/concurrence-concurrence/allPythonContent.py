__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# Concurrence documentation build configuration file, created by
# sphinx-quickstart on Wed Dec 24 14:40:01 2008.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# The contents of this file are pickled, so don't put values in the namespace
# that aren't pickleable (module imports are okay, they're removed automatically).
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If your extensions are in another directory, add it here. If the directory
# is relative to the documentation root, use os.path.abspath to make it
# absolute, like shown here.
#sys.path.append(os.path.abspath('.'))

# General configuration
# ---------------------

autoclass_content = "both"

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
source_encoding = 'latin-1'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'Concurrence Framework'
copyright = u'Copyright (C) 2009, Hyves (Startphone Ltd.)'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
from concurrence import __version__

version = __version__
# The full version, including alpha/beta/rc tags.
release = __version__

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of documents that shouldn't be included in the build.
#unused_docs = []

# List of directories, relative to source directory, that shouldn't be searched
# for source files.
exclude_trees = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'


# Options for HTML output
# -----------------------

# The style sheet to use for HTML and HTML Help pages. A file of that name
# must exist either in Sphinx' static/ path, or in one of the custom paths
# given in html_static_path.
html_style = 'default.css'

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_use_modindex = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, the reST sources are included in the HTML build as _sources/<name>.
#html_copy_source = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# If nonempty, this is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = ''

# Output file base name for HTML help builder.
htmlhelp_basename = 'Concurrencedoc'


# Options for LaTeX output
# ------------------------

# The paper size ('letter' or 'a4').
#latex_paper_size = 'letter'

# The font size ('10pt', '11pt' or '12pt').
#latex_font_size = '10pt'

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, document class [howto/manual]).
latex_documents = [
  ('index', 'Concurrence.tex', ur'Concurrence Documentation',
   ur'Henk Punt', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# Additional stuff for the LaTeX preamble.
#latex_preamble = ''

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_use_modindex = True

########NEW FILE########
__FILENAME__ = chat
from concurrence import dispatch, Tasklet, Message
from concurrence.io import BufferedStream, Socket, Server

class MSG_WRITE_LINE(Message): pass
class MSG_QUIT(Message): pass
class MSG_LINE_READ(Message): pass

connected_clients = set() #set of currently connected clients (tasks)
        
def handle(client_socket):
    """handles a single client connected to the chat server"""
    stream = BufferedStream(client_socket)

    client_task = Tasklet.current() #this is the current task as started by server
    connected_clients.add(client_task)
    
    def writer():
        for msg, args, kwargs in Tasklet.receive():
            if msg.match(MSG_WRITE_LINE):
                stream.writer.write_bytes(args[0] + '\n')
                stream.writer.flush()
            
    def reader():
        for line in stream.reader.read_lines():
            line = line.strip()
            if line == 'quit': 
                MSG_QUIT.send(client_task)()
            else:
                MSG_LINE_READ.send(client_task)(line)
    
    reader_task = Tasklet.new(reader)()
    writer_task = Tasklet.new(writer)()

    MSG_WRITE_LINE.send(writer_task)("type 'quit' to exit..")
    
    for msg, args, kwargs in Tasklet.receive():
        if msg.match(MSG_QUIT):
            break
        elif msg.match(MSG_LINE_READ):
            #a line was recv from our client, multicast it to the other clients
            for task in connected_clients:
                if task != client_task: #don't echo the line back to myself
                    MSG_WRITE_LINE.send(task)(args[0])
        elif msg.match(MSG_WRITE_LINE):
            MSG_WRITE_LINE.send(writer_task)(args[0])
        
    connected_clients.remove(client_task)
    reader_task.kill()
    writer_task.kill()
    client_socket.close()
           
def server():
    """accepts connections on a socket, and dispatches
    new tasks for handling the incoming requests"""
    print 'listening for connections on port 9010'
    Server.serve(('localhost', 9010), handle)

if __name__ == '__main__':
    dispatch(server)

########NEW FILE########
__FILENAME__ = greeter
from concurrence import dispatch, Tasklet
from concurrence.io import BufferedStream, Socket

def handler(client_socket):
    """writes the familiar greeting to client"""
    stream = BufferedStream(client_socket)
    writer = stream.writer    
    writer.write_bytes("HTTP/1.0 200 OK\r\n")
    writer.write_bytes("Content-Length: 12\r\n")    
    writer.write_bytes("\r\n")
    writer.write_bytes("Hello World!")
    writer.flush()
    stream.close()
       
def server():
    """accepts connections on a socket, and dispatches
    new tasks for handling the incoming requests"""
    server_socket = Socket.new()
    server_socket.bind(('localhost', 8080))
    server_socket.listen()

    while True:
        client_socket = server_socket.accept()
        Tasklet.new(handler)(client_socket)

if __name__ == '__main__':
    dispatch(server)

########NEW FILE########
__FILENAME__ = hello
from concurrence import dispatch

def hello():
    print "Hello World!"
    
if __name__ == '__main__':
    dispatch(hello)  

########NEW FILE########
__FILENAME__ = http
from concurrence import dispatch
from concurrence.http import WSGIServer

def hello_world(environ, start_response):
    start_response("200 OK", [])
    return ["<html>Hello, world!</html>"]

def main():
    server = WSGIServer(hello_world)
    server.serve(('localhost', 8080))

if __name__ == '__main__':
    dispatch(main)

########NEW FILE########
__FILENAME__ = http_client
from concurrence import dispatch
from concurrence.http import HTTPConnection

def main():
    
    cnn = HTTPConnection()
    cnn.connect(('www.google.com', 80))

    request = cnn.get('/')
    response = cnn.perform(request)
    
    print response.status
    print response.headers
    print response.body

    cnn.close()

if __name__ == '__main__':
    dispatch(main)

########NEW FILE########
__FILENAME__ = http_client_pipeline
from concurrence import dispatch
from concurrence.http import HTTPConnection

def main():
    
    cnn = HTTPConnection()
    cnn.connect(('www.google.com', 80))

    request = cnn.get('/')

    #you can send multiple http requests on the same connection:
    cnn.send(request) #request 1
    cnn.send(request) #request 2

    #and receive the corresponding responses    
    response1 = cnn.receive()
    response2 = cnn.receive()

    print response1.status
    print response1.headers
    print response1.body

    print response2.status
    print response2.headers
    print response2.body

    cnn.close()

if __name__ == '__main__':
    dispatch(main)

########NEW FILE########
__FILENAME__ = message
from concurrence import Tasklet, Message, dispatch

class MSG_GREETING(Message): pass
class MSG_FAREWELL(Message): pass

def printer():
    for msg, args, kwargs in Tasklet.receive():
        if msg.match(MSG_GREETING):
            print 'Hello', args[0]
        elif msg.match(MSG_FAREWELL):
            print 'Goodbye', args[0]
        else:
            pass #unknown msg
    
def main():
    
    printer_task = Tasklet.new(printer)()
    
    MSG_GREETING.send(printer_task)('World')
    MSG_FAREWELL.send(printer_task)('World')
        
if __name__ == '__main__':
    dispatch(main)  

########NEW FILE########
__FILENAME__ = post
from concurrence import dispatch
from concurrence.wsgi import WSGIServer, WSGISimpleRouter

def show_form(environ, start_response):
    print environ
    start_response("200 OK", [('Content-type', 'text/html')])

    html = """
    <html>
    <body>
        <form method='post' action='/process'>
            <input name='a'></input>
            <input name='b'></input>
            <input type='submit' value='click!'></input>
        </form>
    </body>
    </html>
    """
    return [html]

def upload_form(environ, start_response):
    print environ
    start_response("200 OK", [])

    html = """
    <html>
    <body>
        <form method='post' action='/process' enctype='multipart/form-data'>
            <input type='file' name='thefile'></input>
            <input type='a' name='a' value='klaas'></input>
            <input type='b' name='b' value='piet'></input>
            <input type='submit' value='click!'></input>
        </form>
    </body>
    </html>
    """
    return [html]

def process_form(environ, start_response):
    print 'proc form'    
    print environ
    
    fp = environ['wsgi.input']
    while True:
        data = fp.read(1024)
        if not data: break
        print 'read', repr(data)

    start_response("200 OK", [])

    html = """
    <html>
    <body>
        <h1>blaat</h1>
    </body>
    </html>
    """
    return [html]

def main():
    application = WSGISimpleRouter()

    from wsgiref.validate import validator

    application.map('/form', validator(show_form))
    application.map('/upload', upload_form)
    application.map('/process', process_form)

    server = WSGIServer(application)
    server.serve(('localhost', 8080))

if __name__ == '__main__':
    import logging
    logging.basicConfig(level = logging.DEBUG)
    dispatch(main)

########NEW FILE########
__FILENAME__ = web
from concurrence import dispatch
from concurrence.web import Application, Controller, Filter, web

class PageFilter(Filter):
    """A filter that surrounds the upstream response with a complete html page"""
    def __call__(self, next, *args, **kwargs):
        #A Filter is a callable object and is part of a chain of filters configured for
        #a certain Action. A filter uses the `next` argument to call the next filter in the chain.
        return """
        <html>
            <head>
                <title>Example Page</title>
            </head>
            <body style='background-color: #a0f0f0'>
            %s
            </body>
        </html>""" % next(*args, **kwargs)
    
class WrapperFilter(Filter):
    """A filter that surrounds the upstream response with a tag"""
    def __init__(self, tag):
        self.tag = tag
        
    def __call__(self, next, *args, **kwargs):
        return "<%s>%s</%s>" % (self.tag,  next(*args, **kwargs), self.tag)
    
class ExampleController(Controller):
    """A Controller contains multiple Actions. A controller
    method becomes an Action by adding a `web.route` decorator that links the method to an url."""
    
    #controller level filters are applied to all actions in the controller
    __filters__ = [PageFilter()]  
    
    #a action may be linked to multiple urls
    @web.route('/greeting')
    @web.route('/welcome')
    def hello(self):
        return "Hello World" 

    @web.route('/farewell')
    def goodbye(self):
        return "Goodbye" 
	
    @web.route('/sum') 
    def sum(self):
	
        msg = self.request.params.getone('msg')
        a = int(self.request.params.getone('a'))
        b = int(self.request.params.getone('b'))

        return '%s %d' % (msg, a + b)

    #in addition to the controller level filters, an action may also supply its own filters
    @web.route('/wrapper')
    @web.filter(WrapperFilter('h1'))
    @web.filter(WrapperFilter('strong'))    
    def wrapper(self):
        return "Testing 132"
    
def main():
    #create a web application
    application = Application()
    application.add_controller(ExampleController())
    application.configure()
    application.serve(('localhost', 8080))

if __name__ == '__main__':
    dispatch(main)

########NEW FILE########
__FILENAME__ = application
"""a small IOC container"""
#TODO services (parallel for same runlevel)

import inspect

class Context(object): 
    @classmethod
    def set_attribute(cls, obj, key, val):
        """recurisivly adds fields to obj according to key
        the final field will have val"""
        idx_dot = key.find('.')
        if idx_dot == -1: #single key
            setattr(obj, key, val)
        else: #dotted key
            keyhead, keyrest = key[:idx_dot], key[idx_dot+1:]
            if hasattr(obj, keyhead):
                p = getattr(obj, keyhead)            
                cls.set_attribute(p, keyrest, val)
            else:
                p = Context()
                cls.set_attribute(p, keyrest, val)
                setattr(obj, key[:idx_dot], p)

context = Context()

class Container(object):
    def __init__(self):
        self.resources = {}

    def add(self, key, resource):
        self.resources[key] = resource
    
    def configure(self, parameters, prefix = 'config'):  
        """adds all key, value pairs in dict config as resources to the container, prefixed by prefix"""
        if not parameters:
            return
        for key, val in parameters.items():
            self.resources[prefix + '.' + key] = val

    def finalize(self):
        """configures all resources that need configuring"""
        Context.set_attribute(context, 'container', self)
        for k in sorted(self.resources.keys()):        
            #print k, self.resources[k]
            Context.set_attribute(context, k, self.resources[k])
            
    def _find_members(self, filter):
        import re
        for name, resource in self.resources.items():
            for member_name, member in inspect.getmembers(resource, inspect.ismethod):
                fa = re.findall(filter, member_name)
                if fa:
                    yield name, resource, fa, getattr(resource, member_name)
        
    def statistics(self):
        """return all the statistics from all the resources that define them"""
        stats = {}
        for name, resource, fa, member in self._find_members('__statistics__'):
            stats[name] = member()
        return stats
    
    def start(self):
        """starts up services, services are started up by calling their
        __startXX__ methods, start methods in the same runlevel are started
        concurrently (TODO)"""
        for _, resource, fa, member in self._find_members(r'__start(\d\d)__'):
            try:
                level = int(fa[0])
            except:
                level = -1
                
            if level != -1:
                #start the service
                member()
                
container = Container()


########NEW FILE########
__FILENAME__ = deque
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

from concurrence.core import Deque


########NEW FILE########
__FILENAME__ = dequedict
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

class node: pass

class DequeDict(object):
    """dequedict data structure, e.g. a combination of
    a deque and a map collection
    the deque is based on a circular doubly linked list"""
    def __init__(self, i = []):
        self.l = node() #sentinel node for doubly linked list
        self.l.next = self.l
        self.l.prev = self.l
        self.l.key = None
        self.l.value = None
        self.d = {} #key->n
        if i: self.extend(i)

    def extend(self, l):
        """appends values from sequence l to the end of the list"""
        for key, value in l: self.append(key, value)
        
    def append(self, key, value):
        """adds (key, value) to the end of the list"""
        n = node()
        n.key = key
        n.value = value
        #add n to end of list
        self.l.prev.next = n
        n.prev = self.l.prev        
        n.next = self.l
        self.l.prev = n
        #add n to the map
        self.d[key] = n
        
    def appendleft(self, key, value):
        """adds (key, value) to the head of the list"""
        n = node()
        n.key = key
        n.value = value
        #add n to front of list
        self.l.next.prev = n
        n.next = self.l.next        
        n.prev = self.l
        self.l.next = n
        #add n to the map
        self.d[key] = n
        
    def pop(self):
        """removes entry from back of the list and returns (key, value)"""
        n = self.l.prev
        n.prev.next = self.l
        self.l.prev = n.prev
        del self.d[n.key]
        return (n.key, n.value)

    def popleft(self):
        """removes entry from front of the list and returns (key, value)"""
        n = self.l.next
        n.next.prev = self.l
        self.l.next = n.next
        del self.d[n.key]
        return (n.key, n.value)
    
    def iteritemsright(self):
        """a generator that yields items (key, value) from the list, rightmost first"""
        n = self.l.prev
        while n != self.l:
            yield (n.key, n.value)
            n = n.prev
            
    def iteritems(self):
        """a generator that yields items (key, value) from the list, leftmost first"""
        n = self.l.next
        while n != self.l:
            yield (n.key, n.value)
            n = n.next

    def iterkeys(self):
        """a generator that yields keys from the list, leftmost first"""
        for key, _ in self.iteritems():
            yield key

    def itervalues(self):
        """a generator that yields values from the list, leftmost first"""
        for _, value in self.iteritems():
            yield value

    def iterkeysright(self):
        """a generator that yields keys from the list, rightmost first"""
        for key, _ in self.iteritemsright():
            yield key
            
    def movehead(self, key):
        """moves item identified by key to the head of the list"""
        #remove from old position in list
        n = self.d[key]
        n.next.prev = n.prev
        n.prev.next = n.next
        #put in front position of list
        self.l.next.prev = n
        n.next = self.l.next        
        n.prev = self.l
        self.l.next = n
        
    def keys(self):
        return list(self.iterkeys())
    
    def values(self):
        return list(self.itervalues())
    
    def items(self):
        return list(self.iteritems())
    
    def removeall(self, key):
        if key in self: del self[key]
            
    def __getitem__(self, key):
        #TODO key == -1
        return self.d[key].value

    def __delitem__(self, key):
        """removes item with given key"""
        n = self.d[key]
        n.next.prev = n.prev
        n.prev.next = n.next
        del self.d[key]

    def __iter__(self):
        return self.iterkeys()
    
    def __contains__(self, key):
        return key in self.d
    
    def __len__(self):
        return len(self.d)
    
    def __nonzero__(self):
        return bool(self.d)
    
    def __getstate__(self):
        #convert doubly linked list into simple
        #array otherwise pickle will give maxrecursiondepth exeeded problems
        state = self.__dict__.copy()
        state['l'] = list(self.iteritems()) #simple list of tuples (key, value)
        del state['d'] #can be rebuild from array
        return state
    
    def __setstate__(self, state):
        self.__init__(state['l'])

    def __repr__(self):
        return 'dequedict([%s])' % ','.join(['(%s, %s)' % (repr(key), repr(value)) for key, value in self.iteritems()])
    

########NEW FILE########
__FILENAME__ = reque
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

from collections import deque

class ReorderQueue(object):
    
    def __init__(self):
        self._finished = {}
        self._queue = deque()

    def start(self, request):
        """notes the start of a request"""
        self._queue.append(request)

    def finish(self, request, response):
        """finishes the given request with its corresponding response and yields
        any available (request, response) in order"""
        self._finished[request] = response
        while True:
            if self._queue and self._queue[0] in self._finished:
                request = self._queue.popleft()
                response = self._finished[request]
                del self._finished[request]
                yield (request, response)
            else:
                break


########NEW FILE########
__FILENAME__ = core
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

import sys
import time
import logging
import weakref
import collections
import gc

try:
    import stackless
except ImportError: 
    #we might be running from CPython, or PyPy
    #try the greenlet based stackless emulation
    import _stackless as stackless

if '-Xnogc' in sys.argv:
    logging.warn('disabling gc')    
    gc.disable()

DEBUG_LEAK = False
if '-Xleak' in sys.argv:
    logging.warn('turned on leak detection')
    gc.set_debug(gc.DEBUG_SAVEALL)        
    DEBUG_LEAK = True

from signal import SIGINT
from concurrence import _event

def get_version_info():
    return {'libevent_version': _event.version(),
            'libevent_method': _event.method()}
    
if '-Xversion' in sys.argv:
    print 'libevent: version: %s, method: %s' % (_event.version(),  _event.method())
    print 'python:', sys.version

EXIT_CODE_OK = 0
EXIT_CODE_ERROR = 1
EXIT_CODE_SIGINT = 127
EXIT_CODE_TIMEOUT = 128

class TimeoutError(Exception): 
    """This exception can be raised by various methods that accept *timeout* parameters.""" 
    
class TaskletError(Exception):
    def __init__(self, cause, tasklet):
        self.cause = cause
        self.tasklet = tasklet
    
class JoinError(TaskletError):
    """A JoinError can be raised from any of the :func:`join_XXX` methods of the
    :class:`Tasklet` class."""    
    pass

class Event(object): 
    pass

class FileDescriptorEvent(Event):
    def __init__(self, fd, rw):
        if rw == 'r':
            ev = _event.EV_READ
        elif rw == 'w':
            ev = _event.EV_WRITE
        else:
            assert False, "rw must be one of ['r', 'w']"
        self._event = _event.event(self._on_event, ev, fd)
        self._current_channel = None #this is where read/write ability is notified

    def _on_event(self, ev_type):
        if self._current_channel is None:
            return #already closed
        if ev_type & _event.EV_TIMEOUT:
            self._current_channel.send_exception(TimeoutError, "timeout on fd event")
        else:
            self._current_channel.send(self)

    def notify(self, channel = None, timeout = -1.0):
        if channel is None: channel = Channel()
        self._current_channel = channel
        self._event.add(timeout)
        
    def wait(self, channel = None, timeout = -1.0):
        self.notify(channel, timeout)
        return self._current_channel.receive()        

    def delete(self):
        self._event.delete()

    def close(self):
        self.delete()
        self._event = None
        self._current_channel = None

class SignalEvent(Event):
    def __init__(self, signo, callback, persist = True):
        self._persist = persist
        self._callback = callback
        self._event = _event.event(self._on_event, _event.EV_SIGNAL, signo)
        self._event.add()

    def _on_event(self, ev_type):
        #print 'signal event'
        if self._persist: 
            self._event.add()
        if callable(self._callback):
            self._callback()

    def close(self):
        self._event.delete()
        del self._event
        del self._callback

class TimeoutEvent(Event):
    def __init__(self, timeout, callback, persist = False):
        self._persist = persist
        self._timeout = timeout
        self._callback = callback
        self._event = _event.event(self._on_event, 0)
        self._event.add(timeout)

    def _on_event(self, ev_type):
        #print 'timeout event'
        if self._persist: 
            self._event.add(self._timeout)
        if callable(self._callback):
            self._callback()

    def close(self):
        self._event.delete()
        del self._event
        del self._callback

class Message():
    def __init__(self, reply_channel = None):
        self._reply_channel = reply_channel
        
    def match(self, cls):
        """Checks whether this message is an instance of the given message class *cls*.""" 
        return isinstance(self, cls)
        
    def reply(self, result):
        """Reply to the message and return *result* to the caller."""
        if self._reply_channel is None:
            assert False, "can only reply to a synchronous message, e.g. somebody must be calling us with 'call'"
        else:
            self._reply_channel.send(result)

    def wait(self, timeout = -1):
        if self._reply_channel is None:
            assert False, "can only wait on a synchronous message"
        else:
            return self._reply_channel.receive(timeout)

    @classmethod
    def send(cls, receiver):
        """Asynchronously sends the message *cls* to the given *receiver*."""
        def _sender(*args, **kwargs):
            receiver.send(cls(), *args, **kwargs)
        return _sender
    
    @classmethod
    def call(cls, receiver, timeout = -1):
        """Synchronously send the message *cls* to the given *receiver* and waits 
        for a response. The result will be the response of the *receiver*.
        Optionally a *timeout* in seconds can be specified. If the receiver does not respond within
        the *timeout* period a :class:`TimeoutError` is raised."""
        def _caller(*args, **kwargs):   
            return receiver.call(cls(Channel()), timeout, *args, **kwargs)
        return _caller

class Deque(collections.deque):
    """Deque is an extension of the standard python deque that provides blocking operations and timeouts"""
    def __init__(self, iterable = []):
        collections.deque.__init__(self, iterable)
        self.channel = Channel()
        
    def pop(self, blocking = False, timeout = -1):
        """Pop the last item from the end of the queue. If *blocking* is True, the caller will block for *timeout* seconds until an item 
        becomes available."""
        if len(self) == 0 and blocking:
            self.channel.receive(timeout)
        return collections.deque.pop(self)
    
    def popleft(self, blocking = False, timeout = -1):
        """Pop the first item from the start of the queue. If *blocking* is True, the caller will block for *timeout* seconds until an item 
        becomes available."""
        if len(self) == 0 and blocking:
            self.channel.receive(timeout)
        return collections.deque.popleft(self)
    
    def append(self, x):
        """Append item *x* to the end of the queue."""
        collections.deque.append(self, x)
        if self.channel.balance < 0:
            self.channel.send(True)
                    
    def appendleft(self, x):
        """Append item *x* to the start of the queue."""
        collections.deque.appendleft(self, x)
        if self.channel.balance < 0:
            self.channel.send(True)                    

class Mailbox(Deque):
    """Every tasklet has a mailbox, a queue of messages send by other tasklets that are not yet consumed."""
    pass

class Tasklet(stackless.tasklet):
    """A Tasklet represents an activity that runs concurrently to other Tasklets.
    A Tasklet can be compared to a Thread with the main difference that Tasklets are scheduled co-operatively
    by the Concurrence framework as opposed to Threads, which are scheduled pre-emptively by the OS. 

    Only 1 Tasklet will be actually using 1 CPU at any point in time. But many Tasks
    may be present at the same time. 
    
    A Tasklet can become inactive (block) as soon as it performs some IO, or it explictly releases
    control (for instance by calling :func:`yield_`). 

    As soon as a Tasklet blocks, the Concurrence framework will schedule
    some other Tasklet to run next (in a round-robin fashion).
     
    If a Tasklet became inactive because it needs to wait for IO, The Concurrence framework
    will automatically reschedule that Tasklet again as soon as that IO is complete.""" 
    
    def __init__(self):
        """Please use :func:`new` to create new tasklets"""
        stackless.tasklet.__init__(self)
        self.name = ''
        self._parent = None
        self._children = None
        self._join_channel = None
        self._mailbox = None

    def __exec__(self, f, *args, **kwargs):
        """Wraps the excecution of the task function f in such
        a way that we maintain a nice tree of tasklets. Also
        implements a method to join 2 tasklets such that you can
        wait for a tasklet to exit and receive its result (the result of f)"""
        try:
            self._result = f(*args, **kwargs)           
            if self._join_channel:
                self._join_channel.send(self)
        except TaskletExit, e:
            self._result_exc = e
            if self._join_channel:
                self._join_channel.send_exception(JoinError, e, self)
            else:
                raise
        except Exception, e:
            self._result_exc = e
            if self._join_channel:
                self._join_channel.send_exception(JoinError, e, self)
            else:
                raise
        except:
            self._result_exc = sys.exc_type
            if self._join_channel:
                self._join_channel.send_exception(JoinError, sys.exc_type, self)
            else:
                raise
        finally:
            #i am finished so remove myself from my parents child list
            parent = self.parent()
            if parent:
                parent._remove_child(self)
            self._parent = None
            self._children = None
            self._join_channel = None
            self._mailbox = None
            
    def has_finished(self):
        """Returns whether this Tasklet has already finished or not (either with a result of with an exception)."""
        return hasattr(self, '_result') or hasattr(self, '_result_exc')
    
    def _add_child(self, child):
        if self._children is None:
            self._children = set()
        self._children.add(child)
        
    def _remove_child(self, child):
        if self._children is not None:         
            self._children.remove(child)
        
    def children(self):
        """Gets the set of children of this Tasklet"""
        if self._children is None:
            return set()
        else:
            return self._children

    #TODO parent() and children() should be properties
    def _set_parent(self, parent):
        self._parent = weakref.ref(parent)

    def parent(self):
        """Gets the parent of this Tasklet. This method may return None if the parent is no longer there."""
        if self._parent is not None:
            return self._parent()
        else:
            return None
    
    @property
    def mailbox(self):
        """The queue of messages send by other tasklets that are not yet consumed. Use :func:`receive` to get pending message for the current task.
        Alternatively you can use the methods of :class:`Mailbox` directly.
        """
        if self._mailbox is None:
            self._mailbox = Mailbox()
        return self._mailbox 

    def send(self, msg, *args, **kwargs):
        self.mailbox.append((msg, args, kwargs))                  
    
    def call(self, msg, timeout, *args, **kwargs):
        self.send(msg, *args, **kwargs)
        return msg.wait(timeout)

    @classmethod
    def receive(cls, timeout = -1):
        """A generator that yields the next pending :class:`Message` in the :attr:`mailbox` of the current task. This
        method returns a tuple (msg, args, kwargs) for each message received. If no message is available the task blocks
        and waits for a message to arrive."""
        self = cls.current()
        mailbox = self.mailbox
        while True:
            x = mailbox.popleft(True, timeout)
            yield x
            
    @classmethod
    def yield_(cls):
        """Calls the scheduler to cooperatively schedule some other tasks.
        The current class will block and some other task will continue. The current task remains runnable
        and after some time it will be scheduled again and this method will return.
        If there is no other task runnable, this method is a no-op. 
        :func:`yield_` is used when a task is busy processing some
        lengthy calculation that contains no other blocking events like IO or timeouts. 
        By calling :func:`yield_` once in a while it can prevent itself from hogging 
        the CPU and give other tasks some change to do some work as well."""
        cls.sleep(0.0) 
        #note that we don't use stackless.schedule() here anymore. This would still hog the CPU, never getting
        #never getting into the libevent loop again. by using sleep we prevent this    

    def _get_result(self):
        if hasattr(self, '_result'):
            return self._result
        elif hasattr(self, '_result_exc'):
            raise JoinError(self._result_exc, self)
        else:
            assert False, 'Cannot get result of a task that has not finished'
        
    @classmethod
    def join(cls, t, timeout = -1):
        """The current task will block and wait for the given task *t* to complete. When *t* is finished, this method will return
        its result value. If *t* finishes with an exception this method will raise a :class:`JoinError`. Optionally a *timeout* in seconds may
        be specified. If *task* does not finish within *timeout* a :class:`TimeoutError` will be raised."""
        if t.has_finished():
            return t._get_result()
        if t._join_channel is not None:
            assert False, "Tasklet can only be joined once"
        t._join_channel = Channel()
        try:
            _ = t._join_channel.receive(timeout)
            return t._get_result() 
        finally:
            t._join_channel = None
        
    @classmethod
    def join_all(cls, tasks, timeout = -1):
        """The current task will block and wait for the given *tasks* to complete. When all *tasks* have finished a list of 
        results is returned. If a task finishes with an exception the result value for that task will be an instance of :class:`JoinError`.
        Optionally a *timeout* for the wait can be specified. If all *tasks* do not finish within *timeout* a :class:`TimeoutError` will be
        raised."""
            
        if timeout != -1:
            deadline = time.time() + timeout
        else:
            deadline = -1
            
        results = {}
        
        for t in tasks[:]: #tasks are copied to prevent modification during iteration
            try:
                if deadline == -1:
                    results[t] = cls.join(t, -1)
                else:
                    results[t] = cls.join(t, deadline - time.time())
            except JoinError, je:
                results[je.tasklet] = je
            except TaskletExit:
                raise
            except:
                assert False, "expecting only join errors here"
            
        return [results[t] for t in tasks]
    
    @classmethod
    def join_children(cls, timeout = -1):
        """A convenience method for joining all children of the current task. Behaves as :func:`join_all` where *tasks* is the list
        of children."""
        return cls.join_all(list(cls.current().children()), timeout = -1)
        
    @classmethod
    def loop(cls, f, **kwargs):
        """Creates a new task that will execute the given callable *f* in a loop.
        See :func:`new` for a description of any further keyword arguments.
        Any exception that is raised by *f* is caught and logged but the loop will continue running. A looping
        task can be stopped by calling :func:`kill` on it."""
        def _loop(*args, **kwargs):
            while True:
                try:
                    f(*args, **kwargs)
                except TaskletExit:
                    break
                except:
                    logging.exception("unhandled exception in Tasklet.loop")
                    cls.sleep(1.0) #prevent hogging the cpu if exception repeats
        
        return cls.new(_loop, **kwargs)
    
    @classmethod
    def interval(cls, timeout, f, immediate = False, **kwargs):
        """Creates a new task that will execute the given callable *f* every
        *timeout* seconds. If *immediate* is True, *f* will be called as soon as the 
        task is started. Otherwise, the newly started task will wait *timeout* seconds before
        calling *f* for the first time. See :func:`new` for a description of any further keyword arguments.
        Any exception that is raised by *f* is caught and logged but the interval task will continue running. An interval
        task can be stopped by calling :func:`kill` on it."""
        def _interval(*args, **kwargs):
            if immediate: f(*args, **kwargs)
            while True:
                cls.sleep(timeout)
                try:
                    f(*args, **kwargs)
                except TaskletExit:
                    break
                except:
                    logging.exception("unhandled exception in Tasklet.interval")
        return cls.new(_interval, **kwargs)

    @classmethod
    def rate(cls, rate, f, **kwargs):
        """Creates a new task that will call *f* *rate* times per second. The main difference with :func:`interval` is that
        this method is more accurate in calling *f* exactly *rate* times per second independent of the load generated by *f* and or
        other tasks running on the system. It does this by varying the interval on the basis of the difference between the target interval
        1 / *rate* and the actual interval found by measuring the timing. See :func:`new` for a description of any further keyword arguments.
        As a convenience the current time is passed as the first parameter to *f*.
        """
        def _interval(*args, **kwargs):
            sleep_channel = Channel()
            target_timeout = timeout = 1.0 / rate
            min_timeout = 0.5 * target_timeout
            max_timeout = 1.5 * target_timeout
            last_time = time.time()
            while True:
                try:
                    sleep_channel.receive(timeout)
                except TimeoutError:
                    current_time = time.time()
                    actual_timeout = current_time - last_time
                    last_time = current_time
                    diff = actual_timeout - target_timeout
                    next_timeout = timeout - diff
                    timeout = (0.8 * timeout) + (0.2 * next_timeout)
                    if timeout > max_timeout: timeout = max_timeout
                    if timeout < min_timeout: timeout = min_timeout
                try:
                    f(current_time, *args, **kwargs)
                except TaskletExit:
                    break
                except:
                    logging.exception("unhandled exception in Tasklet.rate")
        return cls.new(_interval, **kwargs)
    
    @classmethod
    def receiver(cls, f, **kwargs):
        """Creates a new task will that will wait for messages to arrive and calls *f* (msg, *args, **kwargs)
        for each :class:`Message` received. 
        See :func:`new` for a description of any further keyword arguments."""
        def _receiver():
            for msg, args, kwargs in cls.receive():
                try:
                    f(msg, *args, **kwargs)
                except TaskletExit:
                    break
                except:
                    logging.exception("unhandled exception in Tasklet.receiver")
        return cls.new(_receiver, **kwargs)

    @classmethod 
    def sleep(cls, timeout):
        """Blocks the current task for the given *timeout* in seconds."""
        sleep_channel = Channel()
        try:
            sleep_channel.receive(timeout)
        except TimeoutError:
            pass #expected to happen after timeout

    @classmethod       
    def current(cls):
        """Returns a reference to the currently running task"""
        return stackless.getcurrent()

    @classmethod 
    def later(cls, timeout, f, **kwargs):
        """Creates a new task that will first sleep for *timeout* seconds
        before calling *f*. See :func:`new` for a description of any further keyword arguments."""
        def x(*args, **kwargs):
            cls.sleep(timeout)
            return f(*args, **kwargs)
        return cls.new(x, **kwargs)
        
    @classmethod
    def new(cls, f, name = '', daemon = False):
        """Creates a new task that will run callable *f*. The new task can optionally
        be named *name*. If no *name* is given a name is derived from the callable *f*.
        
        The result of *f* will be the result of the tasklet. *f* may throw an exception, in which case
        the exception will be the result of the tasklet."""
        t = cls()
        if name is '':
            t.name = f.__name__
        else:
            t.name = name
        def w(*args, **kwargs):
            t.__exec__(f, *args, **kwargs)
        
        t.bind(w)
        if not daemon:
            parent = cls.current()    
            #stackless main task is not an instance of our Tasklet class (but of stackless.tasklet)
            #so we can only keep parent/child relation for Tasklet instances
            if isinstance(parent, cls):
                t._set_parent(parent)
                parent._add_child(t)
            
        return t

    def __str__(self):
        return "<Tasklet name='%s'>" % self.name

    def tree(self, level = 0):
        """An inorder treewalk starting at the current task and 
        iterating over its children, grandchildren etc. this generator
        yields tuples (task, level)."""
        yield (self, level)
        if self._children:
            for child in self._children:
                for child_task, child_level in child.tree(level + 1):
                    yield (child_task, child_level)
 
    def kill(self):
        """Raise a TaskletExit exception in the task. This will normally kill the task.
        Note that TaskletExit is a subclass of SystemExit and thus not a subclass of Exception.
        This means that if a task explicitly catches either TaskletExit or SystemExit it could
        prevent itself from being killed."""
        #overridden for documentation purposes
        stackless.tasklet.kill(self)

class Channel(object):
    """A Channel is a method for transfering control and/or communicate between Tasklets. 
    Please note that the Channel class is basically a small wrapper around a 
    `stackless channel <http://www.stackless.com/wiki/Channels>`_. 
    It was overridden in Concurrence to provide timeouts on the :func:`send` and :func:`receive` methods.

    A :class:`Tasklet` can :func:`receive` from a Channel as soon as some other Tasklet will :func:`send` on the 
    channel. If there is no sender the receiving Tasklet will block until a sender is available. If a sender and a 
    receiver are available, the sender will pass a value to the receiver and execution will continue in the receiver (The sender will
    become 'runnable' as well, but will be placed at the end of the scheduling queue).
    
    The reverse works the same. If there is a sender but no receiver, the sender will block until a receiver arrives. As soon
    as a receiver arrives, the value of the sender is passed and execution continues with the receiver (The sender will become `runnable`
    again, but will be placed at the end of the scheduling queue).
    """

    def __init__(self):
        self._channel = stackless.channel()

    @property
    def balance(self):
        return self._channel.balance

    def has_receiver(self):
        """Whether this Channel has any waiting receivers."""
        return self.balance < 0

    def has_sender(self):
        """Whether this Channel has any waiting senders."""
        return self.balance > 0
    
    def send_exception(self, *args, **kwargs):
        """Send an exception trough the channel instead of some value. This will immediatly raise the exception in the receiver."""
        self._channel.send_exception(*args, **kwargs)

    def receive(self, timeout = -1):
        """Receive from the channel. If there is no sender, the caller will block until there is one.
        Optionally you can specify a *timeout*. If a sender does not show up within the *timeout* period a
        :class:`TimeoutError` is raised. The method returns the value given by the sender.""" 
        if timeout == -1:
            #most common without timeout
            return self._channel.receive()
        else:
            current_task = Tasklet.current()
            def on_timeout():
                current_task.raise_exception(TimeoutError)
            event_timeout = TimeoutEvent(timeout, on_timeout)
            try:
                return self._channel.receive()
            finally:
                event_timeout.close()

    def send(self, value, timeout = -1):
        """Sends to the channel. If there is no receiver, the caller will block until there is one.
        If a receiver is present, the *value* will be passed to the receiver and execution will continue in the 
        receiver. 
        Optionally you can specify a *timeout*. If a receiver does not show up within the *timeout* period a
        :class:`TimeoutError` is raised.""" 
        if timeout == -1: 
            #most common without timeout
            self._channel.send(value)
        else:
            #setup timeout event
            current_task = Tasklet.current()
            def on_timeout():
                current_task.raise_exception(TimeoutError)
            event_timeout = TimeoutEvent(timeout, on_timeout)
            try:
                self._channel.send(value)
            finally:
                event_timeout.close()

_running = False #whether we are currently in dispatch, used stop the dispatch (use quit method)
_exitcode = EXIT_CODE_OK

def quit(exitcode = EXIT_CODE_OK):
    """Quits the concurrence program and exit to the OS with *exitcode*"""
    global _running
    global _exitcode
    _exitcode = exitcode
    _running = False
    
#monkey patch sys exit to call our quit in order
#to properly finish our dispatch loop
sys._exit = sys.exit
sys.exit = quit

def _print_objects(objs):
    d = {}
    for x in objs:
        if hasattr(x, '__class__'):
            name = x.__class__.__module__ + '.' + x.__class__.__name__
            if name in d:
                d[name] += 1
            else:
                d[name] = 1

    for name, count in sorted(d.items()):
        print name, count

def disable_threading():
    """Monkey patches python libs so that all threading stuff is gone"""
    from concurrence import _threading
    _threading.disable_threading()
    
def _dispatch(f = None):
    """The main dispatch routine. This is the starting point of any Concurrence program. 
    The dispatcher schedules tasklets until the :func:`quit` function is called or a SIGINT signal is received.
    As a convenience a callable *f* can be provided that will be run in a new Tasklet."""
    #first install signal handler
    #this way we can quit the program easily from the command line 
    #also, this makes libevent block on the first loop
    #otherwise when there are no events in the beginning, loop will not 
    #block and our main dispatch loop would claim 100% CPU time
    def interrupt():
        quit(EXIT_CODE_SIGINT)
    event_interrupt = SignalEvent(SIGINT, interrupt)
    
    #the heartbeat makes sure the main loop below at least
    #makes a cycle every second. otherwise, if there are no pending signals
    #libevent._loop would block indefinitly, causing our loop never to check
    #if it still must be _running...
    event_heartbeat = TimeoutEvent(1.0, None, True)
    
    if callable(f):
        Tasklet.new(f)()
        
    global _running
    _running = True
    try:
        #this is it, the main dispatch loop...
        #tasklets are scheduled to run by stackless, 
        #and if no more are runnable, we wait for IO events to happen
        #that will trigger tasks to become runnable
        #ad infinitum...
        while _running:
            try:
                while stackless.getruncount() > 1:
                    stackless.schedule()
            except TaskletExit:
                pass
            except:
                logging.exception("unhandled exception in dispatch schedule")
            #note that we changed the way pyevent notifies us of pending events
            #instead of calling the callbacks from within the pyevent extension
            #it returns the list of callbacks that have to be called.
            #calling from pyevent would give us a C stack which is not
            #optimal (stackless would hardswitch instead of softswitch)
            triggered = _event.loop()
            while triggered:
                callback, evtype = triggered.popleft()
                try:
                    callback(evtype)
                except TaskletExit:
                    raise
                except:
                    logging.exception("unhandled exception in dispatch event callback")
    finally:
        event_interrupt.close()
        event_heartbeat.close()
        
    if DEBUG_LEAK: 
        logging.warn("alive objects:")
        gc.collect()
        _print_objects(gc.get_objects())
        logging.warn('garbage:')
        _print_objects(gc.garbage)

    sys._exit(_exitcode)

def _profile(f = None):
    import resource 
    def cpu():
        return (resource.getrusage(resource.RUSAGE_SELF).ru_utime +
                resource.getrusage(resource.RUSAGE_SELF).ru_stime)

    from cProfile import Profile
    prof = Profile(cpu)
    try:
        prof = prof.runctx("_dispatch(f)", globals(), locals())
    except SystemExit:
        pass    

    import pstats
    stats = pstats.Stats(prof)
    stats.strip_dirs()
    stats.sort_stats('time')
    stats.print_stats(20)
        
def dispatch(f = None):
    if '-Xprofile' in sys.argv:
        _profile(f)
    else:
        _dispatch(f)


########NEW FILE########
__FILENAME__ = _sqlalchemy
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

from concurrence.database.pool import Pool, NullPool

class SqlAlchemyPooledConnection:
    def __init__(self, pool, connection):
        self.pool = pool
        self.connection = connection

    def __getattr__(self, key):
        return getattr(self.connection, key)
        
    def close(self, invalidated = False):
        connection = self.connection
        pool = self.pool
        self.connection = None 
        self.pool = None
        pool.disconnect(connection, close = invalidated)
    
    def is_valid(self):
        return self.connection is not None
    
    def invalidate(self, e):
        self.close(True)
        
class SqlAlchemyPoolAdapter(Pool):
    def connect(self):
        _, connection = Pool.connect(self)
        return SqlAlchemyPooledConnection(self, connection)

    def dispose(self):
        pass
    
    def recreate(self):
        return self
    
class SqlAlchemyNullPoolAdapter(NullPool):
    def connect(self):
        _, connection = NullPool.connect(self)
        return SqlAlchemyPooledConnection(self, connection)

    def dispose(self):
        pass
    
    def recreate(self):
        return self        

########NEW FILE########
__FILENAME__ = client
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

#TODO supporting closing a halfread resultset (e.g. automatically read and discard rest)

from concurrence import TimeoutError
from concurrence.io import Buffer 
from concurrence.io.socket import Socket 
from concurrence.timer import Timeout
from concurrence.database.mysql import BufferedPacketReader, BufferedPacketWriter, PACKET_READ_RESULT, CAPS, COMMAND 

import logging
import time

try:
    #python 2.6
    import hashlib
    SHA = hashlib.sha1
except ImportError:
    #python 2.5
    import sha
    SHA = sha.new

#import time
class ClientError(Exception):
    @classmethod
    def from_error_packet(cls, packet, skip = 8):
        packet.skip(skip)
        return cls(packet.read_bytes(packet.remaining))
    
class ClientLoginError(ClientError): pass
class ClientCommandError(ClientError): pass
class ClientProgrammingError(ClientError): pass 
    
class ResultSet(object):
    """Represents the current resultset being read from a Connection.
    The resultset implements an iterator over rows. A Resultset must
    be iterated entirely and closed explicitly."""
    STATE_INIT = 0
    STATE_OPEN = 1
    STATE_EOF = 2
    STATE_CLOSED = 3
    
    def __init__(self, connection, field_count):
        self.state = self.STATE_INIT
        
        self.connection = connection
        
        self.fields = connection.reader.read_fields(field_count)
        
        self.state = self.STATE_OPEN
        
    def __iter__(self):
        assert self.state == self.STATE_OPEN, "cannot iterate a resultset when it is not open"
        
        for row in self.connection.reader.read_rows(self.fields):
            yield row

        self.state = self.STATE_EOF
        
    def close(self, connection_close = False):  
        """Closes the current resultset. Make sure you have iterated over all rows before closing it!"""
        #print 'close on ResultSet', id(self.connection)
        if self.state != self.STATE_EOF and not connection_close:
            raise ClientProgrammingError("you can only close a resultset when it was read entirely!")
        connection = self.connection
        del self.connection
        del self.fields
        connection._close_current_resultset(self)
        self.state = self.STATE_CLOSED
            
class Connection(object):
    """Represents a single connection to a MySQL Database host."""
    STATE_ERROR = -1
    STATE_INIT = 0
    STATE_CONNECTING = 1
    STATE_CONNECTED = 2
    STATE_CLOSING = 3
    STATE_CLOSED = 4
    
    def __init__(self):
        self.state = self.STATE_INIT
        self.buffer = Buffer(1024 * 16)        
        self.socket = None
        self.reader = None
        self.writer = None        
        self._time_command = False #whether to keep timing stats on a cmd
        self._command_time = -1
        self._incommand = False
        self.current_resultset = None

    def _scramble(self, password, seed):
        """taken from java jdbc driver, scrambles the password using the given seed
        according to the mysql login protocol"""
        stage1 = SHA(password).digest()
        stage2 = SHA(stage1).digest()
        md = SHA()
        md.update(seed)
        md.update(stage2)
        #i love python :-):
        return ''.join(map(chr, [x ^ ord(stage1[i]) for i, x in enumerate(map(ord, md.digest()))])) 
        
    def _handshake(self, user, password, database):
        """performs the mysql login handshake"""
        
        #init buffer for reading (both pos and lim = 0)
        self.buffer.clear()
        self.buffer.flip()
        
        #read server welcome
        packet = self.reader.read_packet()
        
        self.protocol_version = packet.read_byte() #normally this would be 10 (0xa)
        
        if self.protocol_version == 0xff:
            #error on initial greeting, possibly too many connection error
            raise ClientLoginError.from_error_packet(packet, skip = 2)
        elif self.protocol_version == 0xa:
            pass #expected
        else:
            assert False, "Unexpected protocol version %02x" % self.protocol_version

        self.server_version = packet.read_bytes_until(0)
        
        packet.skip(4) #thread_id
        scramble_buff = packet.read_bytes(8)
        packet.skip(1) #filler
        server_caps = packet.read_short()
        #CAPS.dbg(server_caps)
        
        if not server_caps & CAPS.PROTOCOL_41:
            assert False, "<4.1 auth not supported"
        
        server_language = packet.read_byte()
        server_status = packet.read_short()
        packet.skip(13) #filler
        if packet.remaining: 
            scramble_buff += packet.read_bytes_until(0)
        else:
            assert False, "<4.1 auth not supported"

        client_caps = server_caps 
        
        #always turn off compression
        client_caps &= ~CAPS.COMPRESS
        
        if not server_caps & CAPS.CONNECT_WITH_DB and database:
            assert False, "initial db given but not supported by server"
        if server_caps & CAPS.CONNECT_WITH_DB and not database:
            client_caps &= ~CAPS.CONNECT_WITH_DB

        #build and write our answer to the initial handshake packet
        self.writer.clear()
        self.writer.start()
        self.writer.write_int(client_caps)
        self.writer.write_int(1024 * 1024 * 32) #16mb max packet
        self.writer.write_byte(server_language)
        self.writer.write_bytes('\0' * 23) #filler
        self.writer.write_bytes(user + '\0')
        
        if password:
            self.writer.write_byte(20)
            self.writer.write_bytes(self._scramble(password, scramble_buff))
        else:
            self.writer.write_byte(0)
            
        if database: 
            self.writer.write_bytes(database + '\0')
        
        self.writer.finish(1)
        self.writer.flush()
           
        #read final answer from server
        self.buffer.flip()
        packet = self.reader.read_packet()
        result = packet.read_byte()
        if result == 0xff:
            raise ClientLoginError.from_error_packet(packet)
        elif result == 0xfe:
            assert False, "old password handshake not implemented"
    
    def _close_current_resultset(self, resultset):
        assert resultset == self.current_resultset
        self.current_resultset = None
        
    def _send_command(self, cmd, cmd_text):
        """sends a command with the given text"""
        #self.log.debug('cmd %s %s', cmd, cmd_text)
        
        #note: we are not using normal writer.start/finish here, because the cmd
        #could not fit in buffer, causing flushes in write_string, in that case 'finish' would
        #not be able to go back to the header of the packet to write the length in that case
        self.writer.clear()
        self.writer.write_header(len(cmd_text) + 1 + 4, 0) #1 is len of cmd, 4 is len of header, 0 is packet number
        self.writer.write_byte(cmd)
        self.writer.write_bytes(cmd_text)
        self.writer.flush()

    def _close(self):
        #self.log.debug("close mysql client %s", id(self))
        try:
            self.state = self.STATE_CLOSING
            if self.current_resultset: 
                self.current_resultset.close(True)
            self.socket.close()
            self.state = self.STATE_CLOSED
        except:
            self.state = self.STATE_ERROR
            raise
        
    def connect(self, host = "localhost", port = 3306, user = "", passwd = "", db = "", autocommit = None, charset = None):
        """connects to the given host and port with user and passwd"""
        #self.log.debug("connect mysql client %s %s %s %s %s", id(self), host, port, user, passwd)
        try:
            #print 'connect', host, user, passwd, db
            #parse addresses of form str <host:port>
            if type(host) == str:
                if host[0] == '/': #assume unix domain socket
                    addr = host 
                elif ':' in host:
                    host, port = host.split(':')
                    port = int(port)
                    addr = (host, port)
                else:
                    addr = (host, port)

            assert self.state == self.STATE_INIT, "make sure connection is not already connected or closed"

            self.state = self.STATE_CONNECTING
            self.socket = Socket.connect(addr, timeout = Timeout.current())
            self.reader = BufferedPacketReader(self.socket, self.buffer)
            self.writer = BufferedPacketWriter(self.socket, self.buffer)
            self._handshake(user, passwd, db)
            #handshake complete client can now send commands
            self.state = self.STATE_CONNECTED
            
            if autocommit == False:
                self.set_autocommit(False)
            elif autocommit == True:
                self.set_autocommit(True)
            else:
                pass #whatever is the default of the db (ON in the case of mysql)

            if charset is not None:
                self.set_charset(charset)
            
            return self
        except TimeoutError:
            self.state = self.STATE_INIT
            raise
        except ClientLoginError:
            self.state = self.STATE_INIT
            raise
        except:
            self.state = self.STATE_ERROR
            raise

    def close(self):
        """close this connection"""
        assert self.is_connected(), "make sure connection is connected before closing"
        if self._incommand != False: assert False, "cannot close while still in a command"
        self._close()
        
    def command(self, cmd, cmd_text):
        """sends a COM_XXX command with the given text and possibly return a resultset (select)"""
        #print 'command', cmd, repr(cmd_text), type(cmd_text)        
        assert type(cmd_text) == str #as opposed to unicode
        assert self.is_connected(), "make sure connection is connected before query"
        if self._incommand != False: assert False, "overlapped commands not supported"
        if self.current_resultset: assert False, "overlapped commands not supported, pls read prev resultset and close it"
        try:
            self._incommand = True
            if self._time_command:
                start_time = time.time()
            self._send_command(cmd, cmd_text)
            #read result, expect 1 of OK, ERROR or result set header
            self.buffer.flip()
            packet = self.reader.read_packet()
            result = packet.read_byte()
            #print 'res', result
            if self._time_command:
                end_time = time.time()
                self._command_time = end_time - start_time			
            if result == 0x00:
                #OK, return (affected rows, last row id)
                rowcount = self.reader.read_length_coded_binary()
                lastrowid = self.reader.read_length_coded_binary()
                return (rowcount, lastrowid)
            elif result == 0xff:
                raise ClientCommandError.from_error_packet(packet)
            else: #result set
                self.current_resultset = ResultSet(self, result) 
                return self.current_resultset
        finally:
            self._incommand = False 
        
    def is_connected(self):
        return self.state == self.STATE_CONNECTED
    
    def query(self, cmd_text):
        """Sends a COM_QUERY command with the given text and return a resultset (select)"""
        return self.command(COMMAND.QUERY, cmd_text)
    
    def init_db(self, cmd_text):
        """Sends a COM_INIT command with the given text"""
        return self.command(COMMAND.INITDB, cmd_text)
    
    def set_autocommit(self, commit):
        """Sets autocommit setting for this connection. True = on, False = off"""
        self.command(COMMAND.QUERY, "SET AUTOCOMMIT = %s" % ('1' if commit else '0'))
        
    def commit(self):
        """Commits this connection"""
        self.command(COMMAND.QUERY, "COMMIT")
        
    def rollback(self):
        """Issues a rollback on this connection"""
        self.command(COMMAND.QUERY, "ROLLBACK")
        
    def set_charset(self, charset):
        """Sets the charset for this connections (used to decode string fields into unicode strings)"""
        self.reader.reader.encoding = charset
    
    def set_time_command(self, time_command):
        self._time_command = time_command
        
    def get_command_time(self):
        return self._command_time
    
Connection.log = logging.getLogger(Connection.__name__)

def connect(*args, **kwargs):
    return Connection().connect(*args, **kwargs)


########NEW FILE########
__FILENAME__ = dbapi
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

#this is a dbapi/mysqldb compatible wrapper around the lowlevel
#client in client.py

#TODO weak ref on connection in cursor


import sys
import logging
import exceptions

from datetime import datetime
from concurrence.database.mysql import client
from concurrence import TimeoutError as ConcurrenceTimeoutError

threadsafety = 1
apilevel = "2.0"
paramstyle = "format"

default_charset = sys.getdefaultencoding()

class Error(exceptions.StandardError): pass
class Warning(exceptions.StandardError): pass
class InterfaceError(Error): pass
class DatabaseError(Error): pass
class InternalError(DatabaseError): pass
class OperationalError(DatabaseError): pass
class ProgrammingError(DatabaseError): pass
class IntegrityError(DatabaseError): pass
class DataError(DatabaseError): pass
class NotSupportedError(DatabaseError): pass

#concurrence specific
class TimeoutError(DatabaseError): pass

class Cursor(object):
    log = logging.getLogger('Cursor')

    def __init__(self, connection):
        self.connection = connection
        self.result = None
        self.closed = False
        self._close_result()
        
    def _close_result(self):
        #make sure any previous resultset is closed correctly
        
        if self.result is not None:
            #make sure any left over resultset is read from the db, otherwise
            #the connection would be in an inconsistent state
            try:
                while True:
                    self.result_iter.next()
            except StopIteration:
                pass #done
            self.result.close()

        self.description = None
        self.result = None
        self.result_iter = None
        self.lastrowid = None
        self.rowcount = -1
        
    def _escape_string(self, s):
        """take from mysql src code:"""
        #TODO how fast is this?, do this in C/pyrex?
        escaped = []
        for ch in s:
            if ch == '\0':
                escaped.append('\\0')
            elif ch == '\n':
                escaped.append('\\n')
            elif ch == '\r':
                escaped.append('\\r')
            elif ch == '\\':
                escaped.append('\\\\')
            elif ch == "'": #single quote
                escaped.append("\\'")
            elif ch == '"': #double quote
                escaped.append('\\"')
            elif ch == '\x1a': #EOF on windows
                escaped.append('\\Z')
            else:
                escaped.append(ch)
        return ''.join(escaped)
            
    def _wrap_exception(self, e, msg):
        self.log.exception(msg)
        if isinstance(e, ConcurrenceTimeoutError):
            return TimeoutError(msg + ': ' + str(e))
        else:
            return Error(msg + ': ' + str(e))
        
    def execute(self, qry, args = []):
        #print repr(qry),  repr(args), self.connection.charset
        
        if self.closed:
            raise ProgrammingError('this cursor is already closed')

        if type(qry) == unicode:
            #we will only communicate in 8-bits with mysql
            qry = qry.encode(self.connection.charset)
            
        try:
            self._close_result() #close any previous result if needed
            #substitute arguments
            for arg in args:
                if type(arg) == str:
                    qry = qry.replace('%s', "'%s'" % self._escape_string(arg), 1)
                elif type(arg) == unicode:
                    qry = qry.replace('%s', "'%s'" % self._escape_string(arg).encode(self.connection.charset), 1)
                elif type(arg) == int:
                    qry = qry.replace('%s', str(arg), 1)
                elif type(arg) == long:
                    qry = qry.replace('%s', str(arg), 1)
                elif arg is None:
                    qry = qry.replace('%s', 'null', 1)
                elif isinstance(arg, datetime):
                    qry = qry.replace('%s', "'%s'" % arg.strftime('%Y-%m-%d %H:%M:%S'), 1)
                else:
                    assert False, "unknown argument type: %s %s" % (type(arg), repr(arg))
            
            result = self.connection.client.query(qry)
            
            #process result if nescecary
            if isinstance(result, client.ResultSet):
                self.description = tuple(((name, type_code, None, None, None, None, None) for name, type_code in result.fields))
                self.result = result
                self.result_iter = iter(result)
                self.lastrowid = None
                self.rowcount = -1
            else:
                self.rowcount, self.lastrowid = result
                self.description = None
                self.result = None

        except TaskletExit:
            raise
        except Exception, e:
            raise self._wrap_exception(e, "an error occurred while executing qry %s" % (qry, ))
        
    def fetchall(self):
        try:
            return list(self.result_iter)
        except TaskletExit:
            raise
        except Exception, e:
            raise self._wrap_exception(e, "an error occurred while fetching results")
            
    def fetchone(self):
        try:
            return self.result_iter.next()
        except StopIteration:
            return None
        except TaskletExit:
            raise
        except Exception, e:
            raise self._wrap_exception(e, "an error occurred while fetching results")
    
    def close(self):
        if self.closed: 
            raise ProgrammingError("cannot cursor twice")
        
        try:
            self._close_result()
            self.closed = True
        except TaskletExit:
            raise
        except Exception, e:
            raise self._wrap_exception(e, "an error occurred while closing cursor")
        
class Connection(object):
    
    def __init__(self, *args, **kwargs):

        self.kwargs = kwargs.copy()
        
        if not 'autocommit' in self.kwargs:
            #we set autocommit explicitly to OFF as required by python db api, because default of mysql would be ON
            self.kwargs['autocommit'] = False
        else:
            pass #user specified explictly what he wanted for autocommit

        
        if 'charset' in self.kwargs:
            self.charset = self.kwargs['charset']
            if 'use_unicode' in self.kwargs and self.kwargs['use_unicode'] == True:
                pass #charset stays in args, and triggers unicode output in low-level client
            else:
                del self.kwargs['charset']  
            if 'use_unicode' in self.kwargs:
                del self.kwargs['use_unicode']
        else:
            self.charset = default_charset

        self.client = client.Connection() #low level mysql client
        self.client.connect(*args, **self.kwargs)
        
        self.closed = False
    
    def close(self):
        #print 'dbapi Connection close'
        if self.closed: 
            raise ProgrammingError("cannot close connection twice")
        
        try:
            self.client.close()
            del self.client
            self.closed = True
        except TaskletExit:
            raise
        except Exception, e:
            msg = "an error occurred while closing connection: "
            self.log.exception(msg)
            raise Error(msg + str(e))
            
    def cursor(self):
        if self.closed: 
            raise ProgrammingError("this connection is already closed")
        return Cursor(self)
    
    def get_server_info(self):
        return self.client.server_version

    def rollback(self):
        self.client.rollback()
    
    def commit(self):
        self.client.commit()
    
    @property
    def socket(self):
        return self.client.socket
    
def connect(*args, **kwargs):
    return Connection(*args, **kwargs) 


########NEW FILE########
__FILENAME__ = proxy
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

from concurrence.timer import Timeout
from concurrence.database.mysql import ProxyProtocol, PacketReader, PACKET_READ_RESULT, CLIENT_STATES, SERVER_STATES

class Proxy(object):

    #errors
    EOF_READ = -1
    EOF_WRITE = -2
    
    #direction
    CLIENT_TO_SERVER = 1
    SERVER_TO_CLIENT = 2
    
    def __init__(self, clientStream, serverStream, buffer, initState):
        self.clientStream = clientStream
        self.serverStream = serverStream
        self.readStream = self.clientStream
        self.writeStream = self.serverStream
        self.direction = self.CLIENT_TO_SERVER        
        self.protocol = ProxyProtocol(initState)
        self.reader = PacketReader()
        self.buffer = buffer
        self.remaining = 0
        
    def close(self):
        self.clientStream = None
        self.serverStream = None
        self.readStream = None
        self.writeStream = None
        self.protocol = None
        self.reader = None
        self.buffer = None
        
    def reset(self, state):
        self.protocol.reset(state)
        
    def readFromStream(self):
        #read some data from stream into buffer
        if self.remaining:
            #some leftover partially read packet from previous read, put it in front of buffer
            self.buffer.limit = self.buffer.position + self.remaining
            self.buffer.compact()
        else:
            #normal clear, position = 0, limit = capacity
            self.buffer.clear()
        #read data from socket
        return self.readStream.read(self.buffer, Timeout.current())
    
    def writeToStream(self):
        #forward data to receiving socket
        self.buffer.flip()
        while self.buffer.remaining:
            if not self.writeStream.write(self.buffer, Timeout.current()):
                return False
        return True                   
        
    def next(self, readResult, newState, prevState):
        return 0
    
    def cycle(self, readProtocol):
        
        if not self.readFromStream():
            return self.EOF_READ

        #inspect data read according to protocol
        n = 0
        self.buffer.flip()
        while True:                
            readResult, newState, prevState = readProtocol(self.reader, self.buffer)
            #make note of any remaining data (half read packets),
            # we use buffer.compact to put remainder in front next time around
            self.remaining = self.buffer.remaining
            #take action depending on state transition
            n = self.next(readResult, newState, prevState)
            if n != 0:
                break
            if not (readResult & PACKET_READ_RESULT.MORE):
                break

        if n == 0:
            #write data trough to write stream
            if not self.writeToStream():
                return self.EOF_WRITE
        
        return n
    
    def run(self):
        while True:
            state = self.protocol.state
            if state in SERVER_STATES:
                self.direction = self.SERVER_TO_CLIENT
                self.readStream = self.serverStream
                self.writeStream = self.clientStream
                n = self.cycle(self.protocol.readServer)
            elif state in CLIENT_STATES:
                self.direction = self.CLIENT_TO_SERVER
                self.readStream = self.clientStream
                self.writeStream = self.serverStream
                n = self.cycle(self.protocol.readClient)
            else:
                assert False, "Unknown state %s" % state
            if n < 0:
                return n 

########NEW FILE########
__FILENAME__ = pool
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

from __future__ import with_statement

import logging
import time

from concurrence import TimeoutError, Channel, Tasklet
from concurrence.containers import Deque
from concurrence.timer import Timeout
from concurrence.statistic import Statistic, StatisticExtra


class BasePool(object):
    def __init__(self, connector, dbargs, connect_timeout):
        self._connector = connector
        self._dbargs = dbargs
        self._connect_timeout = connect_timeout

        self._connections = set() #the whole set of connections
        self._connecting = 0 #the number of connection currently being made
        
        self._new_connection_timer_statistic = StatisticExtra()
        self._close_connection_timer_statistic = StatisticExtra()        
        self._failed_connect = Statistic(0)

    @property
    def connection_count(self):
        return len(self._connections) + self._connecting

    def _new(self):
        """creates a new connection with the given arguments"""
        self.log.debug("new connection")
        with self._new_connection_timer_statistic.time():        
            self._connecting += 1
            try:
                connection = self._connector.connect(**self._dbargs)
            except Exception:
                self._failed_connect += 1
                raise
            finally:
                self._connecting -= 1
            
            connection._pool = self
            connection._created_time = time.time()
            self._connections.add(connection)
        
        self.log.debug("new connection created, in pool: %s", self)
        return connection
        
    def _close(self, connection):
        """close given connection and remove it from the pool"""
        assert hasattr(connection, '_pool'), "this connection did not come from a pool"
        assert connection._pool == self, "this connection did not come from this pool"
        self.log.debug("closing connection")

        #update close connection stats
        self._close_connection_timer_statistic += 1
        self._close_connection_timer_statistic.update_avg(time.time() - connection._created_time)
        
        self._connections.remove(connection)
        del connection._pool
        
        try:
            connection.close()
            self.log.debug("connection closed: %s", self)
        except Exception:
            self.log.exception("%s: error while closing connection", self)
            raise
        
    def __statistics__(self):
        return {} #can be overridden by subclass to provide detailed stats

    def _safe_dbargs(self):
        """create a nice unique string identifying this pool with the dbargs, in a safe way (e.g. without showing password"""
        return ';'.join(['%s' % self._dbargs.get(k, '') for k in ['host', 'port', 'db', 'user']])

    def __str__(self):
        return "<pool: %s>" % self._safe_dbargs()
    
    @property
    def name(self):
        return self._safe_dbargs()

            
class Pool(BasePool):
    log = logging.getLogger('Pool')
    
    def __init__(self, connector, dbargs, max_connections = 10, connect_timeout = -1, max_connection_age = None,
                 max_connection_age_reaper_interval = 60):
        super(Pool, self).__init__(connector, dbargs, connect_timeout)
        
        self._max_connections = max_connections
        self._max_connection_age = max_connection_age
        
        #some statistics        
        self._queue_wait_timer_statistic = StatisticExtra()
        self._queue_wait_tasks_statistic = StatisticExtra()        
        
        self._pool = Deque() #the pool of available idle connections
                
        #watch for server disconnects on idle connections:
        self._idle_disconnect_channel = Channel()
        self._idle_disconnect_reaper_task = Tasklet.loop(self._idle_disconnect_reaper, daemon = True)()
        
        #check for old connections
        if self._max_connection_age is not None:
            self._old_connection_reaper_task = Tasklet.interval(max_connection_age_reaper_interval, 
                                                                self._old_connection_reaper, daemon = True)()
        
    def __statistics__(self):
        return {'connections': {'total': self.connection_count, 
                                'connection_failed': self._failed_connect,
                                'connection_new': self._new_connection_timer_statistic,
                                'connection_close': self._close_connection_timer_statistic,
                                'queue_wait_time': self._queue_wait_timer_statistic,
                                'queue_wait_task': self._queue_wait_tasks_statistic}}
        
    @property
    def idle_connection_count(self):
        return len(self._pool)
    
    def _idle_disconnect_reaper(self):
        """waits for readability events in the idle_disconnect_channel
        this signals a EOF from the database, so we can remove the connection 
        from the pool"""
        readable = self._idle_disconnect_channel.receive()
        #now we now which fd became readable, figure out which connection it was
        disconnected_connection = None
        for connection in self._pool:
            if connection.socket.readable == readable:
                disconnected_connection = connection
        if disconnected_connection is None:
            self.log.error("%s: received disconnected event, but could not find corresponding connection!", self)
        else:
            self._close(disconnected_connection)
            self.log.warn("%s: connection disconnected by database server while idle.", self)

    def _old_connection_reaper(self):
        """checks all connections in the pool for their age
        if too old and idle, gets closed immediatly
        if too old and in use, gets closed on next disconnect"""
        now = time.time()
        close_connections = [] #to prevent concurrent modification in loop:
        for connection in self._connections:
            age = now - connection._created_time
            if age > self._max_connection_age:
                close_connections.append(connection)
                
        for connection in close_connections:
            if connection in self._pool: #it is idle, close now
                self.log.debug("%s: closing idle connection with old age", self)
                self._close(connection)
            else:
                self.log.debug("%s: will close busy connection with old age on next disconnect", self)
                connection.__close__ = True #not idle, will be closed on next disconnect
                
    def _get_connection_from_pool(self):
        self.log.debug("get conn from pool")
        return self._pool.pop(True, Timeout.current())
        
    def _return_connection_to_pool(self, connection):
        """when connection becomes readable while in the idle pool,
        this signals a server disconnect"""
        self.log.debug("return conn to pool")
        connection.socket.readable.notify(self._idle_disconnect_channel)
        self._pool.append(connection)
        
    def connect(self):
        """get a connection from the pool, will wait for maxWaitTime for connection to become
        available, or will create a new connection if connectioncount < max_connections"""
        with Timeout.push(self._connect_timeout):
            if (not self._pool) and (self.connection_count < self._max_connections):
                #none available, but still allowed to create new connection
                try:                    
                    return (True, self._new())
                except TaskletExit:
                    raise #server exiting
                except TimeoutError:
                    raise
                except:
                    self.log.exception("%s: could not create new connection for pool", self)
                    #we will continue from here waiting for idle connection
    
            #if we are here, either connection is available, not available but no more connections are allowed,
            #or there was some exception creating a new connection        
            self.log.debug("waiting for connection")
            with self._queue_wait_timer_statistic.time():
                #keep track off the amount of other tasks waiting for a connection
                balance = self._pool.channel.balance
                waiters = -balance if balance < 0 else 0
                self._queue_wait_tasks_statistic.set_count(waiters)
                self._queue_wait_tasks_statistic.update_avg(waiters)
                connection = self._get_connection_from_pool()
                self.log.debug("got connection")
                return (False, connection)
    
    def _close(self, connection):
        """close given connection and remove it from the pool"""
        #if it is currently in the pool, remove it
        if connection in self._pool:
            self._pool.remove(connection)   
        #close it
        super(Pool, self)._close(connection)
    
    def disconnect(self, connection, close = False):
        """return connection to pool. if close is given, it is closed and removed instead"""
        assert hasattr(connection, '_pool'), "this connection did not come from a pool"
        assert connection._pool == self, "this connection did not come from this pool"
        
        if hasattr(connection, '__close__'): #set by old age reaper
            self.log.debug("close on old age")
            close = True
        
        if close:
            #close connection and remove from pool
            self._close(connection)
            return True
        else:
            #return the connection to idle queue
            self._return_connection_to_pool(connection)                        
            self.log.debug("returning connection to pool %s", self)
            return False


class NullPool(BasePool):
    log = logging.getLogger('NullPool')
    
    def __init__(self, connector, dbargs, connect_timeout = -1):
        super(NullPool, self).__init__(connector, dbargs, connect_timeout)

    def __statistics__(self):
        return {'connections': {'total': self.connection_count, 
                                'connection_failed': self._failed_connect,
                                'connection_new': self._new_connection_timer_statistic,
                                'connection_close': self._close_connection_timer_statistic}}
        
    def connect(self):
        self.log.debug("connect: %s", self)
        with Timeout.push(self._connect_timeout):
            return (True, self._new())

    def disconnect(self, connection, close = True):
        self._close(connection)
            

########NEW FILE########
__FILENAME__ = client
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

#TODO timeout
#TODO asyn dns resolve

import time
import logging

from concurrence import Tasklet, Channel, Message, __version__
from concurrence.timer import Timeout
from concurrence.io import Connector, BufferedStream
from concurrence.http import HTTPError, HTTPRequest, HTTPResponse

AGENT = 'Concurrence-Http-Client/' + __version__

CHUNK_SIZE = 1024 * 4

class HTTPConnection(object):
    """A HTTP 1.1 Client.
    
    Usage:: 
    
        #create an instance of this class and connect to a webserver using the connect method:
        cnn = HTTPConnection() 
        cnn.connect(('www.google.com', 80))
        
        #create a GET request using the get method:
        request = cnn.get('/index.html')
        
        #finally perform the request to get a response:
        response = cnn.perform(request)
        
        #do something with the response:
        print response.body
    
    """

    log = logging.getLogger('HTTPConnection')

    def connect(self, endpoint):
        """Connect to the webserver at *endpoint*. *endpoint* is a tuple (<host>, <port>)."""
        self._host = None
        if type(endpoint) == type(()):
            try:
                self._host = endpoint[0]
            except: 
                pass                
        self._stream = BufferedStream(Connector.connect(endpoint))

    def receive(self):
        """Receive the next :class:`HTTPResponse` from the connection."""
        try:
            return self._receive()
        except TaskletExit:
            raise
        except EOFError:
            raise HTTPError("EOF while reading response")
        except Exception:
            self.log.exception('')
            raise HTTPError("Exception while reading response")
        
    def _receive(self):

        response = HTTPResponse()

        reader = self._stream.reader
        
        lines = reader.read_lines()
                
        #parse status line
        response.status = lines.next()
        
        #rest of response headers
        for line in lines:
            if not line: break
            key, value = line.split(': ')
            response.add_header(key, value)

        #read data
        transfer_encoding = response.get_header('Transfer-Encoding', None)
        
        try:
            content_length = int(response.get_header('Content-Length'))
        except:
            content_length = None

        #TODO better support large data        
        chunks = []

        if transfer_encoding == 'chunked':
            while True:
                chunk_line = reader.read_line()
                chunk_size = int(chunk_line.split(';')[0], 16)
                if chunk_size > 0:
                    data = reader.read_bytes(chunk_size)
                    reader.read_line() #chunk is always followed by a single empty line
                    chunks.append(data)
                else:
                    reader.read_line() #chunk is always followed by a single empty line
                    break 
        elif content_length is not None:
            while content_length > 0:
                n = min(CHUNK_SIZE, content_length)
                data = reader.read_bytes(n)
                chunks.append(data)
                content_length -= len(data)
        else:
            assert False, 'TODO'

        response.iter = chunks

        return response

    def get(self, path, host = None):
        """Returns a new :class:`HTTPRequest` with request.method = 'GET' and request.path = *path*.
        request.host will be set to the host used in :func:`connect`, or optionally you can specify a
        specific *host* just for this request.
        """
        request = HTTPRequest()
        request.method = 'GET'
        request.path = path
        request.host = host or self._host
        return request

    def post(self, path, body = None, host = None):
        """Returns a new :class:`HTTPRequest` with request.method = 'POST' and request.path = *path*.
        request.host will be set to the host used in :func:`connect`, or optionally you can specify a
        specific *host* just for this request.
        *body* is an optional string containing the data to post to the server.
        """
        request = HTTPRequest()
        request.method = 'POST'
        request.path = path
        request.host = host or self._host
        if body is not None:
           request.body = body
        return request

    def perform(self, request):
        """Sends the *request* and waits for and returns the :class:`HTTPResult`."""
        self.send(request)
        return self.receive()

    def send(self, request):
        """Sends the *request* on this connection."""
        if request.method is None:
            assert False, "request method must be set"
        if request.path is None:
            assert False, "request path must be set"
        if request.host is None:
            assert False, "request host must be set"

        writer = self._stream.writer        
        writer.clear()
        writer.write_bytes("%s %s HTTP/1.1\r\n" % (request.method, request.path))
        writer.write_bytes("Host: %s\r\n" % request.host)
        for header_name, header_value in request.headers:
            writer.write_bytes("%s: %s\r\n" % (header_name, header_value))
        writer.write_bytes("\r\n")
        if request.body is not None:
           writer.write_bytes(request.body)
        writer.flush()        

    def close(self):
        """Close this connection."""
        self._stream.close()

########NEW FILE########
__FILENAME__ = server
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

#TODO write timeout

from __future__ import with_statement

import logging
import urlparse
import httplib
import traceback
import rfc822

from concurrence import Tasklet, Message, Channel, TimeoutError, __version__
from concurrence.io import Server, BufferedStream
from concurrence.containers import ReorderQueue
from concurrence.timer import Timeout
from concurrence.http import HTTPError

SERVER_ID = "Concurrence-Http/%s" % __version__

CHUNK_SIZE = 1024 * 4

HTTP_READ_TIMEOUT = 300 #default read timeout, if no request was read within this time, the connection is closed by server


class WSGIInputStream(object):
    def __init__(self, request, reader):
        transfer_encoding = request.get_request_header('Transfer-Encoding')
        if transfer_encoding is not None and transfer_encoding == 'chunked':
            assert False, 'chunked post not supported yet'

        content_length = request.get_request_header('Content-length')
        if content_length is None:
            self._channel = None
            self._n = None
            self._file = None        
        else:
            self._n = int(content_length)
            self._file = reader.file()
            self._channel = Channel()
    
    def _read_request_data(self):
        if self._n is not None:
            self._channel.receive() #wait till handler has read all input data

    def read(self, n):  
        if self._n > 0:
            data = self._file.read(min(self._n, n))
            self._n -= len(data)
            if self._n == 0:
                self._n = None
                self._file = None
                self._channel.send(True) #unblock reader
                self._channel = None
            return data
        else:
            return '' #EOF
        
    def readline(self):
        assert False, 'TODO'

    def readlines(self):
        assert False, 'TODO'

    def __iter__(self):
        assert False, 'TODO'


class WSGIErrorStream(object):
    def write(self, s):
        logging.error(s)

    def writelines(self, s):
        assert False, 'TODO'

    def flush(self):
        assert False, 'TODO'

        
class WSGIRequest(object):
    log = logging.getLogger('WSGIRequest')
    
    STATE_INIT = 0
    STATE_WAIT_FOR_REQUEST = 1
    STATE_READING_HEADER = 2
    STATE_READING_DATA = 3
    STATE_REQUEST_READ = 4
    STATE_WRITING_HEADER = 5
    STATE_WRITING_DATA = 6
    STATE_FINISHED = 7
    
    _disallowed_application_headers = set(['Date', 'Server'])

    def __init__(self, server):
        self._server = server        
        self.version = None #http version
        self.environ = {}
        self.response_headers = []
        self.status = httplib.NOT_FOUND #or internal server error?
        self.exc_info = None     
        self.state = self.STATE_INIT   
        
    def start_response(self, status, response_headers, exc_info = None):
        self.status = status
        self.response_headers = response_headers
        self.exc_info = exc_info

    def get_response_header(self, key):
        for (_key, value) in self.response_headers:
            if _key == key:
                return value
        return None
        
    def get_request_header(self, key):
        http_key = 'HTTP_' + key.replace('-', '_').upper()
        return self.environ.get(http_key, None)

    def write_response(self, response, writer):
        self.state = self.STATE_WRITING_HEADER
        
        if self.version == 'HTTP/1.0':
            chunked = False
        else:
            chunked = True

        writer.clear()
        
        writer.write_bytes("%s %s\r\n" % (self.version, self.status))        
        for header_name, header_value in self.response_headers:
            if header_name in self._disallowed_application_headers: continue
            writer.write_bytes("%s: %s\r\n" % (header_name, header_value))
        writer.write_bytes("Date: %s\r\n" % rfc822.formatdate())
        writer.write_bytes("Server: %s\r\n" % SERVER_ID) 

        if chunked:
            writer.write_bytes("Transfer-Encoding: chunked\r\n")
        else:
            response = ''.join(response)
            writer.write_bytes("Content-length: %d\r\n" % len(response))
        
        writer.write_bytes("\r\n")
    
        self.state = self.STATE_WRITING_DATA
        
        if chunked:
            for chunk in response:
                writer.write_bytes("%x;\r\n" % len(chunk))
                writer.write_bytes(chunk)
                writer.write_bytes("\r\n")
                
            writer.write_bytes("0\r\n\r\n")
        else:
            writer.write_bytes(response)

        writer.flush() #TODO use special header to indicate no flush needed
        
        self.state = self.STATE_FINISHED
    
    def handle_request(self, application):
        try:
            return application(self.environ, self.start_response)
        except TaskletExit:
            raise
        except:
            self.log.exception("unhandled exception while handling request")
            return self._server.internal_server_error(self.environ, self.start_response)
      
    def read_request_data(self):
        self.environ['wsgi.input']._read_request_data()

    def read_request(self, reader):
        with Timeout.push(self._server.read_timeout):
            self._read_request(reader)

    def _read_request(self, reader):

        self.state = self.STATE_WAIT_FOR_REQUEST
        
        #setup readline iterator        
        lines = reader.read_lines()
        
        #parse status line, this will block to read the first request line
        line = lines.next().split()
        
        self.state = self.STATE_READING_HEADER
        
        u = urlparse.urlparse(line[1])
        
        self.method = line[0]
        if self.method not in ['GET', 'POST']:
            raise HTTPError('Unsupported method: %s' % self.method)

        #TODO validate version
        self.version = line[2]
        self.uri = line[1]

        #build up the WSGI environment
        self.environ['REQUEST_METHOD'] = line[0]
        self.environ['SCRIPT_NAME'] = '' #TODO
        self.environ['PATH_INFO'] = u[2]
        self.environ['QUERY_STRING'] = u[4]
        
        self.environ['wsgi.url_scheme'] = 'http'
        self.environ['wsgi.multiprocess'] = False
        self.environ['wsgi.multithread'] = True
        self.environ['wsgi.run_once'] = False
        self.environ['wsgi.version'] = (1, 0)
        
        #rest of request headers
        for line in lines:
            if not line: break
            key, value = line.split(': ')
            key = key.replace('-', '_').upper()
            value = value.strip()
            
            http_key = 'HTTP_' + key 
            if http_key in self.environ:
                self.environ[http_key] += ',' + value # comma-separate multiple headers
            else:
                self.environ[http_key] = value

        #wsgi complience 
        if 'HTTP_CONTENT_LENGTH' in self.environ:
            self.environ['CONTENT_LENGTH'] = self.environ['HTTP_CONTENT_LENGTH']

        if 'HTTP_CONTENT_TYPE' in self.environ:
            self.environ['CONTENT_TYPE'] = self.environ['HTTP_CONTENT_TYPE']

        #setup required wsgi streams
        self.environ['wsgi.input'] = WSGIInputStream(self, reader)
        self.environ['wsgi.errors'] = WSGIErrorStream()
        
        if not 'HTTP_HOST' in self.environ:
            if self.version == 'HTTP/1.0':
                #ok in version 1.0, TODO what should host in wsgi environ be?
                host = 'localhost'
            else:
                raise HTTPError('Host header field is required in HTTP version > 1.0')
        else:
            host = self.environ['HTTP_HOST']

        if ':' in host:
            host, port = host.split(':')
        else:
            host, port = host, 80

        self.environ['SERVER_NAME'] = host
        self.environ['SERVER_PORT'] = port
        self.environ['SERVER_PROTOCOL'] = self.version
        
        self.state = self.STATE_REQUEST_READ
        

class HTTPHandler(object):
    log = logging.getLogger('HTTPHandler')

    class MSG_REQUEST_HANDLED(Message): pass
    class MSG_WRITE_RESPONSE(Message): pass
    class MSG_RESPONSE_WRITTEN(Message): pass
    class MSG_REQUEST_READ(Message): pass
    class MSG_READ_ERROR(Message): pass
    class MSG_WRITE_ERROR(Message): pass
    
    def __init__(self, server):
        self._server = server     
        self._reque = ReorderQueue()

    def write_responses(self, control, stream):        
        try:
            for msg, (request, response), kwargs in Tasklet.receive():
                request.write_response(response, stream.writer)
                self.MSG_RESPONSE_WRITTEN.send(control)(request, response)
        except Exception, e:
            self.log.exception("Exception in writer")
            self.MSG_WRITE_ERROR.send(control)(None, None)

    def read_requests(self, control, stream):
        try:
            while True:
                request = WSGIRequest(self._server)
                request.read_request(stream.reader)                
                self.MSG_REQUEST_READ.send(control)(request, None)
                request.read_request_data()
        except EOFError, e:
            if request.state == request.STATE_WAIT_FOR_REQUEST:
                pass #this is normal at the end of the http KA connection (client closes) 
        except IOError, e:
            if e.errno == 104 and request.state == request.STATE_WAIT_FOR_REQUEST:
                pass #connection reset by peer while waiting for request
        except TimeoutError, e:
            self.log.warn("Timeout in reader")
        except Exception, e:
            self.log.exception("Exception in reader")

        self.MSG_READ_ERROR.send(control)(None, None)

    def handle_request(self, control, request, application):
        response = self._server.handle_request(request, application)
        self.MSG_REQUEST_HANDLED.send(control)(request, response)       

    def handle(self, socket, application):
        stream = BufferedStream(socket)
        #implements http1.1 keep alive handler
        #there are several concurrent tasks for each connection; 
        #1 for reading requests, 1 or more for handling requests and 1 for writing responses
        #the current task (the one created to handle the socket connection) is the controller task,
        #e.g. it coordinates the actions of it's children by message passing
        control = Tasklet.current()

        #writes responses back to the client when they are ready:
        response_writer = Tasklet.new(self.write_responses, name = 'response_writer')(control, stream)
        #reads requests from clients:
        request_reader = Tasklet.new(self.read_requests, name = 'request_reader')(control, stream)

        #typical flow:
        #1. reader reads in request, sends notification to control (MSG_REQUEST_READ)
        #2. control starts handler for the request
        #3. handler works on request and sends notification to control when finished (MSG_REQUEST_HANDLED)
        #4. control sends message to writer to start writing the response (MSG_WRITE_RESPONSE)
        #5. writer notififies control when response is wriiten (MSG_RESPONSE_WRITTEN)

        #control wait for msgs to arrive:        
        for msg, (request, response), kwargs in Tasklet.receive():
            if msg.match(self.MSG_REQUEST_READ):
                #we use reque to be able to send the responses back in the correct order later
                self._reque.start(request)
                Tasklet.new(self.handle_request, name = 'request_handler')(control, request, application)
                
            elif msg.match(self.MSG_REQUEST_HANDLED):
                #we use reque to retire (send out) the responses in the correct order
                for request, response in self._reque.finish(request, response):
                    self.MSG_WRITE_RESPONSE.send(response_writer)(request, response)
                    
            elif msg.match(self.MSG_RESPONSE_WRITTEN):
                if request.version == 'HTTP/1.0':
                    break #no keep-alive support in http 1.0
                elif request.get_response_header('Connection') == 'close':
                    break #response indicated to close after response
                elif request.get_request_header('Connection') == 'close':
                    break #request indicated to close after response
            elif msg.match(self.MSG_READ_ERROR):
                break #stop and close the connection
            elif msg.match(self.MSG_WRITE_ERROR):
                break #stop and close the connection
            else:   
                assert False, "unexpected msg in control loop"

        #kill reader and writer
        #any outstanding request will continue, but will exit by themselves
        response_writer.kill()
        request_reader.kill()
   
        #close our side of the socket
        stream.close()
        
class WSGIServer(object):
    """A HTTP/1.1 Web server with WSGI application interface.
    
    Usage:: 
    
        def hello_world(environ, start_response):
            start_response("200 OK", [])
            return ["<html>Hello, world!</html>"]

        server = WSGIServer(hello_world)
        server.serve(('localhost', 8080))
    """
    log = logging.getLogger('WSGIServer')
    
    read_timeout = HTTP_READ_TIMEOUT

    def __init__(self, application, request_log_level = logging.DEBUG):
        """Create a new WSGIServer serving the given *application*. Optionally
        the *request_log_level* can be given. This loglevel is used for logging the requests."""
        self._application = application
        self._request_log_level = request_log_level

    def internal_server_error(self, environ, start_response):
        """Default WSGI application for creating a default `500 Internal Server Error` response on any
        unhandled exception.
        The default response will render a traceback with a text/plain content-type.
        Can be overridden to provide a custom response."""           
        start_response('500 Internal Server Error', [('Content-type', 'text/plain')])
        return [traceback.format_exc(20)]

    def handle_request(self, request, application):
        """All HTTP requests pass trough this method. 
        This method provides a hook for logging, statistics and or further processing w.r.t. the *request*."""
        response = request.handle_request(application)
        self.log.log(self._request_log_level, "%s %s", request.status, request.uri)
        return response
        
    def handle_connection(self, socket):
        """All HTTP connections pass trough this method.
        This method provides a hook for logging, statistics and or further processing w.r.t. the connection."""
        HTTPHandler(self).handle(socket, self._application)

    def serve(self, endpoint):
        """Serves the application at the given *endpoint*. The *endpoint* must be a tuple (<host>, <port>)."""
        return Server.serve(endpoint, self.handle_connection)
                        


########NEW FILE########
__FILENAME__ = buffered
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

from concurrence.timer import Timeout
from concurrence.io import IOStream, Buffer, BufferOverflowError, BufferUnderflowError, BufferInvalidArgumentError


class BufferedReader(object):
    def __init__(self, stream, buffer):
        assert isinstance(stream, IOStream)
        self.stream = stream
        self.buffer = buffer
        #assume no reading from underlying stream was done, so make sure buffer reflects this:
        self.buffer.position = 0
        self.buffer.limit = 0

    def file(self):
        return CompatibleFile(self, None)

    def clear(self):
        self.buffer.clear()

    def _read_more(self):
        #any partially read data will be put in front, otherwise normal clear:
        self.buffer.compact()
        if not self.stream.read(self.buffer, Timeout.current()): 
            raise EOFError("while reading")
        self.buffer.flip() #prepare to read from buffer
        
    def read_lines(self):
        """note that it cant read line accross buffer"""
        while True:
            try:
                yield self.buffer.read_line()
            except BufferUnderflowError:
                self._read_more()
        
    def read_line(self):
        return self.read_lines().next()
                
    def read_bytes(self, n):
        """read exactly n bytes from stream"""
        buffer = self.buffer
        s = []
        while n > 0:
            r = buffer.remaining 
            if r > 0:
                s.append(buffer.read_bytes(min(n, r)))
                n -= r 
            else:
                self._read_more()
                
        return ''.join(s)

    def read_short(self):
        while True:
            try:
                return self.buffer.read_short()
            except BufferUnderflowError:
                self._read_more()
                
class BufferedWriter(object):
    def __init__(self, stream, buffer):
        assert isinstance(stream, IOStream)
        self.stream = stream
        self.buffer = buffer 
    
    def file(self):
        return CompatibleFile(None, self)

    def clear(self):
        self.buffer.clear()

    def write_bytes(self, s):
        assert type(s) == str, "arg must be a str"
        try:
            self.buffer.write_bytes(s)
        except BufferOverflowError:
            #we need to send it in parts, flushing as we go
            while s:
                r = self.buffer.remaining
                part, s = s[:r], s[r:]
                self.buffer.write_bytes(part)
                self.flush()    
 
    def write_byte(self, ch):
        assert type(ch) == int, "ch arg must be int"
        while True:
            try:
                self.buffer.write_byte(ch)
                return
            except BufferOverflowError:
                self.flush()
       
    def write_short(self, i):
        while True:
            try:
                self.buffer.write_short(i)
                return
            except BufferOverflowError:
                self.flush()
            
    def flush(self):
        self.buffer.flip()
        while self.buffer.remaining:
            if not self.stream.write(self.buffer, Timeout.current()):
                raise EOFError("while writing")
        self.buffer.clear()
        
class BufferedStream(object):
    def __init__(self, stream, buffer_size = 1024 * 8, read_buffer_size = 0, write_buffer_size = 0):        
        self.stream = stream
        self.reader = BufferedReader(stream, Buffer(read_buffer_size or buffer_size))
        self.writer = BufferedWriter(stream, Buffer(write_buffer_size or buffer_size))

    def file(self):
        return CompatibleFile(self.reader, self.writer)

    def close(self):
        self.stream.close()
        del self.stream
        del self.reader
        del self.writer
        

class CompatibleFile(object):
    """A wrapper that implements python's file like object semantics on top
    of concurrence BufferedReader and or BufferedWriter. Don't create
    this object directly, but use the file() method on BufferedReader or BufferedWriter"""
    def __init__(self, reader = None, writer = None):
        self._reader = reader
        self._writer = writer

    def readlines(self):
        reader = self._reader
        buffer = reader.buffer
        while True:
            try:
                yield buffer.read_line(True)
            except BufferUnderflowError:
                try:
                    reader._read_more()
                except EOFError:
                    buffer.flip()
                    yield buffer.read_bytes(-1)
            
    def readline(self):
        return self.readlines().next()

    def read(self, n = -1):
        reader = self._reader
        buffer = reader.buffer
        s = []
        if n == -1: #read all available bytes until EOF
            while True:
                s.append(buffer.read_bytes(-1))
                try:
                    reader._read_more()
                except EOFError:
                    buffer.flip()
                    break
        else:
            while n > 0: #read uptill n avaiable bytes or EOF
                r = buffer.remaining 
                if r > 0:
                    s.append(buffer.read_bytes(min(n, r)))
                    n -= r 
                else:
                    try:
                        reader._read_more()
                    except EOFError:
                        buffer.flip()
                        break            
        return ''.join(s)

    def write(self, s):
        self._writer.write_bytes(s)

    def flush(self):
        self._writer.flush()


########NEW FILE########
__FILENAME__ = socket
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

#TODO try wait read/write optimzation, e.g. don't wait, but try, if EAGAIN, then wait. 
#if ok, then next time expect no wait, otherwise next time expect wait

import logging
import _socket
import types
import os

from errno import EALREADY, EINPROGRESS, EWOULDBLOCK, ECONNRESET, ENOTCONN, ESHUTDOWN, EINTR, EISCONN, ENOENT, EAGAIN

import _io

from concurrence import Tasklet, FileDescriptorEvent
from concurrence.io import IOStream

DEFAULT_BACKLOG = 255    

class Socket(IOStream):
    log = logging.getLogger('Socket')
    
    STATE_INIT = 0
    STATE_LISTENING = 1
    STATE_CONNECTING = 2
    STATE_CONNECTED = 3
    STATE_CLOSING = 4
    STATE_CLOSED = 5
    
    def __init__(self, socket, state = STATE_INIT):
        """don't call directly pls use one of the provided classmethod to create a socket"""
        self.socket = socket

        if _socket.AF_INET == socket.family:
            #always set the nodelay option on tcp sockets. This turns off the Nagle algorithm
            #we don't need this because in concurrence we are always buffering ourselves
            #before sending out data, so no need to let the tcp stack do it again and possibly delay
            #sending
            try:
                self.socket.setsockopt(_socket.IPPROTO_TCP, _socket.TCP_NODELAY, 1)
            except:
                self.log.warn("could not set TCP_NODELAY")
         
        #concurrence sockets are always non-blocking, this is the whole idea :-) :              
        self.socket.setblocking(0)        
        self.fd = self.socket.fileno()
        self._readable = None #will be created lazily
        self._writable = None #will be created lazily
        self.state = state

    @classmethod
    def from_address(cls, addr):
        """Creates a new socket from the given address. If the addr is a tuple (host, port)
        a normal tcp socket is assumed. if addr is a string, a UNIX Domain socket is assumed"""
        if type(addr) == types.StringType:
            return cls(_socket.socket(_socket.AF_UNIX, _socket.SOCK_STREAM)) 
        else:
            return cls(_socket.socket(_socket.AF_INET, _socket.SOCK_STREAM))
    
    @classmethod
    def new(cls):
        return cls(_socket.socket(_socket.AF_INET, _socket.SOCK_STREAM))

    @classmethod
    def connect(cls, addr, timeout = -1):
        """creates a new socket and connects it to the given address.
        returns the connected sockets"""
        socket = cls.from_address(addr)
        socket._connect(addr, timeout)        
        return socket
    
    @classmethod
    def from_file_descriptor(cls, fd, socket_family = _socket.AF_UNIX, socket_type = _socket.SOCK_STREAM, socket_state = STATE_INIT):
        return cls(_socket.fromfd(fd, socket_family, socket_type), socket_state)
    
    def _get_readable(self):
        if self._readable is None:
            self._readable = FileDescriptorEvent(self.fd, 'r')
        return self._readable
  
    def _set_readable(self, readable):
        self._readable = readable
    
    readable = property(_get_readable, _set_readable)

    def _get_writable(self):
        if self._writable is None:
            self._writable = FileDescriptorEvent(self.fd, 'w')
        return self._writable
  
    def _set_writable(self, writable):
        self._writable = writable
    
    writable = property(_get_writable, _set_writable)
    
    def fileno(self):
        return self.fd
    
    def set_reuse_address(self, reuse_address):
        self.socket.setsockopt(_socket.SOL_SOCKET, _socket.SO_REUSEADDR, int(reuse_address))
        
    def bind(self, addr):
        self.socket.bind(addr)
        
    def listen(self, backlog = DEFAULT_BACKLOG):
        self.socket.listen(backlog)
        self.state = self.STATE_LISTENING
        
    def accept(self):
        """waits on a listening socket, returns a new socket_class instance
        for the incoming connection"""
        assert self.state == self.STATE_LISTENING, "make sure socket is listening before calling accept"
        while True:
            #we need a loop because sometimes we become readable and still not a valid 
            #connection was accepted, in which case we return here and wait some more.
            self.readable.wait()
            try:        
                s, _ = self.socket.accept()
            except _socket.error, (errno, _):
                if errno in [EAGAIN, EWOULDBLOCK]:
                    #this can happen when more than one process received readability on the same socket (forked/cloned/dupped)
                    #in that case 1 process will do the accept, the others receive this error, and should continue waiting for
                    #readability 
                    continue 
                else:
                    raise 
            
            return self.__class__(s, self.STATE_CONNECTED)

    def _connect(self, addr, timeout = -1.0):
        assert self.state == self.STATE_INIT, "make sure socket is not already connected or closed"
        try:
            err = self.socket.connect_ex(addr)
            serr = self.socket.getsockopt(_socket.SOL_SOCKET, _socket.SO_ERROR)
        except:
            self.log.exception("unexpected exception thrown by connect_ex")
            raise  
        if err == 0 and serr == 0:
            self.state = self.STATE_CONNECTED
        elif err == EINPROGRESS and serr != 0:
            raise IOError(serr, os.strerror(serr))
        elif err == EINPROGRESS and serr == 0:                    
            self.state = self.STATE_CONNECTING
            try:
                self.writable.wait(timeout = timeout)
                self.state = self.STATE_CONNECTED
            except:
                self.state = self.STATE_INIT
                raise
        else:
            #some other error,  
            #unix domain socket that does not exist, Cannot assign requested address etc etc
            raise _io.error_from_errno(IOError)
        
    def write(self, buffer, timeout = -1.0):
        """Blocks till socket becomes writable and then writes as many bytes as possible from given
        buffer to the socket. The buffer position is updated according to the number of bytes read from it.
        This method could possible write 0 bytes. The method returns the total number of bytes written"""
        assert self.state == self.STATE_CONNECTED, "socket must be connected in order to write to it"        
        self.writable.wait(timeout = timeout)
        bytes_written, _ = buffer.send(self.fd) #write to fd from buffer
        if bytes_written < 0:
            raise _io.error_from_errno(IOError)
        else:
            return bytes_written

    def read(self, buffer, timeout = -1.0):
        """Blocks till socket becomes readable and then reads as many bytes as possible the socket into the given
        buffer. The buffer position is updated according to the number of bytes read from the socket.
        This method could possible read 0 bytes. The method returns the total number of bytes read"""
        assert self.state == self.STATE_CONNECTED, "socket must be connected in order to read from it"
        self.readable.wait(timeout = timeout)
        bytes_read, _ = buffer.recv(self.fd) #read from fd to 
        if bytes_read < 0:
            raise _io.error_from_errno(IOError)
        else:
            return bytes_read

    def write_socket(self, socket, timeout = -1):
        """writes a socket trough this socket"""
        self.writable.wait(timeout = timeout)
        _io.msgsendfd(self.fd, socket.fd)
        
    def read_socket(self, socket_class = None, socket_family =  _socket.AF_INET, socket_type = _socket.SOCK_STREAM, socket_state = STATE_INIT, timeout = -1):
        """reads a socket from this socket"""
        self.readable.wait(timeout = timeout)
        fd = _io.msgrecvfd(self.fd)
        return (socket_class or self.__class__).from_file_descriptor(fd, socket_family, socket_type, socket_state)        
                   
    def is_closed(self):
        return self.state == self.STATE_CLOSED 
    
    def close(self):
        assert self.state in [self.STATE_CONNECTED, self.STATE_LISTENING]
        self.state = self.STATE_CLOSING
        if self._readable is not None:
            self._readable.close()
        if self._writable is not None:
            self._writable.close()
        self.socket.close()          
        del self.socket
        del self._readable
        del self._writable
        self.state = self.STATE_CLOSED

class SocketServer(object):
    log = logging.getLogger('SocketServer')

    def __init__(self, endpoint, handler = None):
        self._addr = None
        self._socket = None
        if isinstance(endpoint, Socket):
            self._socket = endpoint
        else:
            self._addr = endpoint
        self._handler = handler
        self._reuseaddress = True
        self._handler_task_name = 'socket_handler'
        self._accept_task = None
        self._accept_task_name = 'socket_acceptor'
        
    @property
    def socket(self):
        return self._socket

    def _handle_accept(self, accepted_socket):
        result = None
        try:
            result = self._handler(accepted_socket)
        except TaskletExit:
            raise
        except:
            self.log.exception("unhandled exception in socket handler")
        finally:
            if result is None and not accepted_socket.is_closed():
                try:
                    accepted_socket.close()
                except TaskletExit:
                    raise
                except:
                    self.log.exception("unhandled exception while forcefully closing client")
        
    def _create_socket(self):
        if self._socket is None:
            if self._addr is None:
                assert False, "address must be set or accepting socket must be explicitly set"
            self._socket = Socket.from_address(self._addr)
            self._socket.set_reuse_address(self._reuseaddress)            
        return self._socket 
        
    def _accept_task_loop(self):
        accepted_socket = self._socket.accept()
        Tasklet.new(self._handle_accept, self._handler_task_name)(accepted_socket)
        
    def bind(self):
        """creates socket if needed, and binds it"""
        socket = self._create_socket()
        socket.bind(self._addr)

    def listen(self, backlog = DEFAULT_BACKLOG):
        """creates socket if needed, and listens it"""
        socket = self._create_socket()
        socket.listen(backlog)
        
    def serve(self):
        """listens and starts a new tasks accepting incoming connections on the configured address"""
        if self._socket is None:
            self.bind()
            self.listen()

        if not callable(self._handler):
            assert False, "handler not set or not callable"
        
        self._accept_task = Tasklet.loop(self._accept_task_loop, name = self._accept_task_name, daemon = True)()

    def close(self):
        self._accept_task.kill()
        self._socket.close()
        
        
        
        

########NEW FILE########
__FILENAME__ = local
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

import weakref

from concurrence import Tasklet

class TaskLocal(object):
    """A TaskLocal class analogous to pythons ThreadLocal object"""
    
    class _LocalAttributes(object): pass #the instance that will hold the local attributes for a given task
    
    def __init__(self, recursive = False):
        #the only addition in TaskLocal vs ThreadLocal is recursive lookups
        #e.g. if enabled, when an attribute is not found for the calling
        #tasks, the corresponding local for the parent task is checked,
        #up the tree of tasks, until either it is found in some parent, or
        #not, in which case an AttributeError is raised
        self._recursive = recursive
        #we use a weak dict with tasklets as keys,
        #that way we don't need to store the locals on the tasklet itself
        #and also when a tasklet is gc'd, its locals will disappear automatically
        self._d = weakref.WeakKeyDictionary() # tasklet->dict of attributes
        
    def __getattr__(self, key):
        #TODO PROFILING this method seems to be quite expensive in profiling
        #can we cache the route up into the parent or something?
        d = self._d
        current = Tasklet.current()
        while current is not None:
            if (not current in d) or (not hasattr(d[current], key)):
                if not self._recursive:
                    break
                else:
                    current = current.parent() #continue checking parent task locals 
            else:
                return getattr(d[current], key)
            
        raise AttributeError(key)
        
    def __setattr__(self, key, value):
        if key in ['_d', '_recursive']: #to protect from infinite recursion during __init__
            self.__dict__[key] = value
        else:
            d = self._d
            current = Tasklet.current()
            if not current in d: #task specific attributes instance not created yet               
                d[current] = self._LocalAttributes()
            setattr(d[current], key, value)

    def __delattr__(self, key):
        #note: del attr is not recursive!
        d = self._d
        current = Tasklet.current()
        if (not current in d) or (not hasattr(d[current], key)):
            raise AttributeError(key)
        else:
            delattr(d[current], key)
            
class TaskInstance(TaskLocal):
    """A Task scoped Instance, e.g. it is similar to TaskLocal in that it contains
    state that is specific to a task, the difference is, that here the state for the
    task is set explicitly using the 'set' method, instead of being created on first
    attribute access"""
    def __enter__(self):
        return self
     
    def __exit__(self, type, value, traceback):        
        self.unset()

    def unset(self):
        """unsets the instance for current task"""
        del self._d[Tasklet.current()]
        
    def set(self, instance):
        """specifically sets the given instance for current task"""
        self._d[Tasklet.current()] = instance
        return self
    

########NEW FILE########
__FILENAME__ = client
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

from concurrence import Tasklet, Channel, TaskletError
from concurrence.timer import Timeout
from concurrence.io.socket import Socket
from concurrence.io.buffered import BufferedStream
from concurrence.containers.deque import Deque

import cPickle as pickle

#TODO async set
#proper buffer sizes
#bundling of multiple requests in 1 flush
#statistics
#not use pickle for string and unicode types (use flags to indicate this)
#timeout on commands (for clients, support Timeout.current)
#plugable serialization support (and/or provide choise, default (py-serialized, utf-8 encoded json, etc)?
#todo detect timeouts on write/read, and mark host as dead
#keep some time before retrying host
#global consistent hashing algorithm for accessing set of memcached servers

#rename MemcacheNode to MemcacheConnection.
#first, there will be max 1 connection to each host in the system

class MemcacheError(Exception):
    pass

class MemcacheNode(object):
    """this represents the connection/protocol to 1 memcached host
    this class supports concurrent usage of get/set methods by multiple
    tasks, the cmds are queued and performed in order agains the memcached host.    
    """
    def __init__(self):
        self._stream = None

    def connect(self, addr):
        assert self._stream is None, "must not be disconneted before connecting"
        self._stream = BufferedStream(Socket.connect(addr, Timeout.current()))
        self._command_queue = Deque()
        self._response_queue = Deque()
        self._command_writer_task = Tasklet.new(self._command_writer)()
        self._response_reader_task = Tasklet.new(self._response_reader)()

    def _read_response(self, reader):
        cmd, block_channel = self._response_queue.popleft(True)
        try:
            if cmd == 'get':
                result = {} #we will gather 'get' results here
            else:
                result = True
            while True:
                response_line = reader.read_line()
                if cmd == 'get' and response_line.startswith('VALUE'):
                    response_fields = response_line.split(' ')
                    key = response_fields[1]
                    flags = int(response_fields[2])
                    n = int(response_fields[3])
                    encoded_value = reader.read_bytes(n)
                    reader.read_line() #\r\n
                    result[key] = pickle.loads(encoded_value)
                elif cmd == 'get' and response_line == 'END':
                    block_channel.send(result)
                    break                            
                elif cmd == 'set' and response_line == 'STORED':
                    block_channel.send(result)
                    break        
                else:
                    assert False, "unknown protocol state, cmd: %s, response_line: %s" % (cmd, response_line)
        except Exception, e:
            block_channel.send_exception(TaskletError, e, Tasklet.current())
            raise 

    def _write_command(self, writer):
        try:
            cmd, args, block_channel = self._command_queue.popleft(True)
            writer.clear()
            if cmd == 'get':
                writer.write_bytes("get")
                for key in args[0]:
                    writer.write_bytes(" " + key)
            elif cmd in ['set']:
                key, value, flags = args           
                encoded_value = pickle.dumps(value, -1)
                writer.write_bytes("%s %s %d 0 %d\r\n" % (cmd, key, flags, len(encoded_value)))
                writer.write_bytes(encoded_value)
            else:
                assert False, "unknown command %s" % cmd
            writer.write_bytes('\r\n')
            writer.flush()
            self._response_queue.append((cmd, block_channel))
        except Exception, e:
            block_channel.send_exception(TaskletError, e, Tasklet.current())
            raise

    def _response_reader(self):
        reader = self._stream.reader
        while True:
            try:
                self._read_response(reader)
            except Exception, e:
                self.close(e, False, True)
                return #this ends reader
            
    def _command_writer(self):
        writer = self._stream.writer       
        while True:
            try:
                self._write_command(writer)
            except Exception, e:
                self.close(e, True, False)
                return #this ends writer

    def _do_command(self, cmd, *args):
        block_channel = Channel()
        self._command_queue.append((cmd, args, block_channel))
        try:
            return block_channel.receive()
        except TaskletError, e:
            raise MemcacheError(str(e.cause))

    def close(self, exception = None, kill_reader = True, kill_writer = True):
        #assert False, reason
        if kill_reader:     
            self._response_reader_task.kill()
        if kill_writer:
            self._command_writer_task.kill()
        self._response_reader_task = None
        self._command_writer_task = None
        #raise exception on all waiting tasks still in the queues
        for cmd, args, block_channel in self._command_queue:
            block_channel.send_exception(TaskletError, e, Tasklet.current())
        for cmd, block_channel in self._response_queue:
            block_channel.send_exception(TaskletError, e, Tasklet.current())
        self._command_queue = None
        self._response_queue = None
        self._stream.close()
        self._stream = None
        
    def set(self, key, data, flags = 0):
        self._do_command("set", key, data, flags)

    def _get_one(self, key):
        result = self._do_command("get", [key])
        if key in result:
            return result[key]
        else:
            return None

    def get(self, keys):
        if type(keys) == str:
            return self._get_one(keys)
        else:
            return self._do_command("get", keys)
            


########NEW FILE########
__FILENAME__ = remote
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

from concurrence import dispatch, Tasklet, Message
from concurrence.io import Server, Connector, BufferedStream

import logging
import weakref
#import cPickle as pickle
import pickle #TODO why does unittest segfault on cPickle?

#TODO timeouts and exceptions for 'calls'
#TODO management of remote clients (e.g. we could drop the connection if there are no more calls for some time)
#TODO option for private connections and option to turn of auto-flushing, for high troughput asyn messaging

class ObjectReader(object):
    """used to serialize msgs and other objects between a remote server and client"""
    def __init__(self, reader):
        self._unpickler = pickle.Unpickler(reader.file())

    def read_object(self):
        return self._unpickler.load()
       
        
class ObjectWriter(object):
    """used to serialize msgs and other objects between a remote server and client"""
    def __init__(self, writer):
        self._file = writer.file()
        self._pickler = pickle.Pickler(self._file, 2)

    def write_object(self, o):
        self._pickler.dump(o)

    def flush(self):
        self._file.flush()

class MSG_LOOKUP(Message): pass
class MSG_RESULT(Message): pass

class RemoteMessage(Message):
    """proxy of a message in the remote (server side) process"""
    def __init__(self, remote_stream, remote_msg_class, remote_msg_id):
        self._remote_stream = remote_stream
        self._remote_msg_class = remote_msg_class
        self._remote_msg_id = remote_msg_id
        
    def reply(self, result):
        self._remote_stream.write_result_msg(self._remote_msg_id, result)

    def match(self, cls):
        return issubclass(self._remote_msg_class, cls)
        
    @classmethod
    def send(cls, receiver, *args):
        assert False, "NOT AVAILABLE"
    
    @classmethod
    def call(cls, receiver, *args):        
        assert False, "NOT AVAILABLE"
    
    def wait(self):
        assert False, "NOT AVAILABLE"
    
class RemoteStream(object):
    """represents the object stream on the remote (server) side process"""
    def __init__(self, client_stream):
        self._client_stream = BufferedStream(client_stream)
        self._object_reader = ObjectReader(self._client_stream.reader)
        self._object_writer = ObjectWriter(self._client_stream.writer)

    def write_result_msg(self, remote_msg_id, result):
        self._object_writer.write_object((MSG_RESULT, (remote_msg_id, result)))
        self._object_writer.flush()            
    
    def read_msg(self):
        return self._object_reader.read_object()

class RemoteServer(object):
    """remoting server, use this to expose a Task to clients in other processes.
    Use the 'register' method to expose a task. This task will then respond to msgs
    send by clients in other tasks"""
    log = logging.getLogger('RemoteServer')

    def __init__(self):
        self._task_by_name = weakref.WeakValueDictionary()
        self._task_id_by_task = weakref.WeakKeyDictionary()
        self._task_by_task_id = weakref.WeakValueDictionary()
        #the task with id 0 is always available, it provides bootstrap services (e.g. name->task lookup)
        self._task_by_task_id[0] = Tasklet.new(self._bootstrap_service)()

    def _bootstrap_service(self):
        while True:
            for msg, args, kwargs in Tasklet.receive():
                if msg.match(MSG_LOOKUP):
                    name = args[0]
                    if name in self._task_by_name:
                        task_id = self._task_id_by_task.get(self._task_by_name[name], 0)
                    else:
                        task_id = 0
                    msg.reply(task_id)
    

    def handle(self, client_stream):
        #TODO timeout on handling
        remote_stream = RemoteStream(client_stream)
        while True:
            try:
                receiver_task_id, msg_class, msg_id, args, kwargs = remote_stream.read_msg()
            except EOFError:
                break 
            #create a local proxy of the remote msg:        
            msg = RemoteMessage(remote_stream, msg_class, msg_id)
            #send the msg to the task with task_id
            receiver_task = self._task_by_task_id.get(receiver_task_id, None)
            if receiver_task is None:
                self.log.warn("receiver task could not be found for remote msg delivery")
            else:
                receiver_task.send(msg, *args, **kwargs)

    def register(self, name, task = None):  
        if task is None: 
            task = Tasklet.current()
        task_id = id(task)
        self._task_by_name[name] = task        
        self._task_id_by_task[task] = task_id
        self._task_by_task_id[task_id] = task 
        
    def serve(self, endpoint):  
        return Server.serve(endpoint, self.handle)

class RemoteClient(object):
    """Remoteing client. This represents the connection to the remote server.
    Use the lookup method to get a reference to a remote task.
    This reference can then be used to send or call msgs to the remote tasks
    """
    def __init__(self):
        self._stream = None
        self._message_writer_task = None
        self._message_reader_task = None
        self._bootstrap_task = RemoteTasklet(self, 0) #proxy to the remote bootstrap service
        self._blocked_message = {} #message_id -> message, for keeping track of blocking calls

    def _message_writer(self):
        object_writer = ObjectWriter(self._stream.writer)
        for msg, (remote_task_id, args), kwargs in Tasklet.receive():
            object_writer.write_object((remote_task_id, msg.__class__, id(msg), args, kwargs))
            object_writer.flush()
    
    def _message_reader(self):
        object_reader = ObjectReader(self._stream.reader)
        while True:
            msg, args  = object_reader.read_object()
            if issubclass(msg, MSG_RESULT):
                msg_id, result = args
                if msg_id in self._blocked_message:
                    self._blocked_message[msg_id].reply(result)
                else:
                    pass #this happens when caller already gone due to timeout
        
    def connect(self, endpoint):
        self._stream = BufferedStream(Connector.connect(endpoint))
        self._message_writer_task = Tasklet.new(self._message_writer)()
        self._message_reader_task = Tasklet.new(self._message_reader)()

    def close(self):
        self._message_writer_task.kill()
        self._message_reader_task.kill()
        self._stream.close()
        
    def send(self, remote_task_id, msg, args, kwargs):
        self._message_writer_task.send(msg, remote_task_id, args)        
                
    def call(self, remote_task_id, timeout, msg, args, kwargs):
        msg_id = id(msg)
        self._blocked_message[msg_id] = msg
        try:         
            self.send(remote_task_id, msg, args, kwargs)
            result = msg.wait(timeout)
            return result
        finally:
            del self._blocked_message[msg_id]

    def lookup(self, name):
        remote_task_id = MSG_LOOKUP.call(self._bootstrap_task)(name)
        if remote_task_id > 0:
            return RemoteTasklet(self, remote_task_id)
        else:
            return None

class RemoteTasklet(object):
    """Proxy to a remote task. Do not create this yourself, use lookup method on a RemoteClient"""
    def __init__(self, remote_client, remote_task_id):
        self._remote_client = remote_client
        self._remote_task_id = remote_task_id
        
    def send(self, msg, *args, **kwargs):
        assert isinstance(msg, Message)
        self._remote_client.send(self._remote_task_id, msg, args, kwargs)
    
    def call(self, msg, timeout, *args, **kwargs):
        assert isinstance(msg, Message)
        return self._remote_client.call(self._remote_task_id, timeout, msg, args, kwargs)
        


########NEW FILE########
__FILENAME__ = statistic
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

import time

def gamma_filter(prev, v, gamma = 0.95):
    return (gamma * prev) + ((1.0 - gamma) * v)
    
class Statistic(object):
    def __init__(self, v, g = 0.90):
        self._start_v = v
        self._v = v
        self._g = g
        self._lastV = None
        self._deltaV = None
        
    def reset(self):
        self._lastV = None
        self._deltaV = None
        
    @property    
    def count(self):
        return self._v
    
    def set_count(self, count):
        self._v = count

    def __add__(self, o):
        self._v += o
        return self

    def __sub__(self, o):
        self._v -= o
        return self
        
    @property
    def delta(self):
        """count/s"""
        return self._deltaV
    
    def __str__(self):
        return "#%d;%3.3f/s" % (self._v, self._deltaV or 0.0) 
    
    def __json__(self):
        return {'v': self._v, 'dv': self._deltaV or None}
        
    def update(self, elapsed = 0.0):
        """update the statistic delta's according to the elapsed period of time"""
        if self._lastV and elapsed:
            newDeltaV = (self._v - self._lastV) / elapsed
            if self._deltaV:
                self._deltaV = gamma_filter(self._deltaV, newDeltaV, self._g)
            else:
                self._deltaV = newDeltaV
        self._lastV = self._v
        
    @classmethod
    def find(cls, o):
        """find all statistics in o"""
        if isinstance(o, cls):
            yield o
        elif type(o) == dict:
            for v in o.values():
                for s in cls.find(v):
                    yield s
        elif type(o) == list:
            for v in o:
                for s in cls.find(v):
                    yield s
        else:
            pass

    @classmethod
    def updateall(cls, o, elapsed = 0.0):
        """finds all statistics in o and calls their update methods"""
        if elapsed > 0.0:
            for s in cls.find(o):
                s.update(elapsed)
        return o
            
    @classmethod
    def resetall(cls, o):
        """finds all statistics in o and calls their reset methods"""
        for s in cls.find(o):
            s.reset()

class _Time(object):
    def __init__(self, statistic):
        self._statistic = statistic
        
    def __enter__(self):
        self._start_time = time.time()
         
    def __exit__(self, type, value, traceback):        
        end_time = time.time()
        self._statistic += 1
        self._statistic.update_avg(end_time - self._start_time)

#TODO better name
class StatisticExtra(Statistic):
    def __init__(self, g = 0.90):
        Statistic.__init__(self, 0, g)
        self._avg = 0.0
        self._max = None
        self._min = None
    
    def reset(self):
        Statistic.reset(self)
        self._avg = 0.0
        self._max = None
        self._min = None
        
    def __str__(self):
        return "#%d;%3.3f/s;avg:%3.3f;min:%3.3f;max:%3.3f" % \
                (self.count, self.delta or 0.0, self._avg, 
                 -0.0 if self._min is None else self._min,
                 -0.0 if self._max is None else self._max) 

    def __json__(self):
        return {'v': self.count, 'dv': self.delta or None, 'avg': self._avg,
                'min': self._min, 'max': self._max}
    
    @property        
    def avg(self):
        return self._avg
    
    def update_avg(self, avg):
        self._avg = gamma_filter(self._avg, avg, self._g)
        if self._max is None or avg > self._max:
            self._max = avg
        if self._min is None or avg < self._min:
            self._min = avg
        
    def time(self):
        return _Time(self)
    
class StatisticMinMax(Statistic):
    def __init__(self, g = 0.90):
        Statistic.__init__(self, 0, g)
        self._max = None
        self._min = None

    def update_min_max(self):
        if self._max is None or self._v > self._max:
            self._max = self._v
        if self._min is None or self._v < self._min:
            self._min = self._v

    def set_count(self, count):
        self._v = count
        self.update_min_max()

    def __add__(self, o):
        self._v += o
        self.update_min_max()
        return self

    def __sub__(self, o):
        self._v -= o
        self.update_min_max()
        return self

    def update(self, elapsed = 0.0):
        pass
    
    def reset(self):
        self._max = None
        self._min = None
    
    def __str__(self):
        return "#%d;min:%d;max:%d" % \
                (self.count, 
                 -0.0 if self._min is None else self._min,
                 -0.0 if self._max is None else self._max) 

    def __json__(self):
        return {'v': self.count, 'min': self._min, 'max': self._max}


########NEW FILE########
__FILENAME__ = timer
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

import time

from concurrence import TaskLocal

class _Timeout(object):
    def __init__(self):
        self._timeout_time = [-1]

    def current(self):
        """returns the current timeout time to use in low level 'blocking' operations"""
        if self._timeout_time[-1] < 0:
            return -1
        else:
            timeout = self._timeout_time[-1] - time.time()
            if timeout < 0: timeout = 0.0 #expire immidiatly
            return timeout
        
    def push(self, timeout = -1):   
        current_timeout = self._timeout_time[-1]
        if timeout < 0 and current_timeout < 0:
            self._timeout_time.append(timeout)
        elif timeout < 0 and current_timeout >= 0:
            self._timeout_time.append(current_timeout)
        else:
            _timeout_time = time.time() + timeout    
            if current_timeout < 0:
                self._timeout_time.append(_timeout_time)
            else:
                self._timeout_time.append(min(_timeout_time, current_timeout))
            
    def pop(self):
        assert len(self._timeout_time) > 1, "unmatched pop, did you forget to push?"
        self._timeout_time.pop()
        
    def __enter__(self):
        return self
     
    def __exit__(self, type, value, traceback):
        self.pop()
        

class Timeout:
    """Task based timeout. The :class:`Timeout` class lets you set a timeout for the current task.
    If the task takes longer than *timeout* seconds after the timeout is set, a :class:`~concurrence.core.TimeoutError` is raised
    inside the task.
    
    Timeouts form a stack and you can always :func:`push` a new timeout on top of the current one. Every :func:`push` must be matched
    by a corresponding call to :func:`pop`. As a convenience you can use pythons `with` statement to do the pop automatically.  

    Timeout example::
    
        with Timeout.push(30):  #everything in following block must be finished within 30 seconds
            ...
            ...
            with Timeout.push(5):
                cnn = get_database_connection() #must return within 5 seconds
            ...
            ...
    
    """
     
    _local = TaskLocal()
    
    @classmethod
    def push(cls, timeout):
        """Pushes a new *timeout* in seconds for the current task."""
        try:
            t = cls._local.t
        except AttributeError:
            t = _Timeout()
            cls._local.t = t
        t.push(timeout)
        return t

    @classmethod
    def pop(cls):
        """Pops the current timeout for the current task."""
        try:
            t = cls._local.t
            t.pop()
        except AttributeError:
            assert False, "no timeout was pushed for the current task"

    @classmethod
    def current(cls):
        """Gets the current timeout for the current task in seconds. That is the number of seconds before the current task
        will timeout by raising a :class:`~concurrence.core.TimeoutError`. A timeout of -1 indicates that there is no timeout for the
        current task."""
        try:
            t = cls._local.t
        except AttributeError:
            t = None
        if t is None: #no timeout defined for current task, so return indefinte timeout
            return -1
        else:
            return t.current()

########NEW FILE########
__FILENAME__ = application
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

from __future__ import with_statement

import httplib
import inspect
import logging

from routes import Mapper

from webob import Request, Response

from concurrence import TaskInstance
from concurrence.wsgi import WSGIServer, WSGISimpleResponse

class web(object):
    def __init__(self):
        self.paths = []
        self.filters = []
        
    @classmethod
    def _get_web(cls, f):
        if not hasattr(f, '__web__'):
            f.__web__ = web()
        return f.__web__
        
    @classmethod
    def route(cls, path):
        def x(f):
            w = cls._get_web(f)
            w.paths.append(path)
            return f
        return x
    
    @classmethod    
    def filter(cls, filter_):
        def x(f):
            w = cls._get_web(f)
            w.filters.insert(0, filter_)
            return f
        return x

class Filter(object):
    def __call__(self, next, *args, **kwargs):
        return next(*args, **kwargs)

class Controller(object):
    __filters__ = []

    def __init__(self):
        self.application = None
        
    def __call__(self, action, *args, **kwargs):
        return action(*args, **kwargs)

class Application(object):
    log = logging.getLogger('Application')

    _scoped_response = TaskInstance(True)
    _scoped_request = TaskInstance(True)
    
    default_content_type = 'text/html'
    default_charset = 'UTF-8'
    
    def __init__(self):
        self._controllers = {} #name->instance
        self._template_lookup = None
        self._mapper = Mapper()
        self._not_found = WSGISimpleResponse(httplib.NOT_FOUND) #default not found wsgi app
        self._filters = {} #(controller, action): [filter, filter, ...]
        self._filter_chain = {} #(controller, action): filter_chain

    @classmethod
    def get_instance_from_request(cls):
        return cls._scoped_request.environ['concurrence.application']

    def configure(self):
        """configures the application, must be called after all controllers have been added"""        
        self._mapper.create_regs(self._controllers.keys())
        
    def _add_route(self, path, controller_name, action_name):
        self._mapper.connect(path, controller = controller_name, action = action_name)
        
    def _add_filter(self, filter, controller_name, action_name):
        filter.request = self._scoped_request
        filter.response = self._scoped_response
        filter_key = (controller_name, action_name)
        if not filter_key in self._filters:
            self._filters[filter_key] = []
        self._filters[filter_key].append(filter)
        
    def add_controller(self, controller):
        """adds a controller_class to the application.
        the controllers methods will be scanned for @web attributes to 
        connect the methods of the controller to the correct urls"""
        assert isinstance(controller, Controller), "controller must be instance of Controller"
        controller.application = self
        controller_name = controller.__class__.__module__ + '.' + controller.__class__.__name__
        self.log.debug("adding controller %s", controller_name)
        self._controllers[controller_name] = controller
        #add the scoped request and response classes
        controller.request = self._scoped_request
        controller.response = self._scoped_response
        
        #check its members for special @web attribute. these members are 'actions'
        for action_name, member in inspect.getmembers(controller):
            if inspect.ismethod(member) and hasattr(member, '__web__'):
                #this will setup path routing, filters etc:
                w = member.__web__
                for path in w.paths:
                    self._add_route(path, controller_name, action_name) 
                #add controller filters
                for filter in controller.__filters__:
                    self._add_filter(filter, controller_name, action_name) 
                #add action filters
                for filter in w.filters:
                    self._add_filter(filter, controller_name, action_name)
        return controller
        
    def set_template_lookup(self, template_lookup):
        self._template_lookup = template_lookup

    def call_controller(self, controller_name, action_name, *args, **kwargs):
        """provided for override"""
        controller = self._controllers[controller_name]
        action = getattr(controller, action_name)
        return controller(action, *args, **kwargs)
        
    def __call__(self, environ, start_response):

        match =  self._mapper.match(environ['PATH_INFO'])
        if not match:
            return self._not_found(environ, start_response)

        controller_name = match['controller']
        action_name = match['action']        
        controller_action = (controller_name, action_name)

        del match['controller']
        del match['action']

        environ['concurrence.application'] = self

        #the actual request and response instances
        request = Request(environ)
        response = Response(content_type = self.default_content_type, charset = self.default_charset)

        #they will be added to the task local scope here:
        with self._scoped_request.set(request):
            with self._scoped_response.set(response):
                if not controller_action in self._filter_chain:
                    #we still need to setup call chain for this controller:action
                    #calling the controller is the last thing todo in the chain:
                    def last(next, *args, **kwargs):
                        return self.call_controller(controller_name, action_name, *args, **kwargs)
                    #set up call chain
                    filter_chain = []
                    for i, filter in enumerate(self._filters.get(controller_action, []) + [last, None]):
                        def create_next(_i, _filter):                        
                            def next(*args, **kwargs):
                                return _filter(filter_chain[_i + 1], *args, **kwargs)
                            return next
                        filter_chain.append(create_next(i, filter))
                    self._filter_chain[controller_action] = filter_chain
                #this will call the filter chain and produce the result
                result = self._filter_chain[controller_action][0](**match)
        
        if type(result) == str:
            response.body = result
        elif type(result) == unicode:
            response.unicode_body = result
        elif result is None:
            response.body = ''
        elif type(result) == type(response):
            response = result
        else:
            assert False, "result must be None, str, unicode or response object, found: %s" % type(result)

        return response(environ, start_response)

    def render(self, template_path, **kwargs):
        assert self._template_lookup is not None, "template lookup must be set to use render"
        template = self._template_lookup.get_template(template_path)
        return template.render(**kwargs)

    def serve(self, endpoint):
        server = WSGIServer(self)
        return server.serve(endpoint)
        
def render(template_path, **kwargs):
    application = Application.get_instance_from_request()
    return application.render(template_path, **kwargs)

def serve(endpoint = ('0.0.0.0', 8080), controllers = []):
    """a convenience method to quickly start an application for testing"""
    application = Application()
    for controller in controllers:
        application.add_controller(controller)
    application.configure()
    application.serve(endpoint)
    
    from concurrence import dispatch
    dispatch()

########NEW FILE########
__FILENAME__ = filter
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

from __future__ import with_statement

import httplib
import logging
import traceback
import time

from concurrence.web import Filter
from concurrence import json, TimeoutError

class JSONFilter(Filter):
    def __call__(self, next, *args, **kwargs):
        try:
            self.response.content_type = 'application/json'
            return next(*args, **kwargs)
        except TaskletExit:
            raise
        except Exception, e:
            logging.exception("exception in json request")
            if self.response.status_int < 400:
                self.response.status = httplib.INTERNAL_SERVER_ERROR
            return json.dumps({'message': unicode(e), 'trace': unicode(traceback.format_exc(10))})
    
from concurrence.timer import Timeout

class TimeoutFilter(Filter):
    """a filter that checks the request headers for a timeout header
    and sets a timeout for this request as required"""
    def __call__(self, next, *args, **kwargs):
        timeout = float(self.request.environ.get('HTTP_TIMEOUT', '-1'))
        with Timeout.push(timeout):
            return next(*args, **kwargs)

########NEW FILE########
__FILENAME__ = middleware
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

import logging
import httplib
import os
import mimetypes

class WSGISimpleResponse(object):
    def __init__(self, status_code = httplib.OK, response = None, content_type = 'text/html', headers = []):
        self.status_code = status_code
        self.response = response
        self.content_type = content_type
        self.headers = headers

    def __call__(self, environ, start_response):
        response_text = httplib.responses[self.status_code]
        response_line = "%d %s" % (self.status_code, response_text)
        start_response(response_line, [('Content-type', self.content_type)] + self.headers)
        if self.response is None:
            return [response_text]
        else:
            return [self.response]

RESPONSE_NOT_FOUND = WSGISimpleResponse(httplib.NOT_FOUND)

class WSGISimpleMessage(WSGISimpleResponse):
    def __init__(self, msg):
        WSGISimpleResponse.__init__(self, httplib.OK, msg)
        
class WSGISimpleStatic(WSGISimpleResponse):
    log = logging.getLogger('WSGISimpleStatic')

    def __init__(self, root, prefix):
        self._map = {}
        self._load(root)
        self._root = root
        self._prefix = prefix
        self._not_found = RESPONSE_NOT_FOUND

    def _load(self, root):
        if os.path.isfile(root):
            self._load_file(root, root)
        elif os.path.isdir(root):
            for dirpath, dirnames, filenames in os.walk(root):
                for filename in filenames:
                    self._load_file(root, os.path.join(dirpath, filename))                    
        else:
            assert False, "unknown path type (not a file or dir)"

    def _load_file(self, root, path):
        f = open(path)
        content = f.read()
        f.close()
        content_type, _ = mimetypes.guess_type(path, False)
        if content_type is None:
            assert False, "unknown content type"
        content_length = len(content)
        path = path[len(root):]
        self.log.debug("preloading %s => %d, %s", path, content_length, content_type)
        self._map[path] = (content, content_type, content_length)

    def __call__(self, environ, start_response):
        path_info = environ['PATH_INFO'][len(self._prefix):]
        if path_info in self._map:
            content, content_length, content_type = self._map[path_info]
            response_line = "%d %s" % (200, httplib.responses[200])
            start_response(response_line, [('Content-Type', content_type), ('Content-Length', content_length)])
            return [content]            
        else:     
            return self._not_found(environ, start_response) 

class WSGISimpleRouter(object):
    """a simple router middleware to dispatch to applications based on uri-path"""
    def __init__(self):
        self._mapping = []
        self._not_found = RESPONSE_NOT_FOUND
        
    def map(self, path, application):
        self._mapping.append((path, application))
        
    def __call__(self, environ, start_response):
        path_info = environ['PATH_INFO']
        for path, application in self._mapping:
            if path_info.startswith(path):
                return application(environ, start_response)
        return self._not_found(environ, start_response)        


########NEW FILE########
__FILENAME__ = client
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

#TODO heartbeat
from __future__ import with_statement

from xml.etree.cElementTree import dump, tostring

from concurrence.timer import Timeout
from concurrence.io import Connector 
from concurrence.xmpp import sasl
from concurrence.xmpp.stream import XMPPStream

import logging

class XMPPError(Exception):
    pass
        
class XMPPClient(object):
    log = logging.getLogger('XMPPClient')
        
    def __init__(self):
        self.socket = None
        self.elements = None
        
    def close(self):
        if not self.socket.is_closed():
            self.stream.write_end()
            self.socket.close()
        
    def _handshake(self, username, password, realm):
        #perform SASL handshake
        element_features = self.elements.next()
        if element_features.tag != '{http://etherx.jabber.org/streams}features':
            self.log.error(tostring(element_features))
            assert False, 'unexpected tag: %s expected features' % element_features.tag

        self.stream.write_auth()
            
        element_challenge = self.elements.next()
        if element_challenge.tag != '{urn:ietf:params:xml:ns:xmpp-sasl}challenge':
            assert False, 'unexpected element: %s' % element_challenge.tag 

        response = sasl.response(element_challenge.text, username, password, realm, 'xmpp/' + realm)

        self.stream.write_sasl_response(response)
        
        element = self.elements.next()
        
        if element.tag == '{urn:ietf:params:xml:ns:xmpp-sasl}failure':
            assert False, "login failure"
        elif element.tag == '{urn:ietf:params:xml:ns:xmpp-sasl}challenge':
            pass #OK
        else:
            assert False, "unexpected element: %s" % element.tag
        
        self.stream.write_sasl_response()

        element = self.elements.next()
        if element.tag != '{urn:ietf:params:xml:ns:xmpp-sasl}success':
            assert False, "error %s" % element.tag 
        
    def connect(self, endpoint, username, password, realm, resource):
        
        self.socket = Connector.connect(endpoint)

        #start xml stream
        self.stream = XMPPStream(self.socket)

        self.stream.write_start(1)
        self.elements = self.stream.elements()

        #perform auth handshake
        self._handshake(username, password, realm)

        #after SASL-auth we are supposed to restart the xml stream:
        self.stream.reset()
        self.stream.write_start(2, include_xml_pi = False)
        self.elements = self.stream.elements()

        #read stream features
        element = self.elements.next()
        if element.tag != '{http://etherx.jabber.org/streams}features':
            assert False, "expected stream features, got: %s" % element.tag
            
        #bind resource
        self.stream.write_bind_request('bind', resource)
            
        element = self.elements.next()
        #TODO assert more on bind result
        if element.tag != '{jabber:client}iq':
            assert False, "expected iq, got: %s" % element.tag

        #send session request
        self.stream.write_session_request(realm, 3)
            
        element = self.elements.next()
        #TODO check result
        if element.tag != '{jabber:client}iq':
            assert False, 'expected iq result got: %s' % element.tag

        #now we are ready and fully logged in
        self.jid = '%s@%s/%s' % (username, realm, 'henktest')
    
    def send_presence(self, priority):
        self.stream.write_presence(priority)

    def send_message(self, to_jid, msg):
        self.stream.write_message(to_jid, msg)
            
            
            
            

########NEW FILE########
__FILENAME__ = sasl
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

import binascii
import base64
import md5
import random

def H(s):
    return md5.new(s).digest()

def KD(k, s):
    return H(k + ":" + s)
    
def HEX(n):
    return binascii.hexlify(n)

def UNHEX(h):
    return binascii.unhexlify(h)

def response(challenge, user, password, realm, digest_uri):
    #parse challenge
    c = {}
    for x in base64.decodestring(challenge).split(","):
        i = x.find('=')
        if i == -1: continue        
        key = x[:i].strip()
        value = x[i+1:].strip()
        if value[0] == '"' and value[-1] == '"': value = value[1:-1]
        key = key.replace('-', '_')
        c[key] = value
    
    #calculate response
    nonce = c['nonce']    
    cnonce = hex(random.getrandbits(128))[2:-1].lower()
    nc = "00000001"
    qop = "auth"
    digest = HEX(H("%s:%s:%s" % (user, realm, password)))

    A2 = "AUTHENTICATE:" + digest_uri
    A1 = UNHEX( digest ) + ":" + nonce + ":" + cnonce
    response = HEX(KD(HEX(H(A1)), nonce + ":" + nc + ":" + cnonce + ":" + qop + ":" + HEX(H(A2))))

    response = """username="%s",realm="%s",nonce="%s",cnonce="%s",nc=00000001,qop=auth,digest-uri="%s",response=%s,charset=utf-8""" % \
                (user, realm, nonce, cnonce, digest_uri, response)

    return "".join(base64.encodestring(response).split("\n"))
########NEW FILE########
__FILENAME__ = stream
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

from xml.etree.cElementTree import iterparse, dump

from concurrence.io import Buffer
from concurrence.io.buffered import BufferedStream

class XMPPStream:
    MAJOR_VERSION = 1
    MINOR_VERSION = 0
    DEFAULT_LANGUAGE = "en"
    NS_XMPP_STREAM_STREAM = "http://etherx.jabber.org/streams"
    
    NS_JABBER_CLIENT = "jabber:client"
    
    def __init__(self, stream, stream_uri = NS_XMPP_STREAM_STREAM, default_ns = NS_JABBER_CLIENT):
        self.stream = BufferedStream(stream)
        self.stream_uri = stream_uri
        self.default_ns = default_ns
        self.reset()
        
    def reset(self):
        self.parser = None
        self.root = None
        
    def write_bytes(self, s):
        self.stream.writer.clear()
        self.stream.writer.write_bytes(s)
        self.stream.writer.flush()
        
    def write_start(self, _id, lang = DEFAULT_LANGUAGE, major_version = MAJOR_VERSION, minor_version = MINOR_VERSION, _to = "", _from = "", include_xml_pi = True):
        if include_xml_pi:         
            start = """<?xml version='1.0' encoding='utf-8'?>"""
        else:
            start = ""

        start += """<stream:stream xmlns:stream="%s" xmlns="%s" id="%s" xml:lang="%s" version="%d.%d" """ 
        start = start % (self.stream_uri, self.default_ns, _id, lang, major_version, minor_version)
    
        if _from: start += ' from="%s"' % _from
        if _to: start += ' to="%s"' % _to
    
        start += ">"
 
        self.write_bytes(start)
        
    def write_end(self):
        self.write_bytes("</stream:stream>")
                
    def write_auth(self, mechanism = 'DIGEST-MD5'):
        self.write_bytes("""<auth xmlns='urn:ietf:params:xml:ns:xmpp-sasl' mechanism='%s'/>""" % mechanism)
    
    def write_sasl_response(self, response = ''):
        if response:        
            self.write_bytes("""<response xmlns='urn:ietf:params:xml:ns:xmpp-sasl'>%s</response>""" % response)
        else:
            self.write_bytes("""<response xmlns='urn:ietf:params:xml:ns:xmpp-sasl'/>""")
    
    def write_bind_request(self, _id, resource):
        self.write_bytes("""<iq id='%s' type='set'>
          <bind xmlns='urn:ietf:params:xml:ns:xmpp-bind'>
            <resource>%s</resource>
          </bind>
        </iq>""" % (_id, resource))
        
    def write_session_request(self, domain, _id):
        self.write_bytes("""
        <iq id='%s' type='set' to='%s'>
          <session xmlns='urn:ietf:params:xml:ns:xmpp-session'/>
        </iq>""" % (_id, domain))
        
    def write_presence(self, priority):
        self.write_bytes("""<presence><priority>%d</priority></presence>""" % priority)

    def write_message(self, to_jid, msg):
        self.write_bytes(str("<message to='%s' type='chat'><body>%s</body></message>" % (to_jid, msg)))
    
    def elements(self):
        
        if not self.parser:
            reader = self.stream.reader
            class f(object):
                def read(self, n):
                    if reader.buffer.remaining == 0:
                        #read more data into buffer
                        reader._read_more()
                    return reader.buffer.read_bytes(min(n, reader.buffer.remaining))

            self.parser = iter(iterparse(f(), events=("start", "end")))
            event, self.root = self.parser.next()
            level = 0
        
        for event, element in self.parser:
            if event == 'start':
                level += 1
            elif event == 'end':
                level -= 1
                if level == 0:
                    yield element
                #TODO clear root
            else:
                assert False, "unexpected event"
                

########NEW FILE########
__FILENAME__ = _stackless
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

"""This module implements the stackless API on top of py.magic greenlet API
This way it is possible to run concurrence applications on top of normal python
using the greenlet module.
Because the greenlet module uses only 'hard' switching as opposed to stackless 'soft' switching
it is a bit slower (about 35%), but very usefull because you don't need to install stackless.
Note that this does not aim to be a complete implementation of stackless on top of greenlets,
just enough of the stackless API to make concurrence run.
This code was inspired by:
http://aigamedev.com/programming-tips/round-robin-multi-tasking and
also by the pypy implementation of the same thing (buggy, not being maintained?) at 
https://codespeak.net/viewvc/pypy/dist/pypy/lib/stackless.py?view=markup
"""

try:
    from py.magic import greenlet #as of version 1.0 of py, it does not supply greenlets anymore
except ImportError:
    from greenlet import greenlet #there is an older package containing just the greenlet lib

from collections import deque

class TaskletExit(SystemExit):pass

import __builtin__
__builtin__.TaskletExit = TaskletExit


class bomb(object):
    """used as a result value for sending exceptions trough a channel"""
    def __init__(self, exc_type = None, exc_value = None, exc_traceback = None):
        self.type = exc_type
        self.value = exc_value
        self.traceback = exc_traceback

    def raise_(self):
        raise self.type, self.value, self.traceback

class channel(object):
    """implementation of stackless's channel object"""
    def __init__(self):
        self.balance = 0
        self.queue = deque()
        
    def receive(self):
        return _scheduler._receive(self)

    def send(self, data):
        return _scheduler._send(self, data)

    def send_exception(self, exp_type, *args):
        self.send(bomb(exp_type, exp_type(*args)))

    def send_sequence(self, iterable):
        for item in iterable:
            self.send(item)
        

            
class tasklet(object):
    """implementation of stackless's tasklet object"""
    
    def __init__(self, f = None, greenlet = None, alive = False):
        self.greenlet = greenlet
        self.func = f
        self.alive = alive
        self.blocked = False
        self.data = None
        
    def bind(self, func):
        if not callable(func):
            raise TypeError('tasklet function must be a callable')
        self.func = func

    def __call__(self, *args, **kwargs):
        """this is where the new task starts to run, e.g. it is where the greenlet is created
        and the 'task' is first scheduled to run"""
        if self.func is None:
            raise TypeError('tasklet function must be a callable')

        def _func(*_args, **_kwargs):
            try:
                self.func(*args, **kwargs)
            except TaskletExit:
                pass #let it pass silently
            except:
                import logging
                logging.exception('unhandled exception in greenlet')
                #don't propagate to parent
            finally:
                assert _scheduler.current == self
                _scheduler.remove(self)
                if _scheduler._runnable: #there are more tasklets scheduled to run next
                    #this make sure that flow will continue in the correct greenlet, e.g. the next in the schedule
                    self.greenlet.parent = _scheduler._runnable[0].greenlet
                self.alive = False            
                del self.greenlet
                del self.func
                del self.data

        self.greenlet = greenlet(_func)
        self.alive = True
        _scheduler.append(self)
        return self

    def kill(self):
        _scheduler.throw(self, TaskletExit)

    def raise_exception(self, *args):
        _scheduler.throw(self, *args)

    def __str__(self):
        return repr(self)

    def __repr__(self):
        if hasattr(self, 'name'):
            _id = self.name
        else:
            _id = str(self.func)
        return '<tasklet %s at %0x>' % (_id, id(self))

class scheduler(object):
    def __init__(self):
        self._main_task = tasklet(greenlet = greenlet.getcurrent(), alive = True) 
        #all non blocked tast are in this queue
        #all tasks are only onces in this queue
        #the current task is the first item in the queue
        self._runnable = deque([self._main_task])
    
    def schedule(self):
        """schedules the next tasks and puts the current task back at the queue of runnables"""
        self._runnable.rotate(-1)
        next_task = self._runnable[0]
        next_task.greenlet.switch()
        
    def schedule_block(self):
        """blocks the current task and schedules next"""
        self._runnable.popleft()
        next_task = self._runnable[0]
        next_task.greenlet.switch()

    def throw(self, task, *args):
        if not task.alive: return #this is what stackless does
        
        assert task.blocked or task in self._runnable

        task.greenlet.parent = self._runnable[0].greenlet
        if task.blocked:
            self._runnable.appendleft(task)
        else:
            self._runnable.remove(task)
            self._runnable.appendleft(task)

        task.greenlet.throw(*args) 


    def _receive(self, channel):
        #Receiving 1):
        #A tasklet wants to receive and there is
        #a queued sending tasklet. The receiver takes
        #its data from the sender, unblocks it,
        #and inserts it at the end of the runnables.
        #The receiver continues with no switch.
        #Receiving 2):
        #A tasklet wants to receive and there is
        #no queued sending tasklet.
        #The receiver will become blocked and inserted
        #into the queue. The next sender will
        #handle the rest through "Sending 1)".        
        if channel.queue: #some sender
            channel.balance -= 1
            sender = channel.queue.popleft()
            sender.blocked = False
            self._runnable.append(sender)
            data, sender.data = sender.data, None
        else: #no sender
            current = self._runnable[0]
            channel.queue.append(current)
            channel.balance -= 1
            current.blocked = True
            try:    
                self.schedule_block()
            except:
                channel.queue.remove(current)
                channel.balance += 1
                current.blocked = False
                raise

            data, current.data = current.data, None

        if isinstance(data, bomb):
            data.raise_()
        else:
            return data

    def _send(self, channel, data):
        #  Sending 1):
        #    A tasklet wants to send and there is
        #    a queued receiving tasklet. The sender puts
        #    its data into the receiver, unblocks it,
        #    and inserts it at the top of the runnables.
        #    The receiver is scheduled.
        #  Sending 2):
        #    A tasklet wants to send and there is
        #    no queued receiving tasklet.
        #    The sender will become blocked and inserted
        #    into the queue. The next receiver will
        #    handle the rest through "Receiving 1)".     
        #print 'send q', channel.queue   
        if channel.queue: #some receiver   
            channel.balance += 1
            receiver = channel.queue.popleft()
            receiver.data = data
            receiver.blocked = False
            self._runnable.rotate(-1)
            self._runnable.appendleft(receiver)
            self._runnable.rotate(1)
            self.schedule()
        else: #no receiver
            current = self.current
            channel.queue.append(current)
            channel.balance += 1
            current.data = data
            current.blocked = True
            try:
                self.schedule_block()
            except:
                channel.queue.remove(current)
                channel.balance -= 1
                current.data = None
                current.blocked = False
                raise
        
    def remove(self, task):
        assert task.blocked or task in self._runnable
        if task in self._runnable:
            self._runnable.remove(task)
    
    def append(self, task):
        assert task not in self._runnable
        self._runnable.append(task)
        
    @property
    def runcount(self):
        return len(self._runnable) 

    @property
    def current(self):
        return self._runnable[0]

#there is only 1 scheduler, this is it:
_scheduler = scheduler()

def getruncount():
    return _scheduler.runcount

def getcurrent():
    return _scheduler.current

def schedule():
    return _scheduler.schedule()



########NEW FILE########
__FILENAME__ = dummy_thread
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php


########NEW FILE########
__FILENAME__ = dummy_threading
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php


########NEW FILE########
__FILENAME__ = thread
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

def allocate_lock():
    import threading
    return threading.Lock()

########NEW FILE########
__FILENAME__ = threading
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

class LockType(object):
    def __init__(self, *args, **kwargs):
        pass        

    def acquire(self, waitflag=None):        
        return True
 
    __enter__ = acquire
 
    def __exit__(self, typ, val, tb):
        pass
 
    def release(self):
        pass
    
    def locked(self):
        return False

class RLock(LockType):
    pass

class Lock(LockType):
    pass

class Thread(object):
    def getName(self):
        return 'dummy'

class ThreadLocal(object):
    def __init__(self):
        pass        
       
class _Timer(object):
    pass

local = ThreadLocal

_currentThread = Thread()

def currentThread():
    return _currentThread

def _shutdown(*args, **kwargs):
    pass

########NEW FILE########
__FILENAME__ = _unittest
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

import unittest
import logging

from concurrence import dispatch, Tasklet, quit 
from concurrence.core import EXIT_CODE_TIMEOUT

from concurrence.io import IOStream


class TestCase(unittest.TestCase):
    def setUp(self):
        logging.debug(self)

    def tearDown(self):
        try:
            Tasklet.yield_() #this make sure that everything gets a change to exit before we start the next test
        except:
            pass

def main(timeout = None):

    logging.basicConfig()
    logging.root.setLevel(logging.DEBUG)

    if timeout is not None:
        Tasklet.later(timeout, quit, name = 'unittest_timeout')(EXIT_CODE_TIMEOUT)
        
    dispatch(unittest.main)

########NEW FILE########
__FILENAME__ = httpperf
#!/usr/bin/env stackless

from concurrence import dispatch, quit, Tasklet, Channel
from concurrence.http.client import HTTPConnection
from concurrence.statistic import gamma_filter
from concurrence.containers.deque import Deque
from optparse import OptionParser

import urlparse
import logging
import time
import sys

def parse_options():
    
    parser = OptionParser(usage="%prog [options]", version="%prog 1.0", prog="httpperf")
    parser.add_option("--url", type="string", default=None, dest="url", metavar="URL", help="the url to fetch")
    parser.add_option("--sessions", type="int", default=1, dest="sessions", metavar="SESSIONS", help="")
    parser.add_option("--requests", type="int", default=-1, dest="requests", metavar="REQUESTS", help="")
    parser.add_option("--count", type="int", default=-1, dest="count", metavar="COUNT", help="")
    parser.add_option("--delay", type="float", default=1, dest="delay", metavar="DELAY", help="")
    parser.add_option("--pipeline", type="int", default=1, dest="pipeline", metavar="PIPELINE", help="")
    parser.add_option("--dump", action="store_true", dest="dump", metavar="DUMP", help="")
    (options, _) = parser.parse_args()
    return options
    
    
class HttpPerf(object):
    def __init__(self, options):
        self.status = {}
        self.request = 0
        self.lastRequest = None
        self.lastTime = None
        self.options = options
        self.dispenser = Channel()
        
    def session_response_reader(self, cnn, pipeline_tokens):
        #TODO use tasklet.loop, must be extended such that you can stop the loop by returning something (or StopIteration?)
        while True:
            response = cnn.receive()

            #read status
            self.count('status', response.status)
            
            connection_header = response.get_header('Connection')
            if connection_header == 'close' and self.options.requests != 1:
                print >> sys.stderr, "WARNING: Server closed connection, no Keep Alive!, please use --requests=1"
                
            
            #this will read the complete response
            if self.options.dump:
                print response.status
                for k, v in response.headers:
                    print "%s: %s" % (k, v)
                for chunk in response:
                    sys.stdout.write(chunk)
                sys.stdout.flush()
                print
            else:
                list(response)
            #print 'resp'
            pipeline_tokens.append(True)
                
    def session(self, host, port, path):
        cnn = None

        pipeline_tokens = Deque()

        for _ in range(self.options.pipeline): # can append take iterator?, or list?
            pipeline_tokens.append(True)

        try:
            cnn = HTTPConnection()
            cnn.connect((host, port))

            Tasklet.new(self.session_response_reader)(cnn, pipeline_tokens)
            
            requests = 0 #no requests in this session
            while True:

                if self.options.requests != -1 and requests >= self.options.requests:
                    break #we are done with this session
                       
                if self.dispenser.receive() is None:
                    return False #we are done globally

                pipeline_tokens.popleft(True)

                #do the request
                cnn.send(cnn.get(path))
                #print response
                  
                requests += 1
                
                self.count('request')
                
        finally:    
            #if response_reader_task is not None:   
            #    response_reader_task.kill()
            if cnn is not None:
                cnn.close() 

        return True

    def sessions(self):
        u = urlparse.urlparse(self.options.url)
        
        if ':' in u.netloc:
            host, port = u.netloc.split(':')
            port = int(port)
        else:
            host, port = u.netloc, 80
    
        path = urlparse.urlunsplit(['', '', u.path, u.query, u.fragment])
        if path == '':
            path = '/'
    
        try:
            while True:
                if not self.session(host, port, path):
                    return
                    
        except TaskletExit:
            raise
        except:
            logging.exception("exception in http session")
        
    def count(self, attr, key = None, inc = 1):
        a = getattr(self, attr)
        if key is None:
            v = a + inc
            setattr(self, attr, v)
            return v
        else:
            if not key in a:
                a[key] = inc
            else:
                a[key] = a[key] + inc
            return a[key]
       
    def show(self):
        now = time.time()
        
        if self.lastTime is not None:
            reqSec = (self.request - self.lastRequest) / (now - self.lastTime)
            reqSec = gamma_filter(self.lastReqSec, reqSec, 0.60)
        else:
            reqSec = 0.0
            
        print >> sys.stderr, self.status, self.request, reqSec
        
        self.lastTime = time.time()
        self.lastRequest = self.request
        self.lastReqSec = reqSec
        
    def dispense(self):
        if self.options.count == -1: 
            #run forever
            while True:
                self.dispenser.send(True)
                if self.options.delay > 0.0:
                    Tasklet.sleep(self.options.delay)
        else:
            #a fixed number of total requests
            for i in range(self.options.count):
                self.dispenser.send(True)
                if self.options.delay > 0.0:
                    Tasklet.sleep(self.options.delay)
            for i in range(self.options.sessions):
                self.dispenser.send(None)
        
    def run(self):
        #show stats every second:
        Tasklet.interval(1.0, self.show, immediate = True)()
        
        #dispenses tokens for doing a request to sessions:
        Tasklet.new(self.dispense)()
        
        #start up sessions, and wait till they are finished
        Tasklet.join_all([Tasklet.new(self.sessions)() for _ in range(self.options.sessions)])
        
        quit()
           
def main():

    options = parse_options()
    
    if not options.url:
        assert False, "provide a url please!"

    perf = HttpPerf(options)
    perf.run()

if __name__ == '__main__':
    dispatch(main)

########NEW FILE########
__FILENAME__ = queryblaster
# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

import logging
logging.basicConfig(level = logging.ERROR)
#logging.basicConfig(level = logging.DEBUG)

import sys
import time

from optparse import OptionParser

from concurrence import Tasklet, dispatch, quit
from concurrence.database.mysql import client
from concurrence.database.mysql.client import Connection
from concurrence.database.pool import Pool

def parse_options():
    
    parser = OptionParser(usage="%prog [options]", version="%prog 1.0", prog="queryblaster")
    parser.add_option("-u", type="string", default="root", dest="user", metavar="USERNAME", help="")
    parser.add_option("-p", type="string", default='', dest="passwd", metavar="PASSWORD", help="")
    parser.add_option("--host", type="string", default='localhost', dest="host", metavar="HOST", help="")
    parser.add_option("--database", type="string", default='', dest="db", metavar="DATABASE", help="")
    parser.add_option("--port", type="int", default=3306, dest="port", metavar="PORT", help="")
    parser.add_option("--sessions", type="int", default=1, dest="sessions", metavar="SESSIONS", help="number of simultanious connections")
    parser.add_option("--qpc", type="int", default=1, dest="queries_per_connection", metavar="QPC", help="queries per session")
    parser.add_option("--count", type="int", default=1, dest="query_count", metavar="QUERY_COUNT", help="total query count (accross all sessions)") 
    parser.add_option("--query", type="string", default="select 1", dest="query", metavar="QUERY", help="the query (default = select 1)")
    parser.add_option("--use_pool", type="int", default=0, dest="use_pool", metavar="NR_CONNECTIONS", help="use pooling = int, nr of connections in pool")
       
    (options, _) = parser.parse_args()
    return options

class Session(object):
    def __init__(self, options):
        self.options = options
    
    def get_connection(self):
        if self.options.use_pool:
            _, cnn = self.options.pool.connect()
            return cnn
        else:
            cnn = Connection()
            cnn.connect(**self.options.dbargs)
            return cnn

    def end_connection(self, cnn):
        if cnn is None:
            return
        if self.options.use_pool:
            return self.options.pool.disconnect(cnn)
        else:
            if cnn.is_connected():
                cnn.close()
        
    def run(self):
        query_count = 0
        try:
            while True:
                cnn = None
                try:
                    cnn = self.get_connection()
                    for i in range(self.options.queries_per_connection):
                        if self.options.query_count > 0:
                            self.options.query_count -= 1
                            rs = cnn.query(self.options.query)
                            list(rs) #reads out result set
                            rs.close()
                            query_count += 1
                        else:
                            return query_count
                finally:
                    self.end_connection(cnn)
        except Exception:   
            logging.exception("in session")
            raise
        
def main():

    options = parse_options()

    options.dbargs = {'host': options.host, 
                      'port': options.port, 
                      'user': options.user, 
                      'passwd': options.passwd, 
                      'db': options.db}
        
    if options.use_pool:
        options.pool = Pool(client, options.dbargs, options.use_pool)
    
    for i in range(options.sessions):
        session = Session(options)
        Tasklet.new(session.run)()

    try:
        query_count = options.query_count
        start = time.time()
        query_count_done = sum(Tasklet.join_children())
        end = time.time()
        print end - start, query_count_done, query_count_done / (end - start)
    except Exception:
        logging.exception("must be an error in one of the sessions")
    
    quit()
    
if __name__ == '__main__':
    dispatch(main)
########NEW FILE########
__FILENAME__ = update_license
import sys
import os

LICENSE = """# Copyright (C) 2009, Hyves (Startphone Ltd.)
#
# This module is part of the Concurrence Framework and is released under
# the New BSD License: http://www.opensource.org/licenses/bsd-license.php

"""

root = os.path.split(os.path.abspath(sys.argv[0]))[0]
lib = root + os.path.sep + '../lib'

EXTS = ['.py', '.pyx', '.pxd']
EXCLUDE = ['.svn', '_event.pyx']

for path, dirs, files in os.walk(lib):
    for file in files:
        file_path = os.path.join(path, file)
        exclude = False
        for exl in EXCLUDE:
            if exl in file_path: exclude = True
        if exclude: continue
        ext = os.path.splitext(file_path)[1]        
        if not ext in EXTS: continue
        #ok insert license
        f = open(file_path)
        s = f.read()
        f.close()
        s = LICENSE + s
        f = open(file_path, 'w')
        f.write(s)
        f.close()
        print file_path
        #sys.exit()
########NEW FILE########
__FILENAME__ = testbuffer
from concurrence import unittest
from concurrence.io.buffered import Buffer, BufferUnderflowError, BufferInvalidArgumentError

class TestBuffer(unittest.TestCase):
    def testDuplicate(self):

        b = Buffer(1024)
        c = b.duplicate()
        
        self.assertEqual(b.position, c.position)
        self.assertEqual(b.limit, c.limit)
        self.assertEqual(b.capacity, c.capacity)

        b.write_bytes('test')

        #check that position is independend from c
        self.assertNotEqual(b.position, c.position)
        self.assertEqual(b.limit, c.limit)
        self.assertEqual(b.capacity, c.capacity)

        #but data buffer should be shared with c, so c should be able to read it
        self.assertEquals('test', c.read_bytes(4))

        #if we delete b, c should still be able to reference the buffer, (it will keep b around
        #until it itself is released
        del b
        c.clear()
        self.assertEquals('test', c.read_bytes(4))
        del c #this releases buffer b as well, we cannot test this, but this should not crash :-)

    def testGetSetItem(self):
        b = Buffer(1024)
        
        try:
            x = b[-1]
            self.fail()
        except BufferInvalidArgumentError:
            pass
        x = b[0]
        x = b[1023]
        try:            
            x = b[1024]
            self.fail()
        except BufferInvalidArgumentError:
            pass
        try:            
            x = b[1025]
            self.fail()
        except BufferInvalidArgumentError:
            pass
        

        try:
            b[-1] = 1
            self.fail()
        except BufferInvalidArgumentError:
            pass
        b[0] = 1
        b[1023] = 1
        try:            
            b[1024] = 1
            self.fail()
        except BufferInvalidArgumentError:
            pass
        try:            
            b[1025] = 1
            self.fail()
        except BufferInvalidArgumentError:
            pass

        try:
            b[0] = -1
            self.fail()
        except BufferInvalidArgumentError:
            pass

        try:
            b[0] = 256
            self.fail()
        except BufferInvalidArgumentError:
            pass
        
    def testSlice(self):
        b = Buffer(1024)
        for i in range(1024):
            b[i] = i % 256

        self.assertEquals(0, b[0])
        self.assertEquals(255, b[1023])
        self.assertEquals('\x00\x01\x02\x03\x04\x05\x06\x07\x08\t\n\x0b\x0c\r\x0e\x0f', b[0:16])
        self.assertEquals('\xf0\xf1\xf2\xf3\xf4\xf5\xf6\xf7\xf8\xf9\xfa\xfb\xfc\xfd\xfe\xff', b[-16:])

        try:
            b[0:16] = '1234567890123456xxx'
            self.fail()
        except BufferInvalidArgumentError:
            pass

        b[0:16] = '1234567890123456'
        b[16:32] = '1234567890123456'
        b[-16:] = '1234567890123456'
        self.assertEquals('1234567890123456', b[0:16])
        self.assertEquals('1234567890123456', b[16:32])
        self.assertEquals('1234567890123456', b[-16:])
    

    def testInt(self):
        b = Buffer(1024)
        b.write_int(0x4A3B2C1D)
        #write_int is little-endian
        self.assertEquals(['0x1d', '0x2c', '0x3b', '0x4a'], [hex(b[i]) for i in range(4)])

    def testString1(self):
        S = 'Henk\0Punt'
        b = Buffer(1024)
        self.assertEqual(0, b.position)
        self.assertEqual(1024, b.limit)                
        b.write_bytes(S)
        self.assertEqual(9, b.position)
        self.assertEqual(1024, b.limit)
        b.flip()                
        self.assertEqual(0, b.position)
        self.assertEqual(9, b.limit)
        
    def testString2(self):
        b = Buffer(1024)
        self.assertEqual(0, b.position)
        self.assertEqual(1024, b.limit)                
        self.assertEqual('\0' * 10, b.read_bytes(10))
        b.clear()
        b.flip()
        #try read string past limit
        try:
            b.read_bytes(10)
            self.fail("expected buffer underflow")
        except BufferUnderflowError:
            pass #expected
     
    def testReadBytesUntil(self):
        b = Buffer(1024)
        b.write_bytes('hello world!')
        b.flip()
        self.assertEquals('hello', b.read_bytes_until(ord(' ')))
        self.assertEquals('world', b.read_bytes_until(ord('!')))

        b = Buffer(1024)
        b.write_bytes('hello world!\nTest\n\nPiet\nKlaas\n')
        b.flip()
        self.assertEquals('hello world!', b.read_bytes_until(10))
        self.assertEquals('Test', b.read_bytes_until(10))
        self.assertEquals('', b.read_bytes_until(10))
        self.assertEquals('Piet', b.read_bytes_until(10))
        self.assertEquals('Klaas', b.read_bytes_until(10))
        try:
            b.read_bytes_until(10)
            self.fail("expected buffer underflow")
        except BufferUnderflowError:
            pass
        

    def testReadLine(self):
        b = Buffer(1024)
        
        b.clear()
        b.write_bytes('hello world!\n')
        b.flip()
        self.assertEquals('hello world!', b.read_line())
        self.assertEquals(b.position, b.limit)

        b.clear()
        b.write_bytes('hello world!\r\n')
        b.flip()
        self.assertEquals('hello world!', b.read_line())
        self.assertEquals(b.position, b.limit)

        b.clear()
        b.write_bytes('hello world!\r')
        b.flip()
        try:
            b.read_line()
            self.fail('expected BufferUnderFlow')
        except BufferUnderflowError:
            pass
        

        b.clear()
        b.write_bytes('hello world!\n')
        b.flip()
        self.assertEquals('hello world!\n', b.read_line(True))
        self.assertEquals(b.position, b.limit)

        b.clear()
        b.write_bytes('hello world!\r\n')
        b.flip()
        self.assertEquals('hello world!\r\n', b.read_line(True))
        self.assertEquals(b.position, b.limit)

        b.clear()
        b.write_bytes('hello world!\r')
        b.flip()
        try:
            b.read_line(True)
            self.fail('expected BufferUnderFlow')
        except BufferUnderflowError:
            pass
        
        b.clear()
        b.write_bytes('line1\nline2\r\nline3\nline4\r\n')
        b.flip()
        self.assertEquals('line1', b.read_line())
        self.assertEquals('line2', b.read_line())
        self.assertEquals('line3', b.read_line())
        self.assertEquals('line4', b.read_line())
        self.assertEquals(b.position, b.limit)
        
        b.clear()
        b.write_bytes('line1\nline2\r\nline3\nline4\r\n')
        b.flip()
        self.assertEquals('line1\n', b.read_line(True))
        self.assertEquals('line2\r\n', b.read_line(True))
        self.assertEquals('line3\n', b.read_line(True))
        self.assertEquals('line4\r\n', b.read_line(True))
        self.assertEquals(b.position, b.limit)
        
    def testBytes(self):
        #test that we can write all bytes into buffer
        #and get them back without any encoding/decoding stuff going on

        #a string with all possible bytes
        B = ''.join([chr(i) for i in range(256)])
        
        b = Buffer(1024)
        b.write_bytes(B)
        b.flip()
        
        self.assertEqual(256, b.limit)
        x = b.read_bytes(256)

        self.assertEquals(B, x)

    def testCopy(self):
        b = Buffer(1024)
        c = Buffer(1024)
        
        try:
            c.copy(b, 0, 0, -1)
            self.fail()
        except BufferInvalidArgumentError:
            pass

        try:
            c.copy(b, 0, 0, 1025)
            self.fail()
        except BufferInvalidArgumentError:
            pass

        try:
            c.copy(b, 1, 0, 1024)
            self.fail()
        except BufferInvalidArgumentError:
            pass

        try:
            c.copy(b, 0, 1, 1024)
            self.fail()
        except BufferInvalidArgumentError:
            pass

        b[0] = 1
        b[10] = 2
        b[1023] = 3
        c.copy(b, 0, 0, 1024)
        self.assertEquals(1, c[0])
        self.assertEquals(2, c[10])
        self.assertEquals(3, c[1023])
        
        c.copy(b, 0, 10, 20)
        self.assertEquals(1, c[10])
        self.assertEquals(2, c[20])
        self.assertEquals(3, c[1023])







if __name__ == '__main__':
    unittest.main(timeout = 10)













########NEW FILE########
__FILENAME__ = testbuffered
from concurrence import unittest
from concurrence.io import IOStream
from concurrence.io.buffered import Buffer, BufferedReader

class TestStream(IOStream):
    def __init__(self, s, chunk_size = 4):
        self.s = s
        self.chunk_size = chunk_size
        
    def read(self, buffer, timeout = -1.0):

        if not self.s:
            raise EOFError("while reading")

        n = min(self.chunk_size, buffer.remaining, len(self.s))

        buffer.write_bytes(self.s[:n])

        self.s = self.s[n:]

        return n

class TestBuffered(unittest.TestCase):
    def testCompatibleReadLines(self):
        
        for chunk_size in [4, 8, 16, 32, 64, 128]:
            b = Buffer(1024)

            test_stream = TestStream('hello world!\nTest\n\nPiet\nKlaas\nPietBlaat\n', chunk_size = chunk_size)
            
            f = BufferedReader(test_stream, b).file()
            
            lines = f.readlines()

            self.assertEquals('hello world!\n', lines.next())
            self.assertEquals('Test\n', lines.next())
            self.assertEquals('\n', lines.next())
            self.assertEquals('Piet\n', lines.next())
            self.assertEquals('Klaas\n', lines.next())
            self.assertEquals('PietBlaat\n', lines.next())
            self.assertEquals('', lines.next())

        
            #line without newline at end of buffer, should report without newline
            test_stream = TestStream('hello world!\nTest', chunk_size = chunk_size)
            f = BufferedReader(test_stream, b).file()
            lines = f.readlines()
            self.assertEquals('hello world!\n', lines.next())
            self.assertEquals('Test', lines.next())
            self.assertEquals('', lines.next())
        
    def testCompatibleRead(self):
        import cStringIO

        for buffer_size in [1, 2, 4, 8, 16, 32, 1024]:
            for chunk_size in [1, 2, 4, 8, 16]:
                def test_stream(s):
                    b = Buffer(buffer_size)
                    f = BufferedReader(TestStream(s, chunk_size = chunk_size), b).file()
                    i = cStringIO.StringIO(s)
                    return (i, f)

                i, f = test_stream('piet')

                self.assertEquals(i.read(8), f.read(8))
                self.assertEquals(i.read(8), f.read(8))  
                    
                i, f = test_stream('piet')
                
                self.assertEquals(i.read(2), f.read(2))
                self.assertEquals(i.read(2), f.read(2))
                self.assertEquals(i.read(4), f.read(4))
                self.assertEquals(i.read(4), f.read(4))

                i, f = test_stream('piet')
                
                self.assertEquals(i.read(2), f.read(2))
                self.assertEquals(i.read(4), f.read(4))

                for x in range(30):
                    i, f = test_stream('piet klaas aap' * x)
                    self.assertEquals(i.read(), f.read())

    
if __name__ == '__main__':
    unittest.main(timeout = 10)



########NEW FILE########
__FILENAME__ = testcore

import logging
import time
import sys

from concurrence import unittest, Tasklet, Channel, TimeoutError, TaskletError, JoinError, Message

class TestTasklet(unittest.TestCase):
    def testSleep(self):
        start = time.time()
        Tasklet.sleep(1.0)
        end = time.time()
        
        self.assertAlmostEqual(1.0, end - start, places = 1)
        
    def testJoinResult(self):
        """test normal join and checks that parent will get child result"""
        def child(i):
            return i

        ch1 = Tasklet.new(child)(1)
        ch2 = Tasklet.new(child)(2)  

        self.assertEquals(1, Tasklet.join(ch1))
        self.assertEquals(2, Tasklet.join(ch2))

    def testJoinKill(self):
        """tests that we can join a tasklet that gets killed"""
        def child(i):   
            Tasklet.sleep(1000)
        
        def killer(t):
            t.kill()

        ch1 = Tasklet.new(child)(1)
        ch2 = Tasklet.later(1, killer)(ch1)  

        try:
            Tasklet.join(ch1)
            self.fail('expected join error')
        except JoinError, e:
            self.assertEquals(ch1, e.tasklet) 
            self.assertTrue(isinstance(e.cause, TaskletExit))
        

    def testJoinAfterExit(self):
        def child(i):
            return i
 
        ch1 = Tasklet.new(child)(1)
        ch2 = Tasklet.new(child)(2)  

        Tasklet.yield_() #make sure children are run

        self.assertEquals(1, Tasklet.join(ch1))
        self.assertEquals(2, Tasklet.join(ch2))

    def testJoinTimeout(self):
        """test join where child does not exit within timeout"""
        def child():
            Tasklet.sleep(10.0)

        ch = Tasklet.new(child)()

        try:
            Tasklet.join(ch, 1.0)
            self.fail('expected timeout error')
        except TimeoutError:
            pass #ok
        except:
            self.fail('expected timeout error')
        finally:
            ch.kill()
            
    def testJoinException(self):
        """test join where child raised exception, checks that parent receives exception"""

        def sub2():
            raise Exception("test_exc")

        def sub1():
            sub2()

        def child():
            sub1()

        ch = Tasklet.new(child)()
        try:
            Tasklet.join(ch)
            self.fail('expected join error')
        except JoinError, e:
            self.assertEquals(ch, e.tasklet)
            self.assertTrue(isinstance(e.cause, Exception))
            self.assertEqual('test_exc', str(e.cause))
        except:
            self.fail('expected tasklet error')
        
    def testJoinAll(self):
        
        def sub0():
            raise Exception("a proper exc")
        
        def sub1():
            return 1
        
        def sub2():
            return 2
        
        def sub3():
            raise Exception("test exc")
        
        subs = [Tasklet.new(sub)() for sub in [sub0, sub1, sub2, sub3]]
        results = Tasklet.join_all(subs)
        
        self.assertTrue(isinstance(results[0], JoinError))
        self.assertTrue(isinstance(results[0].cause, Exception))
        self.assertEquals("a proper exc", str(results[0].cause), Exception)
        self.assertEquals(1, results[1])
        self.assertEquals(2, results[2])

        self.assertTrue(isinstance(results[3], JoinError))
        self.assertTrue(isinstance(results[3].cause, Exception))
        self.assertEquals("test exc", str(results[3].cause), Exception)

        
    def testJoinChildren(self):
        
        def t():
            return 1
        
        for i in range(4):
            Tasklet.new(t)()
        
        self.assertEquals(4, len(Tasklet.current().children()))
            
        result = Tasklet.join_children()
        
        self.assertEquals([1,1,1,1], result)
        
    def testTree(self):
        
        def child(prefix, level, i):
            if level < 2:
                for j in range(2):
                    name = prefix + str(j)
                    Tasklet.new(child, name = name)(name, level + 1, j)  
            Tasklet.sleep(2)

        Tasklet.new(child, 'child')('child', 0, 0)

        Tasklet.sleep(1)

        #for task, level in Tasklet.current().tree():
        #    print '\t' * level, task.name, level
            
        flattened = set([(task.name, level) for (task, level) in Tasklet.current().tree()][1:])
        
        self.assertEquals(set([('child', 1), ('child0', 2), ('child00', 3), ('child01', 3), 
                           ('child1', 2), ('child10', 3), ('child11', 3)]), flattened)

    def testInterval(self):
        
        count = []
        def ival():
            count.append(1) 
        
        #test non immediate    
        ival_task = Tasklet.interval(1.0, ival, False)()
            
        try:
            Tasklet.join(ival_task, 3.0)
        except TimeoutError:
            #expect 2 counts, because interval started after 1 second
            self.assertEquals(2, len(count))
        except:
            self.fail('expected timeout, got %s' % sys.exc_type)
        finally:
            ival_task.kill()
            
        #test immediate
        count = []
        ival_task = Tasklet.interval(1.0, ival, True)()
            
        try:
            Tasklet.join(ival_task, 3.0)
        except TimeoutError:
            #expect 3 counts, because interval started immediately
            self.assertEquals(3, len(count))
        except:
            self.fail('expected timeout')
        finally:
            ival_task.kill()
        
    def testLoop(self):
        recvd = []
        def looper(channel):
            res = channel.receive()
            if res == None:
                raise Exception("some exception")
            else:
                recvd.append(res)
            
        looper_channel = Channel()
        looper_task = Tasklet.loop(looper)(looper_channel)

        for i in range(10):
            looper_channel.send(i)
        self.assertEqual(range(10), recvd)

        self.assertEqual(-1, looper_channel.balance)

        self.assertTrue(looper_task.alive)
        
        looper_channel.send(None) #will trigger exception loop
        
        #must still be working
        recvd = []
        for i in range(10):
            looper_channel.send(i)
        self.assertEqual(range(10), recvd)

        self.assertEqual(-1, looper_channel.balance)
        
        looper_task.kill()

        self.assertEqual(0, looper_channel.balance)
        
        #assert that looper exitted, because it is not receiving anymore
        self.assertFalse(looper_channel.has_receiver())

        self.assertFalse(looper_task.alive)

    def testYield(self):
        
        l = []

        def child(c):
            for i in range(5):
                l.append((c, i))
                Tasklet.yield_()

        ch1 = Tasklet.new(child)(1)
        ch2 = Tasklet.new(child)(2)

        Tasklet.join_all([ch1, ch2])

        self.assertEquals([(1, 0), (2, 0), (1, 1), (2, 1), (1, 2), (2, 2), (1, 3), (2, 3), (1, 4), (2, 4)], l)

    def testMessageSend(self):
        
        class MSG_PONG(Message): pass
        class MSG_PING(Message): pass

        def c(parent):
            for msg, args, kwargs in Tasklet.receive():     
                if msg.match(MSG_PING):
                    self.assertEquals((10, ), args)
                    MSG_PONG.send(parent)(20)

        parent = Tasklet.current()
        child = Tasklet.new(c)(parent)
        i = 0
        MSG_PING.send(child)(10)
        for msg, args, kwargs in Tasklet.receive():
            if msg.match(MSG_PONG):
                self.assertEquals((20, ), args)
                i += 1
                if i > 5: break
                MSG_PING.send(child)(10)

        self.assertEquals(6, i)

        try:
            start = time.time()
            for msg, args, kwargs in Tasklet.receive(2.0):
                self.fail('expected timeout error')            
        except TimeoutError:
            end = time.time()
            self.assertAlmostEqual(2.0, end - start, places = 1)

        child.kill()
        
        
    def testMessageCall(self):
        
        class MSG_TEST_SUM(Message): pass
        class MSG_TEST_MAX(Message): pass
        class MSG_TEST_SLEEP(Message): pass

        
        def c():
            for msg, args, kwargs in Tasklet.receive():
                if msg.match(MSG_TEST_SUM):
                    msg.reply(sum(args))
                elif msg.match(MSG_TEST_MAX):
                    msg.reply(max(args))
                elif msg.match(MSG_TEST_SLEEP):     
                    Tasklet.sleep(args[0])
                    msg.reply(True)
                
        child = Tasklet.new(c)()
        
        self.assertEquals(60, MSG_TEST_SUM.call(child)(10, 20, 30))
        self.assertEquals(30, MSG_TEST_MAX.call(child)(10, 20, 30))
        
        self.assertEquals(True, MSG_TEST_SLEEP.call(child)(1))

        try:
            MSG_TEST_SLEEP.call(child, timeout = 1)(2)
            self.fail("expected timeout")
        except TimeoutError:
            pass #expected
        child.kill()
        
class TestChannel(unittest.TestCase):
    
    def testSendRecv(self):
        """test simple send and receive on a channel"""
        def sender(channel):
            for i in range(3):
                channel.send(i)
        
        def receiver(channel):
            while True:
                recvd.append(channel.receive())
        
        recvd = []
                
        test_channel = Channel()
        
        send_task = Tasklet.new(sender)(test_channel)
        recv_task = Tasklet.new(receiver)(test_channel)

        Tasklet.join(send_task)
        
        self.assertEquals([0,1,2], recvd)
        
        recv_task.kill()
        
    def testRecvTimeout(self):
        
        #receive within timeout
        test_channel = Channel()
        t1 = Tasklet.later(1.0, test_channel.send)(10)
        try:            
            self.assertEqual(10, test_channel.receive(2.0))
        except TimeoutError:
            self.fail('did not expect timeout')
        finally:
            t1.kill()
        
        #receive with timeout
        test_channel = Channel()
        t1 = Tasklet.later(2.0, test_channel.send)(10)
        try:            
            self.assertEqual(10, test_channel.receive(1.0))
            self.fail('expected timeout')
        except TimeoutError:
            pass #expected
        finally:
            t1.kill()
            
    def testSendTimeout(self):
        #send within timeout

        test_channel = Channel()
        tl = Tasklet.later(1.0, test_channel.receive)()
        try:            
            test_channel.send(10, 2.0)
        except TimeoutError:
            self.fail('did not expect timeout')
        finally:
            tl.kill()
        
        #send with timeout
        test_channel = Channel()
        tl = Tasklet.later(2.0, test_channel.receive)()
        try:            
            test_channel.send(10, 1.0)
            self.fail('expected timeout')
        except TimeoutError:
            pass #expected
        finally:
            tl.kill()
            
        
    def testHasReceiver(self):
        
        test_channel = Channel()
        
        def receiver():
            test_channel.receive()
        
        self.assertEquals(False, test_channel.has_receiver())
        
        r = Tasklet.new(receiver)()
        
        Tasklet.sleep(1.0)
        
        self.assertEquals(True, test_channel.has_receiver())
        
        r.kill()
        
        Tasklet.sleep(1.0)
        
        self.assertEquals(False, test_channel.has_receiver())
        
if __name__ == '__main__':
    unittest.main(timeout = 100.0)

########NEW FILE########
__FILENAME__ = testdeque

import time

from concurrence import dispatch, Tasklet, TimeoutError, unittest
from concurrence.containers.deque import Deque

class TestDeque(unittest.TestCase):
    def testNonBlock(self):
        d = Deque()
        d.append(10)
        d.append(20)
        self.assertEqual(10, d.popleft())
        self.assertEqual(20, d.popleft())

        d = Deque()
        d.append(10)
        d.append(20)
        self.assertEqual(20, d.pop())
        self.assertEqual(10, d.pop())
        
    def testBlock(self):
        d = Deque()
        Tasklet.later(1.0, d.append)(20)
        s = time.time()
        #should block on pop
        self.assertEquals(20, d.pop(True))
        e = time.time()
        self.assertTrue((e - s) > 1.0)
        
    def testBlock2(self):
        d = Deque()
        Tasklet.later(0.5, d.append)(10)
        Tasklet.later(1.0, d.append)(20)
        Tasklet.sleep(1.5)
        s = time.time()
        #should not block
        self.assertEquals(20, d.pop(True))
        self.assertEquals(10, d.pop(True))
        e = time.time()
        self.assertAlmostEqual(0.0, (e - s), places = 1)
        
    def testBlockTimeout(self):
        d = Deque()
        s = time.time()
        try:
            d.pop(True, 2.0)
            self.fail("expected timeout")
        except TimeoutError:
            pass
        e = time.time()
        self.assertAlmostEqual(2.0, (e - s), places = 1)
        
if __name__ == '__main__':
    unittest.main(timeout = 10.0)

########NEW FILE########
__FILENAME__ = testdequedict
import unittest

from concurrence.containers.dequedict import DequeDict

class DequeDictTest(unittest.TestCase):
    def testDequeDict(self):        
        m = DequeDict()
        m.appendleft("piet", 10)
        self.assertEquals(1, len(m))
        m.appendleft("klaas", 20)
        self.assertEquals(2, len(m))
        self.assertTrue("piet" in m)
        self.assertTrue("klaas" in m)
        self.assertFalse("jan" in m)
        self.assertTrue("jan" not in m)
        i = m.iteritemsright()
        self.assertEquals(("piet", 10), i.next())
        self.assertEquals(("klaas", 20), i.next())
        m.movehead("piet")
        i = m.iteritemsright()
        self.assertEquals(("klaas", 20), i.next())
        self.assertEquals(("piet", 10), i.next())
        try: 
            i.next()
            self.fail("expected end of iter")
        except:
            pass
        self.assertEquals(m["piet"], 10)
        del m["piet"]
        self.assertEquals(1, len(m))
        self.assertTrue("piet" not in m)
        self.assertEquals(("klaas", 20), m.pop())
        self.assertEquals(0, len(m))
        
    def testPickle(self):
        m = DequeDict()
        N = 10
        for i in range(N):
            m.append(i, i)
        p1 = m.items()
        import pickle
        s = pickle.dumps(m)
        x = pickle.loads(s)
        p2 = x.items()
        self.assertEquals(p1, p2)
        self.assertEquals(m.d.keys(), x.d.keys())

if __name__ == '__main__':
    unittest.main()


########NEW FILE########
__FILENAME__ = testhttp

import logging
import time

from concurrence import Tasklet, TimeoutError, unittest
from concurrence.http import HTTPError, WSGIServer, HTTPConnection
from concurrence.wsgi import WSGISimpleRouter, WSGISimpleMessage
from concurrence.io import Buffer, Socket

SERVER_PORT = 8080

class TestHTTP(unittest.TestCase):
    def setUp(self):
        application = WSGISimpleRouter()
        for i in range(10):
            application.map('/hello/%d' % i, WSGISimpleMessage("Hello World %d" % i))

        class WSGISleeper(WSGISimpleMessage):
            def __call__(self, environ, start_response):
                sleep_seconds = int(environ['QUERY_STRING'])
                Tasklet.sleep(sleep_seconds)
                self.response = 'slept %d' % sleep_seconds
                return WSGISimpleMessage.__call__(self, environ, start_response)

        class WSGIPOSTSaver(WSGISimpleMessage):
            def __call__(self, environ, start_response):
                self.environ = environ
                f = environ['wsgi.input']
                self.body = f.read(int(environ['HTTP_CONTENT_LENGTH']))
                return WSGISimpleMessage.__call__(self, environ, start_response)                
            
        self.saver = WSGIPOSTSaver('ok')
        application.map('/sleep', WSGISleeper('zzz...'))
        application.map('/post', self.saver)

        self.server = WSGIServer(application)
        self.socket_server = self.server.serve(('0.0.0.0', SERVER_PORT))

    def tearDown(self):
        self.socket_server.close()
        self.server = None

    def testSimple(self):
        cnn = HTTPConnection()
        cnn.connect(('localhost', SERVER_PORT))

        request = cnn.get('/hello/1')
        response = cnn.perform(request)
        self.assertEquals(200, response.status_code)
        chunks = list(response.iter)
        self.assertEquals('Hello World 1', chunks[0])

        request = cnn.get('/hello/2')
        response = cnn.perform(request)
        self.assertEquals(200, response.status_code)
        body = response.body
        self.assertEquals('Hello World 2', body)

        request = cnn.get('/xxx')
        response = cnn.perform(request)
        self.assertEquals(404, response.status_code)
        chunks = list(response)
        self.assertEquals('Not Found', chunks[0])

        cnn.close()            

    def testInterleaved1(self):
        cnn = HTTPConnection()
        cnn.connect(('localhost', SERVER_PORT))

        cnn.send(cnn.get('/hello/1'))
        cnn.send(cnn.get('/hello/2'))

        response = cnn.receive()
        self.assertEquals(200, response.status_code)
        chunks = list(response)
        self.assertEquals('Hello World 1', chunks[0])

        response = cnn.receive()
        self.assertEquals(200, response.status_code)
        chunks = list(response)
        self.assertEquals('Hello World 2', chunks[0])

        cnn.close()            

    def testInterleaved3(self):
        """tests that http client and server really support pipelining"""
        cnn = HTTPConnection()
        cnn.connect(('localhost', SERVER_PORT))

        #we do 2 requests that should take 2 seconds to complete each.
        #if server/client pipelining was not working, fetching the 2 urls
        #would take 4 seconds on a single connection
        #if pipelining works, it should take just 2 seconds

        start = time.time()

        cnn.send(cnn.get('/sleep?2'))
        cnn.send(cnn.get('/sleep?2'))

        list(cnn.receive())
        list(cnn.receive())

        end = time.time()

        self.assertAlmostEqual(2, end - start, places = 1)
        
        cnn.close()

    def testInterleaved4(self):
        """tests that http server returns responses in correct order"""
        cnn = HTTPConnection()
        cnn.connect(('localhost', SERVER_PORT))

        #we do 2 requests that should take 2 seconds to complete each.
        #if server/client pipelining was not working, fetching the 2 urls
        #would take 4 seconds on a single connection
        #if pipelining works, it should take just 2 seconds

        start = time.time()

        cnn.send(cnn.get('/sleep?3'))
        cnn.send(cnn.get('/sleep?1'))
        response1 = cnn.receive()
        response2 = cnn.receive()

        #we expect response1 to be returned first, because it was made first
        #eventhough it takes longer 
        self.assertEquals('slept 3', response1.body)
        self.assertEquals('slept 1', response2.body)       

        end = time.time()

        self.assertAlmostEqual(3, end - start, places = 1)
        
        cnn.close()

    def fetch10(self, s, uri):

        b = Buffer(1024)
        b.clear()
        b.write_bytes("GET %s HTTP/1.0\r\n" % uri)
        b.write_bytes("\r\n")
        b.flip()
        s.write(b)
        
        b.clear()
        s.read(b)
        b.flip()
        return b.read_bytes(b.remaining)

    def testHTTP10(self):
        s = Socket.connect(('localhost', SERVER_PORT))
        r1 = self.fetch10(s, '/hello/1')
        r2 = self.fetch10(s, '/hello/2')
        self.assertEquals('', r2)

    def testHTTPReadTimeout(self):
        self.server.read_timeout = 2
    
        cnn = HTTPConnection()

        try:
            cnn.connect(('localhost', SERVER_PORT))

            Tasklet.sleep(1)

            response = cnn.perform(cnn.get('/hello/1'))
            
            self.assertEquals('HTTP/1.1 200 OK', response.status)
            self.assertEquals('Hello World 1', response.body)

            Tasklet.sleep(3)

            try:        
                list(cnn.perform(cnn.get('/hello/2')))
                self.fail('expected eof')
            except HTTPError, e:
            	pass
	    except:
                self.fail('expected http errror')       
        finally:
            cnn.close()

    def testHTTPPost(self):
        cnn = HTTPConnection()

        try:
            cnn.connect(('localhost', SERVER_PORT))
            for i in [1, 2, 4, 8, 16, 32, 100, 1000, 10000, 100000, 200000]:
                post_data = 'test post data' * i
                request = cnn.post('/post', post_data, host = 'testhost.nl')
                response = cnn.perform(request)
                self.assertEquals('ok', response.body)
                self.assertTrue('HTTP_CONTENT_LENGTH' in self.saver.environ)
                self.assertEquals(len(post_data), int(self.saver.environ['HTTP_CONTENT_LENGTH']))
                self.assertEquals(post_data, self.saver.body)
                self.assertEquals('testhost.nl', self.saver.environ['HTTP_HOST'])
        finally:
            cnn.close()        
        
if __name__ == '__main__':
    unittest.main(timeout = 100.0)


########NEW FILE########
__FILENAME__ = testio

from concurrence import unittest, dispatch, TimeoutError, Tasklet
from concurrence.core import FileDescriptorEvent
from concurrence.io import Socket


class TestIO(unittest.TestCase):
    def testReadableWritableProperties(self):
        
        socket = Socket.new()
        writable = socket.writable
        self.assertTrue(isinstance(writable, FileDescriptorEvent))
        readable = socket.readable
        self.assertTrue(isinstance(readable, FileDescriptorEvent))

        socket.readable = None

        #TODO test why is socket.readable event not deallocated immediatly?

if __name__ == '__main__':
    unittest.main(timeout = 10.0)

########NEW FILE########
__FILENAME__ = testlocal
from __future__ import with_statement

import logging
import time

from concurrence import unittest, Tasklet, TaskLocal, TaskInstance

class TestTaskLocal(unittest.TestCase):
    """test tasklet local storage"""
    def testSingleTask(self):
        
        local = TaskLocal()

        local.piet = 10
        
        self.assertEquals(10, local.piet)
        
        try:        
            x = local.klaas
            self.fail('expected attribute error')
        except AttributeError:
            pass
        
        local.piet = 20
        
        self.assertEquals(True, hasattr(local, 'piet'))
        self.assertEquals(False, hasattr(local, 'klaas'))
        self.assertEquals(20, local.piet)
        
        del local.piet
        
        self.assertEquals(False, hasattr(local, 'piet'))
        
        try:        
            x = local.piet
            self.fail('expected attribute error')
        except AttributeError:
            pass
 
    def testMultiTask(self):
 
        local = TaskLocal()
        
        def t():
            local.piet = []
            for i in range(10):
                local.piet.append(i)
                Tasklet.yield_()
            self.assertEquals(range(10), local.piet)

        t1 = Tasklet.new(t)()
        t2 = Tasklet.new(t)()
        
        Tasklet.join_all([t1,t2])
        
        self.assertEquals(2, len(local._d.keys())) #the 2 tasks are sill around, so local keeps their values
        
        #check that values are gone from dict
        #when tasks are gone
        del t1
        del t2
        #we need to yield, because our 2 tasks were suspended by the join
        #yield will run the scheduler again, so our tasks can properly finish

        #the only strange thing is we need 2 yields for python, stackless requires just 1
        Tasklet.yield_()
        Tasklet.yield_()

        self.assertEquals([], local._d.keys())
            
    def testRecursive(self):
        
        #non-recursive
        local = TaskLocal()
        
        local.piet = 20
        
        def t():
            try:
                local.piet
                self.fail('expected attr error')
            except AttributeError:
                pass
        
        Tasklet.join(Tasklet.new(t)())
        
        #recursive
        local = TaskLocal(True)
        
        local.piet = 30
        
        def t():
            self.assertEquals(30, local.piet)
        
        Tasklet.join(Tasklet.new(t)())
        

class Adder(object):
    def __init__(self, x):
        self.x = x
        
    def sum(self, y):
        return self.x + y 
    
class TestTaskInstance(unittest.TestCase):

    def testTaskInstance(self):
        
        AdderInstance = TaskInstance(True)

        try:
            AdderInstance.sum(10)
            self.fail('expected attribute error')
        except AttributeError:
            pass
        
        def t():
            return AdderInstance.sum(20)
            
        with AdderInstance.set(Adder(10)):
            self.assertEquals(30, AdderInstance.sum(20))
            #check that child task can also find it
            self.assertEquals(30, Tasklet.join(Tasklet.new(t)()))

        #should have been unset
        try:
            AdderInstance.sum(10)
            self.fail('expected attribute error')
        except AttributeError:
            pass

    def testTaskInstance2(self):

        AdderInstance = TaskInstance(True)
        
        with AdderInstance.set(Adder(10)):
            
            self.assertEquals(30, AdderInstance.sum(20))
            
            #now start 2 child tasks
            def t():
                self.assertEquals(30, AdderInstance.sum(20)) #expect to find parents instance
                #now set my own instance
                with AdderInstance.set(Adder(20)):
                    self.assertEquals(40, AdderInstance.sum(20))
                #now it must be unset, and we will find parents instance instead
                self.assertEquals(30, AdderInstance.sum(20))
                
            t1 = Tasklet.new(t)()
            t2 = Tasklet.new(t)()
            Tasklet.join_all([t1, t2])
            
            self.assertEquals(30, AdderInstance.sum(20))
        
if __name__ == '__main__':
    unittest.main()        

########NEW FILE########
__FILENAME__ = testmemcache
import os

from concurrence import unittest, Tasklet
from concurrence.memcache.client import MemcacheNode, MemcacheError

class MemcacheTest(unittest.TestCase):
    def testNodeBasic(self):
        
        node = MemcacheNode()
        node.connect(('127.0.0.1', 11211))

        node.set('test1', '12345')
        node.set('test2', '67890')

        self.assertEquals('12345', node.get('test1'))
        self.assertEquals(None, node.get('test3'))
        self.assertEquals({'test1': '12345', 'test2': '67890'}, node.get(['test1', 'test2', 'test3']))

        #update test2
        node.set('test2', 'hello world!')

        self.assertEquals({'test1': '12345', 'test2': 'hello world!'}, node.get(['test1', 'test2', 'test3']))
       
        #update to unicode type
        node.set('test2', u'C\xe9line')
        self.assertEquals(u'C\xe9line', node.get('test2'))

        #update to some other type
        node.set('test2', {'piet': 'blaat', 10: 20})
        self.assertEquals({'piet': 'blaat', 10: 20}, node.get('test2'))

        node.close()
        
if __name__ == '__main__':
    unittest.main(timeout = 60)

########NEW FILE########
__FILENAME__ = testmysql
# -*- coding: latin1 -*-
from __future__ import with_statement

import time

from concurrence import dispatch, unittest, Tasklet
from concurrence.database.mysql import client, dbapi, PacketReadError

DB_HOST = 'localhost'
DB_USER = 'concurrence_test'
DB_PASSWD = 'concurrence_test'
DB_DB = 'concurrence_test'

class TestMySQL(unittest.TestCase):
    
    def testMySQLClient(self):
        cnn = client.connect(host = DB_HOST, user = DB_USER, 
                             passwd = DB_PASSWD, db = DB_DB)
        
        rs = cnn.query("select 1")
        
        self.assertEqual([('1',)], list(rs))
        
        rs.close()
        cnn.close()

    def testFetchUnicode(self):
        cnn = client.connect(host = DB_HOST, user = DB_USER, 
                             passwd = DB_PASSWD, db = DB_DB)
        
        cnn.query("truncate tbltest")

        for i in range(10):
            self.assertEquals((1, 0), cnn.query("insert into tbltest (test_id, test_string) values (%d, 'test%d')" % (i, i)))

        rs = cnn.query("select test_string from tbltest where test_id = 1")
        s = list(rs)[0][0]
        self.assertTrue(type(s) == str)
        rs.close()
        
        cnn.set_charset('latin1')
        rs = cnn.query("select test_string from tbltest where test_id = 1")
        s = list(rs)[0][0]
        self.assertTrue(type(s) == unicode)        
        rs.close()
        
        cnn.close()
        
        
    def testMySQLClient2(self):
        cnn = client.connect(host = DB_HOST, user = DB_USER, 
                             passwd = DB_PASSWD, db = DB_DB)

        cnn.query("truncate tbltest")

        for i in range(10):
            self.assertEquals((1, 0), cnn.query("insert into tbltest (test_id, test_string) values (%d, 'test%d')" % (i, i)))

        rs = cnn.query("select test_id, test_string from tbltest")
        
        #trying to close it now would give an error, e.g. we always need to read
        #the result from the database otherwise connection would be in wrong stat
        try:
            rs.close()
            self.fail('expected exception')
        except client.ClientProgrammingError:
            pass
            
        for i, row in enumerate(rs):
            self.assertEquals((i, 'test%d' % i), row)

        rs.close()
        cnn.close()
        
    def testMySQLTimeout(self):
        cnn = client.connect(host = DB_HOST, user = DB_USER, 
                             passwd = DB_PASSWD, db = DB_DB)

        rs = cnn.query("select sleep(2)")
        list(rs)
        rs.close()
        
        from concurrence import TimeoutError
        from concurrence.timer import Timeout

        start = time.time()
        try:
            with Timeout.push(2.0):
                cnn.query("select sleep(4)")
                self.fail('expected timeout')
        except TimeoutError, e:
            end = time.time()
            self.assertAlmostEqual(2.0, end - start, places = 1)
        
        cnn.close()

    def testParallelQuery(self):

        def query(s):
            cnn = dbapi.connect(host = DB_HOST, user = DB_USER, 
                                passwd = DB_PASSWD, db = DB_DB)
            cur = cnn.cursor()
            cur.execute("select sleep(%d)" % s)
            cur.close()
            cnn.close()

        start = time.time()
        ch1 = Tasklet.new(query)(1)
        ch2 = Tasklet.new(query)(2)
        ch3 = Tasklet.new(query)(3)
        Tasklet.join_all([ch1, ch2, ch3])

        end = time.time()
        self.assertAlmostEqual(3.0, end - start, places = 1)

    def testMySQLDBAPI(self):
        
        cnn = dbapi.connect(host = DB_HOST, user = DB_USER, 
                            passwd = DB_PASSWD, db = DB_DB)
        
        cur = cnn.cursor()
        
        cur.execute("truncate tbltest")

        for i in range(10):
            cur.execute("insert into tbltest (test_id, test_string) values (%d, 'test%d')" % (i, i))

        cur.close()
        
        cur = cnn.cursor()
        
        cur.execute("select test_id, test_string from tbltest")
        
        self.assertEquals((0, 'test0'), cur.fetchone())
        
        #check that fetchall gets the remainder
        self.assertEquals([(1, 'test1'), (2, 'test2'), (3, 'test3'), (4, 'test4'), (5, 'test5'), (6, 'test6'), (7, 'test7'), (8, 'test8'), (9, 'test9')], cur.fetchall())

        #another query on the same cursor should work
        cur.execute("select test_id, test_string from tbltest")
        
        #fetch some but not all
        self.assertEquals((0, 'test0'), cur.fetchone())
        self.assertEquals((1, 'test1'), cur.fetchone())
        self.assertEquals((2, 'test2'), cur.fetchone())

        #close whould work even with half read resultset
        cur.close()

        #this should not work, cursor was closed
        try:
            cur.execute("select * from tbltest")
            self.fail("expected exception")
        except dbapi.ProgrammingError:
            pass

    def testLargePackets(self):
        cnn = client.connect(host = DB_HOST, user = DB_USER, 
                             passwd = DB_PASSWD, db = DB_DB)
        
        
        cnn.query("truncate tbltest")
        
        c = cnn.buffer.capacity
        
        blob = '0123456789'
        while 1:
            cnn.query("insert into tbltest (test_id, test_blob) values (%d, '%s')" % (len(blob), blob))
            if len(blob) > (c * 2): break
            blob = blob * 2
            
        rs = cnn.query("select test_id, test_blob from tbltest")
        for row in rs:
            self.assertEquals(row[0], len(row[1]))
            self.assertEquals(blob[:row[0]], row[1])
        rs.close()

        #reread, second time, oversize packet is already present
        rs = cnn.query("select test_id, test_blob from tbltest")
        for row in rs:
            self.assertEquals(row[0], len(row[1]))
            self.assertEquals(blob[:row[0]], row[1])
        rs.close()
        cnn.close()

        #have a very low max packet size for oversize packets
        #and check that exception is thrown when trying to read larger packets
        from concurrence.database.mysql import _mysql
        _mysql.MAX_PACKET_SIZE = 1024 * 4

        cnn = client.connect(host = DB_HOST, user = DB_USER, 
                             passwd = DB_PASSWD, db = DB_DB)

        try:
            rs = cnn.query("select test_id, test_blob from tbltest")
            for row in rs:
                self.assertEquals(row[0], len(row[1]))
                self.assertEquals(blob[:row[0]], row[1])
            self.fail()
        except PacketReadError: 
            pass
        finally:
            try:
                rs.close()
            except:
                pass
            cnn.close()

    def testEscapeArgs(self):
        cnn = dbapi.connect(host = DB_HOST, user = DB_USER, 
                            passwd = DB_PASSWD, db = DB_DB)
        
        cur = cnn.cursor()
        
        cur.execute("truncate tbltest")
        
        cur.execute("insert into tbltest (test_id, test_string) values (%s, %s)", (1, 'piet'))
        cur.execute("insert into tbltest (test_id, test_string) values (%s, %s)", (2, 'klaas'))
        cur.execute("insert into tbltest (test_id, test_string) values (%s, %s)", (3, "pi'et"))
        
        #classic sql injection, would return all rows if no proper escaping is done
        cur.execute("select test_id, test_string from tbltest where test_string = %s", ("piet' OR 'a' = 'a",))
        self.assertEquals([], cur.fetchall()) #assert no rows are found
        
        #but we should still be able to find the piet with the apostrophe in its name
        cur.execute("select test_id, test_string from tbltest where test_string = %s", ("pi'et",))
        self.assertEquals([(3, "pi'et")], cur.fetchall())
        
        #also we should be able to insert and retrieve blob/string with all possible bytes transparently
        chars = ''.join([chr(i) for i in range(256)])
        #print repr(chars)
        
        cur.execute("insert into tbltest (test_id, test_string, test_blob) values (%s, %s, %s)", (4, chars, chars))

        cur.execute("select test_string, test_blob from tbltest where test_id = %s", (4,))
        #self.assertEquals([(chars, chars)], cur.fetchall())
        s, b  = cur.fetchall()[0]
        
        #test blob
        self.assertEquals(256, len(b))
        self.assertEquals(chars, b)

        #test string
        self.assertEquals(256, len(s))
        self.assertEquals(chars, s)

        cur.close()

        cnn.close()
        
        
    def testSelectUnicode(self):
        s = u"Cline"
        
        cnn = dbapi.connect(host = DB_HOST, user = DB_USER, 
                            passwd = DB_PASSWD, db = DB_DB, 
                            charset = 'latin-1', use_unicode = True)
        
        cur = cnn.cursor()

        cur.execute("truncate tbltest")
        cur.execute("insert into tbltest (test_id, test_string) values (%s, %s)", (1, 'piet'))
        cur.execute("insert into tbltest (test_id, test_string) values (%s, %s)", (2, s))
        cur.execute(u"insert into tbltest (test_id, test_string) values (%s, %s)", (3, s))
        
        cur.execute("select test_id, test_string from tbltest")
        
        result = cur.fetchall()
        
        self.assertEquals([(1, u'piet'), (2, u'C\xe9line'), (3, u'C\xe9line')], result)

        #test that we can still cleanly roundtrip a blob, (it should not be encoded if we pass
        #it as 'str' argument), eventhough we pass the qry itself as unicode
        blob = ''.join([chr(i) for i in range(256)])
        
        cur.execute(u"insert into tbltest (test_id, test_blob) values (%s, %s)", (4, blob))
        cur.execute("select test_blob from tbltest where test_id = %s", (4,))
        b2 = cur.fetchall()[0][0]
        self.assertEquals(str, type(b2))
        self.assertEquals(256, len(b2))
        self.assertEquals(blob, b2)
        
if __name__ == '__main__':
    unittest.main(timeout = 60)        
        
         
        

########NEW FILE########
__FILENAME__ = testpool
from __future__ import with_statement

import time

from concurrence import dispatch, unittest, Tasklet, TimeoutError
from concurrence.database.mysql import client
from concurrence.database.pool import Pool, NullPool

DB_HOST = 'localhost'
DB_USER = 'concurrence_test'
DB_PASSWD = 'concurrence_test'
DB_DB = 'concurrence_test'

DB_ARGS = {'host': DB_HOST, 'user': DB_USER, 'passwd': DB_PASSWD, 'db': DB_DB}

class TestPool(unittest.TestCase):
    

    def testConnect(self):

        pool = Pool(client, DB_ARGS, max_connections = 2, connect_timeout = 2)
        
        new, cnn1 = pool.connect()
        self.assertTrue(new)
        self.assertTrue(cnn1)
        self.assertEquals(1, pool.connection_count)
        
        new, cnn2 = pool.connect()
        self.assertTrue(new)
        self.assertTrue(cnn2)
        self.assertEquals(2, pool.connection_count)
        
        #check that pool implements Timeout
        #the pool is now empty, so when we try to connect it should timeout
        start = time.time()
        try:
            new, cnn = pool.connect()
            self.fail('expecting timeout')
        except TimeoutError:
            pass
        end = time.time()
        
        self.assertAlmostEqual(2.0, end - start, places = 1)
        
        self.assertEquals(0, pool.idle_connection_count)
        #return 1 cnn to the pool
        closed = pool.disconnect(cnn1)
        self.assertFalse(closed)
        self.assertEquals(1, pool.idle_connection_count)
        #and the other one
        closed = pool.disconnect(cnn2)
        self.assertFalse(closed)
        self.assertEquals(2, pool.idle_connection_count)
        
        
        #check out again
        new, cnn3 = pool.connect()
        self.assertFalse(new) #should not be new, but one of the idle's
        self.assertTrue(cnn3)
        self.assertEquals(cnn2, cnn3) #should have received the last (pool is a stack)
        self.assertEquals(2, pool.connection_count)
        self.assertEquals(1, pool.idle_connection_count)
        
        closed = pool.disconnect(cnn3, close = True)
        self.assertTrue(closed)
        self.assertEquals(1, pool.connection_count)
        self.assertEquals(1, pool.idle_connection_count)
        
    def xtestIdleDisconnect(self):
        
        pool = Pool(client, DB_ARGS, max_connections = 2, connect_timeout = 2)
        
        def qry():
            new, cnn = pool.connect()
            rs = cnn.query("SELECT 1")
            l = list(rs)
            rs.close()
            self.assertEquals([('1',)], l)
            #return it so it becomes idle
            closed = pool.disconnect(cnn)
            self.assertFalse(closed)
            self.assertEquals(1, pool.idle_connection_count)

        qry()
        
        Tasklet.sleep(20)
        
        qry()

    def testMaxAge(self):
        
        pool = Pool(client, DB_ARGS, max_connections = 2, connect_timeout = 2, max_connection_age = 2, 
                    max_connection_age_reaper_interval = 1)
        
        new, cnn1 = pool.connect()
        new, cnn2 = pool.connect()
        
        pool.disconnect(cnn1)
        
        self.assertTrue(cnn1.is_connected())
        self.assertTrue(cnn2.is_connected())
        
        Tasklet.sleep(3)
        
        #cnn1 was idle, should be disconnected now by old age reaper
        self.assertFalse(cnn1.is_connected())
        self.assertTrue(cnn2.is_connected())
        
        pool.disconnect(cnn2)
        #cnn2 should be closed on old age

        self.assertFalse(cnn1.is_connected())
        self.assertFalse(cnn2.is_connected())
        
    def testNullPool(self):
        
        pool = NullPool(client, DB_ARGS)
        
        new1, cnn1 = pool.connect()
        new2, cnn2 = pool.connect()
        
        self.assertTrue(new1)
        self.assertTrue(new2)
        
        self.assertTrue(cnn1.is_connected())
        self.assertTrue(cnn2.is_connected())
        
        pool.disconnect(cnn1, True)
        pool.disconnect(cnn2, False)

        #null pool always disconnects
        self.assertFalse(cnn1.is_connected())
        self.assertFalse(cnn2.is_connected())
        
        
if __name__ == '__main__':
    unittest.main(timeout = 60)        
        
         
        

########NEW FILE########
__FILENAME__ = testremote
from concurrence import unittest, Message, Tasklet, TimeoutError
from concurrence.remote import RemoteServer, RemoteTasklet, RemoteClient

import logging

#we need to define the msgs at the module level
#otherwise the remoting cannot use pickle to serialize them
class MSG_TEST(Message): pass
class MSG_SUM(Message): pass
class MSG_QUIT(Message): pass
class MSG_SLEEP(Message): pass

class RemoteTest(unittest.TestCase):

    def testRemote(self):
        
        client_results = []
        server_results = []

        def server():
            server_endpoint = None
            try:
                remote_server = RemoteServer()
                server_endpoint = remote_server.serve(('localhost', 9081))
                remote_server.register('testing123')
                for msg, args, kwargs in Tasklet.receive():
                    if msg.match(MSG_SUM):
                        server_results.append('s')
                        msg.reply(sum(args))
                    elif msg.match(MSG_TEST):
                        server_results.append('t')
                    elif msg.match(MSG_QUIT):
                        server_results.append('q')
                        break
                    elif msg.match(MSG_SLEEP):
                        server_results.append('sl')
                        Tasklet.sleep(args[0])
                        msg.reply(True)
            except Exception:
                logging.exception("")
                self.fail("")
            finally:
                if server_endpoint is not None: 
                    server_endpoint.close()
            
        def client():
            try:
                remote_client = RemoteClient()
                remote_client.connect(('localhost', 9081))
                remote_task = remote_client.lookup('testing123')
                self.assertFalse(remote_task is None)
                MSG_TEST.send(remote_task)(20, 30)
                MSG_TEST.send(remote_task)(30, 40)
                client_results.append(MSG_SUM.call(remote_task)(10, 20, 30))
                client_results.append(MSG_SUM.call(remote_task)(10, 20, 30))
                MSG_TEST.send(remote_task)(20, 30)
                MSG_TEST.send(remote_task)(30, 40)

                MSG_SLEEP.call(remote_task)(1)

                try:
                    MSG_SLEEP.call(remote_task, timeout = 1)(2)
                    self.fail("expected timeout")
                except TimeoutError:
                    pass #expected

                MSG_QUIT.send(remote_task)()
                Tasklet.sleep(2)
                remote_client.close()
            except Exception:
                logging.exception("")
                self.fail("")
        
        server_task = Tasklet.new(server)()
        client_task = Tasklet.new(client)()

        Tasklet.join_children()
        
        self.assertEquals([60,60], client_results)
        self.assertEquals(['t', 't', 's', 's', 't', 't', 'sl', 'sl', 'q'], server_results)




        
if __name__ == '__main__':
    unittest.main(timeout = 5)

########NEW FILE########
__FILENAME__ = testreque
from concurrence import dispatch, unittest
from concurrence.containers.reque import ReorderQueue

class TestReorderQueue(unittest.TestCase):
    def testRequeue(self):
        
        reque = ReorderQueue()
        
        for request in range(10):
            reque.start(request)

        for request, response in reque.finish(1, 'a'):
            self.fail("did not expect any finished request, response")
            
        for request, response in reque.finish(2, 'b'):
            self.fail("did not expect any finished request, response")

        for request, response in reque.finish(3, 'c'):
            self.fail("did not expect any finished request, response")

        finished = []
        for request, response in reque.finish(0, 'zero'):
            finished.append((request, response))
        
        self.assertEquals([(0, 'zero'), (1, 'a'), (2, 'b'), (3, 'c')], finished)
        
        finished = []
        for request, response in reque.finish(4, 'd'):
            finished.append((request, response))
        
        self.assertEquals([(4, 'd')], finished)
        
if __name__ == '__main__':
    unittest.main(timeout = 10.0)

########NEW FILE########
__FILENAME__ = teststackless

import unittest
import logging

logging.basicConfig(level = logging.DEBUG)

from concurrence.core import stackless

class TestError(Exception): pass

class TestStackless(unittest.TestCase):
    
    def setUp(self):
        logging.debug(self)
        
    def testSchedule(self):

        res1 = []
        res2 = []
        
        def ch1():
            for i in range(10):
                res1.append((i, stackless.getruncount()))
                stackless.schedule()

        def ch2():
            for i in range(10):
                res2.append((i, stackless.getruncount()))
                stackless.schedule()

        child1 = stackless.tasklet(ch1)()
        child2 = stackless.tasklet(ch2)()

        self.assertEquals(3, stackless.getruncount()) #main + ch1, ch2

        while stackless.getruncount() > 1:
            stackless.schedule()

        self.assertEquals([(0, 3), (1, 3), (2, 3), (3, 3), (4, 3), (5, 3), (6, 3), (7, 3), (8, 3), (9, 3)], res1)
        self.assertEquals([(0, 3), (1, 3), (2, 3), (3, 3), (4, 3), (5, 3), (6, 3), (7, 3), (8, 3), (9, 3)], res2)

        self.assertEquals(1, stackless.getruncount()) #main
        
    def testChannel(self):
        
        c = stackless.channel()
        
        recvd = []
        
        def ch1():
            for i in range(10):
                recvd.append(c.receive())

        def ch2():
            for i in range(10):
                c.send(i)

        child1 = stackless.tasklet(ch1)()
        child2 = stackless.tasklet(ch2)()

        self.assertEquals(3, stackless.getruncount()) #main
        
        while stackless.getruncount() > 1:
            stackless.schedule()

        self.assertEquals(range(10), recvd)
        
        self.assertEquals(1, stackless.getruncount()) #main
        
    def testChannelException(self):


        c = stackless.channel()

        result = []

        def ch1():
            for i in range(2):
                try:
                    result.append(c.receive())
                except TestError, te:
                    result.append(te)
             
        def ch2():
            c.send(True)
            c.send_exception(TestError, "test")

        child1 = stackless.tasklet(ch1)()
        child2 = stackless.tasklet(ch2)()

        self.assertEquals(3, stackless.getruncount()) #main + ch1 + ch2
        
        while stackless.getruncount() > 1:
            stackless.schedule()

        self.assertEquals(True, result[0])
        self.assertTrue(isinstance(result[1], TestError))
        
        self.assertEquals(1, stackless.getruncount()) #main

    def testKillOnChannel(self):
        
        c = stackless.channel()
        
        def child(r):
            r.b1 = c.balance
            r.rc1 = stackless.getruncount()
            r.cur1 = stackless.getcurrent()
            r.blocked1 = r.cur1.blocked
            r.alive1 = r.cur1.alive
            try:
                c.receive()
            finally:
                r.b2 = c.balance
                r.rc2 = stackless.getruncount()
                r.cur2 = stackless.getcurrent()
                r.blocked2 = r.cur2.blocked
                r.alive2 = r.cur2.alive

        class result: pass

        r = result()
        ch = stackless.tasklet(child)(r)
        
        stackless.schedule()

        ch.kill()

        self.assertEquals((0, 0), (r.b1, r.b2))
        self.assertEquals((2, 2), (r.rc1, r.rc2))
        self.assertTrue(r.cur1 == r.cur2)
        self.assertEquals((False, False), (r.blocked1, r.blocked2))
        self.assertEquals((True, True), (r.alive1, r.alive2))

    def testExceptionOnChannel(self):
        
        c = stackless.channel()
        
        def child(r):
            r.b1 = c.balance
            try:
                c.receive()
            except TestError:
                r.b2 = c.balance

        class result: pass

        r = result()
        ch = stackless.tasklet(child)(r)
        
        stackless.schedule()

        ch.raise_exception(TestError)
        
        self.assertEquals((0, 0), (r.b1, r.b2))

    def testKillOnSchedule(self):

        class result: pass

        r = result()

        def child1():
            i = 0
            while True:
                i += 1
                #print 'c', i
                r.rc1 = stackless.getruncount()
                r.cur1 = stackless.getcurrent()
                r.blocked1 = r.cur1.blocked
                r.alive1 = r.cur1.alive

                try:
                    stackless.schedule()    
                except TaskletExit:
                    #print 'kill'
                    r.rc2 = stackless.getruncount()
                    r.cur2 = stackless.getcurrent()
                    r.blocked2 = r.cur2.blocked
                    r.alive2 = r.cur2.alive
                    raise

        ch1 = stackless.tasklet(child1)()

        x = 0
        while True:
            x += 1
            stackless.schedule()    
            if x == 10: 
                ch1.kill()
            if x >= 15:
                break

        self.assertEquals((2, 2), (r.rc1, r.rc2))
        self.assertTrue(r.cur1 == r.cur2)
        self.assertEquals((False, False), (r.blocked1, r.blocked2))
        self.assertEquals((True, True), (r.alive1, r.alive2))

    def testKillOrder(self):
        
        def ch1():
            #print 'ch1 start', stackless.getcurrent()
            try:
                for i in range(10):
                    #print 1, i
                    stackless.schedule()
            except:
                #print '1', 'some exc in 1', stackless.getruncount()
                #print '1', stackless.getcurrent(), stackless.getcurrent().alive
                raise

        def ch2():
            for i in range(10):
                #print 2, i
                stackless.schedule()
                if i == 5:
                    #print '2', '!!!!!!!!KILL!!!!'
                    child1.kill()
                    #print '2', stackless.getcurrent(), stackless.getruncount()
            #print '2', 'DONE'
        child1 = stackless.tasklet(ch1)()
        child2 = stackless.tasklet(ch2)()

        for i in range(20):
            #print 's', i, stackless.getruncount(), child1.alive, child2.alive#, stackless._scheduler._runnable
            stackless.schedule()
        #while stackless.getruncount() > 2:
        #    stackless.schedule()

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = teststatistic
from __future__ import with_statement

from concurrence import unittest, Tasklet
from concurrence.statistic import StatisticExtra, Statistic

class TestStatistic(unittest.TestCase):
    
    
    def testStatisticExtra(self):
    
        timer = StatisticExtra(g = 0.1) #low g for fast convergence
        
        for i in range(10):
            with timer.time():
                Tasklet.sleep(0.1)

        self.assertEquals(10, timer.count)
        self.assertAlmostEqual(0.1, timer.avg, places = 1)
        
        timer = StatisticExtra(g = 0.1) #low g for fast convergence
        for i in range(11):
            with timer.time():
                Tasklet.sleep(0.2)

        self.assertEquals(11, timer.count)
        self.assertAlmostEqual(0.2, timer.avg, places = 1)
        
        
    def testStatistic(self):
        
        stat = Statistic(0)
        
        self.assertEquals(0, stat.count)
        stat += 1
        self.assertEquals(1, stat.count)
        stat -= 1
        self.assertEquals(0, stat.count)
        
if __name__ == '__main__':
    unittest.main()
    

########NEW FILE########
__FILENAME__ = testtest
from concurrence import unittest, Tasklet

class TestTest(unittest.TestCase):
    def testTimeout(self):
        try:
            Tasklet.sleep(4)
            self.fail('expected timeout')
        except TaskletExit:
            pass #caused by timeout
        
if __name__ == '__main__':
    unittest.main(timeout = 2)

########NEW FILE########
__FILENAME__ = testtimer
from __future__ import with_statement

import time

from concurrence import unittest, Tasklet, Channel, TimeoutError
from concurrence.timer import Timeout

class TimerTest(unittest.TestCase):
    def testPushPop(self):
        
        self.assertEquals(-1, Timeout.current())
        
        Timeout.push(30)
        self.assertAlmostEqual(30, Timeout.current(), places = 1)
        Timeout.pop()
        self.assertEquals(-1, Timeout.current())
        Timeout.push(30)
        self.assertAlmostEqual(30, Timeout.current(), places = 1)
        Tasklet.sleep(1.0)
        self.assertAlmostEqual(29, Timeout.current(), places = 1)
        #push a temporary short timeout
        Timeout.push(5)
        self.assertAlmostEqual(5, Timeout.current(), places = 1)
        Timeout.pop()
        self.assertAlmostEqual(29, Timeout.current(), places = 1)
        
        #try to push a new longer timeout than the parent timeout
        #this should fail, e.g. it will keep the parent timeout
        Timeout.push(60)
        self.assertAlmostEqual(29, Timeout.current(), places = 1)
        Timeout.pop()
        self.assertAlmostEqual(29, Timeout.current(), places = 1)
        Timeout.pop()
        self.assertEquals(-1, Timeout.current())
        
    def testPushPop2(self):
        
        self.assertEquals(-1, Timeout.current())
        Timeout.push(-1)
        self.assertEquals(-1, Timeout.current())
        Timeout.pop()
        self.assertEquals(-1, Timeout.current())
        
        Timeout.push(10)
        self.assertAlmostEqual(10, Timeout.current(), places = 1)        
        Timeout.push(5)
        self.assertAlmostEqual(5, Timeout.current(), places = 1)
        Timeout.pop()
        self.assertAlmostEqual(10, Timeout.current(), places = 1)
        Timeout.pop()
        self.assertEquals(-1, Timeout.current())
        
    def testTimer(self):
        
        ch = Channel()
        
        def sender(times):
            for i in range(times):
                Tasklet.sleep(1.0)
                ch.send(True)
       
        with Timeout.push(10):
            Tasklet.new(sender)(4)
            for i in range(4):
                ch.receive(Timeout.current())
            
        start = time.time()
        try:            
            with Timeout.push(2.5):
                Tasklet.new(sender)(4)
                for i in range(4):
                    ch.receive(Timeout.current())
                self.fail('expected timeout')
        except TimeoutError, e:
            end = time.time()
            self.assertAlmostEqual(2.5, end - start, places = 1)
            

if __name__ == '__main__':
    unittest.main(timeout = 10)

########NEW FILE########
__FILENAME__ = testweb
# -*- coding: utf-8 -*-

from concurrence import unittest, Tasklet, TimeoutError

from concurrence.web import Application, Controller, Filter, web
from concurrence.web.filter import TimeoutFilter, JSONFilter
from concurrence.http.client import HTTPConnection

class CallManyFilter(Filter):
    def __init__(self, n):
        self.n = n
        
    def __call__(self, next, *args, **kwargs):
        result = ''
        for i in range(self.n):
            result += next(*args, **kwargs)
        return result
    
class TestController(Controller):

    @web.route('/hello')
    def hello(self):
        return u"Hllo World!"

    @web.route('/many')
    @web.filter(CallManyFilter(10))
    def many(self):
        return "blaat"
        
    @web.route('/timeout')
    @web.filter(TimeoutFilter())
    def timeout(self):
        Tasklet.sleep(2.0)
        raise TimeoutError() #simulate it because sleep does not honor timeouts
        
    @web.route('/json')
    @web.filter(JSONFilter())
    def json(self):
        return "[1,2,3,4]"            
        
class TestWeb(unittest.TestCase):

    def setUp(self):

        application = Application()
        application.add_controller(TestController())
        application.configure()
        self.server = application.serve(('localhost', 8080))

    def tearDown(self):

        self.server.close()

    def testWeb(self):

        cnn = None
        try:           
            cnn = HTTPConnection()
            cnn.connect(('localhost', 8080))
            response = cnn.perform(cnn.get('/hello'))
            status = response.status
            self.assertEquals('HTTP/1.1 200 OK', status)    
            self.assertEquals('text/html; charset=UTF-8', response.get_header('Content-Type'))
            self.assertEquals('13', response.get_header('Content-Length'))
            self.assertEquals(u"Hllo World!",  ''.join(response).decode('UTF-8'))
        finally:
            if cnn: cnn.close()

    def testWebTimeout(self):

        cnn = None
        try:           
            cnn = HTTPConnection()
            cnn.connect(('localhost', 8080))

            request = cnn.get('/timeout')
            request.add_header('Timeout', 1.0)
            response = cnn.perform(request)
            status = response.status            
            self.assertEquals('HTTP/1.1 500 Internal Server Error', status)    
            self.assertEquals('text/plain', response.get_header('Content-Type'))
            
        finally:
            if cnn: cnn.close()
        
    def testWebJSON(self):

        cnn = None
        try:           
            cnn = HTTPConnection()
            cnn.connect(('localhost', 8080))
            response = cnn.perform(cnn.get('/json'))
            status = response.status
            self.assertEquals('HTTP/1.1 200 OK', status)    
            self.assertEquals('application/json; charset=UTF-8', response.get_header('Content-Type'))
            self.assertEquals('9', response.get_header('Content-Length'))
            self.assertEquals("[1,2,3,4]",  response.body)
        finally:
            if cnn: cnn.close()
        
    def testMany(self):
        cnn = None
        try:           
            cnn = HTTPConnection()
            cnn.connect(('localhost', 8080))
            response = cnn.perform(cnn.get('/many'))
            self.assertEquals('blaat' * 10, response.body)
        finally:
            if cnn: cnn.close()
        
if __name__ == '__main__':
    unittest.main(timeout = 100)

########NEW FILE########
