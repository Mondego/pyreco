__FILENAME__ = env
from __future__ import with_statement
from alembic import context
from sqlalchemy import engine_from_config, pool
from logging.config import fileConfig

# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config

# Interpret the config file for Python logging.
# This line sets up loggers basically.
fileConfig(config.config_file_name)

# add your model's MetaData object here
# for 'autogenerate' support
# from myapp import mymodel
# target_metadata = mymodel.Base.metadata
target_metadata = None

# other values from the config, defined by the needs of env.py,
# can be acquired:
# my_important_option = config.get_main_option("my_important_option")
# ... etc.

def run_migrations_offline():
    """Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.

    """
    url = config.get_main_option("sqlalchemy.url")
    context.configure(url=url)

    with context.begin_transaction():
        context.run_migrations()

def run_migrations_online():
    """Run migrations in 'online' mode.

    In this scenario we need to create an Engine
    and associate a connection with the context.

    """
    engine = engine_from_config(
                config.get_section(config.config_ini_section),
                prefix='sqlalchemy.',
                poolclass=pool.NullPool)

    connection = engine.connect()
    context.configure(
                connection=connection,
                target_metadata=target_metadata
                )

    try:
        with context.begin_transaction():
            context.run_migrations()
    finally:
        connection.close()

if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()


########NEW FILE########
__FILENAME__ = 15a75c65a3a1_guaranteed_delivery
"""Guaranteed delivery

Revision ID: 15a75c65a3a1
Revises: 1d1df3f2e67d
Create Date: 2013-10-29 22:26:17.288183

"""

# revision identifiers, used by Alembic.
revision = '15a75c65a3a1'
down_revision = '1d1df3f2e67d'

from alembic import op
import sqlalchemy as sa

# Zato
from zato.common.odb import model

def upgrade():
    op.create_table(
        'delivery_def_base',
        sa.Column('id', sa.Integer, sa.Sequence('deliv_def_seq'), primary_key=True),
        sa.Column('name', sa.String(200), nullable=False, index=True),
        sa.Column('short_def', sa.String(200), nullable=False),
        sa.Column('last_used', sa.DateTime(200), nullable=True),
        sa.Column('target_type', sa.DateTime(200), nullable=False),
        sa.Column('callback_list', sa.LargeBinary(10000), nullable=True),
        sa.Column('expire_after', sa.Integer(), nullable=False),
        sa.Column('expire_arch_succ_after', sa.Integer(), nullable=False),
        sa.Column('expire_arch_fail_after', sa.Integer(), nullable=False),
        sa.Column('check_after', sa.Integer(), nullable=False),
        sa.Column('retry_repeats', sa.Integer(), nullable=False),
        sa.Column('retry_seconds', sa.Integer(), nullable=False),
        sa.Column('cluster_id', sa.Integer(), sa.ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False),
    )
    
    op.create_table(
        'delivery_def_out_wmq',
        sa.Column('id', sa.Integer, sa.ForeignKey('delivery_def_base.id'), primary_key=True),
        sa.Column('target_id', sa.Integer, sa.ForeignKey('out_wmq.id', ondelete='CASCADE'), nullable=False, primary_key=False)
    )
    
    op.create_table(
        'delivery',
        sa.Column('id', sa.Integer, sa.Sequence('deliv_seq'), primary_key=True),
        sa.Column('task_id', sa.String(64), unique=True, nullable=False, index=True),
        sa.Column('name', sa.String(200), nullable=False),
        sa.Column('creation_time', sa.DateTime(), nullable=False),
        sa.Column('args', sa.LargeBinary(1000000), nullable=True),
        sa.Column('kwargs', sa.LargeBinary(1000000), nullable=True),
        sa.Column('last_used', sa.DateTime(), nullable=True),
        sa.Column('resubmit_count', sa.Integer, nullable=False, default=0),
        sa.Column('state', sa.String(200), nullable=False, index=True),
        sa.Column('source_count', sa.Integer, nullable=False, default=1),
        sa.Column('target_count', sa.Integer, nullable=False, default=0),
        sa.Column('definition_id', sa.Integer, sa.ForeignKey('delivery_def_base.id', ondelete='CASCADE'), nullable=False, primary_key=False),
    )

    op.create_table(
        'delivery_payload',
        sa.Column('id', sa.Integer, sa.Sequence('deliv_payl_seq'), primary_key=True),
        sa.Column('task_id', sa.String(64), unique=True, nullable=False, index=True),
        sa.Column('creation_time', sa.DateTime(), nullable=False),
        sa.Column('payload', sa.LargeBinary(5000000), nullable=False),
        sa.Column('delivery_id', sa.Integer, sa.ForeignKey('delivery.id', ondelete='CASCADE'), nullable=False, primary_key=False),
    )
    
    op.create_table(
        'delivery_history',
        sa.Column('id', sa.Integer, sa.Sequence('deliv_payl_seq'), primary_key=True),
        sa.Column('task_id', sa.String(64), unique=True, nullable=False, index=True),
        
        sa.Column('entry_type', sa.String(64), nullable=False),
        sa.Column('entry_time', sa.DateTime(), nullable=False, index=True),
        sa.Column('entry_ctx', sa.LargeBinary(6000000), nullable=False),
        sa.Column('resubmit_count', sa.Integer, nullable=False, default=0),
        sa.Column('delivery_id', sa.Integer, sa.ForeignKey('delivery.id', ondelete='CASCADE'), nullable=False, primary_key=False),
    )

def downgrade():
    op.drop_table('delivery_history')
    op.drop_table('delivery_payload')
    op.drop_table('delivery')
    op.drop_table('delivery_def_out_wmq')
    op.drop_table('delivery_def_base')

########NEW FILE########
__FILENAME__ = 1d1df3f2e67d_gh_80559acf_service_
"""gh 80559acf Service.name (300)

Revision ID: 1d1df3f2e67d
Revises: 54c7cc2d0416
Create Date: 2013-10-29 22:18:59.663205

"""

# revision identifiers, used by Alembic.
revision = '1d1df3f2e67d'
down_revision = '54c7cc2d0416'

from alembic import op
import sqlalchemy as sa

# Zato
from zato.common.odb import model

def upgrade():
    op.alter_column(model.Service.__tablename__, 'name',
        type_=sa.String(300), existing_type=sa.String(length=2000),
        nullable=False)


def downgrade():
    op.alter_column(model.Service.__tablename__, 'name',
        type_=sa.String(2000), existing_type=sa.String(length=300),
        nullable=False)

########NEW FILE########
__FILENAME__ = 2538d53b16c8_gh101_restful_channe
"""gh101 RESTful channels (URL params + priority)

Revision ID: 2538d53b16c8
Revises: 15a75c65a3a1
Create Date: 2013-10-29 23:37:49.556055

"""

# revision identifiers, used by Alembic.
revision = '2538d53b16c8'
down_revision = '15a75c65a3a1'

from alembic import op
import sqlalchemy as sa

# Zato
from zato.common.odb import model

def upgrade():
    op.add_column(model.HTTPSOAP.__tablename__,
        sa.Column('merge_url_params_req', sa.Boolean, nullable=True, default=True))
    
    op.add_column(model.HTTPSOAP.__tablename__,
        sa.Column('url_params_pri', sa.String(200), nullable=True, default='path-then-qs'))

    op.add_column(model.HTTPSOAP.__tablename__,
        sa.Column('params_pri', sa.String(200), nullable=True, default='url-then-msg'))

def downgrade():
    op.drop_column('http_soap', 'merge_url_params_req')
    op.drop_column('http_soap', 'url_params_pri')
    op.drop_column('http_soap', 'params_pri')

########NEW FILE########
__FILENAME__ = 3dfa60e5b541_gh77_outconn_http_so
"""gh77: Outconn HTTP/SOAP pool size

Revision ID: 3dfa60e5b541
Revises: 419059182a1d
Create Date: 2013-10-29 21:14:14.310464

"""

# revision identifiers, used by Alembic.
revision = '3dfa60e5b541'
down_revision = '419059182a1d'

from alembic import op
import sqlalchemy as sa

# Zato
from zato.common.odb import model


def upgrade():
    op.add_column(model.HTTPSOAP.__tablename__,
        sa.Column('pool_size', sa.Integer, nullable=True)
    )


def downgrade():
    op.drop_column('http_soap', 'pool_size')

########NEW FILE########
__FILENAME__ = 3f03ae0ef253_gh110_http_channels_
"""gh110 HTTP channels audit

Revision ID: 3f03ae0ef253
Revises: 45c5b38b620e
Create Date: 2013-11-27 20:54:35.653604

"""

# revision identifiers, used by Alembic.
revision = '3f03ae0ef253'
down_revision = '45c5b38b620e'

from alembic import op
import sqlalchemy as sa

# Zato
from zato.common import MISC, MSG_PATTERN_TYPE
from zato.common.odb import model

def upgrade():

    op.add_column(model.HTTPSOAP.__tablename__,
        sa.Column('audit_enabled', sa.Boolean(), nullable=False, default=False)
    )
    
    op.add_column(model.HTTPSOAP.__tablename__,
        sa.Column('audit_back_log', sa.Integer(), nullable=False, default=MISC.DEFAULT_AUDIT_BACK_LOG)
    )
    
    op.add_column(model.HTTPSOAP.__tablename__,
        sa.Column('audit_max_payload', sa.Integer(), nullable=False, default=MISC.DEFAULT_AUDIT_MAX_PAYLOAD)
    )
    
    op.add_column(model.HTTPSOAP.__tablename__,
        sa.Column('audit_repl_patt_type', sa.String(), nullable=False, default=MSG_PATTERN_TYPE.ELEM_PATH.id)
    )
    
    op.create_table(
        'http_soap_audit',
        sa.Column('id', sa.Integer, sa.Sequence('http_soap_audit_seq'), primary_key=True),
        sa.Column('cluster_id', sa.Integer, sa.ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False, primary_key=False),
        sa.Column('cid', sa.String, nullable=False, index=True),
        sa.Column('name', sa.String, nullable=False, index=True),
        sa.Column('transport', sa.String, nullable=False, index=True),
        sa.Column('connection', sa.String, nullable=False, index=True),
        sa.Column('req_time', sa.DateTime, nullable=False),
        sa.Column('resp_time', sa.DateTime, nullable=True),
        sa.Column('user_token', sa.String, nullable=True, index=True),
        sa.Column('invoke_ok', sa.Boolean, nullable=True),
        sa.Column('auth_ok', sa.Boolean, nullable=True),
        sa.Column('user_token', sa.String, nullable=False, index=True),
        sa.Column('remote_addr', sa.String, nullable=False, index=True),
        sa.Column('req_headers', sa.String, nullable=True, index=True),
        sa.Column('req_payload', sa.String, nullable=True, index=True),
        sa.Column('resp_headers', sa.String, nullable=True, index=True),
        sa.Column('resp_payload', sa.String, nullable=True, index=True),
    )
    
    op.create_table(
        'http_soap_au_rpl_p_ep',
        sa.Column('id', sa.Integer, sa.Sequence('htp_sp_ad_rpl_p_ep_seq'), primary_key=True),
        sa.Column('conn_id', sa.Integer, sa.ForeignKey('http_soap.id', ondelete='CASCADE'), nullable=False),
        sa.Column('pattern_id', sa.Integer, sa.ForeignKey('msg_elem_path.id', ondelete='CASCADE'), nullable=False),
        sa.Column('cluster_id', sa.Integer, sa.ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False),
    )
    
    op.create_table(
        'http_soap_au_rpl_p_xp',
        sa.Column('id', sa.Integer, sa.Sequence('htp_sp_ad_rpl_p_xp_seq'), primary_key=True),
        sa.Column('conn_id', sa.Integer, sa.ForeignKey('http_soap.id', ondelete='CASCADE'), nullable=False),
        sa.Column('pattern_id', sa.Integer, sa.ForeignKey('msg_elem_path.id', ondelete='CASCADE'), nullable=False),
        sa.Column('cluster_id', sa.Integer, sa.ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False),
    )

def downgrade():
    op.drop_column(model.HTTPSOAP.__tablename__, 'audit_enabled')
    op.drop_column(model.HTTPSOAP.__tablename__, 'audit_back_log')
    op.drop_column(model.HTTPSOAP.__tablename__, 'audit_max_payload')
    op.drop_column(model.HTTPSOAP.__tablename__, 'audit_repl_patt_type')
    
    op.drop_table('http_soap_audit')
    op.drop_table('http_soap_ad_rpl_p_ep')
    op.drop_table('http_soap_ad_rpl_p_xp')

########NEW FILE########
__FILENAME__ = 419059182a1d_gh44_pinging_plain_h
"""gh44: Pinging Plain HTTP outgoing connection

Revision ID: 419059182a1d
Revises: None
Create Date: 2013-10-29 20:27:14.040498

"""

# revision identifiers, used by Alembic.
revision = '419059182a1d'
down_revision = None

from alembic import op
import sqlalchemy as sa

# Zato
from zato.common.odb import model

def upgrade():
    op.add_column(model.HTTPSOAP.__tablename__,
        sa.Column('ping_method', sa.String(60), nullable=True)
    )

def downgrade():
    op.drop_column('http_soap', 'ping_method')

########NEW FILE########
__FILENAME__ = 45c5b38b620e_gh110_msg_paths
"""gh110 Msg paths

Revision ID: 45c5b38b620e
Revises: 4eb66feec2a6
Create Date: 2013-11-24 17:05:50.526032

"""

# revision identifiers, used by Alembic.
revision = '45c5b38b620e'
down_revision = '4eb66feec2a6'

from alembic import op
import sqlalchemy as sa

# Zato
from zato.common.odb import model

def upgrade():
    op.create_table(
        'msg_xpath',
        sa.Column('id', sa.Integer, sa.Sequence('msg_xpath_seq'), primary_key=True),
        sa.Column('name', sa.String(200), nullable=False, index=True),
        sa.Column('value', sa.String(500), nullable=False),
        sa.Column('cluster_id', sa.Integer(), sa.ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False),
    )

    op.create_table(
        'msg_elem_path',
        sa.Column('id', sa.Integer, sa.Sequence('msg_elem_path_seq'), primary_key=True),
        sa.Column('name', sa.String(200), nullable=False, index=True),
        sa.Column('value', sa.String(500), nullable=False),
        sa.Column('cluster_id', sa.Integer(), sa.ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False),
    )

    op.create_unique_constraint(None, 'msg_xpath', ['name', 'cluster_id'])
    op.create_unique_constraint(None, 'msg_elem_path', ['name', 'cluster_id'])

def downgrade():
    op.drop_table('msg_xpath')
    op.drop_table('msg_elem_path')

########NEW FILE########
__FILENAME__ = 4eb66feec2a6_gh110_message_namesp
"""gh110 Message namespaces

Revision ID: 4eb66feec2a6
Revises: c16781527a4
Create Date: 2013-11-22 13:34:36.678790

"""

# revision identifiers, used by Alembic.
revision = '4eb66feec2a6'
down_revision = 'c16781527a4'

from alembic import op
import sqlalchemy as sa

# Zato
from zato.common.odb import model

def upgrade():
    op.create_table(
        'msg_ns',
        sa.Column('id', sa.Integer, sa.Sequence('msg_ns_seq'), primary_key=True),
        sa.Column('name', sa.String(200), nullable=False, index=True),
        sa.Column('value', sa.String(500), nullable=False),
        sa.Column('cluster_id', sa.Integer(), sa.ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False),
    )
    op.create_unique_constraint(None, 'msg_ns', ['name', 'cluster_id'])

def downgrade():
    op.drop_table('msg_ns')

########NEW FILE########
__FILENAME__ = 54c7cc2d0416_gh43_empty_passwords
"""gh43: Empty passwords in sec definitions

Revision ID: 54c7cc2d0416
Revises: 3dfa60e5b541
Create Date: 2013-10-29 21:28:49.103205

"""

# revision identifiers, used by Alembic.
revision = '54c7cc2d0416'
down_revision = '3dfa60e5b541'

from alembic import op

# Zato
from zato.common.odb import model


def upgrade():
    op.alter_column(model.SecurityBase.__tablename__, 'password', nullable=True)

def downgrade():
    op.alter_column(model.SecurityBase.__tablename__, 'password', nullable=False)

########NEW FILE########
__FILENAME__ = c16781527a4_gh119_oauth_1_0_http
"""gh119: OAuth 1.0 HTTP channels

Revision ID: c16781527a4
Revises: 2538d53b16c8
Create Date: 2013-11-13 14:57:36.541735

"""

# revision identifiers, used by Alembic.
revision = 'c16781527a4'
down_revision = '2538d53b16c8'

from alembic import op
import sqlalchemy as sa

# Zato
from zato.common.odb import model

def upgrade():
    op.create_table(
        'sec_oauth',
        sa.Column('id', sa.Integer, sa.ForeignKey('sec_base.id'), primary_key=True),
        sa.Column('username', sa.String(32), nullable=False),
        sa.Column('proto_version', sa.String(32), nullable=False),
        sa.Column('sig_method', sa.String(32), nullable=False),
        sa.Column('max_nonce_log', sa.Integer(), nullable=False),
    )

def downgrade():
    op.drop_table('sec_oauth')

########NEW FILE########
__FILENAME__ = bootstrap
##############################################################################
#
# Copyright (c) 2006 Zope Foundation and Contributors.
# All Rights Reserved.
#
# This software is subject to the provisions of the Zope Public License,
# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.
# THIS SOFTWARE IS PROVIDED "AS IS" AND ANY AND ALL EXPRESS OR IMPLIED
# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS
# FOR A PARTICULAR PURPOSE.
#
##############################################################################
"""Bootstrap a buildout-based project

Simply run this script in a directory containing a buildout.cfg.
The script accepts buildout command-line options, so you can
use the -c option to specify an alternate configuration file.
"""

import os, shutil, sys, tempfile, textwrap, urllib, urllib2, subprocess
from optparse import OptionParser

if sys.platform == 'win32':
    def quote(c):
        if ' ' in c:
            return '"%s"' % c # work around spawn lamosity on windows
        else:
            return c
else:
    quote = str

# See zc.buildout.easy_install._has_broken_dash_S for motivation and comments.
stdout, stderr = subprocess.Popen(
    [sys.executable, '-Sc',
     'try:\n'
     '    import ConfigParser\n'
     'except ImportError:\n'
     '    print 1\n'
     'else:\n'
     '    print 0\n'],
    stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()
has_broken_dash_S = bool(int(stdout.strip()))

# In order to be more robust in the face of system Pythons, we want to
# run without site-packages loaded.  This is somewhat tricky, in
# particular because Python 2.6's distutils imports site, so starting
# with the -S flag is not sufficient.  However, we'll start with that:
if not has_broken_dash_S and 'site' in sys.modules:
    # We will restart with python -S.
    args = sys.argv[:]
    args[0:0] = [sys.executable, '-S']
    args = map(quote, args)
    os.execv(sys.executable, args)
# Now we are running with -S.  We'll get the clean sys.path, import site
# because distutils will do it later, and then reset the path and clean
# out any namespace packages from site-packages that might have been
# loaded by .pth files.
clean_path = sys.path[:]
import site
sys.path[:] = clean_path
for k, v in sys.modules.items():
    if k in ('setuptools', 'pkg_resources') or (
        hasattr(v, '__path__') and
        len(v.__path__)==1 and
        not os.path.exists(os.path.join(v.__path__[0],'__init__.py'))):
        # This is a namespace package.  Remove it.
        sys.modules.pop(k)

is_jython = sys.platform.startswith('java')

setuptools_source = 'http://peak.telecommunity.com/dist/ez_setup.py'
distribute_source = 'http://python-distribute.org/distribute_setup.py'

# parsing arguments
def normalize_to_url(option, opt_str, value, parser):
    if value:
        if '://' not in value: # It doesn't smell like a URL.
            value = 'file://%s' % (
                urllib.pathname2url(
                    os.path.abspath(os.path.expanduser(value))),)
        if opt_str == '--download-base' and not value.endswith('/'):
            # Download base needs a trailing slash to make the world happy.
            value += '/'
    else:
        value = None
    name = opt_str[2:].replace('-', '_')
    setattr(parser.values, name, value)

usage = '''\
[DESIRED PYTHON FOR BUILDOUT] bootstrap.py [options]

Bootstraps a buildout-based project.

Simply run this script in a directory containing a buildout.cfg, using the
Python that you want bin/buildout to use.

Note that by using --setup-source and --download-base to point to
local resources, you can keep this script from going over the network.
'''

parser = OptionParser(usage=usage)
parser.add_option("-v", "--version", dest="version",
                          help="use a specific zc.buildout version")
parser.add_option("-d", "--distribute",
                   action="store_true", dest="use_distribute", default=False,
                   help="Use Distribute rather than Setuptools.")
parser.add_option("--setup-source", action="callback", dest="setup_source",
                  callback=normalize_to_url, nargs=1, type="string",
                  help=("Specify a URL or file location for the setup file. "
                        "If you use Setuptools, this will default to " +
                        setuptools_source + "; if you use Distribute, this "
                        "will default to " + distribute_source +"."))
parser.add_option("--download-base", action="callback", dest="download_base",
                  callback=normalize_to_url, nargs=1, type="string",
                  help=("Specify a URL or directory for downloading "
                        "zc.buildout and either Setuptools or Distribute. "
                        "Defaults to PyPI."))
parser.add_option("--eggs",
                  help=("Specify a directory for storing eggs.  Defaults to "
                        "a temporary directory that is deleted when the "
                        "bootstrap script completes."))
parser.add_option("-t", "--accept-buildout-test-releases",
                  dest='accept_buildout_test_releases',
                  action="store_true", default=False,
                  help=("Normally, if you do not specify a --version, the "
                        "bootstrap script and buildout gets the newest "
                        "*final* versions of zc.buildout and its recipes and "
                        "extensions for you.  If you use this flag, "
                        "bootstrap and buildout will get the newest releases "
                        "even if they are alphas or betas."))
parser.add_option("-c", None, action="store", dest="config_file",
                   help=("Specify the path to the buildout configuration "
                         "file to be used."))

options, args = parser.parse_args()

# if -c was provided, we push it back into args for buildout's main function
if options.config_file is not None:
    args += ['-c', options.config_file]

if options.eggs:
    eggs_dir = os.path.abspath(os.path.expanduser(options.eggs))
else:
    eggs_dir = tempfile.mkdtemp()

if options.setup_source is None:
    if options.use_distribute:
        options.setup_source = distribute_source
    else:
        options.setup_source = setuptools_source

if options.accept_buildout_test_releases:
    args.append('buildout:accept-buildout-test-releases=true')
args.append('bootstrap')

try:
    import pkg_resources
    import setuptools # A flag.  Sometimes pkg_resources is installed alone.
    if not hasattr(pkg_resources, '_distribute'):
        raise ImportError
except ImportError:
    ez_code = urllib2.urlopen(
        options.setup_source).read().replace('\r\n', '\n')
    ez = {}
    exec ez_code in ez
    setup_args = dict(to_dir=eggs_dir, download_delay=0)
    if options.download_base:
        setup_args['download_base'] = options.download_base
    if options.use_distribute:
        setup_args['no_fake'] = True
    ez['use_setuptools'](**setup_args)
    if 'pkg_resources' in sys.modules:
        reload(sys.modules['pkg_resources'])
    import pkg_resources
    # This does not (always?) update the default working set.  We will
    # do it.
    for path in sys.path:
        if path not in pkg_resources.working_set.entries:
            pkg_resources.working_set.add_entry(path)

cmd = [quote(sys.executable),
       '-c',
       quote('from setuptools.command.easy_install import main; main()'),
       '-mqNxd',
       quote(eggs_dir)]

if not has_broken_dash_S:
    cmd.insert(1, '-S')

find_links = options.download_base
if not find_links:
    find_links = os.environ.get('bootstrap-testing-find-links')
if find_links:
    cmd.extend(['-f', quote(find_links)])

if options.use_distribute:
    setup_requirement = 'distribute'
else:
    setup_requirement = 'setuptools'
ws = pkg_resources.working_set
setup_requirement_path = ws.find(
    pkg_resources.Requirement.parse(setup_requirement)).location
env = dict(
    os.environ,
    PYTHONPATH=setup_requirement_path)

requirement = 'zc.buildout'
version = options.version
if version is None and not options.accept_buildout_test_releases:
    # Figure out the most recent final version of zc.buildout.
    import setuptools.package_index
    _final_parts = '*final-', '*final'
    def _final_version(parsed_version):
        for part in parsed_version:
            if (part[:1] == '*') and (part not in _final_parts):
                return False
        return True
    index = setuptools.package_index.PackageIndex(
        search_path=[setup_requirement_path])
    if find_links:
        index.add_find_links((find_links,))
    req = pkg_resources.Requirement.parse(requirement)
    if index.obtain(req) is not None:
        best = []
        bestv = None
        for dist in index[req.project_name]:
            distv = dist.parsed_version
            if _final_version(distv):
                if bestv is None or distv > bestv:
                    best = [dist]
                    bestv = distv
                elif distv == bestv:
                    best.append(dist)
        if best:
            best.sort()
            version = best[-1].version
if version:
    requirement = '=='.join((requirement, version))
cmd.append(requirement)

if is_jython:
    import subprocess
    exitcode = subprocess.Popen(cmd, env=env).wait()
else: # Windows prefers this, apparently; otherwise we would prefer subprocess
    exitcode = os.spawnle(*([os.P_WAIT, sys.executable] + cmd + [env]))
if exitcode != 0:
    sys.stdout.flush()
    sys.stderr.flush()
    print ("An error occurred when trying to install zc.buildout. "
           "Look above this message for any errors that "
           "were output by easy_install.")
    sys.exit(exitcode)

ws.add_entry(eggs_dir)
ws.require(requirement)
import zc.buildout.buildout
zc.buildout.buildout.main(args)
if not options.eggs: # clean up temporary egg directory
    shutil.rmtree(eggs_dir)

########NEW FILE########
__FILENAME__ = prepare_buildout
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import sys

def _prepare_buildout(has_pymqi):
    buildout = open('./buildout.cfg.template').read()
    if has_pymqi:
        buildout = buildout.replace('#PYMQI_MARKER', '')
        
    open('./buildout.cfg', 'w').write(buildout)

if __name__ == '__main__':
    has_pymqi = len(sys.argv) and str(sys.argv[1]) == '0'
    _prepare_buildout(has_pymqi)


    

########NEW FILE########
__FILENAME__ = client
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Spring Python
from springpython.remoting.xmlrpc import SSLClient

class LoadBalancerAgentClient(SSLClient):
    pass

########NEW FILE########
__FILENAME__ = config
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from string import punctuation

# PyParsing
from pyparsing import Or, Word, Literal, nums, alphanums, alphas, restOfLine

# Zato
from zato.common.haproxy import http_log, Config

logger = logging.getLogger(__name__)

# It's something Zato can understood and treat accordingly if such a token is
# found on any HAProxy configuration file's line.
zato_item_token = "# ZATO "

# PyParsing grammar for config values.

uri = Word(alphanums + punctuation)
backend_server = Literal("server").suppress() + Word(alphanums + ".-_") + \
                             Word(alphanums + ".-_") + Literal(":").suppress() + \
                             Word(nums) + restOfLine
simple_option = Literal("option").suppress() + Word(alphas)
frontend_bind = Literal("bind").suppress() + Or("*" | Word(alphanums + ".-_")) + Literal(":").suppress() + Word(nums)
maxconn = Literal("maxconn").suppress() + Word(nums)
timeout = Literal("timeout").suppress() + Word(alphas).suppress() + Word(nums)

global_log = Literal("log").suppress() + Word(alphanums + ".-_") + Literal(":").suppress() + \
                   Word(nums) + Word(alphanums) + Word(alphanums)
option_httpchk = Literal("option httpchk").suppress() + Word(alphas) + uri
monitor_uri = Literal("monitor-uri").suppress() + uri
stats_uri = Literal("stats uri").suppress() + uri
stats_socket = Literal("stats socket").suppress() + uri

# Config tokens recognized by the parser -> PyParsing grammar for their respective
# values.
config_tokens_grammar = {
    "global:log":global_log,
    "global:stats_socket":stats_socket,
    "defaults:timeout connect":timeout,
    "defaults:timeout client":timeout,
    "defaults:timeout server":timeout,
    "defaults:stats uri":stats_uri,
    "backend bck_http_plain:server": backend_server,
    "backend bck_http_plain:option httpchk": option_httpchk,
    "frontend front_http_plain:monitor-uri":monitor_uri,
    "frontend front_http_plain:option log-http-requests":simple_option,
    "frontend front_http_plain:bind":frontend_bind,
    "frontend front_http_plain:maxconn":maxconn,
}

backend_template = 'server {server_type}--{server_name} '
backend_template += '{address}:{port} {extra} '
backend_template += '{zato_item_token}backend {backend_type}:server--{server_name}'

def config_from_string(data):
    """ Given a string representing a HAProxy configuration, returns a Config
    object representing it.
    """
    config = Config()

    for line in data.split("\n"):
        if zato_item_token in line:
            value, config_token_name = line.split(zato_item_token)
            value = value.strip()

            for token_name in config_tokens_grammar:
                if config_token_name.startswith(token_name):
                    result = config_tokens_grammar[token_name].parseString(value)
                    config.set_value(token_name, result)
    return config

def string_from_config(config, config_template):
    """ Given a Config object and the current HAProxy configuration returns
    a string representing the new HAProxy configuration, which can be validated
    by HAProxy and optionally saved.
    """

    # Keys are HAProxy options understood by Zato. Values are two-element lists,
    # index 0 is a template to use for the new value and index 1 is the values
    # from the configuration to use in the template. Note that not all items
    # understood by Zato are given here, that's because not all of them are editable
    # by users and we simply won't receive them on input in the 'config' object.
    zato_item_dispatch = {
        "global:log": ("log {host}:{port} {facility} {level}", config["global_"]["log"]),

        "defaults:timeout connect": ("timeout connect {timeout_connect}", config["defaults"]),
        "defaults:timeout client": ("timeout client {timeout_client}", config["defaults"]),
        "defaults:timeout server": ("timeout server {timeout_server}", config["defaults"]),

        "frontend front_http_plain:monitor-uri": ("monitor-uri {monitor_uri}", config["frontend"]["front_http_plain"]),
        "frontend front_http_plain:bind": ("bind {address}:{port}", config["frontend"]["front_http_plain"]["bind"]),
        "frontend front_http_plain:maxconn": ("maxconn {maxconn}", config["frontend"]["front_http_plain"]),

        # That below, it looks .. well you know what I mean. But that's the price of
        # using a generic dispatch dictionary. Basically, it boils down to
        # getting a value to use for logging but in the HAProxy format. We were
        # given a string representing an integer and we need to translate it
        # back to a format understood by HAProxy, so that '1' translates into 'nolog' etc.

        "frontend front_http_plain:option log-http-requests":                                                               # noqa
          ("option {value}", dict(value=http_log[int(config["frontend"]["front_http_plain"]["log_http_requests"])][0])), # noqa
    }

    new_config = []
    for line in config_template:

        # Make sure we don't accidentally overwrite something that's not ours.
        if zato_item_token in line:
            if "bck_http" in line or [key for key in zato_item_dispatch if key in line]:

                # Let's see how much the line was indented in the template
                indent = len(line) - len(line.strip()) - 1 # -1 because of the \n
                new_line = " " * indent

                # Let's see to the simple options first..
                for zato_item, (template, value) in zato_item_dispatch.items():
                    if zato_item_token + zato_item in line:
                        new_line += template.format(**value) + " " + zato_item_token + zato_item

                # .. and the more complex ones now.
                if zato_item_token + "backend" in line and "--" in line:
                    line = line.split(zato_item_token + "backend")
                    backend_info = line[1].split("--")
                    backend_type, server_name = (backend_info[0].strip().split(":")[0], backend_info[1].strip())
                    server_type = backend_type.split("bck_")[1]

                    backend_values = {"backend_type": backend_type, "server_name":server_name,
                                      "server_type":server_type, "zato_item_token": zato_item_token}
                    backend_values.update(config["backend"][backend_type][server_name])

                    new_line += backend_template.format(**backend_values)
                else:
                    for name in('begin', 'end'):
                        prefix = '{}{}'.format(zato_item_token, name)
                        if line.startswith(prefix):
                            new_line += line
                new_line += "\n"
                new_config.append(new_line)
            else:
                new_config.append(line)
        else:
            new_config.append(line)

    return "".join(new_config)

########NEW FILE########
__FILENAME__ = haproxy_stats
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
import socket
from cStringIO import StringIO
from time import time
from traceback import format_exc

logger = logging.getLogger(__name__)

class HAProxyStats(object):
    """ Used for communicating with HAProxy through its local UNIX socket interface.
    """
    def __init__(self, socket_name=None):
        self.socket_name = socket_name

    def execute(self, command, extra="", timeout=200):
        """ Executes a HAProxy command by sending a message to a HAProxy's local
        UNIX socket and waiting up to 'timeout' milliseconds for the response.
        """

        if extra:
            command = command + ' ' + extra

        buff = StringIO()
        end = time() + timeout

        client = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)

        try:
            client.connect(self.socket_name)
            client.send(command + '\n')

            while time() <= end:
                data = client.recv(4096)
                if data:
                    buff.write(data)
                else:
                    return buff.getvalue()
        except Exception, e:
            msg = 'An error has occurred, e:[{e}]'.format(e=format_exc(e))
            logger.error(msg)
            raise
        finally:
            client.close()

########NEW FILE########
__FILENAME__ = main
#!/usr/bin/env python

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import os, sys

# Zato
from zato.agent.load_balancer.server import LoadBalancerAgent
from zato.common.util import store_pidfile

if __name__ == '__main__':
    store_pidfile(os.path.abspath(os.path.join(sys.argv[1], '..', '..')))
    lba = LoadBalancerAgent(sys.argv[1])
    lba.start_load_balancer()
    lba.serve_forever()

########NEW FILE########
__FILENAME__ = server
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import httplib, json, logging, logging.config, os, ssl, urllib
from collections import Counter
from datetime import datetime
from subprocess import Popen, PIPE
from tempfile import NamedTemporaryFile
from time import sleep
from traceback import format_exc

# pytz
from pytz import UTC

# Spring Python
from springpython.remoting.xmlrpc import SSLServer

# Zato
from zato.agent.load_balancer.config import backend_template, config_from_string, string_from_config, zato_item_token
from zato.agent.load_balancer.haproxy_stats import HAProxyStats
from zato.common import TRACE1, ZATO_OK
from zato.common.haproxy import haproxy_stats
from zato.common.repo import RepoManager

public_method_prefix = "_lb_agent_"
config_file = "zato.config"

logger = logging.getLogger("")
logging.addLevelName('TRACE1', TRACE1)

# All known HAProxy commands
haproxy_commands = {}
for version, commands in haproxy_stats.items():
    haproxy_commands.update(commands)

# We'll wait up to that many seconds for HAProxy to validate the config file.
HAPROXY_VALIDATE_TIMEOUT = 0.3

class LoadBalancerAgent(SSLServer):
    def __init__(self, repo_dir):

        self.repo_dir = os.path.abspath(repo_dir)
        self.json_config = json.loads(open(os.path.join(self.repo_dir, 'lb-agent.conf')).read())
        
        self.work_dir = os.path.abspath(os.path.join(self.repo_dir, self.json_config['work_dir']))
        self.haproxy_command = self.json_config['haproxy_command']
        self.verify_fields = self.json_config['verify_fields']

        self.keyfile = os.path.abspath(os.path.join(self.repo_dir, self.json_config['keyfile']))
        self.certfile = os.path.abspath(os.path.join(self.repo_dir, self.json_config['certfile']))
        self.ca_certs = os.path.abspath(os.path.join(self.repo_dir, self.json_config['ca_certs']))
        
        self.pid_path = os.path.abspath(os.path.join(self.repo_dir, '../', '../', self.json_config['pid_file']))

        log_config = os.path.abspath(os.path.join(self.repo_dir, self.json_config['log_config']))
        logging.config.fileConfig(log_config)

        self.config_path = os.path.join(self.repo_dir, config_file)
        self.config = self._read_config()
        self.start_time = datetime.utcnow().replace(tzinfo=UTC).isoformat()
        self.haproxy_stats = HAProxyStats(self.config.global_["stats_socket"])
        
        RepoManager(self.repo_dir).ensure_repo_consistency()

        super(LoadBalancerAgent, self).__init__(
            host=self.json_config['host'],
            port=self.json_config['port'], keyfile=self.keyfile, certfile=self.certfile,
            ca_certs=self.ca_certs, cert_reqs=ssl.CERT_REQUIRED,
            verify_fields=self.verify_fields)
        
    def _popen(self, command, timeout, timeout_msg, rc_non_zero_msg, common_msg=''):
        """ Runs a command in background and returns its return_code, stdout and stderr.
        stdout and stderr will be None if return code = 0
        """
        stdout, stderr = None, None
        
        # Run the command
        p = Popen(command, stdout=PIPE, stderr=PIPE)
        
        # Sleep as long as requested and poll for results
        sleep(timeout)
        p.poll()

        if p.returncode is None:
            msg = timeout_msg + common_msg + 'command:[{}]'.format(command)
            raise Exception(msg.format(timeout))
        else:
            if p.returncode != 0:
                stdout, stderr = p.communicate()
                msg = rc_non_zero_msg + common_msg + 'command:[{}], return code:[{}], stdout:[{}], stderr:[{}] '.format(
                    command, p.returncode, stdout, stderr)
                raise Exception(msg)
            
        return p.returncode

    def _re_start_load_balancer(self, timeout_msg, rc_non_zero_msg, additional_params=[]):
        """ A common method for (re-)starting HAProxy.
        """
        command = [self.haproxy_command, '-D', '-f', self.config_path, '-p', self.pid_path]
        command.extend(additional_params)
        self._popen(command, 5.0, timeout_msg, rc_non_zero_msg)
        
    def start_load_balancer(self):
        """ Starts the HAProxy load balancer in background.
        """
        self._re_start_load_balancer("HAProxy didn't start in [{}] seconds. ", 'Failed to start HAProxy. ')

    def restart_load_balancer(self):
        """ Restarts the HAProxy load balancer without disrupting existing connections.
        """
        additional_params = ['-sf', open(self.pid_path).read().strip()]
        self._re_start_load_balancer("Could not restart in [{}] seconds. ", 'Failed to restart HAProxy. ', additional_params)

    def _dispatch(self, method, params):
        try:
            return SSLServer._dispatch(self, method, params)
        except Exception, e:
            logger.error(format_exc(e))
            raise e

    def register_functions(self):
        """ All methods with the '_lb_agent_' prefix will be exposed through
        SSL XML-RPC after chopping off the prefix, so that self._lb_agent_ping
        becomes a 'ping' method, self._lb_agent_get_uptime_info -> 'get_uptime_info'
        etc.
        """
        for item in sorted(dir(self)):
            if item.startswith(public_method_prefix):
                public_name = item.split(public_method_prefix)[1]
                attr = getattr(self, item)
                msg = "Registering [{attr}] under public name [{public_name}]"
                logger.info(msg.format(attr=attr, public_name=public_name))  # TODO: Add logging config
                self.register_function(attr, public_name)
                
    def _read_config_string(self):
        """ Returns the HAProxy config as a string.
        """
        return open(self.config_path).read()

    def _read_config(self):
        """ Read and parse the HAProxy configuration.
        """
        return config_from_string(self._read_config_string())
    
    def _validate(self, config_string):
        """ Writes the config into a temporary file and validates it using the HAProxy's
        -c check mode.
        """
        try:
            with NamedTemporaryFile(prefix='zato-tmp', dir=self.work_dir) as tf:

                tf.write(config_string)
                tf.flush()
                
                common_msg = 'config_file:[{}]'
                common_msg = common_msg.format(open(tf.name).read())
                
                timeout_msg = "HAProxy didn't respond in [{}] seconds. "
                rc_non_zero_msg = 'Failed to validate the config file using HAProxy. '
                
                command = [self.haproxy_command, '-c', '-f', tf.name]
                self._popen(command, HAPROXY_VALIDATE_TIMEOUT, timeout_msg, rc_non_zero_msg, common_msg)

        except Exception, e:
            msg = 'Caught an exception, e:[{e}]'.format(e=format_exc(e))
            logger.error(msg)
            raise Exception(msg)

    def _save_config(self, config_string):
        """ Save a new HAProxy config file on disk. It is assumed the file
        has already been validated.
        """
        # TODO: Use local bzr repo here
        f = open(self.config_path, "wb")
        f.write(config_string)
        f.close()
        
        self.config = self._read_config()
        
    def _validate_save_config_string(self, config_string, save):
        """ Given a string representing the HAProxy config file it first validates
        it and then optionally saves it and restarts the load balancer.
        """
        self._validate(config_string)

        if save:
            self._save_config(config_string)
            self.restart_load_balancer()

        return True

# ##############################################################################

    def _show_stat(self):
        stat = self.haproxy_stats.execute('show stat')

        for line in stat.splitlines():
            if line.startswith('#') or not line.strip():
                continue
            line = line.split(',')
            
            haproxy_name = line[0]
            haproxy_type_or_name = line[1]

            if haproxy_name.startswith('bck') and not haproxy_type_or_name == 'BACKEND':
                backend_name, state = line[1], line[17]
                access_type, server_name = backend_name.split('--')
                
                yield access_type, server_name, state

    def _lb_agent_validate_save_source_code(self, source_code, save=False):
        """ Validate or validates & saves (if 'save' flag is True) an HAProxy
        configuration passed in as a string. Note that the validation step is always performed.
        """
        return self._validate_save_config_string(source_code, save)

    def _lb_agent_validate_save(self, lb_config, save=False):
        """ Validate or validates /and/ saves (if 'save' flag is True) an HAProxy
        configuration. Note that the validation step is always performed.
        """
        config_string = string_from_config(lb_config, open(self.config_path).readlines())
        return self._validate_save_config_string(config_string, save)

    def _lb_agent_get_servers_state(self):
        """ Return a three-key dictionary describing the current state of all Zato servers
        as seen by HAProxy. Keys are "UP" for running servers, "DOWN" for those
        that are unavailable, and "MAINT" for servers in the maintenance mode.
        Values are dictionaries of access type -> names of servers. For instance,
        if there are three servers, one is UP, the second one is DOWN and the
        third one is MAINT, the result will be:

        {
          'UP': {'http_plain': ['SERVER.1']},
          'DOWN': {'http_plain': ['SERVER.2']},
          'MAINT': {'http_plain': ['SERVER.3']},
        }
        """
        servers_state = {
            'UP': {'http_plain':[]},
            'DOWN': {'http_plain':[]},
            'MAINT': {'http_plain':[]},
        }
        
        for access_type, server_name, state in self._show_stat():
            # Don't bail out when future HAProxy versions introduce states
            # we aren't currently aware of.
            if state not in servers_state:
                msg = 'Encountered unknown state [{state}], recognized ones are [{states}]'
                logger.warning(msg.format(state=state, states=str(sorted(servers_state))))
            else:
                servers_state[state][access_type].append(server_name)
        return servers_state
    
    def _lb_agent_get_server_data_dict(self, name=None):
        """ Returns a dictionary whose keys are server names and values are their
        access types and the server's status as reported by HAProxy.
        """
        backend_config = self.config.backend['bck_http_plain']
        servers = {}
        
        def _dict(access_type, state, server_name):
            return {
                'access_type':access_type,
                'state':state,
                'address': '{}:{}'.format(backend_config[server_name]['address'], backend_config[server_name]['port'])
            }
        
        for access_type, server_name, state in self._show_stat():
            if name:
                if name == server_name:
                    servers[server_name] = _dict(access_type, state, server_name)
            else:
                servers[server_name] = _dict(access_type, state, server_name)
            
        return servers
    
    def _lb_agent_rename_server(self, old_name, new_name):
        """ Renames the server, validates and saves the config.
        """
        if old_name == new_name:
            msg = 'Skipped renaming, old_name:[{}] is the same as new_name:[{}]'.format(old_name, new_name)
            self.logger.warn(msg)
            return True
            
        new_config = []
        config_string = self._read_config_string()
        old_servers = Counter()
        new_servers = Counter()

        def _get_lines():
            for line in config_string.splitlines():
                yield line
               
        old_server = '# ZATO backend bck_http_plain:server--{}'.format(old_name)
        new_server = '# ZATO backend bck_http_plain:server--{}'.format(new_name)
        
        for line in _get_lines():
            if old_server in line:
                old_servers[old_name] += 1

            if new_server in line:
                new_servers[new_name] += 1
                
        if not old_servers[old_name]:
            raise Exception("old_name:[{}] not found in the load balancer's configuration".format(old_name))
        
        if new_servers[new_name]:
            raise Exception('new_name:[{}] is not unique'.format(new_name))
        
        for line in _get_lines():
            if old_server in line:
                line = line.replace(old_name, new_name)
            new_config.append(line)
            
        self._validate_save_config_string('\n'.join(new_config), True)
        
        return True
    
    def _lb_agent_add_remove_server(self, action, server_name):
        bck_http_plain = self.config.backend['bck_http_plain']
        
        if action == 'remove':
            del bck_http_plain[server_name]
        elif action == 'add':
            bck_http_plain[server_name] = {}
            bck_http_plain[server_name]['extra'] = 'check inter 2s rise 2 fall 2'
            bck_http_plain[server_name]['address'] = '127.0.0.1'
            bck_http_plain[server_name]['port'] = '123456'
        else:
            raise Exception('Unrecognized action:[{}]'.format(action))
        
        new_config = []
        config_string = self._read_config_string()

        for line in config_string.splitlines():
            if '# ZATO backend bck_http_plain' in line:
                continue
            else:
                backends = []
                if '# ZATO begin backend bck_http_plain' in line:
                    for server_name in bck_http_plain:
                        data_dict = {
                            'server_type':'http_plain',
                            'server_name':server_name,
                            'address':bck_http_plain[server_name]['address'],
                            'port':bck_http_plain[server_name]['port'],
                            'extra':bck_http_plain[server_name]['extra'],
                            'zato_item_token':zato_item_token,
                            'backend_type':'bck_http_plain',
                            
                        }
                        backends.append(backend_template.format(**data_dict))
                line += ('\n' * 2) + '\n'.join(backends)
            new_config.append(line.rstrip())
            
        self._validate_save_config_string('\n'.join(new_config), True)
        
        return True

    def _lb_agent_execute_command(self, command, timeout, extra=""):
        """ Execute an HAProxy command through its UNIX socket interface.
        """
        command = haproxy_commands[int(command)][0]
        timeout = int(timeout)

        result = self.haproxy_stats.execute(command, extra, timeout)

        # Special-case the request for describing the commands available.
        # There's no 'describe commands' command in HAProxy but HAProxy is
        # nice enough to return a usage info when it encounters an unknown
        # command which we parse and return to the caller.
        if command == "ZATO_DESCRIBE_COMMANDS":
            result = "\n\n" + "\n".join(result.splitlines()[1:])

        return result

    def _lb_agent_haproxy_version_info(self):
        """ Return a three-element tuple describing HAProxy's version,
        similar to what stdlib's sys.version_info does.
        """
        # 'show info' is always available and we use it for determining the HAProxy version.
        info = self.haproxy_stats.execute("show info")
        for line in info.splitlines():
            if line.startswith("Version:"):
                version = line.split("Version:")[1]
                return version.strip().split(".")

    def _lb_agent_ping(self):
        """ Always return ZATO_OK.
        """
        return ZATO_OK

    def _lb_agent_get_config(self):
        """ Return those pieces of an HAProxy configuration that are understood
        by Zato.
        """
        return self.config
    
    def _lb_agent_get_config_source_code(self):
        """ Return the HAProxy configuration file's source.
        """
        return self._read_config_string()

    def _lb_agent_get_uptime_info(self):
        """ Return the agent's (not HAProxy's) uptime info, currently returns
        only the time it was started at.
        """
        return self.start_time

    def _lb_agent_is_haproxy_alive(self):
        """ Invoke HAProxy through HTTP monitor_uri and return ZATO_OK if
        HTTP status code is 200. Raise Exception otherwise.
        """
        host = self.config.frontend["front_http_plain"]["bind"]["address"]
        port = self.config.frontend["front_http_plain"]["bind"]["port"]
        path = self.config.frontend["front_http_plain"]["monitor_uri"]
        url = "http://{host}:{port}{path}".format(host=host, port=port, path=path)

        try:
            conn = urllib.urlopen(url)
        except Exception, e:
            msg = "Could not open URL [{url}], e:[{e}]".format(url=url, e=format_exc(e))
            logger.error(msg)
            raise Exception(msg)
        else:
            try:
                code = conn.getcode()
                if code == httplib.OK:
                    return ZATO_OK
                else:
                    msg = "Could not open URL [{url}], HTTP code:[{code}]".format(url=url, code=code)
                    logger.error(msg)
                    raise Exception(msg)
            finally:
                conn.close()

    def _lb_agent_get_work_config(self):
        """ Return the agent's basic configuration.
        """
        return {"work_dir":self.work_dir, "haproxy_command":self.haproxy_command, # noqa
                "keyfile":self.keyfile, "certfile":self.certfile,                 # noqa
               "ca_certs":self.ca_certs, "verify_fields":self.verify_fields}      # noqa

########NEW FILE########
__FILENAME__ = client
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging, time
from traceback import format_exc

# anyjson
from anyjson import dumps, loads

# gevent
from gevent import spawn

# Bunch
from bunch import Bunch

# Redis
import redis

# Zato
from zato.common import BROKER, TRACE1, ZATO_NONE
from zato.common.broker_message import KEYS, MESSAGE_TYPE, TOPICS
from zato.common.kvdb import LuaContainer
from zato.common.util import new_cid

logger = logging.getLogger(__name__)

REMOTE_END_CLOSED_SOCKET = 'Socket closed on remote end'
NEEDS_TMP_KEY = [v for k,v in TOPICS.items() if k in(
    MESSAGE_TYPE.TO_PARALLEL_ANY,
)]

CODE_RENAMED = 10
CODE_NO_SUCH_FROM_KEY = 11

def BrokerClient(kvdb, client_type, topic_callbacks, _initial_lua_programs):
    
    # Imported here so it's guaranteed to be monkey-patched using gevent.monkey.patch_all by whoever called us
    from thread import start_new_thread

    class _ClientThread(object):
        def __init__(self, kvdb, pubsub, name, topic_callbacks=None, on_message=None):
            self.kvdb = kvdb
            self.pubsub = pubsub
            self.topic_callbacks = topic_callbacks
            self.on_message = on_message
            self.client = None
            self.keep_running = ZATO_NONE

        def run(self):

            # We're in a new thread and we can initialize the KVDB connection now.
            self.kvdb.init()

            if self.pubsub == 'sub':
                self.client = self.kvdb.pubsub()
                self.client.subscribe(self.topic_callbacks.keys())
                self.keep_running = True

                try:
                    try:
                        while self.keep_running:
                            for msg in self.client.listen():
                                self.on_message(Bunch(msg))
                    except redis.ConnectionError, e:
                        if e.message != REMOTE_END_CLOSED_SOCKET:  # Hm, there's no error code, only the message
                            logger.info('Caught `%s`, will quit now', e.message)
                            raise
                except KeyboardInterrupt:
                    self.keep_running = False

            else:
                self.client = self.kvdb
                self.keep_running = True

        def publish(self, topic, msg):
            if logger.isEnabledFor(TRACE1):
                logger.log(TRACE1, 'Publishing [{}] to [{}]'.format(msg, topic))
            return self.client.publish(topic, msg)

        def close(self):
            self.keep_running = False
            self.client.close()

    class _BrokerClient(object):
        """ Zato broker client. Starts two background threads, one for publishing
        and one for receiving of the messages.

        There may be 3 types of messages sent out:

        1) to the singleton server
        2) to all the servers/connectors/all connectors of a certain type (e.g. only AMQP ones)
        3) to one of the parallel servers

        1) and 2) are straightforward, a message is being published on a topic,
           off which it is read by broker client(s).

        3) needs more work - the actual message is added to Redis and what is really
           being published is a Redis key it's been stored under. The first client
           to read it will be the one to handle it.

           Yup, it means the messages are sent across to all of the clients
           and the winning one is the one that picked up the Redis message; it's not
           that bad as it may seem, there will be at most as many clients as there
           are servers in the cluster and truth to be told, Zero MQ < 3.x also would
           do client-side PUB/SUB filtering and it did scale nicely.
        """
        def __init__(self, kvdb, client_type, topic_callbacks, initial_lua_programs):
            self.kvdb = kvdb
            self.decrypt_func = kvdb.decrypt_func
            self.name = '{}-{}'.format(client_type, new_cid())
            self.topic_callbacks = topic_callbacks
            self.lua_container = LuaContainer(self.kvdb.conn, initial_lua_programs)

        def run(self):
            logger.info('Starting broker client, host:[{}], port:[{}], name:[{}], topics:[{}]'.format(
                self.kvdb.config.host, self.kvdb.config.port, self.name, sorted(self.topic_callbacks)))

            self.pub_client = _ClientThread(self.kvdb.copy(), 'pub', self.name)
            self.sub_client = _ClientThread(self.kvdb.copy(), 'sub', self.name, self.topic_callbacks, self.on_message)

            start_new_thread(self.pub_client.run, ())
            start_new_thread(self.sub_client.run, ())

            for client in(self.pub_client, self.sub_client):
                while client.keep_running == ZATO_NONE:
                    time.sleep(0.01)

        def publish(self, msg, msg_type=MESSAGE_TYPE.TO_PARALLEL_ALL):
            msg['msg_type'] = msg_type
            topic = TOPICS[msg_type]
            self.pub_client.publish(topic, dumps(msg))

        def invoke_async(self, msg, msg_type=MESSAGE_TYPE.TO_PARALLEL_ANY, expiration=BROKER.DEFAULT_EXPIRATION):
            msg['msg_type'] = msg_type

            try:
                msg = dumps(msg)
            except Exception, e:
                error_msg = 'JSON serialization failed for msg:[%r], e:[%s]'
                logger.error(error_msg, msg, format_exc(e))
                raise
            else:
                topic = TOPICS[msg_type]
                key = broker_msg = b'zato:broker{}:{}'.format(KEYS[msg_type], new_cid())
                
                self.kvdb.conn.set(key, str(msg))
                self.kvdb.conn.expire(key, expiration)  # In seconds

                self.pub_client.publish(topic, broker_msg)

        def on_message(self, msg):
            if logger.isEnabledFor(logging.DEBUG):
                logger.debug('Got broker message:[{}]'.format(msg))

            if msg.type == 'message':

                # Replace payload with stuff read off the KVDB in case this is where the actual message happens to reside.
                if msg.channel in NEEDS_TMP_KEY:
                    tmp_key = '{}.tmp'.format(msg.data)

                    if self.lua_container.run_lua('zato.rename_if_exists', [msg.data, tmp_key]) == CODE_NO_SUCH_FROM_KEY:
                        payload = None
                    else:
                        payload = self.kvdb.conn.get(tmp_key)
                        self.kvdb.conn.delete(tmp_key)  # Note that it would've expired anyway
                        if not payload:
                            logger.warning('No KVDB payload for key [{}] (already expired?)'.format(tmp_key))
                        else:
                            payload = loads(payload)
                else:
                    payload = loads(msg.data)

                if payload:
                    payload = Bunch(payload)
                    if logger.isEnabledFor(logging.DEBUG):
                        logger.debug('Got broker message payload [{}]'.format(payload))
                        
                    callback = self.topic_callbacks[msg.channel]
                    spawn(callback, payload)

                else:
                    if logger.isEnabledFor(logging.DEBUG):
                        logger.debug('No payload in msg:[{}]'.format(msg))

        def close(self):
            for client in(self.pub_client, self.sub_client):
                client.keep_running = False
                client.kvdb.close()

    client = _BrokerClient(kvdb, client_type, topic_callbacks, _initial_lua_programs)
    start_new_thread(client.run, ())
    
    return client

########NEW FILE########
__FILENAME__ = thread_client
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging, time
from threading import Thread
from traceback import format_exc

# anyjson
from anyjson import dumps, loads

# Bunch
from bunch import Bunch

# Redis
import redis

# Zato
from zato.common import BROKER, TRACE1, ZATO_NONE
from zato.common.broker_message import KEYS, MESSAGE_TYPE, TOPICS
from zato.common.util import new_cid

logger = logging.getLogger(__name__)

REMOTE_END_CLOSED_SOCKET = 'Socket closed on remote end'
NEEDS_TMP_KEY = [v for k,v in TOPICS.items() if k in(
    MESSAGE_TYPE.TO_PARALLEL_ANY,
)]

class _ClientThread(Thread):
    def __init__(self, kvdb, pubsub, name, topic_callbacks=None, on_message=None):
        Thread.__init__(self)
        self.kvdb = kvdb
        self.pubsub = pubsub
        self.topic_callbacks = topic_callbacks
        self.on_message = on_message
        self.client = None
        self.keep_running = ZATO_NONE
        
    def run(self):
        
        # We're in a new thread and we can initialize the KVDB connection now.
        self.kvdb.init()
        self.keep_running = True

        if self.pubsub == 'sub':
            self.client = self.kvdb.pubsub()
            self.client.subscribe(self.topic_callbacks.keys())

            try:
                try:
                    while self.keep_running:
                        for msg in self.client.listen():
                            self.on_message(Bunch(msg))
                except redis.ConnectionError, e:
                    if e.message != REMOTE_END_CLOSED_SOCKET:  # Hm, there's no error code, only the message
                        logger.info('Caught `%s`, will quit now', e.message)
                        raise
            except KeyboardInterrupt:
                self.keep_running = False

        else:
            self.client = self.kvdb
            
    def publish(self, topic, msg):
        if logger.isEnabledFor(TRACE1):
            logger.log(TRACE1, 'Publishing [{}] to [{}]'.format(msg, topic))
        return self.client.publish(topic, msg)
    
    def close(self):
        self.keep_running = False
        self.client.close()

class BrokerClient(Thread):
    """ Zato broker client. Starts two background threads, one for publishing
    and one for receiving of the messages.
    
    There may be 3 types of messages sent out:
    
    1) to the singleton server
    2) to all the servers/connectors/all connectors of a certain type (e.g. only AMQP ones)
    3) to one of the parallel servers
    
    1) and 2) are straightforward, a message is being published on a topic,
       off which it is read by broker client(s).
    
    3) needs more work - the actual message is added to Redis and what is really
       being published is a Redis key it's been stored under. The first client
       to read it will be the one to handle it.
       
       Yup, it means the messages are sent across to all of the clients
       and the winning one is the one that picked up the Redis message; it's not
       that bad as it may seem, there will be at most as many clients as there
       are servers in the cluster and truth to be told, Zero MQ < 3.x also would
       do client-side PUB/SUB filtering and it did scale nicely.
    """
    def __init__(self, kvdb, client_type, topic_callbacks):
        Thread.__init__(self)
        self.kvdb = kvdb
        self.decrypt_func = kvdb.decrypt_func
        self.name = '{}-{}'.format(client_type, new_cid())
        self.topic_callbacks = topic_callbacks
        
    def run(self):
        logger.info('Starting broker client, host:[{}], port:[{}], name:[{}], topics:[{}]'.format(
            self.kvdb.config.host, self.kvdb.config.port, self.name, sorted(self.topic_callbacks)))
        
        self.pub_client = _ClientThread(self.kvdb.copy(), 'pub', self.name)
        self.sub_client = _ClientThread(self.kvdb.copy(), 'sub', self.name, self.topic_callbacks, self.on_message)
        
        self.pub_client.start()
        self.sub_client.start()
        
        for client in(self.pub_client, self.sub_client):
            while client.keep_running == ZATO_NONE:
                time.sleep(0.01)
        
    def publish(self, msg, msg_type=MESSAGE_TYPE.TO_PARALLEL_ALL):
        msg['msg_type'] = msg_type
        topic = TOPICS[msg_type]
        self.pub_client.publish(topic, dumps(msg))
        
    def invoke_async(self, msg, msg_type=MESSAGE_TYPE.TO_PARALLEL_ANY, expiration=BROKER.DEFAULT_EXPIRATION):
        msg['msg_type'] = msg_type
        
        try:
            msg = dumps(msg)
        except Exception, e:
            error_msg = 'JSON serialization failed for msg:[%r], e:[%s]'
            logger.error(error_msg, msg, format_exc(e))
            raise
        else:
            topic = TOPICS[msg_type]
            key = broker_msg = b'zato:broker{}:{}'.format(KEYS[msg_type], new_cid())
            
            self.kvdb.conn.set(key, str(msg))
            self.kvdb.conn.expire(key, expiration)  # In seconds
            
            self.pub_client.publish(topic, broker_msg)
        
    def on_message(self, msg):
        if logger.isEnabledFor(logging.DEBUG):
            logger.debug('Got broker message:[{}]'.format(msg))
        
        if msg.type == 'message':
    
            # Replace payload with stuff read off the KVDB in case this is where the actual message happens to reside.
            if msg.channel in NEEDS_TMP_KEY:
                tmp_key = '{}.tmp'.format(msg.data)
                
                try:
                    self.kvdb.conn.rename(msg.data, tmp_key)
                except redis.ResponseError, e:
                    if e.message != 'ERR no such key':  # Doh, I hope Redis guys don't change it out of a sudden :/
                        raise
                    else:
                        payload = None
                else:
                    payload = self.kvdb.conn.get(tmp_key)
                    self.kvdb.conn.delete(tmp_key)  # Note that it would've expired anyway
                    if not payload:
                        logger.warning('No KVDB payload for key [{}] (already expired?)'.format(tmp_key))
                    else:
                        payload = loads(payload)
            else:
                payload = loads(msg.data)
                
            if payload:
                payload = Bunch(payload)
                if logger.isEnabledFor(logging.DEBUG):
                    logger.debug('Got broker message payload [{}]'.format(payload))
                    
                return self.topic_callbacks[msg.channel](payload)
            
            else:
                if logger.isEnabledFor(logging.DEBUG):
                    logger.debug('No payload in msg:[{}]'.format(msg))

    def close(self):
        for client in(self.pub_client, self.sub_client):
            client.keep_running = False
            client.kvdb.close()

########NEW FILE########
__FILENAME__ = ca_create_ca
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import os, uuid, tempfile

# Zato
from zato.cli import ca_defaults, default_ca_name, ZatoCommand

openssl_template = '''
dir                            = {target_dir}

[ ca ]
default_ca                     = CA_default

[ CA_default ]
serial                         = $dir/ca-material/ca-serial
database                       = $dir/ca-material/ca-certindex
new_certs_dir                  = $dir
certificate                    = $dir/ca-material/ca-cert.pem
private_key                    = $dir/ca-material/ca-key.pem
default_days                   = 3650
default_md                     = sha1
preserve                       = no
email_in_dn                    = no
nameopt                        = default_ca
certopt                        = default_ca
policy                         = policy_match

[ policy_match ]
countryName                    = match
stateOrProvinceName            = match
organizationName               = match
organizationalUnitName         = supplied
commonName                     = supplied

[ req ]
default_bits                   = 4096
default_md                     = sha1
string_mask                    = nombstr
distinguished_name             = req_distinguished_name

[ req_distinguished_name ]
0.organizationName             = Organization Name (company)
organizationalUnitName         = Organization Unit Name (department, division)
localityName                   = Locality Name (city, district)
stateOrProvinceName            = State or Province Name (full name)
countryName                    = Country Name (2 letter code)
countryName_min                = 2
countryName_max                = 2
commonName                     = Common Name (hostname, IP, or your name)
commonName_max                 = 64

0.organizationName_default     = {organization}
organizationalUnitName_default = {organizational_unit}
localityName_default           = {locality}
stateOrProvinceName_default    = {state_or_province}
countryName_default            = {country}
commonName_default             = {common_name}

[ v3_ca ]
basicConstraints               = CA:TRUE
subjectKeyIdentifier           = hash
authorityKeyIdentifier         = keyid:always,issuer:always

[ v3_server ]
basicConstraints               = CA:FALSE
subjectKeyIdentifier           = hash
extendedKeyUsage               = serverAuth

[ v3_client_server ]
basicConstraints               = CA:FALSE
subjectKeyIdentifier           = hash
extendedKeyUsage               = serverAuth,clientAuth
'''

class Create(ZatoCommand):
    """Creates a new certificate authority
    """
    opts = [
        {'name':'--organization', 'help':'CA organization name (defaults to {organization})'.format(**ca_defaults)},
        {'name':'--organizational-unit',
            'help':'CA organizational unit name (defaults to {default})'.format(default=default_ca_name)},
        {'name':'--locality', 'help':'CA locality name (defaults to {locality})'.format(**ca_defaults)},
        {'name':'--state-or-province',
            'help':'CA state or province name (defaults to {state_or_province})'.format(**ca_defaults)},
        {'name':'--country', 'help':'CA country (defaults to {country})'.format(**ca_defaults)},
        {'name':'--common-name', 'help':'CA common name (defaults to {default})'.format(default=default_ca_name)},
    ]

    needs_empty_dir = True

    def __init__(self, args):
        super(Create, self).__init__(args)
        self.target_dir = os.path.abspath(args.path)

    def execute(self, args, show_output=True):

        # Prepare the directory layout
        os.mkdir(os.path.join(self.target_dir, 'ca-material'))
        open(os.path.join(self.target_dir, 'ca-material/ca-serial'), 'w').write('01')
        open(os.path.join(self.target_dir, 'ca-material/ca-password'), 'w').write(uuid.uuid4().hex)
        open(os.path.join(self.target_dir, 'ca-material/ca-certindex'), 'w')
        open(os.path.join(self.target_dir, 'ca-material/ca-certindex.attr'), 'w').write('unique_subject = no')
        open(os.path.join(self.target_dir, 'ca-material/openssl-template.conf'), 'w').write(openssl_template)

        # Create the CA's cert and the private key

        template_args = {}
        for name in('organization', 'organizational_unit', 'locality', 'state_or_province', 'country'):
            value = self._get_arg(args, name, ca_defaults[name])
            template_args[name] = value

        template_args['common_name'] = self._get_arg(args, 'common_name', default_ca_name)
        template_args['target_dir'] = self.target_dir

        f = tempfile.NamedTemporaryFile()
        f.write(openssl_template.format(**template_args))
        f.flush()

        cmd = """openssl req -batch -new -x509 -newkey rsa:4096 -extensions v3_ca -keyout \
                   {target_dir}/ca-material/ca-key.pem -out {target_dir}/ca-material/ca-cert.pem -days 3650 \
                   -config {config} -passout file:{target_dir}/ca-material/ca-password >/dev/null 2>&1""".format(
                       config=f.name, target_dir=self.target_dir)
        os.system(cmd)
        f.close()

        for name in('csr', 'cert', 'priv', 'pub'):
            os.mkdir(os.path.join(self.target_dir, 'out-{}'.format(name)))

        # Mark the directory being a Zato CA one.
        open(os.path.join(self.target_dir, '.zato-ca-dir'), 'w')
        
        # Initial info
        self.store_initial_info(self.target_dir, self.COMPONENTS.CA.code)

        if show_output:
            if self.verbose:
                msg = 'Successfully created a certificate authority in {path}'.format(
                    path=os.path.abspath(os.path.join(os.getcwd(), self.target_dir)))
                self.logger.debug(msg)
            else:
                self.logger.info('OK')

########NEW FILE########
__FILENAME__ = ca_create_lb_agent
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Zato
from zato.cli import CACreateCommand, common_ca_create_opts

class Create(CACreateCommand):
    """ Creates crypto material for a Zato load-balancer agent
    """
    opts = [
        {'name':'organizational-unit', 'help':'Organizational unit name'},
    ]
    opts += common_ca_create_opts

    def get_file_prefix(self, file_args):
        return 'lb-agent'

    def get_organizational_unit(self, args):
        return 'zato-lb-agent'

    def execute(self, args, show_output=True):
        self._execute(args, 'v3_server', show_output)

########NEW FILE########
__FILENAME__ = ca_create_server
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Zato
from zato.cli import CACreateCommand, common_ca_create_opts

class Create(CACreateCommand):
    """ Creates crypto material for a Zato server
    """
    opts = [
        {'name':'cluster_name', 'help':'Cluster name'},
        {'name':'server_name', 'help':'Server name'},
        {'name':'--organizational-unit', 'help':'Organizational unit name (defaults to cluster_name:server_name)'},
    ]
    opts += common_ca_create_opts

    def get_file_prefix(self, file_args):
        return '{cluster_name}-{server_name}'.format(**file_args)

    def get_organizational_unit(self, args):
        return args.cluster_name + ':' + args.server_name

    def execute(self, args, show_output=True):
        self._execute(args, 'v3_client_server', show_output)

########NEW FILE########
__FILENAME__ = ca_create_web_admin
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Zato
from zato.cli import CACreateCommand, common_ca_create_opts

class Create(CACreateCommand):
    """ Creates crypto material for a Zato web console
    """
    opts = [
        {'name':'--organizational-unit', 'help':'Organizational unit name'},
    ]
    opts += common_ca_create_opts

    def get_file_prefix(self, file_args):
        return 'web-admin'

    def get_organizational_unit(self, args):
        return 'web-admin'

    def execute(self, args, show_output=True):
        self._execute(args, 'v3_client_server', show_output)

########NEW FILE########
__FILENAME__ = check_config
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from glob import glob
from json import loads
from os.path import abspath, exists, join

# Bunch
from bunch import Bunch

# ConfigObj
from configobj import ConfigObj

# Zato
from zato.cli import ManageCommand
from zato.common.crypto import CryptoManager
from zato.common.kvdb import KVDB
from zato.common.odb import create_pool, ping_queries
from zato.common.util import is_port_taken

class CheckConfig(ManageCommand):
    """ Checks config of a Zato component (currently limited to servers only)
    """
    def get_json_conf(self, conf_name, repo_dir=None):
        repo_dir = repo_dir or join(self.config_dir, 'repo')
        return loads(open(join(repo_dir, conf_name)).read())

    def ensure_port_free(self, prefix, port, address):
        if is_port_taken(port):
            raise Exception('{} check failed. Address `{}` already taken.'.format(prefix, address))

    def ensure_json_config_port_free(self, conf_name, prefix):
        conf = self.get_json_conf(conf_name)
        address = '{}:{}'.format(conf['host'], conf['port'])
        self.ensure_port_free(prefix, conf['port'], address)

    def ping_sql(self, cm, engine_params):
        
        query = ping_queries[engine_params['engine']]

        session = create_pool(cm, engine_params)
        session.execute(query)
        session.close()

        if self.show_output:
            self.logger.info('SQL ODB connection OK')

    def check_sql_odb_server(self, cm, conf):
        engine_params = dict(conf['odb'].items())
        engine_params['extra'] = {}
        engine_params['pool_size'] = 1
        self.ping_sql(cm, engine_params)

    def check_sql_odb_web_admin(self, cm, conf):
        pairs = (
            ('engine', 'db_type'),
            ('username', 'DATABASE_USER'),
            ('password', 'DATABASE_PASSWORD'),
            ('host', 'DATABASE_HOST'),
            ('port', 'DATABASE_PORT'),
            ('db_name', 'DATABASE_NAME'),
        )
        engine_params = {'extra':{}, 'pool_size':1}
        for sqlalch_name, django_name in pairs:
            engine_params[sqlalch_name] = conf[django_name]

        self.ping_sql(cm, engine_params)

    def on_server_check_kvdb(self, cm, conf):

        kvdb_config = Bunch(dict(conf['kvdb'].items()))
        kvdb = KVDB(None, kvdb_config, cm.decrypt)
        kvdb.init()
        
        kvdb.conn.info()
        kvdb.close()

        if self.show_output:
            self.logger.info('Redis connection OK')

    def ensure_no_pidfile(self):
        pidfile = abspath(join(self.component_dir, 'pidfile'))
        if exists(pidfile):
            raise Exception('Cannot proceed, found pidfile `{}`'.format(pidfile))

        if self.show_output:
            self.logger.info('No such pidfile `{}`, OK'.format(pidfile))

    def on_server_check_port_available(self, server_conf):
        address = server_conf['main']['gunicorn_bind']
        _, port = address.split(':')
        self.ensure_port_free('Server', int(port), address)

    def get_crypto_manager_conf(self, conf_file=None, priv_key_location=None, repo_dir=None):
        repo_dir = repo_dir or join(self.config_dir, 'repo')
        conf = None

        if not priv_key_location:
            conf = ConfigObj(join(repo_dir, conf_file))
            priv_key_location = priv_key_location or abspath(join(repo_dir, conf['crypto']['priv_key_location']))

        cm = CryptoManager(priv_key_location=priv_key_location)
        cm.load_keys()

        return cm, conf

    def _on_server(self, args):
        cm, conf = self.get_crypto_manager_conf('server.conf')

        self.check_sql_odb_server(cm, conf)
        self.on_server_check_kvdb(cm, conf)

        # enmasse actually needs a running server and it will set the flags below to False.
        if getattr(args, 'ensure_no_pidfile', True):
            self.ensure_no_pidfile()

        if getattr(args, 'check_server_port_available', True):
            self.on_server_check_port_available(conf)

    def _on_lb(self, *ignored_args, **ignored_kwargs):
        self.ensure_no_pidfile()
        repo_dir = join(self.config_dir, 'repo')

        # Load-balancer's agent
        self.ensure_json_config_port_free('lb-agent.conf', 'Load balancer agent')

        # Load balancer itself
        lb_address = None
        marker = 'ZATO frontend front_http_plain:bind'
        lb_conf = open(join(repo_dir, 'zato.config')).read().splitlines()
        for line in lb_conf:
            if marker in line:
                lb_address = line.split(marker)[0].strip().split()[1]
                break

        if not lb_address:
            raise Exception('Load balancer check failed. Marker line not found `{}`.'.format(marker))

        _, port = lb_address.split(':')
        self.ensure_port_free('Load balancer', int(port), lb_address)

    def _on_web_admin(self, *ignored_args, **ignored_kwargs):
        repo_dir = join(self.component_dir, 'config', 'repo')

        self.check_sql_odb_web_admin(
            self.get_crypto_manager_conf(priv_key_location=join(repo_dir, 'web-admin-priv-key.pem'), repo_dir=repo_dir)[0],
            self.get_json_conf('web-admin.conf', repo_dir))

        self.ensure_no_pidfile()
        self.ensure_json_config_port_free('web-admin.conf', 'Web admin')

########NEW FILE########
__FILENAME__ = component_version
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Zato
from zato.cli import ZatoCommand
from zato.common import ZATO_INFO_FILE

# bzrlib
from bzrlib.lazy_import import lazy_import

lazy_import(globals(), """

    # stdlib
    import json, os
""")

class ComponentVersion(ZatoCommand):
    file_needed = ZATO_INFO_FILE

    def execute(self, args):
        info = json.load(open(os.path.join(args.path, self.file_needed))) # noqa
        self.logger.info(info['version'])

########NEW FILE########
__FILENAME__ = create_cluster
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from copy import deepcopy
from datetime import datetime
from traceback import format_exc
from uuid import uuid4

# SQLAlchemy
from sqlalchemy.exc import IntegrityError

# Zato
from zato.cli import common_odb_opts, get_tech_account_opts, ZatoCommand
from zato.common import SIMPLE_IO
from zato.common.odb.model import Cluster, HTTPBasicAuth, HTTPSOAP, Service, WSSDefinition

zato_services = {

    # Clusters - Connections map
    'zato.info.get-info':'zato.server.service.internal.info.GetInfo',
    'zato.info.get-server-info':'zato.server.service.internal.info.GetServerInfo',

    # Channels - AMQP
    'zato.channel.amqp.create':'zato.server.service.internal.channel.amqp.Create',
    'zato.channel.amqp.delete':'zato.server.service.internal.channel.amqp.Delete',
    'zato.channel.amqp.edit':'zato.server.service.internal.channel.amqp.Edit',
    'zato.channel.amqp.get-list':'zato.server.service.internal.channel.amqp.GetList',

    # Channels - JMS WebSphere MQ
    'zato.channel.jms-wmq.create':'zato.server.service.internal.channel.jms_wmq.Create',
    'zato.channel.jms-wmq.delete':'zato.server.service.internal.channel.jms_wmq.Delete',
    'zato.channel.jms-wmq.edit':'zato.server.service.internal.channel.jms_wmq.Edit',
    'zato.channel.jms-wmq.get-list':'zato.server.service.internal.channel.jms_wmq.GetList',

    # Channels - ZeroMQ
    'zato.channel.zmq.create':'zato.server.service.internal.channel.zmq.Create',
    'zato.channel.zmq.delete':'zato.server.service.internal.channel.zmq.Delete',
    'zato.channel.zmq.edit':'zato.server.service.internal.channel.zmq.Edit',
    'zato.channel.zmq.get-list':'zato.server.service.internal.channel.zmq.GetList',

    # Cloud - AWS - S3
    'zato.cloud.aws.s3.create':'zato.server.service.internal.cloud.aws.s3.Create',
    'zato.cloud.aws.s3.delete':'zato.server.service.internal.cloud.aws.s3.Delete',
    'zato.cloud.aws.s3.edit':'zato.server.service.internal.cloud.aws.s3.Edit',
    'zato.cloud.aws.s3.get-list':'zato.server.service.internal.cloud.aws.s3.GetList',

    # Cloud - OpenStack - Swift
    'zato.cloud.openstack.swift.create':'zato.server.service.internal.cloud.openstack.swift.Create',
    'zato.cloud.openstack.swift.delete':'zato.server.service.internal.cloud.openstack.swift.Delete',
    'zato.cloud.openstack.swift.edit':'zato.server.service.internal.cloud.openstack.swift.Edit',
    'zato.cloud.openstack.swift.get-list':'zato.server.service.internal.cloud.openstack.swift.GetList',

    # Definitions - AMQP
    'zato.definition.amqp.change-password':'zato.server.service.internal.definition.amqp.ChangePassword',
    'zato.definition.amqp.create':'zato.server.service.internal.definition.amqp.Create',
    'zato.definition.amqp.delete':'zato.server.service.internal.definition.amqp.Delete',
    'zato.definition.amqp.edit':'zato.server.service.internal.definition.amqp.Edit',
    'zato.definition.amqp.get-by-id':'zato.server.service.internal.definition.amqp.GetByID',
    'zato.definition.amqp.get-list':'zato.server.service.internal.definition.amqp.GetList',

    # Definitions - JMS WebSphere MQ
    'zato.definition.jms-wmq.create':'zato.server.service.internal.definition.jms_wmq.Create',
    'zato.definition.jms-wmq.delete':'zato.server.service.internal.definition.jms_wmq.Delete',
    'zato.definition.jms-wmq.edit':'zato.server.service.internal.definition.jms_wmq.Edit',
    'zato.definition.jms-wmq.get-by-id':'zato.server.service.internal.definition.jms_wmq.GetByID',
    'zato.definition.jms-wmq.get-list':'zato.server.service.internal.definition.jms_wmq.GetList',

    # HTTP/SOAP
    'zato.http-soap.create':'zato.server.service.internal.http_soap.Create',
    'zato.http-soap.delete':'zato.server.service.internal.http_soap.Delete',
    'zato.http-soap.edit':'zato.server.service.internal.http_soap.Edit',
    'zato.http-soap.get-list':'zato.server.service.internal.http_soap.GetList',
    'zato.http-soap.ping':'zato.server.service.internal.http_soap.Ping',

    # Key/value DB
    'zato.kvdb.data-dict.dictionary.create':'zato.server.service.internal.kvdb.data_dict.dictionary.Create',
    'zato.kvdb.data-dict.dictionary.delete':'zato.server.service.internal.kvdb.data_dict.dictionary.Delete',
    'zato.kvdb.data-dict.dictionary.edit':'zato.server.service.internal.kvdb.data_dict.dictionary.Edit',
    'zato.kvdb.data-dict.dictionary.get-key-list':'zato.server.service.internal.kvdb.data_dict.dictionary.GetKeyList',
    'zato.kvdb.data-dict.dictionary.get-last-id':'zato.server.service.internal.kvdb.data_dict.dictionary.GetLastID',
    'zato.kvdb.data-dict.dictionary.get-list':'zato.server.service.internal.kvdb.data_dict.dictionary.GetList',
    'zato.kvdb.data-dict.dictionary.get-system-list':'zato.server.service.internal.kvdb.data_dict.dictionary.GetSystemList',
    'zato.kvdb.data-dict.dictionary.get-value-list':'zato.server.service.internal.kvdb.data_dict.dictionary.GetValueList',
    'zato.kvdb.data-dict.impexp.import':'zato.server.service.internal.kvdb.data_dict.impexp.Import',
    'zato.kvdb.data-dict.translation.create':'zato.server.service.internal.kvdb.data_dict.translation.Create',
    'zato.kvdb.data-dict.translation.delete':'zato.server.service.internal.kvdb.data_dict.translation.Delete',
    'zato.kvdb.data-dict.translation.edit':'zato.server.service.internal.kvdb.data_dict.translation.Edit',
    'zato.kvdb.data-dict.translation.get-last-id':'zato.server.service.internal.kvdb.data_dict.translation.GetLastID',
    'zato.kvdb.data-dict.translation.get-list':'zato.server.service.internal.kvdb.data_dict.translation.GetList',
    'zato.kvdb.data-dict.translation.translate':'zato.server.service.internal.kvdb.data_dict.translation.Translate',
    'zato.kvdb.remote-command.execute':'zato.server.service.internal.kvdb.ExecuteCommand',
    
    # Outgoing connections - AMQP
    'zato.outgoing.amqp.create':'zato.server.service.internal.outgoing.amqp.Create',
    'zato.outgoing.amqp.delete':'zato.server.service.internal.outgoing.amqp.Delete',
    'zato.outgoing.amqp.edit':'zato.server.service.internal.outgoing.amqp.Edit',
    'zato.outgoing.amqp.get-list':'zato.server.service.internal.outgoing.amqp.GetList',
    
    # Outgoing connections - FTP
    'zato.outgoing.ftp.change-password':'zato.server.service.internal.outgoing.ftp.ChangePassword',
    'zato.outgoing.ftp.create':'zato.server.service.internal.outgoing.ftp.Create',
    'zato.outgoing.ftp.delete':'zato.server.service.internal.outgoing.ftp.Delete',
    'zato.outgoing.ftp.edit':'zato.server.service.internal.outgoing.ftp.Edit',
    'zato.outgoing.ftp.get-list':'zato.server.service.internal.outgoing.ftp.GetList',

    # Outgoing connections - JMS WebSphere MQ
    'zato.outgoing.jms-wmq.create':'zato.server.service.internal.outgoing.jms_wmq.Create',
    'zato.outgoing.jms-wmq.delete':'zato.server.service.internal.outgoing.jms_wmq.Delete',
    'zato.outgoing.jms-wmq.edit':'zato.server.service.internal.outgoing.jms_wmq.Edit',
    'zato.outgoing.jms-wmq.get-list':'zato.server.service.internal.outgoing.jms_wmq.GetList',
    
    # Outgoing connections - SQL
    'zato.outgoing.sql.change-password':'zato.server.service.internal.outgoing.sql.ChangePassword',
    'zato.outgoing.sql.create':'zato.server.service.internal.outgoing.sql.Create',
    'zato.outgoing.sql.delete':'zato.server.service.internal.outgoing.sql.Delete',
    'zato.outgoing.sql.edit':'zato.server.service.internal.outgoing.sql.Edit',
    'zato.outgoing.sql.get-list':'zato.server.service.internal.outgoing.sql.GetList',
    'zato.outgoing.sql.ping':'zato.server.service.internal.outgoing.sql.Ping',
    
    # Outgoing connections - ZeroMQ
    'zato.outgoing.zmq.create':'zato.server.service.internal.outgoing.zmq.Create',
    'zato.outgoing.zmq.delete':'zato.server.service.internal.outgoing.zmq.Delete',
    'zato.outgoing.zmq.edit':'zato.server.service.internal.outgoing.zmq.Edit',
    'zato.outgoing.zmq.get-list':'zato.server.service.internal.outgoing.zmq.GetList',

    # Patterns - delivery
    'zato.pattern.delivery.definition.create':'zato.server.service.internal.pattern.delivery.definition.Create',
    'zato.pattern.delivery.definition.delete':'zato.server.service.internal.pattern.delivery.definition.Delete',
    'zato.pattern.delivery.definition.edit':'zato.server.service.internal.pattern.delivery.definition.Edit',
    'zato.pattern.delivery.definition.get-list':'zato.server.service.internal.pattern.delivery.definition.GetList',
    
    # Ping services are added in Create.add_ping_services

    # Scheduler
    'zato.scheduler.job.create':'zato.server.service.internal.scheduler.Create',
    'zato.scheduler.job.delete':'zato.server.service.internal.scheduler.Delete',
    'zato.scheduler.job.edit':'zato.server.service.internal.scheduler.Edit',
    'zato.scheduler.job.execute':'zato.server.service.internal.scheduler.Execute',
    'zato.scheduler.job.get-by-name':'zato.server.service.internal.scheduler.GetByName',
    'zato.scheduler.job.get-list':'zato.server.service.internal.scheduler.GetList',

    # Security
    'zato.security.get-list':'zato.server.service.internal.security.GetList',

    # Security - API keys
    'zato.security.apikey.change-password':'zato.server.service.internal.security.apikey.ChangePassword',
    'zato.security.apikey.create':'zato.server.service.internal.security.apikey.Create',
    'zato.security.apikey.delete':'zato.server.service.internal.security.apikey.Delete',
    'zato.security.apikey.edit':'zato.server.service.internal.security.apikey.Edit',
    'zato.security.apikey.get-list':'zato.server.service.internal.security.apikey.GetList',

    # Security - AWS
    'zato.security.aws.change-password':'zato.server.service.internal.security.aws.ChangePassword',
    'zato.security.aws.create':'zato.server.service.internal.security.aws.Create',
    'zato.security.aws.delete':'zato.server.service.internal.security.aws.Delete',
    'zato.security.aws.edit':'zato.server.service.internal.security.aws.Edit',
    'zato.security.aws.get-list':'zato.server.service.internal.security.aws.GetList',

    # Security - HTTP Basic Auth
    'zato.security.basic-auth.change-password':'zato.server.service.internal.security.basic_auth.ChangePassword',
    'zato.security.basic-auth.create':'zato.server.service.internal.security.basic_auth.Create',
    'zato.security.basic-auth.delete':'zato.server.service.internal.security.basic_auth.Delete',
    'zato.security.basic-auth.edit':'zato.server.service.internal.security.basic_auth.Edit',
    'zato.security.basic-auth.get-list':'zato.server.service.internal.security.basic_auth.GetList',

    # Security - NTLM
    'zato.security.ntlm.change-password':'zato.server.service.internal.security.ntlm.ChangePassword',
    'zato.security.ntlm.create':'zato.server.service.internal.security.ntlm.Create',
    'zato.security.ntlm.delete':'zato.server.service.internal.security.ntlm.Delete',
    'zato.security.ntlm.edit':'zato.server.service.internal.security.ntlm.Edit',
    'zato.security.ntlm.get-list':'zato.server.service.internal.security.ntlm.GetList',

    # Security - OpenStack
    'zato.security.openstack.change-password':'zato.server.service.internal.security.openstack.ChangePassword',
    'zato.security.openstack.create':'zato.server.service.internal.security.openstack.Create',
    'zato.security.openstack.delete':'zato.server.service.internal.security.openstack.Delete',
    'zato.security.openstack.edit':'zato.server.service.internal.security.openstack.Edit',
    'zato.security.openstack.get-list':'zato.server.service.internal.security.openstack.GetList',

    # Security - Technical accounts
    'zato.security.tech-account.change-password':'zato.server.service.internal.security.tech_account.ChangePassword',
    'zato.security.tech-account.create':'zato.server.service.internal.security.tech_account.Create',
    'zato.security.tech-account.delete':'zato.server.service.internal.security.tech_account.Delete',
    'zato.security.tech-account.edit':'zato.server.service.internal.security.tech_account.Edit',
    'zato.security.tech-account.get-by-id':'zato.server.service.internal.security.tech_account.GetByID',
    'zato.security.tech-account.get-list':'zato.server.service.internal.security.tech_account.GetList',

    # Security - WS-Security
    'zato.security.wss.change-password':'zato.server.service.internal.security.wss.ChangePassword',
    'zato.security.wss.create':'zato.server.service.internal.security.wss.Create',
    'zato.security.wss.delete':'zato.server.service.internal.security.wss.Delete',
    'zato.security.wss.edit':'zato.server.service.internal.security.wss.Edit',
    'zato.security.wss.get-list':'zato.server.service.internal.security.wss.GetList',

    # Security - XPath
    'zato.security.xpath.change-password':'zato.server.service.internal.security.xpath.ChangePassword',
    'zato.security.xpath.create':'zato.server.service.internal.security.xpath.Create',
    'zato.security.xpath.delete':'zato.server.service.internal.security.xpath.Delete',
    'zato.security.xpath.edit':'zato.server.service.internal.security.xpath.Edit',
    'zato.security.xpath.get-list':'zato.server.service.internal.security.xpath.GetList',

    # Servers
    'zato.server.delete':'zato.server.service.internal.server.Delete',
    'zato.server.edit':'zato.server.service.internal.server.Edit',
    'zato.server.get-by-id':'zato.server.service.internal.server.GetByID',

    # Services
    'zato.service.configure-request-response':'zato.server.service.internal.service.ConfigureRequestResponse',
    'zato.service.delete':'zato.server.service.internal.service.Delete',
    'zato.service.edit':'zato.server.service.internal.service.Edit',
    'zato.service.get-by-name':'zato.server.service.internal.service.GetByName',
    'zato.service.get-channel-list':'zato.server.service.internal.service.GetChannelList',
    'zato.service.get-deployment-info-list':'zato.server.service.internal.service.GetDeploymentInfoList',
    'zato.service.get-list':'zato.server.service.internal.service.GetList',
    'zato.service.get-request-response':'zato.server.service.internal.service.GetRequestResponse',
    'zato.service.get-source-info':'zato.server.service.internal.service.GetSourceInfo',
    'zato.service.get-wsdl':'zato.server.service.internal.service.GetWSDL',
    'zato.service.has-wsdl':'zato.server.service.internal.service.HasWSDL',
    'zato.service.invoke':'zato.server.service.internal.service.Invoke',
    'zato.service.set-wsdl':'zato.server.service.internal.service.SetWSDL',
    'zato.service.slow-response.get':'zato.server.service.internal.service.GetSlowResponse',
    'zato.service.slow-response.get-list':'zato.server.service.internal.service.GetSlowResponseList',
    'zato.service.upload-package':'zato.server.service.internal.service.UploadPackage',

    # Statistics
    'zato.stats.delete':'zato.server.service.internal.stats.Delete',
    'zato.stats.get-by-service':'zato.server.service.internal.stats.GetByService',
    'zato.stats.summary.get-summary-by-day':'zato.server.service.internal.stats.summary.GetSummaryByDay',
    'zato.stats.summary.get-summary-by-month':'zato.server.service.internal.stats.summary.GetSummaryByMonth',
    'zato.stats.summary.get-summary-by-range':'zato.server.service.internal.stats.summary.GetSummaryByRange',
    'zato.stats.summary.get-summary-by-week':'zato.server.service.internal.stats.summary.GetSummaryByWeek',
    'zato.stats.summary.get-summary-by-year':'zato.server.service.internal.stats.summary.GetSummaryByYear',
    'zato.stats.trends.get-trends':'zato.server.service.internal.stats.trends.GetTrends',
}

class Create(ZatoCommand):
    """ Creates a new Zato cluster in the ODB
    """
    opts = deepcopy(common_odb_opts)

    opts.append({'name':'lb_host', 'help':"Load-balancer host"})
    opts.append({'name':'lb_port', 'help':'Load-balancer port'})
    opts.append({'name':'lb_agent_port', 'help':'Load-balancer agent host'})
    opts.append({'name':'broker_host', 'help':"Redis host"})
    opts.append({'name':'broker_port', 'help':'Redis port'})
    opts.append({'name':'cluster_name', 'help':'Name of the cluster to create'})

    opts += get_tech_account_opts('for web admin instances to use')

    def execute(self, args, show_output=True):
        
        engine = self._get_engine(args)
        session = self._get_session(engine)

        cluster = Cluster()
        cluster.name = args.cluster_name
        cluster.description = 'Created by {} on {} (UTC)'.format(self._get_user_host(), datetime.utcnow().isoformat())

        for name in(
              'odb_type', 'odb_host', 'odb_port', 'odb_user', 'odb_db_name',
              'broker_host', 'broker_port', 'lb_host', 'lb_port', 'lb_agent_port'):
            setattr(cluster, name, getattr(args, name))
        session.add(cluster)

        # TODO: getattrs below should be squared away - one of the attrs should win
        #       and the other one should be get ridden of.
        admin_invoke_sec = HTTPBasicAuth(None, 'admin.invoke', True, 'admin.invoke', 'Zato admin invoke', getattr(args, 'admin_invoke_password', None) or getattr(args, 'tech_account_password'), cluster)
        session.add(admin_invoke_sec)

        pubapi_sec = HTTPBasicAuth(None, 'pubapi', True, 'pubapi', 'Zato public API', uuid4().hex, cluster)
        session.add(pubapi_sec)

        self.add_soap_services(session, cluster, admin_invoke_sec, pubapi_sec)
        self.add_ping_services(session, cluster)
        self.add_default_pubsub_accounts(session, cluster)

        try:
            session.commit()
        except IntegrityError, e:
            msg = 'Cluster name [{}] already exists'.format(cluster.name)
            if self.verbose:
                msg += '. Caught an exception:[{}]'.format(format_exc(e).decode('utf-8'))
                self.logger.error(msg)
            self.logger.error(msg)
            session.rollback()
            
            return self.SYS_ERROR.CLUSTER_NAME_ALREADY_EXISTS

        if show_output:
            if self.verbose:
                msg = 'Successfully created a new cluster [{}]'.format(args.cluster_name)
                self.logger.debug(msg)
            else:
                self.logger.info('OK')

    def add_soap_services(self, session, cluster, admin_invoke_sec, pubapi_sec):
        """ Adds these Zato internal services that can be accessed through SOAP requests.
        """

        #
        # HTTPSOAP + services
        #

        for name, impl_name in zato_services.iteritems():

            service = Service(None, name, True, impl_name, True, cluster)
            session.add(service)

            # Add the HTTP channel for WSDLs
            if name == 'zato.service.get-wsdl':
                http_soap = HTTPSOAP(
                    None, '{}.soap'.format(name), True, True, 'channel', 'plain_http',
                    None, '/zato/wsdl', None, '', None, None, service=service, cluster=cluster)
                session.add(http_soap)

            elif name == 'zato.service.invoke':
                self.add_admin_invoke(session, cluster, service, admin_invoke_sec)

            zato_soap = HTTPSOAP(
                None, name, True, True, 'channel',
                'soap', None, '/zato/soap', None, name, '1.1',
                SIMPLE_IO.FORMAT.XML, service=service, cluster=cluster, security=pubapi_sec)
            session.add(zato_soap)

            json_url_path = '/zato/json/{}'.format(name)
            json_http = HTTPSOAP(
                None, '{}.json'.format(name), True, True, 'channel', 'plain_http',
                None, json_url_path, None, '', None, SIMPLE_IO.FORMAT.JSON, service=service, cluster=cluster, security=pubapi_sec)
            session.add(json_http)

    def add_ping_services(self, session, cluster):
        """ Adds a ping service and channels, with and without security checks.
        """
        passwords = {
            'ping.plain_http.basic_auth': None,
            'ping.soap.basic_auth': None,
            'ping.soap.wss.clear_text': None,
        }

        for password in passwords:
            passwords[password] = uuid4().hex

        ping_impl_name = 'zato.server.service.internal.Ping'
        ping_service_name = 'zato.ping'
        ping_service = Service(None, ping_service_name, True, ping_impl_name, True, cluster)
        session.add(ping_service)

        #
        # .. no security ..
        #
        # TODO
        # Change it to /zato/json/ping
        # and add an actual /zato/ping with no data format specified.
        ping_no_sec_channel = HTTPSOAP(
            None, 'zato.ping', True, True, 'channel',
            'plain_http', None, '/zato/ping', None, '', None, SIMPLE_IO.FORMAT.JSON, service=ping_service, cluster=cluster)
        session.add(ping_no_sec_channel)

        #
        # All the possible options
        #
        # Plain HTTP / Basic auth
        # SOAP / Basic auth
        # SOAP / WSS / Clear text
        #

        transports = ['plain_http', 'soap']
        wss_types = ['clear_text']

        for transport in transports:

            if transport == 'plain_http':
                data_format = SIMPLE_IO.FORMAT.JSON
            else:
                data_format = SIMPLE_IO.FORMAT.XML

            base_name = 'ping.{0}.basic_auth'.format(transport)
            zato_name = 'zato.{0}'.format(base_name)
            url = '/zato/{0}'.format(base_name)
            soap_action, soap_version = (zato_name, '1.1') if transport == 'soap' else ('', None)
            password = passwords[base_name]

            sec = HTTPBasicAuth(None, zato_name, True, zato_name, 'Zato ping', password, cluster)
            session.add(sec)

            channel = HTTPSOAP(
                None, zato_name, True, True, 'channel', transport, None, url, None, soap_action,
                soap_version, data_format, service=ping_service, security=sec, cluster=cluster)
            session.add(channel)

            if transport == 'soap':
                for wss_type in wss_types:
                    base_name = 'ping.{0}.wss.{1}'.format(transport, wss_type)
                    zato_name = 'zato.{0}'.format(base_name)
                    url = '/zato/{0}'.format(base_name)
                    password = passwords[base_name]

                    sec = WSSDefinition(None, zato_name, True, zato_name, password, wss_type, False, True, 3600, 3600, cluster)
                    session.add(sec)

                    channel = HTTPSOAP(
                        None, zato_name, True, True, 'channel', transport, None, url, None, soap_action,
                        soap_version, data_format, service=ping_service, security=sec, cluster=cluster)
                    session.add(channel)

    def add_admin_invoke(self, session, cluster, service, admin_invoke_sec):
        """ Adds an admin channel for invoking services from web admin and CLI.
        """
        channel = HTTPSOAP(
            None, 'admin.invoke.json', True, True, 'channel', 'plain_http',
            None, '/zato/admin/invoke', None, '', None, SIMPLE_IO.FORMAT.JSON, service=service, cluster=cluster,
            security=admin_invoke_sec)
        session.add(channel)

    def add_default_pubsub_accounts(self, session, cluster):
        """ Adds default accounts used by pub/sub internally.
        """
        for suffix in('consumer', 'producer'):
            name = 'zato.pubsub.default-{}'.format(suffix)
            item = HTTPBasicAuth(None, name, True, name, 'Zato pub/sub', uuid4().hex, cluster)
            session.add(item)

########NEW FILE########
__FILENAME__ = create_lb
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""
from __future__ import absolute_import, division, print_function, unicode_literals

# Zato
from zato.cli import common_logging_conf_contents, ZatoCommand
from zato.common.defaults import http_plain_server_port

# bzrlib
from bzrlib.lazy_import import lazy_import

lazy_import(globals(), """
    # quicli
    import os, uuid
    
""")

config_template = """{
  "haproxy_command": "haproxy",
  "host": "localhost",
  "port": 20151,
  "keyfile": "./zato-lba-priv-key.pem",
  "certfile": "./zato-lba-cert.pem",
  "ca_certs": "./zato-lba-ca-certs.pem",
  "work_dir": "../",
  "verify_fields": {},
  "log_config": "./logging.conf",
  "pid_file": "zato-lb-agent.pid"
}
"""

zato_config_template = """
# ##############################################################################

global
    log 127.0.0.1:514 local0 debug # ZATO global:log
    stats socket {stats_socket} # ZATO global:stats_socket

# ##############################################################################

defaults
    log global
    option httpclose

    stats uri /zato-lb-stats # ZATO defaults:stats uri

    timeout connect 15000 # ZATO defaults:timeout connect
    timeout client 15000 # ZATO defaults:timeout client
    timeout server 15000 # ZATO defaults:timeout server

    stats enable
    stats realm   Haproxy\ Statistics

    # Note: The password below is a UUID4 written in plain-text.
    stats auth    admin1:{stats_password}

    stats refresh 5s

# ##############################################################################

backend bck_http_plain
    mode http
    balance roundrobin
    
# ZATO begin backend bck_http_plain

{default_backend}

# ZATO end backend bck_http_plain

# ##############################################################################

frontend front_http_plain

    mode http
    default_backend bck_http_plain

    option httplog # ZATO frontend front_http_plain:option log-http-requests
    bind 127.0.0.1:11223 # ZATO frontend front_http_plain:bind
    maxconn 200 # ZATO frontend front_http_plain:maxconn

    monitor-uri /zato-lb-alive # ZATO frontend front_http_plain:monitor-uri
"""

default_backend = """
    server http_plain--server1 127.0.0.1:{server01_port} check inter 2s rise 2 fall 2 # ZATO backend bck_http_plain:server--server1
    server http_plain--server2 127.0.0.1:{server02_port} check inter 2s rise 2 fall 2 # ZATO backend bck_http_plain:server--server2
"""

class Create(ZatoCommand):
    """ Creates a new Zato load-balancer
    """
    opts = []
    opts.append({'name':'pub_key_path', 'help':"Path to the load-balancer agent's public key in PEM"})
    opts.append({'name':'priv_key_path', 'help':"Path to the load-balancer agent's private key in PEM"})
    opts.append({'name':'cert_path', 'help':"Path to the load-balancer agent's certificate in PEM"})
    opts.append({'name':'ca_certs_path', 'help':"Path to the a PEM list of certificates the load-balancer's agent will trust"})

    needs_empty_dir = True

    def __init__(self, args):
        super(Create, self).__init__(args)
        self.target_dir = os.path.abspath(args.path) # noqa

    def execute(self, args, use_default_backend=False, server02_port=None, show_output=True):
        os.mkdir(os.path.join(self.target_dir, 'config')) # noqa
        os.mkdir(os.path.join(self.target_dir, 'logs')) # noqa
        
        repo_dir = os.path.join(self.target_dir, 'config', 'repo') # noqa
        os.mkdir(repo_dir) # noqa

        log_path = os.path.abspath(os.path.join(repo_dir, '..', '..', 'logs', 'lb-agent.log')) # noqa
        stats_socket = os.path.join(self.target_dir, 'haproxy-stat.sock') # noqa

        open(os.path.join(repo_dir, 'lb-agent.conf'), 'w').write(config_template) # noqa
        open(os.path.join(repo_dir, 'logging.conf'), 'w').write((common_logging_conf_contents.format(log_path=log_path))) # noqa
        
        if use_default_backend:
            backend = default_backend.format(server01_port=http_plain_server_port, server02_port=server02_port)
        else:
            backend = '\n# ZATO default_backend_empty'

        zato_config = zato_config_template.format(stats_socket=stats_socket, stats_password=uuid.uuid4().hex, default_backend=backend) # noqa
        open(os.path.join(repo_dir, 'zato.config'), 'w').write(zato_config) # noqa
        self.copy_lb_crypto(repo_dir, args)
        
        # Initial info
        self.store_initial_info(self.target_dir, self.COMPONENTS.LOAD_BALANCER.code)

        if show_output:
            if self.verbose:
                msg = "Successfully created a load-balancer's agent in {}".format(self.target_dir)
                self.logger.debug(msg)
            else:
                self.logger.info('OK')

########NEW FILE########
__FILENAME__ = create_odb
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from datetime import datetime
from getpass import getuser
from socket import gethostname

# Zato
from zato.cli import ZatoCommand, common_odb_opts
from zato.common.odb import VERSION
from zato.common.odb.model import Base, ZatoInstallState

class Create(ZatoCommand):
    """ Creates a new Zato ODB (Operational Database)
    """
    opts = common_odb_opts

    def execute(self, args, show_output=True):
        engine = self._get_engine(args)
        session = self._get_session(engine)
        
        if engine.dialect.has_table(engine.connect(), 'install_state'):
            if show_output:
                version = session.query(ZatoInstallState.version).one().version
                msg = (
                    'The ODB (v. {}) already exists, not creating it. ' +
                    "Use the 'zato delete odb' command first if you'd like to start afresh and " +
                    'recreate all ODB objects.').format(version)
                self.logger.error(msg)
            
            return self.SYS_ERROR.ODB_EXISTS

        else:
            Base.metadata.create_all(engine)
            state = ZatoInstallState(None, VERSION, datetime.now(), gethostname(), getuser())

            session.add(state)
            session.commit()

            if show_output:
                if self.verbose:
                    self.logger.debug('Successfully created the ODB')
                else:
                    self.logger.info('OK')

########NEW FILE########
__FILENAME__ = create_server
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import os, uuid
from copy import deepcopy
from datetime import datetime
from traceback import format_exc

# SQLAlchemy
from sqlalchemy.exc import IntegrityError

# Zato
from zato.cli import ZatoCommand, common_logging_conf_contents, common_odb_opts, kvdb_opts
from zato.common import SERVER_JOIN_STATUS
from zato.common.defaults import http_plain_server_port
from zato.common.odb.model import Cluster, Server
from zato.common.util import encrypt

server_conf_template = """[main]
gunicorn_bind=localhost:{port}
gunicorn_worker_class=gevent
gunicorn_workers={gunicorn_workers}
gunicorn_timeout=240
gunicorn_user=
gunicorn_group=
gunicorn_proc_name=
gunicorn_logger_class=

deployment_lock_expires=1073741824 # 2 ** 30 seconds  34 years
deployment_lock_timeout=180

token={token}
service_sources=./service-sources.txt

[crypto]
use_tls=False
tls_protocol=TLSv1
tls_ciphers=AES256
tls_client_certs=optional
priv_key_location=zato-server-priv-key.pem
pub_key_location=zato-server-pub-key.pem
cert_location=zato-server-cert.pem
ca_certs_location=zato-server-ca-certs.pem

[odb]
db_name={odb_db_name}
engine={odb_engine}
extra=
host={odb_host}
port={odb_port}
password={odb_password}
pool_size={odb_pool_size}
username={odb_user}
use_async_driver=False

[hot_deploy]
pickup_dir=../../pickup-dir
work_dir=../../work
backup_history=100
backup_format=bztar
delete_after_pick_up=True

# These three are relative to work_dir
current_work_dir=./hot-deploy/current
backup_work_dir=./hot-deploy/backup
last_backup_work_dir=./hot-deploy/backup/last

[singleton]
initial_sleep_time=2500

# If a server doesn't update its keep alive data in
# connector_server_keep_alive_job_time * grace_time_multiplier seconds
# it will be considered down and another server from the cluster will assume
# the control of connectors
connector_server_keep_alive_job_time=30 # In seconds
grace_time_multiplier=3

[spring]
context_class=zato.server.spring_context.ZatoContext

[misc]
return_internal_objects=False
internal_services_may_be_deleted=False
initial_cluster_name = {initial_cluster_name}
initial_server_name = {initial_server_name}
delivery_lock_timeout = 2
queue_build_cap = 30 # All queue-based connections need to initialize in that many seconds
http_proxy=
locale=

[kvdb]
host={kvdb_host}
port={kvdb_port}
unix_socket_path=
password={kvdb_password}
db=0
socket_timeout=
charset=
errors=
use_redis_sentinels=False
redis_sentinels=
redis_sentinels_master=
shadow_password_in_logs=True
log_connection_info_sleep_time=5 # In seconds

[startup_services]
zato.helpers.input-logger=Sample payload for a startup service
zato.notif.init-notifiers=
zato.pattern.delivery.dispatch-auto-resubmit=
zato.pubsub.move-to-target-queues=
zato.pubsub.delete-expired=
zato.pubsub.invoke-callbacks=
zato.kvdb.log-connection-info=

[pubsub]
move_to_target_queues_interval=3 # In seconds
delete_expired_interval=180 # In seconds
invoke_callbacks_interval=2 # In seconds

[patterns]
delivery_auto_lock_timeout=90
delivery_retry_threshold_multiplier=4

[profiler]
enabled=False
profiler_dir=profiler
log_filename=profiler.log
cachegrind_filename=cachegrind.out
discard_first_request=True
flush_at_shutdown=True
url_path=/zato-profiler
unwind=False

[user_config]
# All paths are either absolute or relative to the directory server.conf is in
user=./user.conf

""".encode('utf-8')

service_sources_contents = """# Visit https://zato.io/docs for more information.

# All paths are relative to server root so that, for instance,
# ./my-services will resolve to /opt/zato/server1/my-services if a server has been
# installed into /opt/zato/server1

# List your service sources below, each on a separate line.

# Recommended to be always the very last line so all services that have been
# hot-deployed are picked up last.
./work/hot-deploy/current

# Visit https://zato.io/docs for more information."""

user_conf_contents = """[sample_section]
string_key=sample_string
list_key=sample,list

"""

lua_zato_rename_if_exists = """
-- Checks whether a from_key exists and if it does renames it to to_key.
-- Returns an error code otherwise.

-- Return codes:
-- 10 = Ok, renamed from_key -> to_key
-- 11 = No such from_key

local from_key = KEYS[1]
local to_key = KEYS[2]

if redis.call('exists', from_key) == 1 then
    redis.call('rename', from_key, to_key)
    return 10
else
    return 11
end
"""

default_odb_pool_size = 1

directories = (
    'config',
    'config/repo',
    'logs',
    'pickup-dir',
    'profiler',
    'work',
    'work/hot-deploy',
    'work/hot-deploy/current',
    'work/hot-deploy/backup',
    'work/hot-deploy/backup/last',
    'config/repo/lua',
    'config/repo/lua/internal',
    'config/repo/lua/user'
)

files = {
    'config/repo/logging.conf':common_logging_conf_contents.format(log_path='./logs/server.log'),
    'config/repo/service-sources.txt':service_sources_contents,
    'config/repo/lua/internal/zato.rename_if_exists.lua':lua_zato_rename_if_exists
}

priv_key_location = './config/repo/config-priv.pem'
priv_key_location = './config/repo/config-pub.pem'

class Create(ZatoCommand):
    """ Creates a new Zato server
    """
    needs_empty_dir = True
    allow_empty_secrets = True
    
    opts = deepcopy(common_odb_opts)
    opts.extend(kvdb_opts)
    
    opts.append({'name':'pub_key_path', 'help':"Path to the server's public key in PEM"})
    opts.append({'name':'priv_key_path', 'help':"Path to the server's private key in PEM"})
    opts.append({'name':'cert_path', 'help':"Path to the server's certificate in PEM"})
    opts.append({'name':'ca_certs_path', 'help':"Path to the a PEM list of certificates the server will trust"})
    opts.append({'name':'cluster_name', 'help':'Name of the cluster to join'})
    opts.append({'name':'server_name', 'help':"Server's name"})

    def __init__(self, args):
        super(Create, self).__init__(args)
        self.target_dir = os.path.abspath(args.path)
        self.dirs_prepared = False
        self.token = uuid.uuid4().hex

    def prepare_directories(self, show_output):
        if show_output:
            self.logger.debug('Creating directories..')
            
        for d in sorted(directories):
            d = os.path.join(self.target_dir, d)
            if show_output:
                self.logger.debug('Creating {d}'.format(d=d))
            os.mkdir(d)

        self.dirs_prepared = True

    def execute(self, args, port=http_plain_server_port, show_output=True):
        
        engine = self._get_engine(args)
        session = self._get_session(engine)

        cluster = session.query(Cluster).\
            filter(Cluster.name == args.cluster_name).\
            first()
        
        if not cluster:
            msg = "Cluster [{}] doesn't exist in the ODB".format(args.cluster_name)
            self.logger.error(msg)
            return self.SYS_ERROR.NO_SUCH_CLUSTER
        
        server = Server()
        server.cluster_id = cluster.id
        server.name = args.server_name
        server.token = self.token
        server.last_join_status = SERVER_JOIN_STATUS.ACCEPTED
        server.last_join_mod_by = self._get_user_host()
        server.last_join_mod_date = datetime.utcnow()
        
        session.add(server)

        try:
            if not self.dirs_prepared:
                self.prepare_directories(show_output)
    
            repo_dir = os.path.join(self.target_dir, 'config', 'repo')
            self.copy_server_crypto(repo_dir, args)
            priv_key = open(os.path.join(repo_dir, 'zato-server-priv-key.pem')).read()
            
            if show_output:
                self.logger.debug('Created a Bazaar repo in {}'.format(repo_dir))
                self.logger.debug('Creating files..')
                
            for file_name, contents in sorted(files.items()):
                file_name = os.path.join(self.target_dir, file_name)
                if show_output:
                    self.logger.debug('Creating {}'.format(file_name))
                f = file(file_name, 'w')
                f.write(contents)
                f.close()
    
            logging_conf_loc = os.path.join(self.target_dir, 'config/repo/logging.conf')
    
            logging_conf = open(logging_conf_loc).read()
            open(logging_conf_loc, 'w').write(logging_conf.format(
                log_path=os.path.join(self.target_dir, 'logs', 'zato.log')))
    
            if show_output:
                self.logger.debug('Logging configuration stored in {}'.format(logging_conf_loc))
    
            server_conf_loc = os.path.join(self.target_dir, 'config/repo/server.conf')
            server_conf = open(server_conf_loc, 'w')
            server_conf.write(
                server_conf_template.format(
                    port=port,
                    gunicorn_workers=2,
                    odb_db_name=args.odb_db_name or args.sqlite_path,
                    odb_engine=args.odb_type,
                    odb_host=args.odb_host or '',
                    odb_port=args.odb_port or '',
                    odb_password=encrypt(args.odb_password, priv_key) if args.odb_password else '',  
                    odb_pool_size=default_odb_pool_size, 
                    odb_user=args.odb_user or '', 
                    token=self.token, 
                    kvdb_host=args.kvdb_host,
                    kvdb_port=args.kvdb_port,
                    kvdb_password=encrypt(args.kvdb_password, priv_key) if args.kvdb_password else '',
                    initial_cluster_name=args.cluster_name,
                    initial_server_name=args.server_name,
                ))
            server_conf.close()

            user_conf_loc = os.path.join(self.target_dir, 'config/repo/user.conf')
            user_conf = open(user_conf_loc, 'w')
            user_conf.write(user_conf_contents)
            user_conf.close()

            if show_output:
                self.logger.debug('Core configuration stored in {}'.format(server_conf_loc))
            
            # Initial info
            self.store_initial_info(self.target_dir, self.COMPONENTS.SERVER.code)
            
            session.commit()

        except IntegrityError, e:
            msg = 'Server name [{}] already exists'.format(args.server_name)
            if self.verbose:
                msg += '. Caught an exception:[{}]'.format(format_exc(e))
                self.logger.error(msg)
            self.logger.error(msg)
            session.rollback()
            
            return self.SYS_ERROR.SERVER_NAME_ALREADY_EXISTS
            
        except Exception, e:
            msg = 'Could not create the server, e:[{}]'.format(format_exc(e))
            self.logger.error(msg)
            session.rollback()
        else:
            if show_output:
                self.logger.debug('Server added to the ODB')

        if show_output:
            if self.verbose:
                msg = """Successfully created a new server.
You can now start it with the 'zato start {}' command.""".format(self.target_dir)
                self.logger.debug(msg)
            else:
                self.logger.info('OK')

########NEW FILE########
__FILENAME__ = create_web_admin
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

try:
    import pymysql
    pymysql.install_as_MySQLdb()
except ImportError:
    pass

# stdlib
import os, json, uuid
from copy import deepcopy
from random import getrandbits
from traceback import format_exc

# Django
from django.core.management import call_command

# Zato
# TODO: There really shouldn't be any direct dependency between zato-cli and zato-web-admin
from zato.admin.zato_settings import update_globals

from zato.cli import get_tech_account_opts, common_logging_conf_contents, common_odb_opts, ZatoCommand
from zato.common.defaults import web_admin_host, web_admin_port
from zato.common.markov_passwords import generate_password
from zato.common.util import encrypt

config_template = """{{
  "host": "{host}",
  "port": {port},
  "db_type": "{db_type}",
  "log_config": "./config/repo/{log_config}",

  "DEBUG": 1,

  "DATABASE_NAME": "{DATABASE_NAME}",
  "DATABASE_USER": "{DATABASE_USER}",
  "DATABASE_PASSWORD": "{DATABASE_PASSWORD}",
  "DATABASE_HOST": "{DATABASE_HOST}",
  "DATABASE_PORT": "{DATABASE_PORT}",

  "TIME_ZONE": "America/New_York",
  "LANGUAGE_CODE": "en-us",

  "SITE_ID": {SITE_ID},
  "SECRET_KEY": "{SECRET_KEY}",
  
  "ADMIN_INVOKE_NAME": "{ADMIN_INVOKE_NAME}",
  "ADMIN_INVOKE_PASSWORD": "{ADMIN_INVOKE_PASSWORD}",
  "ADMIN_INVOKE_PATH": "/zato/admin/invoke",

  "OPENID_SSO_SERVER_URL": ""
}}
"""

initial_data_json = """[{{
"pk": {SITE_ID},
"model": "sites.site",
"fields": {{
    "name": "web admin",
    "domain":"webadmin.example.com"
    }}
}}]
"""

class Create(ZatoCommand):
    """ Creates a new web admin web console
    """
    needs_empty_dir = True
    allow_empty_secrets = True
    
    opts = deepcopy(common_odb_opts)
    
    opts.append({'name':'pub_key_path', 'help':"Path to the web admin's public key in PEM"})
    opts.append({'name':'priv_key_path', 'help':"Path to the web admin's private key in PEM"})
    opts.append({'name':'cert_path', 'help':"Path to the web admin's certificate in PEM"})
    opts.append({'name':'ca_certs_path', 'help':"Path to a bundle of CA certificates to be trusted"})
    
    opts += get_tech_account_opts()
    
    def __init__(self, args):
        self.target_dir = os.path.abspath(args.path)
        super(Create, self).__init__(args)

    def execute(self, args, show_output=True, password=None, needs_admin_created_flag=False):
        os.chdir(self.target_dir)

        repo_dir = os.path.join(self.target_dir, 'config', 'repo')
        web_admin_conf_path = os.path.join(repo_dir, 'web-admin.conf')
        initial_data_json_path = os.path.join(repo_dir, 'initial-data.json')

        os.mkdir(os.path.join(self.target_dir, 'logs'))
        os.mkdir(os.path.join(self.target_dir, 'config'))
        os.mkdir(repo_dir)
        
        user_name = 'admin'
        password = password if password else generate_password()
        
        self.copy_web_admin_crypto(repo_dir, args)
        priv_key = open(os.path.join(repo_dir, 'web-admin-priv-key.pem')).read()
        
        config = {
            'host': web_admin_host,
            'port': web_admin_port,
            'db_type': args.odb_type,
            'log_config': 'logging.conf',
            'DATABASE_NAME': args.odb_db_name or args.sqlite_path,
            'DATABASE_USER': args.odb_user or '',
            'DATABASE_PASSWORD': encrypt(args.odb_password, priv_key) if args.odb_password else '',
            'DATABASE_HOST': args.odb_host or '',
            'DATABASE_PORT': args.odb_port or '',
            'SITE_ID': getrandbits(20),
            'SECRET_KEY': encrypt(uuid.uuid4().hex, priv_key),
            'ADMIN_INVOKE_NAME':'admin.invoke',
            'ADMIN_INVOKE_PASSWORD':encrypt(getattr(args, 'admin_invoke_password', None) or getattr(args, 'tech_account_password'), priv_key),
        }
        
        open(os.path.join(repo_dir, 'logging.conf'), 'w').write(common_logging_conf_contents.format(log_path='./logs/web-admin.log'))
        open(web_admin_conf_path, 'w').write(config_template.format(**config))
        open(initial_data_json_path, 'w').write(initial_data_json.format(**config))
        
        # Initial info
        self.store_initial_info(self.target_dir, self.COMPONENTS.WEB_ADMIN.code)
        
        config = json.loads(open(os.path.join(repo_dir, 'web-admin.conf')).read())
        config['config_dir'] = self.target_dir
        update_globals(config, self.target_dir)
        
        os.environ['DJANGO_SETTINGS_MODULE'] = 'zato.admin.settings'
        
        # Can't import these without DJANGO_SETTINGS_MODULE being set
        from django.contrib.auth.models import User
        from django.db import connection
        from django.db.utils import IntegrityError
        
        call_command('syncdb', interactive=False, verbosity=0)
        call_command('loaddata', initial_data_json_path, verbosity=0)
        
        try:
            call_command(
                'createsuperuser', interactive=False, username=user_name, first_name='admin-first-name',
                last_name='admin-last-name', email='admin@invalid.example.com')
            admin_created = True

            user = User.objects.get(username=user_name)
            user.set_password(password)
            user.save()
            
        except IntegrityError, e:
            admin_created = False
            connection._rollback()
            self.logger.info('Ignoring IntegrityError e:[%s]', format_exc(e).decode('utf-8'))
            
        # Needed because Django took over our logging config
        self.reset_logger(args, True)

        if show_output:
            if self.verbose:
                msg = """Successfully created a web admin instance.
    You can start it with the 'zato start {path}' command.""".format(path=os.path.abspath(os.path.join(os.getcwd(), self.target_dir)))
                self.logger.debug(msg)
            else:
                self.logger.info('OK')

        # We return it only when told to explicitly so when the command runs from CLI
        # it doesn't return a non-zero exit code.
        if needs_admin_created_flag:
            return admin_created

########NEW FILE########
__FILENAME__ = crypto
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import os

# anyjson
import anyjson

# Zato
from zato.cli import ManageCommand, ZatoCommand
from zato.common.crypto import CryptoManager
from zato.common.util import get_config

class Encrypt(ZatoCommand):
    """ Encrypts secrets using a public key
    """
    allow_empty_secrets = True
    opts = [{'name':'--secret', 'help':'Secret to encrypt'}]
    
    def execute(self, args):
        cm = CryptoManager(pub_key_location=os.path.abspath(args.path))
        cm.load_keys()
        
        self.logger.info('Encrypted value is [{}]'.format(cm.encrypt(args.secret)))
    
class Decrypt(ZatoCommand):
    """ Decrypts secrets using a private key
    """
    allow_empty_secrets = True
    opts = [{'name':'--secret', 'help':'Secret to decrypt'}]
    
    def execute(self, args):
        cm = CryptoManager(priv_key_location=os.path.abspath(args.path))
        cm.load_keys()
        
        self.logger.info('Secret is [{}]'.format(cm.decrypt(args.secret)))
        
class UpdateCrypto(ManageCommand):
    """ Updates cryptographic material of a given Zato component
    """
    opts = [
        {'name':'pub_key_path', 'help':'Path to a public key in PEM'},
        {'name':'priv_key_path', 'help':'Path to a private key in PEM'},
        {'name':'cert_path', 'help':"Path to a component's certificate in PEM"},
        {'name':'ca_certs_path', 'help':"Path to a bundle of CA certificates in PEM"},
    ]
    
    def _update_crypto(
            self, args, copy_crypto_func, update_secrets=False, load_secrets_func=None,
            store_secrets_func=None, conf_file_name=None, priv_key_name=None, pub_key_name=None, secret_names=[]):
        
        repo_dir = os.path.join(os.path.abspath(os.path.join(self.original_dir, args.path)), 'config', 'repo')
        secrets = {}
        
        if update_secrets:
            priv_key_location = os.path.abspath(os.path.join(repo_dir, priv_key_name))
            pub_key_location = os.path.abspath(os.path.join(repo_dir, pub_key_name))
            conf_location = os.path.join(repo_dir, conf_file_name)
            
            cm = CryptoManager(priv_key_location=priv_key_location)
            cm.load_keys()
            
            secrets, conf = load_secrets_func(secrets, secret_names, cm, conf_location, conf_file_name)
            
        copy_crypto_func(repo_dir, args)
        
        if update_secrets:
            cm.reset()
            cm.pub_key_location = pub_key_location
            cm.load_keys()
            
            store_secrets_func(secrets, secret_names, cm, conf_location, conf)
    
    def _on_lb(self, args):
        self._update_crypto(args, self.copy_lb_crypto)
        
    def _on_web_admin(self, args):
        def load_secrets(secrets, secret_names, crypto_manager, conf_location, ignored):
            conf = anyjson.loads(open(conf_location).read())
            for name in secret_names:
                secrets[name] = crypto_manager.decrypt(conf[name])
                
            return secrets, conf
                
        def store_secrets(secrets, secret_names, crypto_manager, conf_location, conf):
            for name in secret_names:
                conf[name] = crypto_manager.encrypt(secrets[name])
            open(conf_location, 'w').write(anyjson.dumps(conf))
                
        self._update_crypto(
            args, self.copy_web_admin_crypto, True, load_secrets, store_secrets, 'web-admin.conf',
            'web-admin-priv-key.pem', 'web-admin-pub-key.pem', ['DATABASE_PASSWORD', 'TECH_ACCOUNT_PASSWORD'])

    def _on_server(self, args):
        def load_secrets(secrets, secret_names, crypto_manager, conf_location, conf_file_name):
            conf = get_config(os.path.dirname(conf_location), conf_file_name, False)
            for name in secret_names:
                k, v = name.split(':')
                if conf[k][v]:
                    secrets[name] = crypto_manager.decrypt(conf[k][v])
                
            return secrets, conf
        
        def store_secrets(secrets, secret_names, crypto_manager, conf_location, conf):
            for name in secret_names:
                if name in secrets:
                    k, v = name.split(':')
                    conf[k][v] = crypto_manager.encrypt(secrets[name])
                    
            conf.filename = conf_location
            conf.write()
        
        self._update_crypto(
            args, self.copy_server_crypto, True, load_secrets, store_secrets, 'server.conf',
            'zato-server-priv-key.pem', 'zato-server-pub-key.pem', ['odb:password', 'kvdb:password'])

########NEW FILE########
__FILENAME__ = delete_odb
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Zato
from zato.cli import ZatoCommand, common_odb_opts
from zato.common.odb import drop_all

class Delete(ZatoCommand):
    """ Deletes Zato components
    """
    needs_password_confirm = False
    opts = common_odb_opts

    def execute(self, args):
        engine = self._get_engine(args)
        
        if engine.dialect.has_table(engine.connect(), 'install_state'):
            drop_all(engine)
            
            if self.verbose:
                self.logger.debug('Successfully deleted the ODB')
            else:
                self.logger.info('OK')
        else:
            self.logger.error('No ODB found')
            return self.SYS_ERROR.NO_ODB_FOUND

########NEW FILE########
__FILENAME__ = enmasse
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import argparse, logging, os, sys
from contextlib import closing
from copy import deepcopy
from datetime import datetime
from itertools import chain
from json import dumps
from os.path import abspath, exists, join
from traceback import format_exc
from uuid import uuid4

# anyjson
from anyjson import loads

# Bunch
from bunch import Bunch, bunchify

# Pip
from pip import download

# Texttable
from texttable import Texttable

# Zato
from zato.cli import ManageCommand
from zato.cli.check_config import CheckConfig
from zato.client import AnyServiceInvoker
from zato.common.crypto import CryptoManager
from zato.common.odb.model import ConnDefAMQP, ConnDefWMQ, HTTPBasicAuth, \
     HTTPSOAP, NTLM, OAuth, SecurityBase, Server, Service, TechnicalAccount, \
     to_json, WSSDefinition, XPathSecurity
from zato.common.util import get_config
from zato.server.service import ForceType
from zato.server.service.internal import http_soap as http_soap_mod
from zato.server.service.internal.channel import amqp as channel_amqp_mod
from zato.server.service.internal.channel import jms_wmq as channel_jms_wmq_mod
from zato.server.service.internal.channel import zmq as channel_zmq_mod
from zato.server.service.internal.cloud.openstack import swift as cloud_openstack_swift
from zato.server.service.internal.definition import amqp as definition_amqp_mod
from zato.server.service.internal.definition import jms_wmq as definition_jms_wmq_mod
from zato.server.service.internal.message import json_pointer as json_pointer_mod
from zato.server.service.internal.message import namespace as namespace_mod
from zato.server.service.internal.message import xpath as xpath_mod
from zato.server.service.internal.outgoing import amqp as outgoing_amqp_mod
from zato.server.service.internal.outgoing import ftp as outgoing_ftp_mod
from zato.server.service.internal.outgoing import jms_wmq as outgoing_jms_wmq_mod
from zato.server.service.internal.outgoing import sql as outgoing_sql_mod
from zato.server.service.internal.outgoing import zmq as outgoing_zmq_mod
from zato.server.service.internal import scheduler as scheduler_mod
from zato.server.service.internal.security import basic_auth as sec_basic_auth_mod
from zato.server.service.internal.security import ntlm as sec_ntlm_mod
from zato.server.service.internal.security import oauth as sec_oauth_mod
from zato.server.service.internal.security import tech_account as sec_tech_account_mod
from zato.server.service.internal.security import wss as sec_wss_mod
from zato.server.service.internal.security import xpath as sec_xpath_mod

DEFAULT_COLS_WIDTH = '15,100'
NO_SEC_DEF_NEEDED = 'zato-no-security'

class Code(object):
    def __init__(self, symbol, desc):
        self.symbol = symbol
        self.desc = desc

    def __repr__(self):
        return "<{} at {} symbol:'{}' desc:'{}'>".format(
            self.__class__.__name__, hex(id(self)), self.symbol, self.desc)

WARNING_ALREADY_EXISTS_IN_ODB = Code('W01', 'already exists in ODB')
WARNING_MISSING_DEF = Code('W02', 'missing def')
WARNING_NO_DEF_FOUND = Code('W03', 'no def found')
WARNING_MISSING_DEF_INCL_ODB = Code('W04', 'missing def incl. ODB')
ERROR_ITEM_INCLUDED_MULTIPLE_TIMES = Code('E01', 'item incl multiple')
ERROR_ITEM_INCLUDED_BUT_MISSING = Code('E02', 'incl missing')
ERROR_INCLUDE_COULD_NOT_BE_PARSED = Code('E03', 'incl parsing error')
ERROR_NAME_MISSING = Code('E04', 'name missing')
ERROR_DEF_KEY_NOT_DEFINED = Code('E05', 'def key not defined')
ERROR_NO_DEF_KEY_IN_LOOKUP_TABLE = Code('E06', 'no def key in lookup')
ERROR_KEYS_MISSING = Code('E08', 'missing keys')
ERROR_INVALID_SEC_DEF_TYPE = Code('E09', 'invalid sec def type')
ERROR_INVALID_KEY = Code('E10', 'invalid key')
ERROR_SERVICE_NAME_MISSING = Code('E11', 'service name missing')
ERROR_SERVICE_MISSING = Code('E12', 'service missing')
ERROR_COULD_NOT_IMPORT_OBJECT = Code('E13', 'could not import object')

class _DummyLink(object):
    """ Pip requires URLs to have a .url attribute.
    """
    def __init__(self, url):
        self.url = url

class _Incorrect(object):
    def __init__(self, value_raw, value, code):
        self.value_raw = value_raw
        self.value = value
        self.code = code

    def __repr__(self):
        return "<{} at {} value_raw:'{}' value:'{}' code:'{}'>".format(
            self.__class__.__name__, hex(id(self)), self.value_raw,
            self.value, self.code)

class Warning(_Incorrect):
    pass

class Error(_Incorrect):
    pass

class Results(object):
    def __init__(self, warnings, errors, service=None):
        self.warnings = warnings
        self.errors = errors
        self.service_name = service.get_name() if service else None

    def _get_ok(self):
        return not(self.warnings or self.errors)

    ok = property(_get_ok)

class ZatoClient(AnyServiceInvoker):
    def __init__(self, *args, **kwargs):
        super(ZatoClient, self).__init__(*args, **kwargs)
        self.cluster_id = None
        self.odb_session = None

class EnMasse(ManageCommand):
    """ Manages server objects en masse.
    """
    opts = [
        {'name':'--server-url', 'help':'URL of the server that enmasse should talk to, provided in host[:port] format. Defaults to server.conf\'s \'gunicorn_bind\''},
        {'name':'--export-local', 'help':'Export local JSON definitions into one file (can be used with --export-odb)', 'action':'store_true'},
        {'name':'--export-odb', 'help':'Export ODB definitions into one file (can be used with --export-local)', 'action':'store_true'},
        {'name':'--import', 'help':'Import definitions from a local JSON (excludes --export-*)', 'action':'store_true'},
        {'name':'--ignore-missing-defs', 'help':'Ignore missing definitions when exporting to JSON', 'action':'store_true'},
        {'name':'--replace-odb-objects', 'help':'Force replacing objects already existing in ODB during import', 'action':'store_true'},
        {'name':'--input', 'help':'Path to an input JSON document'},
        {'name':'--cols_width', 'help':'A list of columns width to use for the table output, default: {}'.format(DEFAULT_COLS_WIDTH), 'action':'store_true'},
    ]

    def _on_server(self, args):

        self.args = args
        self.curdir = abspath(self.original_dir)
        self.replace_odb_objects = self.args.replace_odb_objects
        self.has_import = getattr(args, 'import')
        self.ignore_missing_defs = args.ignore_missing_defs
        self.json = {}
        self.json_to_import = {}

        self.odb_objects = Bunch()
        self.odb_services = Bunch()

        #
        # Tasks and scenarios
        #
        # 1) Export all local JSON files into one (--export-local)
        # 2) Export all definitions from ODB (--export-odb)
        # 3) Export all local JSON files with ODB definitions merged into one (--export-local --export-odb):
        # -> 4) Import definitions from a local JSON file (--import)
        #    4a) bail out if local JSON overrides any from ODB (no --replace-odb-objects)
        #    4b) override whatever is found in ODB with values from JSON (--replace-odb-objects)
        #

        if args.export_odb or self.has_import:

            # Checks if connections to ODB/Redis are configured properly
            cc = CheckConfig(self.args)
            cc.show_output = False
            cc.execute(Bunch(path='.', ensure_no_pidfile=False, check_server_port_available=False))

            # Get back to the directory we started in so following commands start afresh as well
            os.chdir(self.curdir)

            # Get client and issue a sanity check as quickly as possible
            self.set_client()
            self.client.invoke('zato.ping')

        # Imports and export are mutually excluding
        if self.has_import and (args.export_local or args.export_odb):
            self.logger.error('Cannot specify import and export options at the same time, stopping now')
            sys.exit(self.SYS_ERROR.CONFLICTING_OPTIONS)

        if args.export_local or self.has_import:
            input_path = self.ensure_input_exists()
            self.json = bunchify(loads(open(input_path).read()))

            # Local JSON sanity check first
            json_sanity_results = self.json_sanity_check()
            if not json_sanity_results.ok:
                self.logger.error('JSON sanity check failed')
                self.report_warnings_errors([json_sanity_results])
                sys.exit(self.SYS_ERROR.INVALID_INPUT)

        # 3)
        if args.export_local and args.export_odb:
            self.report_warnings_errors(self.export_local_odb())
            self.save_json()

        # 1)
        elif args.export_local:
            self.report_warnings_errors(self.export_local())
            self.save_json()

        # 2)
        elif args.export_odb:
            self.report_warnings_errors(self.export_odb())
            self.save_json()

        # 4) a/b
        elif self.has_import:
            self.report_warnings_errors(self.import_())

        else:
            self.logger.error('At least one of --export-local, --export-odb or --import is required, stopping now')
            sys.exit(self.SYS_ERROR.NO_OPTIONS)

# ################################################################################################################################

    def save_json(self):
        now = datetime.now().isoformat() # Not in UTC, we want to use user's TZ
        name = 'zato-export-{}.json'.format(now.replace(':', '_').replace('.', '_'))

        f = open(join(self.curdir, name), 'w')
        f.write(dumps(self.json, indent=1, sort_keys=True))
        f.close()

        self.logger.info('Data exported to {}'.format(f.name))

# ################################################################################################################################

    def set_client(self):

        repo_dir = os.path.join(os.path.abspath(os.path.join(self.args.path)), 'config', 'repo')
        config = get_config(repo_dir, 'server.conf')

        server_url = self.args.server_url if self.args.server_url else config.main.gunicorn_bind
        self.client = ZatoClient('http://{}'.format(server_url),
            '/zato/admin/invoke', self.get_server_client_auth(config, repo_dir), max_response_repr=15000)

        session = self.get_odb_session_from_server_config(
            config, self.get_crypto_manager_from_server_config(config, repo_dir))

        self.client.cluster_id = session.query(Server).\
            filter(Server.token == config.main.token).\
            one().cluster_id

        self.client.odb_session = session

# ################################################################################################################################

    def ensure_input_exists(self):
        input_path = abspath(join(self.curdir, self.args.input))
        if not exists(input_path):
            self.logger.error('No such path: [{}]'.format(input_path))

            # TODO: ManageCommand should not ignore exit codes subclasses return
            sys.exit(self.SYS_ERROR.NO_INPUT)

        return input_path

# ################################################################################################################################

    def get_warnings_errors(self, items):

        warn_idx = 1
        error_idx = 1
        warn_err = {}

        for item in items:

            for warning in item.warnings:
                warn_err['warn{:04}/{} {}'.format(warn_idx, warning.code.symbol, warning.code.desc)] = warning.value
                warn_idx += 1

            for error in item.errors:
                warn_err['err{:04}/{} {}'.format(error_idx, error.code.symbol, error.code.desc)] = error.value
                error_idx += 1

        warn_no = warn_idx-1
        error_no = error_idx-1

        return warn_err, warn_no, error_no

    def report_warnings_errors(self, items):

        warn_err, warn_no, error_no = self.get_warnings_errors(items)
        table = self.get_table(warn_err)

        warn_plural = '' if warn_no == 1 else 's'
        error_plural = '' if error_no == 1 else 's'

        if warn_no or error_no:
            if error_no:
                level = logging.ERROR
            else:
                level = logging.WARN

            prefix = '{} warning{} and {} error{} found:\n'.format(warn_no, warn_plural, error_no, error_plural)
            self.logger.log(level, prefix + table.draw())

        else:
            # A signal that we found no warnings nor errors
            return True

# ################################################################################################################################

    def get_table(self, out):

        cols_width = self.args.cols_width if self.args.cols_width else DEFAULT_COLS_WIDTH
        cols_width = (elem.strip() for elem in cols_width.split(','))
        cols_width = [int(elem) for elem in cols_width]

        table = Texttable()
        table.set_cols_width(cols_width)

        # Use text ('t') instead of auto so that boolean values don't get converted into ints
        table.set_cols_dtype(['t', 't'])

        rows = [['Key', 'Value']]
        rows.extend(sorted(out.items()))

        table.add_rows(rows)

        return table

# ################################################################################################################################

    def get_include_abspath(self, curdir, value):
        return abspath(join(curdir, value.replace('file://', '')))

    def is_include(self, value):
        return isinstance(value, basestring)

    def get_json_includes(self):
        for key in sorted(self.json):
            for value in self.json[key]:
                if self.is_include(value):
                    yield key, value

    def json_find_include_dups(self):
        seen_includes = {}

        for key, value in self.get_json_includes():
            keys = seen_includes.setdefault(value, [])
            keys.append(key)

        dups = dict((k,v) for (k,v) in seen_includes.items() if len(v) > 1)

        return dups

    def json_find_missing_includes(self):
        missing = {}
        for key in sorted(self.json):
            for value in self.json[key]:
                if self.is_include(value):
                    if download.is_file_url(_DummyLink(value)):
                        abs_path = self.get_include_abspath(self.curdir, value)
                        if not exists(abs_path):
                            item = missing.setdefault((value, abs_path), [])
                            item.append(key)
        return missing

    def json_find_unparsable_includes(self, missing):
        unparsable = {}

        for key in sorted(self.json):
            for value in self.json[key]:
                if self.is_include(value):
                    if download.is_file_url(_DummyLink(value)):
                        abs_path = self.get_include_abspath(self.curdir, value)

                        # No point in parsing what is already known not to exist
                        if abs_path not in missing:
                            try:
                                loads(open(abs_path).read())
                            except Exception, e:
                                exc_pretty = format_exc(e)

                                item = unparsable.setdefault((value, abs_path, exc_pretty), [])
                                item.append(key)

        return unparsable

    def json_sanity_check(self):
        errors = []

        for raw, keys in sorted(self.json_find_include_dups().items()):
            len_keys = len(keys)
            keys = sorted(set(keys))
            value = '{} included multiple times ({}) \n{}'.format(
                raw, len_keys, '\n'.join(' - {}'.format(name) for name in keys))
            errors.append(Error(raw, value, ERROR_ITEM_INCLUDED_MULTIPLE_TIMES))

        missing_items = sorted(self.json_find_missing_includes().items())
        for raw, keys in missing_items:
            missing, missing_abs = raw
            len_keys = len(keys)
            keys = sorted(set(keys))
            value = '{} ({}) missing but needed in multiple definitions ({}) \n{}'.format(
                missing, missing_abs, len_keys, '\n'.join(' - {}'.format(name) for name in keys))
            errors.append(Error(raw, value, ERROR_ITEM_INCLUDED_BUT_MISSING))

        unparsable = self.json_find_unparsable_includes([elem[0][1] for elem in missing_items])
        for raw, keys in unparsable.items():
            include, abs_path, exc_pretty = raw
            len_keys = len(keys)
            suffix = '' if len_keys == 1 else 's'
            keys = sorted(set(keys))
            value = '{} ({}) could not be parsed as JSON, used in ({}) definition{}\n{} \n{}'.format(
                include, abs_path, len_keys, suffix, '\n'.join(' - {}'.format(name) for name in keys), exc_pretty)
            errors.append(Error(raw, value, ERROR_INCLUDE_COULD_NOT_BE_PARSED))

        return Results([], errors)

    def merge_includes(self):
        json_with_includes = Bunch()
        for key, values in self.json.items():
            values_with_includes = json_with_includes.setdefault(key, [])
            for value in values:
                if self.is_include(value):
                    abs_path = self.get_include_abspath(self.curdir, value)
                    include = Bunch(loads(open(abs_path).read()))
                    values_with_includes.append(include)
                else:
                    values_with_includes.append(value)

        self.json = json_with_includes
        self.logger.info('Includes merged in successfully')

    def merge_odb_json(self):
        errors = []
        merged = deepcopy(self.odb_objects)

        for json_key, json_elems in self.json.items():
            if 'http' in json_key or 'soap' in json_key:
                odb_key = 'http_soap'
            else:
                odb_key = json_key

            if odb_key not in merged:
                sorted_merged = sorted(merged)
                raw = (json_key, odb_key, sorted_merged)
                value = "JSON key '{}' not one of '{}'".format(odb_key, sorted_merged)
                errors.append(Error(raw, value, ERROR_INVALID_KEY))
            else:
                for json_elem in json_elems:
                    if 'http' in json_key or 'soap' in json_key:
                        connection, transport = json_key.split('_', 1)
                        connection = 'outgoing' if connection == 'outconn' else connection

                        for odb_elem in merged.http_soap:
                            if odb_elem.get('transport') == transport and odb_elem.get('connection') == connection:
                                if odb_elem.name == json_elem.name:
                                    merged.http_soap.remove(odb_elem)
                    else:
                        for odb_elem in merged[odb_key]:
                            if odb_elem.name == json_elem.name:
                                merged[odb_key].remove(odb_elem)
                    merged[odb_key].append(json_elem)

        if errors:
            return Results([], errors)

        self.json = merged

# ################################################################################################################################

    def get_odb_objects(self):

        def _update_service_name(item):
            item.service = self.client.odb_session.query(Service.name).\
                filter(Service.id == item.service_id).one()[0]

        def fix_up_odb_object(key, item):
            if key == 'http_soap':
                if item.connection == 'channel':
                    _update_service_name(item)
                if item.security_id:
                    item.sec_def = self.client.odb_session.query(SecurityBase.name).\
                        filter(SecurityBase.id == item.security_id).one()[0]
                else:
                    item.sec_def = NO_SEC_DEF_NEEDED
            elif key == 'scheduler':
                _update_service_name(item)
            elif 'sec_type' in item:
                item['type'] = item['sec_type']
                del item['sec_type']

            return item

        def get_fields(model):
            return Bunch(loads(to_json(item))[0]['fields'])

        self.odb_objects.def_sec = []
        self.odb_objects.def_amqp = []
        self.odb_objects.http_soap = []

        basic_auth = self.client.odb_session.query(HTTPBasicAuth).\
            filter(HTTPBasicAuth.cluster_id == self.client.cluster_id)

        ntlm = self.client.odb_session.query(NTLM).\
            filter(NTLM.cluster_id == self.client.cluster_id)

        oauth = self.client.odb_session.query(OAuth).\
            filter(OAuth.cluster_id == self.client.cluster_id)

        tech_acc = self.client.odb_session.query(TechnicalAccount).\
            filter(TechnicalAccount.cluster_id == self.client.cluster_id)

        wss = self.client.odb_session.query(WSSDefinition).\
            filter(WSSDefinition.cluster_id == self.client.cluster_id)

        xpath_sec = self.client.odb_session.query(XPathSecurity).\
            filter(XPathSecurity.cluster_id == self.client.cluster_id)

        for query in(basic_auth, ntlm, oauth, tech_acc, wss, xpath_sec):
            for item in query.all():
                name = item.name.lower()
                if not 'zato' in name and name not in('admin.invoke', 'pubapi'):
                    self.odb_objects.def_sec.append(get_fields(item))

        for item in self.client.odb_session.query(ConnDefAMQP).\
            filter(ConnDefAMQP.cluster_id == self.client.cluster_id).all():
            self.odb_objects.def_amqp.append(get_fields(item))

        for item in self.client.odb_session.query(HTTPSOAP).\
            filter(HTTPSOAP.cluster_id == self.client.cluster_id).\
            filter(HTTPSOAP.is_internal == False).all():
            if item.name not in('admin.invoke', 'pubapi', 'zato.check.service'):
                self.odb_objects.http_soap.append(get_fields(item))

        service_key = {
            'zato.channel.amqp.get-list':'channel_amqp',
            'zato.channel.jms-wmq.get-list':'channel_jms_wmq',
            'zato.channel.zmq.get-list':'channel_zmq',
            'zato.message.json-pointer.get-list':'json_pointer',
            'zato.message.namespace.get-list':'def_namespace',
            'zato.message.xpath.get-list':'xpath',
            'zato.definition.jms-wmq.get-list':'def_jms_wmq',
            'zato.outgoing.amqp.get-list':'outconn_amqp',
            'zato.outgoing.ftp.get-list':'outconn_ftp',
            'zato.outgoing.jms-wmq.get-list':'outconn_jms_wmq',
            'zato.outgoing.sql.get-list':'outconn_sql',
            'zato.outgoing.zmq.get-list':'outconn_zmq',
            'zato.scheduler.job.get-list':'scheduler',
            'zato.cloud.openstack.swift.get-list':'cloud_openstack_swift',
            }

        for value in service_key.values():
            self.odb_objects[value] = []

        for service, key in service_key.items():
            response = self.client.invoke(service, {'cluster_id':self.client.cluster_id})
            if response.ok:
                for item in response.data:
                    if not 'zato' in item['name'].lower():
                        self.odb_objects[key].append(Bunch(item))

        for key, items in self.odb_objects.items():
            for item in items:
                fix_up_odb_object(key, item)

# ################################################################################################################################

    def find_already_existing_odb_objects(self):
        warnings = []
        errors = []

        def add_warning(key, value_dict, item):
            raw = (key, value_dict)
            msg = '{} already exists in ODB {} ({})'.format(value_dict.toDict(), item.toDict(), key)
            warnings.append(Warning(raw, msg, WARNING_ALREADY_EXISTS_IN_ODB))

        for key, values in self.json.items():
            for value_dict in values:
                value_name = value_dict.get('name')
                if not value_name:
                    raw = (key, value_dict)
                    msg = "{} has no 'name' key ({})".format(value_dict.toDict(), key)
                    errors.append(Error(raw, msg, ERROR_NAME_MISSING))

                if key == 'http_soap':
                    connection = value_dict.get('connection')
                    transport = value_dict.get('transport')

                    for item in self.odb_objects.http_soap:
                        if connection == item.connection and transport == item.transport:
                            if value_name == item.name:
                                add_warning(key, value_dict, item)
                else:
                    odb_defs = self.odb_objects[key.replace('-', '_')]
                    for odb_def in odb_defs:
                        if odb_def.name == value_name:
                            add_warning(key, value_dict, odb_def)

        return Results(warnings, errors)

# ################################################################################################################################

    def find_missing_defs(self):
        warnings = []
        errors = []
        missing_def_keys = set()
        missing_def_names = {}
        json_keys = tuple(sorted((self.json)))

        def _add_error(item,  key_name, def_, json_key):
            raw = (item, def_)
            value = "{} does not define '{}' (value is {}) ({})".format(item.toDict(), key_name, def_, json_key)
            errors.append(Error(raw, value, ERROR_DEF_KEY_NOT_DEFINED))

        defs_keys = {
                'def': ('jms-wmq', 'amqp'),
                'sec_def': ('plain-http', 'soap'),
            }

        items_defs = {
            'channel_amqp':'def_amqp',
            'channel_jms_wmq':'def_jms_wmq',
            'channel_plain_http':'def_sec',
            'channel_soap':'def_sec',
            'outconn_amqp':'def_amqp',
            'outconn_jms_wmq':'def_jms_wmq',
            'outconn_plain_http':'def_sec',
            'outconn_soap':'def_sec',
            'http_soap':'def_sec'
        }

        _no_sec_needed = ('channel-plain-http', 'channel-soap', 'outconn-plain-http', 'outconn-soap')

        def get_needed_defs():

            for json_key, json_items in self.json.items():
                for def_name, def_keys in defs_keys.items():
                    for def_key in def_keys:
                        if def_key in json_key:
                            for json_item in json_items:
                                if 'def' in json_key:
                                    continue
                                needed_def = json_item.get(def_key)
                                def_ = json_item.get(def_name)
                                if not def_:
                                    _add_error(json_item, def_name, def_, json_key)
                                yield ({json_key:def_})

        needed_defs = list(get_needed_defs())
        for info_dict in needed_defs:
            item_key, def_name = info_dict.items()[0]
            def_key = items_defs.get(item_key)

            if not def_key:
                raw = (info_dict, items_defs)
                value = "Could not find a def key in {} for item_key '{}'".format(items_defs, item_key)
                errors.append(Error(raw, value, ERROR_NO_DEF_KEY_IN_LOOKUP_TABLE))

            else:
                defs = self.json.get(def_key)

                for item in defs:
                    if item.get('name') == def_name:
                        break
                else:
                    if def_name == NO_SEC_DEF_NEEDED and item_key in _no_sec_needed:
                        continue

                    def_names = tuple(sorted([def_.name for def_ in defs]))
                    raw = (def_key, def_name, def_names)
                    dependants = missing_def_names.setdefault(raw, set())
                    dependants.add(item_key)

        if not self.ignore_missing_defs:
            for(def_key, missing_def, existing_ones), dependants in missing_def_names.items():
                if missing_def == NO_SEC_DEF_NEEDED:
                    continue
                dependants = sorted(dependants)
                raw = (def_key, missing_def, existing_ones, dependants)
                value = "'{}' is needed by '{}' but was not among '{}'".format(missing_def, dependants, existing_ones)
                warnings.append(Warning(raw, value, WARNING_MISSING_DEF))

        if warnings or errors:
            return Results(warnings, errors)

# ################################################################################################################################

    def validate_input(self):
        errors = []
        required = {}

        create_services = {
            'channel_amqp':channel_amqp_mod.Create,
            'channel_jms_wmq':channel_jms_wmq_mod.Create,
            'channel_plain_http':http_soap_mod.Create,
            'channel_soap':http_soap_mod.Create,
            'channel_zmq':channel_zmq_mod.Create,
            'def_amqp':definition_amqp_mod.Create,
            'def_jms_wmq':definition_jms_wmq_mod.Create,
            'json_pointer': json_pointer_mod.Create,
            'http_soap':http_soap_mod.Create,
            'def_namespace': namespace_mod.Create,
            'outconn_amqp':outgoing_amqp_mod.Create,
            'outconn_ftp':outgoing_ftp_mod.Create,
            'outconn_jms_wmq':outgoing_jms_wmq_mod.Create,
            'outconn_plain_http':http_soap_mod.Create,
            'outconn_soap':http_soap_mod.Create,
            'outconn_sql':outgoing_sql_mod.Create,
            'outconn_zmq':outgoing_zmq_mod.Create,
            'scheduler':scheduler_mod.Create,
            'xpath': xpath_mod.Create,
            'cloud_openstack_swift': cloud_openstack_swift.Create,
        }

        def_sec_services = {
            'basic_auth':sec_basic_auth_mod.Create,
            'ntlm':sec_ntlm_mod.Create,
            'oauth':sec_oauth_mod.Create,
            'tech_acc':sec_tech_account_mod.Create,
            'wss':sec_wss_mod.Create,
            'xpath_sec':sec_xpath_mod.Create,
        }

        create_services_keys = sorted(create_services)
        def_sec_services_keys = sorted(def_sec_services)

        replace_names = {
            'def_id': 'def',
        }

        skip_names = ('cluster_id',)

        def _needs_password(key):
            return 'sql' in key

        for key, service in chain(create_services.items(), def_sec_services.items()):
            required[key] = set()
            for name in service.SimpleIO.input_required:
                if name in skip_names:
                    continue
                if isinstance(name, ForceType):
                    name = name.name
                name = replace_names.get(name, name)
                required[key].add(name)

        def _validate(key, item, class_, is_sec):
            name = item.get('name')
            item_dict = item.toDict()
            missing = None
            required_lookup_key = None

            if not name:
                raw = (key, item_dict)
                value = "No 'name' key found in item '{}' ({})".format(item_dict, key)
                errors.append(Error(raw, value, ERROR_NAME_MISSING))
            else:
                if is_sec:
                    # We know we have one of correct types already so we can
                    # just look up required attributes.
                    required_keys = required[item.get('type')]
                else:
                    required_keys = required[key]

                if _needs_password(key):
                    required_keys.add('password')

                missing = sorted(required_keys - set(item))

                if missing:
                    missing_value = "key '{}'".format(missing[0]) if len(missing) == 1 else "keys '{}'".format(missing)
                    raw = (key, name, item_dict, required_keys, missing)
                    value = "Missing {} in '{}', the rest is '{}' ({})".format(missing_value, name, item_dict, key)
                    errors.append(Error(raw, value, ERROR_KEYS_MISSING))

                # OK, the keys are there, but do they all have non-None values?
                else:
                    for req_key in required_keys:
                        if item.get(req_key) is None: # 0 or '' can be correct values
                            raw = (req_key, required, item_dict, key)
                            value = "Key '{}' must not be None in '{}' ({})".format(req_key, item_dict, key)

        for key, items in self.json.items():
            for item in items:
                if key == 'def_sec':
                    sec_type = item.get('type')
                    if not sec_type:
                        item_dict = item.toDict()
                        raw = (key, item_dict)
                        value = "'{}' has no required 'type' key (def_sec) ".format(item_dict)
                        errors.append(Error(raw, value, ERROR_TYPE_MISSING))
                    else:
                        class_ = def_sec_services.get(sec_type)
                        if not class_:
                            raw = (sec_type, def_sec_services_keys, item)
                            value = "Invalid type '{}', must be one of '{}' (def_sec)".format(sec_type, def_sec_services_keys)
                            errors.append(Error(raw, value, ERROR_INVALID_SEC_DEF_TYPE))
                        else:
                            _validate(key, item, class_, True)
                else:
                    class_ = create_services.get(key)
                    if not class_:
                        raw = (key, create_services_keys)
                        value = "Invalid key '{}', must be one of '{}'".format(key, create_services_keys)
                        errors.append(Error(raw, value, ERROR_INVALID_KEY))
                    else:
                        _validate(key, item, class_, False)

        if errors:
            return Results([], errors)

# ################################################################################################################################

    def export(self):

        # Find any definitions that are missing
        missing_defs = self.find_missing_defs()
        if missing_defs:
            self.logger.error('Failed to find all definitions needed')
            return [missing_defs]

        # Validate if every required input element has been specified.
        invalid_reqs = self.validate_input()
        if invalid_reqs:
            self.logger.error('Required elements missing')
            return [invalid_reqs]

        return []

    def export_local(self, needs_includes=True):
        if needs_includes:
            self.merge_includes()
        return self.export()

    def export_local_odb(self, needs_local=True):
        if needs_local:
            self.merge_includes()
        self.get_odb_objects()
        self.logger.info('ODB objects read')

        errors = self.merge_odb_json()
        if errors:
            return [errors]
        self.logger.info('ODB objects merged in')

        return self.export_local(False)

    def export_odb(self):
        return self.export_local_odb(False)

# ################################################################################################################################

    def validate_import_data(self):
        warnings = []
        errors = []

        items_defs = {
            'def_amqp':'zato.definition.amqp.get-list',
            'def_jms_wmq':'zato.definition.jms-wmq.get-list',
            'def_sec':'zato.security.get-list',
        }

        def has_def(def_type, def_name):
            service = items_defs[def_type]
            response = self.client.invoke(service, {'cluster_id':self.client.cluster_id})
            if response.ok:
                for item in response.data:
                    if item['name'] == def_name:
                        return False

            return False

        missing_defs = self.find_missing_defs()
        if missing_defs:
            for warning in missing_defs.warnings:
                def_type, def_name, _, dependants = warning.value_raw
                if not has_def(def_type, def_name):
                    raw = (def_type, def_name)
                    value = "Definition '{}' not found in JSON/ODB ({}), needed by '{}'".format(
                        def_name, def_type, dependants)
                    warnings.append(Warning(raw, value, WARNING_MISSING_DEF_INCL_ODB))

        def needs_service(json_key, item):
            return 'channel' in json_key or json_key == 'scheduler' or \
                   ('http_soap' in json_key and item.get('connection') == 'channel')

        for json_key, items in self.json.items():
            for item in items:
                if needs_service(json_key, item):
                    item_dict = item.toDict()
                    service_name = item.get('service')
                    raw = (service_name, item_dict, json_key)
                    if not service_name:
                        value = "No service defined in '{}' ({})".format(item_dict, json_key)
                        errors.append(Error(raw, value, ERROR_SERVICE_NAME_MISSING))
                    else:
                        if service_name not in self.odb_services:
                            value = "Service '{}' from '{}' missing in ODB ({})".format(service_name, item_dict, json_key)
                            errors.append(Error(raw, value, ERROR_SERVICE_MISSING))

        return Results(warnings, errors)

    def import_objects(self, already_existing):
        warnings = []
        errors = []

        existing_defs = []
        existing_other = []

        new_defs = []
        new_other = []

        # FTP definition may use a password but are not required to.
        MAYBE_NEEDS_PASSWORD = 'MAYBE_NEEDS_PASSWORD'

        self.json_to_import = Bunch(deepcopy(self.json))

        class ImportInfo(object):
            def __init__(self, mod, needs_password=False):
                self.mod = mod
                self.needs_password = needs_password

            def __repr__(self):
                return "<{} at {} mod:'{}' needs_password:'{}'>".format(
                    self.__class__.__name__, hex(id(self)), self.mod, self.needs_password)

        service_info = {
            'channel_amqp':ImportInfo(channel_amqp_mod),
            'channel_jms_wmq':ImportInfo(channel_jms_wmq_mod),
            'channel_zmq':ImportInfo(channel_zmq_mod),
            'def_amqp':ImportInfo(definition_amqp_mod, True),
            'def_jms_wmq':ImportInfo(definition_jms_wmq_mod),
            'json_pointer':ImportInfo(json_pointer_mod),
            'http_soap':ImportInfo(http_soap_mod),
            'def_namespace':ImportInfo(namespace_mod),
            'outconn_amqp':ImportInfo(outgoing_amqp_mod),
            'outconn_ftp':ImportInfo(outgoing_ftp_mod, MAYBE_NEEDS_PASSWORD),
            'outconn_jms_wmq':ImportInfo(outgoing_jms_wmq_mod),
            'outconn_sql':ImportInfo(outgoing_sql_mod, True),
            'outconn_zmq':ImportInfo(outgoing_zmq_mod),
            'scheduler':ImportInfo(scheduler_mod),
            'xpath':ImportInfo(xpath_mod),
            'cloud_openstack_swift': ImportInfo(cloud_openstack_swift),
        }

        def_sec_info = {
            'basic_auth':ImportInfo(sec_basic_auth_mod, True),
            'ntlm':ImportInfo(sec_ntlm_mod, True),
            'oauth':ImportInfo(sec_oauth_mod, True),
            'tech_acc':ImportInfo(sec_tech_account_mod, True),
            'wss':ImportInfo(sec_wss_mod, True),
            'xpath_sec':ImportInfo(sec_xpath_mod, True),
        }

        def get_odb_item(item_type, name):
            for item in self.odb_objects[item_type]:
                if item.name == name:
                    return item

        def get_security_by_name(name):
            for item in self.odb_objects.def_sec:
                if item.name == name:
                    return item.id

        def import_object(def_type, attrs, is_edit):
            attrs_dict = attrs.toDict()
            info_dict, info_key = (def_sec_info, attrs.type) if 'sec' in def_type else (service_info, def_type)
            import_info = info_dict[info_key]
            service_class = getattr(import_info.mod, 'Edit' if is_edit else 'Create')
            service_name = service_class.get_name()

            # Fetch an item from a cache of ODB object and assign its ID
            # to attrs so that the Edit service knows what to update.
            if is_edit:
                odb_item = get_odb_item(def_type, attrs.name)
                attrs.id = odb_item.id

            if def_type == 'http_soap':
                if attrs.sec_def == NO_SEC_DEF_NEEDED:
                    attrs.security_id = None
                else:
                    attrs.security_id = get_security_by_name(attrs.sec_def)

            if def_type in('channel_amqp', 'channel_jms_wmq', 'outconn_amqp', 'outconn_jms_wmq'):
                def_type_name = def_type.replace('channel', 'def').replace('outconn', 'def')
                odb_item = get_odb_item(def_type_name, attrs.get('def'))
                attrs.def_id = odb_item.id

            response = self.client.invoke(service_name, attrs)
            if not response.ok:
                return service_name, response.details
            else:
                verb = 'Updated' if is_edit else 'Created'
                self.logger.info("{} object '{}' ({} {})".format(verb, attrs.name, item_type, service_name))
                if import_info.needs_password:

                    password = attrs.get('password')
                    if not password:
                        if import_info.needs_password == MAYBE_NEEDS_PASSWORD:
                            self.logger.info("Password missing but not required '{}' ({} {})".format(
                                attrs.name, item_type, service_name))
                        else:
                            return service_name, "Password missing but is required '{}' ({} {}) attrs '{}'".format(
                                attrs.name, item_type, service_name, attrs_dict)
                    else:
                        if not is_edit:
                            attrs.id = response.data['id']

                        service_class = getattr(import_info.mod, 'ChangePassword')
                        request = {'id':attrs.id, 'password1':attrs.password, 'password2':attrs.password}
                        response = self.client.invoke(service_class.get_name(), request)
                        if not response.ok:
                            return service_name, response.details
                        else:
                            self.logger.info("Updated password '{}' ({} {})".format(
                                attrs.name, item_type, service_name))

            return None, None

        def remove_from_import_list(item_type, name):
            for json_item_type, items in self.json_to_import.items():
                if json_item_type == item_type:
                    for item in items:
                        if item.name == name:
                            items.remove(item)

                            # Name is unique, we can stop now
                            return

        def _import(item_type, attrs, is_edit):
            attrs_dict = attrs.toDict()
            attrs.cluster_id = self.client.cluster_id
            service_name, error_response = import_object(item_type, attrs, is_edit)

            # We quit on first error encountered
            if error_response:
                raw = (item_type, attrs_dict, error_response)
                value = "Could not import '{}' with '{}', response from '{}' was '{}'".format(
                    attrs.name, attrs_dict, service_name, error_response)
                errors.append(Error(raw, value, ERROR_COULD_NOT_IMPORT_OBJECT))
                return Results(warnings, errors)

            # It's been just imported so we don't want to create in next steps
            # (this in fact would result in an error as the object already exists).
            if is_edit:
                remove_from_import_list(item_type, attrs.name)

            # We'll see how expensive this call is. Seems to be but
            # let's see in practice if it's a burden.
            self.get_odb_objects()

        #
        # Update already existing objects first, definitions before any object
        # that may depend on them ..
        #
        for w in already_existing.warnings:
            item_type, _ = w.value_raw
            existing = existing_defs if 'def' in item_type else existing_other
            existing.append(w)

        #
        # .. actually invoke the updates now ..
        #
        for w in chain(existing_defs, existing_other):
            item_type, attrs = w.value_raw
            results = _import(item_type, attrs, True)
            if results:
                return results

        #
        # Create new objects, again, definitions come first ..
        #
        for item_type, items in self.json_to_import.items():
            new = new_defs if 'def' in item_type else new_other
            new.append({item_type:items})

        #
        # .. actually create the objects now.
        #
        for elem in chain(new_defs, new_other):
            for item_type, attr_list in elem.items():
                for attrs in attr_list:
                    results = _import(item_type, attrs, False)
                    if results:
                        return results

        return Results(warnings, errors)

    def import_(self):
        self.get_odb_objects()

        odb_services = self.client.invoke('zato.service.get-list', {'cluster_id':self.client.cluster_id, 'name_filter':'*'})
        if odb_services.has_data:
            for service in odb_services.data:
                self.odb_services[service['name']] = Bunch(service)

        # Find channels and jobs that require services that don't exist
        results = self.validate_import_data()
        if not results.ok:
            return [results]

        already_existing = self.find_already_existing_odb_objects()
        if not already_existing.ok and not self.replace_odb_objects:
            return [already_existing]

        results = self.import_objects(already_existing)
        if not results.ok:
            return [results]

        return []

# ################################################################################################################################

########NEW FILE########
__FILENAME__ = info
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import os

# yaml
import yaml

# Zato
from zato.cli import ManageCommand
from zato.common import INFO_FORMAT
from zato.common.component_info import format_info, get_info

DEFAULT_COLS_WIDTH = '30,90'

class _Dumper(yaml.SafeDumper):
    def represent_none(self, data):
        return self.represent_scalar('tag:yaml.org,2002:null', '')

class Info(ManageCommand):
    """ Shows detailed information regarding a chosen Zato component
    """
    # Changed in 2.0 - --json replaced with --format
    opts = [
        {'name':'--format', 'help':'Output format, must be one of text, json or yaml, default: {}'.format(INFO_FORMAT.TEXT),
           'default':INFO_FORMAT.TEXT},
        {'name':'--cols_width', 'help':'A list of columns width to use for the table output, default: {}'.format(DEFAULT_COLS_WIDTH)}
    ]

    def _on_server(self, args):
        os.chdir(self.original_dir)
        info = get_info(os.path.abspath(args.path), args.format)
        self.logger.info(format_info(info, args.format, args.cols_width if args.cols_width else DEFAULT_COLS_WIDTH, _Dumper))

    _on_lb = _on_web_admin = _on_server

########NEW FILE########
__FILENAME__ = quickstart
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import os, random, stat
from collections import OrderedDict
from copy import deepcopy
from itertools import count
from uuid import uuid4

# Bunch
from bunch import Bunch

# Zato
from zato.cli import common_odb_opts, kvdb_opts, ca_create_ca, ca_create_lb_agent, ca_create_server, \
     ca_create_web_admin, create_cluster, create_lb, create_odb, create_server, create_web_admin, ZatoCommand
from zato.common.defaults import http_plain_server_port
from zato.common.markov_passwords import generate_password
from zato.common.util import make_repr

random.seed()

DEFAULT_NO_SERVERS=2

# Taken from http://stackoverflow.com/a/246128
script_dir = """SOURCE="${BASH_SOURCE[0]}"
BASE_DIR="$( dirname "$SOURCE" )"
while [ -h "$SOURCE" ]
do
  SOURCE="$(readlink "$SOURCE")"
  [[ $SOURCE != /* ]] && SOURCE="$BASE_DIR/$SOURCE"
  BASE_DIR="$( cd -P "$( dirname "$SOURCE"  )" && pwd )"
done
BASE_DIR="$( cd -P "$( dirname "$SOURCE" )" && pwd )"
"""

sanity_checks_template = """$ZATO_BIN check-config $BASE_DIR/{server_name}"""

start_servers_template = """
cd $BASE_DIR/{server_name}
$ZATO_BIN start .
echo [{step_number}/$STEPS] {server_name} started
"""

zato_qs_start_head_template = """#!/bin/bash

set -e
export ZATO_CLI_DONT_SHOW_OUTPUT=1

{script_dir}
ZATO_BIN={zato_bin}
STEPS={start_steps}
CLUSTER={cluster_name}

echo Starting the Zato cluster $CLUSTER
echo Running sanity checks
"""

zato_qs_start_body_template = """
{sanity_checks}

echo [1/$STEPS] Redis connection OK
echo [2/$STEPS] SQL ODB connection OK

# Start the load balancer first ..
cd $BASE_DIR/load-balancer
$ZATO_BIN start .
echo [3/$STEPS] Load-balancer started

# .. servers ..
{start_servers}
"""

zato_qs_start_tail = """
# .. web admin comes as the last one because it may ask Django-related questions.
cd $BASE_DIR/web-admin
$ZATO_BIN start .
echo [$STEPS/$STEPS] Web admin started

cd $BASE_DIR
echo Zato cluster $CLUSTER started
echo Visit https://zato.io/support for more information and support options
exit 0
"""

stop_servers_template = """
cd $BASE_DIR/{server_name}
$ZATO_BIN stop .
echo [{step_number}/$STEPS] {server_name} stopped
"""

zato_qs_stop_template = """#!/bin/bash

export ZATO_CLI_DONT_SHOW_OUTPUT=1

{script_dir}
ZATO_BIN={zato_bin}
STEPS={stop_steps}
CLUSTER={cluster_name}

echo Stopping the Zato cluster $CLUSTER

# Start the load balancer first ..
cd $BASE_DIR/load-balancer
$ZATO_BIN stop .
echo [1/$STEPS] Load-balancer stopped

# .. servers ..
{stop_servers}

cd $BASE_DIR/web-admin
$ZATO_BIN stop .
echo [$STEPS/$STEPS] Web admin stopped

cd $BASE_DIR
echo Zato cluster $CLUSTER stopped
"""

zato_qs_restart = """#!/bin/bash

{script_dir}
cd $BASE_DIR

$BASE_DIR/zato-qs-stop.sh
$BASE_DIR/zato-qs-start.sh
"""


class CryptoMaterialLocation(object):
    """ Locates and remembers location of various crypto material for Zato components.
    """
    def __init__(self, ca_dir, component_pattern):
        self.ca_dir = ca_dir
        self.component_pattern = component_pattern
        self.ca_certs_path = os.path.join(self.ca_dir, 'ca-material', 'ca-cert.pem')
        self.cert_path = None
        self.pub_path = None
        self.priv_path = None
        self.locate()
        
    def __repr__(self):
        return make_repr(self)
        
    def locate(self):
        for crypto_name in('cert', 'priv', 'pub'):
            path = os.path.join(self.ca_dir, 'out-{}'.format(crypto_name))
            for name in os.listdir(path):
                full_path = os.path.join(path, name)
                if '{}-{}'.format(self.component_pattern, crypto_name) in full_path:
                    setattr(self, '{}_path'.format(crypto_name), full_path)

################################################################################

class Create(ZatoCommand):
    """ Quickly creates a working cluster
    """
    needs_empty_dir = True
    allow_empty_secrets = True
    opts = deepcopy(common_odb_opts) + deepcopy(kvdb_opts)
    opts.append({'name':'--cluster_name', 'help':'Name to be given to the new cluster'})
    opts.append({'name':'--servers', 'help':'Number of servers to be created'})

    def _bunch_from_args(self, args, cluster_name):
        bunch = Bunch()
        bunch.path = args.path
        bunch.verbose = args.verbose
        bunch.store_log = args.store_log
        bunch.store_config = args.store_config
        bunch.odb_type = args.odb_type
        bunch.odb_host = args.odb_host
        bunch.odb_port = args.odb_port
        bunch.odb_user = args.odb_user
        bunch.odb_db_name = args.odb_db_name
        bunch.kvdb_host = args.kvdb_host
        bunch.kvdb_port = args.kvdb_port
        bunch.sqlite_path = getattr(args, 'sqlite_path', None)
        bunch.postgresql_schema = getattr(args, 'postgresql_schema', None)
        bunch.odb_password = args.odb_password
        bunch.kvdb_password = args.kvdb_password
        bunch.cluster_name = cluster_name

        return bunch
    
    def execute(self, args):
        """ Quickly creates Zato components
        1) CA and crypto material
        2) ODB
        3) ODB initial data
        4) servers
        5) load-balancer
        6) Web admin
        7) Scripts
        """

        if args.odb_type == 'sqlite':
            args.sqlite_path = os.path.join(args.path, 'zato.db')

        next_step = count(1)
        next_port = count(http_plain_server_port)
        cluster_name = getattr(args, 'cluster_name') or 'quickstart-{}'.format(random.getrandbits(20)).zfill(7)
        servers = int(getattr(args, 'servers') or DEFAULT_NO_SERVERS)

        server_names = OrderedDict()
        for idx in range(1, servers+1):
            server_names['{}'.format(idx)] = 'server{}'.format(idx)

        total_steps = 6 + servers
        admin_invoke_password = uuid4().hex
        broker_host = 'localhost'
        broker_port = 6379
        lb_host = 'localhost'
        lb_port = 11223
        lb_agent_port = 20151
        
        args_path = os.path.abspath(args.path)
        
        # This could've been set to True by user in the command-line so we'd want
        # to unset it so that individual commands quickstart invokes don't attempt
        # to store their own configs.
        args.store_config = False
        
        #
        # 1) CA
        #
        ca_path = os.path.join(args_path, 'ca')
        os.mkdir(ca_path)
        
        ca_args = self._bunch_from_args(args, cluster_name)
        ca_args.path = ca_path
        
        ca_create_ca.Create(ca_args).execute(ca_args, False)
        ca_create_lb_agent.Create(ca_args).execute(ca_args, False)
        
        ca_create_web_admin.Create(ca_args).execute(ca_args, False)
        
        server_crypto_loc = {}

        for name in server_names:
            ca_args_server = deepcopy(ca_args)
            ca_args_server.server_name = server_names[name]
            ca_create_server.Create(ca_args_server).execute(ca_args_server, False)
            server_crypto_loc[name] = CryptoMaterialLocation(ca_path, '{}-{}'.format(cluster_name, server_names[name]))
        
        lb_agent_crypto_loc = CryptoMaterialLocation(ca_path, 'lb-agent')
        web_admin_crypto_loc = CryptoMaterialLocation(ca_path, 'web-admin')
        
        self.logger.info('[{}/{}] Certificate authority created'.format(next_step.next(), total_steps))
        
        #
        # 2) ODB
        #
        if create_odb.Create(args).execute(args, False) == self.SYS_ERROR.ODB_EXISTS:
            self.logger.info('[{}/{}] ODB schema already exists'.format(next_step.next(), total_steps))
        else:
            self.logger.info('[{}/{}] ODB schema created'.format(next_step.next(), total_steps))

        #
        # 3) ODB initial data
        #
        create_cluster_args = self._bunch_from_args(args, cluster_name)
        create_cluster_args.broker_host = broker_host
        create_cluster_args.broker_port = broker_port
        create_cluster_args.lb_host = lb_host
        create_cluster_args.lb_port = lb_port
        create_cluster_args.lb_agent_port = lb_agent_port
        create_cluster_args.admin_invoke_password = admin_invoke_password
        create_cluster.Create(create_cluster_args).execute(create_cluster_args, False)
        
        self.logger.info('[{}/{}] ODB initial data created'.format(next_step.next(), total_steps))
        
        #
        # 4) servers
        #
        for name in server_names:
            server_path = os.path.join(args_path, server_names[name])
            os.mkdir(server_path)
            
            create_server_args = self._bunch_from_args(args, cluster_name)
            create_server_args.server_name = server_names[name]
            create_server_args.path = server_path
            create_server_args.cert_path = server_crypto_loc[name].cert_path
            create_server_args.pub_key_path = server_crypto_loc[name].pub_path
            create_server_args.priv_key_path = server_crypto_loc[name].priv_path
            create_server_args.ca_certs_path = server_crypto_loc[name].ca_certs_path
            
            create_server.Create(create_server_args).execute(create_server_args, next_port.next(), False)
            
            self.logger.info('[{}/{}] server{} created'.format(next_step.next(), total_steps, name))
            
        #
        # 5) load-balancer
        #
        lb_path = os.path.join(args_path, 'load-balancer')
        os.mkdir(lb_path)
        
        create_lb_args = self._bunch_from_args(args, cluster_name)
        create_lb_args.path = lb_path
        create_lb_args.cert_path = lb_agent_crypto_loc.cert_path
        create_lb_args.pub_key_path = lb_agent_crypto_loc.pub_path
        create_lb_args.priv_key_path = lb_agent_crypto_loc.priv_path
        create_lb_args.ca_certs_path = lb_agent_crypto_loc.ca_certs_path
        
        # Need to substract 1 because we've already called .next() twice
        # when creating servers above.
        servers_port = next_port.next() - 1
        
        create_lb.Create(create_lb_args).execute(create_lb_args, True, servers_port, False)
        self.logger.info('[{}/{}] Load-balancer created'.format(next_step.next(), total_steps))
        
        #
        # 6) Web admin
        #
        web_admin_path = os.path.join(args_path, 'web-admin')
        os.mkdir(web_admin_path)
        
        create_web_admin_args = self._bunch_from_args(args, cluster_name)
        create_web_admin_args.path = web_admin_path
        create_web_admin_args.cert_path = web_admin_crypto_loc.cert_path
        create_web_admin_args.pub_key_path = web_admin_crypto_loc.pub_path
        create_web_admin_args.priv_key_path = web_admin_crypto_loc.priv_path
        create_web_admin_args.ca_certs_path = web_admin_crypto_loc.ca_certs_path
        create_web_admin_args.admin_invoke_password = admin_invoke_password
        
        password = generate_password()
        admin_created = create_web_admin.Create(create_web_admin_args).execute(
            create_web_admin_args, False, password, True)
        
        # Need to reset the logger here because executing the create_web_admin command
        # loads the web admin's logger which doesn't like that of ours.
        self.reset_logger(args, True)
        self.logger.info('[{}/{}] Web admin created'.format(next_step.next(), total_steps))
        
        #
        # 7) Scripts
        #
        zato_bin = 'zato'
        zato_qs_start_path = os.path.join(args_path, 'zato-qs-start.sh')
        zato_qs_stop_path = os.path.join(args_path, 'zato-qs-stop.sh')
        zato_qs_restart_path = os.path.join(args_path, 'zato-qs-restart.sh')

        sanity_checks = []
        start_servers = []
        stop_servers = []

        for name in server_names:
            sanity_checks.append(sanity_checks_template.format(server_name=server_names[name]))
            start_servers.append(start_servers_template.format(server_name=server_names[name], step_number=int(name)+3))
            stop_servers.append(stop_servers_template.format(server_name=server_names[name], step_number=int(name)+1))

        sanity_checks = '\n'.join(sanity_checks)
        start_servers = '\n'.join(start_servers)
        stop_servers = '\n'.join(stop_servers)
        start_steps = 4 + servers
        stop_steps = 2 + servers

        zato_qs_start_head = zato_qs_start_head_template.format(zato_bin=zato_bin, script_dir=script_dir, cluster_name=cluster_name, start_steps=start_steps)
        zato_qs_start_body = zato_qs_start_body_template.format(sanity_checks=sanity_checks, start_servers=start_servers)
        zato_qs_start = zato_qs_start_head + zato_qs_start_body + zato_qs_start_tail

        zato_qs_stop = zato_qs_stop_template.format(zato_bin=zato_bin, script_dir=script_dir, cluster_name=cluster_name, stop_steps=stop_steps, stop_servers=stop_servers)

        open(zato_qs_start_path, 'w').write(zato_qs_start)
        open(zato_qs_stop_path, 'w').write(zato_qs_stop)
        open(zato_qs_restart_path, 'w').write(zato_qs_restart.format(script_dir=script_dir, cluster_name=cluster_name))

        file_mod = stat.S_IRUSR | stat.S_IWUSR | stat.S_IXUSR | stat.S_IRGRP
        
        os.chmod(zato_qs_start_path, file_mod)
        os.chmod(zato_qs_stop_path, file_mod)
        os.chmod(zato_qs_restart_path, file_mod)
        
        self.logger.info('[{}/{}] Management scripts created'.format(next_step.next(), total_steps))
        self.logger.info('Quickstart cluster {} created'.format(cluster_name))
        
        if admin_created:
            self.logger.info('Web admin user:[admin], password:[{}]'.format(password))
        else:
            self.logger.info('User [admin] already exists in the ODB')
            
        start_command = os.path.join(args_path, 'zato-qs-start.sh')
        self.logger.info('Start the cluster by issuing the {} command'.format(start_command))
        self.logger.info('Visit https://zato.io/support for more information and support options')

########NEW FILE########
__FILENAME__ = service
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import os
from contextlib import closing

# Bunch
from bunch import Bunch

# Zato
from zato.cli import ZatoCommand
from zato.client import AnyServiceInvoker, CID_NO_CLIP, DEFAULT_MAX_CID_REPR, DEFAULT_MAX_RESPONSE_REPR
from zato.common import BROKER, DATA_FORMAT, ZATO_INFO_FILE
from zato.common.crypto import CryptoManager
from zato.common.odb.model import HTTPBasicAuth, HTTPSOAP, Server
from zato.common.util import get_config

class Invoke(ZatoCommand):
    """ Invokes a service by its name
    """
    file_needed = ZATO_INFO_FILE

    opts = [
        {'name':'path', 'help':'Path in the file-system to a server the service is deployed on'},
        {'name':'name', 'help':'Name of the service to invoke'},
        {'name':'--payload', 'help':'Payload to invoke the service with'},
        {'name':'--headers',
         'help':'Additional HTTP headers the service invoker will receive in format of header-name=header-value; header2-name=header2-value'},
        {'name':'--channel', 'help':'Channel the service will be invoked through', 'default':'invoke'},
        {'name':'--data-format', 'help':"Payload's data format", 'default': 'json'},
        {'name':'--transport', 'help':'Transport to invoke the service over'},
        {'name':'--url-path', 'help':'URL path zato.service.invoke is exposed on', 'default':'/zato/admin/invoke'},
        {'name':'--max-cid-repr',
         'help':'How many characters of each end of a CID to print out in verbose mode, defaults to {}, use {} to print the whole of it'.format(
            DEFAULT_MAX_CID_REPR, CID_NO_CLIP), 'default':DEFAULT_MAX_CID_REPR},
        {'name':'--max-response-repr', 'help':'How many characters of a response to print out in verbose mode, defaults to {}'.format(
            DEFAULT_MAX_RESPONSE_REPR), 'default':DEFAULT_MAX_RESPONSE_REPR},
        {'name':'--async', 'help':'If given, the service will be invoked asynchronously', 'action':'store_true'},
        {'name':'--expiration', 'help':'In async mode, after how many seconds the message should expire, defaults to {} seconds'.format(
            BROKER.DEFAULT_EXPIRATION), 'default':BROKER.DEFAULT_EXPIRATION},
    ]

    def execute(self, args):

        repo_dir = os.path.join(os.path.abspath(os.path.join(self.original_dir, args.path)), 'config', 'repo')
        config = get_config(repo_dir, 'server.conf')

        headers = {}

        if args.headers:
            for pair in args.headers.strip().split(';'):
                k, v = pair.strip().split('=', 1)
                headers[k] = v

        repo_dir = os.path.join(os.path.abspath(os.path.join(args.path)), 'config', 'repo')
        config = get_config(repo_dir, 'server.conf')

        client = AnyServiceInvoker(
            'http://{}'.format(config.main.gunicorn_bind), args.url_path, self.get_server_client_auth(config, repo_dir),
            max_response_repr=int(args.max_response_repr), max_cid_repr=int(args.max_cid_repr))

        # Prevents attempts to convert/escape XML into JSON
        to_json = True if args.data_format == DATA_FORMAT.JSON else False

        func = client.invoke_async if args.async else client.invoke
        response = func(args.name, args.payload, headers, args.channel, args.data_format, args.transport, to_json=to_json)

        if response.ok:
            self.logger.info(response.data or '(None)')
        else:
            self.logger.error(response.details)

        if args.verbose:
            self.logger.debug('inner.text:[{}]'.format(response.inner.text))
            self.logger.debug('response:[{}]'.format(response))

########NEW FILE########
__FILENAME__ = start
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import json, os, sys

# Bunch
from bunch import Bunch

# ConfigObj
from configobj import ConfigObj

# Sarge
from sarge import capture_both, capture_stderr, run

# Zato
from zato.cli import ManageCommand
from zato.cli.check_config import CheckConfig
from zato.cli.stop import Stop
from zato.common import MISC
from zato.common.util import get_executable, get_haproxy_pidfile

class Start(ManageCommand):
    """Starts a Zato component installed in the 'path'. The same command is used for starting servers, load-balancer and web admin instances. 'path' must point to a directory into which the given component has been installed.

Examples:
  - Assuming a Zato server has been installed in /opt/zato/server1, the command to start the server is 'zato start /opt/zato/server1'.
  - If a load-balancer has been installed in /home/zato/lb1, the command to start it is 'zato start /home/zato/lb1'."""

    opts = [
        {'name':'--fg', 'help':'If given, the component will run in foreground', 'action':'store_true'}
    ]

    def run_check_config(self):
        cc = CheckConfig(self.args)
        cc.show_output = False
        cc.execute(Bunch(path='.'))

    def delete_pidfile(self):
        os.remove(os.path.join(self.component_dir, MISC.PIDFILE))

    def check_pidfile(self, pidfile=None):
        pidfile = pidfile or os.path.join(self.config_dir, MISC.PIDFILE)

        # If we have a pidfile of that name then we already have a running
        # server, in which case we refrain from starting new processes now.
        if os.path.exists(pidfile):
            msg = 'Error - found pidfile `{}`'.format(pidfile)
            self.logger.info(msg)
            return self.SYS_ERROR.COMPONENT_ALREADY_RUNNING

    def start_component(self, py_path, name, program_dir, on_keyboard_interrupt=None):
        """ Starts a component in background or foreground, depending on the 'fg' flag.
        """
        program = '{} -m {} {} {}'.format(get_executable(), py_path, program_dir, ('' if self.args.fg else '2>&1 >/dev/null'))
        try:
            run(program, async=False if self.args.fg else True)
        except KeyboardInterrupt:
            if on_keyboard_interrupt:
                on_keyboard_interrupt()
            sys.exit(0)

        if self.show_output:
            if not self.args.fg and self.verbose:
                self.logger.debug('Zato {} `{}` starting in background'.format(name, self.component_dir))
            else:
                self.logger.info('OK')

    def _on_server(self, show_output=True, *ignored):
        self.run_check_config()
        self.start_component('zato.server.main', 'server', self.component_dir, self.delete_pidfile)

    def _on_lb(self, *ignored):
        def stop_haproxy():
            Stop(self.args).stop_haproxy(self.component_dir)

        found_pidfile = self.check_pidfile()
        if not found_pidfile:
            found_pidfile = self.check_pidfile(get_haproxy_pidfile(self.component_dir))
            if not found_pidfile:
                self.start_component(
                    'zato.agent.load_balancer.main', 'load-balancer', os.path.join(self.config_dir, 'repo'), stop_haproxy)

    def _on_web_admin(self, *ignored):
        self.run_check_config()
        self.start_component('zato.admin.main', 'web admin', '', self.delete_pidfile)

########NEW FILE########
__FILENAME__ = stop
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import json, os, signal, sys

# Zato
from zato.cli import ManageCommand
from zato.common.util import get_haproxy_pidfile

class Stop(ManageCommand):
    """ Stops a Zato component
    """
    def signal(self, component_name, signal_name, signal_code, pidfile=None, component_dir=None):
        """ Sends a signal to a process known by its pidfile.
        """
        component_dir = component_dir or self.component_dir
        pidfile = pidfile or os.path.join(component_dir, 'pidfile')
        if not os.path.exists(pidfile):
            self.logger.error('No pidfile found in `%s`', pidfile)
            sys.exit(self.SYS_ERROR.FILE_MISSING)

        pid = open(pidfile).read().strip()
        if not pid:
            self.logger.error('Empty pidfile `%s`, did not attempt to stop `%s`', pidfile, component_dir)
            sys.exit(self.SYS_ERROR.NO_PID_FOUND)

        pid = int(pid)
        self.logger.debug('Will now send `%s` to pid `%s` (as found in `%s`)', signal_name, pid, pidfile)

        os.kill(pid, signal_code)
        os.remove(pidfile)

        self.logger.info('%s `%s` shutting down', component_name, component_dir)

    def _on_server(self, *ignored):
        self.signal('Server', 'SIGTERM', signal.SIGTERM)

    def stop_haproxy(self, component_dir):
        self.signal('Load-balancer', 'SIGTERM', signal.SIGTERM, get_haproxy_pidfile(component_dir), component_dir)

    def _on_lb(self, *ignored):
        self.stop_haproxy(self.component_dir)
        self.signal('Load-balancer\'s agent', 'SIGTERM', signal.SIGTERM)

    def _on_web_admin(self, *ignored):
        self.signal('Web admin', 'SIGTERM', signal.SIGTERM)

########NEW FILE########
__FILENAME__ = util
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import os
from contextlib import closing

# Bunch
from bunch import Bunch

# SQLAlchemy
import sqlalchemy
from sqlalchemy import orm

# Zato
from zato.client import AnyServiceInvoker
from zato.common import odb
from zato.common.crypto import CryptoManager
from zato.common.odb.util import get_engine_url
from zato.common.util import get_config

# ################################################################################################################################

class ZatoClient(AnyServiceInvoker):
    def __init__(self, *args, **kwargs):
        super(ZatoClient, self).__init__(*args, **kwargs)
        self.cluster_id = None
        self.odb_session = None

# ################################################################################################################################

def get_engine(args):
    return sqlalchemy.create_engine(get_engine_url(args))

def get_session(engine):
    session = orm.sessionmaker() # noqa
    session.configure(bind=engine)
    return session()

# ################################################################################################################################

def get_crypto_manager_from_server_config(config, repo_dir):

    priv_key_location = os.path.abspath(os.path.join(repo_dir, config.crypto.priv_key_location))

    cm = CryptoManager(priv_key_location=priv_key_location)
    cm.load_keys()

    return cm

# ################################################################################################################################

def get_odb_session_from_server_config(config, cm):

    engine_args = Bunch()
    engine_args.odb_type = config.odb.engine
    engine_args.odb_user = config.odb.username
    engine_args.odb_password = cm.decrypt(config.odb.password)
    engine_args.odb_host = config.odb.host
    engine_args.odb_port = config.odb.port
    engine_args.odb_db_name = config.odb.db_name

    return get_session(get_engine(engine_args))

# ################################################################################################################################

def get_server_client_auth(config, repo_dir):
    """ Returns credentials to authenticate with against Zato's own /zato/admin/invoke channel.
    """
    session = get_odb_session_from_server_config(config, get_crypto_manager_from_server_config(config, repo_dir))

    auth = None
    with closing(session) as session:
        cluster = session.query(odb.model.Server).\
            filter(odb.model.Server.token == config.main.token).\
            one().cluster

        channel = session.query(odb.model.HTTPSOAP).\
            filter(odb.model.HTTPSOAP.cluster_id == cluster.id).\
            filter(odb.model.HTTPSOAP.url_path == '/zato/admin/invoke').\
            filter(odb.model.HTTPSOAP.connection== 'channel').\
            one()

        if channel.security_id:
            security = session.query(odb.model.HTTPBasicAuth).\
                filter(odb.model.HTTPBasicAuth.id == channel.security_id).\
                first()

            if security:
                return (security.username, security.password)

# ################################################################################################################################

class Util(object):
    def __init__(self, server_path):
        self.server_path = server_path
        self.client = None

    def __repr__(self):
        return '<{} at {} for `{}`>'.format(self.__class__.__name__, hex(id(self)), self.server_path)

    def set_zato_client(self):

        repo_dir = os.path.join(os.path.abspath(os.path.join(self.server_path)), 'config', 'repo')
        config = get_config(repo_dir, 'server.conf')

        self.client = ZatoClient('http://{}'.format(config.main.gunicorn_bind),
            '/zato/admin/invoke', get_server_client_auth(config, repo_dir), max_response_repr=15000)

        session = get_odb_session_from_server_config(
            config, get_crypto_manager_from_server_config(config, repo_dir))

        self.client.cluster_id = session.query(odb.model.Server).\
            filter(odb.model.Server.token == config.main.token).\
            one().cluster_id

        self.client.odb_session = session

        # Sanity check
        self.client.invoke('zato.ping')

# ################################################################################################################################
########NEW FILE########
__FILENAME__ = web_admin_auth
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import json, os, sys

# Zato
from zato.admin.zato_settings import update_globals
from zato.cli import ManageCommand

# ################################################################################################################################

class _WebAdminAuthCommand(ManageCommand):
    def _prepare(self, args):
        os.chdir(args.path)
        base_dir = os.path.join(self.original_dir, args.path)
        config = json.loads(open(os.path.join(base_dir, './config/repo/web-admin.conf')).read())
        config['config_dir'] = os.path.abspath(args.path)
        update_globals(config, base_dir)
        os.environ['DJANGO_SETTINGS_MODULE'] = 'zato.admin.settings'

    def _ok(self, args):
        # Needed because Django took over our logging config
        self.reset_logger(args, True)
        self.logger.info('OK')

# ################################################################################################################################
        
class CreateUser(_WebAdminAuthCommand):
    """ Creates a new web admin user
    """
    class _FakeStdout(object):
        """ django.contrib.auth.management.commands.createsuperuser.Command needs a self.stdout
        so we fake it here
        """
        def __init__(self, logger):
            self.logger = logger

        def write(self, msg):
            self.logger.info(msg.strip())

    def execute(self, args):
        self._prepare(args)

        from django.contrib.auth.management.commands.createsuperuser import Command
        Command.stdout = CreateUser._FakeStdout(self.logger)
        Command().handle(interactive=True)

        self._ok(args)

# ################################################################################################################################

class UpdatePassword(_WebAdminAuthCommand):
    """ Updates a web admin user's password
    """
    opts = [
        {'name': 'username', 'help': 'Username to change the password of'},
    ]

    def execute(self, args):
        self._prepare(args)

        from django.contrib.auth.management.commands.changepassword import Command
        Command().handle(args.username)

        self._ok(args)

# ################################################################################################################################

class UpdateOpenID(_WebAdminAuthCommand):
    """ Updates a claimed OpenID for a user.
    """
    opts = [
        {'name': 'username', 'help': 'Username to change a claimed OpenID of'},
        {'name': 'claimed-id', 'help': 'Claimed OpenID to set of a user'},
    ]

    def execute(self, args):
        self._prepare(args)

        from django.contrib.auth.models import User
        from django_openid_auth.models import UserOpenID

        # Django took over logging and we need it back
        self.reset_logger(args, True)

        try:
            user = User.objects.get(username=args.username)
        except User.DoesNotExist:

            # We can only give up at that point, the user must exist.
            self.logger.error('Error: No such user [{}]'.format(args.username))
            sys.exit(self.SYS_ERROR.NO_SUCH_WEB_ADMIN_USER)

        claimed_id = getattr(args, 'claimed-id')

        try:
            user_open_id = UserOpenID.objects.get(user=user)
        except UserOpenID.DoesNotExist:
            user_open_id = UserOpenID()
            user_open_id.user = user

        user_open_id.claimed_id = claimed_id
        user_open_id.display_id = claimed_id # Same value for display_id
        user_open_id.save()

        self._ok(args)

# ################################################################################################################################

########NEW FILE########
__FILENAME__ = zato_command
#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import argparse

# Zato
from zato.cli import ca_create_ca as ca_create_ca_mod, ca_create_lb_agent as ca_create_lb_agent_mod, \
     ca_create_server as ca_create_server_mod, ca_create_web_admin as ca_create_web_admin_mod, \
     check_config as check_config_mod, component_version as component_version_mod, create_cluster as create_cluster_mod, \
     create_lb as create_lb_mod, create_odb as create_odb_mod, create_server as create_server_mod, \
     create_web_admin as create_web_admin_mod, crypto as crypto_mod, delete_odb as delete_odb_mod, \
     enmasse as enmasse_mod, FromConfig, info as info_mod, quickstart as quickstart_mod, run_command, service as service_mod, \
     start as start_mod, stop as stop_mod, web_admin_auth as web_admin_auth_mod
from zato.common import version as zato_version

def add_opts(parser, opts):
    """ Adds parser-specific options.
    """
    for opt in opts:
        arguments = {}
        for name in('help', 'action', 'default'):
            try:
                arguments[name] = opt[name]
            except KeyError:
                # Almost no command uses 'action' or 'default' parameters
                pass
            
        parser.add_argument(opt['name'], **arguments)

def get_parser():
    base_parser = argparse.ArgumentParser(add_help=False)
    base_parser.add_argument('--store-log', help='Whether to store an execution log', action='store_true')
    base_parser.add_argument('--verbose', help='Show verbose output', action='store_true')
    base_parser.add_argument(
        '--store-config',
        help='Whether to store config options in a file for a later use', action='store_true')

    parser = argparse.ArgumentParser(prog='zato')
    parser.add_argument('--version', action='version', version=zato_version)
    
    subs = parser.add_subparsers()

    #
    # ca
    #
    ca = subs.add_parser('ca', description='Basic certificate authority (CA) management')
    ca_subs = ca.add_subparsers()
    ca_create = ca_subs.add_parser('create', description='Creates crypto material for Zato components')
    ca_create_subs = ca_create.add_subparsers()

    ca_create_ca = ca_create_subs.add_parser('ca', description=ca_create_ca_mod.Create.__doc__, parents=[base_parser])
    ca_create_ca.set_defaults(command='ca_create_ca')
    ca_create_ca.add_argument('path', help='Path to an empty directory to hold the CA')
    add_opts(ca_create_ca, ca_create_ca_mod.Create.opts)

    ca_create_lb_agent = ca_create_subs.add_parser('lb_agent', description=ca_create_lb_agent_mod.Create.__doc__, parents=[base_parser])
    ca_create_lb_agent.set_defaults(command='ca_create_lb_agent')
    ca_create_lb_agent.add_argument('path', help='Path to a CA directory')
    add_opts(ca_create_lb_agent, ca_create_lb_agent_mod.Create.opts)
        
    ca_create_server = ca_create_subs.add_parser('server', description=ca_create_server_mod.Create.__doc__, parents=[base_parser])
    ca_create_server.set_defaults(command='ca_create_server')
    ca_create_server.add_argument('path', help='Path to a CA directory')
    add_opts(ca_create_server, ca_create_server_mod.Create.opts)

    ca_create_web_admin = ca_create_subs.add_parser('web_admin', description=ca_create_web_admin_mod.Create.__doc__, parents=[base_parser])
    ca_create_web_admin.set_defaults(command='ca_create_web_admin')
    ca_create_web_admin.add_argument('path', help='Path to a CA directory')
    add_opts(ca_create_web_admin, ca_create_web_admin_mod.Create.opts)

    #
    # check-config
    #
    check_config = subs.add_parser(
        'check-config',
        description='Checks config of a Zato component (currently limited to servers only)',
        parents=[base_parser])
    check_config.set_defaults(command='check_config')
    check_config.add_argument('path', help='Path to a Zato component')
    add_opts(check_config, check_config_mod.CheckConfig.opts)

    #
    # component-version
    #
    component_version = subs.add_parser(
        'component-version',
        description='Shows the version of a Zato component installed in a given directory',
        parents=[base_parser])
    component_version.set_defaults(command='component_version')
    component_version.add_argument('path', help='Path to a Zato component')
    add_opts(component_version, component_version_mod.ComponentVersion.opts)

    #
    # create
    #
    create = subs.add_parser('create', description='Creates new Zato components')
    create_subs = create.add_subparsers()

    create_cluster = create_subs.add_parser('cluster', description=create_cluster_mod.Create.__doc__, parents=[base_parser])
    create_cluster.set_defaults(command='create_cluster')
    add_opts(create_cluster, create_cluster_mod.Create.opts)
    
    create_lb = create_subs.add_parser('load_balancer', description=create_lb_mod.Create.__doc__, parents=[base_parser])
    create_lb.add_argument('path', help='Path to an empty directory to install the load-balancer in')
    create_lb.set_defaults(command='create_lb')
    add_opts(create_lb, create_lb_mod.Create.opts)

    create_odb = create_subs.add_parser('odb', description=create_odb_mod.Create.__doc__, parents=[base_parser])
    create_odb.set_defaults(command='create_odb')
    add_opts(create_odb, create_odb_mod.Create.opts)
    
    create_server = create_subs.add_parser('server', description=create_server_mod.Create.__doc__, parents=[base_parser])
    create_server.add_argument('path', help='Path to an empty directory to install the server in')
    create_server.set_defaults(command='create_server')
    add_opts(create_server, create_server_mod.Create.opts)

    create_user = create_subs.add_parser('user', description=web_admin_auth_mod.CreateUser.__doc__, parents=[base_parser])
    create_user.add_argument('path', help='Path to a web admin')
    create_user.set_defaults(command='create_user')
    add_opts(create_user, web_admin_auth_mod.CreateUser.opts)

    create_web_admin = create_subs.add_parser('web_admin', description=create_web_admin_mod.Create.__doc__, parents=[base_parser])
    create_web_admin.add_argument('path', help='Path to an empty directory to install a new web admin in')
    create_web_admin.set_defaults(command='create_web_admin')
    add_opts(create_web_admin, create_web_admin_mod.Create.opts)

    #
    # decrypt
    #
    decrypt = subs.add_parser('decrypt', description=crypto_mod.Decrypt.__doc__, parents=[base_parser])
    decrypt.add_argument('path', help='Path to the private key in PEM')
    decrypt.set_defaults(command='decrypt')
    add_opts(decrypt, crypto_mod.Decrypt.opts)

    #
    # delete
    #
    delete = subs.add_parser('delete', description=delete_odb_mod.Delete.__doc__)
    delete_subs = delete.add_subparsers()
    delete_odb = delete_subs.add_parser('odb', description='Deletes a Zato ODB', parents=[base_parser])
    delete_odb.set_defaults(command='delete_odb')
    add_opts(delete_odb, delete_odb_mod.Delete.opts)

    #
    # encrypt
    #
    encrypt = subs.add_parser('encrypt', description=crypto_mod.Encrypt.__doc__, parents=[base_parser])
    encrypt.add_argument('path', help='Path to the public key in PEM')
    encrypt.set_defaults(command='encrypt')
    add_opts(encrypt, crypto_mod.Encrypt.opts)

    #
    # enmasse
    #
    enmasse = subs.add_parser('enmasse', description=enmasse_mod.EnMasse.__doc__, parents=[base_parser])
    enmasse.add_argument('path', help='Path to a running Zato server')
    enmasse.set_defaults(command='enmasse')
    add_opts(enmasse, enmasse_mod.EnMasse.opts)

    #
    # info
    #
    info = subs.add_parser('info', description=info_mod.Info.__doc__, parents=[base_parser])
    info.add_argument('path', help='Path to a Zato component')
    info.set_defaults(command='info')
    add_opts(info, info_mod.Info.opts)

    #
    # from-config-file
    #
    from_config = subs.add_parser('from-config', description=FromConfig.__doc__, parents=[base_parser])
    from_config.add_argument('path', help='Path to a Zato command config file')
    from_config.set_defaults(command='from_config')

    #
    # quickstart
    #
    quickstart = subs.add_parser('quickstart', description='Quickly set up and manage Zato clusters', parents=[base_parser])
    quickstart_subs = quickstart.add_subparsers()

    quickstart_create = quickstart_subs.add_parser('create', description=quickstart_mod.Create.__doc__, parents=[base_parser])
    quickstart_create.add_argument('path', help='Path to an empty directory for the quickstart cluster')
    quickstart_create.set_defaults(command='quickstart_create')
    add_opts(quickstart_create, quickstart_mod.Create.opts)

    #
    # service
    #
    service = subs.add_parser('service', description='Commands related to the management of Zato services')
    service_subs = service.add_subparsers()
    
    service_invoke = service_subs.add_parser('invoke', description=service_mod.Invoke.__doc__, parents=[base_parser])
    service_invoke.set_defaults(command='service_invoke')
    add_opts(service_invoke, service_mod.Invoke.opts)

    #
    # start
    #
    start = subs.add_parser('start', description=start_mod.Start.__doc__, parents=[base_parser], formatter_class=argparse.RawDescriptionHelpFormatter)
    start.add_argument('path', help='Path to the Zato component to be started')
    start.set_defaults(command='start')
    add_opts(start, start_mod.Start.opts)

    #
    # stop
    #
    stop = subs.add_parser('stop', description=stop_mod.Stop.__doc__, parents=[base_parser])
    stop.add_argument('path', help='Path to the Zato component to be stopped')
    stop.set_defaults(command='stop')

    #
    # update
    #
    update = subs.add_parser('update', description='Updates Zato components and users')
    update_subs = update.add_subparsers()

    # .. update crypto

    update_crypto = update_subs.add_parser('crypto', description=crypto_mod.UpdateCrypto.__doc__, parents=[base_parser])
    update_crypto.add_argument('path', help='Path to a Zato component')
    update_crypto.set_defaults(command='update_crypto')
    add_opts(update_crypto, crypto_mod.UpdateCrypto.opts)

    # .. update password
    
    update_password = update_subs.add_parser('password', description=web_admin_auth_mod.UpdatePassword.__doc__, parents=[base_parser])
    update_password.add_argument('path', help='Path to a web admin directory')
    update_password.set_defaults(command='update_password')
    add_opts(update_password, web_admin_auth_mod.UpdatePassword.opts)

    # .. update password

    update_open_id = update_subs.add_parser('openid', description=web_admin_auth_mod.UpdateOpenID.__doc__, parents=[base_parser])
    update_open_id.add_argument('path', help='Path to a web admin directory')
    update_open_id.set_defaults(command='update_openid')
    add_opts(update_open_id, web_admin_auth_mod.UpdateOpenID.opts)

    return parser

def main():
    return run_command(get_parser().parse_args())

########NEW FILE########
__FILENAME__ = test_client
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from unittest import TestCase
from uuid import uuid4

# anyjson
from anyjson import dumps, loads

# lxml
from lxml import etree

# mock
from mock import patch

# nose
from nose.tools import eq_

# Zato
from zato.common import common_namespaces, ZATO_OK
from zato.common.test import rand_bool, rand_int, rand_object, rand_string
from zato.common.util import new_cid, make_repr
from zato.client import AnyServiceInvoker, CID_NO_CLIP, _Client, JSONClient, JSONSIOClient, \
     RawDataClient, _Response, SOAPClient, SOAPSIOClient, _StructuredResponse, XMLClient

# ##############################################################################

class FakeInnerResponse(object):
    def __init__(self, headers, ok, text, status_code):
        self.headers = headers
        self.ok = ok
        self.text = text
        self.status_code = status_code

class FakeSession(object):
    def __init__(self, response=None, auth=None):
        self.response = response
        self.auth = auth
        
    def post(self, address, request, headers):
        return self.response
    
# ##############################################################################

class _Base(TestCase):
    client_class = None
    
    def setUp(self):
        self.url = rand_string()
        self.auth = None
        self.path = rand_string()
        self.session = FakeSession()
        self.to_bunch = rand_bool()
        self.max_response_repr = 10000
        self.max_cid_repr = rand_int()
        self.logger = rand_object()
        
    def get_client(self, response):
        self.session.response = response
        
        return self.client_class(
            self.url, self.auth, self.path, self.session,
            self.to_bunch, self.max_response_repr, self.max_cid_repr)

# ##############################################################################
            
class JSONClientTestCase(_Base):
    client_class = JSONClient
    
    def test_client(self):

        cid = new_cid()
        headers = {'x-zato-cid':cid}
        ok = True
        text = dumps({rand_string(): rand_string()})
        status_code = rand_int()
        
        client = self.get_client(FakeInnerResponse(headers, ok, text, status_code))
        response = client.invoke()
        
        eq_(response.ok, ok)
        eq_(response.inner.text, text)
        eq_(response.data.items(), loads(text).items())
        eq_(response.has_data, True)
        eq_(response.cid, cid)
        
class XMLClientTestCase(_Base):
    client_class = XMLClient
    
    def test_client(self):

        cid = new_cid()
        headers = {'x-zato-cid':cid}
        ok = True
        text = '<abc>{}</abc>'.format(rand_string())
        status_code = rand_int()
        
        client = self.get_client(FakeInnerResponse(headers, ok, text, status_code))
        response = client.invoke()
        
        eq_(response.ok, ok)
        eq_(response.inner.text, text)
        eq_(etree.tostring(response.data), text)
        eq_(response.has_data, True)
        eq_(response.cid, cid)
        
class SOAPClientTestCase(_Base):
    client_class = SOAPClient
    
    def test_client_ok(self):

        cid = new_cid()
        headers = {'x-zato-cid':cid}
        ok = True
        _rand = rand_string()
        soap_action = rand_string()
        
        text = """
            <soapenv:Envelope xmlns:soapenv="http://schemas.xmlsoap.org/soap/envelope/">
             <soapenv:Body>
              <abc>{}</abc>
             </soapenv:Body>
            </soapenv:Envelope>""".format(_rand).strip()
        status_code = rand_int()
        
        client = self.get_client(FakeInnerResponse(headers, ok, text, status_code))
        response = client.invoke(soap_action)

        expected_response_data = """
            <abc xmlns:soapenv="http://schemas.xmlsoap.org/soap/envelope/">{}</abc>
            """.format(_rand).strip()

        eq_(response.details, None)
        eq_(response.ok, ok)
        eq_(response.inner.text, text)
        eq_(etree.tostring(response.data), expected_response_data)
        eq_(response.has_data, True)
        eq_(response.cid, cid)
        
    def test_client_no_soap_response(self):

        cid = new_cid()
        headers = {'x-zato-cid':cid}
        ok = False
        soap_action = rand_string()
        
        text = '<abc/>'
        status_code = rand_int()
        
        client = self.get_client(FakeInnerResponse(headers, ok, text, status_code))
        response = client.invoke(soap_action)
        
        eq_(response.ok, ok)
        eq_(response.details, 'No /soapenv:Envelope/soapenv:Body/*[1] in SOAP response')
        eq_(response.inner.text, text)
        eq_(response.has_data, False)
        eq_(response.cid, cid)
        
# ##############################################################################
        
class JSONSIOClientTestCase(_Base):
    client_class = JSONSIOClient
    
    def test_client(self):

        cid = new_cid()
        headers = {'x-zato-cid':cid}
        ok = True
        
        env = {
            'details': rand_string(),
            'result': ZATO_OK,
            'cid': cid
        }
        
        sio_payload_key = rand_string()
        sio_payload = {rand_string(): rand_string()}
        
        sio_response = {
            'zato_env': env,
            sio_payload_key: sio_payload
        }
        
        text = dumps(sio_response)
        status_code = rand_int()
        
        client = self.get_client(FakeInnerResponse(headers, ok, text, status_code))
        response = client.invoke()
        
        eq_(response.ok, ok)
        eq_(response.inner.text, text)
        eq_(response.data.items(), sio_response[sio_payload_key].items())
        eq_(response.has_data, True)
        eq_(response.cid, cid)
        eq_(response.cid, sio_response['zato_env']['cid'])
        eq_(response.details, sio_response['zato_env']['details'])
        
class SOAPSIOClientTestCase(_Base):
    client_class = SOAPSIOClient
    
    def test_client_ok(self):

        cid = new_cid()
        headers = {'x-zato-cid':cid}
        ok = True
        status_code = rand_int()
        rand_id, rand_name, soap_action = rand_string(), rand_string(), rand_string()

        sio_response = """<zato_outgoing_amqp_edit_response xmlns="https://zato.io/ns/20130518">
           <zato_env>
            <cid>{}</cid>
            <result>ZATO_OK</result>
           </zato_env>
           <item>
            <id>{}</id>
            <name>crm.account</name>
           </item>
          </zato_outgoing_amqp_edit_response>
        """.format(cid, rand_id, rand_name)

        text = """<soap:Envelope xmlns:soap="http://schemas.xmlsoap.org/soap/envelope/" xmlns="https://zato.io/ns/20130518">
             <soap:Body>
              {}
             </soap:Body>
            </soap:Envelope>""".format(sio_response).strip()
        
        client = self.get_client(FakeInnerResponse(headers, ok, text, status_code))
        response = client.invoke(soap_action, '')
        
        eq_(response.ok, ok)
        eq_(response.inner.text, text)
        eq_(response.has_data, True)
        eq_(response.cid, cid)

        path_items = (
            ('zato_env', 'cid'),
            ('zato_env', 'result'),
            ('item', 'id'),
            ('item', 'name'),
        )
        
        for items in path_items:
            path = '//zato:zato_outgoing_amqp_edit_response/zato:' + '/zato:'.join(items)
            xpath = etree.XPath(path, namespaces=common_namespaces)
            
            expected = xpath(etree.fromstring(text))[0].text
            actual = xpath(response.data)[0]
            
            self.assertEquals(expected, actual)
            
    def test_client_soap_fault(self):

        cid = new_cid()
        headers = {'x-zato-cid':cid}
        ok = False
        status_code = rand_int()
        soap_action = rand_string()

        text = b"""<?xml version='1.0' encoding='UTF-8'?>
 <SOAP-ENV:Envelope
   xmlns:SOAP-ENV="http://schemas.xmlsoap.org/soap/envelope/"
   xmlns:xsi="http://www.w3.org/1999/XMLSchema-instance"
   xmlns:xsd="http://www.w3.org/1999/XMLSchema">
    <SOAP-ENV:Body>
      <SOAP-ENV:Fault>
      <faultcode>SOAP-ENV:Client</faultcode>
 <faultstring><![CDATA[cid [K68438211212681798524426103126], faultstring
 [Traceback (most recent call last):
File
"/opt/zato/code/zato-server/src/zato/server/connection/http_soap/
channel.py", line 126, in dispatch
  service_info, response = handler.handle(cid, wsgi_environ, payload, transport,
  worker_store, self.simple_io_config, data_format, path_info)
File
"/opt/zato/code/zato-server/src/zato/server/connection/http_soap/
channel.py", line 227, in handle
  service_instance.handle()
File
"/opt/zato/code/zato-server/src/zato/server/service/internal/
definition/amqp.py", line 174, in handle
  filter(ConnDefAMQP.id==self.request.input.id).\
File
"/opt/zato/code/eggs/SQLAlchemy-0.7.9-py2.7-linux-x86_64.egg/sqlalchemy/
orm/query.py", line 2190, in one
  raise orm_exc.NoResultFound("No row was found for one()")
NoResultFound: No row was found for one()
]]]></faultstring>
       </SOAP-ENV:Fault>
   </SOAP-ENV:Body>
 </SOAP-ENV:Envelope>"""
        
        client = self.get_client(FakeInnerResponse(headers, ok, text, status_code))
        response = client.invoke(soap_action, '')
        
        eq_(response.ok, ok)
        eq_(response.inner.text, text)
        eq_(response.has_data, False)
        eq_(response.cid, cid)
        eq_('NoResultFound: No row was found for one()' in response.details.getchildren()[1].text, True)

# ##############################################################################

class AnyServiceInvokerTestCase(_Base):
    client_class = AnyServiceInvoker
    
    def test_client(self):

        cid = new_cid()
        headers = {'x-zato-cid':cid}
        ok = True
        status_code = rand_int()
        
        service_name = rand_string()
        service_response_name = '{}_response'.format(service_name)
        service_response_payload = {'service_id':5207, 'has_wsdl':True}
        service_response_dict = {'zato_service_has_wsdl_response':service_response_payload}
        service_response = dumps(service_response_dict).encode('base64')
        
        text = dumps({
            'zato_env':{'result':ZATO_OK, 'details':''},
            service_response_name: {
                'response':service_response
            }
        })
        
        client = self.get_client(FakeInnerResponse(headers, ok, text, status_code))
        response = client.invoke(service_name, '')
        
        eq_(response.ok, ok)
        eq_(response.inner.text, text)
        eq_(response.data.items(), service_response_payload.items())
        eq_(response.has_data, True)
        eq_(response.cid, cid)
        
# ##############################################################################

class RawDataClientTestCase(_Base):
    client_class = RawDataClient
    
    def test_client(self):

        cid = new_cid()
        headers = {'x-zato-cid':cid}
        ok = True
        text = rand_string()
        status_code = rand_int()
        
        client = self.get_client(FakeInnerResponse(headers, ok, text, status_code))
        response = client.invoke()
        
        eq_(response.ok, ok)
        eq_(response.inner.text, text)
        eq_(response.data, text)
        eq_(response.has_data, True)
        eq_(response.cid, cid)

# ##############################################################################

class NotImplementedErrorTestCase(_Base):
    
    def test_not_implemented_error(self):
        inner = FakeInnerResponse({}, rand_int(), rand_string(), rand_int())
        response_data = (inner, rand_bool(), rand_int(), rand_int(), None)
        
        self.assertRaises(NotImplementedError, _Response, *response_data)
        self.assertRaises(NotImplementedError, _StructuredResponse(*response_data).load_func)
        self.assertRaises(NotImplementedError, _StructuredResponse(*response_data).set_has_data)
        
class TestResponse(TestCase):
    def test_repr(self):
        
        class MyResponse(_Response):
            def init(self):
                pass
        
        cid = new_cid()
        ok = True
        text = rand_string()
        status_code = rand_int()
        inner_params = ({'x-zato-cid':cid}, ok, text, status_code)
        
        max_repr = ((3,3), (len(text), CID_NO_CLIP))
        for(max_response_repr, max_cid_repr) in max_repr:
            
            inner = FakeInnerResponse(*inner_params)
            response = MyResponse(inner, False, max_response_repr, max_cid_repr, None)
            response.ok = ok
            
            cid_ellipsis = '' if max_cid_repr == CID_NO_CLIP else '..'
            
            expected = 'ok:[{}] inner.status_code:[{}] cid:[{}{}{}], inner.text:[{}]>'.format(
                ok, status_code, cid[:max_cid_repr], cid_ellipsis, cid[-max_cid_repr:], text[:max_response_repr])
            
            eq_(repr(response).endswith(expected), True)

class TestSettingSessionAuth(TestCase):
    def test_setting_session_auth_no_previous_auth(self):
        auth = (uuid4().hex, uuid4().hex)
        client = _Client(uuid4().hex, uuid4().hex, auth)
        
        self.assertEqual(client.session.auth, auth)
        
    def test_setting_session_auth_has_previous_auth(self):
        auth1 = (uuid4().hex, uuid4().hex)
        auth2 = (uuid4().hex, uuid4().hex)
        
        session = FakeSession(uuid4, auth1)
        client = _Client(uuid4().hex, uuid4().hex, auth2, session=session)
        
        # Make sure we don't override already existing auth
        self.assertNotEqual(client.session.auth, auth2)
        
        # The previous auth should still be there
        self.assertEqual(client.session.auth, auth1)

class TestHeaders(TestCase):
    """ GH #221 - Clients don't always properly pass headers on to super classes.
    """
    class InnerInvokeResponse(object):
        def __init__(self, request, response_class, async, headers):
            self.request = request
            self.response_class = response_class
            self.async = async
            self.headers = headers

        def __repr__(self):
            return make_repr(self)

    def get_inner_invoke(self):
        return self.InnerInvokeResponse

    def test_clients(self):
        for class_ in AnyServiceInvoker, JSONClient, JSONSIOClient, XMLClient, RawDataClient, SOAPClient, SOAPSIOClient:
            with patch('zato.client._Client.inner_invoke', self.get_inner_invoke()):

                client = class_(*rand_string(2))

                header1, value1 = rand_string(2)
                header2, value2 = rand_string(2)
                headers = {header1:value1, header2:value2}

                response = client.invoke(rand_string(), headers=headers)
                eq_(sorted(headers.items()), sorted(response.headers.items()))

########NEW FILE########
__FILENAME__ = broker_message
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Bunch
from bunch import Bunch

MESSAGE = Bunch()
MESSAGE.MESSAGE_TYPE_LENGTH = 4
MESSAGE.TOKEN_LENGTH = 32
MESSAGE.TOKEN_START = MESSAGE.MESSAGE_TYPE_LENGTH
MESSAGE.TOKEN_END = MESSAGE.MESSAGE_TYPE_LENGTH + MESSAGE.TOKEN_LENGTH
MESSAGE.PAYLOAD_START = MESSAGE.MESSAGE_TYPE_LENGTH + MESSAGE.TOKEN_LENGTH
MESSAGE.NULL_TOKEN = '0' * MESSAGE.TOKEN_LENGTH

MESSAGE_TYPE = Bunch()
MESSAGE_TYPE.TO_SINGLETON = b'0000'
MESSAGE_TYPE.TO_PARALLEL_ANY = b'0001'
MESSAGE_TYPE.TO_PARALLEL_ALL = b'0002'

MESSAGE_TYPE.TO_AMQP_PUBLISHING_CONNECTOR_ALL = b'0003'
MESSAGE_TYPE.TO_AMQP_CONSUMING_CONNECTOR_ALL = b'0004'
MESSAGE_TYPE.TO_AMQP_CONNECTOR_ALL = b'0005'

MESSAGE_TYPE.TO_JMS_WMQ_PUBLISHING_CONNECTOR_ALL = b'0006'
MESSAGE_TYPE.TO_JMS_WMQ_CONSUMING_CONNECTOR_ALL = b'0007'
MESSAGE_TYPE.TO_JMS_WMQ_CONNECTOR_ALL = b'0008'

MESSAGE_TYPE.TO_ZMQ_PUBLISHING_CONNECTOR_ALL = b'0009'
MESSAGE_TYPE.TO_ZMQ_CONSUMING_CONNECTOR_ALL = b'0010'
MESSAGE_TYPE.TO_ZMQ_CONNECTOR_ALL = b'0011'

MESSAGE_TYPE.USER_DEFINED_START = b'5000'

TOPICS = {
    MESSAGE_TYPE.TO_SINGLETON: b'/zato/to-singleton',

    MESSAGE_TYPE.TO_PARALLEL_ANY: b'/zato/to-parallel/any',
    MESSAGE_TYPE.TO_PARALLEL_ALL: b'/zato/to-parallel/all',

    MESSAGE_TYPE.TO_AMQP_PUBLISHING_CONNECTOR_ALL: b'/zato/connector/amqp/publishing/all',
    MESSAGE_TYPE.TO_AMQP_CONSUMING_CONNECTOR_ALL: b'/zato/connector/amqp/consuming/all',
    MESSAGE_TYPE.TO_AMQP_CONNECTOR_ALL: b'/zato/connector/amqp/all',

    MESSAGE_TYPE.TO_JMS_WMQ_PUBLISHING_CONNECTOR_ALL: b'/zato/connector/jms-wmq/publishing/all',
    MESSAGE_TYPE.TO_JMS_WMQ_CONSUMING_CONNECTOR_ALL: b'/zato/connector/jms-wmq/consuming/all',
    MESSAGE_TYPE.TO_JMS_WMQ_CONNECTOR_ALL: b'/zato/connector/jms-wmq/all',

    MESSAGE_TYPE.TO_ZMQ_PUBLISHING_CONNECTOR_ALL: b'/zato/connector/zmq/publishing/all',
    MESSAGE_TYPE.TO_ZMQ_CONSUMING_CONNECTOR_ALL: b'/zato/connector/zmq/consuming/all',
    MESSAGE_TYPE.TO_ZMQ_CONNECTOR_ALL: b'/zato/connector/zmq/all',
}

KEYS = {k:v.replace('/zato','').replace('/',':') for k,v in TOPICS.items()}

SCHEDULER = Bunch()
SCHEDULER.CREATE = b'10000'
SCHEDULER.EDIT = b'10001'
SCHEDULER.DELETE = b'10002'
SCHEDULER.EXECUTE = b'10003'
SCHEDULER.JOB_EXECUTED = b'10004'

ZMQ_SOCKET = Bunch()
ZMQ_SOCKET.CLOSE = b'10100'

SECURITY = Bunch()
DEFINITION = Bunch()
OUTGOING = Bunch()
CHANNEL = Bunch()

SECURITY.BASIC_AUTH_CREATE = b'10200'
SECURITY.BASIC_AUTH_EDIT = b'10201'
SECURITY.BASIC_AUTH_DELETE = b'10202'
SECURITY.BASIC_AUTH_CHANGE_PASSWORD = b'10203'

SECURITY.TECH_ACC_CREATE = b'10300'
SECURITY.TECH_ACC_EDIT = b'10301'
SECURITY.TECH_ACC_DELETE = b'10302'
SECURITY.TECH_ACC_CHANGE_PASSWORD = b'10303'

SECURITY.WSS_CREATE = b'10400'
SECURITY.WSS_EDIT = b'10401'
SECURITY.WSS_DELETE = b'10402'
SECURITY.WSS_CHANGE_PASSWORD = b'10403'

DEFINITION.AMQP_CREATE = b'10500'
DEFINITION.AMQP_EDIT = b'10501'
DEFINITION.AMQP_DELETE = b'10502'
DEFINITION.AMQP_CHANGE_PASSWORD = b'10503'

DEFINITION.JMS_WMQ_CREATE = b'10504'
DEFINITION.JMS_WMQ_EDIT = b'10505'
DEFINITION.JMS_WMQ_DELETE = b'10506'

DEFINITION.ZMQ_CREATE = b'10507'
DEFINITION.ZMQ_EDIT = b'10508'
DEFINITION.ZMQ_DELETE = b'10509'

OUTGOING.AMQP_CREATE = b'10600'
OUTGOING.AMQP_EDIT = b'10601'
OUTGOING.AMQP_DELETE = b'10602'
OUTGOING.AMQP_PUBLISH = b'10603'

OUTGOING.JMS_WMQ_CREATE = b'10604'
OUTGOING.JMS_WMQ_EDIT = b'10605'
OUTGOING.JMS_WMQ_DELETE = b'10606'
OUTGOING.JMS_WMQ_SEND = b'10607'

OUTGOING.ZMQ_CREATE = b'10608'
OUTGOING.ZMQ_EDIT = b'10609'
OUTGOING.ZMQ_DELETE = b'10610'
OUTGOING.ZMQ_SEND = b'10611'

OUTGOING.SQL_CREATE_EDIT = b'10612' # Same for creating and updating the pools
OUTGOING.SQL_CHANGE_PASSWORD = b'10613'
OUTGOING.SQL_DELETE = b'10614'

OUTGOING.HTTP_SOAP_CREATE_EDIT = b'10615' # Same for creating and updating
OUTGOING.HTTP_SOAP_DELETE = b'10616'

OUTGOING.FTP_CREATE_EDIT = b'10617' # Same for creating and updating
OUTGOING.FTP_DELETE = b'10618'
OUTGOING.FTP_CHANGE_PASSWORD = b'10619'

CHANNEL.AMQP_CREATE = b'10700'
CHANNEL.AMQP_EDIT = b'10701'
CHANNEL.AMQP_DELETE = b'10702'
CHANNEL.AMQP_MESSAGE_RECEIVED = b'10703'

CHANNEL.JMS_WMQ_CREATE = b'10704'
CHANNEL.JMS_WMQ_EDIT = b'10705'
CHANNEL.JMS_WMQ_DELETE = b'10706'
CHANNEL.JMS_WMQ_MESSAGE_RECEIVED = b'10707'

CHANNEL.ZMQ_CREATE = b'10708'
CHANNEL.ZMQ_EDIT = b'10709'
CHANNEL.ZMQ_DELETE = b'10710'
CHANNEL.ZMQ_MESSAGE_RECEIVED = b'10711'

CHANNEL.HTTP_SOAP_CREATE_EDIT = b'10712' # Same for creating and updating
CHANNEL.HTTP_SOAP_DELETE = b'10713'
CHANNEL.HTTP_SOAP_AUDIT_RESPONSE = b'10714' # New in 2.0
CHANNEL.HTTP_SOAP_AUDIT_PATTERNS = b'10715' # New in 2.0
CHANNEL.HTTP_SOAP_AUDIT_STATE = b'10716' # New in 2.0
CHANNEL.HTTP_SOAP_AUDIT_CONFIG = b'10717' # New in 2.0

AMQP_CONNECTOR = Bunch()
AMQP_CONNECTOR.CLOSE = b'10801'

JMS_WMQ_CONNECTOR = Bunch()
JMS_WMQ_CONNECTOR.CLOSE = b'10802'

ZMQ_CONNECTOR = Bunch()
ZMQ_CONNECTOR.CLOSE = b'10803'

SERVICE = Bunch()
SERVICE.EDIT = b'10900'
SERVICE.DELETE = b'10901'
SERVICE.PUBLISH = b'10902'

HOT_DEPLOY = Bunch()
HOT_DEPLOY.CREATE = '11000'

STATS = Bunch()
STATS.DELETE = '11100'
STATS.DELETE_DAY = '11101'

SINGLETON = Bunch()
SINGLETON.CLOSE = b'11200'

# New in 2.0
SECURITY.OAUTH_CREATE = b'11300'
SECURITY.OAUTH_EDIT = b'11301'
SECURITY.OAUTH_DELETE = b'11302'
SECURITY.OAUTH_CHANGE_PASSWORD = b'11303'

# New in 2.0
MSG_NS = Bunch()
MSG_NS.CREATE = b'11400'
MSG_NS.EDIT = b'11401'
MSG_NS.DELETE = b'11402'

# New in 2.0
MSG_XPATH = Bunch()
MSG_XPATH.CREATE = b'11450'
MSG_XPATH.EDIT = b'11451'
MSG_XPATH.DELETE = b'11452'

# New in 2.0
MSG_JSON_POINTER = Bunch()
MSG_JSON_POINTER.CREATE = b'11500'
MSG_JSON_POINTER.EDIT = b'11501'
MSG_JSON_POINTER.DELETE = b'11502'

# New in 2.0
PUB_SUB_TOPIC = Bunch()
PUB_SUB_TOPIC.CREATE = b'11550'
PUB_SUB_TOPIC.EDIT = b'11551'
PUB_SUB_TOPIC.DELETE = b'11552'
PUB_SUB_TOPIC.ADD_DEFAULT_PRODUCER = b'11553'
PUB_SUB_TOPIC.DELETE_DEFAULT_PRODUCER = b'11554'

# New in 2.0
PUB_SUB_PRODUCER = Bunch()
PUB_SUB_PRODUCER.CREATE = b'11600'
PUB_SUB_PRODUCER.EDIT = b'11601'
PUB_SUB_PRODUCER.DELETE = b'11602'

# New in 2.0
PUB_SUB_CONSUMER = Bunch()
PUB_SUB_CONSUMER.CREATE = b'11650'
PUB_SUB_CONSUMER.EDIT = b'11651'
PUB_SUB_CONSUMER.DELETE = b'11652'

# New in 2.0
CLOUD = Bunch()
CLOUD.OPENSTACK_SWIFT_CREATE_EDIT = b'11700'
CLOUD.OPENSTACK_SWIFT_DELETE = b'11701'

# New in 2.0
SECURITY.NTLM_CREATE = b'11750'
SECURITY.NTLM_EDIT = b'11751'
SECURITY.NTLM_DELETE = b'11752'
SECURITY.NTLM_CHANGE_PASSWORD = b'11753'

# New in 2.0
SECURITY.AWS_CREATE = b'11760'
SECURITY.AWS_EDIT = b'11761'
SECURITY.AWS_DELETE = b'11762'
SECURITY.AWS_CHANGE_PASSWORD = b'11763'

# New in 2.0
CLOUD.AWS_S3_CREATE_EDIT = b'11800'
CLOUD.AWS_S3_DELETE = b'11801'

# New in 2.0
SECURITY.OPENSTACK_CREATE = b'11850'
SECURITY.OPENSTACK_EDIT = b'11851'
SECURITY.OPENSTACK_DELETE = b'11852'
SECURITY.OPENSTACK_CHANGE_PASSWORD = b'11853'

# New in 2.0
NOTIF = Bunch()
NOTIF.RUN_NOTIFIER = b'11900'
NOTIF.CLOUD_OPENSTACK_SWIFT_CREATE_EDIT = b'11901'
NOTIF.CLOUD_OPENSTACK_SWIFT_DELETE = b'11902'

# New in 2.0
SECURITY.APIKEY_CREATE = b'12000'
SECURITY.APIKEY_EDIT = b'12001'
SECURITY.APIKEY_DELETE = b'12002'
SECURITY.APIKEY_CHANGE_PASSWORD = b'12003'

# New in 2.0
SECURITY.XPATH_SEC_CREATE = b'12100'
SECURITY.XPATH_SEC_EDIT = b'12101'
SECURITY.XPATH_SEC_DELETE = b'12102'
SECURITY.XPATH_SEC_CHANGE_PASSWORD = b'12103'

code_to_name = {}

# To prevent 'RuntimeError: dictionary changed size during iteration'
bunch_name, bunch = None, None

for bunch_name, bunch in globals().items():
    if isinstance(bunch, Bunch) and not bunch is Bunch:
        if bunch not in(MESSAGE, MESSAGE_TYPE):
            for code_name, code_value in bunch.items():
                code_name = bunch_name + '_' + code_name
                code_to_name[code_value] = code_name

del bunch_name, bunch, code_name, code_value

########NEW FILE########
__FILENAME__ = component_info
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import os
from anyjson import dumps as json_dumps, loads as json_loads
from cStringIO import StringIO
from datetime import datetime
from itertools import chain, groupby
from operator import attrgetter, itemgetter

# pyaml
import pyaml

# psutil
from psutil import CONN_LISTEN, Process

# PyYAML
import yaml

# pytz
from pytz import UTC

# Texttable
from texttable import Texttable

# Zato
from zato.common import INFO_FORMAT, MISC, ZATO_INFO_FILE
from zato.common.util import current_host

def format_connections(conns, format):
    """ Formats a list of connections according to the output format.
    """
    groups = (groupby(conns, key=attrgetter('status')))
    out = {}

    for status, items in groups:
        items = list(items)
        items.sort(key=attrgetter('raddr'))
        out_items = out.setdefault(status, [])

        for item in items:

            laddr_str = ':'.join(str(elem) for elem in item.laddr).ljust(21).decode('utf-8')
            raddr_str = ':'.join(str(elem) for elem in item.raddr).rjust(21).decode('utf-8')

            out_item = {
                'from': '{}:{}'.format(*item.laddr),
                'to': None,
                'formatted': None,
            }

            if item.raddr:
                out_item['to'] = '{}:{}'.format(*item.raddr)
                out_item['formatted'] = '{} -> {}'.format(laddr_str, raddr_str)
            else:
                out_item['formatted'] = '{}:{}'.format(*item.laddr)

            out_items.append(out_item)

    return out

def get_info(component_path, format):
    component_details = open(os.path.join(component_path, ZATO_INFO_FILE)).read()

    out = {
        'component_details': component_details,
        'component_full_path': component_path,
        'component_host': current_host(),
        'component_running': False,
        'current_time': datetime.now().isoformat(),
        'current_time_utc': datetime.utcnow().isoformat(),
        'master_proc_connections': None,
        'master_proc_pid': None,
        'master_proc_name': None,
        'master_proc_create_time': None,
        'master_proc_create_time_utc': None,
        'master_proc_username': None,
        'master_proc_workers_no': None,
        'master_proc_workers_pids': None,
    }

    master_proc_pid = None
    try:
        master_proc_pid = int(open(os.path.join(component_path, MISC.PIDFILE)).read())
    except(IOError, ValueError):
        # Ok, no such file or it's empty
        pass

    if master_proc_pid:
        out['component_running'] = True
        master_proc = Process(master_proc_pid)
        workers_pids = sorted(elem.pid for elem in master_proc.children())

        out['master_proc_connections'] = format_connections(master_proc.connections(), format)
        out['master_proc_pid'] = master_proc.pid
        out['master_proc_create_time'] = datetime.fromtimestamp(master_proc.create_time()).isoformat()
        out['master_proc_create_time_utc'] = datetime.fromtimestamp(master_proc.create_time(), UTC).isoformat()
        out['master_proc_username'] = master_proc.username()
        out['master_proc_name'] = master_proc.name()
        out['master_proc_workers_no'] = len(workers_pids)
        out['master_proc_workers_pids'] = workers_pids

        for pid in workers_pids:
            worker = Process(pid)
            out['worker_{}_create_time'.format(pid)] = datetime.fromtimestamp(worker.create_time()).isoformat()
            out['worker_{}_create_time_utc'.format(pid)] = datetime.fromtimestamp(worker.create_time(), UTC).isoformat()
            out['worker_{}_connections'.format(pid)] = format_connections(worker.connections(), format)

    return out

def format_info(value, format, cols_width=None, dumper=None):
    if format in(INFO_FORMAT.DICT, INFO_FORMAT.JSON, INFO_FORMAT.YAML):
        value['component_details'] = json_loads(value['component_details'])

    if format == INFO_FORMAT.JSON:
        return json_dumps(value)

    elif format == INFO_FORMAT.YAML:
        buff = StringIO()
        yaml.dump_all([value], default_flow_style=False, indent=4, Dumper=dumper, stream=buff)
        value = buff.getvalue()
        buff.close()

        return value

    elif format == INFO_FORMAT.TEXT:
        cols_width = (elem.strip() for elem in cols_width.split(','))
        cols_width = [int(elem) for elem in cols_width]

        table = Texttable()
        table.set_cols_width(cols_width)

        # Use text ('t') instead of auto so that boolean values don't get converted into ints
        table.set_cols_dtype(['t', 't'])

        rows = [['Key', 'Value']]
        rows.extend(sorted(value.items()))

        table.add_rows(rows)

        return table.draw()

    else:
        return value
########NEW FILE########
__FILENAME__ = crypto
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from base64 import b64decode, b64encode
from hashlib import sha256

# PyCrypto
from Crypto.PublicKey import RSA as pycrypto_rsa

# rsa
import rsa

logger = logging.getLogger(__name__)

class CryptoManager(object):
    """ Responsible for management of the server's crypto material.
    """
    def __init__(self, priv_key_location=None, priv_key=None, pub_key_location=None, pub_key=None):
        
        self.priv_key_location = priv_key_location
        self.priv_key = priv_key
        
        self.pub_key_location = pub_key_location
        self.pub_key = pub_key
        
    def _pkcs1_from_pkcs8(self, pkcs8):
        """ Private keys saved by CLI are in PKCS#8 but the rsa module needs PKCS#1.
        Note that PKCS#8 deals with private keys only (https://tools.ietf.org/html/rfc5208).
        """
        key = pycrypto_rsa.importKey(pkcs8)
        return key.exportKey()

    def load_keys(self):
        
        if self.pub_key_location:
            pkcs1 = open(self.pub_key_location).read()
            self.pub_key = rsa.key.PublicKey.load_pkcs1_openssl_pem(pkcs1)
        else:
            if self.priv_key_location:
                pkcs8 = open(self.priv_key_location).read()
                pkcs1 = self._pkcs1_from_pkcs8(pkcs8)
            elif self.priv_key:
                pkcs1 = self._pkcs1_from_pkcs8(self._pkcs1_from_pkcs8(self.priv_key))
                
            self.priv_key = rsa.key.PrivateKey.load_pkcs1(pkcs1)
            self.pub_key = rsa.key.PublicKey(self.priv_key.n, self.priv_key.e)

    def decrypt(self, data, hexlified=True):
        """ Decrypts data using the private config key. Padding used defaults
        to PKCS#1. hexlified defaults to True and indicates whether the data
        should be hex-decoded before being decrypted.
        """
        if hexlified:
            data = b64decode(data)

        return rsa.decrypt(data, self.priv_key)

    def encrypt(self, data, b64=True):
        """ Encrypts data using the public config key. Padding used defaults
        to PKCS#1. b64 defaults to True and indicates whether the data
        should be BASE64-encoded after being encrypted.
        """
        encrypted = rsa.encrypt(data, self.pub_key)
        if b64:
            return b64encode(encrypted)

        return encrypted

    def reset(self):
        """ Sets all the keys to None.
        """
        self.priv_key_location = None
        self.pub_key_location = None
        
        self.priv_key = None
        self.pub_key = None

########NEW FILE########
__FILENAME__ = defaults
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

# A place for storing all the defaults values.

web_admin_host = '0.0.0.0'
web_admin_port = 8183

http_plain_server_port = 17010

########NEW FILE########
__FILENAME__ = delivery
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import csv
from contextlib import closing
from datetime import datetime, timedelta
from json import dumps, loads
from logging import getLogger, DEBUG
from sys import maxint
from traceback import format_exc

# Bunch
from bunch import Bunch

# gevent
from gevent import sleep, spawn_later

# Paste
from paste.util.converters import asbool

# retools
from retools.lock import Lock

# SQLAlchemy
from sqlalchemy.orm.query import orm_exc

# WebHelpers
from webhelpers.paginate import Page

# Zato
from zato.common import CHANNEL, DATA_FORMAT, DELIVERY_CALLBACK_INVOKER, DELIVERY_COUNTERS, \
     DELIVERY_HISTORY_ENTRY, DELIVERY_STATE, INVOCATION_TARGET, KVDB
from zato.common.broker_message import SERVICE
from zato.common.odb.model import Delivery, DeliveryDefinitionBase, DeliveryDefinitionOutconnWMQ, \
     DeliveryHistory, DeliveryPayload
from zato.common.odb.query import delivery, delivery_list
from zato.common.util import datetime_to_seconds, new_cid
from zato.redis_paginator import ZSetPaginator

NULL_BASIC_DATA = {
    'last_updated_utc':None,
    DELIVERY_COUNTERS.TOTAL:0,
    DELIVERY_COUNTERS.IN_PROGRESS:0, 
    DELIVERY_COUNTERS.IN_DOUBT:0,
    DELIVERY_COUNTERS.CONFIRMED:0,
    DELIVERY_COUNTERS.FAILED:0
}

_target_def_class = {
    INVOCATION_TARGET.OUTCONN_WMQ: DeliveryDefinitionOutconnWMQ
}

DELIVERY_KEYS = ('def_name', 'target_type', 'task_id', 'creation_time_utc', 'last_used_utc', 
            'source_count', 'target_count', 'resubmit_count', 'state', 'retry_repeats', 'check_after', 'retry_seconds')

PAYLOAD_KEYS = DELIVERY_KEYS + ('payload', 'args', 'kwargs')
PAYLOAD_ALL_KEYS = PAYLOAD_KEYS + ('target',)

LOCK_TIMEOUT = 0.2
RETRY_SLEEP = 5

def _item_from_api(delivery_def_base, target, payload, task_id, invoke_func, args, kwargs):
    """ Creates an invocation context. 
    """
    return Bunch({
        'task_id': task_id,
        'def_id': delivery_def_base.id,
        'def_name': delivery_def_base.name,
        'target': target,
        'target_type': delivery_def_base.target_type,
        'expire_after': delivery_def_base.expire_after,
        'check_after': delivery_def_base.check_after,
        'retry_repeats': delivery_def_base.retry_repeats,
        'retry_seconds': delivery_def_base.retry_seconds,
        'payload': payload,
        'invoke_func': invoke_func,
        'args': dumps(args),
        'kwargs': dumps(kwargs),
        'log_name': '{}/{}/{}'.format(delivery_def_base.name, target, task_id),
    })

# ##############################################################################

class DeliveryStore(object):
    """ Stores messages in a persistent storage until they are confirmed to have been delivered.
    """
    def __init__(self, kvdb=None, broker_client=None, odb=None, delivery_lock_timeout=None):
        self.kvdb = kvdb
        self.broker_client = broker_client
        self.odb = odb
        self.delivery_lock_timeout = delivery_lock_timeout
        self.logger = getLogger(self.__class__.__name__)
        
# ##############################################################################

    def _history_from_source(self, delivery, item, now, entry_type):
        history = DeliveryHistory()
        history.task_id = item.task_id
        history.entry_type = entry_type
        history.entry_time = now
        history.entry_ctx = DELIVERY_HISTORY_ENTRY.NONE
        history.delivery = delivery
        history.resubmit_count = delivery.resubmit_count
        
        return history

    def _validate_register(self, item):
        if not(item.check_after and item.retry_repeats and item.retry_seconds):
            msg = 'check_after:[{}], retry_repeats:[{}] and retry_seconds:[{}] are all required'.format(
                item.check_after, item.retry_repeats, item.retry_seconds)
            self.logger.error(msg)
            raise ValueError(msg)
        
    def _invoke_delivery_service(self, item):
        """ Invokes the target via a delivery service. 
        """
        delivery_req = {}
        for name in('task_id', 'payload', 'target', 'target_type', 'args', 'kwargs'):
            delivery_req[name] = item[name]
            
        item.invoke_func('zato.pattern.delivery.dispatch', delivery_req)
        
    def register_invoke_schedule(self, item, is_resubmit=False, is_auto=False):
        """ Registers the task, invokes target and schedules a check to find out if the invocation was OK.
        """
        now = datetime.utcnow()
        
        # Sanity check - did we get everything that was needed?
        self._validate_register(item)

        # First, save everything in the ODB
        with closing(self.odb.session()) as session:
            
            if is_resubmit:
                delivery = session.merge(self.get_delivery(item.task_id))
                delivery.state = DELIVERY_STATE.IN_PROGRESS_RESUBMITTED_AUTO if is_auto else DELIVERY_STATE.IN_PROGRESS_RESUBMITTED
                delivery.resubmit_count += 1
                delivery.last_used = now
                delivery.args = item.args
                delivery.kwargs = item.kwargs
                delivery.payload.payload = item.payload
                
                session.add(
                    self._history_from_source(
                        delivery, item, now, 
                        DELIVERY_HISTORY_ENTRY.SENT_FROM_SOURCE_RESUBMIT_AUTO if is_auto else DELIVERY_HISTORY_ENTRY.SENT_FROM_SOURCE_RESUBMIT))
                
            else:
                delivery = Delivery()
                delivery.task_id = item.task_id
                delivery.name = '{}/{}/{}'.format(item.def_name, item.target, item.target_type)
                delivery.creation_time = now
                delivery.args = item.args
                delivery.kwargs = item.kwargs
                delivery.state = DELIVERY_STATE.IN_PROGRESS_STARTED
                delivery.definition_id = item.def_id
                
                payload = DeliveryPayload()
                payload.task_id = item.task_id
                payload.creation_time = now
                payload.payload = item.payload
                payload.delivery = delivery
                
                session.add(delivery)
                session.add(payload)
                session.add(self._history_from_source(delivery, item, now, DELIVERY_HISTORY_ENTRY.SENT_FROM_SOURCE))
    
                # Flush the session so the newly created delivery's definition can be reached ..
                session.flush()
                
                # .. update time the delivery was last used ..
                delivery.last_used = now
                delivery.definition.last_used = now
                
            resubmit_count = delivery.resubmit_count
            
            # .. and commit the whole transaction.
            session.commit()
            
        self.logger.info(
          'Submitting delivery [%s] for target:[%s] (%s/%s), resubmit:[%s], expire_after:[%s], check_after:[%s], retry_repeats:[%s], retry_seconds:[%s]',
            item.task_id, item.target, item.def_name, item.target_type, resubmit_count, 
            item.expire_after, item.check_after, item.retry_repeats, item.retry_seconds)
        
        # Invoke the target now that things are in the ODB
        self._invoke_delivery_service(item)

        # Spawn a greenlet to check whether target confirmed delivery
        self.spawn_check_target(item, item.check_after)

# ##############################################################################
        
    def spawn_check_target(self, item, check_after):
        """ Spawns a greenlet that checks whether the target replied and acts accordingly.
        """
        spawn_later(check_after, self.check_target, item)
        
    def _invoke_callbacks(self, target, target_type, delivery, target_ok, in_doubt, invoker):
        """ Asynchronously notifies all callback services of the outcome of the target's invocation.
        """
        callback_list = delivery.definition.callback_list
        callback_list = callback_list.split(',') or []
        
        payload = dumps({
            'target_ok': target_ok,
            'in_doubt': in_doubt,
            'task_id': delivery.task_id,
            'target': target,
            'target_type': target_type,
            'invoker': invoker
        })

        for service in callback_list:
            if service:
                broker_msg = {}
                broker_msg['action'] = SERVICE.PUBLISH
                broker_msg['task_id'] = delivery.task_id
                broker_msg['channel'] = CHANNEL.DELIVERY
                broker_msg['data_format'] = DATA_FORMAT.JSON
                broker_msg['service'] = service
                broker_msg['payload'] = payload
                broker_msg['cid'] = new_cid()
                
                try:
                    self.broker_client.invoke_async(broker_msg)
                except Exception, e:
                    msg = 'Could not invoke callback:[%s], task_id:[%s], e:[%s]'.format(
                        service, delivery.task_id, format_exc(e))
                    self.logger.warn(msg)
        
# ##############################################################################
        
    def _on_in_doubt(self, item, delivery, now):
        """ Delivery enteres an in-doubt state.
        """
        with closing(self.odb.session()) as session:
            delivery = session.merge(delivery)
            delivery.state = DELIVERY_STATE.IN_DOUBT
            delivery.last_used = now
            delivery.definition.last_used = now
            
            history = DeliveryHistory()
            history.task_id = delivery.task_id
            history.entry_type = DELIVERY_HISTORY_ENTRY.ENTERED_IN_DOUBT
            history.entry_time = now
            history.entry_ctx = DELIVERY_HISTORY_ENTRY.NONE
            history.delivery = delivery
            history.resubmit_count = delivery.resubmit_count
            
            session.add(delivery)
            session.add(history)
            
            session.commit()
            
            self._invoke_callbacks(item.target, item.target_type, delivery, False, True, DELIVERY_CALLBACK_INVOKER.SOURCE)
            
            msg = 'Delivery [%s] is in-doubt (source/target %s/%s)'
            self.logger.warn(msg, item.log_name, delivery.source_count, delivery.target_count)
            
    def finish_delivery(self, delivery, target_ok, now_dt, item):
        """ Called after running out of attempts to deliver the payload.
        """
        with closing(self.odb.session()) as session:
            delivery = session.merge(delivery)
            
            if target_ok:
                msg_prefix = 'Confirmed delivery'
                log_func = self.logger.info
                expires = delivery.definition.expire_arch_succ_after
                delivery_state = DELIVERY_STATE.CONFIRMED
                history_entry_type = DELIVERY_HISTORY_ENTRY.ENTERED_CONFIRMED
            else:
                msg_prefix = 'Delivery failed'
                log_func = self.logger.warn
                expires = delivery.definition.expire_arch_fail_after
                delivery_state = DELIVERY_STATE.FAILED
                history_entry_type = DELIVERY_HISTORY_ENTRY.ENTERED_FAILED
            
            delivery.state = delivery_state
            delivery.last_used = now_dt
            delivery.definition.last_used = now_dt
                
            history = DeliveryHistory()
            history.task_id = delivery.task_id
            history.entry_type = history_entry_type
            history.entry_time = now_dt
            history.entry_ctx = DELIVERY_HISTORY_ENTRY.NONE
            history.delivery = delivery
            history.resubmit_count = delivery.resubmit_count
            
            session.add(delivery)
            session.add(history)
            
            session.commit()
            
            self._invoke_callbacks(item.target, item.target_type, delivery, target_ok, False, DELIVERY_CALLBACK_INVOKER.SOURCE)
                
            msg = '{} [{}] after {}/{} attempts, archive expires in {} hour(s) ({} UTC)'.format(
                msg_prefix, item.log_name, delivery.source_count, delivery.definition.retry_repeats, 
                expires, now_dt + timedelta(hours=expires))
            
            log_func(msg)
            
    def retry(self, delivery, item, now):
        with closing(self.odb.session()) as session:
            delivery = session.merge(delivery)
            delivery.last_used = now
            delivery.definition.last_used = now
            delivery.source_count += 1

            # 'source_count' is needed outside of the 'with' statement because
            # we want to sleep a bit and there's no need to keep the session open in that time.
            source_count = delivery.source_count
            
            session.add(delivery)
            session.add(self._history_from_source(delivery, item, datetime.utcnow(), DELIVERY_HISTORY_ENTRY.ENTERED_RETRY))
            session.commit()
            
            # Sleep a constant time so we're sure any locks related to that task are released
            sleep(RETRY_SLEEP)
            
        self.logger.info('Retrying delivery [%s] (%s/%s)', item.log_name, source_count, item.retry_repeats)
        
        self._invoke_delivery_service(item)
        self.spawn_check_target(item, item.retry_seconds)
                
# ##############################################################################
        
    def check_target(self, item):
        self.logger.debug('Checking name/target/task_id [%s]', item.log_name)
        
        if self.is_deleted(item.def_name):
            self.logger.info('Stopping [%s] (definition.is_deleted->True)', item.log_name)
            return
        
        now_dt = datetime.utcnow()
        now = now_dt.isoformat()
        lock_name = '{}{}'.format(KVDB.LOCK_DELIVERY, item.task_id)
        
        with closing(self.odb.session()) as session:
            try:
                delivery = session.merge(self.get_delivery(item.task_id))
                payload = delivery.payload.payload
            except orm_exc.NoResultFound, e:
                # Apparently the delivery was deleted since the last time we were scheduled to run
                self.logger.info('Stopping [%s] (NoResultFound->True)', item.log_name)
                return
        
        # Fetch new values because it's possible they have been changed since the last time we were invoked
        item['payload'] = payload
        item['args'] = delivery.args
        item['kwargs'] = delivery.kwargs
        
        with Lock(lock_name, self.delivery_lock_timeout, LOCK_TIMEOUT, self.kvdb.conn):

            # Target did not reply at all hence we're entering in-doubt
            if delivery.source_count > delivery.target_count:
                self._on_in_doubt(item, delivery, now)
                
            else:
                # The target has confirmed the invocation in an expected time so we
                # now need to check if it was successful. If it was, this is where it ends,
                # it wasn't, we'll try again as it was originally configured unless
                # it was the last retry.
                
                target_ok = delivery.state == DELIVERY_STATE.IN_PROGRESS_TARGET_OK
                
                # All good, we can stop now.
                if target_ok:
                    self.finish_delivery(delivery, target_ok, now_dt, item)
                    
                # Not so good, we know there was an error.
                else:
                    # Can we try again?
                    if delivery.source_count < item.retry_repeats:
                        self.retry(delivery, item, now)

                    # Nope, that was the last attempt.
                    else:
                        self.finish_delivery(delivery, target_ok, now_dt, item)

# ##############################################################################

    def get_delivery(self, task_id):
        with closing(self.odb.session()) as session:
            delivery = session.query(Delivery).\
                filter(Delivery.task_id==task_id).\
                one()
            
        return delivery

# ##############################################################################

    def get_target_basic_data(self, name):
        """ Returns counters for a given delivery by its name along with info when the delivery
        was last time used. Does not hold onto any locks so the results are precise
        yet may be off by the time caller receives them.
        """
        return self.kvdb.conn.hgetall('{}{}'.format(KVDB.DELIVERY_BY_TARGET_PREFIX, name)) or NULL_BASIC_DATA
    
    def set_deleted(self, name, is_deleted):
        """ Sets a boolean flag indicating whether a definition has been deleted.
        Any new instances of check_target consult this flag to see whether they should
        keep running.
        """
        self.kvdb.conn.hset('{}{}'.format(KVDB.DELIVERY_BY_TARGET_PREFIX, name), 'deleted', is_deleted)
        
    def is_deleted(self, name):
        """ Returns a boolean flag indicating whether a given definition has been deleted in between
        a delivery's executions.
        """
        return not self.kvdb.conn.hget('{}{}'.format(KVDB.DELIVERY_BY_TARGET_PREFIX, name), 'deleted')
        
    def update_counters(self, name, in_progress, in_doubt, confirmed, failed):
        """ Updates counters of a given delivery definition.
        """
        counters = {
            DELIVERY_COUNTERS.IN_PROGRESS: in_progress,
            DELIVERY_COUNTERS.IN_DOUBT: in_doubt,
            DELIVERY_COUNTERS.CONFIRMED: confirmed,
            DELIVERY_COUNTERS.FAILED: failed,
            DELIVERY_COUNTERS.TOTAL: in_progress + in_doubt + confirmed + failed,
            'last_updated_utc': datetime.utcnow().isoformat(),
        }
        
        self.kvdb.conn.hmset('{}{}'.format(KVDB.DELIVERY_BY_TARGET_PREFIX, name), counters)
        
    def get_counters(self, name):
        """ Returns usage counters for a given delivery definition.
        """
        keys = [DELIVERY_COUNTERS.IN_PROGRESS, DELIVERY_COUNTERS.IN_DOUBT, DELIVERY_COUNTERS.CONFIRMED,
                     DELIVERY_COUNTERS.FAILED, DELIVERY_COUNTERS.TOTAL]
        values = self.kvdb.conn.hmget('{}{}'.format(KVDB.DELIVERY_BY_TARGET_PREFIX, name), keys)
        
        return dict(zip(keys, values))

# ##############################################################################

    def deliver(self, cluster_id, def_name, payload, task_id, invoke_func, is_resubmit=False, is_auto=False, *args, **kwargs):
        """ A public method to be invoked by services for delivering payload to target through a definition.
        """
        with closing(self.odb.session()) as session:
            delivery_def_base = session.query(DeliveryDefinitionBase).\
                filter(DeliveryDefinitionBase.cluster_id==cluster_id).\
                filter(DeliveryDefinitionBase.name==def_name).\
                    first()
            
            if not delivery_def_base:
                msg = 'Guaranteed delivery definition [{}] does not exist'.format(def_name)
                self.logger.warn(msg)
                raise ValueError(msg)
            
            target_def_class = _target_def_class[delivery_def_base.target_type]
            definition = session.query(target_def_class).\
                filter(target_def_class.id==delivery_def_base.id).\
                one()
            
            target = definition.target.name
            
        self.register_invoke_schedule(
            _item_from_api(delivery_def_base, target, payload, task_id, invoke_func, args, kwargs),
            is_resubmit, is_auto)

# ##############################################################################
        
    def on_target_completed(self, target_type, target, delivery, start, end, target_ok, target_self_info, err_info=None):
        now = datetime.utcnow().isoformat()
        task_id = delivery['task_id']
        lock_name = '{}{}'.format(KVDB.LOCK_DELIVERY, task_id)
        total_time = str(end - start)
        
        with Lock(lock_name, self.delivery_lock_timeout, LOCK_TIMEOUT, self.kvdb.conn):
            entry_ctx = dumps({
                'target_self_info': target_self_info,
                'total_time': total_time
            })
            
            with closing(self.odb.session()) as session:
                delivery = session.merge(self.get_delivery(task_id))
                delivery.state = DELIVERY_STATE.IN_PROGRESS_TARGET_OK if target_ok else DELIVERY_STATE.IN_PROGRESS_TARGET_FAILURE
                delivery.last_used = now
                delivery.definition.last_used = now
                delivery.target_count += 1
                
                history = DeliveryHistory()
                history.task_id = task_id
                history.entry_type = DELIVERY_HISTORY_ENTRY.TARGET_OK if target_ok else DELIVERY_HISTORY_ENTRY.TARGET_FAILURE
                history.entry_time = now
                history.entry_ctx = entry_ctx
                history.delivery = delivery
                history.resubmit_count = delivery.resubmit_count
                
                session.add(delivery)
                session.add(history)
                
                session.commit()
                
                self._invoke_callbacks(target, target_type, delivery, target_ok, False, DELIVERY_CALLBACK_INVOKER.TARGET)

# ##############################################################################

    def _get_page(self, session, cluster_id, params, state):
        return Page(delivery_list(session, cluster_id, params.def_name, state, params.start, params.stop, params.get('needs_payload', False)),
             page=params.current_batch,
             items_per_page=params.batch_size)

    def get_batch_info(self, cluster_id, params, state):
        """ Returns information regarding how given set of data will be split into
        smaller batches given maximum number of items on a single batch and min/max member score
        of the set. Also returns information regarding a current batch - whether it has prev/next batches.
        """
        with closing(self.odb.session()) as session:
            page = self._get_page(session, cluster_id, params, state)
            return {
                'total_results': page.item_count,
                'num_batches': page.page_count,
                'has_previous': page.previous_page is not None,
                'has_next': page.next_page is not None,
                'next_batch_number': page.next_page,
                'previous_batch_number': page.previous_page,
            }

    def get_delivery_instance_list(self, cluster_id, params, state):
        """ Returns a batch of instances that are in the in-doubt state.
        """
        with closing(self.odb.session()) as session:
            page = self._get_page(session, cluster_id, params, state)
            for values in page.items:
                out = dict(zip((PAYLOAD_KEYS if params.get('needs_payload') else DELIVERY_KEYS), values))
                for name in('creation_time_utc', 'last_used_utc'):
                    out[name] = out[name].isoformat()
                    
                yield out
                
    def get_delivery_instance(self, task_id, target_def_class):
        """ Returns an instance by its task's ID.
        """
        with closing(self.odb.session()) as session:
            out = delivery(session, task_id, target_def_class).\
                   one()
            out = dict(zip(PAYLOAD_ALL_KEYS, out))
            for name in('creation_time_utc', 'last_used_utc'):
                out[name] = out[name].isoformat()
                
            return out

# ##############################################################################

    def update_delivery(self, task_id, payload, args, kwargs):
        with closing(self.odb.session()) as session:
            now = datetime.utcnow().isoformat()
            delivery = session.merge(self.get_delivery(task_id))
            
            old_payload = delivery.payload.payload
            old_args = delivery.args
            old_kwargs = delivery.kwargs
            
            delivery.payload.payload = payload
            delivery.args = args
            delivery.kwargs = kwargs
            
            delivery.definition.last_used = now
            delivery.target_count += 1
            
            entry_ctx = dumps({
                'old_payload': old_payload,
                'old_args': old_args,
                'old_kwargs': old_kwargs,
                })
            
            history = DeliveryHistory()
            history.task_id = task_id
            history.entry_type = DELIVERY_HISTORY_ENTRY.UPDATED
            history.entry_time = now
            history.entry_ctx = entry_ctx
            history.delivery = delivery
            history.resubmit_count = delivery.resubmit_count
            
            session.add(delivery)
            session.add(history)
            
            session.commit()
            
            self.logger.info('Updated delivery [%s], history.id [%s]', task_id, history.id)

# ##############################################################################

    def get_delivery_list_for_auto_resubmit(self, cluster_id, def_name, stop):
        params = Bunch({
            'def_name': def_name,
            'start': None,
            'stop': stop,
            'current_batch': 1,
            'batch_size': maxint,
            'needs_payload': True,
        })
        for item in self.get_delivery_instance_list(
                cluster_id, params, [DELIVERY_STATE.IN_PROGRESS_STARTED, 
                                      DELIVERY_STATE.IN_PROGRESS_RESUBMITTED,
                                      DELIVERY_STATE.IN_PROGRESS_RESUBMITTED_AUTO,
                                      DELIVERY_STATE.IN_PROGRESS_TARGET_OK, 
                                      DELIVERY_STATE.IN_PROGRESS_TARGET_FAILURE]):
            yield item

########NEW FILE########
__FILENAME__ = haproxy
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from logging import getLogger

# Zato
from zato.common.util import make_repr

logger = getLogger(__name__)

# Statistics commands understood by HAproxy 1.3.x and newer. Note that the
# command numbers must be consecutively increasing across HAProxy versions.
haproxy_stats = {
    ("1", "3"): {

        # A special command interpreted by the agent as a request for
        # describing the commands available
        0: ("ZATO_DESCRIBE_COMMANDS", "Describe commands"),

        1: ("show info", "Show info"),
        2: ("show stat", "Show stats"),
        3: ("show errors", "Show errors"),
        4: ("show sess", "Show sessions"),
    },
    ("1", "4"): {
    }
}

# timeout_id -> name, value in milliseconds
timeouts = {
    1: (250, "250ms"),
    2: (500, "500ms"),
    3: (1000, "1s"),
    4: (3000, "3s"),
    5: (5000, "10s"),
    6: (30000, "30s")
}

http_log = {
    1: ("nolog", "No log"),
    2: ("httplog", "HTTP log"),
}

tcp_log = {
    1: ("nolog", "No log"),
    2: ("tcplog", "TCP log"),
}

reversed_http_log = dict((v[0],k) for k,v in http_log.items())
reversed_tcp_log = dict((v[0],k) for k,v in tcp_log.items())

class Config(object):
    """ An object for representing a HAProxy configuration file.
    """
    def __init__(self):
        self.global_ = {}
        self.defaults = {}
        self.backend = {'bck_http_plain': {}}
        self.frontend = {"front_http_plain": {}}

    def __repr__(self):
        return make_repr(self)

    def set_value(self, name, data):
        if name == 'global:log':
            host, port, facility, level = data
            self.global_['log'] = {}
            self.global_['log']['host'] = host
            self.global_['log']['port'] = port
            self.global_['log']['facility'] = facility
            self.global_['log']['level'] = level
        elif name == 'global:stats_socket':
            stats_socket = data[0]
            self.global_['stats_socket'] = stats_socket
        elif name == 'defaults:timeout connect':
            timeout = data[0]
            self.defaults['timeout_connect'] = timeout
        elif name == 'defaults:timeout client':
            timeout = data[0]
            self.defaults['timeout_client'] = timeout
        elif name == 'defaults:timeout server':
            timeout = data[0]
            self.defaults['timeout_server'] = timeout
        elif name == 'defaults:stats uri':
            stats_uri = data[0]
            self.defaults['stats_uri'] = stats_uri
        elif name.startswith('backend bck_http_plain:server'):
            backend_name, address, port, extra = data
            extra = extra.strip()
            backend_name = backend_name.split('http_plain--')[1]
            self.backend['bck_http_plain'][backend_name] = {}
            self.backend['bck_http_plain'][backend_name]['address'] = address
            self.backend['bck_http_plain'][backend_name]['port'] = port
            self.backend['bck_http_plain'][backend_name]['extra'] = extra
        elif name == 'backend bck_http_plain:option httpchk':
            method, path = data
            self.backend['bck_http_plain']['option_httpchk'] = {}
            self.backend['bck_http_plain']['option_httpchk']['method'] = method
            self.backend['bck_http_plain']['option_httpchk']['path'] = path
        elif name == 'frontend front_http_plain:monitor-uri':
            path = data[0]
            self.frontend['front_http_plain']['monitor_uri'] = path
        elif name == 'frontend front_http_plain:option log-http-requests':
            option = reversed_http_log[data[0]]
            self.frontend['front_http_plain']['log_http_requests'] = option
        elif name == 'frontend front_http_plain:bind':
            address, port = data
            self.frontend['front_http_plain']['bind'] = {}
            self.frontend['front_http_plain']['bind']['address'] = address
            self.frontend['front_http_plain']['bind']['port'] = port
        elif name == 'frontend front_http_plain:maxconn':
            maxconn = data[0]
            self.frontend['front_http_plain']['maxconn'] = maxconn
        else:
            msg = 'Could not parse config, name:[{name}], data:[{data}]'.format(name=name, data=data)
            logger.error(msg)
            raise Exception(msg)

########NEW FILE########
__FILENAME__ = kvdb
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from calendar import timegm
from importlib import import_module
from logging import getLogger
from string import punctuation
from time import gmtime

# PyParsing
from pyparsing import alphanums, oneOf, OneOrMore, Optional, White, Word

# redis
from redis import StrictRedis
from redis.sentinel import Sentinel

# Zato
from zato.common import KVDB as _KVDB, NONCE_STORE
from zato.common.util import has_redis_sentinels

logger = getLogger(__name__)

# Redis PyParsing grammar

quot = Optional(oneOf(('"', "'")))
command = oneOf((
    'CONFIG', 'DBSIZE', 'DECR', 'DECRBY', 'DEL', 'DUMP', 'ECHO',
    'EXISTS', 'EXPIRE', 'EXPIREAT', 'FLUSHDB', 'GET',
    'HDEL', 'HEXISTS', 'HGET', 'HGETALL', 'HINCRBY', 'HKEYS', 'HLEN', 'HSETNX',
    'HVALS', 'INCR', 'INCRBY', 'INFO', 'KEYS', 'LLEN', 'LPOP', 'LPUSH', 'LPUSHX',
    'LRANGE', 'LREM', 'LSET', 'LTRIM', 'MGET', 'MSET', 'MSETNX', 'OBJECT', 'PERSIST',
    'PEXPIRE', 'PEXPIREAT', 'PING', 'PSETEX', 'PTTL', 'RANDOMKEY', 'RENAME', 'RENAMENX',
    'RESTORE', 'RPOP', 'SADD', 'SET', 'SISMEMBER', 'SMEMBERS', 'SREM', 'TIME', 'TTL', 'TYPE',
    'ZADD', 'ZRANGE', 'ZREM'), caseless=True).setResultsName('command')
parameters = (OneOrMore(Word(alphanums + '-' + punctuation))).setResultsName('parameters')
redis_grammar = command + Optional(White().suppress() + parameters)

# ################################################################################################################################

class LuaContainer(object):
    """ A class which knows how to add and execute Lua scripts against Redis.
    """
    def __init__(self, kvdb=None, initial_programs=None):
        self.kvdb = kvdb
        self.lua_programs = {}
        self.add_initial_lua_programs(initial_programs or {})

    def add_initial_lua_programs(self, programs):
        for name, program in programs:
            self.add_lua_program(name, program)

    def add_lua_program(self, name, program):
        self.lua_programs[name] = self.kvdb.register_script(program)

    def run_lua(self, name, keys=None, args=None):
        return self.lua_programs[name](keys or [], args or [])

# ################################################################################################################################

class KVDB(object):
    """ A wrapper around the Zato's key-value database.
    """
    def __init__(self, conn=None, config=None, decrypt_func=None):
        self.conn = conn
        self.config = config
        self.decrypt_func = decrypt_func
        self.conn_class = None # Introduced so it's easier to test the class
        self.lua_container = LuaContainer()
        self.run_lua = self.lua_container.run_lua # So it's more natural to use it
        self.has_sentinel = False

    def _get_connection_class(self):
        """ Returns a concrete class to create Redis connections off basing on whether we use Redis sentinels or not.
        Abstracted out to a separate method so it's easier to test the whole class in separation.
        """
        return Sentinel if self.has_sentinel else StrictRedis

    def _parse_sentinels(self, item):
        if item:
            if isinstance(item, basestring):
                item = [item]
            out = []
            for elem in item:
                elem = elem.split(':')
                out.append((elem[0], int(elem[1])))
            return out

    def init(self):
        config = {}

        self.has_sentinel = has_redis_sentinels(self.config)

        if self.has_sentinel:
            sentinels = self._parse_sentinels(self.config.get('redis_sentinels'))

            if not sentinels:
                raise ValueError('kvdb.redis_sentinels must be provided')

            sentinel_master = self.config.get('redis_sentinels_master', None)
            if not sentinel_master:
                raise ValueError('kvdb.redis_sentinels_master must be provided')

            config['sentinels'] = sentinels
            config['sentinel_master'] = sentinel_master

        else:

            if self.config.get('host'):
                config['host'] = self.config.host

            if self.config.get('port'):
                config['port'] = int(self.config.port)

            if self.config.get('unix_socket_path'):
                config['unix_socket_path'] = self.config.unix_socket_path

            if self.config.get('db'):
                config['db'] = int(self.config.db)

        if self.config.get('password'):
            config['password'] = self.decrypt_func(self.config.password)

        if self.config.get('socket_timeout'):
            config['socket_timeout'] = float(self.config.socket_timeout)

        if self.config.get('connection_pool'):
            split = self.config.connection_pool.split('.')
            module, class_name = split[:-1], split[-1]
            mod = import_module(module)
            config['connection_pool'] = getattr(mod, class_name)

        if self.config.get('charset'):
            config['charset'] = self.config.charset

        if self.config.get('errors'):
            config['errors'] = self.config.errors

        self.conn_class = self._get_connection_class()

        if self.has_sentinel:
            instance = self.conn_class(config['sentinels'], config.get('password'), config.get('socket_timeout'))
            self.conn = instance.master_for(config['sentinel_master'])
        else:
            self.conn = self.conn_class(**config)

        self.lua_container.kvdb = self.conn

    def pubsub(self):
        return self.conn.pubsub()

    def publish(self, *args, **kwargs):
        return self.conn.publish(*args, **kwargs)

    def subscribe(self, *args, **kwargs):
        return self.conn.subscribe(*args, **kwargs)

    def translate(self, system1, key1, value1, system2, key2, default=''):
        return self.conn.hget(
            _KVDB.SEPARATOR.join(
                (_KVDB.TRANSLATION, system1, key1, value1, system2, key2)), 'value2') or default

    def copy(self):
        """ Returns an KVDB with the configuration copied over from self. Note that
        the object returned isn't initialized, in particular, the connection to the
        database won't have been initialized.
        """
        kvdb = KVDB()
        kvdb.config = self.config
        kvdb.decrypt_func = self.decrypt_func

        return kvdb

    def close(self):
        self.conn.connection_pool.disconnect()

# ################################################################################################################################

    # OAuth

    def add_oauth_nonce(self, username, nonce, max_nonce_log):
        """ Adds an OAuth to the set containing last N used ones for a given username.
        """
        key = NONCE_STORE.KEY_PATTERN.format('oauth', username)

        # This lets us trim the set to top (last) N nonces
        score = timegm(gmtime())

        self.conn.zadd(key, score, nonce)
        self.conn.zremrangebyrank(key, 0, -max_nonce_log)

    def has_oauth_nonce(self, username, nonce):
        """ Returns a boolean flag indicating if there's an OAuth nonce for a given
        username stored in KVDB.
        """
        return self.conn.zscore(NONCE_STORE.KEY_PATTERN.format('oauth', username), nonce)

# ################################################################################################################################
########NEW FILE########
__FILENAME__ = log_message
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# The constants below don't use the Bunch class because we don't need to iterate
# over them at all.

# LMC stands for the 'log message code'
# CID stands for the 'correlation ID'

# Needs to be kept in sync with zato.common.util.new_cid
CID_LENGTH = 27

NULL_LMC = '0000.0000'
NULL_CID = 'K' + '0' * (CID_LENGTH - 1)

########NEW FILE########
__FILENAME__ = markov_passwords
# coding: utf8
"""

Use Markov chains to generate random text that sounds Japanese.
This makes random pronounceable passwords that are both strong and easy
to memorize.
Of course English or any other language could be used in the sample text.
See more details at http://exyr.org/2011/random-pronounceable-passwords/
Author: Simon Sapin
License: BSD

Slightly adopted for Zato by adding more languages in addition to Japanese
and splitting the resulting string into dash-separated groups.

"""

from __future__ import division
import string
import itertools
import random
from collections import defaultdict

# Zato
from zato.common.util import grouper

# This is a romanization of the opening of "Genji Monogatari"
# by Murasaki Shikibu.
# Source: http://etext.lib.virginia.edu/japanese/genji/roman.html
japanese = '''
Idure no ohom-toki ni ka, nyougo, kaui amata saburahi tamahi keru naka ni,
ito yamgotonaki kiha ni ha ara nu ga, sugurete tokimeki tamahu ari keri.

Hazime yori ware ha to omohi agari tamahe ru ohom-kata-gata, mezamasiki mono ni
otosime sonemi tamahu. Onazi hodo, sore yori gerahu no kaui-tati ha, masite
yasukara zu. Asa-yuhu no miya-dukahe ni tuke te mo, hito no kokoro wo nomi
ugokasi, urami wo ohu tumori ni ya ari kem, ito atusiku nari yuki, mono kokoro-
boso-ge ni sato-gati naru wo, iyo-iyo aka zu ahare naru mono ni omohosi te hito
no sosiri wo mo e habakara se tamaha zu, yo no tamesi ni mo nari nu beki ohom-
motenasi nari.

Kamdatime, uhe-bito nado mo, ainaku me wo sobame tutu, "Ito mabayuki hito no
ohom-oboye nari. Morokosi ni mo, kakaru koto no okori ni koso, yo mo midare,
asikari kere" to, yau-yau amenosita ni mo adikinau, hito no mote-nayami-gusa ni
nari te, Yauki-hi no tamesi mo hiki ide tu beku nariyuku ni, ito hasitanaki koto
ohokare do, katazikenaki mi-kokoro-bahe no taguhi naki wo tanomi ni te mazirahi
tamahu.

TiTi no Dainagon ha nakunari te haha Kita-no-kata nam inisihe no yosi aru ni te,
oya uti-gusi, sasi-atari te yo no oboye hanayaka naru ohom-kata-gata ni mo itau
otora zu, nani-goto no gisiki wo mo motenasi tamahi kere do, tori-tate te haka-
bakasiki usiro-mi si nakere ba, koto aru toki ha, naho yori-dokoro naku kokoro-
boso-ge nari.


Saki no yo ni mo ohom-tigiri ya hukakari kem, yo ni naku kiyora naru tama no
wonoko miko sahe umare tamahi nu. Itusika to kokoro-motonagara se tamahi te,
isogi mawirase te go-ran-zuru ni, meduraka naru tigo no ohom-katati nari.

Iti-no-Miko ha, Udaizin no Nyougo no ohom-hara ni te, yose omoku, utagahi naki
Mauke-no-kimi to, yo ni mote-kasiduki kikoyure do, kono ohom-nihohi ni ha narabi
tamahu beku mo ara zari kere ba, ohokata no yamgotonaki ohom-omohi ni te, kono
Kimi wo ba, watakusi-mono ni omohosi kasiduki tamahu koto kagiri nasi.

Hazime yori osinabete no uhe-miya-dukahe si tamahu beki kiha ni ha ara zari ki.
Oboye ito yamgotonaku, zyauzu-mekasi kere do, warinaku matuhasa se tamahu amari
ni, sarubeki ohom-asobi no wori-wori, nani-goto ni mo yuwe aru koto no husi-busi
ni ha, madu mau-nobora se tamahu. Aru-toki ni ha ohotono-gomori sugusi te,
yagate saburahase tamahi nado, anagati ni o-mahe sara zu mote-nasa se tamahi si
hodo ni, onodukara karoki kata ni mo miye si wo, kono Miko umare tamahi te noti
ha, ito kokoro koto ni omohosi oki te tare ba, Bau ni mo, you se zu ha, kono
Miko no wi tamahu beki na'meri to, Ichi-no-Miko no Nyougo ha obosi utagahe ri.
Hito yori saki ni mawiri tamahi te, yamgotonaki ohom-omohi nabete nara zu, Miko-
tati nado mo ohasimase ba, kono Ohom-kata no ohom-isame wo nomi zo, naho
wadurahasiu kokoro-gurusiu omohi kikoye sase tamahi keru.
Kasikoki mi-kage wo ba tanomi kikoye nagara, otosime kizu wo motome tamahu hito
ha ohoku, waga mi ha ka-yowaku mono-hakanaki arisama ni te, naka-naka naru mono-
omohi wo zo si tamahu. Mi-tubone ha Kiritubo nari. Amata no ohom-Kata-gata wo
sugi sase tamahi te, hima naki o-mahe-watari ni, hito no mi-kokoro wo tukusi
tamahu mo, geni kotowari to miye tari. Mau-nobori tamahu ni mo, amari uti-sikiru
wori-wori ha, uti-hasi, wata-dono no koko kasiko no miti ni, ayasiki waza wo si
tutu, ohom-okuri mukahe no hito no kinu no suso, tahe gataku, masanaki koto mo
ari. Mata aru toki ni ha, e sara nu me-dau no to wo sasi-kome, konata kanata
kokoro wo ahase te, hasitaname wadurahase tamahu toki mo ohokari. Koto ni hure
te kazu sira zu kurusiki koto nomi masare ba, ito itau omohi wabi taru wo, itodo
ahare to go-ran-zi te, Kourau-den ni motoyori saburahi tamahu Kaui no zausi wo
hoka ni utusa se tamahi te, Uhe-tubone ni tamaha su. Sono urami masite yara m
kata nasi.
'''

# http://www.gutenberg.org/files/17544/17544-0.txt
occitan = """
  Despen lou ben per compas  mesure,
E mesquems lou que tas amassat:
Que puch aprs si lou tas despensat,
Den gaigna mes aquo ba a labenture.


    XVI.

  Tant quom te sab force argent en la bousse
De toutis es Moussur  coumpaignon
Quan nou nas ms delechat s deu mon,
Coum si jams connegut nou taugousse.


    XVII.

  Dits la paraule aprs lau pensade
A gens segrets que namen pas lou brut:
Atau ne ba deu perpaus quas tengut,
Coume deu bent ou du peire getade.


    XVIII.

  Si hs plase helou de boun couratge,
Sapies aqui, gouerdet de tempacha,
Que nou te caille  la fin reproucha,
Queu regast pert,  lamic,  lou gatge.


    XIX.

  Si bos au peus bounis locs lentrade,
Saget de h coume beses que hen,
Nou sies fachous, ny broutous, ni biln,
Ni lampourn, coume bere mainade.


    XX.

  Si ta bertut force de ben samasse,
Parens caitious bergoine nou te hn:
Quet beau mesleu que lou darr bilen,
Este prum gentilhomme en sa race.


    XXI.

  A tribailla h tout se que tu pousques
Esburbe-te per tout de la doun s:
Praube mesti que i dvn truque tauls,
Dvn pan derdut, enjourrit, bade mousques.


    XXII.

  Nou hiques pas en ta grane coulre
Que tu madich nout pousques matiga:
Aquet que sab soun bici castiga,
Per dessus touts lo u plus sage sapere


    XXIII.

  Quan as lou temps de poude h la cause,
Nac boutes pas  tantos ou douman,
Qui per vn cop dagine de la man,
Nabigne plus ni lou temps, ni la pause.


    XXIV.

  Nou tanes pas cargua de fantasies,
Mes tot gaujous agerge tous quehs:
Nou dars ourdes  cinq targes dahs:
A mil escuts de tas malencounies.


    XXV.

  Aule escourga sadits om h la cou
De loungs ahs, charges,  coussoulats:
La populasse aporte tant de caps,
Que mes escoute, oun mes om larrasou.


    XXVI.

  Las sages nou disen pas en bades,
Hemne que bo tant de joies pourta,
Si sous mouiens nac poden supourta,
Ou be h mau, ou he pourte las brages.


    XXVII.

  Tut tropes plan mes souuen se tuesperes
De toun parent, ben, ou coumoditat,
Tu sabes trop sac as esprimentat,
Que males son de ton hust las esteres,


    XXVIII.

  Nou hasses mau daqueste, ou daute sorte,
Pensan quaprs degun nac sabera,
Tu nou poures tant lou houec capera,
Qa la perfin la humade nou sorte.


    XXIX.

  Si toun prouheit dentreprene tassajes,
Nou creignes pas aquets que nan despieit,
Ni lembejous, que name toun prouheit,
Que pan  bin, sapere tu ten ajes.


    XXX.

  Nou sies daquets quespousaran v More,
Vn arrebrec, mes quage force argent.
Si nas mouill de quauque boune gent;
Largent sen ba,  la bestio demoro.


    XXXI.

  Dome trichot, jogue tout, encoublaire,
Nou hasses pas amic,  coumpaignoun,
Puch quet nou biu que de tropa lou moun,
De taguerri, nou sendare pas gouaire.


    XXXII.

  Si nou las heit, nous bantes de loubratje,
Ni dautru ben nou prenges la banson,
Ou descridat seras per tout lou moun,
Lairon daunou, que nes pas petit gatje.
"""

breton = """
.NHO
40           MEULEUDI SANTEZ ANNA
.NTO

  Va Breudeur ker, ne laeromp ket loden an Aotrou
Doue. Hen dreist pep tra, eo hen deuz great ar Verc'hez
Sakr ar pez ma zeo. Eva, ar genta maouez, a gollas ar
bed : Eur verc'h da Eva eo a dle hen savetei. Ha Doue
a bell, a bourchassas, a aozas pep tra evit kas da benn
ar pez hen doa rezolvet dre druez ouzomp.
  Mez ma reaz evit ober euz ar Verc'hez eur grouadurez
ker pur, burzud var burzud, Santez Anna a reas he lod.
  1 Sellit outhi : He merc'h c'hoas iaouankik flamm,
a zo en he c'hichen o teski lezen Doue.
  2 D'an eil Santez Anna n'he doa krouadur ebet
nemet-hi. Ha koulskoude, d'an oad a dri bloas, Mari a
zo kaset d'an templ ha roet da Zoue.
  Tadou ha mammou, setu aze ho skouer. Peurvuia
eur c'hrouadur a vez ar pez ma vez great : nebeut a
drec'h wen. En em glemm a rear euz ar vugale ; guel-
loc'h e ve en em glemm euz ar re nebeut a zoursi a vez
bet kemeret d'ho c'helen ervad.
  Erus an nep er bed-ma, a ra evit Doue, evit he
nesa, evithan he unan, ar pez a c'houlenn mad an ene.
  Koulskoude, hag e tiguesfe ganheomp, kueza er
pec'het, ne gollomp ket a fizians.
  Eur sant hen deus bet lavaret divar benn ar Verc'hes :
omnipotentia supplex. Me 'lavaro da m'zro, Santez
Anna dre he feden a zeuio a benn euz kement e dezho
c'hoant. Ar Verc'hez a zo he merc'h, Jesus-Krist a zo
he mab bihan : Galloud he deuz eta dirag Doue. Ha
hent all, ne c'hello ket mankout a garantez evidomp
ni bugale ar beg douar ma a zo en em wlestet dezhi.

.NHO
         MEULEUDI SANTEZ ANNA                 41
.NTO

En em erbedomp eta outhi gant fizians. Mar d'homp
mad, hi hor jikouro da genderc'hel ; mar bevomp er
pec'het, hi a astenno d'heomp he dourn evit hor zevel
da genta ha rei d'heomp nerz da jomm en hor zao beteg
ar fin.
                                             AMEN.

.NPO
"""

def pairwise(iterable):
    """
Yield pairs of consecutive elements in iterable.
>>> list(pairwise('abcd'))
[('a', 'b'), ('b', 'c'), ('c', 'd')]
"""
    iterator = iter(iterable)
    try:
        a = iterator.next()
    except StopIteration:
        return
    for b in iterator:
        yield a, b
        a = b
        
class MarkovChain(object):
    """
If a system transits from a state to another and the next state depends
only on the current state and not the past, it is said to be a Markov chain.
It is determined by the probability of each next state from any current
state.
See http://en.wikipedia.org/wiki/Markov_chain
The probabilities are built from the frequencies in the `sample` chain.
Elements of the sample that are not a valid state are ignored.
"""
    def __init__(self, sample):
        self.counts = counts = defaultdict(lambda: defaultdict(int))
        for current, next in pairwise(sample):
            counts[current][next] += 1
        
        self.totals = dict(
            (current, sum(next_counts.itervalues()))
            for current, next_counts in counts.iteritems()
        )
        
    def next(self, state):
        """
Choose at random and return a next state from a current state,
according to the probabilities for this chain
"""
        nexts = self.counts[state].iteritems()
        # Like random.choice() but with a different weight for each element
        rand = random.randrange(0, self.totals[state])
        # Using bisection here could be faster, but simplicity prevailed.
        # (Also its not that slow with 26 states or so.)
        for next_state, weight in nexts:
            if rand < weight:
                return next_state
            rand -= weight
    
    def __iter__(self):
        """
Return an infinite iterator of states.
"""
        state = random.choice(self.counts.keys())
        while True:
            state = self.next(state)
            yield state

def generate_password(length=16):
    chain = MarkovChain(
        c for c in japanese.lower() + occitan.lower() + breton.lower() if c in string.ascii_lowercase
    )
    return '-'.join(''.join(elems) for elems in (grouper(4, ''.join(itertools.islice(chain, length)))))

########NEW FILE########
__FILENAME__ = model
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Unlike zato.common.odb.model - this place is where DB-independent models are kept,
# regardless if they're backed by an SQL database or not.

# stdlib
from json import loads
from logging import getLogger

# memory_profiler
from memory_profiler import profile

# Zato
from zato.common.util import make_repr

logger = getLogger(__name__)

_key_func_dict = {
    'tx_id': None,
    'name': None,
    'target': None,
    'target_type': None,
    'on_delivery_success': None,
    'on_delivery_failed': None,
    
    'expire_arch_success_after': int,
    'expire_arch_failed_after': int,
    'check_after': int,
    'retry_repeats': int,
    'retry_seconds': int,
    
    #'business_payload': loads,
    #'failed_attempt_list': loads,
    #'in_doubt_history': loads,
}

class DeliveryItem(object):
    """ A container for config pieces regarding a particular delivery effort.
    """
    def __init__(self):
        self.name = None
        self.target = None
        self.target_type = None
        self.tx_id = None
        self.business_payload = None
        self.expire_after = None
        self.expire_arch_success_after = None
        self.expire_arch_failed_after = None
        self.special_case_weekends = False
        self.check_after = None
        self.retry_repeats = None
        self.retry_seconds = None
        self.invoke_func = None
        self.invoke_args = None
        self.invoke_kwargs = None
        self.delivery_key = None
        self.payload_key = None
        self.by_target_type_key = None
        self.uq_by_target_type_key = None
        self.on_delivery_success = None
        self.on_delivery_failed = None
        
        self.source_count = None
        self.target_count = None
        
        self.creation_time_utc = None
        self.creation_time = None # In current user's timezone
        
        self.in_doubt_created_at_utc = None
        self.in_doubt_created_at = None # In current user's timezone
        
        self.last_updated_utc = None
        self.last_updated = None # In current user's timezone
        
    def __repr__(self):
        return make_repr(self)

    @staticmethod
    #@profile
    def from_in_doubt_delivery(payload):
        """ Creates a new delivery item out of previous in-doubt data.
        """
        item = DeliveryItem()
        for key, func in _key_func_dict.items():
            try:
                value = payload[key]
            except TypeError:
                raise KeyError('[{}] [{}] [{}]'.format(key, type(payload), payload))
            
            if func:
                value = func(value)
            setattr(item, key, value)
        
        logger.debug('Returning item %r', item)
        
        return item

########NEW FILE########
__FILENAME__ = nav
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

from butler import Butler

class DictNav(Butler):
    """ Easy navigation over Python dicts.
    """
    def get(self, path, default=None):
        """ Overridden from the base class so it doesn't display warnings on non-existing paths.
        """
        try:
            return self[path]
        except (LookupError, TypeError):
            return default

    def has_key(self, key, nested=True):
        if nested:
            return bool(self.findall(key, True))

        return key in self.obj

    def has_path(self, path):
        return super(DictNav, self).path_exists(path)

# For now they are the same class but may part at some time
ListNav = DictNav
########NEW FILE########
__FILENAME__ = model
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from ftplib import FTP_PORT
from json import dumps

# SQLAlchemy
from sqlalchemy import Column, Integer, String, DateTime, ForeignKey, Sequence, \
     Boolean, LargeBinary, UniqueConstraint, Enum, SmallInteger
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import backref, relationship

# Zato
from zato.common import CLOUD, HTTP_SOAP_SERIALIZATION_TYPE, INVOCATION_TARGET, MISC, NOTIF, MSG_PATTERN_TYPE, \
     PUB_SUB, SCHEDULER_JOB_TYPE
from zato.common.odb import AMQP_DEFAULT_PRIORITY, WMQ_DEFAULT_PRIORITY

Base = declarative_base()

# ################################################################################################################################

def to_json(model, return_as_dict=False):
    """ Returns a JSON representation of an SQLAlchemy-backed object.
    """
    json = {}
    json['fields'] = {}
    json['pk'] = getattr(model, 'id')

    for col in model._sa_class_manager.mapper.mapped_table.columns:
        json['fields'][col.name] = getattr(model, col.name)

    if return_as_dict:
        return json
    else:
        return dumps([json])

class ZatoInstallState(Base):
    """ Contains a row for each Zato installation belonging to that particular
    ODB. For instance, installing Zato 1.0 will add a new row, installing 1.1
    """
    __tablename__ = 'install_state'

    id = Column(Integer, Sequence('install_state_seq'), primary_key=True)
    version = Column(Integer, unique=True, nullable=False)
    install_time = Column(DateTime(), nullable=False)
    source_host = Column(String(200), nullable=False)
    source_user = Column(String(200), nullable=False)

    def __init__(self, id=None, version=None, install_time=None, source_host=None,
                 source_user=None):
        self.id = id
        self.version = version
        self.install_time = install_time
        self.source_host = source_host
        self.source_user = source_user

class Cluster(Base):
    """ Represents a Zato cluster.
    """
    __tablename__ = 'cluster'

    id = Column(Integer, Sequence('cluster_id_seq'), primary_key=True)
    name = Column(String(200), unique=True, nullable=False)
    description = Column(String(1000), nullable=True)
    odb_type = Column(String(30), nullable=False)
    odb_host = Column(String(200), nullable=True)
    odb_port = Column(Integer(), nullable=True)
    odb_user = Column(String(200), nullable=True)
    odb_db_name = Column(String(200), nullable=True)
    odb_schema = Column(String(200), nullable=True)
    broker_host = Column(String(200), nullable=False)
    broker_port = Column(Integer(), nullable=False)
    lb_host = Column(String(200), nullable=False)
    lb_port = Column(Integer(), nullable=False)
    lb_agent_port = Column(Integer(), nullable=False)
    cw_srv_id = Column(Integer(), nullable=True)
    cw_srv_keep_alive_dt = Column(DateTime(), nullable=True)

    def __init__(self, id=None, name=None, description=None, odb_type=None,
                 odb_host=None, odb_port=None, odb_user=None, odb_db_name=None,
                 odb_schema=None, broker_host=None,
                 broker_port=None, lb_host=None, lb_port=None,
                 lb_agent_port=None, cw_srv_id=None, cw_srv_keep_alive_dt=None):
        self.id = id
        self.name = name
        self.description = description
        self.odb_type = odb_type
        self.odb_host = odb_host
        self.odb_port = odb_port
        self.odb_user = odb_user
        self.odb_db_name = odb_db_name
        self.odb_schema = odb_schema
        self.broker_host = broker_host
        self.broker_port = broker_port
        self.lb_host = lb_host
        self.lb_agent_port = lb_agent_port
        self.lb_port = lb_port
        self.cw_srv_id = cw_srv_id
        self.cw_srv_keep_alive_dt = cw_srv_keep_alive_dt

    def to_json(self):
        return to_json(self)

class Server(Base):
    """ Represents a Zato server.
    """
    __tablename__ = 'server'
    __table_args__ = (UniqueConstraint('name', 'cluster_id'), {})

    id = Column(Integer, Sequence('server_id_seq'), primary_key=True)
    name = Column(String(200), nullable=False)
    host = Column(String(400), nullable=True)

    bind_host = Column(String(400), nullable=True)
    bind_port = Column(Integer(), nullable=True)

    # If the server's request to join a cluster has been accepted, and for now
    # it will always be.
    last_join_status = Column(String(40), nullable=True)
    last_join_mod_date = Column(DateTime(), nullable=True)
    last_join_mod_by = Column(String(200), nullable=True)

    # Whether the server's up or not
    up_status = Column(String(40), nullable=True)
    up_mod_date = Column(DateTime(), nullable=True)

    token = Column(String(32), nullable=False)

    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    cluster = relationship(Cluster, backref=backref('servers', order_by=name, cascade='all, delete, delete-orphan'))

    def __init__(self, id=None, name=None, cluster=None, token=None,
                 last_join_status=None, last_join_mod_date=None, last_join_mod_by=None):
        self.id = id
        self.name = name
        self.cluster = cluster
        self.token = token
        self.last_join_status = last_join_status
        self.last_join_mod_date = last_join_mod_date
        self.last_join_mod_by = last_join_mod_by
        self.has_lb_config = False # Not used by the database
        self.in_lb = False # Not used by the database
        self.lb_state = None # Not used by the database
        self.lb_address = None # Not used by the database
        self.may_be_deleted = None # Not used by the database
        self.up_mod_date_user = None # Not used by the database

# ################################################################################################################################

class SecurityBase(Base):
    """ A base class for all the security definitions.
    """
    __tablename__ = 'sec_base'
    __table_args__ = (UniqueConstraint('cluster_id', 'name'),
        UniqueConstraint('cluster_id', 'username', 'sec_type'), {})
    __mapper_args__ = {'polymorphic_on': 'sec_type'}

    id = Column(Integer, Sequence('sec_base_seq'), primary_key=True)
    name = Column(String(200), nullable=False)

    # It's nullable because TechnicalAccount doesn't use usernames
    username = Column(String(200), nullable=True)

    password = Column(String(64), nullable=True)
    password_type = Column(String(45), nullable=True)
    is_active = Column(Boolean(), nullable=False)
    sec_type = Column(String(45), nullable=False)

    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    cluster = relationship(Cluster, backref=backref('security_list', order_by=name, cascade='all, delete, delete-orphan'))

class HTTPBasicAuth(SecurityBase):
    """ An HTTP Basic Auth definition.
    """
    __tablename__ = 'sec_basic_auth'
    __mapper_args__ = {'polymorphic_identity': 'basic_auth'}

    id = Column(Integer, ForeignKey('sec_base.id'), primary_key=True)
    realm = Column(String(200), nullable=False)

    def __init__(self, id=None, name=None, is_active=None, username=None,
                 realm=None, password=None, cluster=None):
        self.id = id
        self.name = name
        self.is_active = is_active
        self.username = username
        self.realm = realm
        self.password = password
        self.cluster = cluster

class WSSDefinition(SecurityBase):
    """ A WS-Security definition.
    """
    __tablename__ = 'sec_wss_def'
    __mapper_args__ = {'polymorphic_identity':'wss'}

    id = Column(Integer, ForeignKey('sec_base.id'), primary_key=True)
    reject_empty_nonce_creat = Column(Boolean(), nullable=False)
    reject_stale_tokens = Column(Boolean(), nullable=True)
    reject_expiry_limit = Column(Integer(), nullable=False)
    nonce_freshness_time = Column(Integer(), nullable=True)

    def __init__(self, id=None, name=None, is_active=None, username=None,
                 password=None, password_type=None, reject_empty_nonce_creat=None,
                 reject_stale_tokens=None, reject_expiry_limit=None,
                 nonce_freshness_time=None, cluster=None, password_type_raw=None):
        self.id = id
        self.name = name
        self.is_active = is_active
        self.username = username
        self.password = password
        self.password_type = password_type
        self.reject_empty_nonce_creat = reject_empty_nonce_creat
        self.reject_stale_tokens = reject_stale_tokens
        self.reject_expiry_limit = reject_expiry_limit
        self.nonce_freshness_time = nonce_freshness_time
        self.cluster = cluster
        self.password_type_raw = password_type_raw

class TechnicalAccount(SecurityBase):
    """ Stores information about technical accounts, used for instance by Zato
    itself for securing access to its API.
    """
    __tablename__ = 'sec_tech_acc'
    __mapper_args__ = {'polymorphic_identity':'tech_acc'}

    id = Column(Integer, ForeignKey('sec_base.id'), primary_key=True)
    salt = Column(String(32), nullable=False)

    def __init__(self, id=None, name=None, is_active=None, password=None, salt=None, cluster=None):
        self.id = id
        self.name = name
        self.is_active = is_active
        self.password = password
        self.salt = salt
        self.cluster = cluster

    def to_json(self):
        return to_json(self)

class OAuth(SecurityBase):
    """ New in 2.0: Stores OAuth credentials.
    """
    __tablename__ = 'sec_oauth'
    __mapper_args__ = {'polymorphic_identity':'oauth'}

    id = Column(Integer, ForeignKey('sec_base.id'), primary_key=True)
    proto_version = Column(String(32), nullable=False)
    sig_method = Column(String(32), nullable=False) # HMAC-SHA1 or PLAINTEXT
    max_nonce_log = Column(Integer(), nullable=False)

    def __init__(self, id=None, name=None, is_active=None, username=None,
                 password=None, proto_version=None, sig_method=None,
                 max_nonce_log=None, cluster=None):
        self.id = id
        self.name = name
        self.is_active = is_active
        self.username = username
        self.password = password
        self.proto_version = proto_version
        self.sig_method = sig_method
        self.max_nonce_log = max_nonce_log
        self.cluster = cluster

    def to_json(self):
        return to_json(self)

class NTLM(SecurityBase):
    """ New in 2.0: Stores NTLM definitions.
    """
    __tablename__ = 'sec_ntlm'
    __mapper_args__ = {'polymorphic_identity': 'ntlm'}

    id = Column(Integer, ForeignKey('sec_base.id'), primary_key=True)

    def __init__(self, id=None, name=None, is_active=None, username=None, password=None, cluster=None):
        self.id = id
        self.name = name
        self.is_active = is_active
        self.username = username
        self.cluster = cluster

    def to_json(self):
        return to_json(self)

class AWSSecurity(SecurityBase):
    """ New in 2.0: Stores Amazon credentials.
    """
    __tablename__ = 'sec_aws'
    __mapper_args__ = {'polymorphic_identity': 'aws'}

    id = Column(Integer, ForeignKey('sec_base.id'), primary_key=True)

    def __init__(self, id=None, name=None, is_active=None, username=None, password=None, cluster=None):
        self.id = id
        self.name = name
        self.is_active = is_active
        self.username = username
        self.password = password
        self.cluster = cluster

    def to_json(self):
        return to_json(self)

class OpenStackSecurity(SecurityBase):
    """ New in 2.0: Stores OpenStack credentials..
    """
    __tablename__ = 'sec_openstack'
    __mapper_args__ = {'polymorphic_identity': 'openstack'}

    id = Column(Integer, ForeignKey('sec_base.id'), primary_key=True)

    def __init__(self, id=None, name=None, is_active=None, username=None, password=None, cluster=None):
        self.id = id
        self.name = name
        self.is_active = is_active
        self.username = username
        self.cluster = cluster

    def to_json(self):
        return to_json(self)

class APIKeySecurity(SecurityBase):
    """ New in 2.0: Stores API keys.
    """
    __tablename__ = 'sec_apikey'
    __mapper_args__ = {'polymorphic_identity': 'apikey'}

    id = Column(Integer, ForeignKey('sec_base.id'), primary_key=True)

    def __init__(self, id=None, name=None, is_active=None, username=None, password=None, cluster=None):
        self.id = id
        self.name = name
        self.is_active = is_active
        self.username = username
        self.password = password
        self.cluster = cluster

    def to_json(self):
        return to_json(self)

class XPathSecurity(SecurityBase):
    """ New in 2.0: Stores XPath-based credentials.
    """
    __tablename__ = 'sec_xpath'
    __mapper_args__ = {'polymorphic_identity':'xpath_sec'}

    id = Column(Integer, ForeignKey('sec_base.id'), primary_key=True)
    username_expr = Column(String(200), nullable=False)
    password_expr = Column(String(200), nullable=True)

    def __init__(self, id=None, name=None, is_active=None, username=None, password=None, username_expr=None, password_expr=None,
                 cluster=None):
        self.id = id
        self.name = name
        self.is_active = is_active
        self.username = username
        self.password = password
        self.username_expr = username_expr
        self.password_expr = password_expr
        self.cluster = cluster

    def to_json(self):
        return to_json(self)

# ################################################################################################################################

class HTTPSOAP(Base):
    """ An incoming or outgoing HTTP/SOAP connection.
    """
    __tablename__ = 'http_soap'
    __table_args__ = (UniqueConstraint('name', 'connection', 'transport', 'cluster_id'),
                      UniqueConstraint('url_path', 'host', 'connection', 'soap_action', 'cluster_id'), {})

    id = Column(Integer, Sequence('http_soap_seq'), primary_key=True)
    name = Column(String(200), nullable=False)
    is_active = Column(Boolean(), nullable=False)
    is_internal = Column(Boolean(), nullable=False)

    connection = Column(Enum('channel', 'outgoing', name='http_soap_connection'), nullable=False)
    transport = Column(Enum('plain_http', 'soap', name='http_soap_transport'), nullable=False)

    host = Column(String(200), nullable=True)
    url_path = Column(String(200), nullable=False)
    method = Column(String(200), nullable=True)

    soap_action = Column(String(200), nullable=False)
    soap_version = Column(String(20), nullable=True)

    data_format = Column(String(20), nullable=True)

    # New in 2.0
    ping_method = Column(String(60), nullable=True)

    # New in 2.0
    pool_size = Column(Integer, nullable=True)

    # New in 2.0
    merge_url_params_req = Column(Boolean, nullable=True, default=True)

    # New in 2.0
    url_params_pri = Column(String(200), nullable=True, default='path-over-qs')

    # New in 2.0
    params_pri = Column(String(200), nullable=True, default='channel-params-over-msg')
    
    # New in 2.0
    audit_enabled = Column(Boolean, nullable=False, default=False)
    
    # New in 2.0
    audit_back_log = Column(Integer, nullable=False, default=MISC.DEFAULT_AUDIT_BACK_LOG)
    
    # New in 2.0
    audit_max_payload = Column(Integer, nullable=False, default=MISC.DEFAULT_AUDIT_MAX_PAYLOAD)
    
    # New in 2.0
    audit_repl_patt_type = Column(String(200), nullable=False, default=MSG_PATTERN_TYPE.JSON_POINTER.id)

    # New in 2.0
    serialization_type = Column(String(200), nullable=False, default=HTTP_SOAP_SERIALIZATION_TYPE.SUDS.id)

    # New in 2.0
    timeout = Column(Integer(), nullable=False, default=MISC.DEFAULT_HTTP_TIMEOUT)

    service_id = Column(Integer, ForeignKey('service.id', ondelete='CASCADE'), nullable=True)
    service = relationship('Service', backref=backref('http_soap', order_by=name, cascade='all, delete, delete-orphan'))

    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    cluster = relationship(Cluster, backref=backref('http_soap_list', order_by=name, cascade='all, delete, delete-orphan'))

    security_id = Column(Integer, ForeignKey('sec_base.id', ondelete='CASCADE'), nullable=True)
    security = relationship(SecurityBase, backref=backref('http_soap_list', order_by=name, cascade='all, delete, delete-orphan'))

    def __init__(self, id=None, name=None, is_active=None, is_internal=None, connection=None, transport=None, host=None, \
                 url_path=None, method=None, soap_action=None, soap_version=None, data_format=None, ping_method=None,
                 pool_size=None, merge_url_params_req=None, url_params_pri=None, params_pri=None, serialization_type=None, \
                 timeout=None, service_id=None, service=None, security=None, cluster_id=None, cluster=None, service_name=None, \
                 security_id=None, security_name=None):
        self.id = id
        self.name = name
        self.is_active = is_active
        self.is_internal = is_internal
        self.connection = connection
        self.transport = transport
        self.host = host
        self.url_path = url_path
        self.method = method
        self.soap_action = soap_action
        self.soap_version = soap_version
        self.data_format = data_format
        self.ping_method = ping_method
        self.pool_size = pool_size
        self.merge_url_params_req = merge_url_params_req
        self.url_params_pri = url_params_pri
        self.params_pri = params_pri
        self.serialization_type = serialization_type
        self.timeout = timeout
        self.service_id = service_id
        self.service = service
        self.security = security
        self.cluster_id = cluster_id
        self.cluster = cluster
        self.service_name = service_name # Not used by the DB
        self.security_id = security_id
        self.security_name = security_name

# ################################################################################################################################

class SQLConnectionPool(Base):
    """ An SQL connection pool.
    """
    __tablename__ = 'sql_pool'
    __table_args__ = (UniqueConstraint('cluster_id', 'name'), {})

    id = Column(Integer, Sequence('sql_pool_id_seq'), primary_key=True)
    name = Column(String(200), nullable=False)
    is_active = Column(Boolean(), nullable=False)
    username = Column(String(200), nullable=False)
    password = Column(String(200), nullable=False)
    db_name = Column(String(200), nullable=False)
    engine = Column(String(200), nullable=False)
    extra = Column(LargeBinary(20000), nullable=True)
    host = Column(String(200), nullable=False)
    port = Column(Integer(), nullable=False)
    pool_size = Column(Integer(), nullable=False)

    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    cluster = relationship(Cluster, backref=backref('sql_pools', order_by=name, cascade='all, delete, delete-orphan'))

    engine_text = None # For auto-completion, not used by the DB

    def __init__(self, id=None, name=None, is_active=None, db_name=None,
                 username=None, engine=None, extra=None, host=None, port=None,
                 pool_size=None, cluster=None):
        self.id = id
        self.name = name
        self.is_active = is_active
        self.db_name = db_name
        self.username = username
        self.engine = engine
        self.extra = extra
        self.host = host
        self.port = port
        self.pool_size = pool_size
        self.cluster = cluster

# ################################################################################################################################

class Service(Base):
    """ A set of basic informations about a service available in a given cluster.
    """
    __tablename__ = 'service'
    __table_args__ = (UniqueConstraint('name', 'cluster_id'), {})

    id = Column(Integer, Sequence('service_id_seq'), primary_key=True)
    name = Column(String(300), nullable=False)
    is_active = Column(Boolean(), nullable=False)
    impl_name = Column(String(2000), nullable=False)
    is_internal = Column(Boolean(), nullable=False)
    wsdl = Column(LargeBinary(5000000), nullable=True)
    wsdl_name = Column(String(200), nullable=True)

    slow_threshold = Column(Integer, nullable=False, default=99999)

    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    cluster = relationship(Cluster, backref=backref('services', order_by=name, cascade='all, delete, delete-orphan'))

    def __init__(self, id=None, name=None, is_active=None, impl_name=None,
                 is_internal=None, cluster=None, wsdl=None, wsdl_name=None):
        self.id = id
        self.name = name
        self.is_active = is_active
        self.impl_name = impl_name
        self.is_internal = is_internal
        self.cluster = cluster
        self.wsdl = wsdl
        self.wsdl_name = wsdl_name
        self.plain_http_channels = [] # Not used by the database
        self.soap_channels = [] # Not used by the database
        self.amqp_channels = [] # Not used by the database
        self.wmq_channels = [] # Not used by the database
        self.zmq_channels = [] # Not used by the database
        self.scheduler_jobs = [] # Not used by the database
        self.deployment_info = [] # Not used by the database
        self.source_info = None # Not used by the database
        self.may_be_deleted = False # Not used by the database

        self.sample_cid = None # Not used by the database
        self.sample_req_timestamp = None # Not used by the database
        self.sample_resp_timestamp = None # Not used by the database
        self.sample_req = None # Not used by the database
        self.sample_resp = None # Not used by the database
        self.sample_req_resp_freq = None # Not used by the database
        self.sample_req_html = None # Not used by the database
        self.sample_resp_html = None # Not used by the database

        self.usage = None # Not used by the database
        self.time_last = None # Not used by the database

        self.time_min_all_time = None # Not used by the database
        self.time_max_all_time = None # Not used by the database
        self.time_mean_all_time = None # Not used by the database

        self.time_usage_1h = None # Not used by the database
        self.time_min_1h = None # Not used by the database
        self.time_max_1h = None # Not used by the database
        self.time_trend_mean_1h = None # Not used by the database
        self.time_trend_rate_1h = None # Not used by the database

class DeployedService(Base):
    """ A service living on a given server.
    """
    __tablename__ = 'deployed_service'
    __table_args__ = (UniqueConstraint('server_id', 'service_id'), {})

    deployment_time = Column(DateTime(), nullable=False)
    details = Column(String(2000), nullable=False)
    source = Column(LargeBinary(500000), nullable=True)
    source_path = Column(String(2000), nullable=True)
    source_hash = Column(String(512), nullable=True)
    source_hash_method = Column(String(20), nullable=True)

    server_id = Column(Integer, ForeignKey('server.id', ondelete='CASCADE'), nullable=False, primary_key=True)
    server = relationship(Server, backref=backref('deployed_services', order_by=deployment_time, cascade='all, delete, delete-orphan'))

    service_id = Column(Integer, ForeignKey('service.id', ondelete='CASCADE'), nullable=False, primary_key=True)
    service = relationship(Service, backref=backref('deployment_data', order_by=deployment_time, cascade='all, delete, delete-orphan'))

    def __init__(self, deployment_time, details, server_id, service, source, source_path,
                 source_hash, source_hash_method):
        self.deployment_time = deployment_time
        self.details = details
        self.server_id = server_id
        self.service = service
        self.source = source
        self.source_path = source_path
        self.source_hash = source_hash
        self.source_hash_method = source_hash_method

# ################################################################################################################################

class Job(Base):
    """ A scheduler's job. Stores all the information needed to execute a job
    if it's a one-time job, otherwise the information is kept in related tables.
    """
    __tablename__ = 'job'
    __table_args__ = (UniqueConstraint('name', 'cluster_id'), {})

    id = Column(Integer, Sequence('job_id_seq'), primary_key=True)
    name = Column(String(200), nullable=False)
    is_active = Column(Boolean(), nullable=False)
    job_type = Column(Enum(SCHEDULER_JOB_TYPE.ONE_TIME, SCHEDULER_JOB_TYPE.INTERVAL_BASED,
                           SCHEDULER_JOB_TYPE.CRON_STYLE, name='job_type'), nullable=False)
    start_date = Column(DateTime(), nullable=False)
    extra = Column(LargeBinary(500000), nullable=True)

    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    cluster = relationship(Cluster, backref=backref('jobs', order_by=name, cascade='all, delete, delete-orphan'))

    service_id = Column(Integer, ForeignKey('service.id', ondelete='CASCADE'), nullable=False)
    service = relationship(Service, backref=backref('jobs', order_by=name, cascade='all, delete, delete-orphan'))

    def __init__(self, id=None, name=None, is_active=None, job_type=None,
                 start_date=None, extra=None, cluster=None, cluster_id=None,
                 service=None, service_id=None, service_name=None, interval_based=None,
                 cron_style=None, definition_text=None, job_type_friendly=None):
        self.id = id
        self.name = name
        self.is_active = is_active
        self.job_type = job_type
        self.start_date = start_date
        self.extra = extra
        self.cluster = cluster
        self.cluster_id = cluster_id
        self.service = service
        self.service_id = service_id
        self.service_name = service_name # Not used by the database
        self.interval_based = interval_based
        self.cron_style = cron_style
        self.definition_text = definition_text # Not used by the database
        self.job_type_friendly = job_type_friendly # Not used by the database

class IntervalBasedJob(Base):
    """ A Cron-style scheduler's job.
    """
    __tablename__ = 'job_interval_based'
    __table_args__ = (UniqueConstraint('job_id'), {})

    id = Column(Integer, Sequence('job_intrvl_seq'), primary_key=True)
    job_id = Column(Integer, nullable=False)

    weeks = Column(Integer, nullable=True)
    days = Column(Integer, nullable=True)
    hours = Column(Integer, nullable=True)
    minutes = Column(Integer, nullable=True)
    seconds = Column(Integer, nullable=True)
    repeats = Column(Integer, nullable=True)

    job_id = Column(Integer, ForeignKey('job.id', ondelete='CASCADE'), nullable=False)
    job = relationship(Job, backref=backref('interval_based', uselist=False, cascade='all, delete, delete-orphan', single_parent=True))

    def __init__(self, id=None, job=None, weeks=None, days=None, hours=None,
                 minutes=None, seconds=None, repeats=None, definition_text=None):
        self.id = id
        self.job = job
        self.weeks = weeks
        self.days = days
        self.hours = hours
        self.minutes = minutes
        self.seconds = seconds
        self.repeats = repeats
        self.definition_text = definition_text # Not used by the database

class CronStyleJob(Base):
    """ A Cron-style scheduler's job.
    """
    __tablename__ = 'job_cron_style'
    __table_args__ = (UniqueConstraint('job_id'), {})

    id = Column(Integer, Sequence('job_cron_seq'), primary_key=True)
    cron_definition = Column(String(4000), nullable=False)

    job_id = Column(Integer, ForeignKey('job.id', ondelete='CASCADE'), nullable=False)
    job = relationship(Job, backref=backref('cron_style', uselist=False, cascade='all, delete, delete-orphan', single_parent=True))

    def __init__(self, id=None, job=None, cron_definition=None):
        self.id = id
        self.job = job
        self.cron_definition = cron_definition

# ################################################################################################################################

class ConnDefAMQP(Base):
    """ An AMQP connection definition.
    """
    __tablename__ = 'conn_def_amqp'
    __table_args__ = (UniqueConstraint('name', 'cluster_id', 'def_type'), {})

    id = Column(Integer, Sequence('conn_def_amqp_seq'), primary_key=True)
    name = Column(String(200), nullable=False)
    # TODO is_active = Column(Boolean(), nullable=False)

    def_type = Column(String(10), nullable=False)
    host = Column(String(200), nullable=False)
    port = Column(Integer(), nullable=False)
    vhost = Column(String(200), nullable=False)
    username = Column(String(200), nullable=False)
    password = Column(String(200), nullable=False)
    frame_max = Column(Integer(), nullable=False)
    heartbeat = Column(Integer(), nullable=False)

    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    cluster = relationship(Cluster, backref=backref('amqp_conn_defs', order_by=name, cascade='all, delete, delete-orphan'))

    def __init__(self, id=None, name=None, def_type=None, host=None, port=None,
                 vhost=None, username=None, password=None, frame_max=None,
                 heartbeat=None, cluster_id=None):
        self.id = id
        self.name = name
        self.def_type = def_type
        self.host = host
        self.port = port
        self.vhost = vhost
        self.username = username
        self.password = password
        self.frame_max = frame_max
        self.heartbeat = heartbeat
        self.cluster_id = cluster_id

class ConnDefWMQ(Base):
    """ A WebSphere MQ connection definition.
    """
    __tablename__ = 'conn_def_wmq'
    __table_args__ = (UniqueConstraint('name', 'cluster_id'), {})

    id = Column(Integer, Sequence('conn_def_wmq_seq'), primary_key=True)
    name = Column(String(200), nullable=False)
    # TODO is_active = Column(Boolean(), nullable=False)

    host = Column(String(200), nullable=False)
    port = Column(Integer, nullable=False)
    queue_manager = Column(String(200), nullable=False)
    channel = Column(String(200), nullable=False)
    cache_open_send_queues = Column(Boolean(), nullable=False)
    cache_open_receive_queues = Column(Boolean(), nullable=False)
    use_shared_connections = Column(Boolean(), nullable=False)
    dynamic_queue_template = Column(String(200), nullable=False, server_default='SYSTEM.DEFAULT.MODEL.QUEUE') # We're not actually using it yet
    ssl = Column(Boolean(), nullable=False)
    ssl_cipher_spec = Column(String(200))
    ssl_key_repository = Column(String(200))
    needs_mcd = Column(Boolean(), nullable=False)
    max_chars_printed = Column(Integer, nullable=False)

    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    cluster = relationship(Cluster, backref=backref('wmq_conn_defs', order_by=name, cascade='all, delete, delete-orphan'))

    def __init__(self, id=None, name=None, host=None, port=None,
                 queue_manager=None, channel=None, cache_open_send_queues=None,
                 cache_open_receive_queues=None, use_shared_connections=None, ssl=None,
                 ssl_cipher_spec=None, ssl_key_repository=None, needs_mcd=None,
                 max_chars_printed=None, cluster_id=None):
        self.id = id
        self.name = name
        self.host = host
        self.queue_manager = queue_manager
        self.channel = channel
        self.port = port
        self.cache_open_receive_queues = cache_open_receive_queues
        self.cache_open_send_queues = cache_open_send_queues
        self.use_shared_connections = use_shared_connections
        self.ssl = ssl
        self.ssl_cipher_spec = ssl_cipher_spec
        self.ssl_key_repository = ssl_key_repository
        self.needs_mcd = needs_mcd
        self.max_chars_printed = max_chars_printed
        self.cluster_id = cluster_id

# ################################################################################################################################

class OutgoingAMQP(Base):
    """ An outgoing AMQP connection.
    """
    __tablename__ = 'out_amqp'
    __table_args__ = (UniqueConstraint('name', 'def_id'), {})

    id = Column(Integer, Sequence('out_amqp_seq'), primary_key=True)
    name = Column(String(200), nullable=False)
    is_active = Column(Boolean(), nullable=False)

    delivery_mode = Column(SmallInteger(), nullable=False)
    priority = Column(SmallInteger(), server_default=str(AMQP_DEFAULT_PRIORITY), nullable=False)

    content_type = Column(String(200), nullable=True)
    content_encoding = Column(String(200), nullable=True)
    expiration = Column(String(20), nullable=True)
    user_id = Column(String(200), nullable=True)
    app_id = Column(String(200), nullable=True)

    def_id = Column(Integer, ForeignKey('conn_def_amqp.id', ondelete='CASCADE'), nullable=False)
    def_ = relationship(ConnDefAMQP, backref=backref('out_conns_amqp', cascade='all, delete, delete-orphan'))

    def __init__(self, id=None, name=None, is_active=None, delivery_mode=None,
                 priority=None, content_type=None, content_encoding=None,
                 expiration=None, user_id=None, app_id=None, def_id=None,
                 delivery_mode_text=None, def_name=None):
        self.id = id
        self.name = name
        self.is_active = is_active
        self.delivery_mode = delivery_mode
        self.priority = priority
        self.content_type = content_type
        self.content_encoding = content_encoding
        self.expiration = expiration
        self.user_id = user_id
        self.app_id = app_id
        self.def_id = def_id
        self.delivery_mode_text = delivery_mode_text # Not used by the DB
        self.def_name = def_name # Not used by the DB

class OutgoingFTP(Base):
    """ An outgoing FTP connection.
    """
    __tablename__ = 'out_ftp'
    __table_args__ = (UniqueConstraint('name', 'cluster_id'), {})

    id = Column(Integer, Sequence('out_ftp_seq'), primary_key=True)
    name = Column(String(200), nullable=False)
    is_active = Column(Boolean(), nullable=False)

    host = Column(String(200), nullable=False)
    user = Column(String(200), nullable=True)
    password = Column(String(200), nullable=True)
    acct = Column(String(200), nullable=True)
    timeout = Column(Integer, nullable=True)
    port = Column(Integer, server_default=str(FTP_PORT), nullable=False)
    dircache = Column(Boolean(), nullable=False)

    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    cluster = relationship(Cluster, backref=backref('out_conns_ftp', order_by=name, cascade='all, delete, delete-orphan'))

    def __init__(self, id=None, name=None, is_active=None, host=None, user=None,
                 password=None, acct=None, timeout=None, port=None, dircache=None,
                 cluster_id=None):
        self.id = id
        self.name = name
        self.is_active = is_active
        self.host = host
        self.user = user
        self.password = password
        self.acct = acct
        self.timeout = timeout
        self.port = port
        self.dircache = dircache
        self.cluster_id = cluster_id

class OutgoingWMQ(Base):
    """ An outgoing WebSphere MQ connection.
    """
    __tablename__ = 'out_wmq'
    __table_args__ = (UniqueConstraint('name', 'def_id'), {})

    id = Column(Integer, Sequence('out_wmq_seq'), primary_key=True)
    name = Column(String(200), nullable=False)
    is_active = Column(Boolean(), nullable=False)

    delivery_mode = Column(SmallInteger(), nullable=False)
    priority = Column(SmallInteger(), server_default=str(WMQ_DEFAULT_PRIORITY), nullable=False)
    expiration = Column(String(20), nullable=True)

    def_id = Column(Integer, ForeignKey('conn_def_wmq.id', ondelete='CASCADE'), nullable=False)
    def_ = relationship(ConnDefWMQ, backref=backref('out_conns_wmq', cascade='all, delete, delete-orphan'))

    def __init__(self, id=None, name=None, is_active=None, delivery_mode=None,
                 priority=None, expiration=None, def_id=None, delivery_mode_text=None,
                 def_name=None):
        self.id = id
        self.name = name
        self.is_active = is_active
        self.delivery_mode = delivery_mode
        self.priority = priority
        self.expiration = expiration
        self.def_id = def_id
        self.delivery_mode_text = delivery_mode_text # Not used by the DB
        self.def_name = def_name # Not used by the DB

class OutgoingZMQ(Base):
    """ An outgoing Zero MQ connection.
    """
    __tablename__ = 'out_zmq'
    __table_args__ = (UniqueConstraint('name', 'cluster_id'), {})

    id = Column(Integer, Sequence('out_zmq_seq'), primary_key=True)
    name = Column(String(200), nullable=False)
    is_active = Column(Boolean(), nullable=False)

    address = Column(String(200), nullable=False)
    socket_type = Column(String(20), nullable=False)

    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    cluster = relationship(Cluster, backref=backref('out_conns_zmq', order_by=name, cascade='all, delete, delete-orphan'))

    def __init__(self, id=None, name=None, is_active=None, address=None,
                 socket_type=None, cluster_id=None):
        self.id = id
        self.name = name
        self.is_active = is_active
        self.socket_type = socket_type
        self.address = address
        self.cluster_id = cluster_id

# ################################################################################################################################

class ChannelAMQP(Base):
    """ An incoming AMQP connection.
    """
    __tablename__ = 'channel_amqp'
    __table_args__ = (UniqueConstraint('name', 'def_id'), {})

    id = Column(Integer, Sequence('channel_amqp_seq'), primary_key=True)
    name = Column(String(200), nullable=False)
    is_active = Column(Boolean(), nullable=False)
    queue = Column(String(200), nullable=False)
    consumer_tag_prefix = Column(String(200), nullable=False)
    data_format = Column(String(20), nullable=True)

    service_id = Column(Integer, ForeignKey('service.id', ondelete='CASCADE'), nullable=False)
    service = relationship(Service, backref=backref('channels_amqp', order_by=name, cascade='all, delete, delete-orphan'))

    def_id = Column(Integer, ForeignKey('conn_def_amqp.id', ondelete='CASCADE'), nullable=False)
    def_ = relationship(ConnDefAMQP, backref=backref('channels_amqp', cascade='all, delete, delete-orphan'))

    def __init__(self, id=None, name=None, is_active=None, queue=None,
                 consumer_tag_prefix=None, def_id=None, def_name=None,
                 service_name=None, data_format=None):
        self.id = id
        self.name = name
        self.is_active = is_active
        self.queue = queue
        self.consumer_tag_prefix = consumer_tag_prefix
        self.def_id = def_id
        self.def_name = def_name # Not used by the DB
        self.service_name = service_name # Not used by the DB
        self.data_format = data_format

class ChannelWMQ(Base):
    """ An incoming WebSphere MQ connection.
    """
    __tablename__ = 'channel_wmq'
    __table_args__ = (UniqueConstraint('name', 'def_id'), {})

    id = Column(Integer, Sequence('channel_wmq_seq'), primary_key=True)
    name = Column(String(200), nullable=False)
    is_active = Column(Boolean(), nullable=False)
    queue = Column(String(200), nullable=False)
    data_format = Column(String(20), nullable=True)

    service_id = Column(Integer, ForeignKey('service.id', ondelete='CASCADE'), nullable=False)
    service = relationship(Service, backref=backref('channels_wmq', order_by=name, cascade='all, delete, delete-orphan'))

    def_id = Column(Integer, ForeignKey('conn_def_wmq.id', ondelete='CASCADE'), nullable=False)
    def_ = relationship(ConnDefWMQ, backref=backref('channels_wmq', cascade='all, delete, delete-orphan'))

    def __init__(self, id=None, name=None, is_active=None, queue=None,
                 def_id=None, def_name=None, service_name=None, data_format=None):
        self.id = id
        self.name = name
        self.is_active = is_active
        self.queue = queue
        self.def_id = def_id
        self.def_name = def_name # Not used by the DB
        self.service_name = service_name # Not used by the DB
        self.data_format = data_format

class ChannelZMQ(Base):
    """ An incoming Zero MQ connection.
    """
    __tablename__ = 'channel_zmq'
    __table_args__ = (UniqueConstraint('name', 'cluster_id'), {})

    id = Column(Integer, Sequence('channel_zmq_seq'), primary_key=True)
    name = Column(String(200), nullable=False)
    is_active = Column(Boolean(), nullable=False)

    address = Column(String(200), nullable=False)
    socket_type = Column(String(20), nullable=False)
    sub_key = Column(String(200), nullable=True)
    data_format = Column(String(20), nullable=True)

    service_id = Column(Integer, ForeignKey('service.id', ondelete='CASCADE'), nullable=False)
    service = relationship(Service, backref=backref('channels_zmq', order_by=name, cascade='all, delete, delete-orphan'))

    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    cluster = relationship(Cluster, backref=backref('channels_zmq', order_by=name, cascade='all, delete, delete-orphan'))

    def __init__(self, id=None, name=None, is_active=None, address=None,
                 socket_type=None, sub_key=None, service_name=None, data_format=None):
        self.id = id
        self.name = name
        self.is_active = is_active
        self.address = address
        self.socket_type = socket_type
        self.sub_key = sub_key
        self.service_name = service_name # Not used by the DB
        self.data_format = data_format

class DeploymentPackage(Base):
    """ A package to be deployed onto a server, either a plain .py/.pyw or
    a Distutils2 archive.
    """
    __tablename__ = 'deployment_package'

    id = Column(Integer, Sequence('depl_package_seq'), primary_key=True)
    deployment_time = Column(DateTime(), nullable=False)
    details = Column(String(2000), nullable=False)

    payload_name = Column(String(200), nullable=False)
    payload = Column(LargeBinary(5000000), nullable=False)

    server_id = Column(Integer, ForeignKey('server.id', ondelete='CASCADE'), nullable=False, primary_key=False)
    server = relationship(Server, backref=backref('originating_deployment_packages', order_by=deployment_time, cascade='all, delete, delete-orphan'))

    def __init__(self, id=None, deployment_time=None, details=None, payload_name=None, payload=None):
        self.id = id
        self.deployment_time = deployment_time
        self.details = details
        self.payload_name = payload_name
        self.payload = payload

class DeploymentStatus(Base):
    """ Whether a server has already deployed a given package.
    """
    __tablename__ = 'deployment_status'
    __table_args__ = (UniqueConstraint('package_id', 'server_id'), {})

    id = Column(Integer, Sequence('depl_status_seq'), primary_key=True)

    package_id = Column(Integer, ForeignKey('deployment_package.id', ondelete='CASCADE'), nullable=False, primary_key=False)
    package = relationship(DeploymentPackage, backref=backref('deployment_status_list', order_by=package_id, cascade='all, delete, delete-orphan'))

    server_id = Column(Integer, ForeignKey('server.id', ondelete='CASCADE'), nullable=False, primary_key=False)
    server = relationship(Server, backref=backref('deployment_status_list', order_by=server_id, cascade='all, delete, delete-orphan'))

    # See zato.common.DEPLOYMENT_STATUS
    status = Column(String(20), nullable=False)
    status_change_time = Column(DateTime(), nullable=False)

    def __init__(self, package_id=None, server_id=None, status=None, status_change_time=None):
        self.package_id = package_id
        self.server_id = server_id
        self.status = status
        self.status_change_time = status_change_time

# ################################################################################################################################

class DeliveryDefinitionBase(Base):
    """ A guaranteed delivery's definition (base class).
    """
    __tablename__ = 'delivery_def_base'
    __mapper_args__ = {'polymorphic_on': 'target_type'}

    id = Column(Integer, Sequence('deliv_def_seq'), primary_key=True)
    name = Column(String(200), nullable=False, index=True)
    short_def = Column(String(200), nullable=False)
    last_used = Column(DateTime(), nullable=True)

    target_type = Column(String(200), nullable=False)
    callback_list = Column(LargeBinary(10000), nullable=True)

    expire_after = Column(Integer, nullable=False)
    expire_arch_succ_after = Column(Integer, nullable=False)
    expire_arch_fail_after = Column(Integer, nullable=False)
    check_after = Column(Integer, nullable=False)
    retry_repeats = Column(Integer, nullable=False)
    retry_seconds = Column(Integer, nullable=False)

    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    cluster = relationship(Cluster, backref=backref('delivery_list', order_by=name, cascade='all, delete, delete-orphan'))

class DeliveryDefinitionOutconnWMQ(DeliveryDefinitionBase):
    """ A guaranteed delivery's definition (outgoing WebSphere MQ connections).
    """
    __tablename__ = 'delivery_def_out_wmq'
    __mapper_args__ = {'polymorphic_identity': INVOCATION_TARGET.OUTCONN_WMQ}

    id = Column(Integer, ForeignKey('delivery_def_base.id'), primary_key=True)
    target_id = Column(Integer, ForeignKey('out_wmq.id', ondelete='CASCADE'), nullable=False, primary_key=False)
    target = relationship(OutgoingWMQ, backref=backref('delivery_def_list', order_by=target_id, cascade='all, delete, delete-orphan'))

    def __init__(self, id=None, target_id=None):
        self.id = id
        self.target_id = target_id

class Delivery(Base):
    """ A guaranteed delivery.
    """
    __tablename__ = 'delivery'

    id = Column(Integer, Sequence('deliv_seq'), primary_key=True)
    task_id = Column(String(64), unique=True, nullable=False, index=True)

    name = Column(String(200), nullable=False)
    creation_time = Column(DateTime(), nullable=False)

    args = Column(LargeBinary(1000000), nullable=True)
    kwargs = Column(LargeBinary(1000000), nullable=True)

    last_used = Column(DateTime(), nullable=True)
    resubmit_count = Column(Integer, nullable=False, default=0)

    state = Column(String(200), nullable=False, index=True)

    source_count = Column(Integer, nullable=False, default=1)
    target_count = Column(Integer, nullable=False, default=0)

    definition_id = Column(Integer, ForeignKey('delivery_def_base.id', ondelete='CASCADE'), nullable=False, primary_key=False)
    definition = relationship(DeliveryDefinitionBase, backref=backref('delivery_list', order_by=creation_time, cascade='all, delete, delete-orphan'))

class DeliveryPayload(Base):
    """ A guaranteed delivery's payload.
    """
    __tablename__ = 'delivery_payload'

    id = Column(Integer, Sequence('deliv_payl_seq'), primary_key=True)
    task_id = Column(String(64), unique=True, nullable=False, index=True)

    creation_time = Column(DateTime(), nullable=False)
    payload = Column(LargeBinary(5000000), nullable=False)

    delivery_id = Column(Integer, ForeignKey('delivery.id', ondelete='CASCADE'), nullable=False, primary_key=False)
    delivery = relationship(Delivery, backref=backref('payload', uselist=False, cascade='all, delete, delete-orphan', single_parent=True))

class DeliveryHistory(Base):
    """ A guaranteed delivery's history.
    """
    __tablename__ = 'delivery_history'

    id = Column(Integer, Sequence('deliv_payl_seq'), primary_key=True)
    task_id = Column(String(64), nullable=False, index=True)

    entry_type = Column(String(64), nullable=False)
    entry_time = Column(DateTime(), nullable=False, index=True)
    entry_ctx = Column(LargeBinary(6000000), nullable=False)
    resubmit_count = Column(Integer, nullable=False, default=0) # Copy of delivery.resubmit_count so it's known for each history entry

    delivery_id = Column(Integer, ForeignKey('delivery.id', ondelete='CASCADE'), nullable=False, primary_key=False)
    delivery = relationship(Delivery, backref=backref('history_list', order_by=entry_time, cascade='all, delete, delete-orphan'))

# ################################################################################################################################

class MsgNamespace(Base):
    """ A message namespace, used in XPath, for instance.
    """
    __tablename__ = 'msg_ns'
    __table_args__ = (UniqueConstraint('name', 'cluster_id'), {})

    id = Column(Integer, Sequence('msg_ns_seq'), primary_key=True)
    name = Column(String(200), nullable=False)
    value = Column(String(500), nullable=False)

    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    cluster = relationship(Cluster, backref=backref('namespaces', order_by=name, cascade='all, delete, delete-orphan'))

    def __init__(self, id=None, name=None, value=None, cluster_id=None):
        self.id = id
        self.name = name
        self.value = value
        self.cluster_id = cluster_id

class XPath(Base):
    """ An XPath expression to run against XML messages.
    """
    __tablename__ = 'msg_xpath'
    __table_args__ = (UniqueConstraint('name', 'cluster_id'), {})

    id = Column(Integer, Sequence('msg_xpath_seq'), primary_key=True)
    name = Column(String(200), nullable=False)
    value = Column(String(1500), nullable=False)

    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    cluster = relationship(Cluster, backref=backref('xpaths', order_by=name, cascade='all, delete, delete-orphan'))

    def __init__(self, id=None, name=None, value=None, cluster_id=None):
        self.id = id
        self.name = name
        self.value = value
        self.cluster_id = cluster_id

class JSONPointer(Base):
    """ An XPath-list expression to run against JSON messages.
    """
    __tablename__ = 'msg_json_pointer'
    __table_args__ = (UniqueConstraint('name', 'cluster_id'), {})

    id = Column(Integer, Sequence('msg_json_pointer_seq'), primary_key=True)
    name = Column(String(200), nullable=False)
    value = Column(String(1500), nullable=False)

    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    cluster = relationship(Cluster, backref=backref('json_pointers', order_by=name, cascade='all, delete, delete-orphan'))

    def __init__(self, id=None, name=None, value=None, cluster_id=None):
        self.id = id
        self.name = name
        self.value = value
        self.cluster_id = cluster_id

# ################################################################################################################################

class HTTSOAPAudit(Base):
    """ An audit log for HTTP/SOAP channels and outgoing connections.
    """
    __tablename__ = 'http_soap_audit'

    id = Column(Integer, Sequence('http_soap_audit_seq'), primary_key=True)
    name = Column(String(200), nullable=False, index=True)
    cid = Column(String(200), nullable=False, index=True)
    
    transport = Column(String(200), nullable=False, index=True)
    connection = Column(String(200), nullable=False, index=True)
    
    req_time = Column(DateTime(), nullable=False)
    resp_time = Column(DateTime(), nullable=True)
    
    user_token = Column(String(200), nullable=True, index=True)
    invoke_ok = Column(Boolean(), nullable=True)
    auth_ok = Column(Boolean(), nullable=True)
    remote_addr = Column(String(200), nullable=False, index=True)
    
    req_headers = Column(LargeBinary(), nullable=True)
    req_payload = Column(LargeBinary(), nullable=True)
    resp_headers = Column(LargeBinary(), nullable=True)
    resp_payload = Column(LargeBinary(), nullable=True)

    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    conn_id = Column(Integer, ForeignKey('http_soap.id', ondelete='CASCADE'), nullable=False)

    def __init__(self, id=None, name=None, cid=None, transport=None, 
            connection=None, req_time=None, resp_time=None, user_token=None, 
            invoke_ok=None, auth_ok=None, remote_addr=None, req_headers=None,
            req_payload=None, resp_headers=None, resp_payload=None):
        
        self.id = id
        self.name = name
        self.cid = cid
        
        self.transport = transport
        self.connection = connection
        
        self.req_time = req_time
        self.resp_time = resp_time
        
        self.user_token = user_token
        self.invoke_ok = invoke_ok
        self.auth_ok = auth_ok
        self.remote_addr = remote_addr
        
        self.req_headers = req_headers
        self.req_payload = req_payload
        self.resp_headers = resp_headers
        self.resp_payload = resp_payload

class HTTSOAPAuditReplacePatternsJSONPointer(Base):
    """ JSONPointer replace patterns for HTTP/SOAP connections.
    """
    __tablename__ = 'http_soap_au_rpl_p_jp'
    __table_args__ = (UniqueConstraint('conn_id', 'pattern_id'), {})
    
    id = Column(Integer, Sequence('htp_sp_ad_rpl_p_jp_seq'), primary_key=True)
    conn_id = Column(Integer, ForeignKey('http_soap.id', ondelete='CASCADE'), nullable=False)
    pattern_id = Column(Integer, ForeignKey('msg_json_pointer.id', ondelete='CASCADE'), nullable=False)
    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    
    replace_patterns_json_pointer = relationship(HTTPSOAP, 
        backref=backref('replace_patterns_json_pointer', order_by=id, cascade='all, delete, delete-orphan'))

    pattern = relationship(JSONPointer)
    
class HTTSOAPAuditReplacePatternsXPath(Base):
    """ XPath replace patterns for HTTP/SOAP connections.
    """
    __tablename__ = 'http_soap_au_rpl_p_xp'
    __table_args__ = (UniqueConstraint('conn_id', 'pattern_id'), {})
    
    id = Column(Integer, Sequence('htp_sp_ad_rpl_p_xp_seq'), primary_key=True)
    conn_id = Column(Integer, ForeignKey('http_soap.id', ondelete='CASCADE'), nullable=False)
    pattern_id = Column(Integer, ForeignKey('msg_xpath.id', ondelete='CASCADE'), nullable=False)
    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    
    replace_patterns_xpath = relationship(HTTPSOAP, 
        backref=backref('replace_patterns_xpath', order_by=id, cascade='all, delete, delete-orphan'))

    pattern = relationship(XPath)

# ################################################################################################################################

class PubSubTopic(Base):
    """ A definition of a topic in pub/sub.
    """
    __tablename__ = 'pub_sub_topic'
    __table_args__ = (UniqueConstraint('name', 'cluster_id'), {})

    id = Column(Integer, Sequence('pub_sub_topic_seq'), primary_key=True)
    name = Column(String(200), nullable=False)
    is_active = Column(Boolean(), nullable=False)
    max_depth = Column(Integer, nullable=False)

    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    cluster = relationship(Cluster, backref=backref('pub_sub_topics', order_by=name, cascade='all, delete, delete-orphan'))

    def __init__(self, id=None, name=None, is_active=None, max_depth=None, cluster_id=None):
        self.id = id
        self.name = name
        self.is_active = is_active
        self.max_depth = max_depth
        self.cluster_id = cluster_id
        self.last_pub_time = None # Not used by the database
        self.cur_depth = None # Not used by the database
        self.cur_consumers = None # Not used by the database
        self.cur_producers = None # Not used by the database

# ################################################################################################################################

class PubSubConsumer(Base):
    """ All consumers of a given topic, including ones that are not currently connected.
    """
    __tablename__ = 'pub_sub_consumer'
    __table_args__ = (UniqueConstraint('sec_def_id', 'topic_id', 'cluster_id'), {})

    id = Column(Integer, Sequence('pub_sub_cons_seq'), primary_key=True)
    is_active = Column(Boolean(), nullable=False)
    sub_key = Column(String(200), nullable=False)
    max_backlog = Column(Integer, nullable=False)
    delivery_mode = Column(String(200), nullable=False)

    # Our only callback type right now is an HTTP outconn but more will come with time.
    callback_id = Column(Integer, ForeignKey('http_soap.id', ondelete='CASCADE'), nullable=True)
    callback_type = Column(String(20), nullable=True, default=PUB_SUB.CALLBACK_TYPE.OUTCONN_PLAIN_HTP)

    topic_id = Column(Integer, ForeignKey('pub_sub_topic.id', ondelete='CASCADE'), nullable=False)
    topic = relationship(PubSubTopic, backref=backref('consumers', order_by=max_backlog, cascade='all, delete, delete-orphan'))

    sec_def_id = Column(Integer, ForeignKey('sec_base.id', ondelete='CASCADE'), nullable=False)
    sec_def = relationship(SecurityBase, backref=backref('pub_sub_consumers', order_by=max_backlog, cascade='all, delete, delete-orphan'))

    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    cluster = relationship(Cluster, backref=backref('pub_sub_consumers', order_by=max_backlog, cascade='all, delete, delete-orphan'))

    http_soap = relationship(SecurityBase, backref=backref('pubsub_consumers', order_by=max_backlog, cascade='all, delete, delete-orphan'))

    def __init__(self, id=None, is_active=None, sub_key=None, max_backlog=None, delivery_mode=None, callback_id=None,
                callback_type=None, topic_id=None, sec_def_id=None, cluster_id=None):
        self.id = id
        self.is_active = is_active
        self.sub_key = sub_key
        self.max_backlog = max_backlog
        self.delivery_mode = delivery_mode
        self.callback_id = callback_id
        self.callback_type = callback_type
        self.topic_id = topic_id
        self.sec_def_id = sec_def_id
        self.cluster_id = cluster_id
        self.last_seen = None # Not used by the DB

# ################################################################################################################################

class PubSubProducer(Base):
    """ All producers allowed to publish to a given topic.
    """
    __tablename__ = 'pub_sub_producer'
    __table_args__ = (UniqueConstraint('sec_def_id', 'topic_id', 'cluster_id'), {})

    id = Column(Integer, Sequence('pub_sub_cons_seq'), primary_key=True)
    is_active = Column(Boolean(), nullable=False)

    topic_id = Column(Integer, ForeignKey('pub_sub_topic.id', ondelete='CASCADE'), nullable=False)
    topic = relationship(PubSubTopic, backref=backref('producers', order_by=is_active, cascade='all, delete, delete-orphan'))

    sec_def_id = Column(Integer, ForeignKey('sec_base.id', ondelete='CASCADE'), nullable=False)
    sec_def = relationship(SecurityBase, backref=backref('pub_sub_producers', order_by=is_active, cascade='all, delete, delete-orphan'))

    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    cluster = relationship(Cluster, backref=backref('pub_sub_producers', order_by=is_active, cascade='all, delete, delete-orphan'))

    def __init__(self, id=None, is_active=None, topic_id=None, sec_def_id=None, cluster_id=None):
        self.id = id
        self.is_active = is_active
        self.topic_id = topic_id
        self.sec_def_id = sec_def_id
        self.cluster_id = cluster_id
        self.last_seen = None # Not used by the DB

# ################################################################################################################################

class OpenStackSwift(Base):
    """ A connection to OpenStack's Swift.
    """
    __tablename__ = 'os_swift'
    __table_args__ = (UniqueConstraint('name', 'cluster_id'), {})

    id = Column(Integer, Sequence('os_swift_seq'), primary_key=True)
    name = Column(String(200), nullable=False)
    is_active = Column(Boolean(), nullable=False)
    pool_size = Column(Integer, nullable=False, default=CLOUD.OPENSTACK.SWIFT.DEFAULTS.POOL_SIZE)

    auth_url = Column(String(200), nullable=False)
    auth_version = Column(String(200), nullable=False, default=CLOUD.OPENSTACK.SWIFT.DEFAULTS.AUTH_VERSION)
    user = Column(String(200), nullable=True)
    key = Column(String(200), nullable=True)
    retries = Column(Integer, nullable=False, default=CLOUD.OPENSTACK.SWIFT.DEFAULTS.RETRIES)
    is_snet = Column(Boolean(), nullable=False)
    starting_backoff = Column(Integer, nullable=False, default=CLOUD.OPENSTACK.SWIFT.DEFAULTS.BACKOFF_STARTING)
    max_backoff = Column(Integer, nullable=False, default=CLOUD.OPENSTACK.SWIFT.DEFAULTS.BACKOFF_MAX)
    tenant_name = Column(String(200), nullable=True)
    should_validate_cert = Column(Boolean(), nullable=False)
    cacert = Column(String(200), nullable=True)
    should_retr_ratelimit = Column(Boolean(), nullable=False)
    needs_tls_compr = Column(Boolean(), nullable=False)
    custom_options = Column(String(2000), nullable=True)

    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    cluster = relationship(Cluster, backref=backref('openstack_swift_conns', order_by=name, cascade='all, delete, delete-orphan'))

    def __init__(self, id=None, name=None, is_active=None, auth_url=None, auth_version=None, user=None, key=None, retries=None,
            is_snet=None, starting_backoff=None, max_backoff=None, tenant_name=None, should_validate_cert=None,
            cacert=None, should_retr_ratelimit=None, needs_tls_compr=None, custom_options=None):
        self.id = id
        self.name = name
        self.is_active = is_active
        self.auth_url = auth_url
        self.auth_version = auth_version
        self.user = user
        self.key = key
        self.retries = retries
        self.is_snet = is_snet
        self.starting_backoff = starting_backoff
        self.max_backoff = max_backoff
        self.tenant_name = tenant_name
        self.should_validate_cert = should_validate_cert
        self.cacert = cacert
        self.should_retr_ratelimit = should_retr_ratelimit
        self.needs_tls_compr = needs_tls_compr
        self.custom_options = custom_options

# ################################################################################################################################

class AWSS3(Base):
    """ An outgoing connection to AWS S3.
    """
    __tablename__ = 'aws_s3'
    __table_args__ = (UniqueConstraint('name', 'cluster_id'), {})

    id = Column(Integer, Sequence('aws_s3_seq'), primary_key=True)
    name = Column(String(200), nullable=False)
    is_active = Column(Boolean(), nullable=False)
    pool_size = Column(Integer, nullable=False, default=CLOUD.AWS.S3.DEFAULTS.POOL_SIZE)

    address = Column(String(200), nullable=False, default=CLOUD.AWS.S3.DEFAULTS.ADDRESS)
    debug_level = Column(Integer, nullable=False, default=CLOUD.AWS.S3.DEFAULTS.DEBUG_LEVEL)
    suppr_cons_slashes = Column(Boolean(), nullable=False, default=True)
    content_type = Column(String(200), nullable=False, default=CLOUD.AWS.S3.DEFAULTS.CONTENT_TYPE)
    metadata_ = Column(String(2000), nullable=True) # Can't be 'metadata' because this is reserved to SQLAlchemy
    bucket = Column(String(2000), nullable=True)
    encrypt_at_rest = Column(Boolean(), nullable=False, default=False)
    storage_class = Column(String(200), nullable=False, default=CLOUD.AWS.S3.STORAGE_CLASS.DEFAULT)

    security_id = Column(Integer, ForeignKey('sec_base.id', ondelete='CASCADE'), nullable=False)
    security = relationship(SecurityBase, backref=backref('aws_s3_conns', order_by=is_active, cascade='all, delete, delete-orphan'))

    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    cluster = relationship(Cluster, backref=backref('aws_s3_conns', order_by=name, cascade='all, delete, delete-orphan'))

    def to_json(self):
        return to_json(self)

# ################################################################################################################################

class Notification(Base):
    """ A base class for all notifications, be it cloud, FTP-based or others.
    """
    __tablename__ = 'notif'
    __table_args__ = (UniqueConstraint('name', 'cluster_id'), {})
    __mapper_args__ = {'polymorphic_on': 'notif_type'}

    id = Column(Integer, Sequence('sec_base_seq'), primary_key=True)
    name = Column(String(200), nullable=False)
    is_active = Column(Boolean(), nullable=False, default=True)
    notif_type = Column(String(45), nullable=False)

    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    interval = Column(Integer, nullable=False, default=NOTIF.DEFAULT.CHECK_INTERVAL)
    name_pattern = Column(String(2000), nullable=False, default=NOTIF.DEFAULT.NAME_PATTERN)
    name_pattern_neg = Column(Boolean(), nullable=False, default=False)

    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    get_data = Column(Boolean(), nullable=False, default=False)
    get_data_patt = Column(String(2000), nullable=False, default=NOTIF.DEFAULT.GET_DATA_PATTERN)
    get_data_patt_neg = Column(Boolean(), nullable=False, default=False)

    service_id = Column(Integer, ForeignKey('service.id', ondelete='CASCADE'), nullable=False)
    service = relationship(Service, backref=backref('notification_list', order_by=name, cascade='all, delete, delete-orphan'))

    cluster_id = Column(Integer, ForeignKey('cluster.id', ondelete='CASCADE'), nullable=False)
    cluster = relationship(Cluster, backref=backref('notification_list', order_by=name, cascade='all, delete, delete-orphan'))

# ################################################################################################################################

class NotificationOpenStackSwift(Notification):
    """ New in 2.0: Stores OpenStack Swift notifications.
    """
    __tablename__ = 'notif_os_swift'
    __mapper_args__ = {'polymorphic_identity': 'openstack_swift'}

    id = Column(Integer, ForeignKey('notif.id'), primary_key=True)
    
    containers = Column(String(20000), nullable=False)

    def_id = Column(Integer, ForeignKey('os_swift.id'), primary_key=True)
    definition = relationship(OpenStackSwift, backref=backref('notif_oss_list', order_by=id, cascade='all, delete, delete-orphan'))

    def to_json(self):
        return to_json(self)

# ################################################################################################################################

########NEW FILE########
__FILENAME__ = query
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from functools import wraps

# SQLAlchemy
from sqlalchemy import func, not_
from sqlalchemy.sql.expression import case

# Zato
from zato.common import DEFAULT_HTTP_PING_METHOD, DEFAULT_HTTP_POOL_SIZE, HTTP_SOAP_SERIALIZATION_TYPE, PARAMS_PRIORITY, \
     URL_PARAMS_PRIORITY
from zato.common.odb.model import AWSS3, APIKeySecurity, AWSSecurity, ChannelAMQP, ChannelWMQ, ChannelZMQ, Cluster, ConnDefAMQP, \
     ConnDefWMQ, CronStyleJob, DeliveryDefinitionBase, DeliveryDefinitionOutconnWMQ, Delivery, DeliveryHistory, DeliveryPayload, \
     JSONPointer, HTTPBasicAuth, HTTPSOAP, HTTSOAPAudit, IntervalBasedJob, Job, MsgNamespace, \
     NotificationOpenStackSwift as NotifOSS, NTLM, OAuth, OpenStackSecurity, OpenStackSwift, OutgoingAMQP, OutgoingFTP, \
     OutgoingWMQ, OutgoingZMQ, PubSubConsumer, PubSubProducer, PubSubTopic, SecurityBase, Server, Service, SQLConnectionPool, \
     TechnicalAccount, WSSDefinition, XPath, XPathSecurity

logger = logging.getLogger(__name__)

def needs_columns(func):
    """ A decorator for queries which works out whether a given query function
    should return the result only or a column list retrieved in addition
    to the result. This is useful because some callers prefer the former and
    some need the latter.
    """
    @wraps(func)
    def inner(*args):
        # needs_columns is always the last argument so we don't have to look
        # it up using the 'inspect' module or anything like that.
        needs_columns = args[-1]

        q = func(*args)

        if needs_columns:
            return q.all(), q.statement.columns
        return q.all()

    return inner

# ################################################################################################################################

def internal_channel_list(session, cluster_id):
    """ All the HTTP/SOAP channels that point to internal services.
    """
    return session.query(
        HTTPSOAP.soap_action, Service.name).\
        filter(HTTPSOAP.cluster_id==Cluster.id).\
        filter(HTTPSOAP.service_id==Service.id).filter(Service.is_internal==True).filter(Cluster.id==cluster_id).filter(Cluster.id==HTTPSOAP.cluster_id) # noqa

# ################################################################################################################################

def _job(session, cluster_id):
    return session.query(
        Job.id, Job.name, Job.is_active,
        Job.job_type, Job.start_date, Job.extra,
        Service.name.label('service_name'), Service.impl_name.label('service_impl_name'),
        Service.id.label('service_id'),
        IntervalBasedJob.weeks, IntervalBasedJob.days,
        IntervalBasedJob.hours, IntervalBasedJob.minutes,
        IntervalBasedJob.seconds, IntervalBasedJob.repeats,
        CronStyleJob.cron_definition).\
        outerjoin(IntervalBasedJob, Job.id==IntervalBasedJob.job_id).\
        outerjoin(CronStyleJob, Job.id==CronStyleJob.job_id).\
        filter(Job.cluster_id==Cluster.id).\
        filter(Job.service_id==Service.id).\
        filter(Cluster.id==cluster_id).\
        order_by('job.name')

@needs_columns
def job_list(session, cluster_id, needs_columns=False):
    """ All the scheduler's jobs defined in the ODB.
    """
    return _job(session, cluster_id)

def job_by_name(session, cluster_id, name):
    """ A scheduler's job fetched by its name.
    """
    return _job(session, cluster_id).\
        filter(Job.name==name).\
        one()

# ################################################################################################################################

@needs_columns
def apikey_security_list(session, cluster_id, needs_columns=False):
    """ All the API keys.
    """
    return session.query(
        APIKeySecurity.id, APIKeySecurity.name,
        APIKeySecurity.is_active,
        APIKeySecurity.username,
        APIKeySecurity.password, APIKeySecurity.sec_type).\
        filter(Cluster.id==cluster_id).\
        filter(Cluster.id==APIKeySecurity.cluster_id).\
        filter(SecurityBase.id==APIKeySecurity.id).\
        order_by('sec_base.name')

@needs_columns
def aws_security_list(session, cluster_id, needs_columns=False):
    """ All the Amazon security definitions.
    """
    return session.query(
        AWSSecurity.id, AWSSecurity.name,
        AWSSecurity.is_active,
        AWSSecurity.username,
        AWSSecurity.password, AWSSecurity.sec_type).\
        filter(Cluster.id==cluster_id).\
        filter(Cluster.id==AWSSecurity.cluster_id).\
        filter(SecurityBase.id==AWSSecurity.id).\
        order_by('sec_base.name')

@needs_columns
def basic_auth_list(session, cluster_id, needs_columns=False):
    """ All the HTTP Basic Auth definitions.
    """
    return session.query(
        HTTPBasicAuth.id, HTTPBasicAuth.name,
        HTTPBasicAuth.is_active,
        HTTPBasicAuth.username, HTTPBasicAuth.realm,
        HTTPBasicAuth.password, HTTPBasicAuth.sec_type,
        HTTPBasicAuth.password_type).\
        filter(Cluster.id==cluster_id).\
        filter(Cluster.id==HTTPBasicAuth.cluster_id).\
        filter(SecurityBase.id==HTTPBasicAuth.id).\
        order_by('sec_base.name')

@needs_columns
def ntlm_list(session, cluster_id, needs_columns=False):
    """ All the NTLM definitions.
    """
    return session.query(
        NTLM.id, NTLM.name,
        NTLM.is_active,
        NTLM.username,
        NTLM.password, NTLM.sec_type,
        NTLM.password_type).\
        filter(Cluster.id==cluster_id).\
        filter(Cluster.id==NTLM.cluster_id).\
        filter(SecurityBase.id==NTLM.id).\
        order_by('sec_base.name')

@needs_columns
def oauth_list(session, cluster_id, needs_columns=False):
    """ All the OAuth definitions.
    """
    return session.query(
        OAuth.id, OAuth.name,
        OAuth.is_active,
        OAuth.username, OAuth.password,
        OAuth.proto_version, OAuth.sig_method,
        OAuth.max_nonce_log, OAuth.sec_type).\
        filter(Cluster.id==cluster_id).\
        filter(Cluster.id==OAuth.cluster_id).\
        filter(SecurityBase.id==OAuth.id).\
        order_by('sec_base.name')

@needs_columns
def openstack_security_list(session, cluster_id, needs_columns=False):
    """ All the OpenStackSecurity definitions.
    """
    return session.query(
        OpenStackSecurity.id, OpenStackSecurity.name, OpenStackSecurity.is_active,
        OpenStackSecurity.username, OpenStackSecurity.sec_type).\
        filter(Cluster.id==cluster_id).\
        filter(Cluster.id==OpenStackSecurity.cluster_id).\
        filter(SecurityBase.id==OpenStackSecurity.id).\
        order_by('sec_base.name')

@needs_columns
def tech_acc_list(session, cluster_id, needs_columns=False):
    """ All the technical accounts.
    """
    return session.query(
        TechnicalAccount.id, TechnicalAccount.name,
        TechnicalAccount.is_active,
        TechnicalAccount.password, TechnicalAccount.salt,
        TechnicalAccount.sec_type, TechnicalAccount.password_type).\
        order_by(TechnicalAccount.name).\
        filter(Cluster.id==cluster_id).\
        filter(Cluster.id==TechnicalAccount.cluster_id).\
        filter(SecurityBase.id==TechnicalAccount.id).\
        order_by('sec_base.name')

@needs_columns
def wss_list(session, cluster_id, needs_columns=False):
    """ All the WS-Security definitions.
    """
    return session.query(
        WSSDefinition.id, WSSDefinition.name, WSSDefinition.is_active,
        WSSDefinition.username, WSSDefinition.password, WSSDefinition.password_type,
        WSSDefinition.reject_empty_nonce_creat, WSSDefinition.reject_stale_tokens,
        WSSDefinition.reject_expiry_limit, WSSDefinition.nonce_freshness_time,
        WSSDefinition.sec_type).\
        filter(Cluster.id==cluster_id).\
        filter(Cluster.id==WSSDefinition.cluster_id).\
        filter(SecurityBase.id==WSSDefinition.id).\
        order_by('sec_base.name')

@needs_columns
def xpath_sec_list(session, cluster_id, needs_columns=False):
    """ All the XPath security definitions.
    """
    return session.query(
        XPathSecurity.id, XPathSecurity.name, XPathSecurity.is_active, XPathSecurity.username, XPathSecurity.username_expr,
        XPathSecurity.password_expr, XPathSecurity.password, XPathSecurity.sec_type).\
        filter(Cluster.id==cluster_id).\
        filter(Cluster.id==XPathSecurity.cluster_id).\
        filter(SecurityBase.id==XPathSecurity.id).\
        order_by('sec_base.name')

# ################################################################################################################################

def _def_amqp(session, cluster_id):
    return session.query(
        ConnDefAMQP.name, ConnDefAMQP.id, ConnDefAMQP.host,
        ConnDefAMQP.port, ConnDefAMQP.vhost, ConnDefAMQP.username,
        ConnDefAMQP.frame_max, ConnDefAMQP.heartbeat, ConnDefAMQP.password).\
        filter(ConnDefAMQP.def_type=='amqp').\
        filter(Cluster.id==ConnDefAMQP.cluster_id).\
        filter(Cluster.id==cluster_id).\
        order_by(ConnDefAMQP.name)

def def_amqp(session, cluster_id, id):
    """ A particular AMQP definition
    """
    return _def_amqp(session, cluster_id).\
        filter(ConnDefAMQP.id==id).\
        one()

@needs_columns
def def_amqp_list(session, cluster_id, needs_columns=False):
    """ AMQP connection definitions.
    """
    return _def_amqp(session, cluster_id)

# ################################################################################################################################

def _def_jms_wmq(session, cluster_id):
    return session.query(
        ConnDefWMQ.id, ConnDefWMQ.name, ConnDefWMQ.host,
        ConnDefWMQ.port, ConnDefWMQ.queue_manager, ConnDefWMQ.channel,
        ConnDefWMQ.cache_open_send_queues, ConnDefWMQ.cache_open_receive_queues,
        ConnDefWMQ.use_shared_connections, ConnDefWMQ.ssl, ConnDefWMQ.ssl_cipher_spec,
        ConnDefWMQ.ssl_key_repository, ConnDefWMQ.needs_mcd, ConnDefWMQ.max_chars_printed).\
        filter(Cluster.id==ConnDefWMQ.cluster_id).\
        filter(Cluster.id==cluster_id).\
        order_by(ConnDefWMQ.name)

def def_jms_wmq(session, cluster_id, id):
    """ A particular JMS WebSphere MQ definition
    """
    return _def_jms_wmq(session, cluster_id).\
        filter(ConnDefWMQ.id==id).\
        one()

@needs_columns
def def_jms_wmq_list(session, cluster_id, needs_columns=False):
    """ JMS WebSphere MQ connection definitions.
    """
    return _def_jms_wmq(session, cluster_id)

# ################################################################################################################################

def _out_amqp(session, cluster_id):
    return session.query(
        OutgoingAMQP.id, OutgoingAMQP.name, OutgoingAMQP.is_active,
        OutgoingAMQP.delivery_mode, OutgoingAMQP.priority, OutgoingAMQP.content_type,
        OutgoingAMQP.content_encoding, OutgoingAMQP.expiration, OutgoingAMQP.user_id,
        OutgoingAMQP.app_id, ConnDefAMQP.name.label('def_name'), OutgoingAMQP.def_id).\
        filter(OutgoingAMQP.def_id==ConnDefAMQP.id).\
        filter(ConnDefAMQP.id==OutgoingAMQP.def_id).\
        filter(Cluster.id==ConnDefAMQP.cluster_id).\
        filter(Cluster.id==cluster_id).\
        order_by(OutgoingAMQP.name)

def out_amqp(session, cluster_id, id):
    """ An outgoing AMQP connection.
    """
    return _out_amqp(session, cluster_id).\
        filter(OutgoingAMQP.id==id).\
        one()

@needs_columns
def out_amqp_list(session, cluster_id, needs_columns=False):
    """ Outgoing AMQP connections.
    """
    return _out_amqp(session, cluster_id)

# ################################################################################################################################

def _out_jms_wmq(session, cluster_id):
    return session.query(
        OutgoingWMQ.id, OutgoingWMQ.name, OutgoingWMQ.is_active,
        OutgoingWMQ.delivery_mode, OutgoingWMQ.priority, OutgoingWMQ.expiration,
        ConnDefWMQ.name.label('def_name'), OutgoingWMQ.def_id).\
        filter(OutgoingWMQ.def_id==ConnDefWMQ.id).\
        filter(ConnDefWMQ.id==OutgoingWMQ.def_id).\
        filter(Cluster.id==ConnDefWMQ.cluster_id).\
        filter(Cluster.id==cluster_id).\
        order_by(OutgoingWMQ.name)

def out_jms_wmq(session, cluster_id, id):
    """ An outgoing JMS WebSphere MQ connection (by ID).
    """
    return _out_jms_wmq(session, cluster_id).\
        filter(OutgoingWMQ.id==id).\
        one()

def out_jms_wmq_by_name(session, cluster_id, name):
    """ An outgoing JMS WebSphere MQ connection (by name).
    """
    return _out_jms_wmq(session, cluster_id).\
        filter(OutgoingWMQ.name==name).\
        first()

@needs_columns
def out_jms_wmq_list(session, cluster_id, needs_columns=False):
    """ Outgoing JMS WebSphere MQ connections.
    """
    return _out_jms_wmq(session, cluster_id)

# ################################################################################################################################

def _channel_amqp(session, cluster_id):
    return session.query(
        ChannelAMQP.id, ChannelAMQP.name, ChannelAMQP.is_active,
        ChannelAMQP.queue, ChannelAMQP.consumer_tag_prefix,
        ConnDefAMQP.name.label('def_name'), ChannelAMQP.def_id,
        ChannelAMQP.data_format,
        Service.name.label('service_name'),
        Service.impl_name.label('service_impl_name')).\
        filter(ChannelAMQP.def_id==ConnDefAMQP.id).\
        filter(ChannelAMQP.service_id==Service.id).\
        filter(Cluster.id==ConnDefAMQP.cluster_id).\
        filter(Cluster.id==cluster_id).\
        order_by(ChannelAMQP.name)

def channel_amqp(session, cluster_id, id):
    """ A particular AMQP channel.
    """
    return _channel_amqp(session, cluster_id).\
        filter(ChannelAMQP.id==id).\
        one()

@needs_columns
def channel_amqp_list(session, cluster_id, needs_columns=False):
    """ AMQP channels.
    """
    return _channel_amqp(session, cluster_id)

# ################################################################################################################################

def _channel_jms_wmq(session, cluster_id):
    return session.query(
        ChannelWMQ.id, ChannelWMQ.name, ChannelWMQ.is_active,
        ChannelWMQ.queue, ConnDefWMQ.name.label('def_name'), ChannelWMQ.def_id,
        ChannelWMQ.data_format, Service.name.label('service_name'),
        Service.impl_name.label('service_impl_name')).\
        filter(ChannelWMQ.def_id==ConnDefWMQ.id).\
        filter(ChannelWMQ.service_id==Service.id).\
        filter(Cluster.id==ConnDefWMQ.cluster_id).\
        filter(Cluster.id==cluster_id).\
        order_by(ChannelWMQ.name)

def channel_jms_wmq(session, cluster_id, id):
    """ A particular JMS WebSphere MQ channel.
    """
    return _channel_jms_wmq(session, cluster_id).\
        filter(ChannelWMQ.id==id).\
        one()

@needs_columns
def channel_jms_wmq_list(session, cluster_id, needs_columns=False):
    """ JMS WebSphere MQ channels.
    """
    return _channel_jms_wmq(session, cluster_id)

# ################################################################################################################################

def _out_zmq(session, cluster_id):
    return session.query(
        OutgoingZMQ.id, OutgoingZMQ.name, OutgoingZMQ.is_active,
        OutgoingZMQ.address, OutgoingZMQ.socket_type).\
        filter(Cluster.id==OutgoingZMQ.cluster_id).\
        filter(Cluster.id==cluster_id).\
        order_by(OutgoingZMQ.name)

def out_zmq(session, cluster_id, id):
    """ An outgoing ZeroMQ connection.
    """
    return _out_zmq(session, cluster_id).\
        filter(OutgoingZMQ.id==id).\
        one()

@needs_columns
def out_zmq_list(session, cluster_id, needs_columns=False):
    """ Outgoing ZeroMQ connections.
    """
    return _out_zmq(session, cluster_id)

# ################################################################################################################################

def _channel_zmq(session, cluster_id):
    return session.query(
        ChannelZMQ.id, ChannelZMQ.name, ChannelZMQ.is_active,
        ChannelZMQ.address, ChannelZMQ.socket_type, ChannelZMQ.sub_key, ChannelZMQ.data_format,
        Service.name.label('service_name'), Service.impl_name.label('service_impl_name')).\
        filter(Service.id==ChannelZMQ.service_id).\
        filter(Cluster.id==ChannelZMQ.cluster_id).\
        filter(Cluster.id==cluster_id).\
        order_by(ChannelZMQ.name)

def channel_zmq(session, cluster_id, id):
    """ An incoming ZeroMQ connection.
    """
    return _channel_zmq(session, cluster_id).\
        filter(ChannelZMQ.id==id).\
        one()

@needs_columns
def channel_zmq_list(session, cluster_id, needs_columns=False):
    """ Incoming ZeroMQ connections.
    """
    return _channel_zmq(session, cluster_id)

# ################################################################################################################################

def _http_soap(session, cluster_id):
    return session.query(
        HTTPSOAP.id, HTTPSOAP.name, HTTPSOAP.is_active,
        HTTPSOAP.is_internal, HTTPSOAP.transport, HTTPSOAP.host,
        HTTPSOAP.url_path, HTTPSOAP.method, HTTPSOAP.soap_action,
        HTTPSOAP.soap_version, HTTPSOAP.data_format, HTTPSOAP.security_id,
        HTTPSOAP.connection,
        case([(HTTPSOAP.ping_method != None, HTTPSOAP.ping_method)], else_=DEFAULT_HTTP_PING_METHOD).label('ping_method'), # noqa
        case([(HTTPSOAP.pool_size != None, HTTPSOAP.pool_size)], else_=DEFAULT_HTTP_POOL_SIZE).label('pool_size'),
        case([(HTTPSOAP.merge_url_params_req != None, HTTPSOAP.merge_url_params_req)], else_=True).label('merge_url_params_req'),
        case([(HTTPSOAP.url_params_pri != None, HTTPSOAP.url_params_pri)], else_=URL_PARAMS_PRIORITY.DEFAULT).label('url_params_pri'),
        case([(HTTPSOAP.params_pri != None, HTTPSOAP.params_pri)], else_=PARAMS_PRIORITY.DEFAULT).label('params_pri'),
        case([(
            HTTPSOAP.serialization_type != None, HTTPSOAP.serialization_type)], 
             else_=HTTP_SOAP_SERIALIZATION_TYPE.DEFAULT.id).label('serialization_type'),
        HTTPSOAP.audit_enabled,
        HTTPSOAP.audit_back_log,
        HTTPSOAP.audit_max_payload,
        HTTPSOAP.audit_repl_patt_type,
        HTTPSOAP.timeout,
        SecurityBase.sec_type,
        Service.name.label('service_name'),
        Service.id.label('service_id'),
        Service.impl_name.label('service_impl_name'),
        SecurityBase.name.label('security_name'),
        SecurityBase.username.label('username'),
        SecurityBase.password.label('password'),
        SecurityBase.password_type.label('password_type'),).\
        outerjoin(Service, Service.id==HTTPSOAP.service_id).\
        outerjoin(SecurityBase, HTTPSOAP.security_id==SecurityBase.id).\
        filter(Cluster.id==HTTPSOAP.cluster_id).\
        filter(Cluster.id==cluster_id).\
        order_by(HTTPSOAP.name)

def http_soap_security_list(session, cluster_id, connection=None):
    """ HTTP/SOAP security definitions.
    """
    q = _http_soap(session, cluster_id)

    if connection:
        q = q.filter(HTTPSOAP.connection==connection)

    return q

def http_soap(session, cluster_id, id):
    """ An HTTP/SOAP connection.
    """
    return _http_soap(session, cluster_id).\
        filter(HTTPSOAP.id==id).\
        one()

@needs_columns
def http_soap_list(session, cluster_id, connection=None, transport=None, return_internal=True, needs_columns=False):
    """ HTTP/SOAP connections, both channels and outgoing ones.
    """
    q = _http_soap(session, cluster_id)

    if connection:
        q = q.filter(HTTPSOAP.connection==connection)

    if transport:
        q = q.filter(HTTPSOAP.transport==transport)

    if not return_internal:
        q = q.filter(not_(HTTPSOAP.name.startswith('zato')))

    return q

# ################################################################################################################################

def _out_sql(session, cluster_id):
    return session.query(SQLConnectionPool).\
        filter(Cluster.id==SQLConnectionPool.cluster_id).\
        filter(Cluster.id==cluster_id).\
        order_by(SQLConnectionPool.name)

def out_sql(session, cluster_id, id):
    """ An outgoing SQL connection.
    """
    return _out_sql(session, cluster_id).\
        filter(SQLConnectionPool.id==id).\
        one()

@needs_columns
def out_sql_list(session, cluster_id, needs_columns=False):
    """ Outgoing SQL connections.
    """
    return _out_sql(session, cluster_id)

# ################################################################################################################################

def _out_ftp(session, cluster_id):
    return session.query(
        OutgoingFTP.id, OutgoingFTP.name, OutgoingFTP.is_active,
        OutgoingFTP.host, OutgoingFTP.port, OutgoingFTP.user, OutgoingFTP.password,
        OutgoingFTP.acct, OutgoingFTP.timeout, OutgoingFTP.dircache).\
        filter(Cluster.id==OutgoingFTP.cluster_id).\
        filter(Cluster.id==cluster_id).\
        order_by(OutgoingFTP.name)

def out_ftp(session, cluster_id, id):
    """ An outgoing FTP connection.
    """
    return _out_ftp(session, cluster_id).\
        filter(OutgoingFTP.id==id).\
        one()

@needs_columns
def out_ftp_list(session, cluster_id, needs_columns=False):
    """ Outgoing FTP connections.
    """
    return _out_ftp(session, cluster_id)

# ################################################################################################################################

def _service(session, cluster_id):
    return session.query(
        Service.id, Service.name, Service.is_active,
        Service.impl_name, Service.is_internal, Service.slow_threshold).\
        filter(Cluster.id==Service.cluster_id).\
        filter(Cluster.id==cluster_id).\
        order_by(Service.name)

def service(session, cluster_id, id):
    """ A service.
    """
    return _service(session, cluster_id).\
        filter(Service.id==id).\
        one()

@needs_columns
def service_list(session, cluster_id, return_internal=True, needs_columns=False):
    """ All services.
    """
    result = _service(session, cluster_id)
    if not return_internal:
        result = result.filter(not_(Service.name.startswith('zato')))
    return result

# ################################################################################################################################

def _delivery_definition(session, cluster_id):
    return session.query(DeliveryDefinitionBase).\
        filter(Cluster.id==DeliveryDefinitionBase.cluster_id).\
        filter(Cluster.id==cluster_id).\
        order_by(DeliveryDefinitionBase.name)

def delivery_definition_list(session, cluster_id, target_type=None):
    """ Returns a list of delivery definitions for a given target type.
    """
    def_list = _delivery_definition(session, cluster_id)

    if target_type:
        def_list = def_list.\
            filter(DeliveryDefinitionBase.target_type==target_type)

    return def_list

# ################################################################################################################################

def delivery_count_by_state(session, def_id):
    return session.query(Delivery.state, func.count(Delivery.state)).\
        filter(Delivery.definition_id==def_id).\
        group_by(Delivery.state)

def delivery_list(session, cluster_id, def_name, state, start=None, stop=None, needs_payload=False):
    columns = [
        DeliveryDefinitionBase.name.label('def_name'),
        DeliveryDefinitionBase.target_type,
        Delivery.task_id,
        Delivery.creation_time.label('creation_time_utc'),
        Delivery.last_used.label('last_used_utc'),
        Delivery.source_count,
        Delivery.target_count,
        Delivery.resubmit_count,
        Delivery.state,
        DeliveryDefinitionBase.retry_repeats,
        DeliveryDefinitionBase.check_after,
        DeliveryDefinitionBase.retry_seconds
    ]

    if needs_payload:
        columns.extend([DeliveryPayload.payload, Delivery.args, Delivery.kwargs])

    q = session.query(*columns).\
        filter(DeliveryDefinitionBase.id==Delivery.definition_id).\
        filter(DeliveryDefinitionBase.cluster_id==cluster_id).\
        filter(DeliveryDefinitionBase.name==def_name).\
        filter(Delivery.state.in_(state))

    if needs_payload:
        q = q.filter(DeliveryPayload.task_id==Delivery.task_id)

    if start:
        q = q.filter(Delivery.last_used >= start)

    if stop:
        q = q.filter(Delivery.last_used <= stop)

    q = q.order_by(Delivery.last_used.desc())

    return q

def delivery(session, task_id, target_def_class):
    return session.query(
        target_def_class.name.label('def_name'),
        target_def_class.target_type,
        Delivery.task_id,
        Delivery.creation_time.label('creation_time_utc'),
        Delivery.last_used.label('last_used_utc'),
        Delivery.source_count,
        Delivery.target_count,
        Delivery.resubmit_count,
        Delivery.state,
        target_def_class.retry_repeats,
        target_def_class.check_after,
        target_def_class.retry_seconds,
        DeliveryPayload.payload,
        Delivery.args,
        Delivery.kwargs,
        target_def_class.target,
        ).\
        filter(target_def_class.id==Delivery.definition_id).\
        filter(Delivery.task_id==task_id).\
        filter(DeliveryPayload.task_id==Delivery.task_id)

@needs_columns
def delivery_history_list(session, task_id, needs_columns=True):
    return session.query(
        DeliveryHistory.entry_type,
        DeliveryHistory.entry_time,
        DeliveryHistory.entry_ctx,
        DeliveryHistory.resubmit_count).\
        filter(DeliveryHistory.task_id==task_id).\
        order_by(DeliveryHistory.entry_time.desc())

# ################################################################################################################################

def _msg_list(class_, order_by, session, cluster_id, needs_columns=False):
    """ All the namespaces.
    """
    return session.query(
        class_.id, class_.name,
        class_.value).\
        filter(Cluster.id==cluster_id).\
        filter(Cluster.id==class_.cluster_id).\
        order_by(order_by)

@needs_columns
def namespace_list(session, cluster_id, needs_columns=False):
    """ All the namespaces.
    """
    return _msg_list(MsgNamespace, 'msg_ns.name', session, cluster_id, needs_columns)

@needs_columns
def xpath_list(session, cluster_id, needs_columns=False):
    """ All the XPaths.
    """
    return _msg_list(XPath, 'msg_xpath.name', session, cluster_id, needs_columns)

@needs_columns
def json_pointer_list(session, cluster_id, needs_columns=False):
    """ All the JSON Pointers.
    """
    return _msg_list(JSONPointer, 'msg_json_pointer.name', session, cluster_id, needs_columns)

# ################################################################################################################################

def _http_soap_audit(session, cluster_id, conn_id=None, start=None, stop=None, query=None, id=None, needs_req_payload=False):
    columns = [
        HTTSOAPAudit.id,
        HTTSOAPAudit.name.label('conn_name'),
        HTTSOAPAudit.cid,
        HTTSOAPAudit.transport,
        HTTSOAPAudit.connection,
        HTTSOAPAudit.req_time.label('req_time_utc'),
        HTTSOAPAudit.resp_time.label('resp_time_utc'),
        HTTSOAPAudit.user_token,
        HTTSOAPAudit.invoke_ok,
        HTTSOAPAudit.auth_ok,
        HTTSOAPAudit.remote_addr,
    ]

    if needs_req_payload:
        columns.extend([
            HTTSOAPAudit.req_headers, HTTSOAPAudit.req_payload, HTTSOAPAudit.resp_headers, HTTSOAPAudit.resp_payload
        ])

    q = session.query(*columns)
    
    if query:
        query = '%{}%'.format(query)
        q = q.filter(
            HTTSOAPAudit.cid.ilike(query) | \
            HTTSOAPAudit.req_headers.ilike(query) | HTTSOAPAudit.req_payload.ilike(query) | \
            HTTSOAPAudit.resp_headers.ilike(query) | HTTSOAPAudit.resp_payload.ilike(query)
        )

    if id:
        q = q.filter(HTTSOAPAudit.id == id)

    if conn_id:
        q = q.filter(HTTSOAPAudit.conn_id == conn_id)

    if start:
        q = q.filter(HTTSOAPAudit.req_time >= start)

    if stop:
        q = q.filter(HTTSOAPAudit.req_time <= start)

    q = q.order_by(HTTSOAPAudit.req_time.desc())

    return q

def http_soap_audit_item_list(session, cluster_id, conn_id, start, stop, query, needs_req_payload):
    return _http_soap_audit(session, cluster_id, conn_id, start, stop, query)

def http_soap_audit_item(session, cluster_id, id):
    return _http_soap_audit(session, cluster_id, id=id, needs_req_payload=True)

# ################################################################################################################################

def _cloud_openstack_swift(session, cluster_id):
    return session.query(OpenStackSwift).\
        filter(Cluster.id==cluster_id).\
        filter(Cluster.id==OpenStackSwift.cluster_id).\
        order_by(OpenStackSwift.name)

def cloud_openstack_swift(session, cluster_id, id):
    """ An OpenStack Swift connection.
    """
    return _cloud_openstack_swift(session, cluster_id).\
        filter(OpenStackSwift.id==id).\
        one()

@needs_columns
def cloud_openstack_swift_list(session, cluster_id, needs_columns=False):
    """ OpenStack Swift connections.
    """
    return _cloud_openstack_swift(session, cluster_id)

# ################################################################################################################################

def _cloud_aws_s3(session, cluster_id):
    return session.query(
        AWSS3.id, AWSS3.name, AWSS3.is_active, AWSS3.pool_size, AWSS3.address, AWSS3.debug_level, AWSS3.suppr_cons_slashes,
        AWSS3.content_type, AWSS3.metadata_, AWSS3.security_id, AWSS3.bucket, AWSS3.encrypt_at_rest, AWSS3.storage_class,
        SecurityBase.username, SecurityBase.password).\
        filter(Cluster.id==cluster_id).\
        filter(AWSS3.security_id==SecurityBase.id).\
        order_by(AWSS3.name)

def cloud_aws_s3(session, cluster_id, id):
    """ An AWS S3 connection.
    """
    return _cloud_aws_s3(session, cluster_id).\
        filter(AWSS3.id==id).\
        one()

@needs_columns
def cloud_aws_s3_list(session, cluster_id, needs_columns=False):
    """ AWS S3 connections.
    """
    return _cloud_aws_s3(session, cluster_id)

# ################################################################################################################################

def _pubsub_topic(session, cluster_id):
    return session.query(PubSubTopic.id, PubSubTopic.name, PubSubTopic.is_active, PubSubTopic.max_depth).\
        filter(Cluster.id==PubSubTopic.cluster_id).\
        filter(Cluster.id==cluster_id).\
        order_by(PubSubTopic.name)

def pubsub_topic(session, cluster_id, id):
    """ A pub/sub topic.
    """
    return _pubsub_topic(session, cluster_id).\
        filter(PubSubTopic.id==id).\
        one()

@needs_columns
def pubsub_topic_list(session, cluster_id, needs_columns=False):
    """ All pub/sub topics.
    """
    return _pubsub_topic(session, cluster_id)

def pubsub_default_client(session, cluster_id, name):
    """ Returns a client ID of a given name used internally for pub/sub.
    """
    return session.query(HTTPBasicAuth.id, HTTPBasicAuth.name).\
        filter(Cluster.id==cluster_id).\
        filter(Cluster.id==HTTPBasicAuth.cluster_id).\
        filter(HTTPBasicAuth.name==name).\
        first()

# ################################################################################################################################

def _pubsub_producer(session, cluster_id, needs_columns=False):
    return session.query(
        PubSubProducer.id,
        PubSubProducer.is_active,
        SecurityBase.id.label('client_id'),
        SecurityBase.name,
        SecurityBase.sec_type,
        PubSubTopic.name.label('topic_name')).\
        filter(Cluster.id==cluster_id).\
        filter(PubSubProducer.topic_id==PubSubTopic.id).\
        filter(PubSubProducer.cluster_id==Cluster.id).\
        filter(PubSubProducer.sec_def_id==SecurityBase.id).\
        order_by(SecurityBase.sec_type, SecurityBase.name)

@needs_columns
def pubsub_producer_list(session, cluster_id, topic_name, needs_columns=False):
    """ All pub/sub producers.
    """
    response = _pubsub_producer(session, cluster_id, needs_columns)
    if topic_name:
        response = response.filter(PubSubTopic.name==topic_name)
    return response

# ################################################################################################################################

def _pubsub_consumer(session, cluster_id, needs_columns=False):
    return session.query(
        PubSubConsumer.id,
        PubSubConsumer.is_active,
        PubSubConsumer.max_backlog,
        PubSubConsumer.sub_key,
        PubSubConsumer.delivery_mode,
        PubSubConsumer.callback_id,
        PubSubConsumer.callback_type,
        HTTPSOAP.name.label('callback_name'),
        HTTPSOAP.soap_version,
        SecurityBase.id.label('client_id'),
        SecurityBase.name,
        SecurityBase.sec_type,
        PubSubTopic.name.label('topic_name')).\
        filter(Cluster.id==cluster_id).\
        filter(PubSubConsumer.callback_id==HTTPSOAP.id).\
        filter(PubSubConsumer.topic_id==PubSubTopic.id).\
        filter(PubSubConsumer.cluster_id==Cluster.id).\
        filter(PubSubConsumer.sec_def_id==SecurityBase.id).\
        order_by(SecurityBase.sec_type, SecurityBase.name)

@needs_columns
def pubsub_consumer_list(session, cluster_id, topic_name, needs_columns=False):
    """ All pub/sub consumers.
    """
    response = _pubsub_consumer(session, cluster_id, needs_columns)
    if topic_name:
        response = response.filter(PubSubTopic.name==topic_name)
    return response

# ################################################################################################################################

def _notif_cloud_openstack_swift(session, cluster_id):
    return session.query(NotifOSS.id, NotifOSS.name, NotifOSS.is_active, NotifOSS.notif_type, NotifOSS.def_id,
        NotifOSS.containers, NotifOSS.interval, NotifOSS.name_pattern, NotifOSS.name_pattern_neg,
        NotifOSS.get_data, NotifOSS.get_data_patt, NotifOSS.get_data_patt_neg, OpenStackSwift.name.label('def_name'),
        Service.name.label('service_name')).\
        filter(Cluster.id==cluster_id).\
        filter(Cluster.id==NotifOSS.cluster_id).\
        filter(NotifOSS.def_id==OpenStackSwift.id).\
        filter(NotifOSS.service_id==Service.id).\
        order_by(NotifOSS.name)

def notif_cloud_openstack_swift(session, cluster_id, id):
    """ An OpenStack Swift notification definition.
    """
    return _notif_cloud_openstack_swift(session, cluster_id).\
        filter(NotifOSS.id==id).\
        one()

@needs_columns
def notif_cloud_openstack_swift_list(session, cluster_id, needs_columns=False):
    """ OpenStack Swift connection definitions.
    """
    return _notif_cloud_openstack_swift(session, cluster_id)

# ################################################################################################################################

def _server(session, cluster_id):
    return session.query(
        Server.id, Server.name, Server.bind_host, Server.bind_port, Server.last_join_status, Server.last_join_mod_date,
        Server.last_join_mod_by, Server.up_status, Server.up_mod_date, Cluster.name.label('cluster_name')).\
        filter(Cluster.id==Server.cluster_id).\
        filter(Cluster.id==cluster_id).\
        order_by(Server.name)

@needs_columns
def server_list(session, cluster_id, needs_columns=False):
    """ All the servers defined on a cluster.
    """
    return _server(session, cluster_id)

# ################################################################################################################################
########NEW FILE########
__FILENAME__ = util
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

# stdlib
from logging import getLogger

# Zato
from zato.common import engine_def, engine_def_sqlite, ZATO_NOT_GIVEN

logger = getLogger(__name__)

django_sa_mappings = {
    'NAME': 'sqlite_path',
    'HOST': 'host',
    'PORT': 'port',
    'USER': 'username',
    'PASSWORD': 'password',
    'odb_type': 'engine',
    'db_type': 'engine',
}

cli_sa_mappings = {
    'odb_db_name': 'db_name',
    'odb_host': 'host',
    'odb_port': 'port',
    'odb_user': 'username',
    'odb_password': 'password',
    'odb_type': 'engine',
}

def get_engine_url(args):
    attrs = {}
    is_sqlite = False
    is_django = 'NAME' in args
    has_get = getattr(args, 'get', False)

    odb_type = getattr(args, 'odb_type', None)
    if odb_type:
        is_sqlite = odb_type == 'sqlite'
    else:
        is_sqlite = args.get('engine') == 'sqlite' or args.get('db_type') == 'sqlite'

    names = ('engine', 'username', 'password', 'host', 'port', 'name', 'db_name', 'db_type', 'sqlite_path', 'odb_type',
             'odb_user', 'odb_password', 'odb_host', 'odb_port', 'odb_db_name', 'odb_type', 'ENGINE', 'NAME', 'HOST', 'USER',
             'PASSWORD', 'PORT')

    for name in names:
        if has_get:
            attrs[name] = args.get(name, '')
        else:
            attrs[name] = getattr(args, name, '')

    # Re-map Django params into SQLAlchemy params
    if is_django:
        for name in django_sa_mappings:
            value = attrs.get(name, ZATO_NOT_GIVEN)
            if value != ZATO_NOT_GIVEN:
                if not value and (name in 'db_type', 'odb_type'):
                    continue
                attrs[django_sa_mappings[name]] = value

    # Zato CLI to SQLAlchemy
    if not attrs.get('engine'):
        for name in cli_sa_mappings:
            value = attrs.get(name, ZATO_NOT_GIVEN)
            if value != ZATO_NOT_GIVEN:
                attrs[cli_sa_mappings[name]] = value

    # Re-map server ODB params into SQLAlchemy params
    if attrs['engine'] == 'sqlite':
        db_name = attrs.get('db_name')
        sqlite_path = attrs.get('sqlite_path')

        if db_name:
            attrs['sqlite_path'] = db_name

        if sqlite_path:
            attrs['db_name'] = sqlite_path

    return (engine_def_sqlite if is_sqlite else engine_def).format(**attrs)

########NEW FILE########
__FILENAME__ = lua
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

lua_publish = """

   local id_key = KEYS[1]
   local msg_values = KEYS[2]
   local msg_metadata_key = KEYS[3]
   local msg_expire_at = KEYS[4]
   local last_pub_time_key = KEYS[5]
   local last_seen_producer_key = KEYS[6]

   local score = ARGV[1]
   local msg_id = ARGV[2]
   local expire_at = ARGV[3]
   local msg_value = ARGV[4]
   local msg_metadata = ARGV[5]
   local topic_name = ARGV[6]
   local utc_now = ARGV[7]
   local client_id = ARGV[8]

   redis.pcall('zadd', id_key, score, msg_id)
   redis.pcall('hset', msg_values, msg_id, msg_value)
   redis.pcall('hset', msg_metadata_key, msg_id, msg_metadata)
   redis.pcall('hset', msg_expire_at, msg_id, expire_at)
   redis.pcall('hset', last_pub_time_key, topic_name, utc_now)
   redis.pcall('hset', last_seen_producer_key, client_id, utc_now)
"""

lua_move_to_target_queues = """

    -- A function to copy Redis keys we operate over to a table which skips the first one, the source queue.
    local function get_target_queues(keys)
        local target_queues = {}
        if #keys == 4 then
          target_queues = {keys[4]}
        else
            for idx = 1, #KEYS do
                -- Note - the whole point is that we're skipping the first few items which are not target queues
                target_queues[idx] = KEYS[idx+3]
            end
        end
        return target_queues
    end

    local source_queue = KEYS[1]
    local backlog_full = KEYS[2]
    local unack_counter = KEYS[3]

    local is_fifo = tonumber(ARGV[1])
    local max_depth = tonumber(ARGV[2])
    local zset_command
    local moved = {}

    if is_fifo then
        zset_command = 'zrevrange'
    else
        zset_command = 'zrange'
    end

    local target_queues = get_target_queues(KEYS)
    local ids = redis.pcall(zset_command, source_queue, 0, max_depth)

    for queue_idx, target_queue in ipairs(target_queues) do
        for id_idx, id in ipairs(ids) do
            redis.call('lpush', target_queue, id)
            redis.pcall('hincrby', unack_counter, id, 1)
            table.insert(moved, {target_queue, id})
        end
    end

    for id_idx, id in ipairs(ids) do
        redis.pcall('zrem', source_queue, id)
    end

    return moved
    """

lua_get_from_cons_queue = """

   local cons_queue = KEYS[1]
   local cons_in_flight_ids = KEYS[2]
   local cons_in_flight_data = KEYS[3]
   local last_seen_consumer_key = KEYS[4]
   local msg_metadata_key = KEYS[5]
   local msg_key = KEYS[6]

   local max_batch_size = tonumber(ARGV[1])
   local utc_now = ARGV[2]
   local client_id = ARGV[3]

   local ids = redis.pcall('lrange', cons_queue, 0, max_batch_size)
   local values = {}

   redis.pcall('hset', last_seen_consumer_key, client_id, utc_now)

   -- It may well be the case that there are no messages for this client
   if #ids > 0 then
       --local values = redis.pcall('hmget', msg_key, unpack(ids))

       for id_idx, id in ipairs(ids) do

           local msg = redis.pcall('hmget', msg_key, id)
           local metadata = redis.pcall('hmget', msg_metadata_key, id)
           table.insert(values, {msg, metadata})

           redis.pcall('sadd', cons_in_flight_ids, id)
           redis.pcall('hset', cons_in_flight_data, id, utc_now)
           redis.pcall('lrem', cons_queue, 0, id)
       end
    end

    return values

"""

lua_reject = """

   local cons_queue = KEYS[1]
   local cons_in_flight_ids = KEYS[2]
   local cons_in_flight_data = KEYS[3]
   local ids = ARGV

   redis.pcall('hdel', cons_in_flight_data, unpack(ids))

    for id_idx, id in ipairs(ids) do
        redis.pcall('srem', cons_in_flight_ids, id)
        redis.pcall('lpush', cons_queue, id)
    end
"""

lua_ack_delete = """

    -- A function to copy IDs to a separate table out of ARGV
    local function get_ids(argv)
        local ids = {}
        for idx = 1, #argv do
            ids[idx] = argv[idx+1]
        end
        return ids
    end

    local cons_in_flight_ids = KEYS[1]
    local cons_in_flight_data = KEYS[2]
    local unack_counter = KEYS[3]
    local msg_values = KEYS[4]
    local msg_expire_at = KEYS[5]
    local msg_metadata_key = KEYS[6]
    local cons_queue = KEYS[7]
 
    local is_delete = ARGV[1]
    local ids = get_ids(ARGV)
    local unack_id_count = 0

    for id_idx, id in ipairs(ids) do

        -- We're deleting a message from a consumer's queue, not merely ack'ing it.
        if is_delete == '1' then
            redis.pcall('lrem', cons_queue, 0, id)
        end

        redis.pcall('srem', cons_in_flight_ids, id)
        redis.pcall('hdel', cons_in_flight_data, id)
        unack_id_count = redis.pcall('hincrby', unack_counter, id, -1)

        -- It was the last confirmation we were waiting for so let's delete all traces of the message.

        if unack_id_count == 0 then
            redis.pcall('hdel', unack_counter, id)
            redis.pcall('hdel', msg_values, id)
            redis.pcall('hdel', msg_metadata_key, id)
            redis.pcall('hdel', msg_expire_at, id)
        end

    end
"""

lua_delete_expired = """
   local consumer_msg_ids = KEYS[1]
   local cons_in_flight_ids = KEYS[2]
   local msg_values = KEYS[3]
   local msg_expire_at = KEYS[4]
   local unack_counter = KEYS[5]

   local now_utc = tostring(ARGV[1])
   local expired = {}

   -- Grab a batch of IDs to check their expiration
   local ids = redis.pcall('lrange', consumer_msg_ids, 0, 500)

   for id_idx, id in ipairs(ids) do

       -- The message may be expired but the result other than 0 means it's still in flight - we don't do anything with these.
       -- It's possible they can block the whole consumer queue but in that case a user intervention will be needed.

       if redis.pcall('sismember', id, cons_in_flight_ids) == 0 then

           -- Ok, we know the message is not in-flight so grab the time it expires at and compare it with now.
           -- Note that we're using ISO-8601 dates in the format of 2014-02-16T02:51:24.013459 so we can always
           -- compare expiration times lexicographically.

           local expire_at = tostring(redis.pcall('hget', msg_expire_at, id))

           -- The message has indeed expired so we can safely delete every piece of information on it.
           if now_utc > expire_at then
               redis.pcall('lrem', consumer_msg_ids, 0, id)
               redis.pcall('hdel', msg_values, id)
               redis.pcall('hdel', msg_expire_at, id)
               redis.pcall('hdel', unack_counter, id)
               table.insert(expired, id)
           end
       end
   end

   return expired

"""

lua_get_message_list = """
    local source_ids_key = KEYS[1]
    local metadata_key = KEYS[2]

    local source_type = ARGV[1]
    local data = {}
    local redis_call = ''

    if source_type == 'topic' then
       redis_call = 'zrange'
    else
       redis_call = 'lrange'
    end

    local ids = redis.pcall(redis_call, source_ids_key, 0, -1)

    for id_idx, id in ipairs(ids) do
       table.insert(data, redis.pcall('hget', metadata_key, id))
    end

    return data
"""

lua_delete_from_topic = """
   local ids_key = KEYS[1]
   local msg_values = KEYS[2]
   local msg_metadata_key = KEYS[3]
   local msg_expire_at = KEYS[4]

   local has_consumers = ARGV[1]
   local msg_id = ARGV[2]

   local result = {has_consumers}

   if has_consumers == '0' then
       table.insert(result, 'has_consumers_false')
       table.insert(result, redis.pcall('zrem', ids_key, msg_id))
       table.insert(result, redis.pcall('hdel', msg_values, msg_id))
       table.insert(result, redis.pcall('hdel', msg_metadata_key, msg_id))
       table.insert(result, redis.pcall('hdel', msg_expire_at, msg_id))
   else
       table.insert(result, 'has_consumers_true')
       table.insert(result, redis.pcall('zrem', ids_key, msg_id))
   end

   return result

"""

lua_delete_from_consumer_queue = """
"""
########NEW FILE########
__FILENAME__ = repo
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging, os, socket

# Bazaar
import bzrlib
from bzrlib.branch import Branch
from bzrlib.bzrdir import BzrDir
from bzrlib.workingtree import WorkingTree

# Zato
from zato.common.util import get_current_user

logger = logging.getLogger(__name__)

class RepoManager(object):
    def __init__(self, repo_location='.'):
        self.repo_location = os.path.abspath(repo_location)

    def ensure_repo_consistency(self):
        """ Makes sure the self.repo_location directory is a Bazaar branch.
        The repo and Bazaar branch will be created if they don't already exist.
        Any unknown or modified files will be commited to the branch.
        Also, 'bzr whoami' will be set to the current user so that all commands
        can be traced back to an actual person (assuming everyone has their
        own logins).
        """

        try:
            BzrDir.open(self.repo_location)
        except bzrlib.errors.NotBranchError:
            logger.info('Location [{}] is not a Bazaar branch. Will turn it into one.'.format(self.repo_location))
            BzrDir.create_branch_convenience(self.repo_location)
            
        c = Branch.open(self.repo_location).get_config_stack()
        c.set('email', '{}@{}'.format(get_current_user(), socket.getfqdn()))

        self.tree = WorkingTree.open(self.repo_location)
        delta = self.tree.changes_from(self.tree.basis_tree(), want_unversioned=True)

        logger.debug('tree [{}]'.format(self.tree))
        logger.debug('delta [{}]'.format(delta))

        for file_info in delta.unversioned:
            logger.debug('unversioned [{}]'.format(file_info))
            file_name = file_info[0]
            self.tree.add(file_name)

        if delta.unversioned:
            self.tree.commit('Added new unversioned files')
        else:
            logger.debug('No unversioned files found')

        if delta.modified:
            self.tree.commit('Committed modified files')
        else:
            logger.debug('No modified files found')

########NEW FILE########
__FILENAME__ = test
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from datetime import datetime
from random import choice, randint, random
from unittest import TestCase
from uuid import uuid4

# anyjson
from anyjson import loads

# Bunch
from bunch import Bunch

# mock
from mock import MagicMock, Mock

# nose
from nose.tools import eq_

# SQLAlchemy
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

# Zato
from zato.common import CHANNEL, DATA_FORMAT, SIMPLE_IO
from zato.common.odb import model
from zato.common.util import new_cid

def rand_bool():
    return choice((True, False))

def rand_datetime():
    return datetime.utcnow().isoformat() # Random in the sense of not repeating

def rand_int(start=1, stop=100):
    return randint(start, stop)
    
def rand_float(start=1.0, stop=100.0):
    return float(rand_int(start, stop))

def rand_string(count=1):
    if count == 1:
        return 'a' + uuid4().hex
    else:
        return ['a' + uuid4().hex for x in range(count)]

def rand_object():
    return object()

def rand_date_utc():
    return datetime.utcnow() # Now is as random as any other date

class Expected(object):
    """ A container for the data a test expects the service to return.
    """
    def __init__(self):
        self.data = []
        
    def add(self, item):
        self.data.append(item)
        
    def get_data(self):
        if not self.data or len(self.data) > 1:
            return self.data
        else:
            return self.data[0]
        
class FakeBrokerClient(object):
    def publish(self, *args, **kwargs):
        raise NotImplementedError()

class FakeKVDB(object):

    class FakeConn(object):
        def __init__(self):
            self.setnx_args = None
            self.setnx_return_value = True
            self.expire_args = None
            self.delete_args = None
            
        def return_none(self, *ignored_args, **ignored_kwargs):
            return None
        
        get = hget = return_none
        
        def setnx(self, *args):
            self.setnx_args = args
            return self.setnx_return_value
        
        def expire(self, *args):
            self.expire_args = args
            
        def delete(self, args):
            self.delete_args = args
        
    def __init__(self):
        self.conn = self.FakeConn()
        
    def translate(self, *ignored_args, **ignored_kwargs):
        raise NotImplementedError()

class FakeServices(object):
    def __getitem__(self, ignored):
        return {'slow_threshold': 1234}
    
class FakeServiceStore(object):
    def __init__(self):
        self.services = FakeServices()
        
class FakeServer(object):
    """ A fake mock server used in test cases.
    """
    def __init__(self):
        self.kvdb = FakeKVDB()
        self.service_store = FakeServiceStore()
        self.fs_server_config = Bunch()
        self.fs_server_config.misc = Bunch()
        self.fs_server_config.misc.internal_services_may_be_deleted = False
        self.repo_location = rand_string()
        self.delivery_store = None
        self.user_config = Bunch()

class ForceTypeWrapper(object):
    """ Makes comparison between two ForceType elements use their names.
    """
    def __init__(self, value):
        self.value = value
        
    def __cmp__(self, other):
        return cmp(self.value.name, other.name)
        
class ServiceTestCase(TestCase):
    
    def invoke(self, class_, request_data, expected, mock_data={}, 
               channel=CHANNEL.HTTP_SOAP, job_type=None, data_format=DATA_FORMAT.JSON):
        """ Sets up a service's invocation environment, then invokes and returns
        an instance of the service.
        """
        instance = class_()
        worker_store = MagicMock()
        worker_store.worker_config = MagicMock
        worker_store.worker_config.outgoing_connections = MagicMock(return_value=(None, None, None))
        worker_store.worker_config.cloud_openstack_swift = MagicMock(return_value=None)
        worker_store.worker_config.cloud_aws_s3 = MagicMock(return_value=None)
        
        simple_io_config = {
            'int_parameters': SIMPLE_IO.INT_PARAMETERS.VALUES,
            'int_parameter_suffixes': SIMPLE_IO.INT_PARAMETERS.SUFFIXES,
            'bool_parameter_prefixes': SIMPLE_IO.BOOL_PARAMETERS.SUFFIXES,
        }
        
        class_.update(
            instance, channel, FakeServer(), None, worker_store, new_cid(), request_data, request_data,
            simple_io_config=simple_io_config, data_format=data_format, job_type=job_type)

        def get_data(self, *ignored_args, **ignored_kwargs):
            return expected.get_data()
            
        instance.get_data = get_data
        
        for attr_name, mock_path_data_list in mock_data.iteritems():
            setattr(instance, attr_name, Mock())
            attr = getattr(instance, attr_name)
            
            for mock_path_data in mock_path_data_list:
                for path, value in mock_path_data.iteritems():
                    splitted = path.split('.')
                    new_path = '.return_value.'.join(elem for elem in splitted) + '.return_value'
                    attr.configure_mock(**{new_path:value})
                    
        broker_client_publish = getattr(self, 'broker_client_publish', None)
        if broker_client_publish:
            instance.broker_client = FakeBrokerClient()
            instance.broker_client.publish = broker_client_publish

        instance.call_hooks('before')
        instance.handle()
        instance.call_hooks('after')

        instance.handle()
        
        return instance
    
    def _check_sio_request_input(self, instance, request_data):
        for k, v in request_data.iteritems():
            self.assertEquals(getattr(instance.request.input, k), v)

        sio_keys = set(getattr(instance.SimpleIO, 'input_required', []))
        sio_keys.update(set(getattr(instance.SimpleIO, 'input_optional', [])))
        given_keys = set(request_data.keys())
        
        diff = sio_keys ^ given_keys
        self.assertFalse(diff, 'There should be no difference between sio_keys {} and given_keys {}, diff {}'.format(
            sio_keys, given_keys, diff))
    
    def check_impl(self, service_class, request_data, response_data, response_elem, mock_data={}):

        expected_data = sorted(response_data.items())
        
        instance = self.invoke(service_class, request_data, None, mock_data)
        self._check_sio_request_input(instance, request_data)
        
        if response_data:
            if not isinstance(instance.response.payload, basestring):
                response = loads(instance.response.payload.getvalue())[response_elem] # Raises KeyError if 'response_elem' doesn't match
            else:
                response = loads(instance.response.payload)[response_elem]
                
            self.assertEqual(sorted(response.items()), expected_data)
    
    def check_impl_list(self, service_class, item_class, request_data, # noqa
            response_data, request_elem, response_elem, mock_data={}): # noqa
        
        expected_keys = response_data.keys()
        expected_data = tuple(response_data for x in range(rand_int(10)))
        expected = Expected()
        
        for datum in expected_data:
            item = item_class()
            for key in expected_keys:
                value = getattr(datum, key)
                setattr(item, key, value)
            expected.add(item)
            
        instance = self.invoke(service_class, request_data, expected, mock_data)
        response = loads(instance.response.payload.getvalue())[response_elem]
        
        for idx, item in enumerate(response):
            expected = expected_data[idx]
            given = Bunch(item)
            
            for key in expected_keys:
                given_value = getattr(given, key)
                expected_value = getattr(expected, key)
                eq_(given_value, expected_value)
                
        self._check_sio_request_input(instance, request_data)

    def wrap_force_type(self, elem):
        return ForceTypeWrapper(elem)

class ODBTestCase(TestCase):

    def setUp(self):
        self.engine = create_engine('sqlite:///:memory:')
        Session = sessionmaker(bind=self.engine)
        session = Session()
        model.Base.metadata.create_all(self.engine)
        
    def tearDown(self):
        model.Base.metadata.drop_all(self.engine)

########NEW FILE########
__FILENAME__ = util
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import copy, gc, inspect, json, linecache, logging, os, random, re, signal, threading, traceback, sys
from contextlib import closing
from cStringIO import StringIO
from datetime import datetime
from glob import glob
from hashlib import sha256
from importlib import import_module
from itertools import ifilter, izip, izip_longest, tee
from operator import itemgetter
from os import getuid
from os.path import abspath, isabs, join
from pprint import pprint as _pprint, PrettyPrinter
from pwd import getpwuid
from random import getrandbits
from socket import gethostname, getfqdn
from string import Template
from threading import current_thread
from traceback import format_exc

# packaging/Distutils2
try:
    from packaging import Config
    from packaging import Distribution
except ImportError:
    from distutils2.config import Config
    from distutils2.dist import Distribution

# anyjson
from anyjson import dumps, loads

# base32_crockford
from base32_crockford import encode as b32_crockford_encode

# Bunch
from bunch import Bunch, bunchify

# ConfigObj
from configobj import ConfigObj

# dateutil
from dateutil.parser import parse

# gevent
from gevent.greenlet import Greenlet
from gevent.hub import Hub
from gevent.socket import wait_read, wait_write

# lxml
from lxml import etree, objectify

# Paste
from paste.util.converters import asbool

# pip
from pip.download import is_archive_file, unpack_file_url

# psutil
import psutil

# psycopg2
import psycopg2
from psycopg2 import extensions

# pytz
import pytz

# Spring Python
from springpython.context import ApplicationContext
from springpython.remoting.http import CAValidatingHTTPSConnection
from springpython.remoting.xmlrpc import SSLClientTransport

# SQLAlchemy
from sqlalchemy.exc import IntegrityError

# Texttable
from texttable import Texttable

# validate
from validate import is_boolean, is_integer, VdtTypeError

# Zato
from zato.agent.load_balancer.client import LoadBalancerAgentClient
from zato.common import DATA_FORMAT, engine_def, engine_def_sqlite, KVDB, MISC, NoDistributionFound, PASSWORD_SHADOW, \
     scheduler_date_time_format, soap_body_path, soap_body_xpath, TRACE1, ZatoException
from zato.common.crypto import CryptoManager
from zato.common.odb.model import IntervalBasedJob, Job, Service
from zato.common.odb.query import _service as _service

logger = logging.getLogger(__name__)

logging.addLevelName(TRACE1, "TRACE1")

_repr_template = Template('<$class_name at $mem_loc$attrs>')
_uncamelify_re = re.compile(r'((?<=[a-z])[A-Z]|(?<!\A)[A-Z](?=[a-z]))')

_epoch = datetime.utcfromtimestamp(0) # Start of UNIX epoch

random.seed()

################################################################################

def absolutize_path(base, path):
    """ Turns a path into an absolute path if it's relative to the base
    location. If the path is already an absolute path, it is returned as-is.
    """
    if isabs(path):
        return path

    return abspath(join(base, path))

def current_host():
    return gethostname() + '/' + getfqdn()

def pprint(obj):
    """ Pretty-print an object into a string buffer.
    """
    # Get dicts' items.
    if hasattr(obj, "items"):
        obj = sorted(obj.items())

    buf = StringIO()
    _pprint(obj, buf)

    value = buf.getvalue()
    buf.close()

    return value

def encrypt(data, priv_key, b64=True):
    """ Encrypt data using a public key derived from the private key.
    data - data to be encrypted
    priv_key - private key to use (as a PEM string)
    b64 - should the encrypted data be BASE64-encoded before being returned, defaults to True
    """

    cm = CryptoManager(priv_key=priv_key)
    cm.load_keys()

    return cm.encrypt(data, b64)

def decrypt(data, priv_key, b64=True):
    """ Decrypts data using the given private key.
    data - data to be encrypted
    priv_key - private key to use (as a PEM string)
    b64 - should the data be BASE64-decoded before being decrypted, defaults to True
    """

    cm = CryptoManager(priv_key=priv_key)
    cm.load_keys()

    return cm.decrypt(data, b64)

def get_executable():
    """ Returns the wrapper buildout uses for executing Zato commands. This has
    all the dependencies added to PYTHONPATH.
    """
    return os.path.join(os.path.dirname(sys.executable), 'py')

def get_zato_command():
    """ Returns the full path to the 'zato' command' in a buildout environment.
    """
    return os.path.join(os.path.dirname(sys.executable), 'zato')

# Based on
# http://stackoverflow.com/questions/384076/how-can-i-make-the-python-logging-output-to-be-colored
class ColorFormatter(logging.Formatter):

    # TODO: Make it all configurable

    BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE = range(8)

    RESET_SEQ = "\033[0m"
    COLOR_SEQ = "\033[1;%dm"
    BOLD_SEQ = "\033[1m"

    COLORS = {
      'WARNING': YELLOW,
      'INFO': WHITE,
      'DEBUG': BLUE,
      'CRITICAL': YELLOW,
      'ERROR': RED,
      'TRACE1': YELLOW
    }

    def __init__(self, log_format, date_format, use_color=True):
        # Note that date_format is ignored.
        msg = self.formatter_msg(log_format, use_color)
        logging.Formatter.__init__(self, msg)
        self.use_color = use_color

    def formatter_msg(self, msg, use_color=True):
        if use_color:
            msg = msg.replace("$RESET", self.RESET_SEQ).replace("$BOLD", self.BOLD_SEQ)
        else:
            msg = msg.replace("$RESET", "").replace("$BOLD", "")
        return msg

    def format(self, record):
        levelname = record.levelname
        if self.use_color and levelname in self.COLORS:
            fore_color = 30 + self.COLORS[levelname]
            levelname_color = self.COLOR_SEQ % fore_color + levelname + self.RESET_SEQ
            record.levelname = levelname_color

        return logging.Formatter.format(self, record)

def object_attrs(_object, ignore_double_underscore, to_avoid_list, sort):
    attrs = dir(_object)

    if ignore_double_underscore:
        attrs = ifilter(lambda elem: not elem.startswith("__"), attrs)

    _to_avoid_list = getattr(_object, to_avoid_list, None) # Don't swallow exceptions
    if _to_avoid_list is not None:
        attrs = ifilter(lambda elem: not elem in _to_avoid_list, attrs)

    if sort:
        attrs = sorted(attrs)

    return attrs

def make_repr(_object, ignore_double_underscore=True, to_avoid_list='repr_to_avoid', sort=True):
    """ Makes a nice string representation of an object, suitable for logging purposes.
    """
    attrs = object_attrs(_object, ignore_double_underscore, to_avoid_list, sort)
    buff = StringIO()

    for attr in attrs:
        attr_obj = getattr(_object, attr)
        if not callable(attr_obj):
            buff.write(' ')
            buff.write('%s:`%r`' % (attr, attr_obj))

    out = _repr_template.safe_substitute(
        class_name=_object.__class__.__name__, mem_loc=hex(id(_object)), attrs=buff.getvalue())
    buff.close()

    return out

def to_form(_object):
    """ Reads public attributes of an object and creates a dictionary out of it;
    handy for providing initial data to a Django form which isn't backed by
    a true Django model.
    """
    out = {}
    attrs = object_attrs(_object, True, "repr_to_avoid", False)
    for attr in attrs:
        out[attr] = getattr(_object, attr)

    return out

def get_lb_client(lb_host, lb_agent_port, ssl_ca_certs, ssl_key_file, ssl_cert_file, timeout):
    """ Returns an SSL XML-RPC client to the load-balancer.
    """
    agent_uri = "https://{host}:{port}/RPC2".format(host=lb_host, port=lb_agent_port)

    # See the 'Problems with XML-RPC over SSL' thread for details
    # https://lists.springsource.com/archives/springpython-users/2011-June/000480.html
    if sys.version_info >= (2, 7):
        class Python27CompatTransport(SSLClientTransport):
            def make_connection(self, host):
                return CAValidatingHTTPSConnection(
                    host, strict=self.strict, ca_certs=self.ca_certs,
                    keyfile=self.keyfile, certfile=self.certfile, cert_reqs=self.cert_reqs,
                    ssl_version=self.ssl_version, timeout=self.timeout)
        transport = Python27CompatTransport
    else:
        transport = None

    return LoadBalancerAgentClient(
        agent_uri, ssl_ca_certs, ssl_key_file, ssl_cert_file, transport=transport, timeout=timeout)

def tech_account_password(password_clear, salt):
    return sha256(password_clear+ ':' + salt).hexdigest()

def new_cid():
    """ Returns a new 128-bit correlation identifier. It's *not* safe to use the ID
    for any cryptographical purposes, it's only meant to be used as a conveniently
    formatted ticket attached to each of the requests processed by Zato servers.
    Changed in 2.0: The number is now 28 characters long not 40, like in previous versions.
    """
    # The number below (27) needs to be kept in sync with zato.common.log_message.CID_LENGTH.
    # There is nothing special in the 'K' prefix, it's just so that a CID always
    # begins with a letter and 'K' seems like something
    # that can't be taken for some other ASCII letter (e.g. is it Z or 2 etc.)
    return 'K{0:0>27}'.format(b32_crockford_encode(getrandbits(128)))

def get_config(repo_location, config_name, bunchified=True):
    """ Returns the configuration object. Will load additional user-defined config files,
    if any are available at all.
    """
    conf = ConfigObj(os.path.join(repo_location, config_name))
    conf = bunchify(conf) if bunchified else conf
    conf.user_config_items = {}

    # user_config is new in 2.0
    user_config = conf.get('user_config')
    if user_config:
        for name, path in user_config.items():
            if not isabs(path):
                path = os.path.expanduser(path)
            if not isabs(path):
                path = os.path.normpath(os.path.join(repo_location, path))
            if not os.path.exists(path):
                logger.warn('User config not found `%s`, name:`%s`', path, name)
            else:
                user_conf = ConfigObj(path)
                user_conf = bunchify(user_conf) if bunchified else user_conf
                conf.user_config_items[name] = user_conf

    return conf

def _get_ioc_config(location, config_class):
    """ Instantiates an Inversion of Control container from the given location
    if the location exists at all.
    """
    stat = os.stat(location)
    if stat.st_size:
        config = config_class(location)
    else:
        config = None

    return config

def get_app_context(config):
    """ Returns the Zato's Inversion of Control application context.
    """
    ctx_class_path = config['spring']['context_class']
    ctx_class_path = ctx_class_path.split('.')
    mod_name, class_name = '.'.join(ctx_class_path[:-1]), ctx_class_path[-1:][0]
    mod = import_module(mod_name)
    class_ = getattr(mod, class_name)()
    return ApplicationContext(class_)

def get_crypto_manager(repo_location, app_context, config, load_keys=True):
    """ Returns a tool for crypto manipulations.
    """
    crypto_manager = app_context.get_object('crypto_manager')

    priv_key_location = config['crypto']['priv_key_location']
    cert_location = config['crypto']['cert_location']
    ca_certs_location = config['crypto']['ca_certs_location']

    priv_key_location = absolutize_path(repo_location, priv_key_location)
    cert_location = absolutize_path(repo_location, cert_location)
    ca_certs_location = absolutize_path(repo_location, ca_certs_location)

    crypto_manager.priv_key_location = priv_key_location
    crypto_manager.cert_location = cert_location
    crypto_manager.ca_certs_location = ca_certs_location

    if load_keys:
        crypto_manager.load_keys()

    return crypto_manager

def get_current_user():
    return getpwuid(getuid()).pw_name

def service_name_from_impl(impl_name):
    """ Turns a Zato internal service's implementation name into a shorter
    service name
    """
    return impl_name.replace('server.service.internal.', '')

def deployment_info(method, object_, timestamp, fs_location, remote_host='', remote_user=''):
    """ Returns a JSON document containing information who deployed a service
    onto a server, where from and when it was.
    """
    return {
        'method': method,
        'object': object_,
        'timestamp': timestamp,
        'fs_location':fs_location,
        'remote_host': remote_host,
        'remote_user': remote_user,
        'current_host': current_host(),
        'current_user': get_current_user(),
    }

def get_body_payload(body):
    body_children_count = body[0].countchildren()

    if body_children_count == 0:
        body_payload = None
    elif body_children_count == 1:
        body_payload = body[0].getchildren()[0]
    else:
        body_payload = body[0].getchildren()

    return body_payload

def payload_from_request(cid, request, data_format, transport):
    """ Converts a raw request to a payload suitable for usage with SimpleIO.
    """
    if request is not None:
        if data_format == DATA_FORMAT.XML:
            if transport == 'soap':
                if isinstance(request, objectify.ObjectifiedElement):
                    soap = request
                else:
                    soap = objectify.fromstring(request)
                body = soap_body_xpath(soap)
                if not body:
                    raise ZatoException(cid, 'Client did not send the [{}] element'.format(soap_body_path))
                payload = get_body_payload(body)
            else:
                if isinstance(request, objectify.ObjectifiedElement):
                    payload = request
                else:
                    payload = objectify.fromstring(request)
        elif data_format == DATA_FORMAT.JSON:
            if not request:
                return ''
            if isinstance(request, basestring):
                payload = loads(request)
            else:
                payload = request
        else:
            payload = request
    else:
        payload = request

    return payload

def is_python_file(name):
    """ Is it a Python file we can import Zato services from?
    """
    for suffix in('py', 'pyw'):
        if name.endswith(suffix):
            return True

def fs_safe_now():
    """ Returns a UTC timestamp with any characters unsafe for filesystem names
    removed.
    """
    return re.sub('[-:. ]', '_', str(datetime.utcnow()))

class _DummyLink(object):
    """ A dummy class for staying consistent with pip's API in certain places
    below.
    """
    def __init__(self, url):
        self.url = url

def decompress(archive, dir_name):
    """ Decompresses an archive into a directory, the directory must already exist.
    """
    unpack_file_url(_DummyLink('file:' + archive), dir_name)

def visit_py_source(dir_name):
    for pattern in('*.py', '*.pyw'):
        glob_path = os.path.join(dir_name, pattern)
        for py_path in sorted(glob(glob_path)):
            yield py_path

def visit_py_source_from_distribution(dir_name):
    """ Yields all the Python source modules from a Distutils2 distribution.
    """
    path = os.path.join(dir_name, 'setup.cfg')
    if not os.path.exists(path):
        msg = "Could not find setup.cfg in [{}], path:[{}] doesn't exist".format(dir_name, path)
        logger.debug(msg)
        raise NoDistributionFound(path)

    dist = Distribution()
    config = Config(dist)
    config.parse_config_files([path])

    logger.debug('dist.packages:[%s]' % dist.packages)

    for package in dist.packages:
        package_dir = os.path.abspath(os.path.join(dir_name, package.replace('.', os.path.sep)))
        yield visit_py_source(package_dir)

def _os_remove(path):
    """ A helper function so it's easier to mock it in unittests.
    """
    return os.remove(path)

def hot_deploy(parallel_server, file_name, path, delete_path=True):
    """ Hot-deploys a package if it looks like a Python module or an archive
    which might contain a Distutils2 distribution.
    """
    if is_python_file(file_name) or is_archive_file(file_name):

        logger.debug('About to hot-deploy [{}]'.format(path))
        now = datetime.utcnow()
        di = dumps(deployment_info('hot-deploy', file_name, now.isoformat(), path))

        # Insert the package into the DB ..
        package_id = parallel_server.odb.hot_deploy(
            now, di, file_name, open(path, 'rb').read(), parallel_server.id)

        # .. and notify all the servers they're to pick up a delivery
        parallel_server.notify_new_package(package_id)

        if delete_path:
            _os_remove(path)

        return True

    else:
        logger.warn('Ignoring {}'.format(path))


# As taken from http://wiki.python.org/moin/SortingListsOfDictionaries
def multikeysort(items, columns):
    comparers = [((itemgetter(col[1:].strip()), -1) if col.startswith('-') else (itemgetter(col.strip()), 1)) for col in columns]

    def comparer(left, right):
        for fn, mult in comparers:
            result = cmp(fn(left), fn(right))
            if result:
                return mult * result
        else:
            return 0
    return sorted(items, cmp=comparer)

# From http://docs.python.org/release/2.7/library/itertools.html#recipes
def grouper(n, iterable, fillvalue=None):
    "grouper(3, 'ABCDEFG', 'x') --> ABC DEF Gxx"
    args = [iter(iterable)] * n
    return izip_longest(fillvalue=fillvalue, *args)

def translation_name(system1, key1, value1, system2, key2):
    return KVDB.SEPARATOR.join((KVDB.TRANSLATION, system1, key1, value1, system2, key2))

def dict_item_name(system, key, value):
    return KVDB.SEPARATOR.join((system, key, value))

# From http://docs.python.org/release/2.7/library/itertools.html#recipes
def pairwise(iterable):
    "s -> (s0,s1), (s1,s2), (s2, s3), ..."
    a, b = tee(iterable)
    next(b, None)
    return izip(a, b)

def from_local_to_utc(dt, tz_name, dayfirst=True):
    """ What is the UTC time given the local time and the timezone's name?
    """
    if not isinstance(dt, datetime):
        dt = parse(dt, dayfirst=dayfirst)

    dt = pytz.timezone(tz_name).localize(dt)
    utc_dt = pytz.utc.normalize(dt.astimezone(pytz.utc))
    return utc_dt

def from_utc_to_local(dt, tz_name):
    """ What is the local time in the user-provided time zone name?
    """
    if not isinstance(dt, datetime):
        dt = parse(dt)

    local_tz = pytz.timezone(tz_name)
    dt = local_tz.normalize(dt.astimezone(local_tz))
    return dt

# ##############################################################################

def _utcnow():
    """ See zato.common.util.utcnow for docstring.
    """
    return datetime.utcnow()

def utcnow():
    """ A thin wrapper around datetime.utcnow added so that tests can mock it
    out and return their own timestamps at will.
    """
    return _utcnow()

def _now(tz):
    """ See zato.common.util.utcnow for docstring.
    """
    return datetime.now(tz)

def now(tz=None):
    """ A thin wrapper around datetime.now added so that tests can mock it
    out and return their own timestamps at will.
    """
    return _now(tz)

def datetime_to_seconds(dt):
    """ Converts a datetime object to a number of seconds since UNIX epoch.
    """
    return (dt - _epoch).total_seconds()

# ##############################################################################

def clear_locks(kvdb, server_token, kvdb_config=None, decrypt_func=None):
    """ Clears out any KVDB locks held by Zato servers.
    """
    if kvdb_config:
        kvdb.config = kvdb_config

    if decrypt_func:
        kvdb.decrypt_func = decrypt_func

    kvdb.init()

    for name in kvdb.conn.keys('{}*{}*'.format(KVDB.LOCK_PREFIX, server_token)):
        value = kvdb.conn.get(name)
        logger.debug('Deleting lock:[{}], value:[{}]'.format(name, value))
        kvdb.conn.delete(name)

    kvdb.close()


# Inspired by http://stackoverflow.com/a/9283563
def uncamelify(s, separator='-', elem_func=unicode.lower):
    """ Converts a CamelCaseName into a more readable one, e.g.
    will turn ILikeToReadWSDLDocsNotReallyNOPENotMeQ into
    i-like-to-read-wsdl-docs-not-really-nope-not-me-q or a similar one,
    depending on the value of separator and elem_func.
    """
    return separator.join(elem_func(elem) for elem in re.sub(_uncamelify_re, r' \1', s).split())

def get_component_name(prefix='parallel'):
    """ Returns a name of the component issuing a given request so it's possible
    to trace which Zato component issued it.
    """
    return '{}/{}/{}/{}'.format(prefix, current_host(), os.getpid(), current_thread().name)

def dotted_getattr(o, path):
    return reduce(getattr, path.split('.'), o)


def get_service_by_name(session, cluster_id, name):
    logger.debug('Looking for name:[{}] in cluster_id:[{}]'.format(name, cluster_id))
    return _service(session, cluster_id).\
           filter(Service.name==name).\
           one()

def add_startup_jobs(cluster_id, odb, stats_jobs):
    """ Adds one of the interval jobs to the ODB. Note that it isn't being added
    directly to the scheduler because we want users to be able to fine-tune the job's
    settings.
    """
    with closing(odb.session()) as session:
        for item in stats_jobs:

            try:
                service_id = get_service_by_name(session, cluster_id, item['service'])[0]

                now = datetime.utcnow()

                job = Job(None, item['name'], True, 'interval_based', now, item.get('extra', '').encode('utf-8'),
                          cluster_id=cluster_id, service_id=service_id)

                kwargs = {}
                for name in('seconds', 'minutes'):
                    if name in item:
                        kwargs[name] = item[name]

                ib_job = IntervalBasedJob(None, job, **kwargs)

                session.add(job)
                session.add(ib_job)
                session.commit()
            except IntegrityError, e:
                session.rollback()
                logger.debug('Caught an IntegrityError, carrying on anyway, e:[%s]', format_exc(e).decode('utf-8'))

def hexlify(item):
    """ Returns a nice hex version of a string given on input.
    """
    return ' '.join([elem1+elem2 for (elem1, elem2) in grouper(2, item.encode('hex'))])

def validate_input_dict(cid, *validation_info):
    """ Checks that input belongs is one of allowed values.
    """
    for key_name, key, source in validation_info:
        if not source.has(key):
            msg = 'Invalid {}:[{}]'.format(key_name, key)
            log_msg = '{} (attrs: {})'.format(msg, source.attrs)

            logger.warn(log_msg)
            raise ZatoException(cid, msg)

# ##############################################################################

# Taken from https://bitbucket.org/zzzeek/green_sqla/src/tip/green_sqla/psyco_gevent.py

# A wait callback to allow psycopg2 cooperation with gevent.
#
# Use `make_psycopg_green()` to enable gevent support in Psycopg.

# Copyright (C) 2010 Daniele Varrazzo <daniele.varrazzo@gmail.com>
# and licensed under the MIT license:
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
# THE SOFTWARE.

def make_psycopg_green():
    """Configure Psycopg to be used with gevent in non-blocking way."""
    if not hasattr(extensions, 'set_wait_callback'):
        raise ImportError(
            "support for coroutines not available in this Psycopg version (%s)"
            % psycopg2.__version__)

    extensions.set_wait_callback(gevent_wait_callback)

def gevent_wait_callback(conn, timeout=None):
    """A wait callback useful to allow gevent to work with Psycopg."""
    while 1:
        state = conn.poll()
        if state == extensions.POLL_OK:
            break
        elif state == extensions.POLL_READ:
            wait_read(conn.fileno(), timeout=timeout)
        elif state == extensions.POLL_WRITE:
            wait_write(conn.fileno(), timeout=timeout)
        else:
            raise psycopg2.OperationalError(
                "Bad result from poll: %r" % state)

# ################################################################################################################################

# Code below taken from tripod https://github.com/shayne/tripod/blob/master/tripod/sampler.py and slightly modified
# under the terms of LGPL (see LICENSE.txt file for details).

class SafePrettyPrinter(PrettyPrinter, object):
    def format(self, obj, context, maxlevels, level):
        try:
            return super(SafePrettyPrinter, self).format(
                obj, context, maxlevels, level)
        except Exception:
            return object.__repr__(obj)[:-1] + ' (bad repr)>', True, False


def spformat(obj, depth=None):
    return SafePrettyPrinter(indent=1, width=76, depth=depth).pformat(obj)


def formatvalue(v):
    s = spformat(v, depth=1).replace('\n', '')
    if len(s) > 12500:
        s = object.__repr__(v)[:-1] + ' (really long repr)>'
    return '=' + s


def get_stack(f, with_locals=False):
    limit = getattr(sys, 'tracebacklimit', None)

    frames = []
    n = 0
    while f is not None and (limit is None or n < limit):
        lineno, co = f.f_lineno, f.f_code
        name, filename = co.co_name, co.co_filename
        args = inspect.getargvalues(f)

        linecache.checkcache(filename)
        line = linecache.getline(filename, lineno, f.f_globals)
        if line:
            line = line.strip()
        else:
            line = None

        frames.append((filename, lineno, name, line, f.f_locals, args))
        f = f.f_back
        n += 1
    frames.reverse()

    out = []
    for filename, lineno, name, line, localvars, args in frames:
        out.append(' File "%s", line %d, in %s' % (filename, lineno, name))
        if line:
            out.append(' %s' % line.strip())

        if with_locals:
            args = inspect.formatargvalues(formatvalue=formatvalue, *args)
            out.append('\n Arguments: %s%s' % (name, args))

        if with_locals and localvars:
            out.append(' Local variables:\n')
            try:
                reprs = spformat(localvars)
            except Exception:
                reprs = "failed to format local variables"
            out += [' ' + l for l in reprs.splitlines()]
            out.append('')
    return '\n'.join(out)

# ################################################################################################################################

def get_threads_traceback(pid):
    result = {}
    id_name = dict([(th.ident, th.name) for th in threading.enumerate()])

    for thread_id, frame in sys._current_frames().items():
        key = '{}:{}'.format(pid, id_name.get(thread_id, '(No name)'))
        result[key] = get_stack(frame, True)

    return result

def get_greenlets_traceback(pid):
    result = {}
    for item in gc.get_objects():
        if not isinstance(item, (Greenlet, Hub)):
            continue
        if not item:
            continue

        key = '{}:{}'.format(pid, repr(item))
        result[key] = ''.join(get_stack(item.gr_frame, True))

    return result

def dump_stacks(*ignored):
    pid = os.getpid()

    table = Texttable()
    table.set_cols_width((30, 90))
    table.set_cols_dtype(['t', 't'])

    rows = [['Proc:Thread/Greenlet', 'Traceback']]

    rows.extend(sorted(get_threads_traceback(pid).items()))
    rows.extend(sorted(get_greenlets_traceback(pid).items()))

    table.add_rows(rows)
    logger.info('\n' + table.draw())

def register_diag_handlers():
    """ Registers diagnostic handlers dumping stacks, threads and greenlets on receiving a signal.
    """
    signal.signal(signal.SIGURG, dump_stacks)

# ################################################################################################################################

def parse_extra_into_dict(lines):
    """ Creates a dictionary out of key=value lines.
    """
    _extra = {}

    if lines:
        extra = ';'.join(lines.splitlines())

        for line in extra.split(';'):
            original_line = line
            if line:
                line = line.split('=')
                if not len(line) == 2:
                    raise ValueError('Each line must be a single key=value entry, not [{}]'.format(original_line))

                key, value = line
                value = value.strip()

                try:
                    value = is_boolean(value)
                except VdtTypeError:
                    # It's cool, not a boolean
                    pass

                try:
                    value = is_integer(value)
                except VdtTypeError:
                    # OK, not an integer
                    pass

                _extra[key.strip()] = value

    return _extra

# ################################################################################################################################

# Taken from http://plumberjack.blogspot.cz/2009/09/how-to-treat-logger-like-output-stream.html

class LoggerWriter:
    def __init__(self, logger, level):
        self.logger = logger
        self.level = level

    def write(self, message):
        if message != '\n':
            self.logger.log(self.level, message)

# ################################################################################################################################

def validate_xpath(expr):
    """ Evaluates an XPath expression thus confirming it is correct.
    """
    etree.XPath(expr)
    return True

# ################################################################################################################################

# Taken from http://grodola.blogspot.com/2014/04/reimplementing-netstat-in-cpython.html
def is_port_taken(port):
    for conn in psutil.net_connections(kind='tcp'):
        if conn.laddr[1] == port and conn.status == psutil.CONN_LISTEN:
            return True
    return False

# ################################################################################################################################

def get_haproxy_pidfile(component_dir):
    json_config = json.loads(open(os.path.join(component_dir, 'config', 'repo', 'lb-agent.conf')).read())
    return os.path.abspath(os.path.join(component_dir, json_config['pid_file']))

def store_pidfile(component_dir):
    open(os.path.join(component_dir, MISC.PIDFILE), 'w').write('{}'.format(os.getpid()))

# ################################################################################################################################

def get_kvdb_config_for_log(config):
    config = copy.deepcopy(config)
    if config.shadow_password_in_logs:
        config.password = PASSWORD_SHADOW
    return config

def has_redis_sentinels(config):
    return asbool(config.get('use_redis_sentinels', False))

# ################################################################################################################################
########NEW FILE########
__FILENAME__ = zmq_
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

"""
Objects useful when implementing ZeroMQ clients. Written without any dependecies
on other partf of Zato code base so they can be re-used outside of the Zato project.
"""

# stdlib
import errno
import logging
from threading import Thread
from traceback import format_exc

# ZeroMQ
import zmq

logger = logging.getLogger(__name__)

class ZMQPullSub(object):
    """ A ZeroMQ client which pulls and subscribe to messages. Runs in a background
    thread and invokes the handler on each incoming message.
    """
    
    def __init__(self, name, zmq_context, broker_push_client_pull, broker_pub_client_sub,
                 on_pull_handler=None, pull_handler_args=None,
                 on_sub_handler=None, sub_handler_args=None, sub_key=b'', keep_running=True):
        self.name = name
        self.zmq_context = zmq_context
        self.broker_push_client_pull = broker_push_client_pull
        self.broker_pub_client_sub = broker_pub_client_sub
        self.keep_running = keep_running
        self.on_pull_handler = on_pull_handler
        self.pull_handler_args = pull_handler_args
        self.on_sub_handler = on_sub_handler
        self.sub_handler_args = sub_handler_args
        self.sub_key = sub_key
        self.pull_socket = None
        self.sub_socket = None
        
    # Custom subclasses may wish to override the two hooks below.
    def on_before_msg_handler(self, msg, args):
        pass

    def on_after_msg_handler(self, msg, e=None, args=None):
        pass
    
    def start(self):
        Thread(target=self.listen).start()
        
    def close(self, pull_socket=None, sub_socket=None):
        self.keep_running = False
        ps = pull_socket if pull_socket else self.pull_socket
        ss = sub_socket if sub_socket else self.sub_socket
        
        if ps:
            ps.close()
        if ss:
            ss.close()
    
    def listen(self):
        
        _socks = []
        poller = zmq.Poller()
        
        if self.broker_push_client_pull:
            self.pull_socket = self.zmq_context.socket(zmq.PULL)
            self.pull_socket.setsockopt(zmq.LINGER, 0)
            self.pull_socket.connect(self.broker_push_client_pull)
            poller.register(self.pull_socket, zmq.POLLIN)
            _socks.append(('pull', self.pull_socket))
            
            logger.info('Starting PULL [{0}/{1}]'.format(
                self.name, self.broker_push_client_pull))
            
        if self.broker_pub_client_sub:
            self.sub_socket = self.zmq_context.socket(zmq.SUB)
            self.sub_socket.setsockopt(zmq.LINGER, 0)
            self.sub_socket.connect(self.broker_pub_client_sub)
            self.sub_socket.setsockopt(zmq.SUBSCRIBE, self.sub_key)
            poller.register(self.sub_socket, zmq.POLLIN)
            _socks.append(('sub', self.sub_socket))
            
            logger.info('Starting SUB [{0}/{1}]'.format(
                self.name, self.broker_pub_client_sub))
            
        _handlers_args = {}
        if self.pull_socket:
            _handlers_args[self.pull_socket] = (self.on_pull_handler, self.pull_handler_args)
        if self.sub_socket:
            _handlers_args[self.sub_socket] = (self.on_sub_handler, self.sub_handler_args)
            
        while self.keep_running:
            try:
                poll_socks = dict(poller.poll())
                for sock_name, sock in _socks:
                    if poll_socks.get(sock) == zmq.POLLIN:
                        msg = sock.recv()
                        try:
                            
                            e = None
                            args = None
                            
                            # A pre-hook, if any..
                            self.on_before_msg_handler(msg, self.pull_handler_args)
                            
                            # .. the actual handler ..
                            handler, args = _handlers_args[sock]
                            args = (args, sock_name)
                            handler(msg, args)
                        except Exception, e:
                            msg = '[{0}] Could not invoke the message handler, msg [{1}] sock_name [{2}] e [{3}]'
                            logger.error(msg.format(self.name, msg, sock_name, format_exc(e)))
                        finally:
                            # .. an after-hook, if any..
                            self.on_after_msg_handler(msg, args, e)
                        
            except Exception, e:
                # It's OK and needs not to disturb the user so log it only
                # in the DEBUG level.
                if isinstance(e, zmq.ZMQError) and(e.errno == zmq.ETERM or e.errno == errno.ENOTSOCK):
                    if e.errno == zmq.ETERM:
                        caught = 'zmq.ETERM'
                    elif e.errno == errno.ENOTSOCK:
                        caught = 'errno.ENOTSOCK'
                    msg = '[{0}] Caught [{1}] [{2}], quitting'.format(self.name, caught, format_exc(e))
                    log_func = logger.debug
                else:
                    e_errno = getattr(e, 'errno', None)
                    msg = '[{0}] Caught an exception [{1}], errno [{2}], quitting.'.format(
                        self.name, e_errno, format_exc(e))
                    log_func = logger.error
                    
                log_func(msg)
                self.close()
                    
class ZMQPush(object):
    """ Sends messages to ZeroMQ using a PUSH socket.
    """
    def __init__(self, name, zmq_context, address):
        self.name = name
        self.zmq_context = zmq_context
        self.address = address
        self.socket_type = zmq.PUSH
        
        logger.debug('Starting PUSH [{0}/{1}]'.format(self.name, self.address))

        self.socket = self.zmq_context.socket(self.socket_type)
        self.socket.setsockopt(zmq.LINGER, 0)
        self.socket.connect(self.address)
        
    def send(self, msg):
        try:
            self.socket.send_unicode(msg)
            if logger.isEnabledFor(logging.DEBUG):
                logger.debug('Sent PUSH msg:[{}] to {}'.format(msg, self.address))
        except zmq.ZMQError, e:
            msg = '[{0}] Caught ZMQError [{1}], continuing anyway.'.format(
                self.name, e.strerror)
            logger.warn(msg)
        
    def close(self):
        msg = 'Stopping [[{0}/{1}/{2}]'.format(self.name, self.address, self.socket_type)
        logger.info(msg)
        self.socket.close()
        
class ZMQClient(object):
    """ A ZeroMQ broker client which knows how to subscribe to messages and push
    the messages onto the broker.
    """
    def __init__(self, init=False, **kwargs):
        self._push = None
        self._pull_sub = None
        self.zmq_context = kwargs.get('zmq_context')
        self.name = kwargs.get('name')
        self.broker_push_client_pull = kwargs.get('broker_push_client_pull')
        self.client_push_broker_pull = kwargs.get('client_push_broker_pull')
        self.broker_pub_client_sub = kwargs.get('broker_pub_client_sub')
        self.on_pull_handler = kwargs.get('on_pull_handler')
        self.pull_handler_args = kwargs.get('pull_handler_args')
        self.on_sub_handler = kwargs.get('on_sub_handler')
        self.sub_handler_args = kwargs.get('sub_handler_args')
        self.sub_key = kwargs.get('sub_key', b'')

        if init:
            self.init()
            
    def __repr__(self):
        return '<{0} at {1} name:[{2}] broker_push_client_pull:[{3}] '\
               'client_push_broker_pull:[{4}] broker_pub_client_sub:[{5}] '\
               'on_pull_handler:[{6}] pull_handler_args:[{7}] on_sub_handler:[{8}] '\
               'sub_handler_args:[{9}] sub_key:[{10}]'.format(
                   self.__class__.__name__,
                   hex(id(self)), self.name, self.broker_push_client_pull,
                   self.client_push_broker_pull, self.broker_pub_client_sub,
                   self.on_pull_handler, self.pull_handler_args,
                   self.on_sub_handler, self.sub_handler_args, self.sub_key)
            
    def init(self):
        if self.broker_pub_client_sub or self.broker_push_client_pull:
            self._pull_sub = ZMQPullSub(
                self.name, self.zmq_context, self.broker_push_client_pull,
                self.broker_pub_client_sub, self.on_pull_handler, self.pull_handler_args,
                self.on_sub_handler, self.sub_handler_args, self.sub_key)
        
        if self.client_push_broker_pull:
            self._push = ZMQPush(self.name, self.zmq_context, self.client_push_broker_pull)
        else:
            logger.debug('Client [{0}] has no [client_push_broker_pull] address defined'.format(self.name))
        
    def set_pull_handler(self, handler):
        self._pull_sub.on_pull_handler = handler
        
    def set_pull_handler_args(self, args):
        self._pull_sub.pull_handler_args = args
        
    def set_sub_handler(self, handler):
        self._pull_sub.on_sub_handler = handler
        
    def set_sub_handler_args(self, args):
        self._pull_sub.sub_handler_args = args
    
    def start(self):
        if self._pull_sub:
            self._pull_sub.start()
    
    def send(self, msg):
        return self._push.send(msg)
    
    def close(self):
        if self._push:
            self._push.close()
        if self._pull_sub:
            self._pull_sub.close()
            
        logger.info('Closed [{0}]'.format(self.get_connection_info()))
            
    def get_connection_info(self):
        return 'name:[{0}] client_pull:[{1}] client_push:[{2}] client_sub:[{3}] sub_key:[{4}]'.format(
            self.name, self.broker_push_client_pull, self.client_push_broker_pull, self.broker_pub_client_sub,
            self.sub_key)

########NEW FILE########
__FILENAME__ = common
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from unittest import TestCase

# Redis
from redis import ConnectionError, Redis

# Zato
from zato.common.util import new_cid

class RedisPubSubCommonTestCase(TestCase):

    def setUp(self):
        self.key_prefix = 'zato:pubsub:{}:'.format(new_cid())
        self.kvdb = Redis()

        try:
            self.kvdb.ping()
        except ConnectionError:
            self.has_redis = False
        else:
            self.has_redis = True

    def tearDown(self):
        for key in self.kvdb.keys('{}*'.format(self.key_prefix)):
            self.kvdb.delete(key)

########NEW FILE########
__FILENAME__ = test_api_impl
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from json import loads
from datetime import datetime
from unittest import TestCase

# datadiff
from datadiff.tools import assert_equal

# dateutil
from dateutil.parser import parse

# Zato
from zato.common import PUB_SUB
from zato.common.log_message import CID_LENGTH
from zato.common.pubsub import AckCtx, Client, Consumer, GetCtx, Message, PubCtx, PubSubAPI, PubSubException, RedisPubSub, \
     RejectCtx, SubCtx, Topic
from zato.common.test import rand_bool, rand_date_utc, rand_int, rand_string
from .common import RedisPubSubCommonTestCase

class RedisPubSubTestCase(RedisPubSubCommonTestCase):

    def setUp(self):
        super(RedisPubSubTestCase, self).setUp()
        self.api = PubSubAPI(RedisPubSub(self.kvdb, self.key_prefix))

# ################################################################################################################################

    def _publish_move(self, move=True, **kwargs):
        payload = rand_string()

        topic = Topic(rand_string())
        self.api.add_topic(topic)

        producer = Client(rand_int(), rand_string())
        self.api.add_producer(producer, topic)

        ctx = self.api.publish(payload, topic.name, client_id=producer.id, **kwargs)
        if move:
            self.api.impl.move_to_target_queues()

        return payload, topic, producer, ctx

    def _check_publish(self, **kwargs):

        if kwargs:
            expected_mime_type = kwargs['mime_type']
            expected_priority = kwargs['priority']
            expected_expiration = kwargs['expiration']
            expected_msg_id = kwargs['msg_id']
        else:
            expected_mime_type = PUB_SUB.DEFAULT_MIME_TYPE
            expected_priority = PUB_SUB.DEFAULT_PRIORITY
            expected_expiration = PUB_SUB.DEFAULT_EXPIRATION
            expected_msg_id = None

        payload, topic, producer, ctx = self._publish_move(**kwargs)

        now = datetime.utcnow()

        # ########################################################################################################################
        #
        # MSG_METADATA_KEY
        #
        # ########################################################################################################################

        msg_metadata_dict = self.kvdb.hgetall(self.api.impl.MSG_METADATA_KEY)

        # E.g. {'K0321C8Q5X67N7K2D642ZYZCXY5T': '{"topic": "ab3ee73838d174cd690a1947b56f67674", "priority": 5, "expiration": 60.0,
        #                 "producer": "a951ec619d0f449969529c0bfe8f7900f",
        #                 "creation_time_utc": "2014-04-06T19:51:37.784905", "msg_id": "K0321C8Q5X67N7K2D642ZYZCXY5T",
        #                 "expire_at_utc": "2014-04-06T19:52:37.784905", "mime_type": "text/plain"}'}

        self.assertEquals(len(msg_metadata_dict), 1)
        self.assertTrue(ctx.msg.msg_id in msg_metadata_dict)

        msg_metadata = loads(msg_metadata_dict[ctx.msg.msg_id])

        self.assertEquals(msg_metadata['mime_type'], expected_mime_type)
        self.assertEquals(msg_metadata['priority'], expected_priority)
        self.assertEquals(msg_metadata['expiration'], expected_expiration)
        self.assertEquals(msg_metadata['topic'], topic.name)
        self.assertEquals(msg_metadata['producer'], producer.name)

        creation_time_utc = parse(msg_metadata['creation_time_utc'])
        expire_at_utc = parse(msg_metadata['expire_at_utc'])

        self.assertTrue(creation_time_utc < now, 'creation_time_utc:`{}` is not less than now:`{}`'.format(creation_time_utc, now))
        self.assertTrue(expire_at_utc > now, 'creation_time_utc:`{}` is not greater than now:`{}`'.format(expire_at_utc, now))

        # ########################################################################################################################
        #
        # LAST_PUB_TIME_KEY
        #
        # ########################################################################################################################

        last_pub_time = self.kvdb.hgetall(self.api.impl.LAST_PUB_TIME_KEY)
        self.assertEquals(len(last_pub_time), 1)
        last_pub_time = parse(last_pub_time[topic.name])
        self.assertTrue(last_pub_time < now, 'last_pub_time:`{}` is not less than now:`{}`'.format(last_pub_time, now))

        # ########################################################################################################################
        #
        # MSG_EXPIRE_AT_KEY
        #
        # ########################################################################################################################

        msg_expire_at = self.kvdb.hgetall(self.api.impl.MSG_EXPIRE_AT_KEY)
        self.assertEquals(len(msg_expire_at), 1)
        msg_expire_at = parse(msg_expire_at[ctx.msg.msg_id])
        self.assertTrue(msg_expire_at > now, 'msg_expire_at:`{}` is not greater than now:`{}`'.format(msg_expire_at, now))

        # ########################################################################################################################
        #
        # LAST_SEEN_PRODUCER_KEY
        #
        # ########################################################################################################################

        last_seen_producer = self.kvdb.hgetall(self.api.impl.LAST_SEEN_PRODUCER_KEY)
        self.assertEquals(len(last_seen_producer), 1)
        last_seen_producer = parse(last_seen_producer[str(producer.id)])
        self.assertTrue(last_seen_producer < now, 'last_seen_producer:`{}` is not less than now:`{}`'.format(last_seen_producer, now))

        # ########################################################################################################################
        #
        # MSG_VALUES_KEY
        #
        # ########################################################################################################################

        msg_values = self.kvdb.hgetall(self.api.impl.MSG_VALUES_KEY)
        self.assertEquals(len(msg_values), 1)
        self.assertEquals(payload, msg_values[ctx.msg.msg_id])

    def test_publish_defaults(self):
        self._check_publish()

    def test_publish_custom_attrs(self):
        self._check_publish(**{
            'mime_type': rand_string(),
            'priority': rand_int(),
            'expiration': rand_int(1000, 2000),
            'msg_id': rand_string(),
        })

# ################################################################################################################################

    def test_delete_metadata(self):
        payload, topic, producer, ctx = self._publish_move(move=False)
        consumer = Consumer(rand_int(), rand_string())

        self.api.add_consumer(consumer, topic)
        sub_key = self.api.subscribe(consumer.id, topic.name)

        self.api.impl.move_to_target_queues()

        self._check_consumer_queue_before_get(ctx, sub_key)
        self._check_get(ctx, sub_key, topic, producer, consumer)
        self.api.acknowledge(sub_key, ctx.msg.msg_id)

        # Ok, we should now have metadata for the consumer, producer and topic.
        last_seen_consumer = self.api.impl.kvdb.hkeys(self.api.impl.LAST_SEEN_CONSUMER_KEY)
        last_seen_producer = self.api.impl.kvdb.hkeys(self.api.impl.LAST_SEEN_PRODUCER_KEY)
        last_pub_time = self.api.impl.kvdb.hkeys(self.api.impl.LAST_PUB_TIME_KEY)

        self.assertIn(str(consumer.id), last_seen_consumer)
        self.assertIn(str(producer.id), last_seen_producer)
        self.assertIn(topic.name, last_pub_time)

        self.api.impl.delete_producer(producer, topic)
        last_seen_producer = self.api.impl.kvdb.hkeys(self.api.impl.LAST_SEEN_PRODUCER_KEY)
        self.assertNotIn(str(producer.id), last_seen_producer)

        self.api.impl.delete_consumer(consumer, topic)
        last_seen_consumer = self.api.impl.kvdb.hkeys(self.api.impl.LAST_SEEN_CONSUMER_KEY)
        self.assertNotIn(str(consumer.id), last_seen_consumer)

        self.api.impl.delete_topic(topic)
        last_pub_time = self.api.impl.kvdb.hkeys(self.api.impl.LAST_PUB_TIME_KEY)
        self.assertNotIn(topic.name, last_pub_time)

# ################################################################################################################################

    def test_subscribe(self):
        client_id, client_name = rand_int(), rand_string()
        client = Client(client_id, client_name)
        topics = rand_string(rand_int())

        sub_key = self.api.subscribe(client.id, topics)

        self.assertEquals(self.api.impl.sub_to_cons[sub_key], client_id)
        self.assertEquals(self.api.impl.cons_to_sub[client_id], sub_key)
        self.assertEquals(sorted(self.api.impl.cons_to_topic[client_id]), sorted(topics))

        for topic in topics:
            self.assertIn(client_id, self.api.impl.topic_to_cons[topic])

# ################################################################################################################################

    def _check_consumer_queue_before_get(self, ctx, sub_key):

        # ########################################################################################################################
        #
        # UNACK_COUNTER_KEY
        #
        # ########################################################################################################################

        unack_counter = self.kvdb.hgetall(self.api.impl.UNACK_COUNTER_KEY)
        self.assertEquals(len(unack_counter), 1)
        self.assertEqual(unack_counter[ctx.msg.msg_id], '1') # One subscriber hence one undelivered message

        # ########################################################################################################################
        #
        # CONSUMER_MSG_IDS_PREFIX
        #
        # ########################################################################################################################

        consumer_msg_ids = self.kvdb.lrange(self.api.impl.CONSUMER_MSG_IDS_PREFIX.format(sub_key), 0, -1)
        self.assertEquals(consumer_msg_ids, [ctx.msg.msg_id])

    def _check_get(self, ctx, sub_key, topic, producer, client):

        msg = list(self.api.get(sub_key))[0].to_dict()
        self.assertEquals(msg['topic'], topic.name)
        self.assertEquals(msg['priority'], PUB_SUB.DEFAULT_PRIORITY)
        self.assertEquals(msg['expiration'], PUB_SUB.DEFAULT_EXPIRATION)
        self.assertEquals(msg['producer'], producer.name)
        self.assertEquals(msg['msg_id'], ctx.msg.msg_id)
        self.assertEquals(msg['mime_type'], PUB_SUB.DEFAULT_MIME_TYPE)

        now = datetime.utcnow()

        creation_time_utc = parse(msg['creation_time_utc'])
        expire_at_utc = parse(msg['expire_at_utc'])

        self.assertTrue(creation_time_utc < now, 'creation_time_utc:`{}` is not less than now:`{}`'.format(creation_time_utc, now))
        self.assertTrue(expire_at_utc > now, 'creation_time_utc:`{}` is not greater than now:`{}`'.format(expire_at_utc, now))

        # ########################################################################################################################
        #
        # LAST_SEEN_CONSUMER_KEY
        #
        # ########################################################################################################################

        last_seen_consumer = self.kvdb.hgetall(self.api.impl.LAST_SEEN_CONSUMER_KEY)
        self.assertEquals(len(last_seen_consumer), 1)
        last_seen_consumer = parse(last_seen_consumer[str(client.id)])
        self.assertTrue(last_seen_consumer < now, 'last_seen_consumer:`{}` is not less than now:`{}`'.format(last_seen_consumer, now))

        # ########################################################################################################################
        #
        # CONSUMER_IN_FLIGHT_IDS_PREFIX
        #
        # ########################################################################################################################

        consumer_id_flight_ids = self.kvdb.smembers(self.api.impl.CONSUMER_IN_FLIGHT_IDS_PREFIX.format(sub_key))
        self.assertEquals(len(consumer_id_flight_ids), 1)
        self.assertEqual(list(consumer_id_flight_ids), [ctx.msg.msg_id])

        # ########################################################################################################################
        #
        # CONSUMER_IN_FLIGHT_DATA_PREFIX
        #
        # ########################################################################################################################

        consumer_in_flight_data = self.kvdb.hgetall(self.api.impl.CONSUMER_IN_FLIGHT_DATA_PREFIX.format(sub_key))
        self.assertEquals(len(consumer_in_flight_data), 1)
        consumer_in_flight_data = parse(consumer_in_flight_data[ctx.msg.msg_id])
        self.assertTrue(
            consumer_in_flight_data < now, 'consumer_in_flight_data:`{}` is not less than now:`{}`'.format(
                consumer_in_flight_data, now))

        # There should still be one unacknowledged message.

        unack_counter = self.kvdb.hgetall(self.api.impl.UNACK_COUNTER_KEY)
        self.assertEquals(len(unack_counter), 1)
        self.assertEqual(unack_counter[ctx.msg.msg_id], '1') # One subscriber hence one undelivered message

    def test_get_reject_acknowledge(self):
        payload, topic, producer, ctx = self._publish_move(move=False)
        client_id, client_name = rand_int(), rand_string()

        client = Client(client_id, client_name)
        sub_key = self.api.subscribe(client.id, topic.name)

        # Moves a message to the consumer's queue
        self.api.impl.move_to_target_queues()
        self._check_consumer_queue_before_get(ctx, sub_key)

        # Consumer gets a message which puts it in the in-flight state.
        self._check_get(ctx, sub_key, topic, producer, client)

        # However, there should be nothing in the consumer's queue.
        consumer_msg_ids = self.kvdb.lrange(self.api.impl.CONSUMER_MSG_IDS_PREFIX.format(sub_key), 0, -1)
        self.assertEquals(consumer_msg_ids, [])

        # Consumer rejects the message which puts it back on a queue.
        self.api.reject(sub_key, ctx.msg.msg_id)

        # After rejection it's as though the message has just been published.
        self._check_consumer_queue_before_get(ctx, sub_key)

        # Get after rejection works as before.
        self._check_get(ctx, sub_key, topic, producer, client)

        # Consumer acknowledges a message.
        self.api.acknowledge(sub_key, ctx.msg.msg_id)

        # This was the only one subscription so now that the message has been delivered
        # there should be no trace of it in backend.
        # The only keys left are LAST_PUB_TIME_KEY, LAST_SEEN_CONSUMER_KEY and LAST_SEEN_PRODUCER_KEY - nothing else.

        keys = self.kvdb.keys('{}*'.format(self.key_prefix))
        self.assertEquals(len(keys), 3)

        now = datetime.utcnow()

        last_pub_time = parse(self.kvdb.hgetall(self.api.impl.LAST_PUB_TIME_KEY)[topic.name])
        last_seen_consumer = parse(self.kvdb.hgetall(self.api.impl.LAST_SEEN_CONSUMER_KEY)[str(client.id)])
        last_seen_producer = parse(self.kvdb.hgetall(self.api.impl.LAST_SEEN_PRODUCER_KEY)[str(producer.id)])

        self.assertTrue(last_pub_time < now, 'last_pub_time:`{}` is not less than now:`{}`'.format(last_pub_time, now))
        self.assertTrue(last_seen_consumer < now, 'last_seen_consumer:`{}` is not less than now:`{}`'.format(last_seen_consumer, now))
        self.assertTrue(last_seen_producer < now, 'last_seen_producer:`{}` is not less than now:`{}`'.format(last_seen_producer, now))

# ################################################################################################################################

    def test_pub_sub_exception(self):

        invalid_sub_key = rand_string()
        valid_sub_key = rand_string()
        client_id = rand_int()
        topic_name = rand_string()

        consumer = Consumer(client_id, rand_string(), sub_key=valid_sub_key)
        topic = Topic(topic_name)

        # Without adding consumer key, validation won't succeed.
        self.assertRaises(PubSubException, self.api.impl.validate_sub_key, invalid_sub_key)
        self.assertRaises(PubSubException, self.api.impl.validate_sub_key, valid_sub_key)

        # After adding a subscription key no error should be raised.
        self.api.impl.add_consumer(consumer, topic)
        self.api.impl.add_subscription(valid_sub_key, client_id, topic_name)

        self.assertRaises(PubSubException, self.api.impl.validate_sub_key, invalid_sub_key)
        self.api.impl.validate_sub_key(valid_sub_key) # Should not raise any exception now.

        self.api.impl.delete_consumer(consumer, topic)

        # After deleting a consumer, validation won't succeed anymore.
        self.assertRaises(PubSubException, self.api.impl.validate_sub_key, invalid_sub_key)
        self.assertRaises(PubSubException, self.api.impl.validate_sub_key, valid_sub_key)

        def invoke_func_sub_key(func, sub_key, *args):
            list(func(sub_key, *args))

        self.assertRaises(PubSubException, invoke_func_sub_key, self.api.get, valid_sub_key)
        self.assertRaises(PubSubException, invoke_func_sub_key, self.api.get, invalid_sub_key)

        self.assertRaises(PubSubException, invoke_func_sub_key, self.api.acknowledge, valid_sub_key, 'abc')
        self.assertRaises(PubSubException, invoke_func_sub_key, self.api.acknowledge, invalid_sub_key, 'def')

        self.assertRaises(PubSubException, invoke_func_sub_key, self.api.reject, valid_sub_key, 'abc')
        self.assertRaises(PubSubException, invoke_func_sub_key, self.api.reject, invalid_sub_key, 'def')

    def test_publish_exceptions(self):
        payload = rand_string()
        producer = Client(rand_int(), rand_string())

        def invoke_publish(payload, topic, producer_id):
            self.api.publish(payload, topic, client_id=producer_id)

        # KeyError because no such producer is in self.api.impl.producers.
        self.assertRaises(KeyError, invoke_publish, payload, rand_string(), producer.id)

        # Adding a producer but still, no such topic.
        self.api.add_producer(producer, Topic(rand_string()))
        self.assertRaises(PubSubException, invoke_publish, payload, rand_string(), producer.id)

        # Adding a topic but still PubSubException is raised because the producer is not allowed to use it.
        topic = Topic(rand_string())
        self.api.add_topic(topic)
        self.assertRaises(PubSubException, invoke_publish, payload, topic.name, producer.id)

        # Combining the topic and producer, no exception is raised now.
        self.api.add_producer(producer, topic)
        invoke_publish(payload, topic.name, producer.id)

        # But it's not possible to publish to inactive topics.
        self.api.impl.topics[topic.name].is_active = False
        self.assertRaises(PubSubException, invoke_publish, payload, topic.name, producer.id)

        # Make the topic active and it can be published to again.
        self.api.impl.topics[topic.name].is_active = True
        invoke_publish(payload, topic.name, producer.id)

        # Inactive producers cannot publish to topics either.
        self.api.impl.producers[producer.id].is_active = False
        self.assertRaises(PubSubException, invoke_publish, payload, topic.name, producer.id)

        # Making them active means they can publish again.
        self.api.impl.producers[producer.id].is_active = True
        invoke_publish(payload, topic.name, producer.id)

    def test_ping(self):
        response = self.api.impl.ping()
        self.assertIsInstance(response, bool)
        self.assertEquals(response, True)

# ################################################################################################################################

    def test_default_clients(self):
        # Initially, default clients are dummy ones.
        default_consumer = self.api.get_default_consumer()
        default_producer = self.api.get_default_producer()

        self.assertEquals(default_consumer.id, None)
        self.assertEquals(default_consumer.name, None)
        self.assertEquals(default_consumer.is_active, True)

        self.assertEquals(default_producer.id, None)
        self.assertEquals(default_producer.name, None)
        self.assertEquals(default_producer.is_active, True)

        cons_id = rand_int()
        cons_name = rand_string()
        cons_is_active = rand_bool()

        prod_name = rand_string()
        prod_id = rand_int()
        prod_is_active = rand_bool()

        cons = Client(cons_id, cons_name, cons_is_active)
        prod = Client(prod_id, prod_name, prod_is_active)

        self.api.set_default_consumer(cons)
        self.api.set_default_producer(prod)

        default_consumer = self.api.get_default_consumer()
        default_producer = self.api.get_default_producer()

        self.assertEquals(default_consumer.id, cons_id)
        self.assertEquals(default_consumer.name, cons_name)
        self.assertEquals(default_consumer.is_active, cons_is_active)

        self.assertEquals(default_producer.id, prod_id)
        self.assertEquals(default_producer.name, prod_name)
        self.assertEquals(default_producer.is_active, prod_is_active)

# ################################################################################################################################

    def test_topic_add(self):
        name = rand_string()
        is_active = rand_bool()
        is_fifo = rand_bool()
        max_depth = rand_int()

        topic = Topic(name, is_active, is_fifo, max_depth)

        self.api.add_topic(topic)

        self.assertIn(name, self.api.impl.topics)
        self.assertEquals(len(self.api.impl.topics), 1)

        given = self.api.impl.topics[name]
        self.assertEquals(given.name, name)
        self.assertEquals(given.is_active, is_active)
        self.assertEquals(given.is_fifo, is_fifo)
        self.assertEquals(given.max_depth, max_depth)

        # Adding topic of the same name should not create a new topic because impl.topics is a dictionary
        self.api.add_topic(topic)
        self.assertEquals(len(self.api.impl.topics), 1)

    def test_topic_update(self):
        self.test_topic_add() # updating a topic works the same like creating it

# ################################################################################################################################

class CtxObjectsTestCase(TestCase):

    def _get_object(self, class_, kwargs=None):
        return class_(**(kwargs or {}))

# ################################################################################################################################

    def test_topic_defaults(self):
        name = rand_string()
        topic = self._get_object(Topic, {'name': name})
        self.assertEquals(topic.name, name)
        self.assertEquals(topic.is_active, True)
        self.assertEquals(topic.is_fifo, PUB_SUB.DEFAULT_IS_FIFO)
        self.assertEquals(topic.max_depth, PUB_SUB.DEFAULT_MAX_DEPTH)

    def test_topic_custom_attrs(self):
        name = rand_string()
        is_active = rand_bool()
        is_fifo = rand_bool()
        max_depth = rand_int()

        topic = self._get_object(Topic, {
            'name':name, 'is_active':is_active, 'is_fifo':is_fifo, 'max_depth':max_depth
        })

        self.assertEquals(topic.name, name)
        self.assertEquals(topic.is_active, is_active)
        self.assertEquals(topic.is_fifo, is_fifo)
        self.assertEquals(topic.max_depth, max_depth)

# ################################################################################################################################

    def test_pub_ctx_defaults(self):
        ctx = PubCtx()
        self.assertEquals(ctx.client_id, None)
        self.assertEquals(ctx.topic, None)
        self.assertEquals(ctx.msg, None)

    def test_pub_ctx_custom_attrs(self):
        client_id, topic, msg = rand_string(3)
        ctx = PubCtx(client_id, topic, msg)
        self.assertEquals(ctx.client_id, client_id)
        self.assertEquals(ctx.topic, topic)
        self.assertEquals(ctx.msg, msg)

# ################################################################################################################################

    def test_sub_ctx_defaults(self):
        ctx = SubCtx()
        self.assertEquals(ctx.client_id, None)
        self.assertEquals(ctx.topics, [])

    def test_sub_ctx_custom_attrs(self):
        client_id, topics = rand_string(2)
        ctx = SubCtx(client_id, topics)
        self.assertEquals(ctx.client_id, client_id)
        self.assertEquals(ctx.topics, topics)

# ################################################################################################################################

    def test_get_ctx_defaults(self):
        ctx = GetCtx()
        self.assertEquals(ctx.sub_key, None)
        self.assertEquals(ctx.max_batch_size, PUB_SUB.DEFAULT_GET_MAX_BATCH_SIZE)
        self.assertEquals(ctx.is_fifo, PUB_SUB.DEFAULT_IS_FIFO)
        self.assertEquals(ctx.get_format, PUB_SUB.GET_FORMAT.OBJECT.id)

    def test_get_ctx_custom_attrs(self):
        sub_key = rand_string()
        max_batch_size = rand_int()
        is_fifo = rand_bool()
        get_format = rand_string()

        ctx = GetCtx(sub_key, max_batch_size, is_fifo, get_format)

        self.assertEquals(ctx.sub_key, sub_key)
        self.assertEquals(ctx.max_batch_size, max_batch_size)
        self.assertEquals(ctx.is_fifo, is_fifo)
        self.assertEquals(ctx.get_format, get_format)

# ################################################################################################################################

    def test_ack_ctx_defaults(self):
        ctx = AckCtx()
        self.assertEquals(ctx.sub_key, None)
        self.assertEquals(ctx.msg_ids, [])

    def test_ack_ctx_custom_attrs(self):
        sub_key = rand_string()
        msg_ids = rand_string(2)

        ctx = AckCtx(sub_key, msg_ids)

        self.assertEquals(ctx.sub_key, sub_key)
        self.assertEquals(ctx.msg_ids, msg_ids)

        msg_id = rand_string()
        ctx.append(msg_id)

        self.assertEquals(ctx.msg_ids, msg_ids)

# ################################################################################################################################

    def test_reject_ctx_defaults(self):
        ctx = RejectCtx()
        self.assertEquals(ctx.sub_key, None)
        self.assertEquals(ctx.msg_ids, [])

    def test_reject_ctx_custom_attrs(self):
        sub_key = rand_string()
        msg_ids = rand_string(2)

        ctx = RejectCtx(sub_key, msg_ids)

        self.assertEquals(ctx.sub_key, sub_key)
        self.assertEquals(ctx.msg_ids, msg_ids)

        msg_id = rand_string()
        ctx.append(msg_id)

        self.assertEquals(ctx.msg_ids, msg_ids)

# ################################################################################################################################

    def test_client_defaults(self):
        id, name = rand_int(), rand_string()
        client = Client(id, name)

        self.assertEquals(client.id, id)
        self.assertEquals(client.name, name)
        self.assertEquals(client.is_active, True)

    def test_client_custom_attrs(self):
        id, name, is_active = rand_int(), rand_string(), rand_bool()
        client = Client(id, name, is_active)

        self.assertEquals(client.id, id)
        self.assertEquals(client.name, name)
        self.assertEquals(client.is_active, is_active)

# ################################################################################################################################

    def test_consumer_defaults(self):
        id, name = rand_int(), rand_string()
        consumer = Consumer(id, name)

        self.assertEquals(consumer.id, id)
        self.assertEquals(consumer.name, name)
        self.assertEquals(consumer.is_active, True)
        self.assertEquals(consumer.sub_key, None)
        self.assertEquals(consumer.max_backlog, PUB_SUB.DEFAULT_MAX_BACKLOG)
        self.assertEquals(consumer.delivery_mode, PUB_SUB.DELIVERY_MODE.PULL.id)
        self.assertEquals(consumer.callback_id, '')

    def test_consumer_custom_attrs(self):
        id = rand_int()
        name = rand_string()
        is_active = rand_bool()
        sub_key = rand_string()
        max_backlog = rand_int()
        delivery_mode = rand_string()
        callback_id = rand_int()
        consumer = Consumer(id, name, is_active, sub_key, max_backlog, delivery_mode, callback_id)

        self.assertEquals(consumer.id, id)
        self.assertEquals(consumer.name, name)
        self.assertEquals(consumer.is_active, is_active)
        self.assertEquals(consumer.sub_key, sub_key)
        self.assertEquals(consumer.max_backlog, max_backlog)
        self.assertEquals(consumer.delivery_mode, delivery_mode)
        self.assertEquals(consumer.callback_id, callback_id)

# ################################################################################################################################

    def test_message_defaults(self):
        msg = self._get_object(Message)
        self.assertEquals(msg.payload, '')
        self.assertEquals(msg.topic, None)
        self.assertEquals(msg.mime_type, PUB_SUB.DEFAULT_MIME_TYPE)
        self.assertEquals(msg.priority, PUB_SUB.DEFAULT_PRIORITY)
        self.assertEquals(msg.expiration, PUB_SUB.DEFAULT_EXPIRATION)
        self.assertEquals(len(msg.msg_id), CID_LENGTH+1) # +1 because CID_LENGTH doesn't take the 'K' prefix into account
        self.assertEquals(msg.producer, None)
        self.assertEquals(msg.expiration, PUB_SUB.DEFAULT_EXPIRATION)

        self.assertIsInstance(msg.creation_time_utc, datetime)
        self.assertLess(msg.creation_time_utc, datetime.utcnow())

        self.assertIsInstance(msg.expire_at_utc, datetime)
        self.assertGreater(msg.expire_at_utc, datetime.utcnow())

        # Used by frontend only
        self.assertEquals(msg.expire_at, None)
        self.assertEquals(msg.payload_html, None)

    def test_message_serialization(self):
        msg_id = rand_string()
        creation_time_utc = rand_date_utc()
        expire_at_utc = rand_date_utc()
        producer = rand_string()
        topic = rand_string()

        actual = self._get_object(Message, {
            'msg_id': msg_id,
            'creation_time_utc': creation_time_utc,
            'expire_at_utc': expire_at_utc,
            'producer': producer,
            'topic':topic,
        })

        expected = {
            'mime_type': PUB_SUB.DEFAULT_MIME_TYPE,
            'msg_id': msg_id,
            'topic': topic,
            'expiration': PUB_SUB.DEFAULT_EXPIRATION,
            'producer': producer,
            'creation_time_utc': creation_time_utc.isoformat(),
            'priority': PUB_SUB.DEFAULT_PRIORITY,
            'expire_at_utc': expire_at_utc.isoformat()
        }

        # Dicts must be equal ..
        assert_equal(actual.to_dict(), expected)

        # .. as well as JSON.
        json = actual.to_json()
        self.assertIsInstance(json, str)
        unjsonified = loads(json)
        assert_equal(unjsonified, expected)

# ################################################################################################################################

########NEW FILE########
__FILENAME__ = test_full_path
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from json import loads
from logging import getLogger
from operator import attrgetter
from time import sleep

# Arrow
import arrow

# Nose
from nose.tools import eq_

# Zato
from zato.common import PUB_SUB
from zato.common.pubsub import AckCtx, Client, Consumer, GetCtx, Message, PubCtx, RedisPubSub, RejectCtx, SubCtx, Topic
from zato.common.test import rand_int
from zato.common.util import new_cid
from .common import RedisPubSubCommonTestCase

logger = getLogger(__name__)

class RedisPubSubInternalTestCase(RedisPubSubCommonTestCase):

    def _check_unack_counter(self, ps, msg_crm1_id, msg_crm2_id, msg_billing1_id, msg_billing2_id,
            msg_crm1_id_counter, msg_crm2_id_counter, msg_billing1_id_counter, msg_billing2_id_counter
        ):

        unack_counter = self.kvdb.hgetall(ps.UNACK_COUNTER_KEY)
        expected_counters = {}

        if msg_crm1_id:
            expected_counters[msg_crm1_id] = str(msg_crm1_id_counter)

        if msg_crm2_id:
            expected_counters[msg_crm2_id] = str(msg_crm2_id_counter)

        if msg_billing1_id:
            expected_counters[msg_billing1_id] = str(msg_billing1_id_counter)

        if msg_billing2_id:
            expected_counters[msg_billing2_id] = str(msg_billing2_id_counter)

        eq_(sorted(unack_counter.items()), sorted(expected_counters.items()))

# ######################################################################################################################

    def _check_in_flight(self, ps, now, sub_key_crm, sub_key_billing, sub_key_erp, msg_crm1_id, msg_crm2_id,
            msg_billing1_id, msg_billing2_id, crm_needs_billing1_id, crm_needs_billing2_id,
            billing_needs_crm1_id, billing_needs_crm2_id, erp_needs_billing1_id, erp_needs_billing2_id):

        # CRM
        in_flight_crm_ids = self.kvdb.smembers(ps.CONSUMER_IN_FLIGHT_IDS_PREFIX.format(sub_key_crm))
        in_flight_crm_data = self.kvdb.hgetall(ps.CONSUMER_IN_FLIGHT_DATA_PREFIX.format(sub_key_crm))

        if crm_needs_billing1_id:
            in_flight_crm_data_msg1 = in_flight_crm_data[msg_billing1_id]
            self.assertLess(arrow.get(in_flight_crm_data_msg1), now)
            eq_(sorted(in_flight_crm_ids), sorted(in_flight_crm_data.keys()))
        else:
            self.assertNotIn(msg_billing1_id, in_flight_crm_data)

        if crm_needs_billing2_id:
            in_flight_crm_data_msg2 = in_flight_crm_data[msg_billing2_id]
            self.assertLess(arrow.get(in_flight_crm_data_msg2), now)
            eq_(sorted(in_flight_crm_ids), sorted(in_flight_crm_data.keys()))
        else:
            self.assertNotIn(msg_billing2_id, in_flight_crm_data)

        # Billing
        in_flight_billing_ids = self.kvdb.smembers(ps.CONSUMER_IN_FLIGHT_IDS_PREFIX.format(sub_key_billing))
        in_flight_billing_data = self.kvdb.hgetall(ps.CONSUMER_IN_FLIGHT_DATA_PREFIX.format(sub_key_billing))

        if billing_needs_crm1_id:
            in_flight_billing_data_msg1 = in_flight_billing_data[msg_crm1_id]
            self.assertLess(arrow.get(in_flight_billing_data_msg1), now)
            eq_(sorted(in_flight_billing_ids), sorted(in_flight_billing_data.keys()))
        else:
            self.assertNotIn(msg_crm1_id, in_flight_billing_data)

        if billing_needs_crm2_id:
            in_flight_billing_data_msg2 = in_flight_billing_data[msg_crm2_id]
            self.assertLess(arrow.get(in_flight_billing_data_msg2), now)
            eq_(sorted(in_flight_billing_ids), sorted(in_flight_billing_data.keys()))
        else:
            self.assertNotIn(msg_crm2_id, in_flight_billing_data)

        # ERP
        in_flight_erp_ids = self.kvdb.smembers(ps.CONSUMER_IN_FLIGHT_IDS_PREFIX.format(sub_key_erp))
        in_flight_erp_data = self.kvdb.hgetall(ps.CONSUMER_IN_FLIGHT_DATA_PREFIX.format(sub_key_erp))

        if erp_needs_billing1_id:
            in_flight_erp_data_msg1 = in_flight_erp_data[msg_billing1_id]
            self.assertLess(arrow.get(in_flight_erp_data_msg1), now)
            eq_(sorted(in_flight_erp_ids), sorted(in_flight_erp_data.keys()))
        else:
            self.assertNotIn(msg_billing1_id, in_flight_erp_data)

        if erp_needs_billing2_id:
            in_flight_erp_data_msg2 = in_flight_erp_data[msg_billing2_id]
            self.assertLess(arrow.get(in_flight_erp_data_msg2), now)
            eq_(sorted(in_flight_erp_ids), sorted(in_flight_erp_data.keys()))
        else:
            self.assertNotIn(msg_billing2_id, in_flight_erp_data)

# ######################################################################################################################

    def _check_msg_values_metadata(self, ps, msg_crm1_id, msg_crm2_id, msg_billing1_id, msg_billing2_id, before_last_acknowledge):

        # Out of all messages that are expected to be acknowledged, when the last one actually is, there should be
        # less messages in Redis because the last acknowledgment deletes a message's key from msg_values.
        msgs_expected_no = 4 if before_last_acknowledge else 2

        raw_msgs_metadata = self.kvdb.hgetall(ps.MSG_METADATA_KEY)
        eq_(len(raw_msgs_metadata), 4)

        raw_msgs_payload = self.kvdb.hgetall(ps.MSG_VALUES_KEY)
        eq_(len(raw_msgs_payload), msgs_expected_no)

        msgs_metadata = {}
        msgs_payload = {}

        for msg_id, msg_data in raw_msgs_metadata.items():
            msgs_metadata[msg_id] = Message(**loads(msg_data))

        msgs_payload = dict(raw_msgs_payload.items())

        if before_last_acknowledge:
            eq_(msgs_payload[msg_crm1_id], '"msg_crm1"')
            eq_(msgs_payload[msg_crm2_id], '"msg_crm2"')

        eq_(msgs_payload[msg_billing1_id], '"msg_billing1"')
        eq_(msgs_payload[msg_billing2_id], '"msg_billing2"')

        # After acks only billing messages are not acked yet
        expected_msg_ids = (
            msg_crm1_id, msg_crm2_id, msg_billing1_id, msg_billing2_id) if before_last_acknowledge else \
                (msg_billing1_id, msg_billing2_id)

        for msg_id in expected_msg_ids:
            self.assertIn(msg_id, msgs_metadata)

        if before_last_acknowledge:
            msg_crm1 = msgs_metadata[msg_crm1_id]
            msg_crm2 = msgs_metadata[msg_crm2_id]

            eq_(msg_crm1.priority, 1)
            eq_(msg_crm1.mime_type, 'text/xml')
            eq_(msg_crm1.expiration, 0.1)

            eq_(msg_crm2.priority, 2)
            eq_(msg_crm2.mime_type, 'application/json')
            eq_(msg_crm2.expiration, 0.2)

        msg_billing1 = msgs_metadata[msg_billing1_id]
        msg_billing2 = msgs_metadata[msg_billing2_id]

        eq_(msg_billing1.priority, 3)
        eq_(msg_billing1.mime_type, 'application/soap+xml')
        eq_(msg_billing1.expiration, 0.3)

        eq_(msg_billing2.priority, 5)
        eq_(msg_billing2.mime_type, 'text/plain')
        eq_(msg_billing2.expiration, 3600)

# ######################################################################################################################

    def _assert_has_msg_metadata(self, msgs, msg_id, mime_type, priority, expiration):
        for msg in msgs:
            if msg.msg_id == msg_id:
                eq_(msg.mime_type, mime_type, 'mime_type `{}` `{}`'.format(mime_type, msg))
                eq_(msg.priority, priority, 'priority `{}` `{}`'.format(priority, msg))
                eq_(msg.expiration, expiration, 'expiration `{}` `{}`'.format(expiration, msg))
                break
        else:
            raise Exception('Msg with msg_id `{}` not in `{}`'.format(msg_id, msgs))

# ######################################################################################################################

    def test_sub_key_generation(self):
        """ Checks whether a sub_key is generated if none is provided on input during subscribing.
        """
        sub_ctx = SubCtx()
        sub_ctx.client_id = '111'
        sub_ctx.topics = ['aaa']

        ps = RedisPubSub(self.kvdb)
        sub_key = ps.subscribe(sub_ctx)

        # Does it looks like a CID?
        eq_(len(sub_key), 28)
        eq_(sub_key[0], 'K')

    def test_full_path(self):
        """ Tests full sub/pub/ack/reject path with 4 topics and 3 clients. Doesn't test background tasks.
        """
        # Give up early if there is no connection to Redis at all
        if not self.has_redis:
            return

        """ What is tested.

        - 3 clients connect to pub/sub: CRM, Billing and ERP.
        - 4 topics are created: /cust/new, /cust/update, /adsl/new and /adsl/update

        - Subscriptions are:

          - CRM subs to /adsl/new
          - CRM subs to /adsl/update

          - Billing subs to /cust/new
          - Billing subs to /cust/update

          - ERP subs to /adsl/new
          - ERP subs to /adsl/update

        - Publications are:

          - CRM publishes Msg-CRM1 to /cust/new -------------- TTL of 0.1s
          - CRM publishes Msg-CRM2 to /cust/update ----------- TTL of 0.2s

          - Billing publishes Msg-Billing1 to /adsl/new ------ TTL of 0.3s
          - Billing publishes Msg-Billing2 to /adsl/update --- TTL of 3600s

          - (ERP doesn't publish anything)

        - Expected deliveries are:

          - Msg-CRM1 goes to Billing
          - Msg-CRM2 goes to Billing

          - Msg-Billing1 goes to CRM
          - Msg-Billing2 goes to CRM

          - Msg-Billing1 goes to ERP
          - Msg-Billing2 goes to ERP

        - Confirmations are:

          - CRM acks Msg-Billing1
          - CRM rejects Msg-Billing2

          - Billing acks Msg-CRM1
          - Billing acks Msg-CRM2

          - ERP rejects Msg-Billing1
          - ERP acks Msg-Billing2

        - Clean up tasks are

          - Msg-CRM1 is deleted because it's confirmed by its only recipient of Billing
          - Msg-CRM2 is deleted because it's confirmed by its only recipient of Billing

          - Msg-Billing1 is deleted because:

            - CRM confirms it
            - ERP rejects it but the message's TTL is 0.3s so it times out
              (In real world ERP would have possibly acknowledged it in say, 2s, but it would've been too late)

          - Msg-Billing2 is not deleted because:

            - ERP confirms it
            - CRM rejects it and the message's TTL is 3600s so it's still around when a clean up task runs

        """

        ps = RedisPubSub(self.kvdb, self.key_prefix)

        msg_billing1_value = '"msg_billing1"'
        msg_billing2_value = '"msg_billing2"'

        msg_crm1_value = '"msg_crm1"'
        msg_crm2_value = '"msg_crm2"'

        # Check all the Lua programs are loaded

        eq_(len(ps.lua_programs), 9)

        for attr in dir(ps):
            if attr.startswith('LUA'):
                value = getattr(ps, attr)
                self.assertTrue(value in ps.lua_programs, value)

        topic_cust_new = Topic('/cust/new')
        topic_cust_update = Topic('/cust/update')

        topic_adsl_new = Topic('/adsl/new')
        topic_adsl_update = Topic('/adsl/update')

        ps.add_topic(topic_cust_new)
        ps.add_topic(topic_cust_update)

        ps.add_topic(topic_adsl_new)
        ps.add_topic(topic_adsl_update)

        # Check all the topics are cached locally

        eq_(len(ps.topics), 4)

        for topic in(topic_cust_new, topic_cust_update, topic_adsl_new, topic_adsl_update):
            eq_(ps.topics[topic.name], topic)

        client_id_crm = Client('CRM', 'CRM')
        client_id_billing = Client('Billing', 'Billing')
        client_id_erp = Client('ERP', 'ERP')

        ps.add_producer(client_id_crm, topic_cust_new)
        ps.add_producer(client_id_crm, topic_cust_update)

        ps.add_producer(client_id_billing, topic_adsl_new)
        ps.add_producer(client_id_billing, topic_adsl_update)

        # Check producers have been registered for topics

        eq_(len(ps.prod_to_topic), 2)

        self.assertTrue(client_id_crm.id in ps.prod_to_topic)
        self.assertTrue(client_id_billing.id in ps.prod_to_topic)
        self.assertTrue(client_id_erp.id not in ps.prod_to_topic)

        self.assertTrue(isinstance(ps.prod_to_topic[client_id_crm.id], set))
        eq_(sorted(ps.prod_to_topic[client_id_crm.id]), ['/cust/new', '/cust/update'])

        self.assertTrue(isinstance(ps.prod_to_topic[client_id_billing.id], set))
        eq_(sorted(ps.prod_to_topic[client_id_billing.id]), ['/adsl/new', '/adsl/update'])

        # Subscribe all the systems

        sub_ctx_crm = SubCtx()
        sub_ctx_crm.client_id = client_id_crm.id
        sub_ctx_crm.topics = [topic_adsl_new.name, topic_adsl_update.name]

        sub_ctx_billing = SubCtx()
        sub_ctx_billing.client_id = client_id_billing.id
        sub_ctx_billing.topics = [topic_cust_new.name, topic_cust_update.name]

        sub_ctx_erp = SubCtx()
        sub_ctx_erp.client_id = client_id_erp.id
        sub_ctx_erp.topics = [topic_adsl_new.name, topic_adsl_update.name]

        sub_key_crm = 'sub_key_crm'
        sub_key_billing = 'sub_key_billing'
        sub_key_erp = 'sub_key_erp'

        received_sub_key_crm = ps.subscribe(sub_ctx_crm, sub_key_crm)
        received_sub_key_billing = ps.subscribe(sub_ctx_billing, sub_key_billing)
        received_sub_key_erp = ps.subscribe(sub_ctx_erp, sub_key_erp)

        eq_(sub_key_crm, received_sub_key_crm)
        eq_(sub_key_billing, received_sub_key_billing)
        eq_(sub_key_erp, received_sub_key_erp)

        eq_(sorted(ps.sub_to_cons.items()), [('sub_key_billing', 'Billing'), ('sub_key_crm', 'CRM'), ('sub_key_erp', 'ERP')])
        eq_(sorted(ps.cons_to_sub.items()), [('Billing', 'sub_key_billing'), ('CRM', 'sub_key_crm'), ('ERP', 'sub_key_erp')])

        # CRM publishes Msg-CRM1 to /cust/new
        pub_ctx_msg_crm1 = PubCtx()
        pub_ctx_msg_crm1.client_id = client_id_crm.id
        pub_ctx_msg_crm1.topic = topic_cust_new.name
        pub_ctx_msg_crm1.msg = Message(msg_crm1_value, mime_type='text/xml', priority=1, expiration=0.1)

        msg_crm1_id = ps.publish(pub_ctx_msg_crm1).msg.msg_id

        # CRM publishes Msg-CRM2 to /cust/new
        pub_ctx_msg_crm2 = PubCtx()
        pub_ctx_msg_crm2.client_id = client_id_crm.id
        pub_ctx_msg_crm2.topic = topic_cust_update.name
        pub_ctx_msg_crm2.msg = Message(msg_crm2_value,  mime_type='application/json', priority=2, expiration=0.2)

        msg_crm2_id = ps.publish(pub_ctx_msg_crm2).msg.msg_id

        # Billing publishes Msg-Billing1 to /adsl/new
        pub_ctx_msg_billing1 = PubCtx()
        pub_ctx_msg_billing1.client_id = client_id_billing.id
        pub_ctx_msg_billing1.topic = topic_adsl_new.name
        pub_ctx_msg_billing1.msg = Message(msg_billing1_value,  mime_type='application/soap+xml', priority=3, expiration=0.3)

        msg_billing1_id = ps.publish(pub_ctx_msg_billing1).msg.msg_id

        # Billing publishes Msg-Billing2 to /adsl/update
        pub_ctx_msg_billing2 = PubCtx()
        pub_ctx_msg_billing2.client_id = client_id_billing.id
        pub_ctx_msg_billing2.topic = topic_adsl_update.name

        # Nothing except payload and expiration set, defaults should be used
        msg_billing2 = Message(msg_billing2_value, expiration=3600)
        pub_ctx_msg_billing2.msg = msg_billing2

        msg_billing2_id = ps.publish(pub_ctx_msg_billing2).msg.msg_id

        keys = self.kvdb.keys('{}*'.format(self.key_prefix))
        eq_(len(keys), 9)

        expected_keys = [ps.MSG_VALUES_KEY, ps.MSG_EXPIRE_AT_KEY, ps.LAST_PUB_TIME_KEY]
        for topic in topic_cust_new, topic_cust_update, topic_adsl_new, topic_adsl_update:
            expected_keys.append(ps.MSG_IDS_PREFIX.format(topic.name))

        for key in expected_keys:
            self.assertIn(key, keys)

        # Check values of messages published
        self._check_msg_values_metadata(ps, msg_crm1_id, msg_crm2_id, msg_billing1_id, msg_billing2_id, True)

        # Now move the messages just published to each of the subscriber's queue.
        # In a real environment this is done by a background job.
        ps.move_to_target_queues()

        # Now all the messages have been moved we can check if everything is in place
        # ready for subscribers to get their messages.

        keys = self.kvdb.keys('{}*'.format(self.key_prefix))
        eq_(len(keys), 9)

        self.assertIn(ps.UNACK_COUNTER_KEY, keys)
        self.assertIn(ps.MSG_VALUES_KEY, keys)

        for sub_key in(sub_key_crm, sub_key_billing, sub_key_erp):
            key = ps.CONSUMER_MSG_IDS_PREFIX.format(sub_key)
            self.assertIn(key, keys)

        self._check_unack_counter(ps, msg_crm1_id, msg_crm2_id, msg_billing1_id, msg_billing2_id, 1, 1, 2, 2)

        # Check values of messages published are still there
        self._check_msg_values_metadata(ps, msg_crm1_id, msg_crm2_id, msg_billing1_id, msg_billing2_id, True)

        # Check that each recipient has expected message IDs in its respective message queue
        keys = self.kvdb.keys(ps.CONSUMER_MSG_IDS_PREFIX.format('*'))
        eq_(len(keys), 3)

        msg_ids_crm = self.kvdb.lrange(ps.CONSUMER_MSG_IDS_PREFIX.format(sub_key_crm), 0, 100)
        msg_ids_billing = self.kvdb.lrange(ps.CONSUMER_MSG_IDS_PREFIX.format(sub_key_billing), 0, 100)
        msg_ids_erp = self.kvdb.lrange(ps.CONSUMER_MSG_IDS_PREFIX.format(sub_key_erp), 0, 100)

        eq_(len(msg_ids_crm), 2)
        eq_(len(msg_ids_billing), 2)
        eq_(len(msg_ids_erp), 2)

        self.assertIn(msg_billing1_id, msg_ids_crm)
        self.assertIn(msg_billing2_id, msg_ids_crm)

        self.assertIn(msg_billing1_id, msg_ids_erp)
        self.assertIn(msg_billing2_id, msg_ids_erp)

        self.assertIn(msg_crm1_id, msg_ids_billing)
        self.assertIn(msg_crm1_id, msg_ids_billing)

        # Now that the messages are in queues, let's fetch them

        get_ctx_crm = GetCtx()
        get_ctx_crm.sub_key = sub_key_crm

        get_ctx_billing = GetCtx()
        get_ctx_billing.sub_key = sub_key_billing

        get_ctx_erp = GetCtx()
        get_ctx_erp.sub_key = sub_key_erp

        msgs_crm = sorted(list(ps.get(get_ctx_crm)), key=attrgetter('payload'))
        msgs_billing = sorted(list(ps.get(get_ctx_billing)), key=attrgetter('payload'))
        msgs_erp = sorted(list(ps.get(get_ctx_erp)), key=attrgetter('payload'))

        eq_(len(msgs_crm), 2)
        eq_(len(msgs_billing), 2)
        eq_(len(msgs_erp), 2)

        self._assert_has_msg_metadata(msgs_crm, msg_billing1_id, 'application/soap+xml', 3, 0.3)
        self._assert_has_msg_metadata(msgs_crm, msg_billing2_id, 'text/plain', 5, 3600)

        self._assert_has_msg_metadata(msgs_billing, msg_crm1_id, 'text/xml', 1, 0.1)
        self._assert_has_msg_metadata(msgs_billing, msg_crm2_id, 'application/json', 2, 0.2)

        self._assert_has_msg_metadata(msgs_erp, msg_billing1_id, 'application/soap+xml', 3, 0.3)
        self._assert_has_msg_metadata(msgs_erp, msg_billing2_id, 'text/plain', 5, 3600)

        # Check in-flight status for each message got
        keys = self.kvdb.keys(ps.CONSUMER_IN_FLIGHT_DATA_PREFIX.format('*'))
        eq_(len(keys), 3)

        now = arrow.utcnow()

        self._check_in_flight(ps, now, sub_key_crm, sub_key_billing, sub_key_erp, msg_crm1_id, msg_crm2_id,
                msg_billing1_id, msg_billing2_id, True, True, True, True, True, True)

        # Messages should still be undelivered hence their unack counters are not touched at this point
        self._check_unack_counter(ps, msg_crm1_id, msg_crm2_id, msg_billing1_id, msg_billing2_id, 1, 1, 2, 2)

# ######################################################################################################################

        # Messages are fetched, they can be confirmed or rejected now

        # CRM
        ack_ctx_crm = AckCtx()
        ack_ctx_crm.sub_key = sub_key_crm
        ack_ctx_crm.append(msg_billing1_id)

        reject_ctx_crm = RejectCtx()
        reject_ctx_crm.sub_key = sub_key_crm
        reject_ctx_crm.append(msg_billing2_id)

        ps.acknowledge_delete(ack_ctx_crm)
        ps.reject(reject_ctx_crm)

        # One in-flight less
        self._check_in_flight(ps, now, sub_key_crm, sub_key_billing, sub_key_erp, msg_crm1_id, msg_crm2_id,
                msg_billing1_id, msg_billing2_id, False, False, True, True, True, True)

        # Rejections, as with reject_ctx_crm, don't change unack count
        self._check_unack_counter(ps, msg_crm1_id, msg_crm2_id, msg_billing1_id, msg_billing2_id, 1, 1, 1, 2)

        # Billing
        ack_ctx_billing = AckCtx()
        ack_ctx_billing.sub_key = sub_key_billing
        ack_ctx_billing.append(msg_crm1_id)
        ack_ctx_billing.append(msg_crm2_id)

        ps.acknowledge_delete(ack_ctx_billing)

        # Two in-flight less
        self._check_in_flight(ps, now, sub_key_crm, sub_key_billing, sub_key_erp, msg_crm1_id, msg_crm2_id,
                msg_billing1_id, msg_billing2_id, False, False, False, False, True, True)

        # Again, rejections, as with reject_ctx_crm, don't change unack count
        self._check_unack_counter(ps, None, None, msg_billing1_id, msg_billing2_id, 1, 1, 1, 2)

        # ERP
        reject_ctx_erp = RejectCtx()
        reject_ctx_erp.sub_key = sub_key_erp
        reject_ctx_erp.append(msg_billing1_id)

        ack_ctx_erp = AckCtx()
        ack_ctx_erp.sub_key = sub_key_erp
        ack_ctx_erp.append(msg_billing2_id)

        ps.reject(reject_ctx_erp)
        ps.acknowledge_delete(ack_ctx_erp)

        # Another in-flight less
        self._check_in_flight(ps, now, sub_key_crm, sub_key_billing, sub_key_erp, msg_crm1_id, msg_crm2_id,
                msg_billing1_id, msg_billing2_id, False, False, False, False, False, False)

        # And again, rejections, as with reject_ctx_crm, don't change unack count
        self._check_unack_counter(ps, None, None, msg_billing1_id, msg_billing2_id, 1, 1, 1, 1)

        # Sleep for a moment to make sure enough time passes for messages to expire
        sleep(0.4)

        # Deletes everything except for Msg-Billing2 which has a TTL of 3600
        ps.delete_expired()

        keys = self.kvdb.keys('{}*'.format(self.key_prefix))
        eq_(len(keys), 8)

        expected_keys = [ps.MSG_VALUES_KEY, ps.MSG_EXPIRE_AT_KEY, ps.UNACK_COUNTER_KEY, 
                         ps.CONSUMER_MSG_IDS_PREFIX.format(sub_key_crm)]
        for key in expected_keys:
            self.assertTrue(key in keys, 'Key not found `{}` in `{}`'.format(key, keys))

        # Check all the remaining keys - still concerning Msg-Billing2 only
        # because this is the only message that wasn't confirmed nor expired.

        expire_at = self.kvdb.hgetall(ps.MSG_EXPIRE_AT_KEY)
        eq_(len(expire_at), 1)
        eq_(expire_at[msg_billing2_id], msg_billing2.expire_at_utc.isoformat())

        unack_counter = self.kvdb.hgetall(ps.UNACK_COUNTER_KEY)
        eq_(len(unack_counter), 1)
        eq_(unack_counter[msg_billing2_id], '1')

        crm_messages = self.kvdb.lrange(ps.CONSUMER_MSG_IDS_PREFIX.format(sub_key_crm), 0, 100)
        eq_(len(crm_messages), 1)
        eq_(crm_messages[0],msg_billing2_id)

        msg_values = self.kvdb.hgetall(ps.MSG_METADATA_KEY)
        eq_(len(msg_values), 2)
        eq_(sorted(loads(msg_values[msg_billing2_id]).items()), sorted(msg_billing2.to_dict().items()))

# ######################################################################################################################

    def test_delete_from_topic_no_subscribers(self):
        """ Tests deleting of messages from a topic without subscribers.
        """
        ps = RedisPubSub(self.kvdb, self.key_prefix)

        msg_value = '"msg_value"'

        topic = Topic('/test/delete')
        ps.add_topic(topic)

        producer = Client('Producer', 'producer')
        ps.add_producer(producer, topic)

        pub_ctx = PubCtx()
        pub_ctx.client_id = producer.id
        pub_ctx.topic = topic.name
        pub_ctx.msg = Message(msg_value)

        msg_id = ps.publish(pub_ctx).msg.msg_id

        # We've got a msg_id now and we know this is a topic with no subsribers. In that case, deleting a messages should
        # also delete all the metadata related to it along with its payload.

        # First, let's confirm the messages is actually there

        result = self.kvdb.zrange(ps.MSG_IDS_PREFIX.format(topic.name), 0, -1)
        eq_(result, [msg_id])

        result = self.kvdb.hgetall(ps.MSG_VALUES_KEY)
        eq_(len(result), 1)
        self.assertTrue(msg_id in result)

        result = self.kvdb.hgetall(ps.MSG_METADATA_KEY)
        eq_(len(result), 1)
        self.assertTrue(msg_id in result)

        result = self.kvdb.hgetall(ps.MSG_EXPIRE_AT_KEY)
        eq_(len(result), 1)
        self.assertTrue(msg_id in result)

        # Ok, now delete the message and confirm it's not in Redis anymore

        ps.delete_from_topic(topic.name, msg_id)

        result = self.kvdb.zrange(ps.MSG_IDS_PREFIX.format(topic.name), 0, -1)
        eq_(result, [])

        result = self.kvdb.hgetall(ps.MSG_VALUES_KEY)
        eq_({}, result)

        result = self.kvdb.hgetall(ps.MSG_METADATA_KEY)
        eq_({}, result)

        result = self.kvdb.hgetall(ps.MSG_EXPIRE_AT_KEY)
        eq_({}, result)

# ######################################################################################################################

    def test_delete_from_topic_has_subscribers(self):
        """ Tests deleting of messages from a topic which has subscribers.
        """
        ps = RedisPubSub(self.kvdb, self.key_prefix)

        msg_value = '"msg_value"'

        topic = Topic('/test/delete')
        ps.add_topic(topic)

        producer = Client('Producer', 'producer')
        ps.add_producer(producer, topic)

        consumer = Consumer('Consumer', 'consumer', new_cid())
        ps.add_consumer(consumer, topic)

        pub_ctx = PubCtx()
        pub_ctx.client_id = producer.id
        pub_ctx.topic = topic.name
        pub_ctx.msg = Message(msg_value)

        msg_id = ps.publish(pub_ctx).msg.msg_id

        # We've got a msg_id now and we know this is a topic which has a subscriber so deleting a message from the topic
        # should not delete it from any other place because the consumer may still hold onto it.

        # First, let's confirm the messages is actually there

        result = self.kvdb.zrange(ps.MSG_IDS_PREFIX.format(topic.name), 0, -1)
        eq_(result, [msg_id])

        result = self.kvdb.hgetall(ps.MSG_VALUES_KEY)
        eq_(len(result), 1)
        self.assertTrue(msg_id in result)

        result = self.kvdb.hgetall(ps.MSG_METADATA_KEY)
        eq_(len(result), 1)
        self.assertTrue(msg_id in result)

        result = self.kvdb.hgetall(ps.MSG_EXPIRE_AT_KEY)
        eq_(len(result), 1)
        self.assertTrue(msg_id in result)

        # Ok, now delete the message and confirm it's not in the topic anymore however it's still kept elsewhere.

        ps.delete_from_topic(topic.name, msg_id)

        result = self.kvdb.zrange(ps.MSG_IDS_PREFIX.format(topic.name), 0, -1)
        eq_(result, [])

        result = self.kvdb.hgetall(ps.MSG_VALUES_KEY)
        eq_(len(result), 1)
        self.assertTrue(msg_id in result)

        result = self.kvdb.hgetall(ps.MSG_METADATA_KEY)
        eq_(len(result), 1)
        self.assertTrue(msg_id in result)

        result = self.kvdb.hgetall(ps.MSG_EXPIRE_AT_KEY)
        eq_(len(result), 1)
        self.assertTrue(msg_id in result)

# ######################################################################################################################

    def test_ack_delete_from(self):
        """ Tests ack and delete on a consumer's queue.
        """
        # Both ack and delete use the same implementation and it's only the user-exposed API that differs.

        ps = RedisPubSub(self.kvdb, self.key_prefix)

        msg_value = '"msg_value"'

        topic = Topic('/test/delete')
        ps.add_topic(topic)

        producer = Client('Producer', 'producer')
        ps.add_producer(producer, topic)

        consumer = Consumer('Consumer', 'consumer', sub_key=new_cid())
        ps.add_consumer(consumer, topic)

        pub_ctx = PubCtx()
        pub_ctx.client_id = producer.id
        pub_ctx.topic = topic.name
        pub_ctx.msg = Message(msg_value)

        msg_id = ps.publish(pub_ctx).msg.msg_id
        ps.move_to_target_queues()

        # A message has been published and move to a consumer's queue so let's confirm the fact first.
        result = self.kvdb.lrange(ps.CONSUMER_MSG_IDS_PREFIX.format(consumer.sub_key), 0, -1)
        eq_(result, [msg_id])

        # Ok, now delete the message and confirm it's not in the consumer's queue anymore.

        ps.delete_from_consumer_queue(consumer.sub_key, msg_id)

        result = self.kvdb.lrange(ps.CONSUMER_MSG_IDS_PREFIX.format(consumer.sub_key), 0, -1)
        eq_(result, [])

# ######################################################################################################################

    def test_get_callback_consumers(self):
        ps = RedisPubSub(self.kvdb, self.key_prefix)

        msg_value = '"msg_value"'

        topic = Topic('/test/delete')
        ps.add_topic(topic)

        producer = Client('Producer', 'producer')
        ps.add_producer(producer, topic)

        id1 = 'Consumer CB1'
        name1 = 'consumer-cb1'
        sub_key1 = new_cid()
        callback_id1 = rand_int()

        id2 = 'Consumer CB2'
        name2 = 'consumer-cb2'
        sub_key2 = new_cid()
        callback_id2 = rand_int()

        consumer_cb1 = Consumer(id1, name1, sub_key=sub_key1, delivery_mode=PUB_SUB.DELIVERY_MODE.CALLBACK_URL.id,
            callback_id=callback_id1)

        consumer_cb2 = Consumer(id2, name2, sub_key=sub_key2, delivery_mode=PUB_SUB.DELIVERY_MODE.CALLBACK_URL.id,
            callback_id=callback_id2)

        consumer_pull = Consumer('Consumer pull', 'consumer-pull', sub_key=new_cid(), delivery_mode=PUB_SUB.DELIVERY_MODE.PULL.id)
        consumer_inactive = Consumer(
            'Consumer pull', 'consumer-pull', is_active=False, sub_key=new_cid(), delivery_mode=PUB_SUB.DELIVERY_MODE.PULL.id)

        ps.add_consumer(consumer_cb1, topic)
        ps.add_consumer(consumer_cb2, topic)
        ps.add_consumer(consumer_pull, topic)     # This one should not be returned because it's a pull one
        ps.add_consumer(consumer_inactive, topic) # This one should not be returned because it's inactive

        consumers = list(ps.get_callback_consumers())

        # Only 2 are returned, the rest won't make it
        eq_(len(consumers), 2)

        # Sort by each consumer's ID, i.e. in lexicographical order
        consumers.sort(key=attrgetter('id'))

        consumer1 = consumers[0]
        eq_(consumer1.id, id1)
        eq_(consumer1.name, name1)
        eq_(consumer1.is_active, True)
        eq_(consumer1.sub_key, sub_key1)
        eq_(consumer1.callback_id, callback_id1)

        consumer2 = consumers[1]
        eq_(consumer2.id, id2)
        eq_(consumer2.name, name2)
        eq_(consumer2.is_active, True)
        eq_(consumer2.sub_key, sub_key2)
        eq_(consumer2.callback_id, callback_id2)

# ######################################################################################################################

########NEW FILE########
__FILENAME__ = test_common
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from unittest import TestCase

# Nose
from nose.tools import eq_

# Zato
from zato.common import StatsElem

class StatsElemTestCase(TestCase):
    def test_from_json(self):
        item = {
         'usage_perc_all_services': 1.22, 'all_services_time': 4360,
         'time_perc_all_services': 17.64,
         'mean_trend': '0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,769,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0',
         'min_resp_time': 769.0, 'service_name': 'zato.stats.summary.create-summary-by-year',
         'max_resp_time': 769.0, 'rate': 0.0, 'mean_all_services': '63',
         'all_services_usage': 82, 'time': 769.0, 'usage': 1,
         'usage_trend': '0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0',
         'mean': 12.61}
        
        stats_elem = StatsElem.from_json(item)
        
        for k, v in item.items():
            value = getattr(stats_elem, k)
            eq_(v, value)

########NEW FILE########
__FILENAME__ = test_crypto
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from tempfile import NamedTemporaryFile
from unittest import TestCase
from uuid import uuid4

# Nose
from nose.tools import eq_

# Zato
from zato.common.crypto import CryptoManager

# ##############################################################################

# Test keys - note that the private one uses PKCS#8 not PKCS#1.

pub_key = """-----BEGIN PUBLIC KEY-----
MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA5yVNaJJCukjfg7aEslhz
vxRP4rQ6Lt6s0tEdT/1sM2VREsJo2VZY66jrSHJWyTmIQmdYEbJk/gEnVhadQ/n6
YJwrjGY6M6VzTO4D6vLBugaQ60x6nDNAgA2cQ79HPACLLSeyamW1uunV0PqoGbBV
kUQ+G8Ob0IabN6eGcN6OBsc6BSja3VmM++tIn679yE9yUM7LTGr3y2yOUI3dBWz4
RZH3QJPTJcLBY+arh49RIVfLHvwjG+zlKNEXw8AhI9SlmOXP+O03CvwoQxU8zmpe
isKc5rGni2pgn6oaGaLMOlu+bHBT5aZOJt6q1GqHaKviwNb/nIw+GvPiYwSr95t8
bwIDAQAB
-----END PUBLIC KEY-----"""

# ##############################################################################

priv_key = """-----BEGIN PRIVATE KEY-----
MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQDnJU1okkK6SN+D
toSyWHO/FE/itDou3qzS0R1P/WwzZVESwmjZVljrqOtIclbJOYhCZ1gRsmT+ASdW
Fp1D+fpgnCuMZjozpXNM7gPq8sG6BpDrTHqcM0CADZxDv0c8AIstJ7JqZbW66dXQ
+qgZsFWRRD4bw5vQhps3p4Zw3o4GxzoFKNrdWYz760ifrv3IT3JQzstMavfLbI5Q
jd0FbPhFkfdAk9MlwsFj5quHj1EhV8se/CMb7OUo0RfDwCEj1KWY5c/47TcK/ChD
FTzOal6KwpzmsaeLamCfqhoZosw6W75scFPlpk4m3qrUaodoq+LA1v+cjD4a8+Jj
BKv3m3xvAgMBAAECggEAB2HEmBtbsDFVmhJBKKT0hVyztGzHEuofoNf21LAmPXn1
3eCBkrdUPap2YSjtpp2EwYIlaONGoGoPBIvSV/Jq0Z0LMv+syit1hDZxv5YjI7rD
9A/MNqLYY36LyAoaz0rBJx8Gbqly5VZEctkedzuPcAU66o4TstQprtxVydMBvCuf
G20TSE+GlD7fcS4AlEJ7+LebNbAU3aCZ9c0dqthhRmu2xxvIEzCrA5PVcTqw7krn
fqej8Hm3ArfL1YWyV56oaF0SmS4qotm88QHeR6VBgv0KP0AHnaPgRkJTQQvZZ1A0
PrCcgiVQNDCUz6MFiZGj1WVRKLvFS2TzwS2Ei80Y2QKBgQD/YC4f2p0ED6ZbcxJe
n57EhZeWQW2ZKSmELzx4S4bqSo9IAkWu98JVYnN6rP1V0IARN6VVLlTMjM9q37Wq
y6YusNBB8AELYOvEL3g4ImepBQR4xF5N9wfESr87Y9x+DruDeKevBAcLwRCEstHo
/ae7RI2A8h3StJxu7pboaxaLywKBgQDntfViaMS+R3WF0FV3IXdJOnMG5SjYXs+B
NpdMg1dsbhucrHC7unKjBCjSiw0CKtLcFTCR+xc93Jx0lo1aayPR54lEXy58gsGG
WvHeM/TeWEwd+6QXsY7GoqKFQRNt86efgY++mL7lQaCGuz24J1sRtaIafFP/Ig+i
psnGz/UFbQKBgD51qrJVyMN+hGSnj12fUrikKAAy/nhQbfwLhZGyf0v8cnDdRWfW
5yv1CWN+vfNoLHqJjqF31Hu3EOAF2Svt5TZUPotyBP9gdCmmppOsLohTVtWmyZ3u
BnNHCOCguwQF3Gz6bKDMrmB8luqtxdNjfsu5p5ZbIVownHYxWq17y6bjAoGADbfQ
F0tsmndQleOHq83nagZz2OyoRmcWkefRfU4pVtoN+HCdHAAl2VDdudlRo9c1NKJs
hbf/4EG3YY+oPropHLxAfDPGZMi4/GNV/nnE/YTsvLmxNVXlxgzK4mi/5bqPKfpZ
sEcKxjfkcRWUydpKofnG5xqFPo2dr1uAhqy5LOECgYEAsMpk9adcah/axZf30AR8
kDUp83UmxVI4nBPpsJGC92SDuOE7Pr4MzROhPIMum8aBpM6MwwsyQrPF1MxFvyIl
Ckuau69qTi/h6A/DoqpbZ9426khtB7A4zSPYqfhbj4C2LFhC385ZbOhA6Coa7u1s
HtO3lDnY8Qno29yTCP4+GWM=
-----END PRIVATE KEY-----"""

# ##############################################################################

# Plain text and its value after encrypting with the private key
plain_text = 'zato1'
secret = 'T8irIao63mrrSIItl1JDgs8K+9zIXi3OTXYzEHtSpzB9m52Q34LYeeiyYJTvEq8nWb3Lpuav29QuJAfgyPCUgf8RZAWNNkIgmfwsNPAcP4os62i13QGp2Vuxk22QZ7qOjZtMRXncQ8sDgL9JyEo+bphthw8TEdo08I1aGe0iSMg8QQhbwtEGVgdY0286cvSFLbadwNYQCSdadUMlCmtBft2vVUxM/cZGYc5VAgE4ey2KeFgGYVtg7GZjbiWT1JUPKsJESksrvKMmv5SZ9aVBa8Ex/ahIWy+IDPcNKe4MskZrGnqCxWF3+yQYa/1xv0hCw1N7LlW592xDzNWdTALE5A=='

# ##############################################################################

class CryptoTestCase(TestCase):
    
    def test_decrypt_priv_key_in_file(self):
        """ Decrypt a message using a private key from file.
        """
        with NamedTemporaryFile(prefix='zato-test-') as tf:
            tf.write(priv_key)
            tf.flush()
            
            cm = CryptoManager()
            cm.priv_key_location = tf.name
            cm.load_keys()
            
            eq_(plain_text, cm.decrypt(secret))

    def test_decrypt_priv_key_in_string(self):
        """ Decrypt a message using a private key from string.
        """
        cm = CryptoManager()
        cm.priv_key = priv_key
        cm.load_keys()
        
        eq_(plain_text, cm.decrypt(secret))
        
    def test_enrypt(self):
        """ Encrypt a message using the public key.
        """
        _plain_text = uuid4().hex
        
        with NamedTemporaryFile(prefix='zato-test-') as tf_priv:
            with NamedTemporaryFile(prefix='zato-test-') as tf_pub:
                
                tf_priv.write(priv_key)
                tf_priv.flush()
                
                tf_pub.write(pub_key)
                tf_pub.flush()
                
                cm_priv = CryptoManager()
                cm_priv.priv_key_location = tf_priv.name
                cm_priv.load_keys()
                
                cm_pub = CryptoManager()
                cm_pub.pub_key_location = tf_pub.name
                cm_pub.load_keys()
                
                encrypted = cm_pub.encrypt(_plain_text)
                decrypted = cm_priv.decrypt(encrypted)
                
                eq_(_plain_text, decrypted)
        
    def test_reset(self):
        """ Resets all keys to None.
        """
        cm = CryptoManager()
        cm.reset()
        
        eq_(cm.priv_key_location, None)
        eq_(cm.pub_key_location, None)
        eq_(cm.priv_key, None)
        eq_(cm.pub_key, None)

########NEW FILE########
__FILENAME__ = test_delivery
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from unittest import TestCase
from uuid import uuid4

# Nose
from nose.tools import eq_

# SQLAlchemy
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

# Zato
from zato.common.test import ODBTestCase

# ##############################################################################

class MiscTestCase(ODBTestCase):
    def test_null_basic_data(self):
        #self.fail()
        pass
########NEW FILE########
__FILENAME__ = test_kvdb
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from unittest import TestCase
from uuid import uuid4

# Bunch
from bunch import Bunch

# Nose
from nose.tools import eq_

# Zato
from zato.common.kvdb import KVDB
from zato.common.test import rand_string, rand_int

# ##############################################################################

class KVDBTestCase(TestCase):
    def test_parse_config(self):

        class FakeSentinel(object):
            def __init__(self, sentinels, password, socket_timeout):
                self.sentinels = sentinels
                self.password = password
                self.socket_timeout = socket_timeout
                self.master_for_called_with = None

            def master_for(self, master_name):
                self.master_for_called_with = master_name
                return self

        class FakeStrictRedis(object):
            def __init__(self, **config):
                self.config = config

        class FakeKVDB(KVDB):
            def _get_connection_class(self):
                return FakeSentinel if self.has_sentinel else FakeStrictRedis

        def decrypt_func(password):
            return password

        sentinel1_host, sentinel1_port = 'a-' + rand_string(), rand_int()
        sentinel2_host, sentinel2_port = 'b-' + rand_string(), rand_int()

        password = rand_string()
        socket_timeout = rand_int()
        redis_sentinels_master = rand_string()
        redis_sentinels = ['{}:{}'.format(sentinel1_host, sentinel1_port), '{}:{}'.format(sentinel2_host, sentinel2_port)]

        try:
            config = {'use_redis_sentinels': True}
            kvdb = KVDB(config=config)
            kvdb.init()
        except ValueError, e:
            eq_(e.message, 'kvdb.redis_sentinels must be provided')
        else:
            self.fail('Expected a ValueError (kvdb.redis_sentinels)')

        try:
            config = {'use_redis_sentinels': True, 'redis_sentinels': redis_sentinels}
            kvdb = KVDB(config=config)
            kvdb.init()
        except ValueError, e:
            eq_(e.message, 'kvdb.redis_sentinels_master must be provided')
        else:
            self.fail('Expected a ValueError (kvdb.redis_sentinels_master)')

        config = Bunch({
            'use_redis_sentinels': True,
            'redis_sentinels':redis_sentinels,
            'redis_sentinels_master':redis_sentinels_master,
            'password': password,
            'socket_timeout':socket_timeout
        })
        kvdb = FakeKVDB(config=config, decrypt_func=decrypt_func)
        kvdb.init()

        eq_(sorted(kvdb.conn.sentinels), [(sentinel1_host, sentinel1_port), (sentinel2_host, sentinel2_port)])

        eq_(kvdb.conn.password, password)
        eq_(kvdb.conn.socket_timeout, socket_timeout)
        eq_(kvdb.conn.master_for_called_with, redis_sentinels_master)

        config = {'use_redis_sentinels': False}
        kvdb = FakeKVDB(config=config, decrypt_func=decrypt_func)
        kvdb.init()

        self.assertTrue(isinstance(kvdb.conn, FakeStrictRedis))
########NEW FILE########
__FILENAME__ = test_util
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from unittest import TestCase
from uuid import uuid4

# lxml
from lxml import etree

# Zato
from zato.common import ParsingException, soap_body_xpath, zato_path
from zato.common import util

class ZatoPathTestCase(TestCase):
    def test_zato_path(self):
        xml = etree.fromstring("""<soap:Envelope xmlns:soap="http://schemas.xmlsoap.org/soap/envelope/"
         xmlns="https://zato.io/ns/20130518">
      <soap:Body>
            <zato_channel_amqp_edit_response xmlns="https://zato.io/ns/20130518">
               <zato_env>
                  <cid>K08984532360785332835581231451</cid>
                  <result>ZATO_OK</result>
               </zato_env>
               <item>
                  <id>1</id>
                  <name>crm.account</name>
               </item>
            </zato_channel_amqp_edit_response>
      </soap:Body>
   </soap:Envelope>""")

        request = soap_body_xpath(xml)[0].getchildren()[0]
        zato_path('item', True).get_from(request)
        
        path = uuid4().hex
        try:
            zato_path(path, True).get_from(request)
        except ParsingException:
            pass
        else:
            raise AssertionError('Expected an ParsingException with path:[{}]'.format(path))


class UtilsTestCase(TestCase):
    def test_uncamelify(self):
        original = 'ILikeToReadWSDLDocsNotReallyNOPENotMeQ'
        expected1 = 'i-like-to-read-wsdl-docs-not-really-nope-not-me-q'
        expected2 = 'I_LIKE_TO_READ_WSDL_DOCS_NOT_REALLY_NOPE_NOT_ME_Q'
        
        self.assertEquals(util.uncamelify(original), expected1)
        self.assertEquals(util.uncamelify(original, '_', unicode.upper), expected2)

class XPathTestCase(TestCase):
    def test_validate_xpath(self):
        self.assertRaises(etree.XPathSyntaxError, util.validate_xpath, 'a b c')
        self.assertTrue(util.validate_xpath('//node'))
########NEW FILE########
__FILENAME__ = parallel
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging, os, time, signal
from datetime import datetime
from hashlib import sha1
from httplib import INTERNAL_SERVER_ERROR, responses
from logging import INFO
from threading import Thread
from traceback import format_exc
from uuid import uuid4

# anyjson
from anyjson import dumps

# arrow
from arrow import utcnow

# Bunch
from bunch import Bunch

# faulthandler
import faulthandler

# parse
from parse import compile as parse_compile

# Paste
from paste.util.converters import asbool
from paste.util.multidict import MultiDict

# pytz
from pytz import UTC

# Spring Python
from springpython.context import DisposableObject

# retools
from retools.lock import Lock

# tzlocal
from tzlocal import get_localzone

# Zato
from zato.broker.client import BrokerClient
from zato.common import ACCESS_LOG_DT_FORMAT, CHANNEL, KVDB, MISC, SERVER_JOIN_STATUS, SERVER_UP_STATUS,\
     ZATO_ODB_POOL_NAME
from zato.common.broker_message import AMQP_CONNECTOR, code_to_name, HOT_DEPLOY,\
     JMS_WMQ_CONNECTOR, MESSAGE_TYPE, SERVICE, TOPICS, ZMQ_CONNECTOR
from zato.common.pubsub import PubSubAPI, RedisPubSub
from zato.common.util import add_startup_jobs, get_kvdb_config_for_log, make_psycopg_green, new_cid, register_diag_handlers
from zato.server.base import BrokerMessageReceiver
from zato.server.base.worker import WorkerStore
from zato.server.config import ConfigDict, ConfigStore
from zato.server.connection.amqp.channel import start_connector as amqp_channel_start_connector
from zato.server.connection.amqp.outgoing import start_connector as amqp_out_start_connector
from zato.server.connection.jms_wmq.channel import start_connector as jms_wmq_channel_start_connector
from zato.server.connection.jms_wmq.outgoing import start_connector as jms_wmq_out_start_connector
from zato.server.connection.zmq_.channel import start_connector as zmq_channel_start_connector
from zato.server.connection.zmq_.outgoing import start_connector as zmq_outgoing_start_connector
from zato.server.pickup import get_pickup

logger = logging.getLogger(__name__)
kvdb_logger = logging.getLogger('zato_kvdb')

class ParallelServer(DisposableObject, BrokerMessageReceiver):
    def __init__(self):
        self.host = None
        self.port = None
        self.crypto_manager = None
        self.odb = None
        self.odb_data = None
        self.singleton_server = None
        self.config = None
        self.repo_location = None
        self.sql_pool_store = None
        self.int_parameters = None
        self.int_parameter_suffixes = None
        self.bool_parameter_prefixes = None
        self.soap11_content_type = None
        self.soap12_content_type = None
        self.plain_xml_content_type = None
        self.json_content_type = None
        self.internal_service_modules = None # Zato's own internal services
        self.service_modules = None # Set programmatically in Spring
        self.service_sources = None # Set in a config file
        self.base_dir = None
        self.hot_deploy_config = None
        self.pickup = None
        self.fs_server_config = None
        self.connector_server_grace_time = None
        self.id = None
        self.name = None
        self.cluster_id = None
        self.kvdb = None
        self.startup_jobs = None
        self.worker_store = None
        self.deployment_lock_expires = None
        self.deployment_lock_timeout = None
        self.app_context = None
        self.has_gevent = None
        self.delivery_store = None

        self.access_logger = logging.getLogger('zato_access_log')

        # The main config store
        self.config = ConfigStore()

    def set_tls_info(self, wsgi_environ):
        wsgi_environ['zato.tls.client_cert.dict'] = wsgi_environ['gunicorn.socket'].getpeercert()

        if wsgi_environ['zato.tls.client_cert.dict']:
            wsgi_environ['zato.tls.client_cert.der'] = wsgi_environ['gunicorn.socket'].getpeercert(True)
            wsgi_environ['zato.tls.client_cert.sha1'] = sha1(wsgi_environ['zato.tls.client_cert.der']).hexdigest().upper()
        else:
            wsgi_environ['zato.tls.client_cert.der'] = None
            wsgi_environ['zato.tls.client_cert.sha1'] = None

        return wsgi_environ

    def on_wsgi_request(self, wsgi_environ, start_response, **kwargs):
        """ Handles incoming HTTP requests.
        """
        cid = kwargs.get('cid', new_cid())

        wsgi_environ['zato.local_tz'] = get_localzone()
        wsgi_environ['zato.request_timestamp_utc'] = utcnow()

        local_dt = wsgi_environ['zato.request_timestamp_utc'].replace(tzinfo=UTC).astimezone(wsgi_environ['zato.local_tz'])
        wsgi_environ['zato.request_timestamp'] = wsgi_environ['zato.local_tz'].normalize(local_dt)

        wsgi_environ['zato.http.response.headers'] = {'X-Zato-CID': cid}
        wsgi_environ['zato.http.remote_addr'] = wsgi_environ.get('HTTP_X_FORWARDED_FOR') or wsgi_environ.get('REMOTE_ADDR')

        try:
            # We need to populate all the TLS-related environ keys so that
            # lower layers can possibly use them for authentication and authorization.
            # But we're not doing it if we are sure it wasn't an HTTPS call.
            if wsgi_environ['wsgi.url_scheme'] == 'https':
                self.set_tls_info(wsgi_environ)

            payload = self.worker_store.request_dispatcher.dispatch(
                cid, datetime.utcnow(), wsgi_environ, self.worker_store) or b''

        # Any exception at this point must be our fault
        except Exception, e:
            tb = format_exc(e)
            wsgi_environ['zato.http.response.status'] = b'{} {}'.format(INTERNAL_SERVER_ERROR, responses[INTERNAL_SERVER_ERROR])
            error_msg = b'[{0}] Exception caught [{1}]'.format(cid, tb)
            logger.error(error_msg)
            payload = error_msg
            raise

        # Note that this call is asynchronous and we do it the last possible moment.
        if wsgi_environ['zato.http.channel_item'] and wsgi_environ['zato.http.channel_item'].get('audit_enabled'):
            self.worker_store.request_dispatcher.url_data.audit_set_response(
                cid, payload, wsgi_environ)

        headers = ((k.encode('utf-8'), v.encode('utf-8')) for k, v in wsgi_environ['zato.http.response.headers'].items())
        start_response(wsgi_environ['zato.http.response.status'], headers)

        if isinstance(payload, unicode):
            payload = payload.encode('utf-8')

        if self.access_logger.isEnabledFor(INFO):

            channel_item = wsgi_environ.get('zato.http.channel_item')
            if channel_item:
                channel_name = channel_item.get('name', '-')
            else:
                channel_name = '-'

            self.access_logger.info('', extra = {
                'remote_ip': wsgi_environ['zato.http.remote_addr'],
                'cid': cid,
                'channel_name': channel_name,
                'req_timestamp_utc': wsgi_environ['zato.request_timestamp_utc'].strftime(ACCESS_LOG_DT_FORMAT),
                'req_timestamp': wsgi_environ['zato.request_timestamp'].strftime(ACCESS_LOG_DT_FORMAT),
                'method': wsgi_environ['REQUEST_METHOD'],
                'path': wsgi_environ['PATH_INFO'],
                'http_version': wsgi_environ['SERVER_PROTOCOL'],
                'status_code': wsgi_environ['zato.http.response.status'].split()[0],
                'response_size': len(payload),
                'user_agent': wsgi_environ['HTTP_USER_AGENT'],
                })

        return [payload]

    def maybe_on_first_worker(self, server, redis_conn, deployment_key):
        """ This method will execute code with a Redis lock held. We need a lock
        because we can have multiple worker processes fighting over the right to
        redeploy services. The first worker to grab the lock will actually perform
        the redeployment and set a flag meaning that for this particular deployment
        key (and remember that each server restart means a new deployment key)
        the services have been already deployed. Later workers will check that
        the flag exists and will skip the deployment altogether.

        The first worker to be started will also start a singleton thread later on,
        outside this method but basing on whether the method returns True or not.
        """
        def import_initial_services_jobs():
            # (re-)deploy the services from a clear state
            self.service_store.import_services_from_anywhere(
                self.internal_service_modules + self.service_modules +
                self.service_sources, self.base_dir)

            # Add the statistics-related scheduler jobs to the ODB
            add_startup_jobs(self.cluster_id, self.odb, self.startup_jobs)

        lock_name = '{}{}:{}'.format(KVDB.LOCK_SERVER_STARTING, self.fs_server_config.main.token, deployment_key)
        already_deployed_flag = '{}{}:{}'.format(KVDB.LOCK_SERVER_ALREADY_DEPLOYED,
            self.fs_server_config.main.token, deployment_key)

        logger.debug('Will use the lock_name: [{}]'.format(lock_name))

        with Lock(lock_name, self.deployment_lock_expires, self.deployment_lock_timeout, redis_conn):
            if redis_conn.get(already_deployed_flag):
                # There has been already the first worker who's done everything
                # there is to be done so we may just return.
                msg = 'Not attempting to grab the lock_name:[{}]'.format(lock_name)
                logger.debug(msg)

                # Simply deploy services, the first worker has already cleared out the ODB
                import_initial_services_jobs()
            else:
                # We are this server's first worker so we need to re-populate
                # the database and create the flag indicating we're done.
                msg = 'Got Redis lock_name:[{}], expires:[{}], timeout:[{}]'.format(
                    lock_name, self.deployment_lock_expires, self.deployment_lock_timeout)
                logger.debug(msg)

                # .. Remove all the deployed services from the DB ..
                self.odb.drop_deployed_services(server.id)

                # .. deploy them back.
                import_initial_services_jobs()

                # Add the flag to Redis indicating that this server has already
                # deployed its services. Note that by default the expiration
                # time is more than a century in the future. It will be cleared out
                # next time the server will be started. This also means that when
                # a process dies and it's the one holding the singleton thread,
                # no other process will be able to start the singleton thread
                # until the server is fully restarted so that the locks are cleared.

                redis_conn.set(already_deployed_flag, dumps({'create_time_utc':datetime.utcnow().isoformat()}))
                redis_conn.expire(already_deployed_flag, self.deployment_lock_expires)

                return True

    def get_lua_programs(self):
        for item in 'internal', 'user':
            dir_name = os.path.join(self.repo_location, 'lua', item)
            for file_name in os.listdir(dir_name):

                lua_idx = file_name.find('.lua')
                name = file_name[0:lua_idx] if lua_idx else file_name
                program = open(os.path.join(dir_name, file_name)).read()

                yield [name, program]

    def _after_init_common(self, server, deployment_key):
        """ Initializes parts of the server that don't depend on whether the
        server's been allowed to join the cluster or not.
        """
        self.worker_store = WorkerStore(self.config, self)

        # Key-value DB
        kvdb_config = get_kvdb_config_for_log(self.fs_server_config.kvdb)
        kvdb_logger.info('Worker config `%s`', kvdb_config)

        self.kvdb.config = self.fs_server_config.kvdb
        self.kvdb.server = self
        self.kvdb.decrypt_func = self.crypto_manager.decrypt
        self.kvdb.init()

        kvdb_logger.info('Worker config `%s`', kvdb_config)

        # Lua programs, both internal and user defined ones.
        for name, program in self.get_lua_programs():
            self.kvdb.lua_container.add_lua_program(name, program)

        # Service sources
        self.service_sources = []
        for name in open(os.path.join(self.repo_location, self.fs_server_config.main.service_sources)):
            name = name.strip()
            if name and not name.startswith('#'):
                self.service_sources.append(name)

        # Normalize hot-deploy configuration
        self.hot_deploy_config = Bunch()

        self.hot_deploy_config.work_dir = os.path.normpath(os.path.join(
            self.repo_location, self.fs_server_config.hot_deploy.work_dir))

        self.hot_deploy_config.backup_history = int(self.fs_server_config.hot_deploy.backup_history)
        self.hot_deploy_config.backup_format = self.fs_server_config.hot_deploy.backup_format

        for name in('current_work_dir', 'backup_work_dir', 'last_backup_work_dir', 'delete_after_pick_up'):

            # New in 2.0
            if name == 'delete_after_pick_up':
                value = asbool(self.fs_server_config.hot_deploy.get(name, True))
                self.hot_deploy_config[name] = value
            else:
                self.hot_deploy_config[name] = os.path.normpath(os.path.join(
                  self.hot_deploy_config.work_dir, self.fs_server_config.hot_deploy[name]))

        is_first = self.maybe_on_first_worker(server, self.kvdb.conn, deployment_key)

        # Broker callbacks
        broker_callbacks = {
            TOPICS[MESSAGE_TYPE.TO_PARALLEL_ANY]: self.worker_store.on_broker_msg,
            TOPICS[MESSAGE_TYPE.TO_PARALLEL_ALL]: self.worker_store.on_broker_msg,
            }

        if is_first:
            broker_callbacks[TOPICS[MESSAGE_TYPE.TO_SINGLETON]] = self.on_broker_msg_singleton

        self.broker_client = BrokerClient(self.kvdb, 'parallel', broker_callbacks, self.get_lua_programs())

        if is_first:

            self.singleton_server = self.app_context.get_object('singleton_server')
            self.singleton_server.initial_sleep_time = int(self.fs_server_config.singleton.initial_sleep_time) / 1000.0
            self.singleton_server.parallel_server = self

            pickup_dir = self.fs_server_config.hot_deploy.pickup_dir
            if not os.path.isabs(pickup_dir):
                pickup_dir = os.path.join(self.repo_location, pickup_dir)

            self.singleton_server.pickup = get_pickup(self.has_gevent)
            self.singleton_server.pickup.pickup_dir = pickup_dir
            self.singleton_server.pickup.pickup_event_processor.pickup_dir = pickup_dir
            self.singleton_server.pickup.pickup_event_processor.server = self.singleton_server

            kwargs = {'broker_client':self.broker_client}
            Thread(target=self.singleton_server.run, kwargs=kwargs).start()

            # Let the scheduler fully initialize
            self.singleton_server.scheduler.wait_for_init()
            self.singleton_server.server_id = server.id

        return is_first

    def _after_init_accepted(self, server, deployment_key):

        # Pub/sub
        self.pubsub = PubSubAPI(RedisPubSub(self.kvdb.conn))

        # Repo location so that AMQP subprocesses know where to read
        # the server's configuration from.
        self.config.repo_location = self.repo_location

        # 
        # Cloud - start
        #

        # OpenStack - Swift

        query = self.odb.get_cloud_openstack_swift_list(server.cluster.id, True)
        self.config.cloud_openstack_swift = ConfigDict.from_query('cloud_openstack_swift', query)

        query = self.odb.get_cloud_aws_s3_list(server.cluster.id, True)
        self.config.cloud_aws_s3 = ConfigDict.from_query('cloud_aws_s3', query)

        # 
        # Cloud - end
        #

        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        #
        # Outgoing connections - start
        #

        # FTP
        query = self.odb.get_out_ftp_list(server.cluster.id, True)
        self.config.out_ftp = ConfigDict.from_query('out_ftp', query)

        # Plain HTTP
        query = self.odb.get_http_soap_list(server.cluster.id, 'outgoing', 'plain_http', True)
        self.config.out_plain_http = ConfigDict.from_query('out_plain_http', query)

        # SOAP
        query = self.odb.get_http_soap_list(server.cluster.id, 'outgoing', 'soap', True)
        self.config.out_soap = ConfigDict.from_query('out_soap', query)

        # SQL
        query = self.odb.get_out_sql_list(server.cluster.id, True)
        self.config.out_sql = ConfigDict.from_query('out_sql', query)

        # AMQP
        query = self.odb.get_out_amqp_list(server.cluster.id, True)
        self.config.out_amqp = ConfigDict.from_query('out_amqp', query)

        # JMS WMQ
        query = self.odb.get_out_jms_wmq_list(server.cluster.id, True)
        self.config.out_jms_wmq = ConfigDict.from_query('out_jms_wmq', query)

        # ZMQ
        query = self.odb.get_out_zmq_list(server.cluster.id, True)
        self.config.out_zmq = ConfigDict.from_query('out_zmq', query)

        #
        # Outgoing connections - end
        #

        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        #
        # Notifications - start
        #

        # OpenStack Swift
        query = self.odb.get_notif_cloud_openstack_swift(server.cluster.id, True)
        self.config.notif_cloud_openstack_swift = ConfigDict.from_query('notif_cloud_openstack_swift', query)

        #
        # Notifications - end
        #

        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        #
        # Security - start
        #

        # API keys
        query = self.odb.get_apikey_security_list(server.cluster.id, True)
        self.config.apikey = ConfigDict.from_query('apikey', query)

        # AWS
        query = self.odb.get_aws_security_list(server.cluster.id, True)
        self.config.aws = ConfigDict.from_query('aws', query)

        # HTTP Basic Auth
        query = self.odb.get_basic_auth_list(server.cluster.id, True)
        self.config.basic_auth = ConfigDict.from_query('basic_auth', query)

        # NTLM
        query = self.odb.get_ntlm_list(server.cluster.id, True)
        self.config.ntlm = ConfigDict.from_query('ntlm', query)

        # OAuth
        query = self.odb.get_oauth_list(server.cluster.id, True)
        self.config.oauth = ConfigDict.from_query('oauth', query)

        # OpenStack
        query = self.odb.get_openstack_security_list(server.cluster.id, True)
        self.config.openstack_security = ConfigDict.from_query('openstack_security', query)

        # Technical accounts
        query = self.odb.get_tech_acc_list(server.cluster.id, True)
        self.config.tech_acc = ConfigDict.from_query('tech_acc', query)

        # WS-Security
        query = self.odb.get_wss_list(server.cluster.id, True)
        self.config.wss = ConfigDict.from_query('wss', query)

        # XPath
        query = self.odb.get_xpath_sec_list(server.cluster.id, True)
        self.config.xpath_sec = ConfigDict.from_query('xpath_sec', query)

        #
        # Security - end
        #

        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        # All the HTTP/SOAP channels.
        http_soap = []
        for item in self.odb.get_http_soap_list(server.cluster.id, 'channel'):

            hs_item = Bunch()
            for key in item.keys():
                hs_item[key] = getattr(item, key)

            hs_item.replace_patterns_json_pointer = item.replace_patterns_json_pointer
            hs_item.replace_patterns_xpath = item.replace_patterns_xpath

            hs_item.match_target = '{}{}{}'.format(hs_item.soap_action, MISC.SEPARATOR, hs_item.url_path)
            hs_item.match_target_compiled = parse_compile(hs_item.match_target)

            http_soap.append(hs_item)

        self.config.http_soap = http_soap

        # Namespaces
        query = self.odb.get_namespace_list(server.cluster.id, True)
        self.config.msg_ns = ConfigDict.from_query('msg_ns', query)

        # XPath
        query = self.odb.get_xpath_list(server.cluster.id, True)
        self.config.xpath = ConfigDict.from_query('msg_xpath', query)

        # JSON Pointer
        query = self.odb.get_json_pointer_list(server.cluster.id, True)
        self.config.json_pointer = ConfigDict.from_query('json_pointer', query)

        # SimpleIO
        self.config.simple_io = ConfigDict('simple_io', Bunch())
        self.config.simple_io['int_parameters'] = self.int_parameters
        self.config.simple_io['int_parameter_suffixes'] = self.int_parameter_suffixes
        self.config.simple_io['bool_parameter_prefixes'] = self.bool_parameter_prefixes

        # Pub/sub config
        self.config.pubsub = Bunch()
        self.config.pubsub.default_consumer = Bunch()
        self.config.pubsub.default_producer = Bunch()

        query = self.odb.get_pubsub_topic_list(server.cluster.id, True)
        self.config.pubsub.topics = ConfigDict.from_query('pubsub_topics', query)

        id, name = self.odb.get_pubsub_default_client(server.cluster.id, 'zato.pubsub.default-consumer')
        self.config.pubsub.default_consumer.id, self.config.pubsub.default_consumer.name = id, name

        id, name = self.odb.get_pubsub_default_client(server.cluster.id, 'zato.pubsub.default-producer')
        self.config.pubsub.default_producer.id, self.config.pubsub.default_producer.name = id, name

        query = self.odb.get_pubsub_producer_list(server.cluster.id, True)
        self.config.pubsub.producers = ConfigDict.from_query('pubsub_producers', query, list_config=True)

        query = self.odb.get_pubsub_consumer_list(server.cluster.id, True)
        self.config.pubsub.consumers = ConfigDict.from_query('pubsub_consumers', query, list_config=True)

        # Assign config to worker
        self.worker_store.worker_config = self.config
        self.worker_store.broker_client = self.broker_client
        self.worker_store.pubsub = self.pubsub
        self.worker_store.init()

        if self.singleton_server:

            self.singleton_server.wait_for_worker()

            # Let's see if we can become a connector server, the one to start all
            # the connectors, and start the connectors only once throughout the whole cluster.
            self.connector_server_keep_alive_job_time = int(
                self.fs_server_config.singleton.connector_server_keep_alive_job_time)
            self.connector_server_grace_time = int(
                self.fs_server_config.singleton.grace_time_multiplier) * self.connector_server_keep_alive_job_time

            if self.singleton_server.become_cluster_wide(
                    self.connector_server_keep_alive_job_time, self.connector_server_grace_time,
                    server.id, server.cluster_id, True):
                self.init_connectors()

                for(_, name, is_active, job_type, start_date, extra, service_name, _,
                    _, weeks, days, hours, minutes, seconds, repeats, cron_definition)\
                        in self.odb.get_job_list(server.cluster.id):
                    if is_active:
                        job_data = Bunch({'name':name, 'is_active':is_active,
                            'job_type':job_type, 'start_date':start_date,
                            'extra':extra, 'service':service_name, 'weeks':weeks,
                            'days':days, 'hours':hours, 'minutes':minutes,
                            'seconds':seconds, 'repeats':repeats,
                            'cron_definition':cron_definition})
                        self.singleton_server.scheduler.create_edit('create', job_data)

        # Signal to ODB that we are done with deploying everything
        self.odb.on_deployment_finished()

    def init_connectors(self):
        """ Starts all the connector subprocesses.
        """
        logger.info('Initializing connectors')

        # AMQP - channels
        channel_amqp_list = self.odb.get_channel_amqp_list(self.cluster_id)
        if channel_amqp_list:
            for item in channel_amqp_list:
                if item.is_active:
                    amqp_channel_start_connector(self.repo_location, item.id, item.def_id)
                else:
                    logger.info('Not starting an inactive channel (AMQP {})'.format(item.name))

        else:
            logger.info('No AMQP channels to start')

        # AMQP - outgoing
        out_amqp_list = self.odb.get_out_amqp_list(self.cluster_id)
        if out_amqp_list:
            for item in out_amqp_list:
                if item.is_active:
                    amqp_out_start_connector(self.repo_location, item.id, item.def_id)
                else:
                    logger.info('Not starting an inactive outgoing connection (AMQP {})'.format(item.name))
        else:
            logger.info('No AMQP outgoing connections to start')

        # JMS WMQ - channels
        channel_jms_wmq_list = self.odb.get_channel_jms_wmq_list(self.cluster_id)
        if channel_jms_wmq_list:
            for item in channel_jms_wmq_list:
                if item.is_active:
                    jms_wmq_channel_start_connector(self.repo_location, item.id, item.def_id)
                else:
                    logger.info('Not starting an inactive channel (JMS WebSphere MQ {})'.format(item.name))
        else:
            logger.info('No JMS WebSphere MQ channels to start')

        # JMS WMQ - outgoing
        out_jms_wmq_list = self.odb.get_out_jms_wmq_list(self.cluster_id)
        if out_jms_wmq_list:
            for item in out_jms_wmq_list:
                if item.is_active:
                    jms_wmq_out_start_connector(self.repo_location, item.id, item.def_id)
                else:
                    logger.info('Not starting an inactive outgoing connection (JMS WebSphere MQ {})'.format(item.name))
        else:
            logger.info('No JMS WebSphere MQ outgoing connections to start')

        # ZMQ - channels
        channel_zmq_list = self.odb.get_channel_zmq_list(self.cluster_id)
        if channel_zmq_list:
            for item in channel_zmq_list:
                if item.is_active:
                    zmq_channel_start_connector(self.repo_location, item.id)
                else:
                    logger.info('Not starting an inactive channel (ZeroMQ {})'.format(item.name))
        else:
            logger.info('No Zero MQ channels to start')

        # ZMQ - outgoing
        out_zmq_list = self.odb.get_out_zmq_list(self.cluster_id)
        if out_zmq_list:
            for item in out_zmq_list:
                if item.is_active:
                    logger.error(item)
                    zmq_outgoing_start_connector(self.repo_location, item.id)
                else:
                    logger.info('Not starting an inactive outgoing connection (ZeroMQ {})'.format(item.name))
        else:
            logger.info('No Zero MQ outgoing connections to start')

    def _after_init_non_accepted(self, server):
        raise NotImplementedError("This Zato version doesn't support join states other than ACCEPTED")

    def get_config_odb_data(self, parallel_server):
        """ Returns configuration with regards to ODB data.
        """
        odb_data = Bunch()
        odb_data.db_name = parallel_server.odb_data['db_name']
        odb_data.extra = parallel_server.odb_data['extra']
        odb_data.engine = parallel_server.odb_data['engine']
        odb_data.token = parallel_server.fs_server_config.main.token
        odb_data.is_odb = True

        if odb_data.engine != 'sqlite':
            odb_data.password = parallel_server.crypto_manager.decrypt(parallel_server.odb_data['password'])
            odb_data.host = parallel_server.odb_data['host']
            odb_data.port = parallel_server.odb_data['port']
            odb_data.engine = parallel_server.odb_data['engine']
            odb_data.pool_size = parallel_server.odb_data['pool_size']
            odb_data.username = parallel_server.odb_data['username']

        # Note that we don't read is_active off of anywhere - ODB always must
        # be active and it's not a regular connection pool anyway.
        odb_data.is_active = True

        return odb_data

    def set_odb_pool(self):
        # This is the call that creates an SQLAlchemy connection
        self.sql_pool_store[ZATO_ODB_POOL_NAME] = self.config.odb_data
        self.odb.pool = self.sql_pool_store[ZATO_ODB_POOL_NAME].pool
        self.odb.token = self.config.odb_data.token

    def _startup_service_payload_from_path(self, name, value, repo_location):
        """ Reads payload from a local file. Abstracted out to ease in testing.
        """
        orig_path = value.replace('file://', '')
        if not os.path.isabs(orig_path):
            path = os.path.normpath(os.path.join(repo_location, orig_path))
        else:
            path = orig_path

        try:
            payload = open(path).read()
        except Exception, e:
            msg = 'Could not open payload path:[{}] [{}], skipping startup service:[{}], e:[{}]'.format(
                orig_path, path, name, format_exc(e))
            logger.warn(msg)
        else:
            return payload

    def invoke_startup_services(self):
        """ We are the first worker and we know we have a broker client and all the other config ready
        so we can publish the request to execute startup services. In the worst
        case the requests will get back to us but it's also possible that other
        workers are already running. In short, there is no guarantee that any
        server or worker in particular will receive the requests, only that there
        will be exactly one.
        """
        for name, payload in self.fs_server_config.get('startup_services', {}).items():
            if payload.startswith('file://'):
                payload = self._startup_service_payload_from_path(name, payload, self.repo_location)
                if not payload:
                    continue

            cid = new_cid()

            msg = {}
            msg['action'] = SERVICE.PUBLISH
            msg['service'] = name
            msg['payload'] = payload
            msg['cid'] = cid
            msg['channel'] = CHANNEL.STARTUP_SERVICE

            self.broker_client.invoke_async(msg)

    @staticmethod
    def start_server(parallel_server, zato_deployment_key=None):

        # Will be None if we are not running in background.
        if not zato_deployment_key:
            zato_deployment_key = uuid4().hex

        register_diag_handlers()

        # Store the ODB configuration, create an ODB connection pool and have self.odb use it
        parallel_server.config.odb_data = parallel_server.get_config_odb_data(parallel_server)
        parallel_server.set_odb_pool()

        # Now try grabbing the basic server's data from the ODB. No point
        # in doing anything else if we can't get past this point.
        server = parallel_server.odb.fetch_server(parallel_server.config.odb_data)

        if not server:
            raise Exception('Server does not exist in the ODB')

        parallel_server.id = server.id
        parallel_server.name = server.name
        parallel_server.cluster_id = server.cluster_id

        is_first = parallel_server._after_init_common(server, zato_deployment_key)

        # For now, all the servers are always ACCEPTED but future versions
        # might introduce more join states
        if server.last_join_status in(SERVER_JOIN_STATUS.ACCEPTED):
            parallel_server._after_init_accepted(server, zato_deployment_key)
        else:
            msg = 'Server has not been accepted, last_join_status:[{0}]'
            logger.warn(msg.format(server.last_join_status))

            parallel_server._after_init_non_accepted(server)

        parallel_server.odb.server_up_down(server.token, SERVER_UP_STATUS.RUNNING, True,
            parallel_server.host, parallel_server.port)

        parallel_server.delivery_store = parallel_server.app_context.get_object('delivery_store')
        parallel_server.delivery_store.broker_client = parallel_server.broker_client
        parallel_server.delivery_store.odb = parallel_server.odb
        parallel_server.delivery_store.delivery_lock_timeout = float(parallel_server.fs_server_config.misc.delivery_lock_timeout)

        if is_first:
            parallel_server.invoke_startup_services()

    @staticmethod
    def post_fork(arbiter, worker):
        """ A Gunicorn hook which initializes the worker.
        """
        ParallelServer.start_server(worker.app.zato_wsgi_app, arbiter.zato_deployment_key)

    @staticmethod
    def on_starting(arbiter):
        """ A Gunicorn hook for setting the deployment key for this particular
        set of server processes. It needs to be added to the arbiter because
        we want for each worker to be (re-)started to see the same key.
        """
        setattr(arbiter, 'zato_deployment_key', uuid4().hex)

    def destroy(self):
        """ A Spring Python hook for closing down all the resources held.
        """
        if self.singleton_server:

            # Close all the connector subprocesses this server has possibly started
            pairs = ((AMQP_CONNECTOR.CLOSE, MESSAGE_TYPE.TO_AMQP_CONNECTOR_ALL),
                    (JMS_WMQ_CONNECTOR.CLOSE, MESSAGE_TYPE.TO_JMS_WMQ_CONNECTOR_ALL),
                    (ZMQ_CONNECTOR.CLOSE, MESSAGE_TYPE.TO_ZMQ_CONNECTOR_ALL),
                    )

            for action, msg_type in pairs:
                msg = {}
                msg['action'] = action
                msg['token'] = self.odb.token
                self.broker_client.publish(msg, msg_type=msg_type)
                time.sleep(0.2)

            # Broker client
            self.broker_client.close()

            # Scheduler
            self.singleton_server.scheduler.stop()

            # Pick-up processor
            self.singleton_server.pickup.stop()

            # Cluster-wide flags
            if self.singleton_server.is_cluster_wide:
                self.odb.clear_cluster_wide()

        # Tell the ODB we've gone through a clean shutdown but only if this is
        # the main process going down (Arbiter) not one of Gunicorn workers.
        # We know it's the main process because its ODB's session has never
        # been initialized.
        if not self.odb.session_initialized:

            self.config.odb_data = self.get_config_odb_data(self)
            self.set_odb_pool()

            self.odb.init_session(ZATO_ODB_POOL_NAME, self.config.odb_data, self.odb.pool, False)

            self.odb.server_up_down(self.odb.token, SERVER_UP_STATUS.CLEAN_DOWN)
            self.odb.close()

    # Convenience API
    stop = destroy

# ##############################################################################

    def on_broker_msg_singleton(self, msg):
        getattr(self.singleton_server, 'on_broker_msg_{}'.format(code_to_name[msg.action]))(msg)

# ##############################################################################

    def notify_new_package(self, package_id):
        """ Publishes a message on the broker so all the servers (this one including
        can deploy a new package).
        """
        msg = {'action': HOT_DEPLOY.CREATE, 'package_id': package_id}
        self.broker_client.publish(msg)

########NEW FILE########
__FILENAME__ = singleton
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from datetime import datetime, timedelta
from time import sleep

# Bunch
from bunch import Bunch

# Zato
from zato.common import ENSURE_SINGLETON_JOB
from zato.common.broker_message import MESSAGE_TYPE, SCHEDULER, SINGLETON
from zato.server.base import BrokerMessageReceiver

_accepted_messages = SCHEDULER.values() + SINGLETON.values()

class SingletonServer(BrokerMessageReceiver):
    """ A server of which one instance only may be running in a Zato container.
    Holds and processes data which can't be made parallel, such as scheduler,
    hot-deployment or on-disk configuration management.
    """
    def __init__(self, parallel_server=None, server_id=None, scheduler=None, 
                 broker_client=None, initial_sleep_time=None, is_cluster_wide=False):
        self.parallel_server = parallel_server
        self.server_id = server_id
        self.scheduler = scheduler
        self.broker_client = broker_client
        self.initial_sleep_time = initial_sleep_time
        self.is_cluster_wide = is_cluster_wide
        self.logger = logging.getLogger(self.__class__.__name__)

    def run(self, *ignored_args, **kwargs):
        # So that other moving parts - like connector subprocesses - have time
        # to initialize before the singleton server starts the scheduler.
        self.logger.debug('Sleeping for %s s', self.initial_sleep_time)
        sleep(self.initial_sleep_time)

        for name in('broker_client',):
            if name in kwargs:
                setattr(self, name, kwargs[name])

        # Initialize scheduler
        self.scheduler.singleton = self

        # Start the hot-reload pickup monitor
        self.logger.info('Pickup notifier starting')
        self.pickup.watch()

    def wait_for_worker(self):
        """ OK, we have already slept for a while however this isn't neccessarily enough. The thing is, we can't publish messages
        from the scheduler yet. This would be good in itself, but we must be sure there is at least one server (worker) to handle
        the message. We don't know how many server there are in this cluster so the only thing we can do is to assume that our
        parallel_server's worker is the only one. Hence we wait until this very worker is initialized.
        """
        worker_not_ready_sleep_time = 0.25 # In seconds

        while not self.parallel_server.worker_store.is_ready:
            self.logger.info('Worker not ready, sleeping for %s s', worker_not_ready_sleep_time)
            sleep(worker_not_ready_sleep_time)

    def become_cluster_wide(self, connector_server_keep_alive_job_time, connector_server_grace_time, 
            server_id, cluster_id, starting_up):
        """ Attempts to become a connector server, the one to start the connector
        processes.
        """
        base_job_data = Bunch({
            'weeks': None, 'days': None, 
            'hours': None, 'minutes': None, 
            'seconds': connector_server_keep_alive_job_time, 
            'repeats': None, 
            'extra': 'server_id:{};cluster_id:{}'.format(server_id, cluster_id),
        })
        job_data = None

        if self.parallel_server.odb.become_cluster_wide(connector_server_grace_time):
            self.is_cluster_wide = True

            # Schedule a job for letting the other servers know we're still alive
            job_data = Bunch(base_job_data.copy())
            job_data.start_date = datetime.utcnow()
            job_data.name = 'zato.server.cluster-wide-singleton-keep-alive'
            job_data.service = 'zato.server.cluster-wide-singleton-keep-alive'

        else:
            # All other singleton servers that are just starting up get this job
            # for checking whether the connector server is alive or not
            if starting_up:
                job_data = Bunch(base_job_data.copy())
                job_data.start_date = datetime.utcnow() + timedelta(seconds=10) # Let's give the other server some time to warm up
                job_data.name = ENSURE_SINGLETON_JOB
                job_data.service = 'zato.server.ensure-cluster-wide-singleton'

        if job_data:
            self.scheduler.create_interval_based(job_data, MESSAGE_TYPE.TO_AMQP_PUBLISHING_CONNECTOR_ALL)

        return self.is_cluster_wide

################################################################################

    def filter(self, msg):
        """ Filters out messages not meant to be received by a singleton server.
        """
        if msg.action in _accepted_messages:
            return True
        return False

    def on_broker_msg_SCHEDULER_CREATE(self, msg, *ignored_args):
        self.scheduler.create_edit('create', msg)

    def on_broker_msg_SCHEDULER_EDIT(self, msg, *ignored_args):
        self.scheduler.create_edit('edit', msg)

    def on_broker_msg_SCHEDULER_DELETE(self, msg, *ignored_args):
        self.scheduler.delete(msg)

    def on_broker_msg_SCHEDULER_EXECUTE(self, msg, *ignored_args):
        self.scheduler.execute(msg)

    def on_broker_msg_SINGLETON_CLOSE(self, msg, *ignored_args):
        self.broker_client.close()

########NEW FILE########
__FILENAME__ = worker
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging, inspect, os, sys
from copy import deepcopy
from errno import ENOENT
from json import loads
from threading import RLock
from time import sleep
from traceback import format_exc
from urlparse import urlparse
from uuid import uuid4

# Bunch
from bunch import Bunch

# dateutil
from dateutil.parser import parse
from dateutil.relativedelta import relativedelta
from dateutil.rrule import DAILY, MINUTELY, rrule

# gunicorn
from gunicorn.workers.ggevent import GeventWorker as GunicornGeventWorker
from gunicorn.workers.sync import SyncWorker as GunicornSyncWorker

# Zato
from zato.common import CHANNEL, DATA_FORMAT, HTTP_SOAP_SERIALIZATION_TYPE, MSG_PATTERN_TYPE, PUB_SUB, SEC_DEF_TYPE, SIMPLE_IO, \
     TRACE1, ZATO_ODB_POOL_NAME
from zato.common.broker_message import code_to_name, SERVICE, STATS
from zato.common.pubsub import Client, Consumer, Topic
from zato.common.util import new_cid, pairwise, parse_extra_into_dict
from zato.server.base import BrokerMessageReceiver
from zato.server.connection.cloud.aws.s3 import S3Wrapper
from zato.server.connection.cloud.openstack.swift import SwiftWrapper
from zato.server.connection.ftp import FTPStore
from zato.server.connection.http_soap.channel import RequestDispatcher, RequestHandler
from zato.server.connection.http_soap.outgoing import HTTPSOAPWrapper, SudsSOAPWrapper
from zato.server.connection.http_soap.url_data import URLData
from zato.server.connection.sql import PoolStore, SessionWrapper
from zato.server.message import JSONPointerStore, NamespaceStore, XPathStore
from zato.server.stats import MaintenanceTool

logger = logging.getLogger(__name__)

class GeventWorker(GunicornGeventWorker):
    def __init__(self, *args, **kwargs):
        self.deployment_key = uuid4().hex
        super(GunicornGeventWorker, self).__init__(*args, **kwargs)

class SyncWorker(GunicornSyncWorker):
    def __init__(self, *args, **kwargs):
        self.deployment_key = uuid4().hex
        super(GunicornSyncWorker, self).__init__(*args, **kwargs)

class WorkerStore(BrokerMessageReceiver):
    """ Each worker thread has its own configuration store. The store is assigned
    to the thread's threading.local variable. All the methods assume the data's
    being already validated and sanitized by one of Zato's internal services.

    There are exactly two threads willing to access the data at any time
    - the worker thread this store belongs to
    - the background ZeroMQ thread which may wish to update the store's configuration
    hence the need for employing RLocks yet there shouldn't be much contention
    because configuration updates are extremaly rare when compared to regular
    access by worker threads.
    """
    def __init__(self, worker_config=None, server=None):
        self.logger = logging.getLogger(self.__class__.__name__)
        self.is_ready = False
        self.worker_config = worker_config
        self.server = server
        self.update_lock = RLock()
        self.kvdb = server.kvdb
        self.broker_client = None

        self.pubsub = None
        """:type: zato.common.pubsub.PubSubAPI"""

    def init(self):

        # Statistics maintenance
        self.stats_maint = MaintenanceTool(self.kvdb.conn)

        self.msg_ns_store = NamespaceStore()
        self.json_pointer_store = JSONPointerStore()
        self.xpath_store = XPathStore()

        # Message-related config - init_msg_ns_store must come before init_xpath_store
        # so the latter has access to the former's namespace map.
        self.init_msg_ns_store()
        self.init_json_pointer_store()
        self.init_xpath_store()

        # Request dispatcher - matches URLs, checks security and dispatches HTTP
        # requests to services.
        self.request_dispatcher = RequestDispatcher(simple_io_config=self.worker_config.simple_io)
        self.request_dispatcher.url_data = URLData(
            deepcopy(self.worker_config.http_soap),
            self.server.odb.get_url_security(self.server.cluster_id, 'channel')[0],
            self.worker_config.basic_auth, self.worker_config.ntlm, self.worker_config.oauth, self.worker_config.tech_acc,
            self.worker_config.wss, self.worker_config.apikey, self.worker_config.aws, self.worker_config.openstack_security,
            self.worker_config.xpath_sec, self.kvdb, self.broker_client, self.server.odb, self.json_pointer_store, self.xpath_store)

        self.request_dispatcher.request_handler = RequestHandler(self.server)

        # Create all the expected connections and objects
        self.init_sql()
        self.init_ftp()
        self.init_http_soap()
        self.init_cloud()
        self.init_pubsub()
        self.init_notifiers()

        # All set, whoever is waiting for us, if anyone at all, can now proceed
        self.is_ready = True

    def filter(self, msg):
        # TODO: Fix it, worker doesn't need to accept all the messages
        return True

    def _update_aws_config(self, msg):
        """ Parses the address to AWS we store into discrete components S3Connection objects expect.
        Also turns metadata string into a dictionary
        """
        url_info = urlparse(msg.address)

        msg.is_secure = True if url_info.scheme == 'https' else False
        msg.port = url_info.port if url_info.port else (443 if msg.is_secure else 80)
        msg.host = url_info.netloc

        msg.metadata = parse_extra_into_dict(msg.metadata_)

    def _http_soap_wrapper_from_config(self, config, has_sec_config=True):
        """ Creates a new HTTP/SOAP connection wrapper out of a configuration
        dictionary.
        """
        security_name = config.get('security_name')
        sec_config = {'security_name':security_name, 'sec_type':None, 'username':None, 'password':None, 'password_type':None}
        _sec_config = None

        # This will be set to True only if the method's invoked on a server's starting up
        if has_sec_config:
            # It's possible that there is no security config attached at all
            if security_name:
                _sec_config = config
        else:
            if security_name:
                sec_type = config.sec_type
                func = getattr(self.request_dispatcher.url_data, sec_type + '_get')
                _sec_config = func(security_name).config

        if logger.isEnabledFor(TRACE1):
            logger.log(TRACE1, 'has_sec_config:[{}], security_name:[{}], _sec_config:[{}]'.format(
                has_sec_config, security_name, _sec_config))

        if _sec_config:
            sec_config['sec_type'] = _sec_config['sec_type']
            sec_config['username'] = _sec_config['username']
            sec_config['password'] = _sec_config['password']
            sec_config['password_type'] = _sec_config.get('password_type')
            sec_config['salt'] = _sec_config.get('salt')

        wrapper_config = {'id':config.id,
            'is_active':config.is_active, 'method':config.method,
            'data_format':config.get('data_format'),
            'name':config.name, 'transport':config.transport,
            'address_host':config.host,
            'address_url_path':config.url_path,
            'soap_action':config.soap_action, 'soap_version':config.soap_version, 'ping_method':config.ping_method,
            'pool_size':config.pool_size, 'serialization_type':config.serialization_type,
            'timeout':config.timeout}
        wrapper_config.update(sec_config)

        if wrapper_config['serialization_type'] == HTTP_SOAP_SERIALIZATION_TYPE.SUDS.id:
            wrapper_config['queue_build_cap'] = float(self.server.fs_server_config.misc.queue_build_cap)
            wrapper = SudsSOAPWrapper(wrapper_config)
            wrapper.build_client_queue()
            return wrapper

        return HTTPSOAPWrapper(wrapper_config)

# ################################################################################################################################

    def init_sql(self):
        """ Initializes SQL connections, first to ODB and then any user-defined ones.
        """
        # We need a store first
        self.sql_pool_store = PoolStore()

        # Connect to ODB
        self.sql_pool_store[ZATO_ODB_POOL_NAME] = self.worker_config.odb_data
        self.odb = SessionWrapper()
        self.odb.init_session(ZATO_ODB_POOL_NAME, self.worker_config.odb_data, self.sql_pool_store[ZATO_ODB_POOL_NAME].pool)

        # Any user-defined SQL connections left?
        for pool_name in self.worker_config.out_sql:
            config = self.worker_config.out_sql[pool_name]['config']
            self.sql_pool_store[pool_name] = config

    def init_ftp(self):
        """ Initializes FTP connetions. The method replaces whatever value self.out_ftp
        previously had (initially this would be a ConfigDict of connection definitions).
        """
        config_list = self.worker_config.out_ftp.get_config_list()
        self.worker_config.out_ftp = FTPStore()
        self.worker_config.out_ftp.add_params(config_list)

    def init_http_soap(self):
        """ Initializes plain HTTP/SOAP connections.
        """
        for transport in('soap', 'plain_http'):
            config_dict = getattr(self.worker_config, 'out_' + transport)
            for name in config_dict:
                config = config_dict[name].config

                wrapper = self._http_soap_wrapper_from_config(config)
                config_dict[name].conn = wrapper

                # To make the API consistent with that of SQL connection pools
                config_dict[name].ping = wrapper.ping

    def init_cloud(self):
        """ Initializes all the cloud connections.
        """
        data = (
            ('cloud_openstack_swift', SwiftWrapper),
            ('cloud_aws_s3', S3Wrapper),
        )

        for config_key, wrapper in data:
            config_attr = getattr(self.worker_config, config_key)
            for name in config_attr:
                config = config_attr[name]['config']
                if isinstance(wrapper, S3Wrapper):
                    self._update_aws_config(config)
                config.queue_build_cap = float(self.server.fs_server_config.misc.queue_build_cap)
                config_attr[name].conn = wrapper(config)
                config_attr[name].conn.build_queue()

    def _update_cloud_openstack_swift_container(self, config_dict):
        """ Makes sure OpenStack Swift containers always have a path to prefix queries with.
        """
        config_dict.containers = [elem.split(':') for elem in config_dict.containers.splitlines()]
        for item in config_dict.containers:
            # No path specified so we use an empty string to catch everything.
            if len(item) == 1:
                item.append('')

            item.append('{}:{}'.format(item[0], item[1]))

    def init_notifiers(self):
        for config_dict in self.worker_config.notif_cloud_openstack_swift.values():
            self._update_cloud_openstack_swift_container(config_dict.config)

# ################################################################################################################################

    def _topic_from_topic_data(self, data):
        return Topic(data.name, data.is_active, True, data.max_depth)

    def _add_pubsub_topic(self, data):
        self.pubsub.add_topic(self._topic_from_topic_data(data))

    def init_pubsub(self):
        """ Initializes publish/subscribe mechanisms.
        """
        self.pubsub.set_default_consumer(self.worker_config.pubsub.default_consumer)
        self.pubsub.set_default_producer(self.worker_config.pubsub.default_producer)

        for topic_name, topic_data in self.worker_config.pubsub.topics.items():
            self._add_pubsub_topic(topic_data.config)

        for list_value in self.worker_config.pubsub.producers.values():
            for config in list_value:
                self.pubsub.add_producer(Client(config.client_id, config.name, config.is_active), Topic(config.topic_name))

        for list_value in self.worker_config.pubsub.consumers.values():
            for config in list_value:

                callback_type = PUB_SUB.CALLBACK_TYPE.OUTCONN_SOAP if bool(config.soap_version) else \
                    PUB_SUB.CALLBACK_TYPE.OUTCONN_PLAIN_HTP

                self.pubsub.add_consumer(
                    Consumer(
                        config.client_id, config.name, config.is_active, config.sub_key, config.max_backlog,
                        config.delivery_mode, config.callback_id, config.callback_name, callback_type),
                    Topic(config.topic_name))

# ################################################################################################################################

    def init_msg_ns_store(self):
        for k, v in self.worker_config.msg_ns.items():
            self.msg_ns_store.add(k, v.config)

    def init_xpath_store(self):
        for k, v in self.worker_config.xpath.items():
            self.xpath_store.add(k, v.config, self.msg_ns_store.ns_map)

    def init_json_pointer_store(self):
        for k, v in self.worker_config.json_pointer.items():
            self.json_pointer_store.add(k, v.config.value)

# ################################################################################################################################

    def _update_auth(self, msg, action_name, sec_type, visit_wrapper, keys=None):
        """ A common method for updating auth-related configuration.
        """
        with self.update_lock:
            # Channels
            handler = getattr(self.request_dispatcher.url_data, 'on_broker_msg_' + action_name)
            handler(msg)

            for transport in('soap', 'plain_http'):
                config_dict = getattr(self.worker_config, 'out_' + transport)

                # Wrappers and static configuration for outgoing connections
                for name in config_dict.copy_keys():
                    config = config_dict[name].config
                    wrapper = config_dict[name].conn
                    if config['sec_type'] == sec_type:
                        if keys:
                            visit_wrapper(wrapper, msg, keys)
                        else:
                            visit_wrapper(wrapper, msg)

    def _visit_wrapper_edit(self, wrapper, msg, keys):
        """ Updates a given wrapper's security configuration.
        """
        if wrapper.config['security_name'] == msg['old_name']:
            for key in keys:
                # All's good except for 'name', the msg's 'name' is known
                # as 'security_name' in wrapper's config.
                if key == 'name':
                    key1 = 'security_name'
                    key2 = key
                else:
                    key1, key2 = key, key
                wrapper.config[key1] = msg[key2]
            wrapper.set_auth()

    def _visit_wrapper_delete(self, wrapper, msg):
        """ Deletes a wrapper.
        """
        config_dict = getattr(self.worker_config, 'out_' + wrapper.config['transport'])
        if wrapper.config['security_name'] == msg['name']:
            del config_dict[wrapper.config['name']]

    def _visit_wrapper_change_password(self, wrapper, msg):
        """ Changes a wrapper's password.
        """
        if wrapper.config['security_name'] == msg['name']:
            wrapper.config['password'] = msg['password']
            wrapper.set_auth()

# ################################################################################################################################

    def apikey_get(self, name):
        """ Returns the configuration of the API key of the given name.
        """
        return self.request_dispatcher.url_data.apikey_get(name)

    def on_broker_msg_SECURITY_APIKEY_CREATE(self, msg, *args):
        """ Creates a new API key security definition.
        """
        self.request_dispatcher.url_data.on_broker_msg_SECURITY_APIKEY_CREATE(msg, *args)

    def on_broker_msg_SECURITY_APIKEY_EDIT(self, msg, *args):
        """ Updates an existing API key security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.APIKEY,
                self._visit_wrapper_edit, keys=('is_active', 'username', 'name'))

    def on_broker_msg_SECURITY_APIKEY_DELETE(self, msg, *args):
        """ Deletes an API key security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.APIKEY,
                self._visit_wrapper_delete)

    def on_broker_msg_SECURITY_APIKEY_CHANGE_PASSWORD(self, msg, *args):
        """ Changes password of an API key security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.APIKEY,
                self._visit_wrapper_change_password)

# ################################################################################################################################

    def aws_get(self, name):
        """ Returns the configuration of the AWS security definition
        of the given name.
        """
        return self.request_dispatcher.url_data.aws_get(name)

    def on_broker_msg_SECURITY_AWS_CREATE(self, msg, *args):
        """ Creates a new AWS security definition
        """
        self.request_dispatcher.url_data.on_broker_msg_SECURITY_AWS_CREATE(msg, *args)

    def on_broker_msg_SECURITY_AWS_EDIT(self, msg, *args):
        """ Updates an existing AWS security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.AWS,
                self._visit_wrapper_edit, keys=('is_active', 'username', 'name'))

    def on_broker_msg_SECURITY_AWS_DELETE(self, msg, *args):
        """ Deletes an AWS security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.AWS,
                self._visit_wrapper_delete)

    def on_broker_msg_SECURITY_AWS_CHANGE_PASSWORD(self, msg, *args):
        """ Changes password of an AWS security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.AWS,
                self._visit_wrapper_change_password)

# ################################################################################################################################

    def openstack_get(self, name):
        """ Returns the configuration of the OpenStack security definition
        of the given name.
        """
        self.request_dispatcher.url_data.openstack_get(name)

    def on_broker_msg_SECURITY_OPENSTACK_CREATE(self, msg, *args):
        """ Creates a new OpenStack security definition
        """
        self.request_dispatcher.url_data.on_broker_msg_SECURITY_OPENSTACK_CREATE(msg, *args)

    def on_broker_msg_SECURITY_OPENSTACK_EDIT(self, msg, *args):
        """ Updates an existing OpenStack security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.OPENSTACK,
                self._visit_wrapper_edit, keys=('is_active', 'username', 'name'))

    def on_broker_msg_SECURITY_OPENSTACK_DELETE(self, msg, *args):
        """ Deletes an OpenStack security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.OPENSTACK,
                self._visit_wrapper_delete)

    def on_broker_msg_SECURITY_OPENSTACK_CHANGE_PASSWORD(self, msg, *args):
        """ Changes password of an OpenStack security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.OPENSTACK,
                self._visit_wrapper_change_password)

# ################################################################################################################################

    def ntlm_get(self, name):
        """ Returns the configuration of the NTLM security definition
        of the given name.
        """
        return self.request_dispatcher.url_data.ntlm_get(name)

    def on_broker_msg_SECURITY_NTLM_CREATE(self, msg, *args):
        """ Creates a new NTLM security definition
        """
        self.request_dispatcher.url_data.on_broker_msg_SECURITY_NTLM_CREATE(msg, *args)

    def on_broker_msg_SECURITY_NTLM_EDIT(self, msg, *args):
        """ Updates an existing NTLM security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.NTLM,
                self._visit_wrapper_edit, keys=('is_active', 'username', 'name'))

    def on_broker_msg_SECURITY_NTLM_DELETE(self, msg, *args):
        """ Deletes an NTLM security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.NTLM,
                self._visit_wrapper_delete)

    def on_broker_msg_SECURITY_NTLM_CHANGE_PASSWORD(self, msg, *args):
        """ Changes password of an NTLM security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.NTLM,
                self._visit_wrapper_change_password)

# ################################################################################################################################

    def basic_auth_get(self, name):
        """ Returns the configuration of the HTTP Basic Auth security definition
        of the given name.
        """
        return self.request_dispatcher.url_data.basic_auth_get(name)

    def on_broker_msg_SECURITY_BASIC_AUTH_CREATE(self, msg, *args):
        """ Creates a new HTTP Basic Auth security definition
        """
        self.request_dispatcher.url_data.on_broker_msg_SECURITY_BASIC_AUTH_CREATE(msg, *args)

    def on_broker_msg_SECURITY_BASIC_AUTH_EDIT(self, msg, *args):
        """ Updates an existing HTTP Basic Auth security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.BASIC_AUTH,
                self._visit_wrapper_edit, keys=('is_active', 'username', 'name'))

    def on_broker_msg_SECURITY_BASIC_AUTH_DELETE(self, msg, *args):
        """ Deletes an HTTP Basic Auth security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.BASIC_AUTH,
                self._visit_wrapper_delete)

    def on_broker_msg_SECURITY_BASIC_AUTH_CHANGE_PASSWORD(self, msg, *args):
        """ Changes password of an HTTP Basic Auth security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.BASIC_AUTH,
                self._visit_wrapper_change_password)

# ################################################################################################################################

    def oauth_get(self, name):
        """ Returns the configuration of the OAuth security definition
        of the given name.
        """
        return self.request_dispatcher.url_data.oauth_get(name)

    def on_broker_msg_SECURITY_OAUTH_CREATE(self, msg, *args):
        """ Creates a new OAuth security definition
        """
        self.request_dispatcher.url_data.on_broker_msg_SECURITY_OAUTH_CREATE(msg, *args)

    def on_broker_msg_SECURITY_OAUTH_EDIT(self, msg, *args):
        """ Updates an existing OAuth security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.OAUTH,
                self._visit_wrapper_edit, keys=('is_active', 'username', 'name'))

    def on_broker_msg_SECURITY_OAUTH_DELETE(self, msg, *args):
        """ Deletes an OAuth security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.OAUTH,
                self._visit_wrapper_delete)

    def on_broker_msg_SECURITY_OAUTH_CHANGE_PASSWORD(self, msg, *args):
        """ Changes password of an OAuth security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.OAUTH,
                self._visit_wrapper_change_password)

# ################################################################################################################################

    def tech_acc_get(self, name):
        """ Returns the configuration of the technical account of the given name.
        """
        self.request_dispatcher.url_data.tech_acc_get(name)

    def on_broker_msg_SECURITY_TECH_ACC_CREATE(self, msg, *args):
        """ Creates a new technical account.
        """
        self.request_dispatcher.url_data.on_broker_msg_SECURITY_TECH_ACC_CREATE(msg, *args)

    def on_broker_msg_SECURITY_TECH_ACC_EDIT(self, msg, *args):
        """ Updates an existing technical account.
        """
        self.request_dispatcher.url_data.on_broker_msg_SECURITY_TECH_ACC_EDIT(msg, *args)

    def on_broker_msg_SECURITY_TECH_ACC_DELETE(self, msg, *args):
        """ Deletes a technical account.
        """
        self.request_dispatcher.url_data.on_broker_msg_SECURITY_TECH_ACC_DELETE(msg, *args)

    def on_broker_msg_SECURITY_TECH_ACC_CHANGE_PASSWORD(self, msg, *args):
        """ Changes the password of a technical account.
        """
        self.request_dispatcher.url_data.on_broker_msg_SECURITY_TECH_ACC_CHANGE_PASSWORD(msg, *args)

# ################################################################################################################################

    def wss_get(self, name):
        """ Returns the configuration of the WSS definition of the given name.
        """
        self.request_dispatcher.url_data.wss_get(name)

    def on_broker_msg_SECURITY_WSS_CREATE(self, msg, *args):
        """ Creates a new WS-Security definition.
        """
        self.request_dispatcher.url_data.on_broker_msg_SECURITY_WSS_CREATE(msg, *args)

    def on_broker_msg_SECURITY_WSS_EDIT(self, msg, *args):
        """ Updates an existing WS-Security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.WSS,
                self._visit_wrapper_edit, keys=('is_active', 'username', 'name',
                    'nonce_freshness_time', 'reject_expiry_limit', 'password_type',
                    'reject_empty_nonce_creat', 'reject_stale_tokens'))

    def on_broker_msg_SECURITY_WSS_DELETE(self, msg, *args):
        """ Deletes a WS-Security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.WSS,
                self._visit_wrapper_delete)

    def on_broker_msg_SECURITY_WSS_CHANGE_PASSWORD(self, msg, *args):
        """ Changes the password of a WS-Security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.WSS,
                self._visit_wrapper_change_password)

# ################################################################################################################################

    def xpath_sec_get(self, name):
        """ Returns the configuration of an XPath security definition of the given name.
        """
        self.request_dispatcher.url_data.xpath_sec_get(name)

    def on_broker_msg_SECURITY_XPATH_SEC_CREATE(self, msg, *args):
        """ Creates a new XPath security definition
        """
        self.request_dispatcher.url_data.on_broker_msg_SECURITY_XPATH_SEC_CREATE(msg, *args)

    def on_broker_msg_SECURITY_XPATH_SEC_EDIT(self, msg, *args):
        """ Updates an existing XPath security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.XPATH_SEC,
                self._visit_wrapper_edit, keys=('is_active', 'username', 'name'))

    def on_broker_msg_SECURITY_XPATH_SEC_DELETE(self, msg, *args):
        """ Deletes an XPath security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.XPATH_SEC,
                self._visit_wrapper_delete)

    def on_broker_msg_SECURITY_XPATH_SEC_CHANGE_PASSWORD(self, msg, *args):
        """ Changes password of an XPath security definition.
        """
        self._update_auth(msg, code_to_name[msg.action], SEC_DEF_TYPE.XPATH_SEC,
                self._visit_wrapper_change_password)


# ################################################################################################################################

    def _set_service_response_data(self, service, **ignored):
        if not isinstance(service.response.payload, basestring):
            service.response.payload = service.response.payload.getvalue()

    def _on_message_invoke_service(self, msg, channel, action, args=None):
        """ Triggered by external processes, such as AMQP or the singleton's scheduler,
        creates a new service instance and invokes it.
        """
        # WSGI environment is the best place we have to store raw msg in
        wsgi_environ = {'zato.request_ctx.async_msg':msg}

        service = self.server.service_store.new_instance_by_name(msg['service'])
        service.update_handle(self._set_service_response_data, service, msg['payload'],
            channel, msg.get('data_format'), msg.get('transport'), self.server,
            self.broker_client, self, msg['cid'], self.worker_config.simple_io,
            job_type=msg.get('job_type'), wsgi_environ=wsgi_environ)

# ################################################################################################################################

    def on_broker_msg_SCHEDULER_JOB_EXECUTED(self, msg, args=None):
        return self._on_message_invoke_service(msg, CHANNEL.SCHEDULER, 'SCHEDULER_JOB_EXECUTED', args)

    def on_broker_msg_CHANNEL_AMQP_MESSAGE_RECEIVED(self, msg, args=None):
        return self._on_message_invoke_service(msg, CHANNEL.AMQP, 'CHANNEL_AMQP_MESSAGE_RECEIVED', args)

    def on_broker_msg_CHANNEL_JMS_WMQ_MESSAGE_RECEIVED(self, msg, args=None):
        return self._on_message_invoke_service(msg, CHANNEL.JMS_WMQ, 'CHANNEL_JMS_WMQ_MESSAGE_RECEIVED', args)

    def on_broker_msg_CHANNEL_ZMQ_MESSAGE_RECEIVED(self, msg, args=None):
        return self._on_message_invoke_service(msg, CHANNEL.ZMQ, 'CHANNEL_ZMQ_MESSAGE_RECEIVED', args)

# ################################################################################################################################

    def on_broker_msg_OUTGOING_SQL_CREATE_EDIT(self, msg, *args):
        """ Creates or updates an SQL connection, including changing its
        password.
        """
        # Is it a rename? If so, delete the connection first
        if msg.get('old_name') and msg.get('old_name') != msg['name']:
            del self.sql_pool_store[msg['old_name']]

        self.sql_pool_store[msg['name']] = msg

    def on_broker_msg_OUTGOING_SQL_CHANGE_PASSWORD(self, msg, *args):
        """ Deletes an outgoing SQL connection pool and recreates it using the
        new password.
        """
        self.sql_pool_store.change_password(msg['name'], msg['password'])

    def on_broker_msg_OUTGOING_SQL_DELETE(self, msg, *args):
        """ Deletes an outgoing SQL connection pool.
        """
        del self.sql_pool_store[msg['name']]

# ################################################################################################################################

    def get_channel_plain_http(self, name):
        with self.update_lock:
            for item in self.request_dispatcher.url_data.channel_data:
                if item.connection == 'channel' and item.name == name:
                    return item

    def on_broker_msg_CHANNEL_HTTP_SOAP_CREATE_EDIT(self, msg, *args):
        """ Creates or updates an HTTP/SOAP channel.
        """
        self.request_dispatcher.url_data.on_broker_msg_CHANNEL_HTTP_SOAP_CREATE_EDIT(msg, *args)

    def on_broker_msg_CHANNEL_HTTP_SOAP_DELETE(self, msg, *args):
        """ Deletes an HTTP/SOAP channel.
        """
        self.request_dispatcher.url_data.on_broker_msg_CHANNEL_HTTP_SOAP_DELETE(msg, *args)

# ################################################################################################################################

    def _delete_config_close_wrapper(self, name, config_dict, conn_type, log_func):
        """ Deletes a wrapper-based connection's config and closes its underlying wrapper.
        """
        # Delete the connection first, if it exists at all ..
        try:
            try:
                wrapper = config_dict[name].conn
            except (KeyError, AttributeError), e:
                log_func('Could not access wrapper, e:[{}]'.format(format_exc(e)))
            else:
                try:
                    wrapper.session.close()
                finally:
                    del config_dict[name]
        except Exception, e:
            log_func('Could not delete `{}`, e:`{}`'.format(conn_type, format_exc(e)))

# ################################################################################################################################

    def _delete_config_close_wrapper_http_soap(self, name, transport, log_func):
        """ Deletes/closes an HTTP/SOAP outconn.
        """ 
        # Are we dealing with plain HTTP or SOAP?
        config_dict = getattr(self.worker_config, 'out_' + transport)

        return self._delete_config_close_wrapper(name, config_dict, 'an outgoing HTTP/SOAP connection', log_func)

    def on_broker_msg_OUTGOING_HTTP_SOAP_CREATE_EDIT(self, msg, *args):
        """ Creates or updates an outgoing HTTP/SOAP connection.
        """
        # It might be a rename
        old_name = msg.get('old_name')
        del_name = old_name if old_name else msg['name']

        # .. delete the connection if it exists ..
        self._delete_config_close_wrapper_http_soap(del_name, msg['transport'], logger.debug)

        # .. and create a new one
        wrapper = self._http_soap_wrapper_from_config(msg, False)
        config_dict = getattr(self.worker_config, 'out_' + msg['transport'])
        config_dict[msg['name']] = Bunch()
        config_dict[msg['name']].config = msg
        config_dict[msg['name']].conn = wrapper
        config_dict[msg['name']].ping = wrapper.ping # (just like in self.init_http)

    def on_broker_msg_OUTGOING_HTTP_SOAP_DELETE(self, msg, *args):
        """ Deletes an outgoing HTTP/SOAP connection (actually delegates the
        task to self._delete_config_close_wrapper_http_soap.
        """
        self._delete_config_close_wrapper_http_soap(msg['name'], msg['transport'], logger.error)

# ################################################################################################################################

    def on_broker_msg_SERVICE_DELETE(self, msg, *args):
        """ Deletes the service from the service store and removes it from the filesystem
        if it's not an internal one.
        """
        # Module this service is in so it can be removed from sys.modules
        mod = inspect.getmodule(self.server.service_store.services[msg.impl_name]['service_class'])

        # Where to delete it from in the second step
        fs_location = self.server.service_store.services[msg.impl_name]['deployment_info']['fs_location']

        # Delete it from the service store
        del self.server.service_store.services[msg.impl_name]

        # Delete it from the filesystem, including any bytecode left over. Note that
        # other parallel servers may wish to do exactly the same so we just ignore
        # the error if any files are missing. Also note that internal services won't
        # be ever deleted from the FS.
        if not msg.is_internal:
            all_ext = ('py', 'pyc', 'pyo')
            no_ext = '.'.join(fs_location.split('.')[:-1])
            for ext in all_ext:
                path = '{}.{}'.format(no_ext, ext)
                try:
                    os.remove(path)
                except OSError, e:
                    if e.errno != ENOENT:
                        raise

        # Makes it actually gets reimported next time it's redeployed
        del sys.modules[mod.__name__]

    def on_broker_msg_SERVICE_EDIT(self, msg, *args):
        for name in('is_active', 'slow_threshold'):
            self.server.service_store.services[msg.impl_name][name] = msg[name]

# ################################################################################################################################

    def on_broker_msg_OUTGOING_FTP_CREATE_EDIT(self, msg, *args):
        self.worker_config.out_ftp.create_edit(msg, msg.get('old_name'))

    def on_broker_msg_OUTGOING_FTP_DELETE(self, msg, *args):
        self.worker_config.out_ftp.delete(msg.name)

    def on_broker_msg_OUTGOING_FTP_CHANGE_PASSWORD(self, msg, *args):
        self.worker_config.out_ftp.change_password(msg.name, msg.password)

# ################################################################################################################################

    def on_broker_msg_HOT_DEPLOY_CREATE(self, msg, *args):
        msg.cid = new_cid()
        msg.service = 'zato.hot-deploy.create'
        msg.payload = {'package_id': msg.package_id}
        msg.data_format = SIMPLE_IO.FORMAT.JSON
        return self._on_message_invoke_service(msg, 'hot-deploy', 'HOT_DEPLOY_CREATE', args)

# ################################################################################################################################

    def on_broker_msg_STATS_DELETE(self, msg, *args):
        start = parse(msg.start)
        stop = parse(msg.stop)

        # Looks weird but this is so we don't have to create a list instead of a generator
        # (and Python 3 won't leak the last element anymore)
        last_elem = None

        # Are the dates are at least a day apart? If so, we'll split the interval
        # into smaller one day-long batches.
        if(stop-start).days:
            for elem1, elem2 in pairwise(elem for elem in rrule(DAILY, dtstart=start, until=stop)):
                self.broker_client.invoke_async({'action':STATS.DELETE_DAY, 'start':elem1.isoformat(), 'stop':elem2.isoformat()})

                # So as not to drown the broker with a sudden surge of messages
                sleep(0.02)

                last_elem = elem2

            # It's possible we still have something left over. Let's say
            #
            # start = '2012-07-24T02:02:53'
            # stop = '2012-07-25T02:04:53'
            #
            # The call to rrule(DAILY, ...) will nicely slice the time between
            # start and stop into one day intervals yet the last element of the slice
            # will have the time portion equal to that of start - so in this
            # particular case it would be that last_elem was 2012-07-25T02:02:53
            # which would be still be 2 minutes short of stop. Hence the need for
            # a relativedelta, to tease out the remaining time information.
            delta = relativedelta(stop, last_elem)
            if delta.minutes:
                self.stats_maint.delete(last_elem, stop, MINUTELY)

        # Not a full day apart so we can delete everything ourselves
        else:
            self.stats_maint.delete(start, stop, MINUTELY)

    def on_broker_msg_STATS_DELETE_DAY(self, msg, *args):
        self.stats_maint.delete(parse(msg.start), parse(msg.stop), MINUTELY)

# ################################################################################################################################

    def on_broker_msg_SERVICE_PUBLISH(self, msg, args=None):
        return self._on_message_invoke_service(msg, CHANNEL.INVOKE_ASYNC, 'SERVICE_PUBLISH', args)

# ################################################################################################################################

    def on_broker_msg_MSG_NS_CREATE(self, msg, *args):
        """ Creates a new namespace.
        """
        self.msg_ns_store.on_broker_msg_MSG_NS_CREATE(msg, *args)

    def on_broker_msg_MSG_NS_EDIT(self, msg, *args):
        """ Updates an existing namespace.
        """
        self.msg_ns_store.on_broker_msg_MSG_NS_EDIT(msg, *args)

    def on_broker_msg_MSG_NS_DELETE(self, msg, *args):
        """ Deletes a namespace.
        """
        self.msg_ns_store.on_broker_msg_MSG_NS_DELETE(msg, *args)

# ################################################################################################################################

    def on_broker_msg_MSG_XPATH_CREATE(self, msg, *args):
        """ Creates a new XPath.
        """
        self.xpath_store.on_broker_msg_create(msg, self.msg_ns_store.ns_map)

    def on_broker_msg_MSG_XPATH_EDIT(self, msg, *args):
        """ Updates an existing XPath.
        """
        self.xpath_store.on_broker_msg_edit(msg, self.msg_ns_store.ns_map)

    def on_broker_msg_MSG_XPATH_DELETE(self, msg, *args):
        """ Deletes an XPath.
        """
        self.xpath_store.on_broker_msg_delete(msg, *args)

# ################################################################################################################################

    def on_broker_msg_MSG_JSON_POINTER_CREATE(self, msg, *args):
        """ Creates a new JSON Pointer.
        """
        self.json_pointer_store.on_broker_msg_create(msg)

    def on_broker_msg_MSG_JSON_POINTER_EDIT(self, msg, *args):
        """ Updates an existing JSON Pointer.
        """
        self.request_dispatcher.url_data.on_broker_msg_MSG_JSON_POINTER_EDIT(msg)
        self.json_pointer_store.on_broker_msg_edit(msg)

    def on_broker_msg_MSG_JSON_POINTER_DELETE(self, msg, *args):
        """ Deletes an JSON Pointer.
        """
        # Delete the pattern from its store
        self.json_pointer_store.on_broker_msg_delete(msg, *args)

        # Delete the pattern from url_data's cache and let know servers that it should be deleted from the ODB as well
        for item_id, pattern_list in self.request_dispatcher.url_data.on_broker_msg_MSG_JSON_POINTER_DELETE(msg):

            # This is a bit inefficient, if harmless, because each worker in a cluster will publish it
            # so the list of patterns will be updated that many times.

            msg = {}
            msg['action'] = SERVICE.PUBLISH
            msg['service'] = 'zato.http-soap.set-audit-replace-patterns'
            msg['payload'] = {'id':item_id, 'audit_repl_patt_type':MSG_PATTERN_TYPE.JSON_POINTER.id, 'pattern_list':pattern_list}
            msg['cid'] = new_cid()
            msg['channel'] = CHANNEL.WORKER
            msg['data_format'] = DATA_FORMAT.JSON

            self.broker_client.invoke_async(msg)

# ################################################################################################################################

    def on_broker_msg_CHANNEL_HTTP_SOAP_AUDIT_RESPONSE(self, msg, *args):
        return self._on_message_invoke_service(msg, CHANNEL.AUDIT, 'SCHEDULER_JOB_EXECUTED', args)

    def on_broker_msg_CHANNEL_HTTP_SOAP_AUDIT_CONFIG(self, msg, *args):
        return self.request_dispatcher.url_data.on_broker_msg_CHANNEL_HTTP_SOAP_AUDIT_CONFIG(msg)

    def on_broker_msg_CHANNEL_HTTP_SOAP_AUDIT_STATE(self, msg, *args):
        return self.request_dispatcher.url_data.on_broker_msg_CHANNEL_HTTP_SOAP_AUDIT_STATE(msg)

    def on_broker_msg_CHANNEL_HTTP_SOAP_AUDIT_PATTERNS(self, msg, *args):
        return self.request_dispatcher.url_data.on_broker_msg_CHANNEL_HTTP_SOAP_AUDIT_PATTERNS(msg)

# ################################################################################################################################

    def _on_broker_msg_cloud_create_edit(self, msg, conn_type, config_dict, wrapper_class):

        # It might be a rename
        old_name = msg.get('old_name')
        del_name = old_name if old_name else msg['name']

        # .. delete the connection if it exists ..
        self._delete_config_close_wrapper(del_name, config_dict, conn_type, logger.debug)

        # .. and create a new one
        msg['queue_build_cap'] = float(self.server.fs_server_config.misc.queue_build_cap)
        wrapper = wrapper_class(msg)
        wrapper.build_queue()

        item = Bunch()

        config_dict[msg['name']] = item
        config_dict[msg['name']].config = msg
        config_dict[msg['name']].conn = wrapper

        return item

# ################################################################################################################################

    def on_broker_msg_CLOUD_OPENSTACK_SWIFT_CREATE_EDIT(self, msg, *args):
        """ Creates or updates an OpenStack Swift connection.
        """
        self._on_broker_msg_cloud_create_edit(msg, 'OpenStack Swift', self.worker_config.cloud_openstack_swift, SwiftWrapper)

    def on_broker_msg_CLOUD_OPENSTACK_SWIFT_DELETE(self, msg, *args):
        """ Closes and deletes an OpenStack Swift connection.
        """
        self._delete_config_close_wrapper(msg['name'], self.worker_config.cloud_openstack_swift, 'OpenStack Swift', logger.debug)

# ################################################################################################################################

    def on_broker_msg_CLOUD_AWS_S3_CREATE_EDIT(self, msg, *args):
        """ Creates or updates an AWS S3 connection.
        """
        self._update_aws_config(msg)
        self._on_broker_msg_cloud_create_edit(msg, 'AWS S3', self.worker_config.cloud_aws_s3, S3Wrapper)

    def on_broker_msg_CLOUD_AWS_S3_DELETE(self, msg, *args):
        """ Closes and deletes an AWS S3 connection.
        """
        self._delete_config_close_wrapper(msg['name'], self.worker_config.cloud_aws_s3, 'AWS S3', logger.debug)

# ################################################################################################################################

    def on_broker_msg_PUB_SUB_TOPIC_CREATE(self, msg):
        self._add_pubsub_topic(msg)

    def on_broker_msg_PUB_SUB_TOPIC_EDIT(self, msg):
        self.pubsub.update_topic(Topic(msg.name, msg.is_active, True, msg.max_depth))

    def on_broker_msg_PUB_SUB_TOPIC_DELETE(self, msg):
        self.pubsub.delete_topic(Topic(msg.name))

# ################################################################################################################################

    def _on_broker_msg_pub_sub_consumer_create_edit(self, msg):
        self.pubsub.add_consumer(
            Consumer(
                msg.client_id, msg.client_name, msg.is_active, msg.sub_key, msg.max_backlog,
                msg.delivery_mode, msg.callback_id, msg.callback_name, msg.callback_type),
            Topic(msg.topic_name))

    def _on_broker_msg_PUB_SUB_CONSUMER_CREATE(self, msg):
        self._on_broker_msg_pub_sub_consumer_create_edit(msg)

    def on_broker_msg_PUB_SUB_CONSUMER_EDIT(self, msg):
        self._on_broker_msg_pub_sub_consumer_create_edit(msg)

    def on_broker_msg_PUB_SUB_CONSUMER_DELETE(self, msg):
        self.pubsub.delete_consumer(
            Consumer(msg.client_id, msg.client_name, msg.is_active, msg.sub_key, msg.max_backlog), Topic(msg.topic_name))

# ################################################################################################################################

    def on_broker_msg_PUB_SUB_PRODUCER_CREATE(self, msg):
        self.pubsub.add_producer(Client(msg.client_id, msg.name, msg.is_active), Topic(msg.topic_name))

    def on_broker_msg_PUB_SUB_PRODUCER_EDIT(self, msg):
        self.pubsub.update_producer(Client(msg.client_id, msg.client_name, msg.is_active), Topic(msg.topic_name))

    def on_broker_msg_PUB_SUB_PRODUCER_DELETE(self, msg):
        self.pubsub.delete_producer(Client(msg.client_id, msg.client_name), Topic(msg.topic_name))

# ################################################################################################################################

    def on_broker_msg_NOTIF_RUN_NOTIFIER(self, msg):
        self._on_message_invoke_service(loads(msg.request), CHANNEL.NOTIFIER_RUN, 'NOTIF_RUN_NOTIFIER')

    def on_broker_msg_NOTIF_CLOUD_OPENSTACK_SWIFT_CREATE_EDIT(self, msg):

        # It might be a rename
        old_name = msg.get('old_name')
        del_name = old_name if old_name else msg.name

        config_dict = self.server.worker_store.worker_config.notif_cloud_openstack_swift
        config_dict.pop(del_name, None) # Delete and ignore if it doesn't exit (it's CREATE then)
        config_dict[msg.name] = Bunch()
        config_dict[msg.name].config = msg

        self._update_cloud_openstack_swift_container(msg)

        # Start a new background notifier either if it's a create action or on rename.
        if msg.source_service_type == 'create' or (old_name and old_name != msg.name):

            self._on_message_invoke_service({
                'service': 'zato.notif.invoke-run-notifier',
                'payload': {'config': msg},
                'cid': new_cid(),
            }, CHANNEL.NOTIFIER_RUN, 'NOTIF_CLOUD_OPENSTACK_SWIFT_CREATE_EDIT')

    def on_broker_msg_NOTIF_CLOUD_OPENSTACK_SWIFT_DELETE(self, msg):
        del self.server.worker_store.worker_config.notif_cloud_openstack_swift[msg.name]

# ################################################################################################################################

########NEW FILE########
__FILENAME__ = config
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from copy import deepcopy
from logging import getLogger
from threading import RLock

# Paste
from paste.util.multidict import MultiDict

# Bunch
from bunch import Bunch

# Zato
from zato.common import ZATO_NONE

logger = getLogger(__name__)

class ConfigDict(object):
    """ Stores configuration of a particular item of interest, such as an
    outgoing HTTP connection. Could've been a dict and we wouldn't have been using
    .get and .set but things like connection names aren't necessarily proper
    Python attribute names. Also, despite certain dict operations being atomic
    in CPython, the class employs a threading.Lock in critical places so the code
    doesn't assume anything about CPython's byte code-specific implementation
    details.
    """
    def __init__(self, name, _bunch=None):
        self.name = name
        self._impl = _bunch
        self.lock = RLock()

    def get(self, key, default=None):
        with self.lock:
            return self._impl.get(key, default)

    def set(self, key, value):
        with self.lock:
            self._impl[key] = value

    __setitem__ = set

    def __getitem__(self, key):
        with self.lock:
            return self._impl.__getitem__(key)

    def __delitem__(self, key):
        with self.lock:
            del self._impl[key]

    def pop(self, key, default):
        with self.lock:
            return self._impl.pop(key, default)

    def __iter__(self):
        with self.lock:
            return iter(self._impl)

    def __repr__(self):
        with self.lock:
            return '<{} at {} keys:[{}]>'.format(self.__class__.__name__,
                hex(id(self)), sorted(self._impl.keys()))

    __str__ = __repr__

    def __nonzero__(self):
        with self.lock:
            return bool(self._impl)

    def keys(self):
        with self.lock:
            return self._impl.keys()

    def values(self):
        with self.lock:
            return self._impl.values()

    def items(self):
        with self.lock:
            return self._impl.items()

    def copy(self):
        """ Returns a new instance of ConfigDict with items copied over from self.
        """
        with self.lock:
            config_dict = ConfigDict(self.name)
            config_dict._impl = Bunch()
            config_dict._impl.update(deepcopy(self._impl))

            return config_dict

    def get_config_list(self):
        """ Returns a list of deepcopied config Bunch objects.
        """
        with self.lock:
            out = []
            for value in self._impl.values():
                config = value['config']
                out.append(deepcopy(config))

        return out

    def copy_keys(self):
        """ Returns a deepcopy of the underlying Bunch's keys
        """
        with self.lock:
            return deepcopy(self._impl.keys())

    @staticmethod
    def from_query(name, query_data, impl_class=Bunch, item_class=Bunch, list_config=False):
        """ Return a new ConfigDict with items taken from an SQL query.
        """
        config_dict = ConfigDict(name)
        config_dict._impl = impl_class()

        if query_data:
            query, attrs = query_data

            for item in query:

                if list_config:
                    list_dict = Bunch()
                    if item.name not in config_dict._impl:
                        config_dict._impl[item.name] = []
                    config_dict._impl[item.name].append(list_dict)
                else:
                    config_dict._impl[item.name] = item_class()

                if list_config:
                    for attr_name in attrs.keys():
                        list_dict[attr_name] = getattr(item, attr_name)

                else:
                    config_dict._impl[item.name].config = item_class()
                    for attr_name in attrs.keys():
                        config_dict._impl[item.name]['config'][attr_name] = getattr(item, attr_name)

        return config_dict

class ConfigStore(object):
    """ The central place for storing a Zato server's thread configuration.
    May /not/ be shared across threads - each thread should get its own copy
    using the .copy method.

    Note that much more should be stored in here but the work is not finished yet -
    for instance, connection definitions should be kept here.
    """
    def __init__(self, out_ftp=ZATO_NONE, out_plain_http=ZATO_NONE,
            out_soap=ZATO_NONE, out_sql=ZATO_NONE, repo_location=ZATO_NONE,
            basic_auth=ZATO_NONE, wss=ZATO_NONE, tech_acc=ZATO_NONE,
            url_sec=ZATO_NONE, http_soap=ZATO_NONE, broker_config=ZATO_NONE,
            odb_data=ZATO_NONE, simple_io=ZATO_NONE, msg_ns=ZATO_NONE,
            json_pointer=ZATO_NONE, xpath=ZATO_NONE, pubsub_topics=ZATO_NONE):

        # Outgoing connections
        self.out_ftp = out_ftp
        self.out_plain_http = out_plain_http
        self.out_soap = out_soap
        self.out_sql = out_sql

        # Local on-disk configuraion repository
        self.repo_location = repo_location

        # Security definitions
        self.basic_auth = basic_auth
        self.wss = wss
        self.tech_acc = tech_acc

        # URL security
        self.url_sec = url_sec

        # HTTP channels
        self.http_soap = http_soap

        # Configuration for broker clients
        self.broker_config = broker_config

        # ODB
        self.odb_data = odb_data

        # SimpleIO
        self.simple_io = simple_io

        # Namespace
        self.msg_ns = msg_ns

        # JSON Pointer
        self.json_pointer = json_pointer

        # XPath
        self.xpath = xpath

        # Pub/sub
        self.pubsub_topics = pubsub_topics

    def outgoing_connections(self):
        """ Returns all the outgoing connections.
        """
        return self.out_ftp, self.out_plain_http, self.out_soap

    def copy(self):
        """ Creates a copy of this ConfigStore. All configuration data is copied
        over except for SQL connections.
        """
        config_store = ConfigStore()

        # Grab all ConfigDicts - even if they're actually ZATO_NONE - and make their copies
        for attr_name in dir(self):
            attr = getattr(self, attr_name)
            if isinstance(attr, ConfigDict):
                copy_func = getattr(attr, 'copy')
                setattr(config_store, attr_name, copy_func())
            elif attr is ZATO_NONE:
                setattr(config_store, attr_name, ZATO_NONE)

        http_soap = MultiDict()
        dict_of_lists = self.http_soap.dict_of_lists()
        for url_path, lists in dict_of_lists.items():
            _info = Bunch()
            for elem in lists:
                for soap_action, item in elem.items():
                    _info[soap_action] = Bunch()
                    _info[soap_action].id = item.id
                    _info[soap_action].name = item.name
                    _info[soap_action].is_active = item.is_active
                    _info[soap_action].is_internal = item.is_internal
                    _info[soap_action].url_path = item.url_path
                    _info[soap_action].method = item.method
                    _info[soap_action].soap_version = item.soap_version
                    _info[soap_action].service_id = item.service_id
                    _info[soap_action].service_name = item.service_name
                    _info[soap_action].impl_name = item.impl_name
                    _info[soap_action].transport = item.transport
                    _info[soap_action].connection = item.connection
            http_soap.add(url_path, _info)

        config_store.http_soap = http_soap
        config_store.url_sec = self.url_sec
        config_store.broker_config = self.broker_config
        config_store.odb_data = deepcopy(self.odb_data)

        return config_store

########NEW FILE########
__FILENAME__ = channel
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function

# stdlib
import logging, os
from random import getrandbits
from os import getpid
from socket import getfqdn, gethostbyname, gethostname
from threading import Thread

# Bunch
from bunch import Bunch

# Zato
from zato.common import TRACE1
from zato.common.broker_message import CHANNEL, MESSAGE_TYPE, TOPICS
from zato.common.util import new_cid
from zato.server.connection.amqp import BaseAMQPConnection, BaseAMQPConnector
from zato.server.connection import setup_logging, start_connector as _start_connector

ENV_ITEM_NAME = 'ZATO_CONNECTOR_AMQP_CHANNEL_ID'

class ConsumingConnection(BaseAMQPConnection):
    """ A connection for consuming the AMQP messages.
    """
    def __init__(self, conn_params, channel_name, queue, consumer_tag_prefix, callback):
        super(ConsumingConnection, self).__init__(conn_params, channel_name)
        self.logger = logging.getLogger(self.__class__.__name__)
        self.queue = queue
        self.consumer_tag_prefix = consumer_tag_prefix
        self.callback = callback
        
    def _on_channel_open(self, channel):
        """ We've opened a channel to the broker.
        """
        super(ConsumingConnection, self)._on_channel_open(channel)
        self.consume()
        
    def _on_basic_consume(self, channel, method_frame, header_frame, body):
        """ We've got a message to handle.
        """
        self.callback(method_frame, header_frame, body)
        channel.basic_ack(delivery_tag=method_frame.delivery_tag)
        
    def consume(self, queue=None, consumer_tag_prefix=None):
        """ Starts consuming messages from the broker.
        """
        _queue = queue if queue else self.queue
        _consumer_tag_prefix = consumer_tag_prefix if consumer_tag_prefix else self.consumer_tag_prefix
        
        consumer_tag = '{0}:{1}:{2}:{3}:{4}'.format(
            _consumer_tag_prefix, gethostbyname(gethostname()), getfqdn(),
            getpid(), getrandbits(64)).ljust(72, '0')
        
        self.channel.basic_consume(self._on_basic_consume, queue=_queue, consumer_tag=consumer_tag)
        self.logger.info(u'Started an AMQP consumer for [{0}], queue [{1}], tag [{2}]'.format(
            self._conn_info(), _queue, consumer_tag))
        
class ConsumingConnector(BaseAMQPConnector):
    """ An AMQP consuming connector started as a subprocess. Each connection to an AMQP
    broker gets its own connector.
    """
    def __init__(self, repo_location=None, def_id=None, channel_id=None, init=True):
        super(ConsumingConnector, self).__init__(repo_location, def_id)
        self.broker_client_id = 'amqp-consuming-connector'
        self.logger = logging.getLogger(self.__class__.__name__)
        self.channel_id = channel_id
        
        self.broker_client_id = 'amqp-consuming-connector'
        self.broker_callbacks = {
            TOPICS[MESSAGE_TYPE.TO_AMQP_CONSUMING_CONNECTOR_ALL]: self.on_broker_msg,
            TOPICS[MESSAGE_TYPE.TO_AMQP_CONNECTOR_ALL]: self.on_broker_msg
        }
        self.broker_messages = self.broker_callbacks.keys()
        
        if init:
            self._init()
            self._setup_amqp()
            
    def _setup_odb(self):
        super(ConsumingConnector, self)._setup_odb()
        
        item = self.odb.get_channel_amqp(self.server.cluster.id, self.channel_id)
        self.channel_amqp = Bunch()
        self.channel_amqp.id = item.id
        self.channel_amqp.name = item.name
        self.channel_amqp.is_active = item.is_active
        self.channel_amqp.queue = item.queue
        self.channel_amqp.consumer_tag_prefix = item.consumer_tag_prefix
        self.channel_amqp.service = item.service_name
        self.channel_amqp.data_format = item.data_format
        
    def _setup_amqp(self):
        """ Sets up the AMQP listener on startup.
        """
        with self.out_amqp_lock:
            with self.def_amqp_lock:
                self._recreate_consumer()
                
    def filter(self, msg):
        """ Finds out whether the incoming message actually belongs to the 
        listener. All the listeners receive incoming each of the PUB messages 
        and filtering out is being performed here, on the client side, not in the broker.
        """
        if super(ConsumingConnector, self).filter(msg):
            return True
        
        elif msg.action in(CHANNEL.AMQP_EDIT, CHANNEL.AMQP_DELETE):
            if self.channel_amqp.id == msg.id:
                return True
        else:
            if self.logger.isEnabledFor(TRACE1):
                self.logger.log(TRACE1, 'Returning False for msg [{0}]'.format(msg))
            return False
                            
    def _recreate_consumer(self):
        """ (Re-)creates an AMQP consumer and updates the related attributes so 
        that they point to the newly created consumer. The method must be called 
        from a method that holds onto all AMQP-related RLocks.
        """
        self._stop_amqp_connection()
        
        # An actual AMQP consumer
        if self.channel_amqp.is_active:
            consumer = self._amqp_consumer()
            self.channel_amqp.consumer = consumer
            
    def _amqp_consumer(self):
        consumer = ConsumingConnection(self._amqp_conn_params(), self.channel_amqp.name,
            self.channel_amqp.queue, self.channel_amqp.consumer_tag_prefix,
            self._on_message)
        t = Thread(target=consumer._run)
        t.start()
        
        return consumer
        
    def _channel_amqp_create_edit(self, msg, *args):
        """ Creates or updates an outgoing AMQP connection and its associated
        AMQP consumer.
        """ 
        with self.def_amqp_lock:
            with self.channel_amqp_lock:
                consumer = self.channel_amqp.get('consumer')
                self.channel_amqp = msg
                self.channel_amqp.consumer = consumer
                self._recreate_consumer()
                
    def _stop_amqp_connection(self):
        """ Stops the AMQP connection.
        """
        if self.channel_amqp.get('consumer'):
            self.channel_amqp.consumer.close()
                
    def _on_message(self, method_frame, header_frame, body):
        """ A callback to be invoked by ConsumingConnection on each new AMQP message.
        """
        with self.def_amqp_lock:
            with self.channel_amqp_lock:
                params = {}
                params['action'] = CHANNEL.AMQP_MESSAGE_RECEIVED
                params['service'] = self.channel_amqp.service
                params['data_format'] = self.channel_amqp.data_format
                params['cid'] = new_cid()
                params['payload'] = body
                
                self.broker_client.invoke_async(params)

    def on_broker_msg_CHANNEL_AMQP_CREATE(self, msg, *args):
        """ Creates a new outgoing AMQP connection. Note that the implementation
        is the same for both OUTGOING_AMQP_CREATE and OUTGOING_AMQP_EDIT.
        """
        self._channel_amqp_create_edit(msg, *args)
        
    def on_broker_msg_CHANNEL_AMQP_EDIT(self, msg, *args):
        """ Updates an AMQP consumer. Note that the implementation
        is the same for both CHANNEL_AMQP_CREATE and CHANNEL_AMQP_EDIT.
        """
        self._channel_amqp_create_edit(msg, *args)
        
    def on_broker_msg_CHANNEL_AMQP_DELETE(self, msg, *args):
        """ Deletes an AMQP connection, closes all the other connections
        and stops the process.
        """
        self._close()
        
    def on_broker_msg_CHANNEL_AMQP_CLOSE(self, msg, *args):
        """ Stops the consumer, ODB connection and exits the process.
        """
        self._close()

def run_connector():
    """ Invoked on the process startup.
    """
    setup_logging()
    
    repo_location = os.environ['ZATO_REPO_LOCATION']
    def_id = os.environ['ZATO_CONNECTOR_DEF_ID']
    item_id = os.environ[ENV_ITEM_NAME]
    
    ConsumingConnector(repo_location, def_id, item_id)
    
    logger = logging.getLogger(__name__)
    logger.debug('Starting AMQP consuming connector, repo_location [{0}], item_id [{1}], def_id [{2}]'.format(
        repo_location, item_id, def_id))
    
def start_connector(repo_location, item_id, def_id):
    _start_connector(repo_location, __file__, ENV_ITEM_NAME, def_id, item_id)
    
if __name__ == '__main__':
    run_connector()

########NEW FILE########
__FILENAME__ = outgoing
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function

# stdlib
import logging, os
from datetime import datetime

# Bunch
from bunch import Bunch

# Kombu
from kombu import Connection
from kombu.pools import producers, reset as reset_pools
from kombu.transport.pyamqp import Transport

# Zato
from zato.common import TRACE1
from zato.common.broker_message import MESSAGE_TYPE, OUTGOING, TOPICS
from zato.common.util import get_component_name
from zato.server.connection.amqp import BaseAMQPConnector
from zato.server.connection import setup_logging, start_connector as _start_connector

ENV_ITEM_NAME = 'ZATO_CONNECTOR_AMQP_OUT_ID'
CONN_TEMPLATE = 'amqp://{username}:{password}@{host}:{port}/{vhost}'
COMPONENT_PREFIX = 'out-amqp'
logger = logging.getLogger(__name__)

class _Transport(Transport):
    """ Allows to pass client properties to the broker.
    TODO: This should be made non-Zato specific and turned into a patch
    to Kombu.
    """
    def establish_connection(self):
        
        conninfo = self.client
        for name, default_value in self.default_connection_params.items():
            if not getattr(conninfo, name, None):
                setattr(conninfo, name, default_value)
        if conninfo.hostname == 'localhost':
            conninfo.hostname = '127.0.0.1'
        conn = self.Connection(host=conninfo.host,
                               userid=conninfo.userid,
                               password=conninfo.password,
                               login_method=conninfo.login_method,
                               virtual_host=conninfo.virtual_host,
                               insist=conninfo.insist,
                               ssl=conninfo.ssl,
                               connect_timeout=conninfo.connect_timeout,
                               heartbeat=conninfo.heartbeat,
                               client_properties={'zato-component':get_component_name(COMPONENT_PREFIX)})
        
        conn.client = self.client
        return conn

class _Connection(Connection):
    """ A connection subclass which uses our own transport class.
    """
    def get_transport_cls(self):
        return _Transport

class PublisherFacade(object):
    """ An AMQP facade for services so they aren't aware that publishing AMQP
    messages actually requires us to use the Zato broker underneath.
    """
    def __init__(self, broker_client, delivery_store):
        self.broker_client = broker_client # A Zato broker client, not the AMQP one.
        self.delivery_store = delivery_store
    
    def send(self, msg, out_name, exchange, routing_key, properties={}, headers={}, *args, **kwargs):
        """ Publishes the message on the Zato broker which forwards it to one of the
        AMQP connectors.
        """
        params = {}
        params['action'] = OUTGOING.AMQP_PUBLISH
        params['out_name'] = out_name
        params['body'] = msg
        params['exchange'] = bytes(exchange)
        params['routing_key'] = bytes(routing_key)
        params['properties'] = properties
        params['headers'] = headers
        params['args'] = args
        params['kwargs'] = kwargs
        
        self.broker_client.publish(params, msg_type=MESSAGE_TYPE.TO_AMQP_PUBLISHING_CONNECTOR_ALL)
        
    def conn(self):
        """ Returns self. Added to make the facade look like other outgoing
        connection wrappers.
        """
        return self

class OutgoingConnector(BaseAMQPConnector):
    """ An AMQP publishing connector started as a subprocess.
    """
    def __init__(self, repo_location=None, def_id=None, out_id=None, init=True):
        super(OutgoingConnector, self).__init__(repo_location, def_id)
        self.logger = logging.getLogger(self.__class__.__name__)
        self.out_id = out_id
        
        self.broker_client_id = 'amqp-publishing-connector'
        self.broker_callbacks = {
            TOPICS[MESSAGE_TYPE.TO_AMQP_PUBLISHING_CONNECTOR_ALL]: self.on_broker_msg,
            TOPICS[MESSAGE_TYPE.TO_AMQP_CONNECTOR_ALL]: self.on_broker_msg
        }
        self.broker_messages = self.broker_callbacks.keys()
        self.component_name = get_component_name('out-amqp')
        
        if init:
            self._init()
        
        self.logger.info('Started an AMQP publisher for [{}]'.format(self._conn_info()))
            
    def _setup_odb(self):
        super(OutgoingConnector, self)._setup_odb()
        
        item = self.odb.get_out_amqp(self.server.cluster.id, self.out_id)
        self.out_amqp = Bunch()
        self.out_amqp.id = item.id
        self.out_amqp.name = item.name
        self.out_amqp.is_active = item.is_active
        self.out_amqp.delivery_mode = item.delivery_mode
        self.out_amqp.priority = item.priority
        self.out_amqp.content_type = item.content_type
        self.out_amqp.content_encoding = item.content_encoding
        self.out_amqp.expiration = item.expiration
        self.out_amqp.user_id = item.user_id
        self.out_amqp.app_id = item.app_id
        self.out_amqp.def_name = item.def_name
        self.out_amqp.def_id = item.def_id
                
    def filter(self, msg):
        """ Finds out whether the incoming message actually belongs to the 
        listener. All the listeners receive each of the incoming PUB messages 
        and filtering out is being performed here, on the client side, not in the broker.
        """
        if super(OutgoingConnector, self).filter(msg):
            return True
        
        elif msg.action == OUTGOING.AMQP_PUBLISH:
            if self.out_amqp.name == msg.out_name:
                return True
        elif msg.action in(OUTGOING.AMQP_EDIT, OUTGOING.AMQP_DELETE):
            if self.out_amqp.id == msg.id:
                return True
        else:
            if self.logger.isEnabledFor(TRACE1):
                self.logger.log(TRACE1, 'Returning False for msg [{0}]'.format(msg))
            return False
    
    def def_amqp_get(self, id):
        """ Returns the configuration of the AMQP definition of the given name.
        """
        with self.def_amqp_lock:
            return self.def_amqp.get(id)
        
    def _out_amqp_create_edit(self, msg, *args):
        """ Creates or updates an outgoing AMQP connection details.
        """ 
        with self.def_amqp_lock:
            with self.out_amqp_lock:
                self.out_amqp = msg
                self._recreate_sender()

    def out_amqp_get(self, name):
        """ Returns the configuration of an outgoing AMQP connection.
        """
        with self.out_amqp_lock:
            if self.out_amqp.is_active:
                return self.out_amqp

    def on_broker_msg_OUTGOING_AMQP_CREATE(self, msg, *args):
        """ Creates a new outgoing AMQP connection. Note that the implementation
        is the same for both OUTGOING_AMQP_CREATE and OUTGOING_AMQP_EDIT.
        """
        self._out_amqp_create_edit(msg, *args)
        
    def on_broker_msg_OUTGOING_AMQP_EDIT(self, msg, *args):
        """ Updates an outgoing AMQP connection. Note that the implementation
        is the same for both OUTGOING_AMQP_CREATE and OUTGOING_AMQP_EDIT.
        """
        self._out_amqp_create_edit(msg, *args)
        
    def on_broker_msg_OUTGOING_AMQP_DELETE(self, msg, *args):
        """ Deletes an outgoing AMQP connection, closes all the other connections
        and stops the process.
        """
        self._close()
                
    def on_broker_msg_OUTGOING_AMQP_PUBLISH(self, msg, *args):
        """ Publishes an AMQP message on the broker.
        """
        properties = {}
        msg_properties = msg['properties']
        
        for name in ('content_type', 'content_encoding', 'delivery_mode', 
                     'priority', 'expiration', 'user_id', 'app_id', 'correlation_id', 'cluster_id'):
            if msg_properties:
                value = msg_properties.get(name) if msg_properties.get(name) else getattr(self.out_amqp, name, None)
            else:
                value = getattr(self.out_amqp, name, None)
            properties[name] = value
       
        headers = msg.get('headers') or {}
        
        if not 'X-Zato-Component' in headers:
            headers['X-Zato-Component'] = self.component_name
            
        if not 'X-Zato-Msg-TS' in headers:
            headers['X-Zato-Msg-TS'] = datetime.utcnow().isoformat()
        
        conn = _Connection(CONN_TEMPLATE.format(**self.def_amqp), heartbeat=self.def_amqp.heartbeat)
        
        with producers[conn].acquire(block=True) as producer:
            producer.publish(msg.body, routing_key=msg.routing_key, exchange=msg.exchange, headers=headers, **properties)
        
    def _stop_amqp_connection(self):
        """ Stops any underlying connections.
        """
        reset_pools()
        
    def _recreate_sender(self):
        return self._stop_amqp_connection()

def run_connector():
    """ Invoked on the process startup.
    """
    setup_logging()
    
    repo_location = os.environ['ZATO_REPO_LOCATION']
    def_id = os.environ['ZATO_CONNECTOR_DEF_ID']
    item_id = os.environ[ENV_ITEM_NAME]
    
    OutgoingConnector(repo_location, def_id, item_id)
    
    logger = logging.getLogger(__name__)
    logger.info('Starting AMQP connector, repo_location [{0}], item_id [{1}], def_id [{2}]'.format(
        repo_location, item_id, def_id))
    
def start_connector(repo_location, item_id, def_id):
    _start_connector(repo_location, __file__, ENV_ITEM_NAME, def_id, item_id)
    
if __name__ == '__main__':
    run_connector()

########NEW FILE########
__FILENAME__ = s3
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from logging import getLogger
from traceback import format_exc

# Boto
from boto.s3.bucket import Bucket
from boto.s3.connection import S3Connection
from boto.s3.key import Key

# gevent
from gevent.lock import RLock

# python-swiftclient
from swiftclient.client import Connection

# Zato
from zato.common import ZATO_NONE
from zato.common.util import parse_extra_into_dict
from zato.server.connection.queue import Wrapper

logger = getLogger(__name__)

class _S3Connection(object):
    def __init__(self, **kwargs):
        self.zato_default_bucket = kwargs.pop('bucket')
        self.zato_content_type = kwargs.pop('content_type')
        self.zato_metadata = kwargs.pop('metadata')

        encrypt_at_rest = kwargs.pop('encrypt_at_rest')
        self.zato_encrypt_at_rest = 'AES256' if encrypt_at_rest else None

        self.zato_storage_class = kwargs.pop('storage_class')
        self._conn = S3Connection(**kwargs)

    def sanity_check(self):
        self._conn.get_canonical_user_id()

    def set(self, key, value, bucket=ZATO_NONE, content_type=ZATO_NONE, metadata=ZATO_NONE,
            storage_class=ZATO_NONE, encrypt_at_rest=ZATO_NONE):
        _bucket = Bucket(self._conn, bucket if bucket != ZATO_NONE else self.zato_default_bucket)
        _key = Key(_bucket)

        _key.content_type = content_type if content_type != ZATO_NONE else self.zato_content_type
        _key.metadata.update(metadata if metadata != ZATO_NONE else self.zato_metadata)
        _key.name = key
        _key.storage_class = storage_class if storage_class != ZATO_NONE else self.zato_storage_class
        _key.set_contents_from_string(
            value, encrypt_key=(encrypt_at_rest if encrypt_at_rest != ZATO_NONE else self.zato_encrypt_at_rest))

class S3Wrapper(Wrapper):
    """ Wraps a queue of connections to AWS S3.
    """
    def __init__(self, config):
        config.auth_url = config.address
        super(S3Wrapper, self).__init__(config, 'AWS S3')

    def add_client(self):
        conn = _S3Connection(aws_access_key_id=self.config.username, aws_secret_access_key=self.config.password,
            is_secure=self.config.is_secure, port=self.config.port, host=self.config.host, debug=self.config.debug_level,
            suppress_consec_slashes=self.config.suppr_cons_slashes, content_type=self.config.content_type,
            metadata=self.config.metadata or {}, bucket=self.config.bucket, encrypt_at_rest=self.config.encrypt_at_rest,
            storage_class=self.config.storage_class)

        # Sanity check - no exception here means the config is correct.
        conn.sanity_check()

        self.client.put_client(conn)

########NEW FILE########
__FILENAME__ = swift
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from logging import getLogger
from traceback import format_exc

# gevent
from gevent.lock import RLock

# python-swiftclient
from swiftclient.client import Connection

# Zato
from zato.common.util import parse_extra_into_dict
from zato.server.connection.queue import ConnectionQueue

class SwiftWrapper(object):
    """ Wraps a queue of connections to OpenStack Swift.
    """
    def __init__(self, config):
        self.config = config

        self.client = ConnectionQueue(
            self.config.pool_size, self.config.queue_build_cap, self.config.name, 'OpenStack Swift', self.config.auth_url,
            self.add_client)

        self.update_lock = RLock()
        self.logger = getLogger(self.__class__.__name__)

    def build_queue(self):
        with self.update_lock:
            self.client.build_queue()

    def add_client(self):
        conn = Connection(authurl=self.config.auth_url, user=self.config.user, key=self.config.key, retries=self.config.retries,
                 snet=self.config.is_snet, starting_backoff=float(self.config.starting_backoff),
                 max_backoff=float(self.config.max_backoff), tenant_name=self.config.tenant_name,
                 os_options=parse_extra_into_dict(self.config.custom_options), auth_version=self.config.auth_version,
                 cacert=self.config.cacert, insecure=not self.config.should_validate_cert,
                 ssl_compression=self.config.needs_tls_compr, retry_on_ratelimit=self.config.should_retr_ratelimit)
        try:
            conn.head_account()
        except Exception, e:
            self.logger.warn('Could not HEAD an account (%s), e:`%s`', self.config.name, format_exc(e))

        self.client.put_client(conn)

########NEW FILE########
__FILENAME__ = ftp
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from copy import deepcopy
from threading import RLock
from traceback import format_exc

# pyfilesystem
from fs.ftpfs import FTPFS, _GLOBAL_DEFAULT_TIMEOUT

# Zato
from zato.common import Inactive, PASSWORD_SHADOW, TRACE1

logger = logging.getLogger(__name__)

class FTPFacade(FTPFS):
    """ A thin wrapper around fs's FTPFS so it looks like the other Zato connection objects.
    """
    def conn(self):
        return self

class FTPStore(object):
    """ An object through which services access FTP connections.
    """
    def __init__(self):
        self.conn_params = {}
        self._lock = RLock()

    def _add(self, params):
        """ Adds one set of params to the list of connection parameters. Must not
        be called without holding onto self._lock
        """
        self.conn_params[params.name] = params

        msg = 'FTP params added:[{!r}]'
        
        if logger.isEnabledFor(TRACE1):
            logger.log(TRACE1, msg.format(params))

        elif logger.isEnabledFor(logging.DEBUG):
            params = deepcopy(params)
            params['password'] = PASSWORD_SHADOW
            logger.debug(params)

    def add_params(self, params_list):
        with self._lock:
            for params in params_list:
                self._add(params)

    def get_conn_names(self):
        """ Returns a list of UTF-8 connection names this store contains,
        sorted in ascending order.
        """
        with self._lock:
            return [elem.encode('utf-8') for elem in sorted(self.conn_params)]

    def get(self, name):
        with self._lock:
            params = self.conn_params[name]
            if params.is_active:
                timeout = float(params.timeout) if params.timeout else _GLOBAL_DEFAULT_TIMEOUT
                return FTPFacade(params.host, params.user, params.get('password'), params.acct, timeout, int(params.port), params.dircache)
            else:
                raise Inactive(params.name)

    def create_edit(self, params, old_name):
        with self._lock:
            if params:
                _name = old_name if old_name else params.name
                ftp = params.get(_name)
                try:
                    if ftp:
                        ftp.close()
                except Exception, e:
                    msg = 'Could not close the FTP connection [{0}], e [{1}]'.format(params.name, format_exc(e))
                    logger.warn(msg)
                finally:
                    self._add(params)

            if old_name and old_name != params.name:
                del self.conn_params[old_name]

            msg = 'FTP connection stored, name:[{}], old_name:[{}]'.format(params.name, old_name)
            logger.info(msg)

    def change_password(self, name, password):
        with self._lock:
            self.conn_params[name].password = password
            logger.info('Password updated - FTP connection [{}]'.format(name))

    def delete(self, name):
        with self._lock:
            del self.conn_params[name]
            logger.info('FTP connection [{}] deleted'.format(name))

########NEW FILE########
__FILENAME__ = channel
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from cStringIO import StringIO
from httplib import INTERNAL_SERVER_ERROR, NOT_FOUND, responses, UNAUTHORIZED
from pprint import pprint
from traceback import format_exc

# anyjson
from anyjson import dumps

# Bunch
from bunch import Bunch

# Django
from django.http import QueryDict

# Zato
from zato.common import CHANNEL, DATA_FORMAT, SEC_DEF_TYPE, SIMPLE_IO, TRACE1, URL_PARAMS_PRIORITY, URL_TYPE, zato_namespace, \
     ZATO_ERROR, ZATO_NONE, ZATO_OK
from zato.common.util import payload_from_request
from zato.server.connection.http_soap import BadRequest, ClientHTTPError, NotFound, Unauthorized
from zato.server.service.internal import AdminService

logger = logging.getLogger(__name__)

_status_internal_server_error = b'{} {}'.format(INTERNAL_SERVER_ERROR, responses[INTERNAL_SERVER_ERROR])
_status_not_found = b'{} {}'.format(NOT_FOUND, responses[NOT_FOUND])
_status_unauthorized = b'{} {}'.format(UNAUTHORIZED, responses[UNAUTHORIZED])

soap_doc = b"""<?xml version='1.0' encoding='UTF-8'?><soap:Envelope xmlns:soap="http://schemas.xmlsoap.org/soap/envelope/" xmlns="https://zato.io/ns/20130518"><soap:Body>{body}</soap:Body></soap:Envelope>""" # noqa

zato_message_soap = b"""<soap:Envelope xmlns:soap="http://schemas.xmlsoap.org/soap/envelope/" xmlns="https://zato.io/ns/20130518">
  <soap:Body>{data}</soap:Body>
</soap:Envelope>"""

zato_message_plain = b'{data}'
zato_message_declaration = b"<?xml version='1.0' encoding='UTF-8'?>" + zato_message_plain

# Returned if there has been any exception caught.
soap_error = """<?xml version='1.0' encoding='UTF-8'?>
<SOAP-ENV:Envelope
  xmlns:SOAP-ENV="http://schemas.xmlsoap.org/soap/envelope/"
  xmlns:xsi="http://www.w3.org/1999/XMLSchema-instance"
  xmlns:xsd="http://www.w3.org/1999/XMLSchema">
   <SOAP-ENV:Body>
     <SOAP-ENV:Fault>
     <faultcode>SOAP-ENV:{faultcode}</faultcode>
     <faultstring><![CDATA[cid [{cid}], faultstring [{faultstring}]]]></faultstring>
      </SOAP-ENV:Fault>
  </SOAP-ENV:Body>
</SOAP-ENV:Envelope>"""

def client_json_error(cid, faultstring):
    zato_env = {'zato_env':{'result':ZATO_ERROR, 'cid':cid, 'details':faultstring}}
    return dumps(zato_env)

def client_soap_error(cid, faultstring):
    return soap_error.format(**{'faultcode':'Client', 'cid':cid, 'faultstring':faultstring})

def server_soap_error(cid, faultstring):
    return soap_error.format(**{'faultcode':'Server', 'cid':cid, 'faultstring':faultstring})

client_error_wrapper = {
    'json': client_json_error,
    'soap': client_soap_error,
}

def get_client_error_wrapper(transport, data_format):
    try:
        return client_error_wrapper[transport]
    except KeyError:
        # Any KeyError must be caught by the caller
        return client_error_wrapper[data_format]

# ##############################################################################

class RequestDispatcher(object):
    """ Dispatches all the incoming HTTP/SOAP requests to appropriate handlers.
    """
    def __init__(self, url_data=None, security=None, request_handler=None, simple_io_config=None):
        self.url_data = url_data
        self.security = security
        self.request_handler = request_handler
        self.simple_io_config = simple_io_config

    def wrap_error_message(self, cid, url_type, msg):
        """ Wraps an error message in a transport-specific envelope.
        """
        if url_type == URL_TYPE.SOAP:
            return server_soap_error(cid, msg)

        # Let's return the message as-is if we didn't have any specific envelope
        # to use.
        return msg

    def _handle_quotes_soap_action(self, soap_action):
        """ Make sure quotes around SOAP actions are ignored so these two
        are equivalent:
        - SOAPAction: "my.soap.action"
        - SOAPAction: my.soap.action
        """
        if soap_action[0] == '"' and soap_action[-1] == '"':
            soap_action = soap_action[1:-1]

        return soap_action

    def dispatch(self, cid, req_timestamp, wsgi_environ, worker_store):
        """ Base method for dispatching incoming HTTP/SOAP messages. If the security
        configuration is one of the technical account or HTTP basic auth,
        the security validation is being performed. Otherwise, that step
        is postponed until a concrete transport-specific handler is invoked.
        """

        # Needed in later steps
        path_info = wsgi_environ['PATH_INFO']
        soap_action = wsgi_environ.get('HTTP_SOAPACTION', '')

        # Fix up SOAP action - turns "my:soap:action" into my:soap:action,
        # that is, strips it out of surrounding quotes, if any.
        if soap_action:
            soap_action = self._handle_quotes_soap_action(soap_action)

        # Can we recognize this combination of URL path and SOAP action at all?
        # This gives us the URL info and security data - but note that here
        # we still haven't validated credentials, only matched the URL.
        # Credentials are checked in a call to self.url_data.check_security
        url_match, channel_item = self.url_data.match(path_info, soap_action)

        if channel_item:
            logger.debug('url_match:[%r], channel_item:[%r]', url_match, sorted(channel_item.items()))

        # This is needed in parallel.py's on_wsgi_request
        wsgi_environ['zato.http.channel_item'] = channel_item

        payload = wsgi_environ['wsgi.input'].read()
        
        # OK, we can possibly handle it
        if url_match:

            # This is a synchronous call so that whatever happens next we are always
            # able to have at least initial audit log of requests.
            if channel_item['audit_enabled']:
                self.url_data.audit_set_request(cid, channel_item, payload, wsgi_environ)

            # Raise 404 if the channel is inactive
            if not channel_item['is_active']:
                logger.warn('url_data:[%s] is not active, raising NotFound', sorted(url_match.items()))
                raise NotFound(cid, 'Channel inactive')

            try:

                # Need to read security info here so we know if POST needs to be
                # parsed. If so, we do it here and reuse it in other places
                # so it doesn't have to be parsed two or more times.
                sec = self.url_data.url_sec[channel_item['match_target']]
                if sec.sec_def != ZATO_NONE and sec.sec_def.sec_type == SEC_DEF_TYPE.OAUTH:
                    post_data = QueryDict(payload, encoding='utf-8')
                else:
                    post_data = {}

                # This is handy if someone invoked URLData's OAuth API manually
                wsgi_environ['zato.oauth.post_data'] = post_data

                # Eagerly parse the request but only if we expect XPath-based credentials. The request will be re-used
                # in later steps, it won't be parsed twice or more.
                if sec.sec_def != ZATO_NONE and sec.sec_def.sec_type == SEC_DEF_TYPE.XPATH_SEC:
                    wsgi_environ['zato.request.payload'] = payload_from_request(
                        cid, payload, channel_item.data_format, channel_item.transport)

                # Will raise an exception on any security violation
                self.url_data.check_security(
                    sec, cid, channel_item, path_info, payload, wsgi_environ, post_data)

                # OK, no security exception at that point means we can finally
                # invoke the service.
                response = self.request_handler.handle(cid, url_match, channel_item, wsgi_environ,
                    payload, worker_store, self.simple_io_config, post_data)

                # Got response from the service so we can construct response headers now
                self.add_response_headers(wsgi_environ, response)

                # Return the payload to the client
                return response.payload

            except Exception, e:

                _format_exc = format_exc(e)
                status = _status_internal_server_error

                if isinstance(e, ClientHTTPError):
                    response = e.msg
                    status_code = e.status

                    if isinstance(e, Unauthorized):
                        status = _status_unauthorized
                        wsgi_environ['zato.http.response.headers']['WWW-Authenticate'] = e.challenge
                    elif isinstance(e, NotFound):
                        status = _status_not_found
                else:
                    status_code = INTERNAL_SERVER_ERROR
                    response = _format_exc

                # TODO: This should be configurable. Some people may want such
                # things to be on DEBUG whereas for others ERROR will make most sense
                # in given circumstances.
                logger.error('Caught an exception, cid:[%s], status_code:[%s], _format_exc:[%s]', cid, status_code, _format_exc)

                try:
                    error_wrapper = get_client_error_wrapper(channel_item['transport'], channel_item['data_format'])
                except KeyError:
                    # It's OK. Apparently it's neither 'soap' nor json'
                    if logger.isEnabledFor(TRACE1):
                        msg = 'No client error wrapper for transport:[{}], data_format:[{}]'.format(
                            channel_item['transport'], channel_item['data_format'])
                        logger.log(TRACE1, msg)
                else:
                    response = error_wrapper(cid, response)

                wsgi_environ['zato.http.response.status'] = status
                
                return response

        # This is 404, no such URL path and SOAP action is known.
        else:
            response = b"[{}] Unknown URL:[{}] or SOAP action:[{}]".format(cid, path_info, soap_action)
            wsgi_environ['zato.http.response.status'] = _status_not_found

            logger.error(response)
            return response

    def add_response_headers(self, wsgi_environ, response):
        """ Adds HTTP response headers on a 200 OK.
        """
        wsgi_environ['zato.http.response.headers']['Content-Type'] = response.content_type
        wsgi_environ['zato.http.response.headers'].update(response.headers)
        wsgi_environ['zato.http.response.status'] = b'{} {}'.format(response.status_code, responses[response.status_code])

# ##############################################################################

class RequestHandler(object):
    """ Handles individual HTTP requests to a given service.
    """
    def __init__(self, server=None):
        self.server = server # A ParallelServer instance

    def _set_response_data(self, service, **kwargs):
        """ A callback invoked by the services after it's done producing the response.
        """
        data_format = kwargs.get('data_format')
        transport = kwargs.get('transport')

        self.set_payload(service.response, data_format, transport, service)
        self.set_content_type(service.response, data_format, transport, kwargs.get('url_match'), kwargs.get('channel_item'))

        return service.response

    def create_channel_params(self, url_match, channel_item, wsgi_environ, raw_request, post_data=None):
        """ Collects parameters specific to this channel (HTTP) and updates wsgi_environ
        with HTTP-specific data.
        """
        path_params = url_match.named

        qs = wsgi_environ.get('QUERY_STRING')
        qs = QueryDict(qs, encoding='utf-8')

        # Whoever called us has already parsed POST for us so we just use it as is
        if post_data:
            post = post_data
        else:
            if channel_item.data_format == DATA_FORMAT.POST:
                post = QueryDict(raw_request, encoding='utf-8')
            else:
                post = QueryDict(None, encoding='utf-8')

        _qs = {}
        for key, value in qs.iterlists():
            if len(value) > 1:
                _qs[key] = value
            else:
                _qs[key] = value[0]

        wsgi_environ['zato.http.GET'] = _qs
        wsgi_environ['zato.http.POST'] = post

        if channel_item.url_params_pri == URL_PARAMS_PRIORITY.QS_OVER_PATH:
            path_params.update((key, value) for key, value in _qs.items())
            channel_params = path_params
        else:
            channel_params = dict((key, value) for key, value in _qs.items())
            channel_params.update(path_params)

        logger.debug('channel_params `%s`, path_params `%s`, _qs `%s`', channel_params, path_params, _qs)

        return channel_params

    def handle(self, cid, url_match, channel_item, wsgi_environ, raw_request,
            worker_store, simple_io_config, post_data):
        """ Create a new instance of a service and invoke it.
        """
        service = self.server.service_store.new_instance(channel_item.service_impl_name)

        if channel_item.merge_url_params_req:
            channel_params = self.create_channel_params(url_match, channel_item,
                wsgi_environ, raw_request, post_data)
        else:
            channel_params = None

        response = service.update_handle(self._set_response_data, service, raw_request,
            CHANNEL.HTTP_SOAP, channel_item.data_format, channel_item.transport, self.server, worker_store.broker_client,
            worker_store, cid, simple_io_config, wsgi_environ=wsgi_environ,
            url_match=url_match, channel_item=channel_item, channel_params=channel_params,
            merge_channel_params=channel_item.merge_url_params_req,
            params_priority=channel_item.params_pri)

        return response

    # ##########################################################################

    def _get_xml_admin_payload(self, service_instance, zato_message_template, payload):

        if payload:
            data=payload.getvalue()
        else:
            data=b"""<{response_elem} xmlns="{namespace}">
                <zato_env>
                  <cid>{cid}</cid>
                  <result>{result}</result>
                </zato_env>
              </{response_elem}>
            """.format(response_elem=getattr(service_instance.SimpleIO, 'response_elem', 'response'),
                       namespace=getattr(service_instance.SimpleIO, 'namespace', zato_namespace),
                         cid=service_instance.cid, result=ZATO_OK)

        return zato_message_template.format(data=data.encode('utf-8'))

    def set_payload(self, response, data_format, transport, service_instance):
        """ Sets the actual payload to represent the service's response out of
        whatever the service produced. This includes converting dictionaries into
        JSON, adding Zato metadata and wrapping the mesasge in SOAP if need be.
        """
        if isinstance(service_instance, AdminService):
            if data_format == SIMPLE_IO.FORMAT.JSON:
                zato_env = {'zato_env':{'result':response.result, 'cid':service_instance.cid, 'details':response.result_details}}
                if response.payload:
                    payload = response.payload.getvalue(False)
                    payload.update(zato_env)
                else:
                    payload = zato_env

                response.payload = dumps(payload)

            else:
                if transport == URL_TYPE.SOAP:
                    zato_message_template = zato_message_soap
                else:
                    zato_message_template = zato_message_declaration

                if response.payload:
                    if not isinstance(response.payload, basestring):
                        response.payload = self._get_xml_admin_payload(service_instance, zato_message_template, response.payload)
                else:
                    response.payload = self._get_xml_admin_payload(service_instance, zato_message_template, None)
        else:
            if not isinstance(response.payload, basestring):
                response.payload = response.payload.getvalue() if response.payload else ''

        if transport == URL_TYPE.SOAP:
            if not isinstance(service_instance, AdminService):
                response.payload = soap_doc.format(body=response.payload)

    def set_content_type(self, response, data_format, transport, url_match, channel_item):
        """ Sets a response's content type if one hasn't been supplied by the user.
        """
        # A user provided their own content type ..
        if response.content_type_changed:
            content_type = response.content_type
        else:
            # .. or they did not so let's find out if we're using SimpleIO ..
            if data_format == SIMPLE_IO.FORMAT.XML:
                if transport == URL_TYPE.SOAP:
                    if channel_item.soap_version == '1.1':
                        content_type = self.server.soap11_content_type
                    else:
                        content_type = self.server.soap12_content_type
                else:
                    content_type = self.server.plain_xml_content_type
            elif data_format == SIMPLE_IO.FORMAT.JSON:
                content_type = self.server.json_content_type
            # .. alright, let's use the default value after all.
            else:
                content_type = response.content_type

        response.content_type = content_type

# ##########################################################################

########NEW FILE########
__FILENAME__ = handler
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

########NEW FILE########
__FILENAME__ = outgoing
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from copy import deepcopy
from cStringIO import StringIO
from datetime import datetime, timedelta
from json import dumps, loads
from traceback import format_exc

# gevent
import gevent
from gevent.lock import RLock
from gevent.queue import Empty, Queue

# parse
from parse import PARSE_RE

# Requests
import requests

# Zato
from zato.common import DATA_FORMAT, HTTP_SOAP_SERIALIZATION_TYPE, Inactive, SEC_DEF_TYPE, URL_TYPE, ZatoException
from zato.common.util import get_component_name, new_cid
from zato.server.connection.queue import ConnectionQueue

logger = logging.getLogger(__name__)

# ################################################################################################################################

class BaseHTTPSOAPWrapper(object):
    """ Base class for HTTP/SOAP connections wrappers.
    """
    def __init__(self, config, requests_module=None):
        self.config = config
        self.config['timeout'] = float(self.config['timeout'])
        self.config_no_sensitive = deepcopy(self.config)
        self.config_no_sensitive['password'] = '***'
        self.requests_module = requests_module or requests
        self.session = self.requests_module.session(pool_maxsize=self.config['pool_size'])
        self._component_name = get_component_name()

        self.address = None
        self.path_params = []

        self.set_address_data()
        self.set_auth()

    def ping(self, cid):
        """ Pings a given HTTP/SOAP resource
        """
        if logger.isEnabledFor(logging.DEBUG):
            msg = 'About to ping:[{}]'.format(self.config_no_sensitive)
            logger.debug(msg)

        # session will write some info to it ..
        verbose = StringIO()

        start = datetime.utcnow()

        def zato_pre_request_hook(hook_data, *args, **kwargs):
            entry = '{} (UTC) {} {}\n'.format(datetime.utcnow().isoformat(), 
                hook_data['request'].method, hook_data['request'].url)
            verbose.write(entry)

        # .. invoke the other end ..
        response = self.session.request(self.config['ping_method'], self.address, 
                auth=self.requests_auth, headers=self._create_headers(cid, {}),
                hooks={'zato_pre_request':zato_pre_request_hook}, timeout=self.config['timeout'])

        # .. store additional info, get and close the stream.
        verbose.write('Code: {}'.format(response.status_code))
        verbose.write('\nResponse time: {}'.format(datetime.utcnow() - start))
        value = verbose.getvalue()
        verbose.close()

        return value

    def _create_headers(self, cid, user_headers):
        headers = {
            'X-Zato-CID': cid,
            'X-Zato-Component':self._component_name,
            'X-Zato-Msg-TS':datetime.utcnow().isoformat(),
            }

        if self.config.get('transport') == URL_TYPE.SOAP:
            headers['SOAPAction'] = self.config.get('soap_action')

        headers.update(user_headers)

        return headers

    def set_auth(self):
        """ Configures the security for requests, if any is to be configured at all.
        """

        # Suds SOAP requests
        if self.config['serialization_type'] == HTTP_SOAP_SERIALIZATION_TYPE.SUDS.id:
            self.suds_auth = {'username':self.config['username'], 'password':self.config['password']}

        # Everything else
        else:
            self.requests_auth = self.auth if self.config['sec_type'] == SEC_DEF_TYPE.BASIC_AUTH else None
            if self.config['sec_type'] == SEC_DEF_TYPE.WSS:
                self.soap[self.config['soap_version']]['header'] = \
                    self.soap[self.config['soap_version']]['header_template'].format(
                        Username=self.config['username'], Password=self.config['password'])


    def set_address_data(self):
        """Sets the full address to invoke and parses input URL's configuration, 
        to extract any named parameters that will have to be passed in by users
        during actual calls to the resource.
        """
        self.address = '{}{}'.format(self.config['address_host'], self.config['address_url_path'])
        groups = PARSE_RE.split(self.config['address_url_path'])

        logger.debug('self.address:[%s], groups:[%s]', self.address, groups)

        for group in groups:
            if group and group[0] == '{':
                self.path_params.append(group[1:-1])

        logger.debug('self.address:[%s], self.path_params:[%s]', self.address, self.path_params)

# ################################################################################################################################

class HTTPSOAPWrapper(BaseHTTPSOAPWrapper):
    """ A thin wrapper around the API exposed by the 'requests' package.
    """
    def __init__(self, config, requests_module=None):
        super(HTTPSOAPWrapper, self).__init__(config, requests_module)

        self.soap = {}
        self.soap['1.1'] = {}
        self.soap['1.1']['content_type'] = 'text/xml; charset=utf-8'
        self.soap['1.1']['message'] = """<?xml version="1.0" encoding="utf-8"?>
<s11:Envelope xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:s11="http://schemas.xmlsoap.org/soap/envelope/">
  {header}
  <s11:Body>{data}</s11:Body>
</s11:Envelope>"""
        self.soap['1.1']['header_template'] = """<s11:Header xmlns:wsse="http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd" >
          <wsse:Security>
            <wsse:UsernameToken>
              <wsse:Username>{Username}</wsse:Username>
              <wsse:Password Type="http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-username-token-profile-1.0#PasswordText">{Password}</wsse:Password>
            </wsse:UsernameToken>
          </wsse:Security>
        </s11:Header>
        """

        self.soap['1.2'] = {}
        self.soap['1.2']['content_type'] = 'application/soap+xml; charset=utf-8'
        self.soap['1.2']['message'] = """<?xml version="1.0" encoding="utf-8"?>
<s12:Envelope xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:s12="http://www.w3.org/2003/05/soap-envelope/">
  {header}
  <s12:Body></s12:Body>
</s12:Envelope>"""
        self.soap['1.2']['header_template'] = """<s12:Header xmlns:wsse="http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd" >
          <wsse:Security>
            <wsse:UsernameToken>
              <wsse:Username>{Username}</wsse:Username>
              <wsse:Password Type="http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-username-token-profile-1.0#PasswordText">{Password}</wsse:Password>
            </wsse:UsernameToken>
          </wsse:Security>
        </s12:Header>
        """

# ################################################################################################################################
        
    def __str__(self):
        return '<{} at {}, config:[{}]>'.format(self.__class__.__name__, hex(id(self)), self.config_no_sensitive)

    __repr__ = __str__

# ################################################################################################################################

    def format_address(self, cid, params):
        """ Formats a URL path to an external resource. Note that exception raised
        do not contain anything except for CID. This is in order to keep any potentially
        sensitive data from leaking to clients.
        """

        if not params:
            logger.warn('CID:[%s] No parameters given for URL path:`%r`', cid, self.config['address_url_path'])
            raise ValueError('CID:[{}] No parameters given for URL path'.format(cid))

        path_params = {}
        try:
            for name in self.path_params:
                path_params[name] = params.pop(name)

            return (self.address.format(**path_params), dict(params))
        except(KeyError, ValueError), e:
            logger.warn('CID:[%s] Could not build URL address `%r` path:`%r` with params:`%r`, e:`%s`', 
                cid, self.address, self.config['address_url_path'], params, format_exc(e))
            
            raise ValueError('CID:[{}] Could not build URL path'.format(cid))

# ################################################################################################################################

    def _impl(self):
        """ Returns the self.session object through which access to HTTP/SOAP
        resources is mediated.
        """
        return self.session

    impl = property(fget=_impl, doc=_impl.__doc__)

    def _get_auth(self):
        """ Returns a username and password pair or None, if no security definition
        has been attached.
        """
        if self.config['sec_type'] in (SEC_DEF_TYPE.BASIC_AUTH, SEC_DEF_TYPE.WSS):
            auth = (self.config['username'], self.config['password'])
        else:
            auth = None

        return auth

    auth = property(fget=_get_auth, doc=_get_auth)

    def _enforce_is_active(self):
        if not self.config['is_active']:
            raise Inactive(self.config['name'])

    def _soap_data(self, data, headers):
        """ Wraps the data in a SOAP-specific messages and adds the headers required.
        """
        soap_config = self.soap[self.config['soap_version']]

        # The idea here is that even though there usually won't be the Content-Type
        # header provided by the user, we shouldn't overwrite it if one has been
        # actually passed in.
        if not headers.get('Content-Type'):
            headers['Content-Type'] = soap_config['content_type']

        if self.config['sec_type'] == SEC_DEF_TYPE.WSS:
            soap_header = soap_config['header']
        else:
            soap_header = ''

        return soap_config['message'].format(header=soap_header, data=data), headers

# ################################################################################################################################

    def http_request(self, method, cid, data='', params=None, *args, **kwargs):
        self._enforce_is_active()

        # We never touch strings/unicode because apparently the user already serialized outgoing data
        needs_serialize = not isinstance(data, basestring)

        if needs_serialize:
            if self.config['data_format'] == DATA_FORMAT.JSON:
                data = dumps(data)

        headers = self._create_headers(cid, kwargs.pop('headers', {}))
        if self.config['transport'] == 'soap':
            data, headers = self._soap_data(data, headers)

        params = params or {}

        if self.path_params:
            address, qs_params = self.format_address(cid, params)
        else:
            address, qs_params = self.address, dict(params)

        logger.info('CID:[%s], address:[%s], qs_params:[%s], auth:[%s], kwargs:[%s]', cid, address, qs_params, self.requests_auth, kwargs) 

        response = self.session.request(method, address, data=data,
            auth=self.requests_auth, params=qs_params, headers=headers, timeout=self.config['timeout'], *args, **kwargs)

        logger.debug('CID:[%s], response:[%s]', cid, response.text)

        if needs_serialize:
            if self.config['data_format'] == DATA_FORMAT.JSON:
                response.data = loads(response.text)

        return response

# ################################################################################################################################

    def get(self, cid, params=None, *args, **kwargs):
        return self.http_request('GET', cid, '', params, *args, **kwargs)

    def delete(self, cid, params=None, *args, **kwargs):
        return self.http_request('DELETE', cid, '', params, *args, **kwargs)

    def options(self, cid, params=None, *args, **kwargs):
        return self.http_request('OPTIONS', cid, '', params, *args, **kwargs)

# ################################################################################################################################

    def post(self, cid, data='', params=None, *args, **kwargs):
        return self.http_request('POST', cid, data, params, *args, **kwargs)

    send = post

    def put(self, cid, data='', params=None, *args, **kwargs):
        return self.http_request('PUT', cid, data, params, *args, **kwargs)

    def patch(self, cid, data='', params=None, *args, **kwargs):
        return self.http_request('PATCH', cid, data, params, *args, **kwargs)

# ################################################################################################################################

class SudsSOAPWrapper(BaseHTTPSOAPWrapper):
    """ A thin wrapper around the suds SOAP library
    """
    def __init__(self, config):
        super(SudsSOAPWrapper, self).__init__(config)
        self.update_lock = RLock()
        self.config = config
        self.config['timeout'] = float(self.config['timeout'])
        self.config_no_sensitive = deepcopy(self.config)
        self.config_no_sensitive['password'] = '***'
        self.address = '{}{}'.format(self.config['address_host'], self.config['address_url_path'])
        self.conn_type = 'Suds SOAP'
        self.client = ConnectionQueue(
            self.config['pool_size'], self.config['queue_build_cap'], self.config['name'], self.conn_type, self.address,
            self.add_client)

    def add_client(self):

        logger.info('About to add a client to `%s` (%s)', self.address, self.conn_type)

        # Lazily-imported here to make sure gevent monkey patches everything well in advance
        from suds.client import Client
        from suds.transport.https import HttpAuthenticated
        from suds.transport.https import WindowsHttpAuthenticated
        from suds.wsse import Security, UsernameToken

        sec_type = self.config['sec_type']

        if sec_type == SEC_DEF_TYPE.BASIC_AUTH:
            transport = HttpAuthenticated(**self.suds_auth)

        elif sec_type == SEC_DEF_TYPE.NTLM:
            transport = WindowsHttpAuthenticated(**self.suds_auth)

        elif sec_type == SEC_DEF_TYPE.WSS:
            security = Security()
            token = UsernameToken(self.suds_auth['username'], self.suds_auth['password'])
            security.tokens.append(token)

            client = Client(self.address, autoblend=True, wsse=security)

        if sec_type in(SEC_DEF_TYPE.BASIC_AUTH, SEC_DEF_TYPE.NTLM):
            client = Client(self.address, autoblend=True, transport=transport)

        # Still could be either none at all or WSS
        if not sec_type:
            client = Client(self.address, autoblend=True, timeout=self.config['timeout'])

        self.client.put_client(client)

    def build_client_queue(self):

        with self.update_lock:
            self.client.build_queue()

# ################################################################################################################################

########NEW FILE########
__FILENAME__ = url_data
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from copy import deepcopy
from datetime import datetime
from hashlib import sha256
from json import dumps, loads
from threading import RLock
from traceback import format_exc

# Bunch
from bunch import Bunch

# oauth
from oauth.oauth import OAuthDataStore, OAuthConsumer, OAuthRequest, \
     OAuthServer, OAuthSignatureMethod_HMAC_SHA1, OAuthSignatureMethod_PLAINTEXT, \
     OAuthToken

# parse
from parse import compile as parse_compile

# sec-wall
from secwall.server import on_basic_auth, on_wsse_pwd
from secwall.wsse import WSSE

# Zato
from zato.common import AUDIT_LOG, DATA_FORMAT, MISC, MSG_PATTERN_TYPE, SEC_DEF_TYPE, TRACE1, URL_TYPE, ZATO_NONE
from zato.common.broker_message import CHANNEL
from zato.server.connection.http_soap import Unauthorized

logger = logging.getLogger(__name__)

class OAuthStore(object):
    def __init__(self, oauth_config):
        self.oauth_config = oauth_config

class URLData(OAuthDataStore):
    """ Performs URL matching and all the HTTP/SOAP-related security checks.
    """
    def __init__(self, channel_data=None, url_sec=None, basic_auth_config=None, ntlm_config=None, oauth_config=None,
                 tech_acc_config=None, wss_config=None, apikey_config=None, aws_config=None, openstack_config=None,
                 xpath_sec_config=None, kvdb=None, broker_client=None, odb=None, json_pointer_store=None, xpath_store=None):
        self.channel_data = channel_data
        self.url_sec = url_sec
        self.basic_auth_config = basic_auth_config
        self.ntlm_config = ntlm_config
        self.oauth_config = oauth_config
        self.tech_acc_config = tech_acc_config
        self.wss_config = wss_config
        self.apikey_config = apikey_config
        self.aws_config = aws_config
        self.openstack_config = openstack_config
        self.xpath_sec_config = xpath_sec_config
        self.kvdb = kvdb
        self.broker_client = broker_client
        self.odb = odb

        self.json_pointer_store = json_pointer_store
        self.xpath_store = xpath_store

        self.url_sec_lock = RLock()
        self.update_lock = RLock()
        self._wss = WSSE()
        self._target_separator = MISC.SEPARATOR

        self._oauth_server = OAuthServer(self)
        self._oauth_server.add_signature_method(OAuthSignatureMethod_HMAC_SHA1())
        self._oauth_server.add_signature_method(OAuthSignatureMethod_PLAINTEXT())

# ################################################################################################################################

    # OAuth data store API

    def _lookup_oauth(self, username, class_):
        # usernames are unique so we know the first match is ours
        for sec_config in self.oauth_config.values():
            if sec_config.config.username == username:
                return class_(sec_config.config.username, sec_config.config.password)

    def lookup_consumer(self, key):
        return self._lookup_oauth(key, OAuthConsumer)

    def lookup_token(self, token_type, token_field):
        return self._lookup_oauth(token_field, OAuthToken)

    def lookup_nonce(self, oauth_consumer, oauth_token, nonce):
        for sec_config in self.oauth_config.values():
            if sec_config.config.username == oauth_consumer.key:

                # The nonce was reused
                existing_nonce = self.kvdb.has_oauth_nonce(oauth_consumer.key, nonce)
                if existing_nonce:
                    return nonce
                else:
                    # No such nonce so we add it to the store
                    self.kvdb.add_oauth_nonce(
                        oauth_consumer.key, nonce, sec_config.config.max_nonce_log)

    def fetch_request_token(self, oauth_consumer, oauth_callback):
        """-> OAuthToken."""
        raise NotImplementedError

    def fetch_access_token(self, oauth_consumer, oauth_token, oauth_verifier):
        """-> OAuthToken."""
        raise NotImplementedError

    def authorize_request_token(self, oauth_token, user):
        """-> OAuthToken."""
        raise NotImplementedError

# ################################################################################################################################

    def _handle_security_apikey(self, cid, sec_def, path_info, body, wsgi_environ, ignored_post_data=None):
        """ Performs the authentication against an API key in a specified HTTP header.
        """
        expected_key = sec_def['password']
        actual_key = wsgi_environ.get(sec_def['username'])

        if not actual_key:
            msg = 'UNAUTHORIZED path_info:`{}`, cid:`{}`'.format(path_info, cid)
            logger.error(msg + ' (No header)')
            raise Unauthorized(cid, msg, 'zato-apikey')

        if actual_key != expected_key:
            msg = 'UNAUTHORIZED path_info:`{}`, cid:`{}`'.format(path_info, cid)
            logger.error(msg + ' (Invalid key)')
            raise Unauthorized(cid, msg, 'zato-apikey')

    def _handle_security_basic_auth(self, cid, sec_def, path_info, body, wsgi_environ, ignored_post_data=None):
        """ Performs the authentication using HTTP Basic Auth.
        """
        env = {'HTTP_AUTHORIZATION':wsgi_environ.get('HTTP_AUTHORIZATION')}
        url_config = {'basic-auth-username':sec_def.username, 'basic-auth-password':sec_def.password}

        result = on_basic_auth(env, url_config, False)

        if not result:
            msg = 'UNAUTHORIZED path_info:[{}], cid:[{}], sec-wall code:[{}], description:[{}]\n'.format(
                path_info, cid, result.code, result.description)
            logger.error(msg)
            raise Unauthorized(cid, msg, 'Basic realm="{}"'.format(sec_def.realm))

    def _handle_security_wss(self, cid, sec_def, path_info, body, wsgi_environ, ignored_post_data=None):
        """ Performs the authentication using WS-Security.
        """
        if not body:
            raise Unauthorized(cid, 'No message body found in [{}]'.format(body), 'zato-wss')

        url_config = {}

        url_config['wsse-pwd-password'] = sec_def['password']
        url_config['wsse-pwd-username'] = sec_def['username']
        url_config['wsse-pwd-reject-empty-nonce-creation'] = sec_def['reject_empty_nonce_creat']
        url_config['wsse-pwd-reject-stale-tokens'] = sec_def['reject_stale_tokens']
        url_config['wsse-pwd-reject-expiry-limit'] = sec_def['reject_expiry_limit']
        url_config['wsse-pwd-nonce-freshness-time'] = sec_def['nonce_freshness_time']

        try:
            result = on_wsse_pwd(self._wss, url_config, body, False)
        except Exception, e:
            msg = 'Could not parse the WS-Security data, body:[{}], e:[{}]'.format(body, format_exc(e))
            raise Unauthorized(cid, msg, 'zato-wss')

        if not result:
            msg = 'UNAUTHORIZED path_info:[{}], cid:[{}], sec-wall code:[{}], description:[{}]\n'.format(
                path_info, cid, result.code, result.description)
            logger.error(msg)
            raise Unauthorized(cid, msg, 'zato-wss')

    def _handle_security_oauth(self, cid, sec_def, path_info, body, wsgi_environ, post_data):
        """ Performs the authentication using OAuth.
        """
        http_url = '{}://{}{}'.format(wsgi_environ['wsgi.url_scheme'],
            wsgi_environ['HTTP_HOST'], wsgi_environ['RAW_URI'])

        # The underlying library needs Authorization instead of HTTP_AUTHORIZATION
        http_auth_header = wsgi_environ.get('HTTP_AUTHORIZATION')

        if not http_auth_header:
            msg = 'No Authorization header in wsgi_environ:[%r]'
            logger.error(msg, wsgi_environ)
            raise Unauthorized(cid, 'No Authorization header found', 'OAuth')

        wsgi_environ['Authorization'] = http_auth_header

        oauth_request = OAuthRequest.from_request(
            wsgi_environ['REQUEST_METHOD'], http_url, wsgi_environ, post_data.copy(),
            wsgi_environ['QUERY_STRING'])

        if oauth_request is None:
            msg = 'No sig could be built using wsgi_environ:[%r], post_data:[%r]'
            logger.error(msg, wsgi_environ, post_data)
            raise Unauthorized(cid, 'No parameters to build signature found', 'OAuth')

        try:
            self._oauth_server.verify_request(oauth_request)
        except Exception, e:
            msg = 'Signature verification failed, wsgi_environ:[%r], e:[%s], e.message:[%s]'
            logger.error(msg, wsgi_environ, format_exc(e), e.message)
            raise Unauthorized(cid, 'Signature verification failed', 'OAuth')
        else:
            # Store for later use, custom channels may want to inspect it later on
            wsgi_environ['zato.oauth.request'] = oauth_request

    def _handle_security_tech_acc(self, cid, sec_def, path_info, body, wsgi_environ, ignored_post_data=None):
        """ Performs the authentication using technical accounts.
        """
        zato_headers = ('HTTP_X_ZATO_USER', 'HTTP_X_ZATO_PASSWORD')

        for header in zato_headers:
            if not wsgi_environ.get(header, None):
                error_msg = ("[{}] The header [{}] doesn't exist or is empty, URI:[{}, wsgi_environ:[{}]]").\
                    format(cid, header, path_info, wsgi_environ)
                logger.error(error_msg)
                raise Unauthorized(cid, error_msg, 'zato-tech-acc')

        # Note that logs get a specific information what went wrong whereas the
        # user gets a generic 'username or password' message
        msg_template = '[{}] The {} is incorrect, URI:[{}], X_ZATO_USER:[{}]'

        if wsgi_environ['HTTP_X_ZATO_USER'] != sec_def.name:
            error_msg = msg_template.format(cid, 'username', path_info, wsgi_environ['HTTP_X_ZATO_USER'])
            user_msg = msg_template.format(cid, 'username or password', path_info, wsgi_environ['HTTP_X_ZATO_USER'])
            logger.error(error_msg)
            raise Unauthorized(cid, user_msg, 'zato-tech-acc')

        incoming_password = sha256(wsgi_environ['HTTP_X_ZATO_PASSWORD'] + ':' + sec_def.salt).hexdigest()

        if incoming_password != sec_def.password:
            error_msg = msg_template.format(cid, 'password', path_info, wsgi_environ['HTTP_X_ZATO_USER'])
            user_msg = msg_template.format(cid, 'username or password', path_info, wsgi_environ['HTTP_X_ZATO_USER'])
            logger.error(error_msg)
            raise Unauthorized(cid, user_msg, 'zato-tech-acc')

        return wsgi_environ['HTTP_X_ZATO_USER']

    def _handle_security_xpath_sec(self, cid, sec_def, ignored_path_info, ignored_body, wsgi_environ, ignored_post_data=None):

        payload = wsgi_environ['zato.request.payload']
        user_msg = 'Invalid username or password'

        username = payload.xpath(sec_def.username_expr)
        if not username:
            logger.error('%s `%s` expr:`%s`, value:`%r`', user_msg, '(no username)', sec_def.username_expr, username)
            raise Unauthorized(cid, user_msg, 'zato-xpath')

        username = username[0]

        if username != sec_def.username:
            logger.error('%s `%s` expr:`%s`, value:`%r`', user_msg, '(username)', sec_def.username_expr, username)
            raise Unauthorized(cid, user_msg, 'zato-xpath')

        if sec_def.get('password_expr'):

            password = payload.xpath(sec_def.password_expr)
            if not password:
                logger.error('%s `%s` expr:`%s`', user_msg, '(no password)', sec_def.password_expr)
                raise Unauthorized(cid, user_msg, 'zato-xpath')

            password = password[0]

            if password != sec_def.password:
                logger.error('%s `%s` expr:`%s`', user_msg, '(password)', sec_def.password_expr)
                raise Unauthorized(cid, user_msg, 'zato-xpath')

        return True

# ################################################################################################################################

    def match(self, url_path, soap_action):
        """ Attemps to match the combination of SOAP Action and URL path against
        the list of HTTP channel targets.
        """
        target = '{}{}{}'.format(soap_action, self._target_separator, url_path)
        for item in self.channel_data:
            match = item.match_target_compiled.parse(target)
            if match:
                if logger.isEnabledFor(TRACE1):
                    logger.log(TRACE1, 'Matched target:[%s] with:[%r]', target, item)
                return match, item

        return None, None

    def check_security(self, sec, cid, channel_item, path_info, payload, wsgi_environ, post_data):
        """ Authenticates and authorizes a given request. Returns None on success
        or raises an exception otherwise.
        """
        if sec.sec_def != ZATO_NONE:
            sec_def, sec_def_type = sec.sec_def, sec.sec_def.sec_type
            handler_name = '_handle_security_{0}'.format(sec_def_type.replace('-', '_'))
            getattr(self, handler_name)(
                cid, sec_def, path_info, payload, wsgi_environ, post_data)

    def _update_url_sec(self, msg, sec_def_type, delete=False):
        """ Updates URL security definitions that use the security configuration
        of the name and type given in 'msg' so that existing definitions use
        the new configuration or, optionally, deletes the URL security definition
        altogether if 'delete' is True.
        """
        for target_match, url_info in self.url_sec.items():
            sec_def = url_info.sec_def
            if sec_def != ZATO_NONE and sec_def.sec_type == sec_def_type:
                name = msg.get('old_name') if msg.get('old_name') else msg.get('name')
                if sec_def.name == name:
                    if delete:
                        del self.url_sec[target_match]
                    else:
                        for key, new_value in msg.items():
                            if key in sec_def:
                                sec_def[key] = msg[key]

# ################################################################################################################################

    def _delete_channel_data(self, sec_type, sec_name):
        match_idx = ZATO_NONE
        for item in self.channel_data:
            if item.sec_type == sec_type and item.security_name == sec_name:
                match_idx = self.channel_data.index(item)

        # No error, let's delete channel info
        if match_idx != ZATO_NONE:
            self.channel_data.pop(match_idx)

# ################################################################################################################################

    def _update_apikey(self, name, config):
        self.apikey_config[name] = Bunch()
        self.apikey_config[name].config = config

    def apikey_get(self, name):
        """ Returns the configuration of the API key of the given name.
        """
        with self.url_sec_lock:
            return self.apikey_config.get(name)

    def on_broker_msg_SECURITY_APIKEY_CREATE(self, msg, *args):
        """ Creates a new API key security definition.
        """
        with self.url_sec_lock:
            self._update_apikey(msg.name, msg)

    def on_broker_msg_SECURITY_APIKEY_EDIT(self, msg, *args):
        """ Updates an existing API key security definition.
        """
        with self.url_sec_lock:
            del self.apikey_config[msg.old_name]
            self._update_apikey(msg.name, msg)
            self._update_url_sec(msg, SEC_DEF_TYPE.APIKEY)

    def on_broker_msg_SECURITY_APIKEY_DELETE(self, msg, *args):
        """ Deletes an API key security definition.
        """
        with self.url_sec_lock:
            self._delete_channel_data('apikey', msg.name)
            del self.apikey_config[msg.name]
            self._update_url_sec(msg, SEC_DEF_TYPE.APIKEY, True)

    def on_broker_msg_SECURITY_APIKEY_CHANGE_PASSWORD(self, msg, *args):
        """ Changes password of an API key security definition.
        """
        with self.url_sec_lock:
            self.apikey_config[msg.name]['config']['password'] = msg.password
            self._update_url_sec(msg, SEC_DEF_TYPE.APIKEY)

# ################################################################################################################################

    def _update_aws(self, name, config):
        self.aws_config[name] = Bunch()
        self.aws_config[name].config = config

    def aws_get(self, name):
        """ Returns the configuration of the AWS security definition of the given name.
        """
        with self.url_sec_lock:
            return self.aws_config.get(name)

    def on_broker_msg_SECURITY_AWS_CREATE(self, msg, *args):
        """ Creates a new AWS security definition.
        """
        with self.url_sec_lock:
            self._update_aws(msg.name, msg)

    def on_broker_msg_SECURITY_AWS_EDIT(self, msg, *args):
        """ Updates an existing AWS security definition.
        """
        with self.url_sec_lock:
            del self.aws_config[msg.old_name]
            self._update_aws(msg.name, msg)

    def on_broker_msg_SECURITY_AWS_DELETE(self, msg, *args):
        """ Deletes an AWS security definition.
        """
        with self.url_sec_lock:
            self._delete_channel_data('aws', msg.name)
            del self.aws_config[msg.name]

    def on_broker_msg_SECURITY_AWS_CHANGE_PASSWORD(self, msg, *args):
        """ Changes password of an AWS security definition.
        """
        with self.url_sec_lock:
            self.aws_config[msg.name]['config']['password'] = msg.password

# ################################################################################################################################

    def _update_openstack(self, name, config):
        self.openstack_config[name] = Bunch()
        self.openstack_config[name].config = config

    def openstack_get(self, name):
        """ Returns the configuration of the OpenStack security definition of the given name.
        """
        with self.url_sec_lock:
            return self.openstack_config.get(name)

    def on_broker_msg_SECURITY_OPENSTACK_CREATE(self, msg, *args):
        """ Creates a new OpenStack security definition.
        """
        with self.url_sec_lock:
            self._update_openstack(msg.name, msg)

    def on_broker_msg_SECURITY_OPENSTACK_EDIT(self, msg, *args):
        """ Updates an existing OpenStack security definition.
        """
        with self.url_sec_lock:
            del self.openstack_config[msg.old_name]
            self._update_openstack(msg.name, msg)

    def on_broker_msg_SECURITY_OPENSTACK_DELETE(self, msg, *args):
        """ Deletes an OpenStack security definition.
        """
        with self.url_sec_lock:
            self._delete_channel_data('openstack', msg.name)
            del self.openstack_config[msg.name]

    def on_broker_msg_SECURITY_OPENSTACK_CHANGE_PASSWORD(self, msg, *args):
        """ Changes password of an OpenStack security definition.
        """
        with self.url_sec_lock:
            self.openstack_config[msg.name]['config']['password'] = msg.password

# ################################################################################################################################

    def _update_basic_auth(self, name, config):
        self.basic_auth_config[name] = Bunch()
        self.basic_auth_config[name].config = config

    def basic_auth_get(self, name):
        """ Returns the configuration of the HTTP Basic Auth security definition
        of the given name.
        """
        with self.url_sec_lock:
            return self.basic_auth_config.get(name)

    def on_broker_msg_SECURITY_BASIC_AUTH_CREATE(self, msg, *args):
        """ Creates a new HTTP Basic Auth security definition.
        """
        with self.url_sec_lock:
            self._update_basic_auth(msg.name, msg)

    def on_broker_msg_SECURITY_BASIC_AUTH_EDIT(self, msg, *args):
        """ Updates an existing HTTP Basic Auth security definition.
        """
        with self.url_sec_lock:
            del self.basic_auth_config[msg.old_name]
            self._update_basic_auth(msg.name, msg)
            self._update_url_sec(msg, SEC_DEF_TYPE.BASIC_AUTH)

    def on_broker_msg_SECURITY_BASIC_AUTH_DELETE(self, msg, *args):
        """ Deletes an HTTP Basic Auth security definition.
        """
        with self.url_sec_lock:
            self._delete_channel_data('basic_auth', msg.name)
            del self.basic_auth_config[msg.name]
            self._update_url_sec(msg, SEC_DEF_TYPE.BASIC_AUTH, True)

    def on_broker_msg_SECURITY_BASIC_AUTH_CHANGE_PASSWORD(self, msg, *args):
        """ Changes password of an HTTP Basic Auth security definition.
        """
        with self.url_sec_lock:
            self.basic_auth_config[msg.name]['config']['password'] = msg.password
            self._update_url_sec(msg, SEC_DEF_TYPE.BASIC_AUTH)

# ################################################################################################################################

    def _update_ntlm(self, name, config):
        self.ntlm_config[name] = Bunch()
        self.ntlm_config[name].config = config

    def ntlm_get(self, name):
        """ Returns the configuration of the NTLM security definition of the given name.
        """
        with self.url_sec_lock:
            return self.ntlm_config.get(name)

    def on_broker_msg_SECURITY_NTLM_CREATE(self, msg, *args):
        """ Creates a new NTLM security definition.
        """
        with self.url_sec_lock:
            self._update_ntlm(msg.name, msg)

    def on_broker_msg_SECURITY_NTLM_EDIT(self, msg, *args):
        """ Updates an existing NTLM security definition.
        """
        with self.url_sec_lock:
            del self.ntlm_config[msg.old_name]
            self._update_ntlm(msg.name, msg)
            self._update_url_sec(msg, SEC_DEF_TYPE.NTLM)

    def on_broker_msg_SECURITY_NTLM_DELETE(self, msg, *args):
        """ Deletes an NTLM security definition.
        """
        with self.url_sec_lock:
            self._delete_channel_data('ntlm', msg.name)
            del self.ntlm_config[msg.name]
            self._update_url_sec(msg, SEC_DEF_TYPE.NTLM, True)

    def on_broker_msg_SECURITY_NTLM_CHANGE_PASSWORD(self, msg, *args):
        """ Changes password of an NTLM security definition.
        """
        with self.url_sec_lock:
            self.ntlm_config[msg.name]['config']['password'] = msg.password
            self._update_url_sec(msg, SEC_DEF_TYPE.NTLM)

# ################################################################################################################################

    def _update_oauth(self, name, config):
        self.oauth_config[name] = Bunch()
        self.oauth_config[name].config = config

    def oauth_get(self, name):
        """ Returns the configuration of the OAuth account of the given name.
        """
        with self.url_sec_lock:
            return self.oauth_config.get(name)

    def on_broker_msg_SECURITY_OAUTH_CREATE(self, msg, *args):
        """ Creates a new OAuth account.
        """
        with self.url_sec_lock:
            self._update_oauth(msg.name, msg)

    def on_broker_msg_SECURITY_OAUTH_EDIT(self, msg, *args):
        """ Updates an existing OAuth account.
        """
        with self.url_sec_lock:
            del self.oauth_config[msg.old_name]
            self._update_oauth(msg.name, msg)
            self._update_url_sec(msg, SEC_DEF_TYPE.OAUTH)

    def on_broker_msg_SECURITY_OAUTH_DELETE(self, msg, *args):
        """ Deletes an OAuth account.
        """
        with self.url_sec_lock:
            self._delete_channel_data('oauth', msg.name)
            del self.oauth_config[msg.name]
            self._update_url_sec(msg, SEC_DEF_TYPE.OAUTH, True)

    def on_broker_msg_SECURITY_OAUTH_CHANGE_PASSWORD(self, msg, *args):
        """ Changes the password of an OAuth account.
        """
        with self.url_sec_lock:
            self.oauth_config[msg.name]['config']['password'] = msg.password
            self._update_url_sec(msg, SEC_DEF_TYPE.OAUTH)

# ################################################################################################################################

    def _update_tech_acc(self, name, config):
        self.tech_acc_config[name] = Bunch()
        self.tech_acc_config[name].config = config

    def tech_acc_get(self, name):
        """ Returns the configuration of the technical account of the given name.
        """
        with self.url_sec_lock:
            return self.tech_acc_config.get(name)

    def on_broker_msg_SECURITY_TECH_ACC_CREATE(self, msg, *args):
        """ Creates a new technical account.
        """
        with self.url_sec_lock:
            self._update_tech_acc(msg.name, msg)

    def on_broker_msg_SECURITY_TECH_ACC_EDIT(self, msg, *args):
        """ Updates an existing technical account.
        """
        with self.url_sec_lock:
            del self.tech_acc_config[msg.old_name]
            self._update_tech_acc(msg.name, msg)
            self._update_url_sec(msg, SEC_DEF_TYPE.TECH_ACCOUNT)

    def on_broker_msg_SECURITY_TECH_ACC_DELETE(self, msg, *args):
        """ Deletes a technical account.
        """
        with self.url_sec_lock:
            self._delete_channel_data('tech_acc', msg.name)
            del self.tech_acc_config[msg.name]
            self._update_url_sec(msg, SEC_DEF_TYPE.TECH_ACCOUNT, True)

    def on_broker_msg_SECURITY_TECH_ACC_CHANGE_PASSWORD(self, msg, *args):
        """ Changes the password of a technical account.
        """
        with self.url_sec_lock:
            # The message's 'password' attribute already takes the salt
            # into account (pun intended ;-))
            self.tech_acc_config[msg.name]['config']['password'] = msg.password
            self._update_url_sec(msg, SEC_DEF_TYPE.TECH_ACCOUNT)

# ################################################################################################################################

    def _update_wss(self, name, config):
        if name in self.wss_config:
            self.wss_config[name].clear()

        self.wss_config[name] = Bunch()
        self.wss_config[name].config = config

    def wss_get(self, name):
        """ Returns the configuration of the WSS definition of the given name.
        """
        with self.url_sec_lock:
            return self.wss_config.get(name)

    def on_broker_msg_SECURITY_WSS_CREATE(self, msg, *args):
        """ Creates a new WS-Security definition.
        """
        with self.url_sec_lock:
            self._update_wss(msg.name, msg)

    def on_broker_msg_SECURITY_WSS_EDIT(self, msg, *args):
        """ Updates an existing WS-Security definition.
        """
        with self.url_sec_lock:
            del self.wss_config[msg.old_name]
            self._update_wss(msg.name, msg)
            self._update_url_sec(msg, SEC_DEF_TYPE.WSS)

    def on_broker_msg_SECURITY_WSS_DELETE(self, msg, *args):
        """ Deletes a WS-Security definition.
        """
        with self.url_sec_lock:
            self._delete_channel_data('wss', msg.name)
            del self.wss_config[msg.name]
            self._update_url_sec(msg, SEC_DEF_TYPE.WSS, True)

    def on_broker_msg_SECURITY_WSS_CHANGE_PASSWORD(self, msg, *args):
        """ Changes the password of a WS-Security definition.
        """
        with self.url_sec_lock:
            # The message's 'password' attribute already takes the salt
            # into account.
            self.wss_config[msg.name]['config']['password'] = msg.password
            self._update_url_sec(msg, SEC_DEF_TYPE.WSS)

# ################################################################################################################################

    def _update_xpath_sec(self, name, config):
        self.xpath_sec_config[name] = Bunch()
        self.xpath_sec_config[name].config = config

    def xpath_sec_get(self, name):
        """ Returns the configuration of the XPath security definition
        of the given name.
        """
        with self.url_sec_lock:
            return self.xpath_sec_config.get(name)

    def on_broker_msg_SECURITY_XPATH_SEC_CREATE(self, msg, *args):
        """ Creates a new XPath security definition.
        """
        with self.url_sec_lock:
            self._update_xpath_sec(msg.name, msg)

    def on_broker_msg_SECURITY_XPATH_SEC_EDIT(self, msg, *args):
        """ Updates an existing XPath security definition.
        """
        with self.url_sec_lock:
            del self.xpath_sec_config[msg.old_name]
            self._update_xpath_sec(msg.name, msg)
            self._update_url_sec(msg, SEC_DEF_TYPE.XPATH_SEC)

    def on_broker_msg_SECURITY_XPATH_SEC_DELETE(self, msg, *args):
        """ Deletes an XPath security definition.
        """
        with self.url_sec_lock:
            self._delete_channel_data('xpath_sec', msg.name)
            del self.xpath_sec_config[msg.name]
            self._update_url_sec(msg, SEC_DEF_TYPE.XPATH_SEC, True)

    def on_broker_msg_SECURITY_XPATH_SEC_CHANGE_PASSWORD(self, msg, *args):
        """ Changes password of an XPath security definition.
        """
        with self.url_sec_lock:
            self.xpath_sec_config[msg.name]['config']['password'] = msg.password
            self._update_url_sec(msg, SEC_DEF_TYPE.XPATH_SEC)

# ################################################################################################################################

    def _channel_item_from_msg(self, msg, match_target, old_data={}):
        """ Creates a channel info bunch out of an incoming CREATE_EDIT message.
        """
        channel_item = Bunch()
        for name in('connection', 'data_format', 'host', 'id', 'is_active',
            'is_internal', 'method', 'name', 'ping_method', 'pool_size',
            'service_id',  'impl_name', 'service_name',
            'soap_action', 'soap_version', 'transport', 'url_path',
            'merge_url_params_req', 'url_params_pri', 'params_pri'):

            channel_item[name] = msg[name]

        if msg.get('security_id'):
            channel_item['sec_type'] = msg['sec_type']
            channel_item['security_id'] = msg['security_id']
            channel_item['security_name'] = msg['security_name']

        channel_item.audit_enabled = old_data.get('audit_enabled', False)
        channel_item.audit_max_payload = old_data.get('audit_max_payload', 0)
        channel_item.audit_repl_patt_type = old_data.get('audit_repl_patt_type', None)
        channel_item.replace_patterns_json_pointer = old_data.get('replace_patterns_json_pointer', [])
        channel_item.replace_patterns_xpath = old_data.get('replace_patterns_xpath', [])

        channel_item.service_impl_name = msg.impl_name
        channel_item.match_target = match_target
        channel_item.match_target_compiled = parse_compile(channel_item.match_target)

        return channel_item

    def _sec_info_from_msg(self, msg):
        """ Creates a security info bunch out of an incoming CREATE_EDIT message.
        """
        sec_info = Bunch()
        sec_info.is_active = msg.is_active
        sec_info.data_format = msg.data_format
        sec_info.transport = msg.transport

        if msg.get('security_name'):
            sec_info.sec_def = Bunch()
            sec_config = getattr(self, '{}_config'.format(msg['sec_type']))
            config_item = sec_config[msg['security_name']]

            for k, v in config_item['config'].items():
                sec_info.sec_def[k] = config_item['config'][k]
        else:
            sec_info.sec_def = ZATO_NONE

        return sec_info

    def _create_channel(self, msg, old_data):
        """ Creates a new channel, both its core data and the related security definition.
        """
        match_target = '{}{}{}'.format(msg.soap_action, MISC.SEPARATOR, msg.url_path)
        self.channel_data.append(self._channel_item_from_msg(msg, match_target, old_data))
        self.url_sec[match_target] = self._sec_info_from_msg(msg)

    def _delete_channel(self, msg):
        """ Deletes a channel, both its core data and the related security definition. Returns the deleted data.
        """
        old_match_target = '{}{}{}'.format(
            msg.get('old_soap_action'), MISC.SEPARATOR, msg.get('old_url_path'))

        # In case of an internal error, we won't have the match all
        match_idx = ZATO_NONE
        for item in self.channel_data:
            if item.match_target == old_match_target:
                match_idx = self.channel_data.index(item)

        # No error, let's delete channel info
        if match_idx != ZATO_NONE:
            old_data = self.channel_data.pop(match_idx)
        else:
            old_data = {}

        # Channel's security now
        del self.url_sec[old_match_target]

        return old_data

    def on_broker_msg_CHANNEL_HTTP_SOAP_CREATE_EDIT(self, msg, *args):
        """ Creates or updates an HTTP/SOAP channel.
        """
        with self.url_sec_lock:
            # Only edits have 'old_name', creates don't. So for edits we delete
            # the channel and later recreate it while creates, obviously,
            # get to creation only.
            if msg.get('old_name'):
                old_data = self._delete_channel(msg)
            else:
                old_data = {}

            self._create_channel(msg, old_data)

    def on_broker_msg_CHANNEL_HTTP_SOAP_DELETE(self, msg, *args):
        """ Deletes an HTTP/SOAP channel.
        """
        with self.url_sec_lock:
            self._delete_channel(msg)

# ################################################################################################################################

    def replace_payload(self, pattern_name, payload, pattern_type):
        """ Replaces elements in a given payload using either JSON Pointer or XPath
        """
        store = self.json_pointer_store if pattern_type == MSG_PATTERN_TYPE.JSON_POINTER.id else self.xpath_store

        logger.debug('Replacing pattern:`%r` in`%r` , store:`%r`', pattern_name, payload, store)

        return store.set(pattern_name, payload, AUDIT_LOG.REPLACE_WITH, True)

# ################################################################################################################################

    def _dump_wsgi_environ(self, wsgi_environ):
        """ A convenience method to dump WSGI environment with all the element repr'ed.
        """
        # TODO: There should be another copy of WSGI environ added with password masked out
        env = wsgi_environ.items()
        for elem in env:
            if elem[0] == 'zato.http.channel_item':
                elem[1]['password'] = AUDIT_LOG.REPLACE_WITH

        return dumps({key: repr(value) for key, value in env})

    def audit_set_request(self, cid, channel_item, payload, wsgi_environ):
        """ Stores initial audit information, right after receiving a request.
        """
        if channel_item['audit_repl_patt_type'] == MSG_PATTERN_TYPE.JSON_POINTER.id:
            payload = loads(payload) if payload else ''
            pattern_list = channel_item['replace_patterns_json_pointer']
        else:
            pattern_list = channel_item['replace_patterns_xpath']

        if payload:
            for name in pattern_list:
                logger.debug('Before `%r`:`%r`', name, payload)
                payload = self.replace_payload(name, payload, channel_item.audit_repl_patt_type)
                logger.debug('After `%r`:`%r`', name, payload)

        if channel_item['audit_repl_patt_type'] == MSG_PATTERN_TYPE.JSON_POINTER.id:
            payload = dumps(payload)

        if channel_item['audit_max_payload']:
            payload = payload[:channel_item['audit_max_payload']]

        remote_addr = wsgi_environ.get('HTTP_X_FORWARDED_FOR')
        if not remote_addr:
            remote_addr = wsgi_environ.get('REMOTE_ADDR', '(None)')

        self.odb.audit_set_request_http_soap(channel_item['id'], channel_item['name'], cid, 
            channel_item['transport'], channel_item['connection'], datetime.utcnow(),
            channel_item.get('username'), remote_addr, self._dump_wsgi_environ(wsgi_environ), payload)

    def audit_set_response(self, cid, response, wsgi_environ):
        """ Stores audit info regarding a response to a previous request.
        """
        payload = dumps({
            'cid': cid,
            'invoke_ok': wsgi_environ['zato.http.response.status'][0] not in ('4', '5'),
            'auth_ok':  wsgi_environ['zato.http.response.status'][0] != '4',
            'resp_time': datetime.utcnow().isoformat(),
            'resp_headers': self._dump_wsgi_environ(wsgi_environ),
            'resp_payload': response,
        })

        self.broker_client.publish({
            'cid': cid,
            'data_format':DATA_FORMAT.JSON, 
            'action': CHANNEL.HTTP_SOAP_AUDIT_RESPONSE,
            'payload': payload,
            'service': 'zato.http-soap.set-audit-response-data'
        })

    def on_broker_msg_CHANNEL_HTTP_SOAP_AUDIT_CONFIG(self, msg):
        for item in self.channel_data:
            if item.id == msg.id:
                item.audit_max_payload = msg.audit_max_payload

    def on_broker_msg_CHANNEL_HTTP_SOAP_AUDIT_STATE(self, msg):
        for item in self.channel_data:
            if item.id == msg.id:
                item.audit_enabled = msg.audit_enabled
                break

    def on_broker_msg_CHANNEL_HTTP_SOAP_AUDIT_PATTERNS(self, msg):
        for item in self.channel_data:
            if item.id == msg.id:
                item.audit_repl_patt_type = msg.audit_repl_patt_type

                if item.audit_repl_patt_type == MSG_PATTERN_TYPE.JSON_POINTER.id:
                    item.replace_patterns_json_pointer = msg.pattern_list
                else:
                    item.replace_patterns_xpath = msg.pattern_list

                break

    def _yield_pattern_list(self, msg):
        for item in self.channel_data:
            if msg.msg_pattern_type == MSG_PATTERN_TYPE.JSON_POINTER.id:
                pattern_list = item.replace_patterns_json_pointer 
            else:
                pattern_list = item.replace_patterns_xpath 

            if pattern_list:
                yield pattern_list

    def on_broker_msg_MSG_JSON_POINTER_EDIT(self, msg):
        with self.update_lock:
            for pattern_list in self._yield_pattern_list(msg):
                if msg.old_name in pattern_list:
                    pattern_list.remove(msg.old_name)
                    pattern_list.append(msg.name)

    def on_broker_msg_MSG_JSON_POINTER_DELETE(self, msg):
        with self.update_lock:
            for pattern_list in self._yield_pattern_list(msg):

                try:
                    pattern_list.remove(msg.name)
                except ValueError:
                    # It's OK, this item wasn't using that particular JSON Pointer
                    pass

                yield item.id, pattern_list

# ################################################################################################################################

########NEW FILE########
__FILENAME__ = channel
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging, os
from copy import deepcopy
from threading import RLock, Thread
from time import sleep
from traceback import format_exc

# Bunch
from bunch import Bunch

# Spring Python
from springpython.jms import WebSphereMQJMSException, NoMessageAvailableException
from springpython.jms.core import reserved_attributes

# Zato
from zato.common import TRACE1
from zato.common.broker_message import CHANNEL, MESSAGE_TYPE, TOPICS
from zato.common.util import new_cid
from zato.server.connection import setup_logging, start_connector as _start_connector
from zato.server.connection.jms_wmq import BaseJMSWMQConnection, BaseJMSWMQConnector

ENV_ITEM_NAME = 'ZATO_CONNECTOR_JMS_WMQ_CHANNEL_ID'

# Spring Python's 'text' is our 'payload' hence we need to do away with the 'text' attribute.
# In addition to that, we also need to get cid of all the magic methods.

MESSAGE_ATTRS = deepcopy(reserved_attributes)
MESSAGE_ATTRS.remove('text')
MESSAGE_ATTRS = MESSAGE_ATTRS - set(dir(object) + ['__weakref__', '__dict__', '__module__'])

class ConsumingConnection(BaseJMSWMQConnection):
    def __init__(self, factory, name, queue, callback):
        super(ConsumingConnection, self).__init__(factory, name)
        self.logger = logging.getLogger(self.__class__.__name__)
        self.queue = queue
        self.callback = callback
        self.keep_listening = False
        
    def _close(self):
        self.keep_listening = False
        super(ConsumingConnection, self)._close()
        
    def _on_connected(self):
        super(ConsumingConnection, self)._on_connected()
        
        self.keep_listening = True
        self.logger.debug('Starting listener for [{0}]'.format(self._conn_info()))
        
        while self.keep_listening:
            try:
                msg = self.factory.receive(self.queue, 1000)
                self.logger.log(TRACE1, 'Message received [{0}]'.format(str(msg).decode("utf-8")))
                
                if msg:
                    self.callback(msg)
                
            except NoMessageAvailableException, e:
                self.logger.log(TRACE1, 'No messages [{0}], queue [{1}]'.format(
                    self._conn_info(), self.queue))
                
            except WebSphereMQJMSException, e:
                self.logger.error('Caught [{0}], e.completion_code [{1}], '
                    'e.reason_code [{2}]'.format(format_exc(e), e.completion_code, e.reason_code))
              
                self.keep_listening = False
                self.close()
                
                self.factory._disconnecting = False
                self.keep_connecting = True
                self.start()
            except Exception, e:
                self.logger.error(
                    'Caught an exception, sleeping for 5 seconds, self.queue:[%s], e:[%s]', 
                    self.queue, format_exc(e))
                sleep(5)
        
class ConsumingConnector(BaseJMSWMQConnector):
    """ An AMQP consuming connector started as a subprocess. Each connection to an AMQP
    broker gets its own connector.
    """
    def __init__(self, repo_location=None, def_id=None, channel_id=None, init=True):
        super(ConsumingConnector, self).__init__(repo_location, def_id)
        self.logger = logging.getLogger(self.__class__.__name__)
        self.channel_id = channel_id
        
        self.channel_lock = RLock()
        self.def_lock = RLock()
        
        self.def_ = Bunch()
        self.channel = Bunch()
        
        self.broker_client_id = 'jms-wmq-consuming-connector'
        self.broker_callbacks = {
            TOPICS[MESSAGE_TYPE.TO_JMS_WMQ_CONSUMING_CONNECTOR_ALL]: self.on_broker_msg,
            TOPICS[MESSAGE_TYPE.TO_JMS_WMQ_CONNECTOR_ALL]: self.on_broker_msg
        }
        self.broker_messages = self.broker_callbacks.keys()
        
        if init:
            self._init()
            self._setup_connector()
            
    def filter(self, msg):
        """ Can we handle the incoming message?
        """
        if super(ConsumingConnector, self).filter(msg):
            return True
            
        elif msg.action in(CHANNEL.JMS_WMQ_DELETE, CHANNEL.JMS_WMQ_EDIT):
            return self.channel.id == msg['id']
        
    def _setup_odb(self):
        super(ConsumingConnector, self)._setup_odb()
        
        item = self.odb.get_def_jms_wmq(self.server.cluster.id, self.def_id)
        self.def_.name = item.name
        self.def_.id = item.id
        self.def_.host = item.host
        self.def_.port = item.port
        self.def_.queue_manager = item.queue_manager
        self.def_.channel = item.channel
        self.def_.cache_open_send_queues = item.cache_open_send_queues
        self.def_.cache_open_receive_queues = item.cache_open_receive_queues
        self.def_.use_shared_connections = item.use_shared_connections
        self.def_.ssl = item.ssl
        self.def_.ssl_cipher_spec = item.ssl_cipher_spec
        self.def_.ssl_key_repository = item.ssl_key_repository
        self.def_.needs_mcd = item.needs_mcd
        self.def_.max_chars_printed = item.max_chars_printed
        
        item = self.odb.get_channel_jms_wmq(self.server.cluster.id, self.channel_id)
        self.channel.id = item.id
        self.channel.name = item.name
        self.channel.is_active = item.is_active
        self.channel.queue = str(item.queue)
        self.channel.service = item.service_name
        self.channel.data_format = item.data_format
        self.channel.listener = None
            
    def _recreate_listener(self):
        self._stop_connection()
        
        if self.channel.is_active:
            factory = self._get_factory()
            listener = self._listener(factory, self.channel.queue, self._on_message)
            self.channel.listener = listener

    def _listener(self, factory, queue, handler):
        """ Starts the listener in a new thread and returns it.
        """
        listener = ConsumingConnection(factory, self.channel.name, queue, handler)
        t = Thread(target=listener._run)
        t.start()
        
        return listener
        
    def _setup_connector(self):
        """ Sets up the connector on startup.
        """
        with self.def_lock:
            with self.channel_lock:
                self._recreate_listener()
            
    def _stop_connection(self):
        """ Stops the given channel's listener. The method must be called from 
        a method that holds onto all related RLocks.
        """
        if self.channel.get('listener'):
            listener = self.channel.listener
            listener.close()
            
    def _close_delete(self):
        """ Stops the connections, exits the process.
        """
        with self.def_lock:
            with self.channel_lock:
                self._stop_connection()
                self._close()
                
    def _on_message(self, msg):
        """ Invoked for each message taken off a WebSphere MQ queue.
        """
        with self.def_lock:
            with self.channel_lock:
                params = {}
                params['action'] = CHANNEL.JMS_WMQ_MESSAGE_RECEIVED
                params['service'] = self.channel.service
                params['cid'] = new_cid()
                params['payload'] = msg.text
                params['data_format'] = self.channel.data_format
                
                for attr in MESSAGE_ATTRS:
                    params[attr] = getattr(msg, attr, None)
                
                try:
                    self.broker_client.invoke_async(params)
                except Exception, e:
                    msg = 'Could not invoke_async broker with params:[%s]'
                    self.logger.warn(msg, params)
                
    def on_broker_msg_DEFINITION_JMS_WMQ_EDIT(self, msg, args=None):
        with self.def_lock:
            with self.channel_lock:
                self.def_ = msg
                self._recreate_listener()
                
    def on_broker_msg_CHANNEL_JMS_WMQ_DELETE(self, msg, args=None):
        self._close_delete()
        
    def on_broker_msg_CHANNEL_JMS_WMQ_EDIT(self, msg, args=None):
        with self.def_lock:
            with self.channel_lock:
                listener = self.channel.listener
                self.channel = msg
                self.channel.queue = str(self.channel.queue)
                self.channel.listener = listener
                self._recreate_listener()

def run_connector():
    """ Invoked on the process startup.
    """
    setup_logging()
    
    repo_location = os.environ['ZATO_REPO_LOCATION']
    def_id = os.environ['ZATO_CONNECTOR_DEF_ID']
    item_id = os.environ[ENV_ITEM_NAME]
    
    ConsumingConnector(repo_location, def_id, item_id)
    
    logger = logging.getLogger(__name__)
    logger.debug('Starting JMS WebSphere MQ outgoing, repo_location [{0}], item_id [{1}], def_id [{2}]'.format(
        repo_location, item_id, def_id))
    
def start_connector(repo_location, item_id, def_id):
    _start_connector(repo_location, __file__, ENV_ITEM_NAME, def_id, item_id)
    
if __name__ == '__main__':
    run_connector()

########NEW FILE########
__FILENAME__ = outgoing
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging, os
from datetime import datetime
from threading import RLock, Thread
from traceback import format_exc

# anyjson
from anyjson import dumps

# Bunch
from bunch import Bunch

# retools
from retools.lock import Lock

# Spring Python
from springpython.jms.core import JmsTemplate, TextMessage

# Zato
from zato.common import INVOCATION_TARGET, KVDB, TRACE1
from zato.common.broker_message import MESSAGE_TYPE, OUTGOING, TOPICS
from zato.common.model import DeliveryItem
from zato.common.util import new_cid
from zato.server.connection import setup_logging, start_connector as _start_connector
from zato.server.connection.jms_wmq import BaseJMSWMQConnection, BaseJMSWMQConnector

ENV_ITEM_NAME = 'ZATO_CONNECTOR_JMS_WMQ_OUT_ID'

class WMQFacade(object):
    """ A WebSphere MQ facade for services so they aren't aware that sending WMQ
    messages actually requires us to use the Zato broker underneath.
    """
    def __init__(self, broker_client, delivery_store):
        self.broker_client = broker_client # A Zato broker client
        self.delivery_store = delivery_store
    
    def send(self, msg, out_name, queue, delivery_mode=None, expiration=None, priority=None, max_chars_printed=None, 
            task_id=None, *args, **kwargs):
        """ Puts a message on a WebSphere MQ queue.
        """
        
        # Common parameters
        params = {}
        params['action'] = OUTGOING.JMS_WMQ_SEND
        params['name'] = out_name
        params['body'] = msg
        params['queue'] = queue
        params['delivery_mode'] = int(delivery_mode) if delivery_mode else None
        params['expiration'] = int(expiration) if expiration else None
        params['priority'] = int(priority) if priority else None
        params['max_chars_printed'] = int(max_chars_printed) if max_chars_printed else None
        
        # Confirmed delivery
        if task_id:
            params['confirm_delivery'] = True
            params['task_id'] = task_id
        
        # Any extra arguments
        params['args'] = args
        params['kwargs'] = kwargs

        self.broker_client.publish(params, msg_type=MESSAGE_TYPE.TO_JMS_WMQ_PUBLISHING_CONNECTOR_ALL)
        
    def conn(self):
        """ Returns self. Added to make the facade look like other outgoing
        connection wrappers.
        """
        return self

class OutgoingConnection(BaseJMSWMQConnection):
    def __init__(self, factory, name, kvdb, delivery_store):
        super(OutgoingConnection, self).__init__(factory, name, kvdb, delivery_store)
        self.logger = logging.getLogger(self.__class__.__name__)
        self.jms_template = JmsTemplate(self.factory)
        
        # So people don't have to install PyMQI if they don't need it
        from CMQC import MQRC_UNKNOWN_OBJECT_NAME
        from pymqi import MQMIError
        
        self.MQMIError = MQMIError
        self.dont_reconnect_errors = (MQRC_UNKNOWN_OBJECT_NAME,)
        
    def maybe_on_target_delivery(self, msg, start, end, target_ok, queue, inner_exc=None, needs_reconnect=None):
        if msg.get('confirm_delivery'):
            target_self_info = dumps({
                'name': self.name,
                'details': {
                    'conn_info':self.factory.get_connection_info(),
                    'queue': queue
                }
            })
            
            exc_info = {
                'inner_exc': inner_exc,
                'needs_reconnect': needs_reconnect
            }
            
            self.delivery_store.on_target_completed(
                INVOCATION_TARGET.OUTCONN_WMQ, self.name, msg, start, end, target_ok, target_self_info, exc_info)
        
    def send(self, msg, default_delivery_mode, default_expiration, default_priority, default_max_chars_printed):
        
        jms_msg = TextMessage()
        
        # Common named arguments first
        jms_msg.text = msg.get('body')
        jms_msg.jms_expiration = int(msg.get('expiration') or default_expiration)
        jms_msg.jms_delivery_mode = msg.get('delivery_mode') or default_delivery_mode
        jms_msg.jms_priority = msg.get('priority') or default_priority
        jms_msg.max_chars_printed = msg.get('max_chars_printed') or default_max_chars_printed
        
        kwargs = msg.get('kwargs')
        
        # JMS-specific ones now
        jms_msg.jms_destination = kwargs.get('jms_destination')
        jms_msg.jms_correlation_id = str(kwargs.get('jms_correlation_id'))
        jms_msg.jms_message_id = str(kwargs.get('jms_message_id'))
        jms_msg.jms_redelivered = kwargs.get('jms_redelivered')
        jms_msg.jms_timestamp = kwargs.get('jms_timestamp')
        
        queue = str(msg['queue'])
        
        try:
            start = datetime.utcnow()
            self.jms_template.send(jms_msg, queue)
            self.maybe_on_target_delivery(msg, start, datetime.utcnow(), True, queue)
                
        except Exception, e:
            if isinstance(e, self.MQMIError) and e.reason in self.dont_reconnect_errors:
                self.logger.warn(
                    'Caught [{}/{}] while sending the message [{}] (not reconnecting)'.format(e.reason, e.errorAsString(), jms_msg))
                self.maybe_on_target_delivery(msg, start, datetime.utcnow(), False, queue, format_exc(e), False)
                
            else:
                self.logger.warn('Caught [{}] while sending the message [{}] (reconnecting)'.format(format_exc(e), jms_msg))
                self.maybe_on_target_delivery(msg, start, datetime.utcnow(), False, queue, format_exc(e), True)
                
                if self._keep_connecting(e):
                    self.close()
                    self.keep_connecting = True
                    self.factory._disconnecting = False
                    self.start()
                else:
                    raise
                
class OutgoingConnector(BaseJMSWMQConnector):
    """ An outgoing connector started as a subprocess. Each connection to a queue manager
    gets its own connector.
    """
    def __init__(self, repo_location=None, def_id=None, out_id=None, init=True):
        super(OutgoingConnector, self).__init__(repo_location, def_id)
        self.logger = logging.getLogger(self.__class__.__name__)
        self.out_id = out_id
        
        self.out_lock = RLock()
        self.def_lock = RLock()
        
        self.broker_client_id = 'jms-wmq-outgoing-connector'
        self.broker_callbacks = {
            TOPICS[MESSAGE_TYPE.TO_JMS_WMQ_PUBLISHING_CONNECTOR_ALL]: self.on_broker_msg,
            TOPICS[MESSAGE_TYPE.TO_JMS_WMQ_CONNECTOR_ALL]: self.on_broker_msg
        }
        self.broker_messages = self.broker_callbacks.keys()
        
        if init:
            self._init()
            self._setup_connector()
            
    def _setup_odb(self):
        super(OutgoingConnector, self)._setup_odb()
        
        item = self.odb.get_def_jms_wmq(self.server.cluster.id, self.def_id)
        self.def_ = Bunch()
        self.def_.name = item.name
        self.def_.id = item.id
        self.def_.host = item.host
        self.def_.port = item.port
        self.def_.queue_manager = item.queue_manager
        self.def_.channel = item.channel
        self.def_.cache_open_send_queues = item.cache_open_send_queues
        self.def_.cache_open_receive_queues = item.cache_open_receive_queues
        self.def_.use_shared_connections = item.use_shared_connections
        self.def_.ssl = item.ssl
        self.def_.ssl_cipher_spec = item.ssl_cipher_spec
        self.def_.ssl_key_repository = item.ssl_key_repository
        self.def_.needs_mcd = item.needs_mcd
        self.def_.max_chars_printed = item.max_chars_printed
        
        item = self.odb.get_out_jms_wmq(self.server.cluster.id, self.out_id)
        self.out = Bunch()
        self.out.id = item.id
        self.out.name = item.name
        self.out.is_active = item.is_active
        self.out.delivery_mode = item.delivery_mode
        self.out.priority = item.priority
        self.out.expiration = item.expiration
        self.out.sender = None
        
    def filter(self, msg):
        """ Can we handle the incoming message?
        """
        if super(OutgoingConnector, self).filter(msg):
            return True

        elif msg.action in(OUTGOING.JMS_WMQ_DELETE, OUTGOING.JMS_WMQ_EDIT):
            return self.out.name == msg['old_name']
        
        elif msg.action == OUTGOING.JMS_WMQ_SEND:
            return self.out.name == msg['name']
        
    def _stop_connection(self):
        """ Stops the given outgoing connection's sender. The method must 
        be called from a method that holds onto all related RLocks.
        """
        if self.out.get('sender'):
            sender = self.out.sender
            sender.close()
        
    def _recreate_sender(self):
        self._stop_connection()
        
        if self.out.is_active:
            factory = self._get_factory()
            sender = self._sender(factory)
            self.out.sender = sender

    def _sender(self, factory):
        """ Starts the outgoing connection in a new thread and returns it.
        """
        sender = OutgoingConnection(factory, self.out.name, self.kvdb, self.delivery_store)
        t = Thread(target=sender._run)
        t.start()
        
        return sender
        
    def _setup_connector(self):
        """ Sets up the connector on startup.
        """
        with self.out_lock:
            with self.def_lock:
                self._recreate_sender()
                
    def _close_delete(self):
        """ Stops the connections, exits the process.
        """
        with self.def_lock:
            with self.out_lock:
                self._stop_connection()
                self._close()

    def on_broker_msg_DEFINITION_JMS_WMQ_EDIT(self, msg, args=None):
        with self.def_lock:
            with self.out_lock:
                self.def_ = msg
                self._recreate_sender()
                
    def on_broker_msg_OUTGOING_JMS_WMQ_SEND(self, msg, args=None):
        """ Puts a message on a queue.
        """
        if not self.out.get('is_active'):
            log_msg = 'Not sending, the connection is not active [{0}]'.format(self.out)
            self.logger.info(log_msg)
            return
            
        if self.out.get('sender'):
            if self.out.get('sender').factory._is_connected:
                self.out.sender.send(msg, self.out.delivery_mode, self.out.expiration, 
                    self.out.priority, self.def_.max_chars_printed)
            else:
                if self.logger.isEnabledFor(logging.DEBUG):
                    log_msg = 'Not sending, the factory for [{0}] is not connected'.format(self.out)
                    self.logger.debug(log_msg)
        else:
            if self.logger.isEnabledFor(TRACE1):
                log_msg = 'No sender for [{0}]'.format(self.out)
                self.logger.log(TRACE1, log_msg)
                
    def on_broker_msg_OUTGOING_JMS_WMQ_DELETE(self, msg, args=None):
        self._close_delete()
        
    def on_broker_msg_OUTGOING_JMS_WMQ_EDIT(self, msg, args=None):
        with self.def_lock:
            with self.out_lock:
                sender = self.out.get('sender')
                self.out = msg
                self.out.sender = sender
                self._recreate_sender()

def run_connector():
    """ Invoked on the process startup.
    """
    setup_logging()
    
    repo_location = os.environ['ZATO_REPO_LOCATION']
    def_id = os.environ['ZATO_CONNECTOR_DEF_ID']
    item_id = os.environ[ENV_ITEM_NAME]
    
    OutgoingConnector(repo_location, def_id, item_id)
    
    logger = logging.getLogger(__name__)
    logger.debug('Starting JMS WebSphere MQ outgoing, repo_location [{0}], item_id [{1}], def_id [{2}]'.format(
        repo_location, item_id, def_id))
    
def start_connector(repo_location, item_id, def_id):
    _start_connector(repo_location, __file__, ENV_ITEM_NAME, def_id, item_id)
    
if __name__ == '__main__':
    run_connector()

########NEW FILE########
__FILENAME__ = queue
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from datetime import datetime, timedelta

# gevent
import gevent
from gevent.lock import RLock
from gevent.queue import Empty, Queue

# A set of utilities for constructing greenlets-safe outgoing connection objects.
# Used, for instance, in SOAP Suds and OpenStack Swift outconns.

logger = logging.getLogger(__name__)

# ################################################################################################################################

class _Connection(object):
    """ Meant to be used as a part of a 'with' block - returns a connection from its queue each time 'with' is entered
    assuming the queue isn't empty.
    """
    def __init__(self, client_queue, conn_name):
        self.queue = client_queue
        self.conn_name = conn_name
        self.client = None

    def __enter__(self):
        try:
            self.client = self.queue.get(block=False)
        except Empty:
            self.client = None
            msg = 'No free connections to `{}`'.format(self.conn_name)
            logger.error(msg)
            raise Exception(msg)
        else:
            return self.client

    def __exit__(self, type, value, traceback):
        if self.client:
            self.queue.put(self.client)

# ################################################################################################################################

class ConnectionQueue(object):
    """ Holds connections to resources. Each time it's called a connection is fetched from its underlying queue
    assuming any connection is still available.
    """
    def __init__(self, pool_size, queue_build_cap, conn_name, conn_type, address, add_client_func):
        self.queue = Queue(pool_size)
        self.queue_build_cap = queue_build_cap
        self.conn_name = conn_name
        self.conn_type = conn_type
        self.address = address
        self.add_client_func = add_client_func

        self.logger = logging.getLogger(self.__class__.__name__)

    def __call__(self):
        return _Connection(self.queue, self.conn_name)

    def put_client(self, client):
        self.queue.put(client)
        self.logger.info('Added `%s` client to %s (%s)', self.conn_name, self.address, self.conn_type)

    def build_queue(self):
        """ Spawns greenlets to populate the queue and waits up to self.queue_build_cap seconds until the queue is full.
        If it never is, raises an exception stating so.
        """
        for x in range(self.queue.maxsize):
            gevent.spawn(self.add_client_func)

        start = datetime.utcnow()
        build_until = start + timedelta(seconds=self.queue_build_cap)

        while not self.queue.full():
            gevent.sleep(0.5)

            now = datetime.utcnow()
            if  now >= build_until:

                self.logger.error('Built %s/%s %s clients to `%s` within %s seconds, giving up',
                    self.queue.qsize(), self.queue.maxsize, self.conn_type, self.address, self.queue_build_cap)
                return

            self.logger.info('%d/%d %s clients connected to `%s` (%s) after %s (cap: %ss)',
                self.queue.qsize(), self.queue.maxsize, self.conn_type, self.address, self.conn_name, now - start,
                self.queue_build_cap)

        self.logger.info('Obtained %d %s clients to `%s` for `%s`', self.queue.maxsize, self.conn_type, self.address, self.conn_name)

# ################################################################################################################################

class Wrapper(object):
    """ Base class for connections wrappers.
    """
    def __init__(self, config, conn_type):
        self.conn_type = conn_type
        self.config = config

        self.client = ConnectionQueue(
            self.config.pool_size, self.config.queue_build_cap, self.config.name, self.conn_type, self.config.auth_url,
            self.add_client)

        self.update_lock = RLock()
        self.logger = logging.getLogger(self.__class__.__name__)

    def build_queue(self):
        with self.update_lock:
            self.client.build_queue()
########NEW FILE########
__FILENAME__ = request_response
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

# stdlib
import logging

# Zato
from zato.common import KVDB, TRACE1

logger = logging.getLogger(__name__)

def should_store(kvdb, service_usage, service_name):
    """ Decides whether a service's request/response pair should be kept in the DB.
    """
    key = '{}{}'.format(KVDB.REQ_RESP_SAMPLE, service_name)
    freq = int(kvdb.conn.hget(key, 'freq') or 0)
    
    if freq and service_usage % freq == 0:
        return key, freq
    
    return None, None

def store(kvdb, key, usage, freq, **data):
    """ Stores a service's request/response pair.
    """
    if logger.isEnabledFor(TRACE1):
        msg = 'key:[{}], usage:[{}], freq:[{}], data:[{}]'.format(key, usage, freq, data)
        logger.log(TRACE1, msg)
        
    kvdb.conn.hmset(key, data)

########NEW FILE########
__FILENAME__ = slow_response
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

# stdlib
import logging

# anyjson
from anyjson import dumps

# Zato
from zato.common import KVDB, TRACE1

logger = logging.getLogger(__name__)

def store(kvdb, name, **data):
    """ Stores information regarding an invocation that came later than it was allowed.
    """
    key = '{}{}'.format(KVDB.RESP_SLOW, name)
    data = dumps(data)
    
    if logger.isEnabledFor(TRACE1):
        msg = 'key:[{}], name:[{}], data:[{}]'.format(key, name, data)
        logger.log(TRACE1, msg)
        
    kvdb.conn.lpush(key, data)
    kvdb.conn.ltrim(key, 0, 99) # TODO: This should be configurable

########NEW FILE########
__FILENAME__ = sql
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

""" Manages the server's SQL connection pools.
"""

# stdlib
from copy import deepcopy
from cStringIO import StringIO
from logging import DEBUG, getLogger
from threading import RLock
from traceback import format_exc
from time import time

# SQLAlchemy
from sqlalchemy import create_engine, event
from sqlalchemy.orm import sessionmaker, scoped_session

# validate
from validate import is_boolean, is_integer, VdtTypeError

# Spring Python
from springpython.context import DisposableObject

# Zato
from zato.common import engine_def, Inactive, PASSWORD_SHADOW
from zato.common.odb import ping_queries
from zato.common.odb.util import get_engine_url
from zato.common.util import get_component_name, parse_extra_into_dict

class SessionWrapper(object):
    """ Wraps an SQLAlchemy session.
    """
    def __init__(self):
        self.session_initialized = False
        self.pool = None
        self.config = None
        self.logger = getLogger(self.__class__.__name__)
        
    def init_session(self, name, config, pool, use_scoped_session=True, warn_on_ping_fail=False):
        self.config = config
        self.pool = pool
        
        try:
            self.pool.ping()
        except Exception, e:
            msg = 'Could not ping:[{}], session will be left uninitialized, e:[{}]'.format(name, format_exc(e))
            self.logger.warn(msg)
        else:
            if use_scoped_session:
                self._Session = scoped_session(sessionmaker(bind=self.pool.engine))
            else:
                self._Session = sessionmaker(bind=self.pool.engine)
                
            self._session = self._Session()
            self.session_initialized = True
    
    def session(self):
        return self._Session()
    
    def close(self):
        self._session.close()
    
class SQLConnectionPool(object):
    """ A pool of SQL connections wrapping an SQLAlchemy engine.
    """
    def __init__(self, name, config, config_no_sensitive):
        self.logger = getLogger(self.__class__.__name__)

        self.name = name
        self.config = config
        self.engine_name = config['engine'] # self.engine.name is 'mysql' while 'self.engine_name' is mysql+pymysql

        # Safe for printing out to logs, any sensitive data has been shadowed
        self.config_no_sensitive = config_no_sensitive 
        
        _extra = {}

        # Postgres-only
        if self.engine_name.startswith('mysql'):
            _extra['pool_recycle'] = 600
        elif self.engine_name.startswith('postgres'):
            _extra['connect_args'] = {'application_name': get_component_name()}

        extra = self.config.get('extra') # Optional, hence .get
        _extra.update(parse_extra_into_dict(extra))

        # SQLite has no pools
        if self.engine_name != 'sqlite':
            _extra['pool_size'] = int(config.get('pool_size', 1))

        engine_url = get_engine_url(config)
        self.engine = create_engine(engine_url, **_extra)
        
        event.listen(self.engine, 'checkin', self.on_checkin)
        event.listen(self.engine, 'checkout', self.on_checkout)
        event.listen(self.engine, 'connect', self.on_connect)
        event.listen(self.engine, 'first_connect', self.on_first_connect)
        
    def __str__(self):
        return '<{} at {}, config:[{}]>'.format(self.__class__.__name__, hex(id(self)), self.config_no_sensitive)
    
    __repr__ = __str__
        
    def on_checkin(self, dbapi_conn, conn_record):
        if self.logger.isEnabledFor(DEBUG):
            msg = 'Checked in dbapi_conn:{}, conn_record:{}'.format(dbapi_conn, conn_record)
            self.logger.debug(msg)
            
    def on_checkout(self, dbapi_conn, conn_record, conn_proxy):
        if self.logger.isEnabledFor(DEBUG):
            msg = 'Checked out dbapi_conn:{}, conn_record:{}, conn_proxy:{}'.format(
                dbapi_conn, conn_record, conn_proxy)
            self.logger.debug(msg)
            
    def on_connect(self, dbapi_conn, conn_record):
        if self.logger.isEnabledFor(DEBUG):
            msg = 'Connect dbapi_conn:{}, conn_record:{}'.format(dbapi_conn, conn_record)
            self.logger.debug(msg)
            
    def on_first_connect(self, dbapi_conn, conn_record):
        if self.logger.isEnabledFor(DEBUG):
            msg = 'First connect dbapi_conn:{}, conn_record:{}'.format(dbapi_conn, conn_record)
            self.logger.debug(msg)
        
    def ping(self):
        """ Pings the SQL database and returns the response time, in milliseconds.
        """
        query = ping_queries[self.engine_name]

        self.logger.debug('About to ping the SQL connection pool:[{}], query:[{}]'.format(self.config_no_sensitive, query))

        start_time = time()
        self.engine.connect().execute(query)
        response_time = time() - start_time

        self.logger.debug('Ping OK, pool:[{0}], response_time:[{1:03.4f} s]'.format(self.config_no_sensitive, response_time))

        return response_time
    
    def _conn(self):
        """ Returns an SQLAlchemy connection object.
        """
        return self.engine.connect()
    
    conn = property(fget=_conn, doc=_conn.__doc__)
    
    def _impl(self):
        """ Returns the underlying connection's implementation, the SQLAlchemy engine.
        """
        return self.engine
    
    impl = property(fget=_impl, doc=_impl.__doc__)

class PoolStore(DisposableObject):
    """ A main class for accessing all of the SQL connection pools. Each server
    thread has its own store.
    """
    def __init__(self, sql_conn_class=SQLConnectionPool):
        super(PoolStore, self).__init__()
        self.sql_conn_class = sql_conn_class
        self._lock = RLock()
        self.wrappers = {}
        self.logger = getLogger(self.__class__.__name__)
        
    def __getitem__(self, name, enforce_is_active=True):
        """ Checks out the connection pool. If enforce_is_active is False,
        the pool's is_active flag will be ignored.
        """
        with self._lock:
            if enforce_is_active:
                wrapper = self.wrappers[name]
                if wrapper.config['is_active']:
                    return wrapper
                raise Inactive(name)
            else:
                return self.wrappers[name]
        
    get = __getitem__
        
    def __setitem__(self, name, config):
        """ Stops a connection pool if it exists and replaces it with a new one 
        using updated settings.
        """
        with self._lock:
            if name in self.wrappers:
                del self[name]
                
            config_no_sensitive = deepcopy(config)
            config_no_sensitive['password'] = PASSWORD_SHADOW
            pool = self.sql_conn_class(name, config, config_no_sensitive)

            wrapper = SessionWrapper()
            wrapper.init_session(name, config, pool)
            
            self.wrappers[name] = wrapper
    
    def __delitem__(self, name):
        """ Stops a pool and deletes it from the store.
        """
        with self._lock:
            self.wrappers[name].pool.engine.dispose()
            del self.wrappers[name]
            
    def __str__(self):
        out = StringIO()
        out.write('<{} at {} wrappers:['.format(self.__class__.__name__, hex(id(self))))
        out.write(', '.join(sorted(self.wrappers.keys())))
        out.write(']>')
        return out.getvalue()
    
    __repr__ = __str__
    
    def change_password(self, name, password):
        """ Updates the password which means recreating the pool using the new
        password.
        """
        with self._lock:
            self[name].pool.engine.dispose()
            config = deepcopy(self.wrappers[name].pool.config)
            config['password'] = password
            self[name] = config
        
    def destroy(self):
        """ Invoked when Spring Python's container is releasing the store.
        """
        with self._lock:
            for name, wrapper in self.wrappers.items():
                wrapper.pool.engine.dispose()

########NEW FILE########
__FILENAME__ = channel
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging, os
from threading import RLock, Thread

# Bunch
from bunch import Bunch

# Zato
from zato.common.broker_message import CHANNEL, MESSAGE_TYPE, TOPICS
from zato.common.util import new_cid
from zato.server.connection import setup_logging, start_connector as _start_connector
from zato.server.connection.zmq_ import BaseZMQConnection, BaseZMQConnector

ENV_ITEM_NAME = 'ZATO_CONNECTOR_ZMQ_CHANNEL_ID'

class ConsumingConnection(BaseZMQConnection):
    def __init__(self, factory, name):
        super(ConsumingConnection, self).__init__(factory, name)
        self.logger = logging.getLogger(self.__class__.__name__)
        self.keep_listening = False
        
    def _close(self):
        self.keep_listening = False
        super(ConsumingConnection, self)._close()
        
    def _on_connected(self):
        super(ConsumingConnection, self)._on_connected()
        
        self.keep_listening = True
        self.logger.debug('Starting listener for [{0}]'.format(self._conn_info()))

class ConsumingConnector(BaseZMQConnector):
    """ An AMQP consuming connector started as a subprocess. Each connection to an AMQP
    broker gets its own connector.
    """
    def __init__(self, repo_location=None, channel_id=None, init=True):
        super(ConsumingConnector, self).__init__(repo_location, None)
        self.logger = logging.getLogger(self.__class__.__name__)
        self.channel_id = channel_id
        self.name = None
        
        self.channel_lock = RLock()
        self.channel = Bunch()
        
        self.broker_client_id = 'zmq-consuming-connector'
        self.broker_callbacks = {
            TOPICS[MESSAGE_TYPE.TO_ZMQ_CONSUMING_CONNECTOR_ALL]: self.on_broker_msg,
            TOPICS[MESSAGE_TYPE.TO_ZMQ_CONNECTOR_ALL]: self.on_broker_msg
        }
        self.broker_messages = self.broker_callbacks.keys()
        
        if init:
            self._init()
            self._setup_connector()
            
    def filter(self, msg):
        """ Can we handle the incoming message?
        """
        if super(ConsumingConnector, self).filter(msg):
            return True
            
        elif msg.action in(CHANNEL.ZMQ_DELETE, CHANNEL.ZMQ_EDIT):
            return self.channel.id == msg['id']
        
    def _setup_odb(self):
        super(ConsumingConnector, self)._setup_odb()
        
        item = self.odb.get_channel_zmq(self.server.cluster.id, self.channel_id)
        self.channel.id = item.id
        self.channel.name = item.name
        self.channel.is_active = item.is_active
        self.channel.address = str(item.address)
        self.channel.socket_type = self.socket_type = item.socket_type
        self.channel.service = item.service_name
        self.channel.sub_key = item.sub_key or ''
        self.channel.data_format = item.data_format
        self.channel.listener = None
        
    def _recreate_listener(self):
        self._stop_connection()
        self.name = self.channel.name
        
        if self.channel.is_active:
            factory = self._get_factory(self._on_message, self.channel.address, self.channel.sub_key)
            listener = self._listener(factory)
            self.channel.listener = listener

    def _listener(self, factory):
        """ Starts the listener in a new thread and returns it.
        """
        listener = ConsumingConnection(factory, self.channel.name)
        t = Thread(target=listener._run)
        t.start()
        
        return listener
        
    def _setup_connector(self):
        """ Sets up the connector on startup.
        """
        with self.channel_lock:
            self._recreate_listener()
            
    def _stop_connection(self):
        """ Stops the given channel's listener. The method must be called from 
        a method that holds onto all related RLocks.
        """
        if self.channel.get('listener'):
            listener = self.channel.listener
            listener.close()
            
    def _close_delete(self):
        """ Stops the connections, exits the process.
        """
        with self.channel_lock:
            self._stop_connection()
            self._close()
                
    def _on_message(self, msg, args):
        """ Invoked for each message taken off a ZMQ socket.
        """
        with self.channel_lock:
            params = {}
            params['action'] = CHANNEL.ZMQ_MESSAGE_RECEIVED
            params['service'] = self.channel.service
            params['cid'] = new_cid()
            params['payload'] = msg
            params['data_format'] = self.channel.data_format
            
            self.broker_client.invoke_async(params)
                
    def on_broker_msg_CHANNEL_ZMQ_DELETE(self, msg, args=None):
        self._close_delete()
        
    def on_broker_msg_CHANNEL_ZMQ_EDIT(self, msg, args=None):
        with self.channel_lock:
            listener = self.channel.listener
            
            service_name = self.channel.service
            self.channel = msg
            self.channel.service = service_name
            
            self.socket_type = self.channel.socket_type
            self.channel.sub_key = msg.sub_key or ''
            self.channel.listener = listener
            self._recreate_listener()

def run_connector():
    """ Invoked on the process startup.
    """
    setup_logging()
    
    repo_location = os.environ['ZATO_REPO_LOCATION']
    item_id = os.environ[ENV_ITEM_NAME]
    
    ConsumingConnector(repo_location, item_id)
    
    logger = logging.getLogger(__name__)
    logger.debug('Starting ZMQ outgoing, repo_location [{0}], item_id [{1}]'.format(
        repo_location, item_id))
    
def start_connector(repo_location, item_id):
    _start_connector(repo_location, __file__, ENV_ITEM_NAME, None, item_id)
    
if __name__ == '__main__':
    run_connector()

########NEW FILE########
__FILENAME__ = outgoing
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging, os
from threading import RLock, Thread

# Bunch
from bunch import Bunch

# Zato
from zato.common import TRACE1
from zato.common.broker_message import MESSAGE_TYPE, OUTGOING, TOPICS
from zato.server.connection import setup_logging, start_connector as _start_connector
from zato.server.connection.zmq_ import BaseZMQConnection, BaseZMQConnector

ENV_ITEM_NAME = 'ZATO_CONNECTOR_ZMQ_OUT_ID'

class ZMQFacade(object):
    """ A ZeroMQ facade for services so they aren't aware that sending ZMQ
    messages actually requires us to use the Zato broker underneath.
    """
    def __init__(self, broker_client, delivery_store):
        self.broker_client = broker_client # A Zato broker client
        self.delivery_store = delivery_store
    
    def send(self, msg, out_name, *args, **kwargs):
        """ Puts a message on a ZeroMQ socket.
        """
        params = {}
        params['action'] = OUTGOING.ZMQ_SEND
        params['name'] = out_name
        params['body'] = msg
        params['args'] = args
        params['kwargs'] = kwargs
        
        self.broker_client.publish(params, msg_type=MESSAGE_TYPE.TO_ZMQ_PUBLISHING_CONNECTOR_ALL)
        
    def conn(self):
        """ Returns self. Added to make the facade look like other outgoing
        connection wrappers.
        """
        return self

class OutgoingConnection(BaseZMQConnection):
    """ An outgoing (PUSH) connection to a ZMQ socket.
    """
    def __init__(self, factory, out_name):
        super(OutgoingConnection, self).__init__(factory, out_name)
        self.logger = logging.getLogger(self.__class__.__name__)
        
    def send(self, msg):
        """ Sends a message to a ZMQ socket.
        """
        self.factory.send(msg)
        if self.logger.isEnabledFor(TRACE1):
            self.logger.log(TRACE1, 'Sent {0} name {1} factory {2}'.format(msg, self.name, self.factory))

class OutgoingConnector(BaseZMQConnector):
    """ An outgoing connector started as a subprocess. Each connection to a queue manager
    gets its own connector.
    """
    def __init__(self, repo_location=None, out_id=None, init=True):
        super(OutgoingConnector, self).__init__(repo_location, None)
        self.logger = logging.getLogger(self.__class__.__name__)
        self.out_id = out_id
        
        self.out_lock = RLock()
        
        self.broker_client_id = 'zmq-outgoing-connector'
        self.broker_callbacks = {
            TOPICS[MESSAGE_TYPE.TO_ZMQ_PUBLISHING_CONNECTOR_ALL]: self.on_broker_msg,
            TOPICS[MESSAGE_TYPE.TO_ZMQ_CONNECTOR_ALL]: self.on_broker_msg
        }
        self.broker_messages = self.broker_callbacks.keys()
        
        if init:
            self._init()
            self._setup_connector()
            
    def _setup_odb(self):
        super(OutgoingConnector, self)._setup_odb()
        
        item = self.odb.get_out_zmq(self.server.cluster.id, self.out_id)
        self.out = Bunch()
        self.out.id = item.id
        self.out.name = item.name
        self.out.is_active = item.is_active
        self.out.address = item.address
        self.out.socket_type = self.socket_type = item.socket_type
        self.out.sender = None
        
    def filter(self, msg):
        """ Can we handle the incoming message?
        """
        if super(OutgoingConnector, self).filter(msg):
            return True

        elif msg.action in(OUTGOING.ZMQ_SEND, OUTGOING.ZMQ_DELETE, OUTGOING.ZMQ_EDIT):
            return self.out.name == msg['name']
        
    def _stop_connection(self):
        """ Stops the given outgoing connection's sender. The method must 
        be called from a method that holds onto all related RLocks.
        """
        if self.out.get('sender'):
            sender = self.out.sender
            sender.close()
        
    def _recreate_sender(self):
        self._stop_connection()
        self.name = self.out.name
        
        if self.out.get('is_active'):
            factory = self._get_factory(None, self.out.address, None)
            sender = self._sender(factory)
            self.out.sender = sender

    def _sender(self, factory):
        """ Starts the outgoing connection in a new thread and returns it.
        """
        sender = OutgoingConnection(factory, self.out.name)
        t = Thread(target=sender._run)
        t.start()
        
        return sender
        
    def _setup_connector(self):
        """ Sets up the connector on startup.
        """
        with self.out_lock:
            self._recreate_sender()
                
    def _close_delete(self):
        """ Stops the connections, exits the process.
        """
        with self.out_lock:
            self._stop_connection()
            self._close()

    def on_broker_msg_OUTGOING_ZMQ_SEND(self, msg, args=None):
        """ Puts a message on a socket.
        """
        if not self.out.get('is_active'):
            log_msg = 'Not sending, the connection is not active [{0}]'.format(self.out.toDict())
            self.logger.info(log_msg)
            return
            
        if self.out.get('sender'):
            self.out.sender.send(msg.body)
        else:
            if self.logger.isEnabledFor(logging.DEBUG):
                log_msg = 'No sender for [{0}]'.format(self.out.toDict())
                self.logger.debug(log_msg)
                
    def on_broker_msg_OUTGOING_ZMQ_DELETE(self, msg, args=None):
        self._close_delete()
        
    def on_broker_msg_OUTGOING_ZMQ_EDIT(self, msg, args=None):
        with self.out_lock:
            sender = self.out.get('sender')
            self.out = msg
            self.out.sender = sender
            self._recreate_sender()

def run_connector():
    """ Invoked on the process startup.
    """
    setup_logging()
    
    repo_location = os.environ['ZATO_REPO_LOCATION']
    item_id = os.environ[ENV_ITEM_NAME]
    
    OutgoingConnector(repo_location, item_id)
    
    logger = logging.getLogger(__name__)
    logger.debug('Starting ZeroMQ outgoing, repo_location [{0}], item_id [{1}]'.format(
        repo_location, item_id))
    
def start_connector(repo_location, item_id):
    _start_connector(repo_location, __file__, ENV_ITEM_NAME, None, item_id)
    
if __name__ == '__main__':
    run_connector()

########NEW FILE########
__FILENAME__ = log
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from logging import Logger

# Zato
from zato.common.log_message import NULL_LMC, NULL_CID

def wrapper(name):
    def _log(self, msg, *args, **kwargs):
        def _invoke(name, self, msg):
            extra={'cid':kwargs.pop('cid', NULL_CID), 'lmc':kwargs.pop('lmc', NULL_LMC)}
            extra.update(kwargs.pop('extra', {}))
            return Logger.__dict__[name](self, msg, *args, extra=extra, **kwargs)
        return _invoke(name, self, msg)
    return _log

class ZatoLogger(Logger):
    """ A custom subclass which turns parameters not understood otherwise
    into an 'extra' dictionary passed on to the base class.
    """
    debug = wrapper('debug')
    info = wrapper('info')
    warning = wrapper('warning')
    error = wrapper('error')
    
    # Alias
    warn = warning

########NEW FILE########
__FILENAME__ = main
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Setting the custom logger must come first
import locale, logging
from zato.server.log import ZatoLogger
logging.setLoggerClass(ZatoLogger)

logging.captureWarnings(True)

# stdlib
import copy, os, ssl, sys
import logging.config

# gunicorn
from gunicorn.app.base import Application

# Paste
from paste.util.converters import asbool

# psycopg2
import psycopg2

# Repoze
from repoze.profile import ProfileMiddleware

# Zato
from zato.common.repo import RepoManager
from zato.common import TRACE1
from zato.common.util import absolutize_path, clear_locks, get_app_context, get_config, get_crypto_manager, \
     get_kvdb_config_for_log, make_psycopg_green, register_diag_handlers, store_pidfile

class ZatoGunicornApplication(Application):
    def __init__(self, zato_wsgi_app, repo_location, config_main, crypto_config, *args, **kwargs):
        self.zato_wsgi_app = zato_wsgi_app
        self.repo_location = repo_location
        self.config_main = config_main
        self.crypto_config = crypto_config
        self.zato_host = None
        self.zato_port = None
        self.zato_config = {}
        super(ZatoGunicornApplication, self).__init__(*args, **kwargs)

    def init(self, *ignored_args, **ignored_kwargs):
        self.cfg.set('post_fork', self.zato_wsgi_app.post_fork) # Initializes a worker
        self.cfg.set('on_starting', self.zato_wsgi_app.on_starting) # Generates the deployment key

        for k, v in self.config_main.items():
            if k.startswith('gunicorn') and v:
                k = k.replace('gunicorn_', '')
                if k == 'bind':
                    if not ':' in v:
                        raise ValueError('No port found in main.gunicorn_bind [{v}]; a proper value is, for instance, [{v}:17010]'.format(v=v))
                    else:
                        host, port = v.split(':')
                        self.zato_host = host
                        self.zato_port = port
                self.cfg.set(k, v)
            else:
                if 'deployment_lock' in k:
                    v = int(v)

                self.zato_config[k] = v

        for name in('deployment_lock_expires', 'deployment_lock_timeout'):
            setattr(self.zato_wsgi_app, name, self.zato_config[name])

        # TLS is new in 2.0 and we need to assume it's not enabled. In Zato 1.3
        # this will be changed to assume that we are always over TLS by default.
        if asbool(self.crypto_config.get('use_tls', False)):
            self.cfg.set('ssl_version', getattr(ssl, 'PROTOCOL_{}'.format(self.crypto_config.tls_protocol)))
            self.cfg.set('ciphers', self.crypto_config.tls_ciphers)
            self.cfg.set('cert_reqs', getattr(ssl, 'CERT_{}'.format(self.crypto_config.tls_client_certs.upper())))
            self.cfg.set('ca_certs', absolutize_path(self.repo_location, self.crypto_config.ca_certs_location))
            self.cfg.set('keyfile', absolutize_path(self.repo_location, self.crypto_config.priv_key_location))
            self.cfg.set('certfile', absolutize_path(self.repo_location, self.crypto_config.cert_location))
            self.cfg.set('do_handshake_on_connect', True)

        self.zato_wsgi_app.has_gevent = 'gevent' in self.cfg.settings['worker_class'].value
        
    def load(self):
        return self.zato_wsgi_app.on_wsgi_request

def run(base_dir, start_gunicorn_app=True):

    # Store a pidfile before doing anything else
    store_pidfile(base_dir)

    # For dumping stacktraces
    register_diag_handlers()

    # Start initializing the server now
    os.chdir(base_dir)

    try:
        import pymysql
        pymysql.install_as_MySQLdb()
    except ImportError:
        pass

    # We're doing it here even if someone doesn't use PostgreSQL at all
    # so we're not suprised when someone suddenly starts using PG.
    # TODO: Make sure it's registered for each of the subprocess
    psycopg2.extensions.register_type(psycopg2.extensions.UNICODE)
    psycopg2.extensions.register_type(psycopg2.extensions.UNICODEARRAY)

    repo_location = os.path.join(base_dir, 'config', 'repo')

    # Configure the logging first, before configuring the actual server.
    logging.addLevelName('TRACE1', TRACE1)
    logging.config.fileConfig(os.path.join(repo_location, 'logging.conf'))

    logger = logging.getLogger(__name__)
    kvdb_logger = logging.getLogger('zato_kvdb')

    config = get_config(repo_location, 'server.conf')

    # Store KVDB config in logs, possibly replacing its password if told to
    kvdb_config = get_kvdb_config_for_log(config.kvdb)
    kvdb_logger.info('Master process config `%s`', kvdb_config)

    # New in 2.0 hence optional
    user_locale = config.misc.get('locale', None)
    if user_locale:
        locale.setlocale(locale.LC_ALL, user_locale)
        value = 12345
        logger.info('Locale is `%s`, amount of %s -> `%s`', user_locale, value,
                    locale.currency(value, grouping=True).decode('utf-8'))

    # Spring Python
    app_context = get_app_context(config)

    # Makes queries against Postgres asynchronous
    if asbool(config.odb.use_async_driver) and config.odb.engine == 'postgresql':
        make_psycopg_green()

    # New in 2.0 - Put HTTP_PROXY in os.environ.
    http_proxy = config.misc.get('http_proxy', False)
    if http_proxy:
        os.environ['http_proxy'] = http_proxy

    crypto_manager = get_crypto_manager(repo_location, app_context, config)
    parallel_server = app_context.get_object('parallel_server')

    zato_gunicorn_app = ZatoGunicornApplication(parallel_server, repo_location, config.main, config.crypto)

    parallel_server.crypto_manager = crypto_manager
    parallel_server.odb_data = config.odb
    parallel_server.host = zato_gunicorn_app.zato_host
    parallel_server.port = zato_gunicorn_app.zato_port
    parallel_server.repo_location = repo_location
    parallel_server.base_dir = base_dir
    parallel_server.fs_server_config = config
    parallel_server.user_config.update(config.user_config_items)
    parallel_server.startup_jobs = app_context.get_object('startup_jobs')
    parallel_server.app_context = app_context

    # Remove all locks possibly left over by previous server instances
    kvdb = app_context.get_object('kvdb')
    kvdb.component = 'master-proc'
    clear_locks(kvdb, config.main.token, config.kvdb, crypto_manager.decrypt)

    # Turn the repo dir into an actual repository and commit any new/modified files
    RepoManager(repo_location).ensure_repo_consistency()

    # New in 2.0 so it's optional.
    profiler_enabled = config.get('profiler', {}).get('enabled', False)

    if asbool(profiler_enabled):
        profiler_dir = os.path.abspath(os.path.join(base_dir, config.profiler.profiler_dir))
        parallel_server.on_wsgi_request = ProfileMiddleware(
            parallel_server.on_wsgi_request,
            log_filename = os.path.join(profiler_dir, config.profiler.log_filename),
            cachegrind_filename = os.path.join(profiler_dir, config.profiler.cachegrind_filename),
            discard_first_request = config.profiler.discard_first_request,
            flush_at_shutdown = config.profiler.flush_at_shutdown,
            path = config.profiler.url_path,
            unwind = config.profiler.unwind)

    # Run the app at last we execute from command line
    if start_gunicorn_app:
        zato_gunicorn_app.run()
    else:
        return zato_gunicorn_app.zato_wsgi_app

def run_in_foreground(base_dir):
    server = run(base_dir, False)
    server.start_server(server)

    return server

if __name__ == '__main__':
    base_dir = sys.argv[1]
    if not os.path.isabs(base_dir):
        base_dir = os.path.abspath(os.path.join(os.getcwd(), base_dir))
    run(base_dir)

########NEW FILE########
__FILENAME__ = message
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from copy import deepcopy
from json import loads
from threading import RLock
from traceback import format_exc

# Bunch
from bunch import Bunch

# dpath
from dpath import util as dpath_util

# jsonpointer
from jsonpointer import JsonPointer, JsonPointerException, PathNotFoundException

# lxml
from lxml import etree

# Paste
from paste.util.converters import asbool

# xmldict
from xmltodict import parse as xml_parse

# Zato
from zato.common import MSG_MAPPER, ZATO_NOT_GIVEN
from zato.common.nav import DictNav

logger = logging.getLogger(__name__)

# ################################################################################################################################

class JSONPointerAPI(object):
    """ User-visible API to a store of JSON Pointers.
    """
    def __init__(self, doc, store):
        self._doc = doc
        self._store = store

    def get(self, name, default=None):
        return self._store.get(name, self._doc, default)

    def set(self, name, value, return_on_missing=False, in_place=True):
        return self._store.set(name, self._doc, value, return_on_missing, in_place)

class XPathAPI(object):
    """ User-visible API to a store of XPath expressions.
    """
    def __init__(self, doc, store, ns_store):
        self._doc = doc
        self._store = store
        self._ns_store = ns_store

    def get(self, name, default=None):
        return self._store.get(name, self._doc, default)

    def set(self, name, value):
        return self._store.set(name, self._doc, value, self._ns_store.ns_map)

class MessageFacade(object):
    """ An object through which services access all the message-related features,
    such as namespaces, JSON Pointer or XPath.
    """
    def __init__(self, msg_ns_store=None, json_pointer_store=None, xpath_store=None, ns_store=None, payload=None, time_util=None):
        self._ns = msg_ns_store
        self._json_pointer_store = json_pointer_store
        self._xpath_store = xpath_store
        self._ns_store = ns_store
        self._payload = payload
        self._time_util = time_util

    def json_pointer(self, doc=None):
        return JSONPointerAPI(doc if doc is not None else self._payload, self._json_pointer_store)

    def xpath(self, msg=None):
        return XPathAPI(msg if msg is not None else self._payload, self._xpath_store, self._ns_store)

    def mapper(self, source, target=None, *args, **kwargs):
        return Mapper(source, target, time_util=self._time_util, *args, **kwargs)

# ################################################################################################################################

class NamespaceStore(object):
    """ A store of all the namespaces used with XML processing.
    """
    def __init__(self, data={}):
        self.data = Bunch.fromDict(data)
        self.ns_map = {}
        self.update_lock = RLock()

    def __getitem__(self, name):
        return self.data[name].config.value

    def add(self, name, item):
        with self.update_lock:
            self.data[name] = Bunch()
            self.data[name].config = item
            self.ns_map[name] = self.data[name].config.value

    def on_broker_msg_MSG_NS_CREATE(self, msg, *args):
        """ Creates a new namespace.
        """
        self.add(msg.name, msg)

    def on_broker_msg_MSG_NS_EDIT(self, msg, *args):
        """ Updates an existing namespace.
        """
        with self.update_lock:
            del self.data[msg.old_name]
            del self.ns_map[msg.old_name]
        self.add(msg.name, msg)

    def on_broker_msg_MSG_NS_DELETE(self, msg, *args):
        """ Deletes a namespace.
        """
        with self.update_lock:
            del self.data[msg.name]
            del self.ns_map[msg.name]

# ################################################################################################################################

class BaseStore(object):
    def __init__(self, data={}):
        self.data = Bunch.fromDict(data)
        self.update_lock = RLock()

        # Dummy document to test expressions against - will yield
        # an XPathEvalError in an XPath's .evaluate method if a namespace
        # prefix used wasn't defined in a namespace map.
        self.dummy_doc = etree.XML('<dummy/>')

    def __getitem__(self, name):
        return self.data[name].config.value

    def compile(self, expr, ns_map={}):
        """ Compiles an XPath expression using a namespace map provided, if any,
        and evaluates it against a dummy document to check that all the namespace
        prefixes are valid.
        """
        try:
            compiled = etree.XPath(expr, namespaces=ns_map)
            compiled.evaluate(self.dummy_doc)
        except Exception, e:
            logger.warn('Failed to compile expr:[%s] with ns_map:[%s]', expr, ns_map)
            raise
        else:
            return compiled

    def on_broker_msg_create(self, msg, ns_map=None):
        """ Creates a new XPath.
        """
        self.add(msg.name, msg, ns_map)

    def on_broker_msg_edit(self, msg, ns_map=None):
        """ Updates an existing XPath.
        """
        with self.update_lock:
            del self.data[msg.old_name]
            self.add(msg.name, msg, ns_map)

    def on_broker_msg_delete(self, msg, *args):
        """ Deletes an XPath.
        """
        with self.update_lock:
            del self.data[msg.name]

# ################################################################################################################################

class XPathStore(BaseStore):
    """ Keeps config of and evaluates XPath expressions.
    """
    def add(self, name, config, ns_map=None):
        ns_map = ns_map or {}
        with self.update_lock:
            compiled_elem = self.compile(config.value, ns_map)
            self.data[name] = Bunch()
            self.data[name].config = config
            self.data[name].compiled_elem = compiled_elem

    def get(self, name, doc, default=None, needs_text=True):
        result = self.data[name].compiled_elem.evaluate(doc)
        if result:
            if len(result) == 1:
                if needs_text:
                    result = result[0].text
            else:
                if needs_text:
                    result = [elem.text for elem in result]
        else:
            result = None

        return result if result is not None else default

    def set(self, name, doc, value, ns_map=None):
        """ Sets a value of element(s) under a given name in a doc.
        If value is False, element(s) are deleted.
        """
        # Mostly taken from https://stackoverflow.com/a/5547668
        ns_map = ns_map or {}
        path = self.data[name].config.value
        nodes = doc.xpath(path, namespaces=ns_map)

        if nodes:
            node = nodes
        else:
            parts = path.split('/')
            parts = (part for part in parts if part)
            p = doc
            for part in parts:
                nodes = p.xpath(part, namespaces=ns_map)
                if not nodes:
                    name_elems = part.split(':')

                    # No namespaces:
                    if len(name_elems) == 1:
                        n = etree.Element(part)

                    # Need to map prefixes to actual namespaces
                    else:
                        prefix, name = name_elems
                        ns = ns_map[prefix]

                        # String interpolation is much easier to comprehend than str.format here
                        n = etree.Element('{%s}%s' % (ns, name))

                    p.append(n)
                    p = n
                else:
                    p = nodes[0]

            node = p
            nodes = [node]

        if value is False:
            node.getparent().remove(node)
        else:
            for node in nodes:
                node.text = value

    def delete(self, name, doc):
        return self.set(name, doc, False)

# ################################################################################################################################

class JSONPointerStore(BaseStore):

    def get(self, name, doc, default=None):
        value = self.data[name].get(doc, default)
        if value is not None:
            return value
        else:
            return default

    def set(self, name, doc, value, return_on_missing=False, in_place=True):
        if return_on_missing:
            if not self.get(name, doc):
                return doc

        pointer = self.data[name]

        try:
            return pointer.set(doc, value, in_place)
        except PathNotFoundException:
            dpath_util.new(doc, '/' + '/'.join(pointer.parts), value)
            return doc

    def add(self, name, config, *ignored_args, **ignored_kwargs):
        """ Adds a new JSON Pointer expression to the store.
        """
        # Make sure it's valid, no exception in 'resolve' means the expression was valid.
        pointer = JsonPointer(config.value)
        pointer.resolve({}, None)

        with self.update_lock:
            self.data[name] = pointer

# ################################################################################################################################

class Mapper(object):
    def __init__(self, source, target=None, time_util=None, *args, **kwargs):
        self.target = target if target is not None else {}
        self.map_type = kwargs.get('msg_type', MSG_MAPPER.DICT_TO_DICT)
        self.skip_ns = kwargs.get('skip_ns', True)
        self.time_util = time_util
        self.subs = {}
        self.funcs = {'int':int, 'bool':asbool}
        self.func_keys = self.funcs.keys()
        self.times = {}
        self.cache = {}

        if isinstance(source, DictNav):
            self.source = source
        else:
            if self.map_type.startswith('dict-to-'):
                self.source = DictNav(source)

    def set_time(self, name, format):
        self.times[name] = format

    def set_substitution(self, name, value):
        self.subs[name] = value

    def set_func(self, name, func):
        self.funcs[name] = func
        self.func_keys = self.funcs.keys()

    def map(self, to,  from_, separator='/', skip_missing=True, default=ZATO_NOT_GIVEN):
        """ Maps 'from_' into 'to', splitting from using the 'separator' and applying
        transformation functions along the way.
        """
        # Store for later use, such as in log entries.
        orig_from = from_
        force_func = None
        force_func_name = None
        needs_time_reformat = False
        from_format, to_format = None, None

        # Perform any string substitutions first.
        if self.subs:
            from_.format(**self.subs)
            to.format(**self.subs)

        # Pick at most one processing functions.
        for key in self.func_keys:
            if from_.startswith(key):
                from_ = from_.replace('{}:'.format(key), '', 1)
                force_func = self.funcs[key]
                force_func_name = key
                break

        # Perhaps it's a date value that needs to be converted.
        if from_.startswith('time:'):
            needs_time_reformat = True
            from_format, from_ = self._get_time_format(from_)
            to_format, to_ = self._get_time_format(to)

        # Obtain the value.
        value = self.source.get(from_.split(separator)[1:])

        if needs_time_reformat:
            value = self.time_util.reformat(value, from_format, to_format)

        # Don't return anything if we are to skip missing values
        # or, we aren't, return a default value.
        if not value:
            if skip_missing:
                return
            else:
                value = default if default != ZATO_NOT_GIVEN else value

        # We have some value, let's process it using the function found above.
        if force_func:
            try:
                value = force_func(value)
            except Exception, e:
                logger.warn('Error in force_func:`%s` `%s` over `%s` in `%s` -> `%s`',
                    force_func_name, force_func, value, orig_from, to)
                raise

        dpath_util.new(self.target, to, value)

    def map_many(self, items, *args, **kwargs):
        for to, from_ in items:
            self.map(to, from_, *args, **kwargs)

    def get(self, path, default=None, separator='/'):
        for found_path, value in dpath_util.search(self.source.obj, path, yielded=True, separator=separator):
            if path == '{}{}'.format(separator, found_path):
                return value

        return default

    def set(self, to, value):
        """ Sets 'to' to a static 'value'.
        """
        dpath_util.new(self.target, to, value)

    def _get_time_format(self, path):
        path = path.split('time:')[1]
        sep_idx = path.find(':')
        return self.times[path[:sep_idx]], path[sep_idx+1:]
########NEW FILE########
__FILENAME__ = odb
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from contextlib import closing
from datetime import datetime, timedelta
from traceback import format_exc

# SQLAlchemy
from sqlalchemy.exc import IntegrityError

# Paste
from paste.util.multidict import MultiDict

# Bunch
from bunch import Bunch

# Zato
from zato.common import DEPLOYMENT_STATUS, MISC, MSG_PATTERN_TYPE, SEC_DEF_TYPE, TRACE1, ZATO_NONE, ZATO_ODB_POOL_NAME
from zato.common.odb.model import APIKeySecurity, Cluster, DeployedService, DeploymentPackage, DeploymentStatus, HTTPBasicAuth, \
     HTTPSOAP, HTTSOAPAudit, HTTSOAPAuditReplacePatternsJSONPointer, HTTSOAPAuditReplacePatternsXPath, OAuth, Server, Service, \
     TechnicalAccount, XPathSecurity, WSSDefinition
from zato.common.odb import query
from zato.common.util import current_host
from zato.server.connection.sql import SessionWrapper

logger = logging.getLogger(__name__)

class _Server(object):
    """ A plain Python object which is used instead of an SQLAlchemy model so the latter is not tied to a session
    for as long a server is up.
    """
    def __init__(self, odb_server, odb_cluster):
        self.id = odb_server.id
        self.name = odb_server.name
        self.last_join_status = odb_server.last_join_status
        self.token = odb_server.token
        self.cluster_id = odb_cluster.id
        self.cluster = odb_cluster

class ODBManager(SessionWrapper):
    """ Manages connections to the server's Operational Database.
    """
    def __init__(self, well_known_data=None, token=None, crypto_manager=None,
                 server_id=None, server_name=None, cluster_id=None, pool=None):
        super(ODBManager, self).__init__()
        self.well_known_data = well_known_data
        self.token = token
        self.crypto_manager = crypto_manager
        self.server_id = server_id
        self.server_name = server_name
        self.cluster_id = cluster_id
        self.pool = pool

    def on_deployment_finished(self):
        """ Commits all the implicit BEGIN blocks opened by SELECTs.
        """
        self._session.commit()

    def fetch_server(self, odb_config):
        """ Fetches the server from the ODB. Also sets the 'cluster' attribute
        to the value pointed to by the server's .cluster attribute.
        """
        if not self.session_initialized:
            self.init_session(ZATO_ODB_POOL_NAME, odb_config, self.pool, False)

        with closing(self.session()) as session:
            try:
                server = session.query(Server).\
                       filter(Server.token == self.token).\
                       one()
                self.server = _Server(server, server.cluster)
                self.cluster = server.cluster
                return self.server
            except Exception:
                msg = 'Could not find the server in the ODB, token:[{0}]'.format(
                    self.token)
                logger.error(msg)
                raise

    def server_up_down(self, token, status, update_host=False, bind_host=None, bind_port=None):
        """ Updates the information regarding the server is RUNNING or CLEAN_DOWN etc.
        and what host it's running on.
        """
        with closing(self.session()) as session:
            server = session.query(Server).\
                filter(Server.token==token).\
                one()

            server.up_status = status
            server.up_mod_date = datetime.utcnow()

            if update_host:
                server.host = current_host()
                server.bind_host = bind_host
                server.bind_port = bind_port

            session.add(server)
            session.commit()

    def get_url_security(self, cluster_id, connection=None):
        """ Returns the security configuration of HTTP URLs.
        """
        with closing(self.session()) as session:
            # What DB class to fetch depending on the string value of the security type.
            sec_type_db_class = {
                SEC_DEF_TYPE.APIKEY: APIKeySecurity,
                SEC_DEF_TYPE.BASIC_AUTH: HTTPBasicAuth,
                SEC_DEF_TYPE.OAUTH: OAuth,
                SEC_DEF_TYPE.TECH_ACCOUNT: TechnicalAccount,
                SEC_DEF_TYPE.WSS: WSSDefinition,
                SEC_DEF_TYPE.XPATH_SEC: XPathSecurity,
                }

            result = {}

            q = query.http_soap_security_list(session, cluster_id, connection)
            columns = Bunch()

            # So ConfigDict has its data in the format it expects
            for c in q.statement.columns:
                columns[c.name] = None

            for item in q.all():
                target = '{}{}{}'.format(item.soap_action, MISC.SEPARATOR, item.url_path)

                result[target] = Bunch()
                result[target].is_active = item.is_active
                result[target].transport = item.transport
                result[target].data_format = item.data_format

                if item.security_id:
                    result[target].sec_def = Bunch()

                    # Will raise KeyError if the DB gets somehow misconfigured.
                    db_class = sec_type_db_class[item.sec_type]

                    sec_def = session.query(db_class).\
                            filter(db_class.id==item.security_id).\
                            one()

                    # Common things first
                    result[target].sec_def.name = sec_def.name
                    result[target].sec_def.password = sec_def.password
                    result[target].sec_def.sec_type = item.sec_type

                    if item.sec_type == SEC_DEF_TYPE.TECH_ACCOUNT:
                        result[target].sec_def.salt = sec_def.salt

                    elif item.sec_type == SEC_DEF_TYPE.BASIC_AUTH:
                        result[target].sec_def.username = sec_def.username
                        result[target].sec_def.password = sec_def.password
                        result[target].sec_def.realm = sec_def.realm

                    elif item.sec_type == SEC_DEF_TYPE.APIKEY:
                        result[target].sec_def.username = 'HTTP_{}'.format(sec_def.username.upper())
                        result[target].sec_def.password = sec_def.password

                    elif item.sec_type == SEC_DEF_TYPE.WSS:
                        result[target].sec_def.username = sec_def.username
                        result[target].sec_def.password = sec_def.password
                        result[target].sec_def.password_type = sec_def.password_type
                        result[target].sec_def.reject_empty_nonce_creat = sec_def.reject_empty_nonce_creat
                        result[target].sec_def.reject_stale_tokens = sec_def.reject_stale_tokens
                        result[target].sec_def.reject_expiry_limit = sec_def.reject_expiry_limit
                        result[target].sec_def.nonce_freshness_time = sec_def.nonce_freshness_time

                    elif item.sec_type == SEC_DEF_TYPE.XPATH_SEC:
                        result[target].sec_def.username = sec_def.username
                        result[target].sec_def.password = sec_def.password
                        result[target].sec_def.username_expr = sec_def.username_expr
                        result[target].sec_def.password_expr = sec_def.password_expr

                else:
                    result[target].sec_def = ZATO_NONE

            return result, columns

    def add_service(self, name, impl_name, is_internal, deployment_time, details, source_info):
        """ Adds information about the server's service into the ODB.
        """
        try:
            service = Service(None, name, True, impl_name, is_internal, self.cluster)
            self._session.add(service)
            try:
                self._session.commit()
            except IntegrityError, e:
                logger.log(TRACE1, 'IntegrityError (Service), e:[%s]', format_exc(e).decode('utf-8'))
                self._session.rollback()

                service = self._session.query(Service).\
                    join(Cluster, Service.cluster_id==Cluster.id).\
                    filter(Service.name==name).\
                    filter(Cluster.id==self.cluster.id).\
                    one()

            self.add_deployed_service(deployment_time, details, service, source_info)

            return service.id, service.is_active, service.slow_threshold

        except Exception, e:
            logger.error('Could not add service, name:[%s], e:[%s]', name, format_exc(e).decode('utf-8'))
            self._session.rollback()

    def drop_deployed_services(self, server_id):
        """ Removes all the deployed services from a server.
        """
        with closing(self.session()) as session:
            session.query(DeployedService).\
                filter(DeployedService.server_id==server_id).\
                delete()
            session.commit()

    def add_deployed_service(self, deployment_time, details, service, source_info):
        """ Adds information about the server's deployed service into the ODB.
        """
        try:
            ds = DeployedService(deployment_time, details, self.server.id, service,
                source_info.source, source_info.path, source_info.hash, source_info.hash_method)
            self._session.add(ds)
            try:
                self._session.commit()
            except IntegrityError, e:

                logger.log(TRACE1, 'IntegrityError (DeployedService), e:[%s]', format_exc(e).decode('utf-8'))
                self._session.rollback()

                ds = self._session.query(DeployedService).\
                    filter(DeployedService.service_id==service.id).\
                    filter(DeployedService.server_id==self.server.id).\
                    one()

                ds.deployment_time = deployment_time
                ds.details = details
                ds.source = source_info.source
                ds.source_path = source_info.path
                ds.source_hash = source_info.hash
                ds.source_hash_method = source_info.hash_method

                self._session.add(ds)
                self._session.commit()

        except Exception, e:
            msg = 'Could not add the DeployedService, e:[{e}]'.format(e=format_exc(e))
            logger.error(msg)
            self._session.rollback()

    def is_service_active(self, service_id):
        """ Returns whether the given service is active or not.
        """
        with closing(self.session()) as session:
            return session.query(Service.is_active).\
                filter(Service.id==service_id).\
                one()[0]

    def hot_deploy(self, deployment_time, details, payload_name, payload, server_id):
        """ Inserts a hot-deployed data into the DB along with setting the preliminary
        AWAITING_DEPLOYMENT status for each of the servers this server's cluster
        is aware of.
        """
        with closing(self.session()) as session:
            # Create the deployment package info ..
            dp = DeploymentPackage()
            dp.deployment_time = deployment_time
            dp.details = details
            dp.payload_name = payload_name
            dp.payload = payload
            dp.server_id = server_id

            # .. add it to the session ..
            session.add(dp)

            # .. for each of the servers in this cluster set the initial status ..
            servers = session.query(Cluster).\
                   filter(Cluster.id == self.server.cluster_id).\
                   one().servers

            for server in servers:
                ds = DeploymentStatus()
                ds.package_id = dp.id
                ds.server_id = server.id
                ds.status = DEPLOYMENT_STATUS.AWAITING_DEPLOYMENT
                ds.status_change_time = datetime.utcnow()

                session.add(ds)

            session.commit()

            return dp.id

    def _become_cluster_wide(self, cluster, session):
        """ Update all the Cluster's attributes that are related to connector servers.
        """
        cluster.cw_srv_id = self.server.id
        cluster.cw_srv_keep_alive_dt = datetime.utcnow()

        session.add(cluster)
        session.commit()

        msg = 'Server id:[{}], name:[{}] is now a connector server for cluster id:[{}], name:[{}]'.format(
            self.server.id, self.server.name, cluster.id, cluster.name)
        logger.info(msg)

        return True

    def conn_server_past_grace_time(self, cluster, grace_time):
        """ Whether it's already past the grace time the connector server had
        for updating its keep-alive timestamp.
        """
        last_keep_alive = cluster.cw_srv_keep_alive_dt
        max_allowed = last_keep_alive + timedelta(seconds=grace_time)
        now = datetime.utcnow()

        msg = 'last_keep_alive:[{}], grace_time:[{}], max_allowed:[{}], now:[{}]'.format(
            last_keep_alive, grace_time, max_allowed, now)
        logger.info(msg)

        # Return True if 'now' is past what it's allowed
        return now > max_allowed

    def become_cluster_wide(self, grace_time):
        """ Makes an attempt for the server to become a connector one, that is,
        the server to start all the connectors.
        """
        with closing(self.session()) as session:
            cluster = session.query(Cluster).\
                with_lockmode('update').\
                filter(Cluster.id == self.server.cluster_id).\
                one()

            # No cluster-wide singleton server at all so we made it first
            if not cluster.cw_srv_id:
                return self._become_cluster_wide(cluster, session)
            elif self.conn_server_past_grace_time(cluster, grace_time):
                return self._become_cluster_wide(cluster, session)
            else:
                session.rollback()
                msg = ('Server id:[{}], name:[{}] will not be a connector server for '
                'cluster id:[{}], name:[{}], cluster.cw_srv_id:[{}], cluster.cw_srv_keep_alive_dt:[{}]').format(
                    self.server.id, self.server.name, cluster.id, cluster.name, cluster.cw_srv_id, cluster.cw_srv_keep_alive_dt)
                logger.debug(msg)

    def clear_cluster_wide(self):
        """ Invoked when the cluster-wide singleton server is making a clean shutdown, sets
        all the relevant data to NULL in the ODB.
        """
        with closing(self.session()) as session:
            cluster = session.query(Cluster).\
                with_lockmode('update').\
                filter(Cluster.id == self.server.cluster_id).\
                one()

            cluster.cw_srv_id = None
            cluster.cw_srv_keep_alive_dt = None

            session.add(cluster)
            session.commit()

    def add_delivery(self, deployment_time, details, service, source_info):
        """ Adds information about the server's deployed service into the ODB.
        """
        with closing(self.session()) as session:
            dp = DeliveryPayload
            session.add(dp)
            session.commit()

# ################################################################################################################################

    def get_internal_channel_list(self, cluster_id, needs_columns=False):
        """ Returns the list of internal HTTP/SOAP channels, that is,
        channels pointing to internal services.
        """
        with closing(self.session()) as session:
            return query.internal_channel_list(session, cluster_id, needs_columns)

    def get_http_soap_list(self, cluster_id, connection=None, transport=None, needs_columns=False):
        """ Returns the list of all HTTP/SOAP connections.
        """
        with closing(self.session()) as session:
            item_list = query.http_soap_list(session, cluster_id, connection, transport, True, needs_columns)

            if connection == 'channel':
                for item in item_list:
                    item.replace_patterns_json_pointer = [elem.pattern.name for elem in session.query(HTTPSOAP).\
                        filter(HTTPSOAP.id == item.id).one().replace_patterns_json_pointer]

                    item.replace_patterns_xpath = [elem.pattern.name for elem in session.query(HTTPSOAP).\
                        filter(HTTPSOAP.id == item.id).one().replace_patterns_xpath]

            return item_list

# ################################################################################################################################

    def get_job_list(self, cluster_id, needs_columns=False):
        """ Returns a list of jobs defined on the given cluster.
        """
        with closing(self.session()) as session:
            return query.job_list(session, cluster_id, needs_columns)

# ################################################################################################################################

    def get_apikey_security_list(self, cluster_id, needs_columns=False):
        """ Returns a list of API keys existing on the given cluster.
        """
        with closing(self.session()) as session:
            return query.apikey_security_list(session, cluster_id, needs_columns)

    def get_aws_security_list(self, cluster_id, needs_columns=False):
        """ Returns a list of AWS definitions existing on the given cluster.
        """
        with closing(self.session()) as session:
            return query.aws_security_list(session, cluster_id, needs_columns)

    def get_basic_auth_list(self, cluster_id, needs_columns=False):
        """ Returns a list of HTTP Basic Auth definitions existing on the given cluster.
        """
        with closing(self.session()) as session:
            return query.basic_auth_list(session, cluster_id, needs_columns)

    def get_ntlm_list(self, cluster_id, needs_columns=False):
        """ Returns a list of NTLM definitions existing on the given cluster.
        """
        with closing(self.session()) as session:
            return query.ntlm_list(session, cluster_id, needs_columns)

    def get_oauth_list(self, cluster_id, needs_columns=False):
        """ Returns a list of OAuth accounts existing on the given cluster.
        """
        with closing(self.session()) as session:
            return query.oauth_list(session, cluster_id, needs_columns)

    def get_openstack_security_list(self, cluster_id, needs_columns=False):
        """ Returns a list of OpenStack security accounts existing on the given cluster.
        """
        with closing(self.session()) as session:
            return query.openstack_security_list(session, cluster_id, needs_columns)

    def get_tech_acc_list(self, cluster_id, needs_columns=False):
        """ Returns a list of technical accounts existing on the given cluster.
        """
        with closing(self.session()) as session:
            return query.tech_acc_list(session, cluster_id, needs_columns)

    def get_wss_list(self, cluster_id, needs_columns=False):
        """ Returns a list of WS-Security definitions on the given cluster.
        """
        with closing(self.session()) as session:
            return query.wss_list(session, cluster_id, needs_columns)

    def get_xpath_sec_list(self, cluster_id, needs_columns=False):
        """ Returns a list of XPath-based security definitions on the given cluster.
        """
        with closing(self.session()) as session:
            return query.xpath_sec_list(session, cluster_id, needs_columns)

# ################################################################################################################################

    def get_def_amqp(self, cluster_id, def_id):
        """ Returns an AMQP definition's details.
        """
        with closing(self.session()) as session:
            return query.def_amqp(session, cluster_id, def_id)

    def get_def_amqp_list(self, cluster_id, needs_columns=False):
        """ Returns a list of AMQP definitions on the given cluster.
        """
        with closing(self.session()) as session:
            return query.def_amqp_list(session, cluster_id, needs_columns)

    def get_out_amqp(self, cluster_id, out_id):
        """ Returns an outgoing AMQP connection's details.
        """
        with closing(self.session()) as session:
            return query.out_amqp(session, cluster_id, out_id)

    def get_out_amqp_list(self, cluster_id, needs_columns=False):
        """ Returns a list of outgoing AMQP connections.
        """
        with closing(self.session()) as session:
            return query.out_amqp_list(session, cluster_id, needs_columns)

    def get_channel_amqp(self, cluster_id, channel_id):
        """ Returns a particular AMQP channel.
        """
        with closing(self.session()) as session:
            return query.channel_amqp(session, cluster_id, channel_id)

    def get_channel_amqp_list(self, cluster_id, needs_columns=False):
        """ Returns a list of AMQP channels.
        """
        with closing(self.session()) as session:
            return query.channel_amqp_list(session, cluster_id, needs_columns)

# ################################################################################################################################

    def get_def_jms_wmq(self, cluster_id, def_id):
        """ Returns an JMS WebSphere MQ definition's details.
        """
        with closing(self.session()) as session:
            return query.def_jms_wmq(session, cluster_id, def_id)

    def get_def_jms_wmq_list(self, cluster_id, needs_columns=False):
        """ Returns a list of JMS WebSphere MQ definitions on the given cluster.
        """
        with closing(self.session()) as session:
            return query.def_jms_wmq_list(session, cluster_id, needs_columns)

    def get_out_jms_wmq(self, cluster_id, out_id):
        """ Returns an outgoing JMS WebSphere MQ connection's details.
        """
        with closing(self.session()) as session:
            return query.out_jms_wmq(session, cluster_id, out_id)

    def get_out_jms_wmq_list(self, cluster_id, needs_columns=False):
        """ Returns a list of outgoing JMS WebSphere MQ connections.
        """
        with closing(self.session()) as session:
            return query.out_jms_wmq_list(session, cluster_id, needs_columns)

    def get_channel_jms_wmq(self, cluster_id, channel_id):
        """ Returns a particular JMS WebSphere MQ channel.
        """
        with closing(self.session()) as session:
            return query.channel_jms_wmq(session, cluster_id, channel_id)

    def get_channel_jms_wmq_list(self, cluster_id, needs_columns=False):
        """ Returns a list of JMS WebSphere MQ channels.
        """
        with closing(self.session()) as session:
            return query.channel_jms_wmq_list(session, cluster_id, needs_columns)

# ################################################################################################################################

    def get_out_zmq(self, cluster_id, out_id):
        """ Returns an outgoing ZMQ connection's details.
        """
        with closing(self.session()) as session:
            return query.out_zmq(session, cluster_id, out_id)

    def get_out_zmq_list(self, cluster_id, needs_columns=False):
        """ Returns a list of outgoing ZMQ connections.
        """
        with closing(self.session()) as session:
            return query.out_zmq_list(session, cluster_id, needs_columns)

    def get_channel_zmq(self, cluster_id, channel_id):
        """ Returns a particular ZMQ channel.
        """
        with closing(self.session()) as session:
            return query.channel_zmq(session, cluster_id, channel_id)

    def get_channel_zmq_list(self, cluster_id, needs_columns=False):
        """ Returns a list of ZMQ channels.
        """
        with closing(self.session()) as session:
            return query.channel_zmq_list(session, cluster_id, needs_columns)

# ################################################################################################################################

    def get_out_sql(self, cluster_id, out_id):
        """ Returns an outgoing SQL connection's details.
        """
        with closing(self.session()) as session:
            return query.out_sql(session, cluster_id, out_id)

    def get_out_sql_list(self, cluster_id, needs_columns=False):
        """ Returns a list of outgoing SQL connections.
        """
        with closing(self.session()) as session:
            return query.out_sql_list(session, cluster_id, needs_columns)

# ################################################################################################################################

    def get_out_ftp(self, cluster_id, out_id):
        """ Returns an outgoing FTP connection's details.
        """
        with closing(self.session()) as session:
            return query.out_ftp(session, cluster_id, out_id)

    def get_out_ftp_list(self, cluster_id, needs_columns=False):
        """ Returns a list of outgoing FTP connections.
        """
        with closing(self.session()) as session:
            return query.out_ftp_list(session, cluster_id, needs_columns)

# ################################################################################################################################

    def get_namespace_list(self, cluster_id, needs_columns=False):
        """ Returns a list of XML namespaces.
        """
        with closing(self.session()) as session:
            return query.namespace_list(session, cluster_id, needs_columns)

    def get_xpath_list(self, cluster_id, needs_columns=False):
        """ Returns a list of XPath expressions.
        """
        with closing(self.session()) as session:
            return query.xpath_list(session, cluster_id, needs_columns)

    def get_json_pointer_list(self, cluster_id, needs_columns=False):
        """ Returns a list of JSON Pointer expressions.
        """
        with closing(self.session()) as session:
            return query.json_pointer_list(session, cluster_id, needs_columns)

# ################################################################################################################################

    def audit_set_request_http_soap(self, conn_id, name, cid, transport, 
            connection, req_time, user_token, remote_addr, req_headers,
            req_payload):

        with closing(self.session()) as session:

            audit = HTTSOAPAudit()
            audit.conn_id = conn_id
            audit.cluster_id = self.cluster.id
            audit.name = name
            audit.cid = cid
            audit.transport = transport
            audit.connection = connection
            audit.req_time = req_time
            audit.user_token = user_token
            audit.remote_addr = remote_addr
            audit.req_headers = req_headers
            audit.req_payload = req_payload

            session.add(audit)
            session.commit()

# ################################################################################################################################

    def get_cloud_openstack_swift_list(self, cluster_id, needs_columns=False):
        """ Returns a list of OpenStack Swift connections.
        """
        with closing(self.session()) as session:
            return query.cloud_openstack_swift_list(session, cluster_id, needs_columns)

    def get_cloud_aws_s3_list(self, cluster_id, needs_columns=False):
        """ Returns a list of AWS S3 connections.
        """
        with closing(self.session()) as session:
            return query.cloud_aws_s3_list(session, cluster_id, needs_columns)

# ################################################################################################################################

    def get_pubsub_topic_list(self, cluster_id, needs_columns=False):
        """ Returns a list of pub/sub topics defined on a cluster.
        """
        return query.pubsub_topic_list(self._session, cluster_id, needs_columns)

    def get_pubsub_default_client(self, cluster_id, name):
        """ Returns an ID/name pair of a default internal consumer or producer, used for pub/sub.
        """
        result = query.pubsub_default_client(self._session, cluster_id, name)

        if not result:
            logger.warn('Could not find `%s` account', name)
            return None, 'Warn: Missing `%s` account'.format(name)
        else:
            return result.id, result.name

    def get_pubsub_producer_list(self, cluster_id, needs_columns=False):
        """ Returns a list of pub/sub producers defined on a cluster.
        """
        return query.pubsub_producer_list(self._session, cluster_id, None,needs_columns)

    def get_pubsub_consumer_list(self, cluster_id, needs_columns=False):
        """ Returns a list of pub/sub consumers defined on a cluster.
        """
        return query.pubsub_consumer_list(self._session, cluster_id, None, needs_columns)

# ################################################################################################################################

    def get_notif_cloud_openstack_swift(self, cluster_id, needs_columns=False):
        """ Returns a list of OpenStack Swift notification definitions.
        """
        return query.notif_cloud_openstack_swift_list(self._session, cluster_id, needs_columns)

# ################################################################################################################################

########NEW FILE########
__FILENAME__ = generic
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from time import sleep

# watchdog
from watchdog.observers.polling import PollingObserver
from watchdog.events import FileSystemEventHandler

# Zato
from zato.server.pickup import BasePickup, BasePickupEventProcessor

logger = logging.getLogger(__name__)

__all__ = ['Pickup', 'PickupEventProcessor']

class PickupEventProcessor(FileSystemEventHandler, BasePickupEventProcessor):
    def process(self, src_path):
        self.hot_deploy(src_path)
        
    def on_created(self, event):
        logger.debug('EVENT_TYPE_CREATED event.src_path:[{}], event:[{}]'.format(event.src_path, event))
        self.process(event.src_path)

class Pickup(BasePickup):
    def __init__(self, pickup_dir=None, pickup_event_processor=None):
        self.pickup_dir = pickup_dir
        self.pickup_event_processor = pickup_event_processor or PickupEventProcessor()
        self.keep_running = True

    def watch(self):
        observer = PollingObserver()
        observer.schedule(self.pickup_event_processor, path=self.pickup_dir)
        observer.start()
        
        try:
            while self.keep_running:
                sleep(3)
        except KeyboardInterrupt:
            observer.stop()

        observer.join()

########NEW FILE########
__FILENAME__ = gevent_pickup
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging, os

# gevent
from gevent import sleep

# gevent_inotifyx
import gevent_inotifyx as inotifyx

# Zato
from zato.server.pickup import BasePickupEventProcessor

__all__ = ['Pickup', 'PickupEventProcessor']

logger = logging.getLogger(__name__)


class PickupEventProcessor(BasePickupEventProcessor):
    def process(self, event):
        logger.debug('IN_MODIFY event.name:[{}], event:[{}]'.format(event.name, event))
        self.hot_deploy(event.name)


class Pickup(object):
    def __init__(self, pickup_dir=None, pickup_event_processor=None):
        self.pickup_dir = pickup_dir
        self.pickup_event_processor = pickup_event_processor or PickupEventProcessor()
        self.keep_running = True

    def watch(self):
        fd = inotifyx.init()
        inotifyx.add_watch(fd, self.pickup_dir, inotifyx.IN_CLOSE_WRITE | inotifyx.IN_MOVE)
        
        while self.keep_running:
            try:
                events = inotifyx.get_events(fd, 1.0)
                for event in events:
                    self.pickup_event_processor.process(event)

                sleep(0.1)
            except KeyboardInterrupt:
                self.keep_running = False

        os.close(fd)

    def stop(self):
        logger.debug('Stopping the notifier')
        self.keep_running = False
        logger.info('Successfully stopped the notifier')

########NEW FILE########
__FILENAME__ = scheduler
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging, time
from traceback import format_exc

# APScheduler
from apscheduler.scheduler import Scheduler as APScheduler

# dateutil
from dateutil.parser import parse

# Zato 
from zato.common import ENSURE_SINGLETON_JOB, SCHEDULER_JOB_TYPE
from zato.common.broker_message import MESSAGE_TYPE, SCHEDULER
from zato.common.util import new_cid

logger = logging.getLogger(__name__)

def _start_date(job_data):
    if isinstance(job_data.start_date, basestring):
        return parse(job_data.start_date)
    return job_data.start_date

class Scheduler(object):
    """ The Zato's job scheduler. All of the operations assume the data's being
    first validated and sanitized by relevant Zato public API services.
    """
    def __init__(self, singleton=None, init=False):
        self.singleton = singleton
        self.broker_token = None
        self.zmq_context = None
        self.client_push_broker_pull = None
        
        if init:
            self._init()
            
    def _init(self):
        self._sched = APScheduler()
        self._sched.start()
        
    def wait_for_init(self):
        """ Sleeps till the background APScheduler's thread is up and running.
        """
        self._init()
        while not self._sched.running:
            time.sleep(0.01)
        
    def _parse_cron(self, def_):
        minute, hour, day_of_month, month, day_of_week = [elem.strip() for elem in def_.split()]
        return minute, hour, day_of_month, month, day_of_week
        
    def _on_job_execution(self, name, service, extra, broker_msg_type, job_type):
        """ Invoked by the underlying APScheduler when a job is executed. Sends
        the actual execution request to the broker so it can be picked up by
        one of the parallel server's broker clients.
        """
        msg = {'action': SCHEDULER.JOB_EXECUTED, 'name':name, 'service': service, 
                   'payload':extra, 'cid':new_cid(), 'job_type': job_type}

        # Special case an internal job that needs to be delivered to all parallel
        # servers.
        if name == ENSURE_SINGLETON_JOB:
            self.singleton.broker_client.publish(msg)
        else:
            self.singleton.broker_client.invoke_async(msg)
        
        if logger.isEnabledFor(logging.DEBUG):
            msg = 'Sent a job execution request, name [{0}], service [{1}], extra [{2}]'.format(
                name, service, extra)
            logger.debug(msg)

    def create_edit(self, action, job_data, broker_msg_type=MESSAGE_TYPE.TO_PARALLEL_ANY):
        """ Invokes a handler appropriate for the given action and job_data.job_type.
        """
        if logger.isEnabledFor(logging.DEBUG):
            logger.debug(job_data)
            
        if not job_data.is_active:
            msg = 'Job [{0}] is not active, not scheduling it'.format(job_data.name)
            logger.info(msg)
            return
        
        handler = '{0}_{1}'.format(action, job_data.job_type)
        handler = getattr(self, handler)
        
        try:
            handler(job_data, broker_msg_type)
        except Exception, e:
            msg = 'Caught exception [{0}]'.format(format_exc(e))
            logger.error(msg)
        
    def create_one_time(self, job_data, broker_msg_type):
        """ Schedules the execution of a one-time job.
        """
        start_date = _start_date(job_data)
        self._sched.add_date_job(self._on_job_execution, start_date, 
            [job_data.name, job_data.service, job_data.extra, broker_msg_type,
               SCHEDULER_JOB_TYPE.ONE_TIME], name=job_data.name)
        
        logger.info('One-time job [{0}] scheduled'.format(job_data.name))
        
    def create_interval_based(self, job_data, broker_msg_type):
        """ Schedules the execution of an interval-based job.
        """
        start_date = _start_date(job_data)
        weeks = job_data.weeks if job_data.get('weeks') else 0
        days = job_data.days if job_data.get('days') else 0
        hours = job_data.hours if job_data.get('hours') else 0
        minutes = job_data.minutes if job_data.get('minutes') else 0
        seconds = job_data.seconds if job_data.get('seconds') else 0
        max_runs = job_data.repeats if job_data.get('repeats') else None
        
        self._sched.add_interval_job(self._on_job_execution, 
            weeks, days, hours, minutes, seconds, start_date, 
            [job_data.name, job_data.service, job_data.extra, broker_msg_type,
               SCHEDULER_JOB_TYPE.INTERVAL_BASED], name=job_data.name, max_runs=max_runs)
        
        logger.info('Interval-based job [{0}] scheduled'.format(job_data.name))
        
    def create_cron_style(self, job_data, broker_msg_type):
        """ Schedules the execution of a one-time job.
        """
        start_date = _start_date(job_data)
        minute, hour, day_of_month, month, day_of_week = self._parse_cron(job_data.cron_definition)
        self._sched.add_cron_job(self._on_job_execution, 
            year=None, month=month, day=day_of_month, hour=hour,
            minute=minute, second=None, start_date=start_date, 
            args=[job_data.name, job_data.service, job_data.extra, broker_msg_type,
                    SCHEDULER_JOB_TYPE.CRON_STYLE], name=job_data.name)
        
        logger.info('Cron-style job [{0}] scheduled'.format(job_data.name))

    def delete(self, job_data):
        """ Deletes the job or warns if it hasn't been scheduled.
        """
        # If there's an old_name then we're performing an edit, 
        # otherwise we're using the current name.
        _name = job_data.old_name if job_data.get('old_name') else job_data.name
        for job in self._sched.get_jobs():
            if job.name == _name:
                self._sched.unschedule_job(job)
                logger.info('Job [{0}] unscheduled'.format(_name))
                break
        else:
            logger.warn('Job [{0}] was not scheduled, could not unschedule it'.format(_name))
            
    def edit_one_time(self, job_data, broker_msg_type):
        """ First deletes a one-time job and then schedules its execution. 
        The operations aren't parts of an atomic transaction.
        """
        self.delete(job_data)
        self.create_one_time(job_data, broker_msg_type)
        
    def edit_interval_based(self, job_data, broker_msg_type):
        """ First deletes an interval-based job and then schedules its execution. 
        The operations aren't parts of an atomic transaction.
        """
        self.delete(job_data)
        self.create_interval_based(job_data, broker_msg_type)
        
    def edit_cron_style(self, job_data, broker_msg_type):
        """ First deletes a cron-style job and then schedules its execution. 
        The operations aren't parts of an atomic transaction.
        """
        self.delete(job_data)
        self.create_cron_style(job_data, broker_msg_type)
            
    def execute(self, job_data):
        for job in self._sched.get_jobs():
            if job.name == job_data.name:
                self._on_job_execution(*job.args)
                logger.info('Job [{0}] executed'.format(job_data.name))
                break
        else:
            logger.warn('Job [{0}] is not scheduled, could not execute it'.format(job_data.name))

    def stop(self):
        self._sched.shutdown()
########NEW FILE########
__FILENAME__ = adapter
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from json import dumps, loads
from uuid import uuid4

# Zato
from zato.common import ADAPTER_PARAMS, HTTPException
from zato.server.service import Service

# ################################################################################################################################

class JSONAdapter(Service):
    """ Invokes HTTP resources with JSON or query strings. In echo mode, returns request into response. In dry-run mode,
    returns in response the request that would have been sent to an external resource.
    """
    outconn = 'not-configured-{}'.format(uuid4().hex)
    method = 'not-configured-{}'.format(uuid4().hex)
    params_to_qs = False
    load_response = True
    params = {}
    force_in_qs = []
    apply_params = ADAPTER_PARAMS.APPLY_AFTER_REQUEST
    raise_error_on = ['4', '5'] # Any HTTP code starting with these prefixes will mean an exception

    def get_call_params(self):
        call_params = {'params':{}}
        dyn_params = {}

        for name in self.force_in_qs:
            call_params['params'][name] = self.request.payload.pop(name, '')

        if self.apply_params == ADAPTER_PARAMS.APPLY_AFTER_REQUEST:
            dyn_params.update(self.request.payload)
            dyn_params.update(self.params)
        else:
            dyn_params.update(self.params)
            dyn_params.update(self.request.payload)

        if self.params_to_qs:
            call_params['params'].update(dyn_params)
        else:
            call_params['data'] = dumps(dyn_params)

        return call_params

    def handle(self):
        self.logger.debug(
            '`%s` invoked with `%r` and `%r`, `%r`, `%r`, `%r`, `%r`, `%r`', self.name, self.request.payload,
            self.outconn, self.method, self.params_to_qs, self.load_response, self.params, self.apply_params)

        # Only return what was received
        if self.request.payload.pop('echo', False):
            self.response.payload = self.request.payload
            return

        # Parameters to invoke the remote resource with
        call_params = self.get_call_params()

        # Build a request but don't actually call it
        if call_params.pop('dry-run', False):
            self.response.payload = call_params
            return

        conn = self.outgoing.plain_http[self.outconn].conn
        func = getattr(conn, self.method.lower())

        response = func(self.cid, **call_params)

        for item in self.raise_error_on:
            if str(response.status_code).startswith(item):
                raise HTTPException(self.cid, response.text, response.status_code)

        if self.load_response:
            try:
                self.response.payload = loads(response.text)
            except ValueError, e:
                self.logger.error('Cannot load JSON response `%s` for request `%s` to `%s`', 
                    response.text, call_params, self.outconn)
                raise
        else:
            self.response.payload = response.text

# ################################################################################################################################

########NEW FILE########
__FILENAME__ = amqp
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc

# Zato
from zato.common.broker_message import CHANNEL, MESSAGE_TYPE
from zato.common.odb.model import ChannelAMQP, Cluster, ConnDefAMQP, Service
from zato.common.odb.query import channel_amqp_list
from zato.server.connection.amqp.channel import start_connector
from zato.server.service.internal import AdminService, AdminSIO

class _AMQPService(AdminService):
    def delete_channel(self, channel):
        msg = {'action': CHANNEL.AMQP_DELETE, 'name': channel.name, 'id':channel.id}
        self.broker_client.publish(msg, MESSAGE_TYPE.TO_AMQP_CONNECTOR_ALL)

class GetList(AdminService):
    """ Returns a list of AMQP channels.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_channel_amqp_get_list_request'
        response_elem = 'zato_channel_amqp_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'queue', 'consumer_tag_prefix', 
            'def_name', 'def_id', 'service_name', 'data_format')
        
    def get_data(self, session):
        return channel_amqp_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)
        
class Create(AdminService):
    """ Creates a new AMQP channel.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_channel_amqp_create_request'
        response_elem = 'zato_channel_amqp_create_response'
        input_required = ('cluster_id', 'name', 'is_active', 'def_id', 'queue', 'consumer_tag_prefix', 'service')
        input_optional = ('data_format',)
        output_required = ('id', 'name')

    def handle(self):
        with closing(self.odb.session()) as session:
            input = self.request.input
            
            # Let's see if we already have a channel of that name before committing
            # any stuff into the database.
            existing_one = session.query(ChannelAMQP.id).\
                filter(ConnDefAMQP.cluster_id==input.cluster_id).\
                filter(ChannelAMQP.def_id==ConnDefAMQP.id).\
                filter(ChannelAMQP.name==input.name).\
                first()
            
            if existing_one:
                raise Exception('An AMQP channel [{0}] already exists on this cluster'.format(input.name))
            
            # Is the service's name correct?
            service = session.query(Service).\
                filter(Cluster.id==input.cluster_id).\
                filter(Service.name==input.service).\
                first()
            
            if not service:
                msg = 'Service [{0}] does not exist on this cluster'.format(input.service)
                raise Exception(msg)
            
            try:
                item = ChannelAMQP()
                item.name = input.name
                item.is_active = input.is_active
                item.queue = input.queue
                item.consumer_tag_prefix = input.consumer_tag_prefix
                item.def_id = input.def_id
                item.service = service
                item.data_format = input.data_format
                
                session.add(item)
                session.commit()
                
                if item.is_active:
                    start_connector(self.server.repo_location, item.id, item.def_id)
                
                self.response.payload.id = item.id
                self.response.payload.name = item.name
                
            except Exception, e:
                msg = 'Could not create an AMQP channel, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise 

class Edit(_AMQPService):
    """ Updates an AMQP channel.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_channel_amqp_edit_request'
        response_elem = 'zato_channel_amqp_edit_response'
        input_required = ('id', 'cluster_id', 'name', 'is_active', 'def_id', 'queue', 'consumer_tag_prefix', 'service')
        input_optional = ('data_format',)
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        
        with closing(self.odb.session()) as session:
            # Let's see if we already have an account of that name before committing
            # any stuff into the database.
            existing_one = session.query(ChannelAMQP.id).\
                filter(ConnDefAMQP.cluster_id==input.cluster_id).\
                filter(ChannelAMQP.def_id==ConnDefAMQP.id).\
                filter(ChannelAMQP.name==input.name).\
                filter(ChannelAMQP.id!=input.id).\
                first()
            
            if existing_one:
                raise Exception('An AMQP channel [{0}] already exists on this cluster'.format(input.name))
            
            # Is the service's name correct?
            service = session.query(Service).\
                filter(Cluster.id==input.cluster_id).\
                filter(Service.name==input.service).\
                first()
            
            if not service:
                msg = 'Service [{0}] does not exist on this cluster'.format(input.service)
                raise Exception(msg)
            
            try:
                item = session.query(ChannelAMQP).filter_by(id=input.id).one()
                item.name = input.name
                item.is_active = input.is_active
                item.queue = input.queue
                item.consumer_tag_prefix = input.consumer_tag_prefix
                item.def_id = input.def_id
                item.service = service
                item.data_format = input.data_format
                
                session.add(item)
                session.commit()
                
                self.delete_channel(item)
                if item.is_active:
                    start_connector(self.server.repo_location, item.id, item.def_id)
                
                self.response.payload.id = item.id
                self.response.payload.name = item.name
                
            except Exception, e:
                msg = 'Could not update the AMQP definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise  
        
class Delete(_AMQPService):
    """ Deletes an AMQP channel.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_channel_amqp_delete_request'
        response_elem = 'zato_channel_amqp_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                channel = session.query(ChannelAMQP).\
                    filter(ChannelAMQP.id==self.request.input.id).\
                    one()
                
                session.delete(channel)
                session.commit()
                
                self.delete_channel(channel)

            except Exception, e:
                session.rollback()
                msg = 'Could not delete the AMQP channel, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                
                raise

########NEW FILE########
__FILENAME__ = jms_wmq
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc

# Zato
from zato.common.broker_message import CHANNEL, MESSAGE_TYPE
from zato.common.odb.model import ChannelWMQ, Cluster, ConnDefWMQ, Service
from zato.common.odb.query import channel_jms_wmq_list
from zato.server.connection.jms_wmq.channel import start_connector
from zato.server.service.internal import AdminService, AdminSIO

class GetList(AdminService):
    """ Returns a list of JMS WebSphere MQ channels.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_channel_jms_wmq_get_list_request'
        response_elem = 'zato_channel_jms_wmq_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'def_id', 'def_name', 'queue', 'service_name')
        output_optional = ('data_format',)
        
    def get_data(self, session):
        return channel_jms_wmq_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)
        
class Create(AdminService):
    """ Creates a new WebSphere MQ channel.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_channel_jms_wmq_create_request'
        response_elem = 'zato_channel_jms_wmq_create_response'
        input_required = ('cluster_id', 'name', 'is_active', 'def_id', 'queue', 'service')
        input_optional = ('data_format',)
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        
        with closing(self.odb.session()) as session:
            # Let's see if we already have a channel of that name before committing
            # any stuff into the database.
            existing_one = session.query(ChannelWMQ.id).\
                filter(ConnDefWMQ.cluster_id==input.cluster_id).\
                filter(ChannelWMQ.def_id==ConnDefWMQ.id).\
                filter(ChannelWMQ.name==input.name).\
                first()
            
            if existing_one:
                raise Exception('A WebSphere MQ channel [{0}] already exists on this cluster'.format(input.name))
            
            # Is the service's name correct?
            service = session.query(Service).\
                filter(Cluster.id==input.cluster_id).\
                filter(Service.name==input.service).first()
            
            if not service:
                msg = 'Service [{0}] does not exist on this cluster'.format(input.service)
                self.logger.error(msg)
                raise Exception(msg)
            
            try:

                item = ChannelWMQ()
                item.name = input.name
                item.is_active = input.is_active
                item.queue = input.queue
                item.def_id = input.def_id
                item.service = service
                item.data_format = input.data_format
                
                session.add(item)
                session.commit()
                
                if item.is_active:
                    start_connector(self.server.repo_location, item.id, item.def_id)
                
                self.response.payload.id = item.id
                self.response.payload.name = item.name
                
            except Exception, e:
                msg = 'Could not create a WebSphere MQ channel, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise 

class Edit(AdminService):
    """ Updates a JMS WebSphere MQ channel.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_channel_jms_wmq_edit_request'
        response_elem = 'zato_channel_jms_wmq_edit_response'
        input_required = ('id', 'cluster_id', 'name', 'is_active', 'def_id', 'queue', 'service')
        input_optional = ('data_format',)
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        
        with closing(self.odb.session()) as session:
            # Let's see if we already have an account of that name before committing
            # any stuff into the database.
            existing_one = session.query(ChannelWMQ.id).\
                filter(ConnDefWMQ.cluster_id==input.cluster_id).\
                filter(ChannelWMQ.def_id==ConnDefWMQ.id).\
                filter(ChannelWMQ.name==input.name).\
                filter(ChannelWMQ.id!=input.id).\
                first()
            
            if existing_one:
                raise Exception('A JMS WebSphere MQ channel [{0}] already exists on this cluster'.format(input.name))
            
            # Is the service's name correct?
            service = session.query(Service).\
                filter(Cluster.id==input.cluster_id).\
                filter(Service.name==input.service).first()
            
            if not service:
                msg = 'Service [{0}] does not exist on this cluster'.format(input.service)
                raise Exception(msg)
            
            try:
                item = session.query(ChannelWMQ).filter_by(id=input.id).one()
                old_name = item.name
                item.name = input.name
                item.is_active = input.is_active
                item.queue = input.queue
                item.def_id = input.def_id
                item.service = service
                item.data_format = input.data_format
                
                session.add(item)
                session.commit()
                
                input.action = CHANNEL.JMS_WMQ_EDIT
                input.old_name = old_name
                input.service = service.impl_name
                self.broker_client.publish(input, msg_type=MESSAGE_TYPE.TO_JMS_WMQ_CONSUMING_CONNECTOR_ALL)
                
                self.response.payload.id = item.id
                self.response.payload.name = item.name
                
            except Exception, e:
                msg = 'Could not update the JMS WebSphere MQ definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise  
        
class Delete(AdminService):
    """ Deletes an JMS WebSphere MQ channel.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_channel_jms_wmq_delete_request'
        response_elem = 'zato_channel_jms_wmq_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                def_ = session.query(ChannelWMQ).\
                    filter(ChannelWMQ.id==self.request.input.id).\
                    one()
                
                session.delete(def_)
                session.commit()

                msg = {'action': CHANNEL.JMS_WMQ_DELETE, 'name': def_.name, 'id':def_.id}
                self.broker_client.publish(msg, MESSAGE_TYPE.TO_JMS_WMQ_CONSUMING_CONNECTOR_ALL)
                
            except Exception, e:
                session.rollback()
                msg = 'Could not delete the JMS WebSphere MQ channel, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                
                raise

########NEW FILE########
__FILENAME__ = zmq
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc

# Zato
from zato.common.broker_message import MESSAGE_TYPE, CHANNEL
from zato.common.odb.model import ChannelZMQ, Cluster, Service
from zato.common.odb.query import channel_zmq_list
from zato.server.connection.zmq_.channel import start_connector
from zato.server.service.internal import AdminService, AdminSIO

class GetList(AdminService):
    """ Returns a list of ZeroMQ channels.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_channel_zmq_get_list_request'
        response_elem = 'zato_channel_zmq_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'address', 'socket_type', 'service_name', 'data_format')
        output_optional = ('sub_key',)

    def get_data(self, session):
        return channel_zmq_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)

class Create(AdminService):
    """ Creates a new ZeroMQ channel.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_channel_zmq_create_request'
        response_elem = 'zato_channel_zmq_create_response'
        input_required = ('cluster_id', 'name', 'is_active', 'address', 'socket_type', 'service')
        input_optional = ('sub_key', 'data_format')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input

        with closing(self.odb.session()) as session:
            existing_one = session.query(ChannelZMQ.id).\
                filter(ChannelZMQ.cluster_id==input.cluster_id).\
                filter(ChannelZMQ.name==input.name).\
                first()

            if existing_one:
                raise Exception('A ZeroMQ channel [{0}] already exists on this cluster'.format(input.name))

            # Is the service's name correct?
            service = session.query(Service).\
                filter(Cluster.id==input.cluster_id).\
                filter(Service.name==input.service).first()

            if not service:
                msg = 'Service [{0}] does not exist on this cluster'.format(input.service)
                raise Exception(msg)

            try:
                item = ChannelZMQ()
                item.name = input.name
                item.is_active = input.is_active
                item.address = input.address
                item.socket_type = input.socket_type
                item.sub_key = input.get('sub_key', b'')
                item.cluster_id = input.cluster_id
                item.service = service
                item.data_format = input.data_format

                session.add(item)
                session.commit()

                if item.is_active:
                    start_connector(self.server.repo_location, item.id)

                self.response.payload.id = item.id
                self.response.payload.name = item.name

            except Exception, e:
                msg = 'Could not create a ZeroMQ channel, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise

class Edit(AdminService):
    """ Updates a ZeroMQ channel.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_channel_zmq_edit_request'
        response_elem = 'zato_channel_zmq_edit_response'
        input_required = ('id', 'cluster_id', 'name', 'is_active', 'address', 'socket_type', 'service')
        input_optional = ('sub_key', 'data_format')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input

        with closing(self.odb.session()) as session:
            existing_one = session.query(ChannelZMQ.id).\
                filter(ChannelZMQ.cluster_id==input.cluster_id).\
                filter(ChannelZMQ.name==input.name).\
                filter(ChannelZMQ.id!=input.id).\
                first()

            if existing_one:
                raise Exception('A ZeroMQ channel [{0}] already exists on this cluster'.format(input.name))

            # Is the service's name correct?
            service = session.query(Service).\
                filter(Cluster.id==input.cluster_id).\
                filter(Service.name==input.service).first()

            if not service:
                msg = 'Service [{0}] does not exist on this cluster'.format(input.service)
                raise Exception(msg)

            try:
                item = session.query(ChannelZMQ).filter_by(id=input.id).one()
                item.name = input.name
                item.is_active = input.is_active
                item.address = input.address
                item.socket_type = input.socket_type
                item.sub_key = input.sub_key
                item.service = service
                item.data_format = input.data_format

                session.add(item)
                session.commit()

                input.action = CHANNEL.ZMQ_EDIT
                input.sub_key = input.get('sub_key', b'')
                input.service = service.impl_name
                self.broker_client.publish(input, msg_type=MESSAGE_TYPE.TO_ZMQ_CONSUMING_CONNECTOR_ALL)

                self.response.payload.id = item.id
                self.response.payload.name = item.name

            except Exception, e:
                msg = 'Could not update the ZeroMQ channel, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise

class Delete(AdminService):
    """ Deletes a ZeroMQ channel.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_channel_zmq_delete_request'
        response_elem = 'zato_channel_zmq_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                item = session.query(ChannelZMQ).\
                    filter(ChannelZMQ.id==self.request.input.id).\
                    one()

                session.delete(item)
                session.commit()

                msg = {'action': CHANNEL.ZMQ_DELETE, 'name': item.name, 'id':item.id}
                self.broker_client.publish(msg, MESSAGE_TYPE.TO_ZMQ_CONSUMING_CONNECTOR_ALL)

            except Exception, e:
                session.rollback()
                msg = 'Could not delete the ZeroMQ channel, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)

                raise

########NEW FILE########
__FILENAME__ = sio
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Nose
from nose.tools import eq_

# Zato
from zato.common import DATA_FORMAT
from zato.server.service import AsIs, CSV, Bool, Boolean, Dict, Int, Integer, List, ListOfDicts, Nested, Service, Unicode, UTC
from zato.server.service.internal.checks import CheckService

# ################################################################################################################################

def _test_nested(msg):
    eq_(msg.meta.limit, 111)
    eq_(msg.meta.next, 'abc')
    eq_(msg.meta.offset, 30)
    eq_(msg.meta.previous, 'zxc')
    eq_(msg.meta.total_count, 9090)

    eq_(msg.objects.also_known_as, [1, 22, 333, 444])
    eq_(msg.objects.catchment, 'my-catchment')
    eq_(msg.objects.description, 'my-description')
    eq_(msg.objects.emails, [
        {'comment':'comment', 'confidential':'confidential', 'email':'email'},
        {'comment':'comment2', 'confidential':'confidential2', 'email':'email2'}])
    eq_(msg.objects.id, 123)
    eq_(msg.objects.is_mobile, True)
    eq_(msg.objects.last_updated, '2013-12-15')
    eq_(msg.objects.location.building, 'my-building')
    eq_(msg.objects.location.confidential, True)
    eq_(msg.objects.location.flat_number, '12')
    eq_(msg.objects.location.level, '5')
    eq_(msg.objects.location.point.lat, '90.0')
    eq_(msg.objects.location.point.non, '10.0')
    eq_(msg.objects.location.postcode, '123456')
    eq_(msg.objects.location.state, 'my-state')
    eq_(msg.objects.location.street_name, 'my-street_name')
    eq_(msg.objects.location.street_number, '23')
    eq_(msg.objects.location.street_suffix, 'my-street_suffix')
    eq_(msg.objects.location.street_type, 'my-street_type')
    eq_(msg.objects.location.suburb, 'my-suburb')
    eq_(msg.objects.location.unit, 'my-unit')
    eq_(msg.objects.name, 'my-name')
    eq_(msg.objects.ndis_approved, False)
    eq_(msg.objects.organisation.id, 123)
    eq_(msg.objects.organisation.name, 'my-org-name')
    eq_(msg.objects.parking_info, 'my-parking_info')
    eq_(msg.objects.phones, [
        {'comment': 'comment1', 'confidential': True, 'kind': 'kind1', 'number': 'number1'},
        {'comment': 'comment2', 'confidential': False, 'kind': 'kind2', 'number': 'number2'}])
    eq_(msg.objects.postal_address.confidential, True)
    eq_(msg.objects.postal_address.line1, 'my-line1')
    eq_(msg.objects.postal_address.line2, 'my-line2')
    eq_(msg.objects.postal_address.postcode, 'my-postcode')
    eq_(msg.objects.postal_address.state, 'my-state')
    eq_(msg.objects.postal_address.suburb, 'my-suburb')
    eq_(msg.objects.provider_type, 'my-provider_type')
    eq_(msg.objects.public_transport_info, 'my-public_transport_info')
    eq_(msg.objects.type, 'my-type')
    eq_(msg.objects.web, 'example.org')

def _get_nested_msg():
    return {
        'meta': {
            'limit': 111,
            'next': 'abc',
            'offset': 30,
            'previous': 'zxc',
            'total_count': 9090
        },
        'objects': {
            'also_known_as': [1, 22, 333, 444],
            'catchment': 'my-catchment',
            'description': 'my-description',
            'emails': [{'comment':'comment', 'confidential':'confidential', 'email':'email'},
                       {'comment':'comment2', 'confidential':'confidential2', 'email':'email2'}],
            'id': 123,
            'is_mobile': True,
            'last_updated': '2013-12-15',
            'location': {
                'building': 'my-building',
                'confidential': True,
                'flat_number': '12',
                'level': '5',
                'point': {
                    'lat': '90.0',
                    'non': '10.0',
                },
                'postcode': '123456',
                'state': 'my-state',
                'street_name': 'my-street_name',
                'street_number': '23',
                'street_suffix': 'my-street_suffix',
                'street_type': 'my-street_type',
                'suburb': 'my-suburb',
                'unit': 'my-unit',
            },
            'name': 'my-name',
            'ndis_approved': False,
            'organisation': {
                'id': 123,
                'name': 'my-org-name'
            },
            'parking_info': 'my-parking_info',
            'phones': [{'comment': 'comment1', 'confidential': True, 'kind': 'kind1', 'number': 'number1'},
                       {'comment': 'comment2', 'confidential': False, 'kind': 'kind2', 'number': 'number2'}],
            'postal_address': {
                'confidential': True,
                'line1': 'my-line1',
                'line2': 'my-line2',
                'postcode': 'my-postcode',
                'state': 'my-state',
                'suburb': 'my-suburb'
            },
            'provider_type': 'my-provider_type',
            'public_transport_info': 'my-public_transport_info',
            'type': 'my-type',
            'web': 'example.org',
        }
    }

def _get_sio_msg():

    meta = (Int('limit'), 'next', Int('offset'), 'previous',
            Int('total_count'))

    location = Nested('location', 'building', Bool('confidential'),
        'flat_number', 'level', Dict('point', 'lat', 'non'), 'postcode',
        'state','street_name','street_number', 'street_suffix',
        'street_type', 'suburb', 'unit')

    phones = ListOfDicts('phones', 'comment', Bool('confidential'),
        'kind', 'number')

    postal_address = Dict('postal_address', Bool('confidential'),
        'line1', 'line2', 'postcode', 'state', 'suburb')

    objects = (List('also_known_as'), 'catchment', 'description',
            ListOfDicts('emails'), Int('id'), Bool('is_mobile'),
            'last_updated', location, 'name', Bool('ndis_approved'),
            Dict('organisation', 'id', 'name'), 'parking_info', phones,
            postal_address, 'provider_type', 'public_transport_info',
            'type', 'web')

    return [Nested('meta', meta), Nested('objects', objects)]

# ################################################################################################################################

class CheckTargetService(Service):
    def set_payload(self):
        raise NotImplementedError()

    def after_handle(self):
        self.set_payload()

# ################################################################################################################################

class AsIsService(CheckTargetService):

    class SimpleIO:
        input_required = (AsIs('id'), AsIs('a_id'), AsIs('b_count'), AsIs('c_size'), AsIs('d_timeout'),
                          AsIs('is_e'), AsIs('needs_f'), AsIs('should_g'))
        output_required = (AsIs('id'), AsIs('a_id'), AsIs('b_count'), AsIs('c_size'), AsIs('d_timeout'),
                          AsIs('is_e'), AsIs('needs_f'), AsIs('should_g'))

    def handle(self):
        eq_(self.request.input.id, 'id1')
        eq_(self.request.input.a_id, 'a1')
        eq_(self.request.input.b_count, 'b1')
        eq_(self.request.input.c_size, 'c1')
        eq_(self.request.input.d_timeout, 'd1')
        eq_(self.request.input.is_e, 'e1')
        eq_(self.request.input.needs_f, 'f1')
        eq_(self.request.input.should_g, 'g1')

    def set_payload(self):
        self.response.payload.id = 'id2'
        self.response.payload.a_id = 'a2'
        self.response.payload.b_count = 'b2'
        self.response.payload.c_size = 'c2'
        self.response.payload.d_timeout = 'd2'
        self.response.payload.is_e = 'e2'
        self.response.payload.needs_f = 'f2'
        self.response.payload.should_g = 'g2'

# ################################################################################################################################

class BooleanService(CheckTargetService):

    class SimpleIO:
        input_required = (Boolean('bool1'), Boolean('bool2'))
        output_required = (Boolean('bool1'), Boolean('bool2'))

    def handle(self):
        eq_(self.request.input.bool1, True)
        eq_(self.request.input.bool2, False)

    def set_payload(self):
        self.response.payload.bool1 = False
        self.response.payload.bool2 = True

# ################################################################################################################################

class CSVService(CheckTargetService):

    class SimpleIO:
        input_required = (CSV('csv1'), CSV('csv2'))
        output_required = (CSV('csv3'), CSV('csv4'))

    def handle(self):
        eq_(self.request.input.csv1, ['1', '11', '111', '1111'])
        eq_(self.request.input.csv2, ['2', '22', '222', '2222'])

    def set_payload(self):
        self.response.payload.csv3 = ['3', '33', '333', '3333']
        self.response.payload.csv4 = ['4', '44', '444', '4444']

# ################################################################################################################################

class DictService(CheckTargetService):

    class SimpleIO:
        input_required = (Dict('dict1'), Dict('dict2'))
        output_required = (Dict('dict3'), Dict('dict4'))

    def handle(self):
        eq_(self.request.input.dict1['key1_1'], 'value1_1')
        eq_(self.request.input.dict1['key1_2'], 'value1_2')

        eq_(self.request.input.dict2['key2_1'], 'value2_1')
        eq_(self.request.input.dict2['key2_2'], 'value2_2')

    def set_payload(self):
        self.response.payload.dict3 = {'key3_1': 'value3_1', 'key3_2':'value3_2'}
        self.response.payload.dict4 = {'key4_1': 'value4_1', 'key4_2':'value4_2'}

# ################################################################################################################################

class IntegerService(CheckTargetService):

    class SimpleIO:
        input_required = (Integer('int1'), Integer('int2'))
        output_required = (Integer('int3'), Integer('int4'))

    def handle(self):
        eq_(self.request.input.int1, 1)
        eq_(self.request.input.int2, 2)

    def set_payload(self):
        self.response.payload.int3 = 3
        self.response.payload.int4 = 4

# ################################################################################################################################

class ListService(CheckTargetService):

    class SimpleIO:
        input_required = (List('list1'), List('list2'))
        output_required = (List('list3'), List('list4'))

    def handle(self):
        eq_(self.request.input.list1, ['1', '2', '3'])
        eq_(self.request.input.list2, ['4', '5', '6'])

    def set_payload(self):
        self.response.payload.list3 = ['7', '8', '9']
        self.response.payload.list4 = ['10', '11', '12']

# ################################################################################################################################

class ListOfDictsService(CheckTargetService):

    class SimpleIO:
        input_required = (ListOfDicts('lod1'), ListOfDicts('lod2'))
        output_required = (ListOfDicts('lod3'), ListOfDicts('lod4'))

    def handle(self):
        eq_(self.request.input.lod1[0]['key111'], 'value111')
        eq_(self.request.input.lod1[0]['key112'], 'value112')
        eq_(self.request.input.lod1[1]['key121'], 'value121')
        eq_(self.request.input.lod1[1]['key122'], 'value122')

        eq_(self.request.input.lod2[0]['key211'], 'value211')
        eq_(self.request.input.lod2[0]['key212'], 'value212')
        eq_(self.request.input.lod2[1]['key221'], 'value221')
        eq_(self.request.input.lod2[1]['key222'], 'value222')

    def set_payload(self):
        self.response.payload.lod3 = [{'key311':'value311', 'key312':'value312'}, {'key321':'value321', 'key322':'value322'}]
        self.response.payload.lod4 = [{'key411':'value411', 'key412':'value412'}, {'key421':'value421', 'key422':'value422'}]

# ################################################################################################################################

class NoForceTypeService(CheckTargetService):

    class SimpleIO:
        input_required = ('aa1', 'bb1', 'a_id', 'a_count', 'a_size', 'a_timeout', 'is_b', 'needs_b', 'should_b')
        output_required = ('aa2', 'bb2', 'c_id', 'c_count', 'c_size', 'c_timeout', 'is_d', 'needs_d', 'should_d')

    def handle(self):
        eq_(self.request.input.aa1, 'aa1-value')
        eq_(self.request.input.bb1, 'bb1-value')

        eq_(self.request.input.a_id, 1)
        eq_(self.request.input.a_count, 2)
        eq_(self.request.input.a_size, 3)
        eq_(self.request.input.a_timeout, 4)

        eq_(self.request.input.is_b, True)
        eq_(self.request.input.needs_b, False)
        eq_(self.request.input.should_b, True)

    def set_payload(self):
        self.response.payload.aa2 = 11
        self.response.payload.bb2 = 22

        self.response.payload.c_id = 33
        self.response.payload.c_count = 44
        self.response.payload.c_size = 55
        self.response.payload.c_timeout = 66

        self.response.payload.is_d = False
        self.response.payload.needs_d = True
        self.response.payload.should_d = False

# ################################################################################################################################

class UnicodeService(CheckTargetService):

    class SimpleIO:
        input_required = (Unicode('uni_a'), Unicode('uni_b'))
        output_required = (Unicode('uni_c'), Unicode('uni_d'))

    def handle(self):
        eq_(self.request.input.uni_a, 'a')
        eq_(self.request.input.uni_b, 'b')

    def set_payload(self):
        self.response.payload.uni_c = 'c'
        self.response.payload.uni_d = 'd'

# ################################################################################################################################

class UTCService(CheckTargetService):

    class SimpleIO:
        input_required = (UTC('utc1'), UTC('utc2'))
        output_required = (UTC('utc1'), UTC('utc2'))

    def handle(self):
        eq_(self.request.input.utc1, '2019-01-26T22:33:44')
        eq_(self.request.input.utc2, '2023-12-19T21:31:41')

    def set_payload(self):
        self.response.payload.utc1 = '1234-11-22T01:02:03+00:00'
        self.response.payload.utc2 = '2918-03-19T21:22:23+00:00'

# ################################################################################################################################

class NestedService(CheckTargetService):

    class SimpleIO:
        input_required = _get_sio_msg()
        output_required = _get_sio_msg()

    def handle(self):
        _test_nested(self.request.bunchified())

    def set_payload(self):
        self.response.payload = _get_nested_msg()

# ################################################################################################################################

class CheckSIO(CheckService):

    def json_check_as_is(self):
        response = self.invoke_check_json('zato.checks.sio.as-is-service', {
            'id': 'id1',
            'a_id': 'a1',
            'b_count': 'b1',
            'c_size': 'c1',
            'd_timeout': 'd1',
            'is_e': 'e1',
            'needs_f': 'f1',
            'should_g': 'g1',
        })

        eq_(response.id, 'id2')
        eq_(response.a_id, 'a2')
        eq_(response.b_count, 'b2')
        eq_(response.c_size, 'c2')
        eq_(response.d_timeout, 'd2')
        eq_(response.is_e, 'e2')
        eq_(response.needs_f, 'f2')
        eq_(response.should_g, 'g2')

    def json_check_boolean(self):
        response = self.invoke_check_json('zato.checks.sio.boolean-service', {
            'bool1': True,
            'bool2': False,
        })

        eq_(response.bool1, False)
        eq_(response.bool2, True)

    def json_check_csv(self):
        response = self.invoke_check_json('zato.checks.sio.csv-service', {
            'csv1': '1,11,111,1111',
            'csv2': '2,22,222,2222',
        })

        eq_(response.csv3, '3,33,333,3333')
        eq_(response.csv4, '4,44,444,4444')

    def json_check_dict(self):
        response = self.invoke_check_json('zato.checks.sio.dict-service', {
            'dict1': {'key1_1': 'value1_1', 'key1_2':'value1_2'},
            'dict2': {'key2_1': 'value2_1', 'key2_2':'value2_2'},
        })

        eq_(response.dict3['key3_1'], 'value3_1')
        eq_(response.dict3['key3_2'], 'value3_2')

    def json_check_integer(self):
        response = self.invoke_check_json('zato.checks.sio.integer-service', {
            'int1': 1,
            'int2': 2,
        })

        eq_(response.int3, 3)
        eq_(response.int4, 4)

    def json_check_list(self):
        response = self.invoke_check_json('zato.checks.sio.list-service', {
            'list1': ['1', '2', '3'],
            'list2': ['4', '5', '6'],
        })

        eq_(response.list3, ['7', '8', '9'])
        eq_(response.list4, ['10', '11', '12'])

    def json_check_list_of_dicts(self):
        response = self.invoke_check_json('zato.checks.sio.list-of-dicts-service', {
            'lod1': [{'key111':'value111', 'key112':'value112'}, {'key121':'value121', 'key122':'value122'}],
            'lod2': [{'key211':'value211', 'key212':'value212'}, {'key221':'value221', 'key222':'value222'}],
        })

        eq_(response.lod3[0]['key311'], 'value311')
        eq_(response.lod3[0]['key312'], 'value312')
        eq_(response.lod3[1]['key321'], 'value321')
        eq_(response.lod3[1]['key322'], 'value322')

        eq_(response.lod4[0]['key411'], 'value411')
        eq_(response.lod4[0]['key412'], 'value412')
        eq_(response.lod4[1]['key421'], 'value421')
        eq_(response.lod4[1]['key422'], 'value422')

    def json_check_no_force_type(self):
        response = self.invoke_check_json('zato.checks.sio.no-force-type-service', {
            'aa1': 'aa1-value',
            'bb1': 'bb1-value',
            'a_id': '1',
            'a_count': '2',
            'a_size': '3',
            'a_timeout': '4',
            'is_b': True,
            'needs_b': False,
            'should_b': True,
        })

        eq_(response.aa2, 11)
        eq_(response.bb2, 22)

        eq_(response.c_id, 33)
        eq_(response.c_count, 44)
        eq_(response.c_size, 55)
        eq_(response.c_timeout, 66)

        eq_(response.is_d, False)
        eq_(response.needs_d, True)
        eq_(response.should_d, False)

    def json_check_unicode(self):
        response = self.invoke_check_json('zato.checks.sio.unicode-service', {
            'uni_a': 'a',
            'uni_b': 'b',
        })

        eq_(response.uni_c, 'c')
        eq_(response.uni_d, 'd')

    def json_check_utc(self):
        response = self.invoke_check_json('zato.checks.sio.utc-service', {
            'utc1': '2019-01-26T22:33:44+00:00',
            'utc2': '2023-12-19T21:31:41+00:00',
        })

        eq_(response.utc1, '1234-11-22T01:02:03')
        eq_(response.utc2, '2918-03-19T21:22:23')

    def json_check_nested(self):
        response = self.invoke_check_json('zato.checks.sio.nested-service', _get_nested_msg())
        _test_nested(response)

# ################################################################################################################################

    def xml_check_as_is(self):
        request = """
            <request>
             <id>id1</id>
             <a_id>a1</a_id>
             <b_count>b1</b_count>
             <c_size>c1</c_size>
             <d_timeout>d1</d_timeout>
             <is_e>e1</is_e>
             <needs_f>f1</needs_f>
             <should_g>g1</should_g>
            </request>
            """

        response = self.invoke_check_xml('zato.checks.sio.as-is-service', request)

        eq_(response.item.id, 'id2')
        eq_(response.item.a_id, 'a2')
        eq_(response.item.b_count, 'b2')
        eq_(response.item.c_size, 'c2')
        eq_(response.item.d_timeout, 'd2')
        eq_(response.item.is_e, 'e2')
        eq_(response.item.needs_f, 'f2')
        eq_(response.item.should_g, 'g2')

    def xml_check_boolean(self):

        # Note that booleans are case-insensitive
        request = """
            <request>
             <bool1>true</bool1>
             <bool2>False</bool2>
            </request>
            """

        response = self.invoke_check_xml('zato.checks.sio.boolean-service', request)

        eq_(response.item.bool1, False)
        eq_(response.item.bool2, True)

    def xml_check_csv(self):
        request = """
            <request>
             <csv1>1,11,111,1111</csv1>
             <csv2>2,22,222,2222</csv2>
            </request>
            """

        response = self.invoke_check_xml('zato.checks.sio.csv-service', request)

        eq_(response.item.csv3, '3,33,333,3333')
        eq_(response.item.csv4, '4,44,444,4444')

    def xml_check_dict(self):
        request = """
            <request>
             <dict1>
              <item><key>key1_1</key><value>value1_1</value></item>
              <item><key>key1_2</key><value>value1_2</value></item>
             </dict1>

             <dict2>
              <item><key>key2_1</key><value>value2_1</value></item>
              <item><key>key2_2</key><value>value2_2</value></item>
             </dict2>
            </request>
            """

        response = self.invoke_check_xml('zato.checks.sio.dict-service', request)

        # The order of dict items is unspecified so we cannot assume any concrete indexes

        dict3_key = response.item.dict3.item[0].key

        if dict3_key == 'key3_1':
            eq_(response.item.dict3.item[0].value, 'value3_1')
            eq_(response.item.dict3.item[1].key, 'key3_2')
            eq_(response.item.dict3.item[1].value, 'value3_2')

        elif dict3_key == 'key3_2':
            eq_(response.item.dict3.item[0].value, 'value3_2')
            eq_(response.item.dict3.item[1].key, 'key3_1')
            eq_(response.item.dict3.item[1].value, 'value3_1')
        else:
            raise ValueError('Unexpected key:[{}]'.format(dict3_key))

        dict4_key = response.item.dict4.item[0].key

        if dict4_key == 'key4_1':
            eq_(response.item.dict4.item[0].value, 'value4_1')
            eq_(response.item.dict4.item[1].key, 'key4_2')
            eq_(response.item.dict4.item[1].value, 'value4_2')

        elif dict4_key == 'key4_2':
            eq_(response.item.dict4.item[0].value, 'value4_2')
            eq_(response.item.dict4.item[1].key, 'key4_1')
            eq_(response.item.dict4.item[1].value, 'value4_1')
        else:
            raise ValueError('Unexpected key:[{}]'.format(dict4_key))

    def xml_check_integer(self):
        request = """
            <request>
             <int1>1</int1>
             <int2>2</int2>
            </request>
            """

        response = self.invoke_check_xml('zato.checks.sio.integer-service', request)

        eq_(response.item.int3, 3)
        eq_(response.item.int4, 4)

    def xml_check_list(self):
        request = """
            <request>
             <list1>
              <item>1</item>
              <item>2</item>
              <item>3</item>
             </list1>
             <list2>
              <item>4</item>
              <item>5</item>
              <item>6</item>
             </list2>
            </request>
            """

        response = self.invoke_check_xml('zato.checks.sio.list-service', request)

        eq_(response.item.list3.item[0], 7)
        eq_(response.item.list3.item[1], 8)
        eq_(response.item.list3.item[2], 9)

        eq_(response.item.list4.item[0], 10)
        eq_(response.item.list4.item[1], 11)
        eq_(response.item.list4.item[2], 12)

    def xml_check_list_of_dicts(self):
        request = """
        <request>

         <lod1>
           <dict>
            <item><key>key111</key><value>value111</value></item>
            <item><key>key112</key><value>value112</value></item>
           </dict>
           <dict>
            <item><key>key121</key><value>value121</value></item>
            <item><key>key122</key><value>value122</value></item>
           </dict>
         </lod1>

         <lod2>
           <dict>
            <item><key>key211</key><value>value211</value></item>
            <item><key>key212</key><value>value212</value></item>
           </dict>
           <dict>
            <item><key>key221</key><value>value221</value></item>
            <item><key>key222</key><value>value222</value></item>
           </dict>
         </lod2>

        </request>
        """

        response = self.invoke_check_xml('zato.checks.sio.list-of-dicts-service', request)

        lod_dict = {}

        for name in('lod3', 'lod4'):
            lod_dict[name] = []
            lod = getattr(response.item, name)
            for _dict in lod.dict:
                d = {}
                for item in _dict.item:
                    d[item.key.text] = item.value.text
                lod_dict[name].append(d)

        lod3_0 = sorted(lod_dict['lod3'][0])
        lod3_1 = sorted(lod_dict['lod3'][1])

        lod4_0 = sorted(lod_dict['lod4'][0])
        lod4_1 = sorted(lod_dict['lod4'][1])

        eq_(lod3_0, ['key311', 'key312'])
        eq_(lod3_1, ['key321', 'key322'])

        eq_(lod4_0, ['key411', 'key412'])
        eq_(lod4_1, ['key421', 'key422'])

    def xml_check_no_force_type(self):
        request = """
            <request>
             <aa1>aa1-value</aa1>
             <bb1>bb1-value</bb1>
             <a_id>1</a_id>
             <a_count>2</a_count>
             <a_size>3</a_size>
             <a_timeout>4</a_timeout>
             <is_b>True</is_b>
             <needs_b>false</needs_b>
             <should_b>true</should_b>
            </request>
            """

        response = self.invoke_check_xml('zato.checks.sio.no-force-type-service', request)

        eq_(response.item.aa2, 11)
        eq_(response.item.bb2, 22)

        eq_(response.item.c_id, 33)
        eq_(response.item.c_count, 44)
        eq_(response.item.c_size, 55)
        eq_(response.item.c_timeout, 66)

        eq_(response.item.is_d, False)
        eq_(response.item.needs_d, True)
        eq_(response.item.should_d, False)

    def xml_check_unicode(self):
        request = """
            <request>
             <uni_a>a</uni_a>
             <uni_b>b</uni_b>
            </request>
            """

        response = self.invoke_check_xml('zato.checks.sio.unicode-service', request)

        eq_(response.item.uni_c, 'c')
        eq_(response.item.uni_d, 'd')

    def xml_check_utc(self):
        request = """
            <request>
             <utc1>2019-01-26T22:33:44+00:00</utc1>
             <utc2>2023-12-19T21:31:41+00:00</utc2>
            </request>
            """

        response = self.invoke_check_xml('zato.checks.sio.utc-service', request)

        eq_(response.item.utc1, '1234-11-22T01:02:03')
        eq_(response.item.utc2, '2918-03-19T21:22:23')

# ################################################################################################################################

    def handle(self):

        self.json_check_as_is()
        self.json_check_boolean()
        self.json_check_csv()
        self.json_check_dict()
        self.json_check_integer()
        self.json_check_list()
        self.json_check_list_of_dicts()
        self.json_check_no_force_type()
        self.json_check_unicode()
        self.json_check_utc()
        self.json_check_nested()

        self.xml_check_as_is()
        self.xml_check_boolean()
        self.xml_check_csv()
        self.xml_check_dict()
        self.xml_check_integer()
        self.xml_check_list()
        self.xml_check_list_of_dicts()
        self.xml_check_no_force_type()
        self.xml_check_unicode()
        self.xml_check_utc()

# ################################################################################################################################

########NEW FILE########
__FILENAME__ = s3
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc

# Zato
from zato.common.broker_message import MESSAGE_TYPE, CLOUD
from zato.common.odb.model import AWSS3
from zato.common.odb.query import cloud_aws_s3_list
from zato.server.service import Bool, ForceType, Int
from zato.server.service.internal import AdminService, AdminSIO

class GetList(AdminService):
    """ Returns a list of AWS S3 connections.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_cloud_aws_s3_get_list_request'
        response_elem = 'zato_cloud_aws_s3_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'pool_size', 'address', Int('debug_level'), Bool('suppr_cons_slashes'),
            'content_type', 'security_id', Bool('encrypt_at_rest'), 'storage_class')
        output_optional = ('metadata_', 'bucket')

    def get_data(self, session):
        return cloud_aws_s3_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)

class Create(AdminService):
    """ Creates a new AWS S3 connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_cloud_aws_s3_create_request'
        response_elem = 'zato_cloud_aws_s3_create_response'
        input_required = ('cluster_id', 'name', 'is_active', 'pool_size', 'address', Int('debug_level'),
            Bool('suppr_cons_slashes'), 'content_type', 'security_id', Bool('encrypt_at_rest'), 'storage_class')
        input_optional = ('metadata_', 'bucket')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:
            existing_one = session.query(AWSS3.id).\
                filter(AWSS3.cluster_id==input.cluster_id).\
                filter(AWSS3.name==input.name).\
                first()

            if existing_one:
                raise Exception('An AWS S3 connection [{0}] already exists on this cluster'.format(input.name))

            try:
                item = AWSS3()
                for name in self.SimpleIO.input_required + self.SimpleIO.input_optional:
                    if isinstance(name, ForceType):
                        name = name.name
                    setattr(item, name, self.request.input.get(name))

                session.add(item)
                session.commit()

                input.action = CLOUD.AWS_S3_CREATE_EDIT
                input.username = item.security.username
                input.password = item.security.password

                self.broker_client.publish(input)

                self.response.payload.id = item.id
                self.response.payload.name = item.name

            except Exception, e:
                msg = 'Could not create an AWS S3 connection, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise 

class Edit(AdminService):
    """ Updates an AWS S3 connection.
    """
    class SimpleIO(Create.SimpleIO):
        request_elem = 'zato_cloud_aws_s3_edit_request'
        response_elem = 'zato_cloud_aws_s3_edit_response'
        input_required = ('id',) + Create.SimpleIO.input_required

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:
            existing_one = session.query(AWSS3.id).\
                filter(AWSS3.cluster_id==input.cluster_id).\
                filter(AWSS3.name==input.name).\
                filter(AWSS3.id!=input.id).\
                first()

            if existing_one:
                raise Exception('An AWS S3 connection [{0}] already exists on this cluster'.format(input.name))

            try:
                item = session.query(AWSS3).filter_by(id=input.id).one()
                old_name = item.name

                for name in self.SimpleIO.input_required + self.SimpleIO.input_optional:
                    if isinstance(name, ForceType):
                        name = name.name
                    setattr(item, name, self.request.input.get(name))

                session.add(item)
                session.commit()

                input.action = CLOUD.AWS_S3_CREATE_EDIT
                input.old_name = old_name
                input.username = item.security.username
                input.password = item.security.password

                self.broker_client.publish(input)
                
                self.response.payload.id = item.id
                self.response.payload.name = item.name

            except Exception, e:
                msg = 'Could not update the AWS S3 connection, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise  

class Delete(AdminService):
    """ Deletes an AWS S3 connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_cloud_aws_s3_delete_request'
        response_elem = 'zato_cloud_aws_s3_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                item = session.query(AWSS3).\
                    filter(AWSS3.id==self.request.input.id).\
                    one()

                session.delete(item)
                session.commit()

                msg = {'action': CLOUD.AWS_S3_DELETE, 'name': item.name, 'id':item.id}
                self.broker_client.publish(msg)
                
            except Exception, e:
                session.rollback()
                msg = 'Could not delete the AWS S3 connection, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)

                raise

########NEW FILE########
__FILENAME__ = swift
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc

# Zato
from zato.common.broker_message import MESSAGE_TYPE, CLOUD
from zato.common.odb.model import OpenStackSwift
from zato.common.odb.query import cloud_openstack_swift_list
from zato.server.service.internal import AdminService, AdminSIO

class GetList(AdminService):
    """ Returns a list of OpenStack Swift connections.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_cloud_openstack_swift_get_list_request'
        response_elem = 'zato_cloud_openstack_swift_get_list_response'
        input_required = ('cluster_id',)
        output_required = (
            'id', 'name', 'is_active', 'auth_url', 'retries', 'starting_backoff', 'max_backoff', 'auth_version', 'key', 'pool_size')
        output_optional = (
            'user', 'is_snet', 'tenant_name', 'should_validate_cert', 'cacert', 'should_retr_ratelimit', 'needs_tls_compr',
            'custom_options')

    def get_data(self, session):
        return cloud_openstack_swift_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)

class Create(AdminService):
    """ Creates a new OpenStack Swift connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_cloud_openstack_swift_create_request'
        response_elem = 'zato_cloud_openstack_swift_create_response'
        input_required = ('cluster_id', 'name', 'is_active', 'auth_url', 'retries', 'starting_backoff', 'max_backoff',
            'auth_version', 'key', 'should_validate_cert', 'should_retr_ratelimit', 'needs_tls_compr', 'is_snet')
        input_optional = ('user', 'tenant_name', 'cacert', 'custom_options', 'pool_size')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:
            existing_one = session.query(OpenStackSwift.id).\
                filter(OpenStackSwift.cluster_id==input.cluster_id).\
                filter(OpenStackSwift.name==input.name).\
                first()

            if existing_one:
                raise Exception('An OpenStack Swift connection [{0}] already exists on this cluster'.format(input.name))

            try:
                item = OpenStackSwift()
                for name in self.SimpleIO.input_required + self.SimpleIO.input_optional:
                    setattr(item, name, self.request.input.get(name))

                session.add(item)
                session.commit()

                input.action = CLOUD.OPENSTACK_SWIFT_CREATE_EDIT
                self.broker_client.publish(input)

                self.response.payload.id = item.id
                self.response.payload.name = item.name

            except Exception, e:
                msg = 'Could not create an OpenStack Swift connection, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise 

class Edit(AdminService):
    """ Updates an OpenStack Swift connection.
    """
    class SimpleIO(Create.SimpleIO):
        request_elem = 'zato_cloud_openstack_swift_edit_request'
        response_elem = 'zato_cloud_openstack_swift_edit_response'
        input_required = ('id',) + Create.SimpleIO.input_required

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:
            existing_one = session.query(OpenStackSwift.id).\
                filter(OpenStackSwift.cluster_id==input.cluster_id).\
                filter(OpenStackSwift.name==input.name).\
                filter(OpenStackSwift.id!=input.id).\
                first()

            if existing_one:
                raise Exception('An OpenStack Swift connection [{0}] already exists on this cluster'.format(input.name))

            try:
                item = session.query(OpenStackSwift).filter_by(id=input.id).one()
                old_name = item.name

                for name in self.SimpleIO.input_required + self.SimpleIO.input_optional:
                    setattr(item, name, self.request.input.get(name))

                session.add(item)
                session.commit()

                input.action = CLOUD.OPENSTACK_SWIFT_CREATE_EDIT
                input.old_name = old_name
                self.broker_client.publish(input)
                
                self.response.payload.id = item.id
                self.response.payload.name = item.name

            except Exception, e:
                msg = 'Could not update the OpenStack Swift connection, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise  

class Delete(AdminService):
    """ Deletes an OpenStack Swift connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_cloud_openstack_swift_delete_request'
        response_elem = 'zato_cloud_openstack_swift_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                item = session.query(OpenStackSwift).\
                    filter(OpenStackSwift.id==self.request.input.id).\
                    one()

                session.delete(item)
                session.commit()

                msg = {'action': CLOUD.OPENSTACK_SWIFT_DELETE, 'name': item.name, 'id':item.id}
                self.broker_client.publish(msg)
                
            except Exception, e:
                session.rollback()
                msg = 'Could not delete the OpenStack Swift connection, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)

                raise

########NEW FILE########
__FILENAME__ = amqp
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc
from uuid import uuid4

# Zato
from zato.common.broker_message import MESSAGE_TYPE, DEFINITION
from zato.common.odb.model import Cluster, ConnDefAMQP
from zato.common.odb.query import def_amqp, def_amqp_list
from zato.server.service.internal import AdminService, AdminSIO, ChangePasswordBase

class GetList(AdminService):
    """ Returns a list of AMQP definitions available.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_definition_amqp_get_list_request'
        response_elem = 'zato_definition_amqp_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'host', 'port', 'vhost', 'username', 'frame_max', 'heartbeat')
        output_repeated = True
        
    def get_data(self, session):
        return def_amqp_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)

class GetByID(AdminService):
    """ Returns a particular AMQP definition
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_definition_amqp_get_by_id_request'
        response_elem = 'zato_definition_amqp_get_by_id_response'
        input_required = ('id', 'cluster_id')
        output_required = ('id', 'name', 'host', 'port', 'vhost', 'username', 'frame_max', 'heartbeat')

    def get_data(self, session):
        return def_amqp(session, self.request.input.cluster_id, self.request.input.id)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload = self.get_data(session)
        
class Create(AdminService):
    """ Creates a new AMQP definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_definition_amqp_create_request'
        response_elem = 'zato_definition_amqp_create_response'
        input_required = ('cluster_id', 'name', 'host', 'port', 'vhost', 'username', 'frame_max', 'heartbeat')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        input.password = uuid4().hex
        
        with closing(self.odb.session()) as session:
            # Let's see if we already have an account of that name before committing
            # any stuff into the database.
            existing_one = session.query(ConnDefAMQP).\
                filter(ConnDefAMQP.cluster_id==Cluster.id).\
                filter(ConnDefAMQP.def_type=='amqp').\
                filter(ConnDefAMQP.name==input.name).\
                first()
            
            if existing_one:
                raise Exception('AMQP definition [{0}] already exists on this cluster'.format(input.name))
            
            try:
                def_ = ConnDefAMQP(None, input.name, 'amqp', input.host, input.port, input.vhost, 
                    input.username, input.password, input.frame_max, input.heartbeat,
                    input.cluster_id)
                session.add(def_)
                session.commit()
                
                self.response.payload.id = def_.id
                self.response.payload.name = def_.name
                
            except Exception, e:
                msg = 'Could not create an AMQP definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise 

class Edit(AdminService):
    """ Updates an AMQP definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_definition_amqp_edit_request'
        response_elem = 'zato_definition_amqp_edit_response'
        input_required = ('id', 'cluster_id', 'name', 'host', 'port', 'vhost', 'username', 'frame_max', 'heartbeat')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        
        with closing(self.odb.session()) as session:
            # Let's see if we already have an account of that name before committing
            # any stuff into the database.
            existing_one = session.query(ConnDefAMQP).\
                filter(ConnDefAMQP.cluster_id==Cluster.id).\
                filter(ConnDefAMQP.def_type=='amqp').\
                filter(ConnDefAMQP.id!=input.id).\
                filter(ConnDefAMQP.name==input.name).\
                first()
            
            if existing_one:
                raise Exception('AMQP definition [{0}] already exists on this cluster'.format(input.name))
            
            try:
                
                def_amqp = session.query(ConnDefAMQP).filter_by(id=input.id).one()
                old_name = def_amqp.name
                def_amqp.name = input.name
                def_amqp.host = input.host
                def_amqp.port = input.port
                def_amqp.vhost = input.vhost
                def_amqp.username = input.username
                def_amqp.frame_max = input.frame_max
                def_amqp.heartbeat = input.heartbeat
                
                session.add(def_amqp)
                session.commit()
                
                input.action = DEFINITION.AMQP_EDIT
                input.old_name = old_name
                self.broker_client.publish(input, msg_type=MESSAGE_TYPE.TO_AMQP_CONNECTOR_ALL)
                
                self.response.payload.id = def_amqp.id
                self.response.payload.name = def_amqp.name
                
            except Exception, e:
                msg = 'Could not update the AMQP definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise         
        
class Delete(AdminService):
    """ Deletes an AMQP definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_definition_amqp_delete_request'
        response_elem = 'zato_definition_amqp_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                def_ = session.query(ConnDefAMQP).\
                    filter(ConnDefAMQP.id==self.request.input.id).\
                    one()
                
                session.delete(def_)
                session.commit()

                msg = {'action': DEFINITION.AMQP_DELETE, 'id': self.request.input.id}
                self.broker_client.publish(msg, msg_type=MESSAGE_TYPE.TO_AMQP_CONNECTOR_ALL)
                
            except Exception, e:
                session.rollback()
                msg = 'Could not delete the AMQP definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                
                raise
            
class ChangePassword(ChangePasswordBase):
    """ Changes the password of an AMQP definition.
    """
    class SimpleIO(ChangePasswordBase.SimpleIO):
        request_elem = 'zato_definition_amqp_change_password_request'
        response_elem = 'zato_definition_amqp_change_password_response'
    
    def handle(self):
        
        def _auth(instance, password):
            instance.password = password
            
        return self._handle(ConnDefAMQP, _auth, 
            DEFINITION.AMQP_CHANGE_PASSWORD, msg_type=MESSAGE_TYPE.TO_AMQP_CONNECTOR_ALL, 
            payload=self.request.payload)

########NEW FILE########
__FILENAME__ = jms_wmq
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc

# Zato
from zato.common.broker_message import MESSAGE_TYPE, DEFINITION
from zato.common.odb.model import Cluster, ConnDefWMQ
from zato.common.odb.query import def_jms_wmq, def_jms_wmq_list
from zato.server.service import Boolean, Integer
from zato.server.service.internal import AdminService, AdminSIO

class GetList(AdminService):
    """ Returns a list of JMS WebSphere MQ definitions available.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_definition_jms_wmq_get_list_request'
        response_elem = 'zato_definition_jms_wmq_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'host', 'port', 'queue_manager', 'channel', 
            Boolean('cache_open_send_queues'), Boolean('cache_open_receive_queues'), 
            Boolean('use_shared_connections'), Boolean('ssl'), 
            'needs_mcd', Integer('max_chars_printed'))
        output_optional = ('ssl_cipher_spec', 'ssl_key_repository')
        
    def get_data(self, session):
        return def_jms_wmq_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)
        
class GetByID(AdminService):
    """ Returns a particular JMS WebSphere MQ definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_definition_jms_wmq_get_by_id_request'
        response_elem = 'zato_definition_jms_wmq_get_by_id_response'
        input_required = ('id', 'cluster_id',)
        output_required = ('id', 'name', 'host', 'port', 'queue_manager', 'channel', 
            Boolean('cache_open_send_queues'), Boolean('cache_open_receive_queues'), 
            Boolean('use_shared_connections'), Boolean('ssl'), 
            'needs_mcd', Integer('max_chars_printed'))
        output_optional = ('ssl_cipher_spec', 'ssl_key_repository')
        
    def get_data(self, session):
        return def_jms_wmq(session, self.request.input.cluster_id, self.request.input.id)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload = self.get_data(session)
        
class Create(AdminService):
    """ Creates a new JMS WebSphere MQ definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_definition_jms_wmq_create_request'
        response_elem = 'zato_definition_jms_wmq_create_response'
        input_required = ('cluster_id', 'name', 'host', 'port', 'queue_manager', 
            'channel', Boolean('cache_open_send_queues'), Boolean('cache_open_receive_queues'),
            Boolean('use_shared_connections'), Boolean('ssl'), 'needs_mcd', 
            Integer('max_chars_printed'))
        input_optional = ('ssl_cipher_spec', 'ssl_key_repository')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:
            # Let's see if we already have an object of that name before committing
            # any stuff into the database.
            existing_one = session.query(ConnDefWMQ).\
                filter(ConnDefWMQ.cluster_id==Cluster.id).\
                filter(ConnDefWMQ.name==input.name).\
                first()
            
            if existing_one:
                raise Exception('JMS WebSphere MQ definition [{0}] already exists on this cluster'.format(input.name))
            
            try:
                def_ = ConnDefWMQ(None, input.name, input.host, input.port, input.queue_manager, 
                    input.channel, input.cache_open_send_queues, input.cache_open_receive_queues,
                    input.use_shared_connections, input.ssl, input.ssl_cipher_spec, 
                    input.ssl_key_repository, input.needs_mcd, input.max_chars_printed,
                    input.cluster_id)
                session.add(def_)
                session.commit()

                self.response.payload.id = def_.id
                self.response.payload.name = def_.name

            except Exception, e:
                msg = "Could not create a JMS WebSphere MQ definition, e:[{e}]".format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise 

class Edit(AdminService):
    """ Updates a JMS WMQ definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_definition_jms_wmq_edit_request'
        response_elem = 'zato_definition_jms_wmq_edit_response'
        input_required = ('id', 'cluster_id', 'name', 'host', 'port', 'queue_manager', 
            'channel', Boolean('cache_open_send_queues'), Boolean('cache_open_receive_queues'),
            Boolean('use_shared_connections'), Boolean('ssl'), 
            'needs_mcd', Integer('max_chars_printed'))
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        
        with closing(self.odb.session()) as session:
            # Let's see if we already have an object of that name before committing
            # any stuff into the database.
            existing_one = session.query(ConnDefWMQ).\
                filter(ConnDefWMQ.cluster_id==Cluster.id).\
                filter(ConnDefWMQ.id!=input.id).\
                filter(ConnDefWMQ.name==input.name).\
                first()
            
            if existing_one:
                raise Exception('JMS WebSphere MQ definition [{0}] already exists on this cluster'.format(input.name))
            
            try:
                def_jms_wmq = session.query(ConnDefWMQ).filter_by(id=input.id).one()
                old_name = def_jms_wmq.name
                def_jms_wmq.name = input.name
                def_jms_wmq.host = input.host
                def_jms_wmq.port = input.port
                def_jms_wmq.queue_manager = input.queue_manager
                def_jms_wmq.channel = input.channel
                def_jms_wmq.cache_open_send_queues = input.cache_open_send_queues
                def_jms_wmq.cache_open_receive_queues = input.cache_open_receive_queues
                def_jms_wmq.use_shared_connections = input.use_shared_connections
                def_jms_wmq.ssl = input.ssl
                def_jms_wmq.ssl_cipher_spec = input.get('ssl_cipher_spec')
                def_jms_wmq.ssl_key_repository = input.get('ssl_key_repository')
                def_jms_wmq.needs_mcd = input.needs_mcd
                def_jms_wmq.max_chars_printed = input.max_chars_printed
                
                session.add(def_jms_wmq)
                session.commit()
                
                input.id = def_jms_wmq.id
                input.action = DEFINITION.JMS_WMQ_EDIT
                input.old_name = old_name
                self.broker_client.publish(input, msg_type=MESSAGE_TYPE.TO_JMS_WMQ_CONNECTOR_ALL)
                
                self.response.payload.id = def_jms_wmq.id
                self.response.payload.name = def_jms_wmq.name
                
            except Exception, e:
                msg = 'Could not update the JMS WebSphere MQ definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise         
        
class Delete(AdminService):
    """ Deletes a JMS WebSphere MQ definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_definition_jms_wmq_delete_request'
        response_elem = 'zato_definition_jms_wmq_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                def_ = session.query(ConnDefWMQ).\
                    filter(ConnDefWMQ.id==self.request.input.id).\
                    one()
                
                session.delete(def_)
                session.commit()

                msg = {'action': DEFINITION.JMS_WMQ_DELETE, 'id': self.request.input.id}
                self.broker_client.publish(msg, msg_type=MESSAGE_TYPE.TO_JMS_WMQ_CONNECTOR_ALL)
                
            except Exception, e:
                session.rollback()
                msg = 'Could not delete the JMS WebSphere MQ definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                
                raise

########NEW FILE########
__FILENAME__ = helpers
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Zato
from zato.server.service import Service

# ################################################################################################################################

class Echo(Service):
    """ Copies request over to response.
    """
    def handle(self):
        self.response.payload = self.request.raw_request

# ################################################################################################################################

class InputLogger(Service):
    """ Writes out all input data to server logs.
    """
    def handle(self):
        pass
    
    def finalize_handle(self):
        self.log_input()

# ################################################################################################################################

class SIOInputLogger(Service):
    """ Writes out all SIO input parameters to server logs.
    """
    def handle(self):
        self.logger.info('%r', self.request.input)

# ################################################################################################################################
########NEW FILE########
__FILENAME__ = http_soap
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from json import dumps, loads
from traceback import format_exc

# Paste
from paste.util.converters import asbool

# WebHelpers
from webhelpers.paginate import Page

# Zato
from zato.common import BATCH_DEFAULTS, DEFAULT_HTTP_PING_METHOD, DEFAULT_HTTP_POOL_SIZE, HTTP_SOAP_SERIALIZATION_TYPE, \
     MISC, MSG_PATTERN_TYPE, PARAMS_PRIORITY, SEC_DEF_TYPE, URL_PARAMS_PRIORITY, URL_TYPE, ZatoException, ZATO_NONE
from zato.common.broker_message import CHANNEL, OUTGOING
from zato.common.odb.model import Cluster, JSONPointer, HTTPSOAP, HTTSOAPAudit, HTTSOAPAuditReplacePatternsJSONPointer, \
     HTTSOAPAuditReplacePatternsXPath, SecurityBase, Service, to_json, XPath
from zato.common.odb.query import http_soap_audit_item, http_soap_audit_item_list, http_soap_list
from zato.server.service import Boolean, Integer, List
from zato.server.service.internal import AdminService, AdminSIO

class _HTTPSOAPService(object):
    """ A common class for various HTTP/SOAP-related services.
    """
    def notify_worker_threads(self, params, action):
        """ Notify worker threads of new or updated parameters.
        """
        params['action'] = action
        self.broker_client.publish(params)

    def _handle_security_info(self, session, security_id, connection, transport):
        """ First checks whether the security type is correct for the given 
        connection type. If it is, returns a dictionary of security-related information.
        """
        info = {'security_name':None, 'sec_type':None}
        
        if security_id:
            
            security = session.query(SecurityBase.name, SecurityBase.sec_type).\
                filter(SecurityBase.id==security_id).\
                one()
            
            # Outgoing plain HTTP connections may use HTTP Basic Auth only,
            # outgoing SOAP connections may use either WSS or HTTP Basic Auth.                
            if connection == 'outgoing':
                if transport == URL_TYPE.PLAIN_HTTP and security.sec_type != SEC_DEF_TYPE.BASIC_AUTH:
                    raise Exception('Only HTTP Basic Auth is supported, not [{}]'.format(security.sec_type))
                elif transport == URL_TYPE.SOAP and security.sec_type \
                     not in(SEC_DEF_TYPE.BASIC_AUTH, SEC_DEF_TYPE.NTLM, SEC_DEF_TYPE.WSS):
                    raise Exception('Security type must be HTTP Basic Auth, NTLM or WS-Security, not [{}]'.format(
                        security.sec_type))
            
            info['security_name'] = security.name
            info['sec_type'] = security.sec_type
            
        return info
        
class GetList(AdminService):
    """ Returns a list of HTTP/SOAP connections.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_http_soap_get_list_request'
        response_elem = 'zato_http_soap_get_list_response'
        input_required = ('cluster_id', 'connection', 'transport')
        output_required = ('id', 'name', 'is_active', 'is_internal', 'url_path')
        output_optional = ('service_id', 'service_name', 'security_id', 'security_name', 'sec_type', 
                           'method', 'soap_action', 'soap_version', 'data_format', 'host', 'ping_method',
                           'pool_size', 'merge_url_params_req', 'url_params_pri', 'params_pri', 'serialization_type',
                           'timeout')
        output_repeated = True
        
    def get_data(self, session):
        return http_soap_list(session, self.request.input.cluster_id,
            self.request.input.connection, self.request.input.transport,
            asbool(self.server.fs_server_config.misc.return_internal_objects), False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)

class Create(AdminService, _HTTPSOAPService):
    """ Creates a new HTTP/SOAP connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_http_soap_create_request'
        response_elem = 'zato_http_soap_create_response'
        input_required = ('cluster_id', 'name', 'is_active', 'connection', 'transport', 'is_internal', 'url_path')
        input_optional = ('service', 'security_id', 'method', 'soap_action', 'soap_version', 'data_format',
            'host', 'ping_method', 'pool_size', Boolean('merge_url_params_req'), 'url_params_pri', 'params_pri',
            'serialization_type', 'timeout')
        output_required = ('id', 'name')
    
    def handle(self):
        input = self.request.input
        input.security_id = input.security_id if input.security_id != ZATO_NONE else None
        input.soap_action = input.soap_action if input.soap_action else ''
        
        if not input.url_path.startswith('/'):
            msg = 'URL path:[{}] must start with a slash /'.format(input.url_path)
            self.logger.error(msg)
            raise Exception(msg)
        
        with closing(self.odb.session()) as session:
            existing_one = session.query(HTTPSOAP.id).\
                filter(HTTPSOAP.cluster_id==input.cluster_id).\
                filter(HTTPSOAP.name==input.name).\
                filter(HTTPSOAP.connection==input.connection).\
                filter(HTTPSOAP.transport==input.transport).\
                first()

            if existing_one:
                raise Exception('An object of that name [{0}] already exists on this cluster'.format(input.name))
            
            # Is the service's name correct?
            service = session.query(Service).\
                filter(Cluster.id==input.cluster_id).\
                filter(Service.name==input.service).first()
            
            if input.connection == 'channel' and not service:
                msg = 'Service [{0}] does not exist on this cluster'.format(input.service)
                self.logger.error(msg)
                raise Exception(msg)
            
            # Will raise exception if the security type doesn't match connection
            # type and transport
            sec_info = self._handle_security_info(session, input.security_id, 
                input.connection, input.transport)
            
            try:

                item = HTTPSOAP()
                item.connection = input.connection
                item.transport = input.transport
                item.cluster_id = input.cluster_id
                item.is_internal = input.is_internal
                item.name = input.name
                item.is_active = input.is_active
                item.host = input.host
                item.url_path = input.url_path
                item.security_id = input.security_id
                item.method = input.method
                item.soap_action = input.soap_action
                item.soap_version = input.soap_version
                item.data_format = input.data_format
                item.service = service
                item.ping_method = input.get('ping_method') or DEFAULT_HTTP_PING_METHOD
                item.pool_size = input.get('pool_size') or DEFAULT_HTTP_POOL_SIZE
                item.merge_url_params_req = input.get('merge_url_params_req') or True
                item.url_params_pri = input.get('url_params_pri') or URL_PARAMS_PRIORITY.DEFAULT
                item.params_pri = input.get('params_pri') or PARAMS_PRIORITY.DEFAULT
                item.serialization_type = input.get('serialization_type') or HTTP_SOAP_SERIALIZATION_TYPE.DEFAULT.id
                item.timeout = input.get('timeout') or MISC.DEFAULT_HTTP_TIMEOUT

                session.add(item)
                session.commit()
                
                if input.connection == 'channel':
                    input.impl_name = service.impl_name
                    input.service_id = service.id
                    input.service_name = service.name

                input.id = item.id
                input.update(sec_info)
                
                if input.connection == 'channel':
                    action = CHANNEL.HTTP_SOAP_CREATE_EDIT
                else:
                    action = OUTGOING.HTTP_SOAP_CREATE_EDIT
                self.notify_worker_threads(input, action)

                self.response.payload.id = item.id
                self.response.payload.name = item.name

            except Exception, e:
                msg = 'Could not create the object, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise

class Edit(AdminService, _HTTPSOAPService):
    """ Updates an HTTP/SOAP connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_http_soap_edit_request'
        response_elem = 'zato_http_soap_edit_response'
        input_required = ('id', 'cluster_id', 'name', 'is_active', 'connection', 'transport', 'url_path')
        input_optional = ('service', 'security_id', 'method', 'soap_action', 'soap_version', 'data_format', 
            'host', 'ping_method', 'pool_size', Boolean('merge_url_params_req'), 'url_params_pri', 'params_pri',
            'serialization_type', 'timeout')
        output_required = ('id', 'name')
    
    def handle(self):
        input = self.request.input
        input.security_id = input.security_id if input.security_id != ZATO_NONE else None
        input.soap_action = input.soap_action if input.soap_action else ''
        
        if not input.url_path.startswith('/'):
            msg = 'URL path:[{}] must start with a slash /'.format(input.url_path)
            self.logger.error(msg)
            raise Exception(msg)
        
        with closing(self.odb.session()) as session:

            existing_one = session.query(HTTPSOAP.id).\
                filter(HTTPSOAP.cluster_id==input.cluster_id).\
                filter(HTTPSOAP.id!=input.id).\
                filter(HTTPSOAP.name==input.name).\
                filter(HTTPSOAP.connection==input.connection).\
                filter(HTTPSOAP.transport==input.transport).\
                first()

            if existing_one:
                raise Exception('An object of that name [{0}] already exists on this cluster'.format(input.name))
            
            # Is the service's name correct?
            service = session.query(Service).\
                filter(Cluster.id==input.cluster_id).\
                filter(Service.name==input.service).first()
            
            if input.connection == 'channel' and not service:
                msg = 'Service [{0}] does not exist on this cluster'.format(input.service)
                self.logger.error(msg)
                raise Exception(msg)
            
            # Will raise exception if the security type doesn't match connection
            # type and transport
            sec_info = self._handle_security_info(session, input.security_id, input.connection, input.transport)

            try:
                item = session.query(HTTPSOAP).filter_by(id=input.id).one()
                old_name = item.name
                old_url_path = item.url_path
                old_soap_action = item.soap_action
                item.name = input.name
                item.is_active = input.is_active
                item.host = input.host
                item.url_path = input.url_path
                item.security_id = input.security_id
                item.connection = input.connection
                item.transport = input.transport
                item.cluster_id = input.cluster_id
                item.method = input.method
                item.soap_action = input.soap_action
                item.soap_version = input.soap_version
                item.data_format = input.data_format
                item.service = service
                item.ping_method = input.get('ping_method') or DEFAULT_HTTP_PING_METHOD
                item.pool_size = input.get('pool_size') or DEFAULT_HTTP_POOL_SIZE
                item.merge_url_params_req = input.get('merge_url_params_req') or True
                item.url_params_pri = input.get('url_params_pri') or URL_PARAMS_PRIORITY.DEFAULT
                item.params_pri = input.get('params_pri') or PARAMS_PRIORITY.DEFAULT
                item.serialization_type = input.get('serialization_type') or HTTP_SOAP_SERIALIZATION_TYPE.DEFAULT.id
                item.timeout = input.get('timeout') or MISC.DEFAULT_HTTP_TIMEOUT

                session.add(item)
                session.commit()
                
                if input.connection == 'channel':
                    input.impl_name = service.impl_name
                    input.service_id = service.id
                    input.service_name = service.name
                    input.merge_url_params_req = item.merge_url_params_req
                    input.url_params_pri = item.url_params_pri
                    input.params_pri = item.params_pri
                else:
                    input.ping_method = item.ping_method
                    input.pool_size = item.pool_size
                
                input.is_internal = item.is_internal
                input.old_name = old_name
                input.old_url_path = old_url_path
                input.old_soap_action = old_soap_action
                input.update(sec_info)
                
                if input.connection == 'channel':
                    action = CHANNEL.HTTP_SOAP_CREATE_EDIT
                else:
                    action = OUTGOING.HTTP_SOAP_CREATE_EDIT
                self.notify_worker_threads(input, action)

                self.response.payload.id = item.id
                self.response.payload.name = item.name

            except Exception, e:
                msg = 'Could not update the object, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise

class Delete(AdminService, _HTTPSOAPService):
    """ Deletes an HTTP/SOAP connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_http_soap_delete_request'
        response_elem = 'zato_http_soap_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                item = session.query(HTTPSOAP).\
                    filter(HTTPSOAP.id==self.request.input.id).\
                    one()
                
                old_name = item.name
                old_transport = item.transport
                old_url_path = item.url_path
                old_soap_action = item.soap_action

                session.delete(item)
                session.commit()
                
                if item.connection == 'channel':
                    action = CHANNEL.HTTP_SOAP_DELETE
                else:
                    action = OUTGOING.HTTP_SOAP_DELETE
                
                self.notify_worker_threads({'name':old_name, 'transport':old_transport,
                    'old_url_path':old_url_path, 'old_soap_action':old_soap_action}, action)

            except Exception, e:
                session.rollback()
                msg = 'Could not delete the object, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)

                raise
            
class Ping(AdminService):
    """ Pings an HTTP/SOAP connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_http_soap_ping_request'
        response_elem = 'zato_http_soap_ping_response'
        input_required = ('id',)
        output_required = ('info',)

    def handle(self):
        with closing(self.odb.session()) as session:
            item = session.query(HTTPSOAP).filter_by(id=self.request.input.id).one()
            config_dict = getattr(self.outgoing, item.transport)
            self.response.payload.info = config_dict.get(item.name).ping(self.cid)

class ReloadWSDL(AdminService, _HTTPSOAPService):
    """ Reloads WSDL by recreating the whole underlying queue of SOAP clients.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_http_soap_reload_wsdl_request'
        response_elem = 'zato_http_soap_reload_wsdl_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            item = session.query(HTTPSOAP).filter_by(id=self.request.input.id).one()
            sec_info = self._handle_security_info(session, item.security_id, item.connection, item.transport)

        fields = to_json(item, True)['fields']
        fields['sec_type'] = sec_info['sec_type']
        fields['security_name'] = sec_info['security_name']

        action = OUTGOING.HTTP_SOAP_CREATE_EDIT
        self.notify_worker_threads(fields, action)

class GetURLSecurity(AdminService):
    """ Returns a JSON document describing the security configuration of all
    Zato channels.
    """
    def handle(self):
        response = {}
        response['url_sec'] = sorted(self.worker_store.request_handler.security.url_sec.items())
        response['plain_http_handler.http_soap'] = sorted(self.worker_store.request_handler.plain_http_handler.http_soap.items())
        response['soap_handler.http_soap'] = sorted(self.worker_store.request_handler.soap_handler.http_soap.items())
        self.response.payload = dumps(response, sort_keys=True, indent=4)
        self.response.content_type = 'application/json'

# ################################################################################################################################
        
class GetAuditConfig(AdminService):
    """ Returns audit configuration for a given HTTP/SOAP object.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_http_soap_get_audit_config_request'
        response_elem = 'zato_http_soap_get_audit_config_response'
        input_required = ('id',)
        output_required = (Boolean('audit_enabled'), Integer('audit_back_log'), 
            Integer('audit_max_payload'), 'audit_repl_patt_type')
    
    def handle(self):
        with closing(self.odb.session()) as session:
            item = session.query(HTTPSOAP).\
                filter(HTTPSOAP.id==self.request.input.id).\
                one()
            
            self.response.payload.audit_enabled = item.audit_enabled
            self.response.payload.audit_back_log = item.audit_back_log
            self.response.payload.audit_max_payload = item.audit_max_payload
            self.response.payload.audit_repl_patt_type = item.audit_repl_patt_type

class SetAuditConfig(AdminService):
    """ Sets audit configuration for a given HTTP/SOAP connection. Everything except for replace patterns.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_http_soap_set_audit_config_request'
        response_elem = 'zato_http_soap_set_audit_config_response'
        input_required = ('id', Integer('audit_max_payload'))

    def handle(self):
        with closing(self.odb.session()) as session:
            item = session.query(HTTPSOAP).\
                filter(HTTPSOAP.id==self.request.input.id).\
                one()

            item.audit_max_payload = self.request.input.audit_max_payload
            session.commit()

            params = {
                'action': CHANNEL.HTTP_SOAP_AUDIT_CONFIG,
                'audit_max_payload': item.audit_max_payload,
                'id': item.id
            }
            self.broker_client.publish(params)

# ################################################################################################################################

class GetAuditReplacePatterns(AdminService):
    """ Returns audit replace patterns for a given connection, both JSONPointer and XPath.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_http_soap_get_audit_replace_patterns_request'
        response_elem = 'zato_http_soap_get_audit_replace_patterns_response'
        input_required = ('id',)
        output_required = (List('patterns_json_pointer'), List('patterns_xpath'))

    def handle(self):
        with closing(self.odb.session()) as session:
            item = session.query(HTTPSOAP).\
                filter(HTTPSOAP.id==self.request.input.id).\
                one()

            self.response.payload.patterns_json_pointer = [elem.pattern.name for elem in item.replace_patterns_json_pointer]
            self.response.payload.patterns_xpath = [elem.pattern.name for elem in item.replace_patterns_xpath]

class SetAuditReplacePatterns(AdminService):
    """ Set audit replace patterns for a given HTTP/SOAP connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_http_soap_set_replace_patterns_request'
        response_elem = 'zato_http_soap_set_replace_patterns_response'
        input_required = ('id', 'audit_repl_patt_type')
        input_optional = (List('pattern_list'),)

    def _clear_patterns(self, conn):
        conn.replace_patterns_json_pointer[:] = []
        conn.replace_patterns_xpath[:] = []

    def handle(self):
        conn_id = self.request.input.id
        patt_type = self.request.input.audit_repl_patt_type

        with closing(self.odb.session()) as session:
            conn = session.query(HTTPSOAP).\
                filter(HTTPSOAP.id==conn_id).\
                one()

            if not self.request.input.pattern_list:
                # OK, no patterns at all so we indiscriminately delete existing ones, if any, for the connection.
                self._clear_patterns(conn)
                session.commit()
                
            else:
                pattern_class = JSONPointer if patt_type == MSG_PATTERN_TYPE.JSON_POINTER.id else XPath
                conn_pattern_list_class = HTTSOAPAuditReplacePatternsJSONPointer if patt_type == MSG_PATTERN_TYPE.JSON_POINTER.id else \
                    HTTSOAPAuditReplacePatternsXPath
                
                all_patterns = session.query(pattern_class).\
                    filter(pattern_class.cluster_id==self.server.cluster_id).\
                    all()
                
                missing = set(self.request.input.pattern_list) - set([elem.name for elem in all_patterns])
                if missing:
                    msg = 'Could not find one or more pattern(s) {}'.format(sorted(missing))
                    self.logger.warn(msg)
                    raise ZatoException(self.cid, msg)

                # Clears but doesn't commit yet
                self._clear_patterns(conn)

                for name in self.request.input.pattern_list:
                    for pattern in all_patterns:
                        if name == pattern.name:
                            item = conn_pattern_list_class()
                            item.conn_id = conn.id
                            item.pattern_id = pattern.id
                            item.cluster_id = self.server.cluster_id
                            session.add(item)

                session.commit()

                params = {
                    'action': CHANNEL.HTTP_SOAP_AUDIT_PATTERNS,
                    'id': conn_id,
                    'audit_repl_patt_type': self.request.input.audit_repl_patt_type,
                    'pattern_list': self.request.input.pattern_list,
                }
                self.broker_client.publish(params)

# ################################################################################################################################

class SetAuditState(AdminService):
    """ Enables or disables audit for a given HTTP/SOAP object.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_http_soap_set_audit_state_request'
        response_elem = 'zato_http_soap_set_audit_state_response'
        input_required = ('id', Boolean('audit_enabled'))
    
    def handle(self):
        with closing(self.odb.session()) as session:
            item = session.query(HTTPSOAP).\
                filter(HTTPSOAP.id==self.request.input.id).\
                one()
            
            item.audit_enabled = self.request.input.audit_enabled
            
            session.add(item)
            session.commit()
            
            params = {
                'action': CHANNEL.HTTP_SOAP_AUDIT_STATE,
                'id': item.id,
                'audit_enabled': item.audit_enabled,
            }
            self.broker_client.publish(params)

# ################################################################################################################################

class SetAuditResponseData(AdminService):
    """ Updates information regarding a response of a channel/outconn invocation.
    """
    def handle(self):
        with closing(self.odb.session()) as session:
            
            payload_req = self.request.payload
            item = session.query(HTTSOAPAudit).filter_by(cid=payload_req['cid']).one()
            
            item.invoke_ok = asbool(payload_req['invoke_ok'])
            item.auth_ok = asbool(payload_req['auth_ok'])
            item.resp_time = payload_req['resp_time']
            item.resp_headers = payload_req['resp_headers'].encode('utf-8')
            item.resp_payload = payload_req['resp_payload'].encode('utf-8')
            
            session.add(item)
            session.commit()

# ################################################################################################################################

class _BaseAuditService(AdminService):
    def get_page(self, session):
        current_batch = self.request.input.get('current_batch', BATCH_DEFAULTS.PAGE_NO)
        batch_size = self.request.input.get('batch_size', BATCH_DEFAULTS.SIZE)
        batch_size = min(batch_size, BATCH_DEFAULTS.MAX_SIZE)
        
        q = http_soap_audit_item_list(session, self.server.cluster_id, self.request.input.conn_id, 
            self.request.input.get('start'), self.request.input.get('stop'), self.request.input.get('query'), False)
        
        return Page(q, page=current_batch, items_per_page=batch_size)

class GetAuditItemList(_BaseAuditService):
    """ Returns a list of audit items for a particular HTTP/SOAP object.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_http_soap_get_audit_item_list_request'
        response_elem = 'zato_http_soap_get_audit_item_list_response'
        input_required = ('conn_id', )
        input_optional = ('start', 'stop', Integer('current_batch'), Integer('batch_size'), 'query')
        output_required = ('id', 'cid', 'req_time_utc', 'remote_addr',)
        output_optional = ('resp_time_utc', 'user_token', 'invoke_ok', 'auth_ok', )

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_page(session)
            
        for item in self.response.payload.zato_output:
            item.req_time_utc = item.req_time_utc.isoformat()
            if item.resp_time_utc:
                item.resp_time_utc = item.resp_time_utc.isoformat()
                
class GetAuditBatchInfo(_BaseAuditService):
    """ Returns pagination information for audit log for a specified object and from/to dates.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_http_soap_get_batch_info_request'
        response_elem = 'zato_http_soap_get_batch_info_response'
        input_required = ('conn_id',)
        input_optional = ('start', 'stop', Integer('current_batch'), Integer('batch_size'), 'query')
        output_required = ('total_results', 'num_batches', 'has_previous', 'has_next', 'next_batch_number', 'previous_batch_number')

    def handle(self):
        with closing(self.odb.session()) as session:
            page = self.get_page(session)
            self.response.payload = {
                'total_results': page.item_count,
                'num_batches': page.page_count,
                'has_previous': page.previous_page is not None,
                'has_next': page.next_page is not None,
                'next_batch_number': page.next_page,
                'previous_batch_number': page.previous_page,
            }
            
class GetAuditItem(_BaseAuditService):
    """ Returns a particular audit item by its ID.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_http_soap_get_audit_item_request'
        response_elem = 'zato_http_soap_get_audit_item_response'
        input_required = ('id',)
        output_required = ('id', 'cid', 'req_time_utc', 'remote_addr',)
        output_optional = ('resp_time_utc', 'user_token', 'invoke_ok', 'auth_ok', 'req_headers', 'req_payload', 
            'resp_headers', 'resp_payload')

    def handle(self):
        with closing(self.odb.session()) as session:
            item = http_soap_audit_item(session, self.server.cluster_id, self.request.input.id).one()
            item.req_time_utc = item.req_time_utc.isoformat()
            if item.resp_time_utc:
                item.resp_time_utc = item.resp_time_utc.isoformat()
                
            self.response.payload = item

# ################################################################################################################################

########NEW FILE########
__FILENAME__ = info
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from json import dumps, loads

# Zato
from zato.client import AnyServiceInvoker
from zato.common import INFO_FORMAT, SERVER_JOIN_STATUS, SERVER_UP_STATUS
from zato.common.broker_message import MESSAGE_TYPE
from zato.common.odb.query import server_list
from zato.common.component_info import format_info, get_info
from zato.server.service import Service

# ################################################################################################################################

class GetInfo(Service):
    """ Like 'zato info' on command line but works across the whole cluster rather than with a single server.
    """
    def handle(self):

        # Let's prepare as much as we can upfront.
        sec_def = self.worker_store.basic_auth_get('admin.invoke').config
        channel = self.worker_store.get_channel_plain_http('admin.invoke.json')
        out = {}

        with closing(self.odb.session()) as session:
            for item in server_list(session, self.server.cluster_id, False):
                server_info = out.setdefault(item.name, {})
                server_info['cluster_name'] = item.cluster_name

                server_info['up_mod_date'] = item.up_mod_date.isoformat() if item.up_status == SERVER_UP_STATUS.RUNNING else None
                server_info['last_join_mod_date'] = item.last_join_mod_date.isoformat() if \
                    item.last_join_status == SERVER_JOIN_STATUS.ACCEPTED else None

                for name in 'id', 'name', 'bind_host', 'bind_port', 'last_join_status', 'last_join_mod_by', 'up_status':
                    server_info[name] = getattr(item, name)

                if item.up_status == SERVER_UP_STATUS.RUNNING:

                    client = AnyServiceInvoker(
                        'http://{}:{}'.format(item.bind_host, item.bind_port),
                        channel.url_path, (sec_def.username, sec_def.password))
                    response = client.invoke('zato.info.get-server-info')
                    if response.ok:
                        response = loads(response.inner.text)['zato_service_invoke_response']['response'].decode('base64')
                        response = loads(response)['response']
                        server_info['info'] = loads(response['info'])
                    else:
                        self.logger.warn(response)

        self.response.content_type = 'application/json'
        self.response.payload = dumps(out)

class GetServerInfo(Service):
    """ Collects information about a server it's invoked on.
    """
    class SimpleIO(object):
        output_required = ('info',)

    def handle(self):
        self.response.content_type = 'application/json'
        self.response.payload.info = format_info(get_info(self.server.base_dir, INFO_FORMAT.JSON), INFO_FORMAT.JSON)

########NEW FILE########
__FILENAME__ = dictionary
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import re

# Zato
from zato.common import KVDB, ZatoException
from zato.common.util import dict_item_name
from zato.server.service.internal import AdminService, AdminSIO
from zato.server.service.internal.kvdb.data_dict import DataDictService

class GetList(DataDictService):
    """ Returns a list of dictionary items.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_kvdb_data_dict_dictionary_get_list_request'
        response_elem = 'zato_kvdb_data_dict_dictionary_get_list_response'
        output_required = ('id', 'system', 'key', 'value')
        
    def get_data(self):
        return self._get_dict_items()

    def handle(self):
        self.response.payload[:] = self.get_data()

class _CreateEdit(DataDictService):
    NAME_PATTERN = '\w+'
    NAME_RE = re.compile(NAME_PATTERN)
    
    class SimpleIO(AdminSIO):
        input_required = ('system', 'key', 'value')
        input_optional = ('id',)
        output_required = ('id',)
        
    def _validate_entry(self, validate_item, id=None):
        for elem in('system', 'key'):
            name = self.request.input[elem]
            match = self.NAME_RE.match(name)
            if match and match.group() == name:
                continue
            else:
                msg = "System and key may contain only letters, digits and an underscore, failed to validate [{}] against the regular expression {}".format(
                    name, self.NAME_PATTERN)
                raise ZatoException(self.cid, msg)
        
        for item in self._get_dict_items():
            joined = KVDB.SEPARATOR.join((item['system'], item['key'], item['value']))
            if validate_item == joined and id != item['id']:
                msg = 'The triple of system:[{}], key:[{}], value:[{}] already exists'.format(item['system'], item['key'], item['value'])
                raise ZatoException(self.cid, msg)

        return True

    def _get_item_name(self):
        return dict_item_name(self.request.input.system, self.request.input.key, self.request.input.value)

    def handle(self):
        item = self._get_item_name()

        if self.request.input.get('id'):
            id = self.request.input.id
        else:
            id = self.server.kvdb.conn.incr(KVDB.DICTIONARY_ITEM_ID)
            
        id = str(id)
            
        if self._validate_entry(item, id):
            self._handle(id)
        
        self.server.kvdb.conn.hset(KVDB.DICTIONARY_ITEM, id, item)
        self.response.payload.id = id
        
    def _handle(self, *args, **kwargs):
        raise NotImplementedError('Must be implemented by a subclass')

class Create(_CreateEdit):
    """ Creates a new dictionary entry.
    """
    class SimpleIO(_CreateEdit.SimpleIO):
        request_elem = 'zato_kvdb_data_dict_dictionary_create_request'
        response_elem = 'zato_kvdb_data_dict_dictionary_create_response'
    
    def _handle(self, *ignored_args, **ignored_kwargs):
        pass
        
class Edit(_CreateEdit):
    """ Updates a dictionary entry.
    """
    class SimpleIO(_CreateEdit.SimpleIO):
        request_elem = 'zato_kvdb_data_dict_dictionary_edit_request'
        response_elem = 'zato_kvdb_data_dict_dictionary_edit_response'
    
    def _handle(self, id):
        for item in self._get_translations():
            if item['id1'] == id or item['id2'] == id:
                existing_name = self._name(item['system1'], item['key1'], item['value1'], item['system2'], item['key2'])
                if item['id1'] == id:
                    hash_name = self._name(self.request.input.system, self.request.input.key, self.request.input.value, item['system2'], item['key2'])
                else:
                    hash_name = self._name(item['system1'], item['key1'], item['value1'], self.request.input.system, self.request.input.key)
                    
                if existing_name == hash_name and item['value2'] == self.request.input:
                    continue
                
                if existing_name != hash_name:
                    self.server.kvdb.conn.renamenx(existing_name, hash_name)

                if item['id2'] == id:
                    self.server.kvdb.conn.hset(hash_name, 'value2', self.request.input.value)

class Delete(DataDictService):
    """ Deletes a dictionary entry by its ID.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_kvdb_data_dict_dictionary_delete_request'
        response_elem = 'zato_kvdb_data_dict_dictionary_delete_response'
        input_required = ('id',)
        output_required = ('id',)
        
    def handle(self):
        id = str(self.request.input.id)
        self.server.kvdb.conn.hdel(KVDB.DICTIONARY_ITEM, id)
        for item in self._get_translations():
            if item['id1'] == id or item['id2'] == id:
                self.server.kvdb.conn.delete(self._name(item['system1'], item['key1'], item['value1'], item['system2'], item['key2']))
                
        self.response.payload.id = self.request.input.id
        
class _DictionaryEntryService(DataDictService):
    """ Base class for returning a list of systems, keys and values.
    """
    def get_data(self, needs_systems=False, by_system=None, by_key=None):
        for triple in self.server.kvdb.conn.hvals(KVDB.DICTIONARY_ITEM):
            system, key, value = triple.decode('utf-8').split(KVDB.SEPARATOR)
            if needs_systems:
                yield system
            elif by_system:
                if by_key:
                    if system == by_system and key == by_key:
                        yield value
                elif system == by_system:
                    yield key

class GetSystemList(_DictionaryEntryService):
    """ Returns a list of systems used in dictionaries.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_kvdb_data_dict_dictionary_get_system_list_request'
        response_elem = 'zato_kvdb_data_dict_dictionary_get_system_list_response'
        output_required = ('name',)
        
    def handle(self):
        self.response.payload[:] = ({'name':elem} for elem in sorted(set(self.get_data(True))))

class GetKeyList(_DictionaryEntryService):
    """ Returns a list of keys used in a system's dictionary.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_kvdb_data_dict_dictionary_get_key_list_request'
        response_elem = 'zato_kvdb_data_dict_dictionary_get_key_list_response'
        input_required = ('system',)
        output_required = ('name',)
        
    def handle(self):
        self.response.payload[:] = ({'name':elem} for elem in sorted(set(self.get_data(False, self.request.input.system))))

class GetValueList(_DictionaryEntryService):
    """ Returns a list of values used in a system dictionary's key.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_kvdb_data_dict_dictionary_get_value_list_request'
        response_elem = 'zato_kvdb_data_dict_dictionary_get_value_list_response'
        input_required = ('system', 'key')
        output_required = ('name',)
        
    def handle(self):
        self.response.payload[:] = ({'name':elem} for elem in sorted(set(self.get_data(False, self.request.input.system, self.request.input.key))))

class GetLastID(AdminService):
    """ Returns the value of the last dictionary's ID or nothing at all if the key
    for holding its value doesn't exist.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_kvdb_data_dict_dictionary_get_last_id_request'
        response_elem = 'zato_kvdb_data_dict_dictionary_get_last_id_response'
        output_optional = ('value',)
        
    def handle(self):
        self.response.payload.value = self.server.kvdb.conn.get(KVDB.DICTIONARY_ITEM_ID) or ''

########NEW FILE########
__FILENAME__ = impexp
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# anyjson
from anyjson import loads

# Zato
from zato.common import KVDB
from zato.common.util import dict_item_name, translation_name
from zato.server.service.internal import AdminSIO
from zato.server.service.internal.kvdb.data_dict import DataDictService

class Import(DataDictService):
    """ Imports a bz2-compressed JSON document containing data dictionaries replacing
    any other existing ones.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_kvdb_data_dict_impexp_import_request'
        response_elem = 'zato_kvdb_data_dict_impexp_import_response'
        input_required = ('data',)
        
    def handle(self):
        data = loads(self.request.input.data.decode('base64').decode('bz2'))
        with self.server.kvdb.conn.pipeline() as p:
            p.delete(KVDB.DICTIONARY_ITEM_ID)
            p.delete(KVDB.DICTIONARY_ITEM)
            p.delete(KVDB.TRANSLATION_ID)
            
            for item in self._get_translations():
                key = translation_name(item['system1'], item['key1'], item['value1'], item['system2'], item['key2'])
                p.delete(key)
                
            # Another proof software engineering and philosophy have /a lot/ in common!
            data = data['data'] 
            
            p.set(KVDB.DICTIONARY_ITEM_ID, data['last_dict_id'])
            p.set(KVDB.TRANSLATION_ID, data['last_translation_id'])
            
            for item in data['dict_list']:
                p.hset(KVDB.DICTIONARY_ITEM, item['id'], dict_item_name(item['system'], item['key'], item['value']))
                
            for item in data['translation_list']:
                key = item.keys()[0]
                for value_key, value in item[key].items():
                    p.hset(key, value_key, value)
                
            p.execute()

########NEW FILE########
__FILENAME__ = translation
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from hashlib import sha1, sha256

# Zato
from zato.common import KVDB, ZatoException
from zato.common.util import hexlify, multikeysort
from zato.server.service.internal import AdminService, AdminSIO
from zato.server.service.internal.kvdb.data_dict import DataDictService

class _DeletingService(DataDictService):
    """ Subclasses of this class know how to delete a translation.
    """
    def delete(self, id):
        for item in self._get_translations():
            if int(item['id']) == id:
                delete_key = KVDB.SEPARATOR.join((KVDB.TRANSLATION, item['system1'], item['key1'], item['value1'], item['system2'], item['key2']))
                self.server.kvdb.conn.delete(delete_key)

class GetList(DataDictService):
    """ Returns a list of translations.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_kvdb_data_dict_translation_get_list_request'
        response_elem = 'zato_kvdb_data_dict_translation_get_list_response'
        output_required = ('id', 'system1', 'key1', 'value1', 'system2', 'key2', 'value2', 'id1', 'id2')
        
    def get_data(self):
        return multikeysort(self._get_translations(), ['system1', 'key1', 'value1', 'system2', 'key2', 'value2'])

    def handle(self):
        self.response.payload[:] = self.get_data()
        
class _CreateEdit(DataDictService):
    """ A base class for both Create and Edit actions.
    """
    def _validate_name(self, name, system1, key1, value1, system2, key2, id):
        """ Makes sure the translation doesn't already exist.
        """
        def _exception():
            msg = 'A mapping between system1:[{}], key1:[{}], value1:[{}] and system2:[{}], key2:[{}] already exists'.format(
                system1, key1, value1, system2, key2)
            self.logger.error(msg)
            raise ZatoException(self.cid, msg)

        if self.server.kvdb.conn.exists(name):
            # No ID means it's a Create so it's a genuine match of an existing mapping
            if not id:
                _exception()
            
            # We've got an ID so it's an Edit and we need ignore it if we're
            # editing ourself.
            existing_id = self.server.kvdb.conn.hget(name, 'id')
            if not str(existing_id) == str(id):
                _exception()

        return True
        
    def _get_item_ids(self):
        """ Returns IDs of the dictionary entries used in the translation.
        """
        item_ids = {'id1':None, 'id2':None}
        
        for idx in('1', '2'):
            system = self.request.input.get('system' + idx)
            key = self.request.input.get('key' + idx)
            value = self.request.input.get('value' + idx)
            item_ids['id' + idx] = self._get_dict_item_id(system, key, value)
         
        # This is a sanity check, in theory the input data can't possibly be outside
        # of what's in the KVDB.DICTIONARY_ITEM key
        for idx in('1', '2'):
            if not item_ids['id' + idx]:
                msg = 'Could not find the ID for system:[{}], key:[{}], value:[{}]'.format(
                    self.request.input.get('system' + idx), self.request.input.get('key' + idx),
                    self.request.input.get('value' + idx))
                raise ZatoException(self.cid, msg)
            
        return item_ids
    
    def handle(self):
        system1 = self.request.input.system1
        key1 = self.request.input.key1
        value1 = self.request.input.value1
        system2 = self.request.input.system2
        key2 = self.request.input.key2
        
        item_ids = self._get_item_ids()
        hash_name = self._name(system1, key1, value1, system2, key2)
        
        if self._validate_name(hash_name, system1, key1, value1, system2, key2, self.request.input.get('id')):
            self.response.payload.id = self._handle(hash_name, item_ids)
            
    def _handle(self, *args, **kwargs):
        raise NotImplementedError('Must be implemented by a subclass')
    
    def _set_hash_fields(self, hash_name, item_ids):
        self.server.kvdb.conn.hset(hash_name, 'id1', item_ids['id1'])
        self.server.kvdb.conn.hset(hash_name, 'id2', item_ids['id2'])
        self.server.kvdb.conn.hset(hash_name, 'value2', self.request.input.value2)
            
class Create(_CreateEdit):
    """ Creates a translation between dictionary entries.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_kvdb_data_dict_translation_create_request'
        response_elem = 'zato_kvdb_data_dict_translation_create_response'
        input_required = ('system1', 'key1', 'value1', 'system2', 'key2', 'value2')
        output_required = ('id',)
        
    def _handle(self, hash_name, item_ids):
        id = self.server.kvdb.conn.incr(KVDB.TRANSLATION_ID)
        self.server.kvdb.conn.hset(hash_name, 'id', id)
        self._set_hash_fields(hash_name, item_ids)
        return id
    
class Edit(_CreateEdit):
    """ Updates a translation between dictionary entries.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_kvdb_data_dict_translation_edit_request'
        response_elem = 'zato_kvdb_data_dict_translation_edit_response'
        input_required = ('id', 'system1', 'key1', 'value1', 'system2', 'key2', 'value2')
        output_required = ('id',)
        
    def _handle(self, hash_name, item_ids):
        for item in self._get_translations():
            if item['id'] == str(self.request.input.id):
                existing_name = self._name(item['system1'], item['key1'], item['value1'], item['system2'], item['key2'])
                if existing_name != hash_name:
                    self.server.kvdb.conn.renamenx(existing_name, hash_name)
                    self._set_hash_fields(hash_name, item_ids)
                break

        return self.request.input.id

class Delete(_DeletingService):
    """ Deletes a translation between dictionary entries.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_kvdb_data_dict_translation_delete_request'
        response_elem = 'zato_kvdb_data_dict_translation_delete_response'
        input_required = ('id',)
        
    def handle(self):
        self.delete(self.request.input.id)

class Translate(AdminService):
    class SimpleIO(AdminSIO):
        request_elem = 'zato_kvdb_data_dict_translation_translate_request'
        response_elem = 'zato_kvdb_data_dict_translation_translate_response'
        input_required = ('system1', 'key1', 'value1', 'system2', 'key2')
        output_optional = ('value2', 'repr', 'hex', 'sha1', 'sha256')
        
    def handle(self):
        result = self.translate(self.request.input.system1, self.request.input.key1, self.request.input.value1, 
            self.request.input.system2, self.request.input.key2)
        
        if result:
            self.response.payload.value2 = result.decode('utf-8')
            self.response.payload.repr = repr(result)
            self.response.payload.hex = hexlify(result)
            self.response.payload.sha1 = sha1(result).hexdigest()
            self.response.payload.sha256 = sha256(result).hexdigest()

class GetLastID(AdminService):
    """ Returns the value of the last dictionary's ID or nothing at all if the key
    for holding its value doesn't exist.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_kvdb_data_dict_translation_get_last_id_request'
        response_elem = 'zato_kvdb_data_dict_translation_get_last_id_response'
        output_optional = ('value',)
        
    def handle(self):
        self.response.payload.value = self.server.kvdb.conn.get(KVDB.TRANSLATION_ID) or ''

########NEW FILE########
__FILENAME__ = json_pointer
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc
from uuid import uuid4

# jsonpointer 
# Using 'as' below because Wing IDE confuses it with JSONPointer
from jsonpointer import JsonPointer as _JsonPointer

# Zato
from zato.common import MSG_PATTERN_TYPE
from zato.common.broker_message import MSG_JSON_POINTER
from zato.common.odb.model import Cluster, JSONPointer
from zato.common.odb.query import json_pointer_list
from zato.server.service.internal import AdminService, AdminSIO

# ##############################################################################

class GetList(AdminService):
    """ Returns a list of JSON Pointers available.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_message_json_pointer_get_list_request'
        response_elem = 'zato_message_json_pointer_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'value')

    def get_data(self, session):
        return json_pointer_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)

# ##############################################################################

class _CreateEdit(AdminService):
    def check_json_pointer(self, value):
        """ Check whether the expression can be evaluated at all.
        """
        p = _JsonPointer(value)
        p.resolve({}, None)

class Create(_CreateEdit):
    """ Creates a new JSON Pointer.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_message_json_pointer_create_request'
        response_elem = 'zato_message_json_pointer_create_response'
        input_required = ('cluster_id', 'name', 'value')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input

        # Sanity check
        self.check_json_pointer(input.value)

        with closing(self.odb.session()) as session:
            try:
                cluster = session.query(Cluster).filter_by(id=input.cluster_id).first()

                # Let's see if we already have a definition of that name before committing
                # any stuff into the database.
                existing_one = session.query(JSONPointer).\
                    filter(Cluster.id==input.cluster_id).\
                    filter(JSONPointer.name==input.name).first()

                if existing_one:
                    raise Exception('JSON Pointer [{0}] already exists on this cluster'.format(input.name))

                definition = JSONPointer(None, input.name, input.value, cluster.id)

                session.add(definition)
                session.commit()

            except Exception, e:
                msg = 'Could not create an JSON Pointer, e:[%s]'
                self.logger.error(msg, format_exc(e))
                session.rollback()

                raise
            else:
                input.action = MSG_JSON_POINTER.CREATE
                self.broker_client.publish(input)

            self.response.payload.id = definition.id
            self.response.payload.name = definition.name

class Edit(_CreateEdit):
    """ Updates an JSON Pointer.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_message_json_pointer_edit_request'
        response_elem = 'zato_message_json_pointer_edit_response'
        input_required = ('id', 'cluster_id', 'name', 'value')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input

        # Sanity check
        self.check_json_pointer(input.value)

        with closing(self.odb.session()) as session:
            try:
                existing_one = session.query(JSONPointer).\
                    filter(Cluster.id==input.cluster_id).\
                    filter(JSONPointer.name==input.name).\
                    filter(JSONPointer.id!=input.id).\
                    first()

                if existing_one:
                    raise Exception('JSON Pointer [{0}] already exists on this cluster'.format(input.name))

                definition = session.query(JSONPointer).filter_by(id=input.id).one()
                old_name = definition.name

                definition.name = input.name
                definition.value = input.value

                session.add(definition)
                session.commit()

            except Exception, e:
                msg = 'Could not update the JSON Pointer, e:[%s]'
                self.logger.error(msg, format_exc(e))
                session.rollback()

                raise
            else:
                input.action = MSG_JSON_POINTER.EDIT
                input.old_name = old_name
                self.request.input.msg_pattern_type = MSG_PATTERN_TYPE.JSON_POINTER.id
                self.broker_client.publish(input)

                self.response.payload.id = definition.id
                self.response.payload.name = definition.name

class Delete(AdminService):
    """ Deletes an JSON Pointer.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_message_json_pointer_delete_request'
        response_elem = 'zato_message_json_pointer_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                auth = session.query(JSONPointer).\
                    filter(JSONPointer.id==self.request.input.id).\
                    one()

                session.delete(auth)
                session.commit()
            except Exception, e:
                msg = 'Could not delete the JSON Pointer, e:[%s]'
                self.logger.error(msg, format_exc(e))
                session.rollback()

                raise
            else:
                self.request.input.action = MSG_JSON_POINTER.DELETE
                self.request.input.name = auth.name
                self.request.input.msg_pattern_type = MSG_PATTERN_TYPE.JSON_POINTER.id
                self.broker_client.publish(self.request.input)

########NEW FILE########
__FILENAME__ = namespace
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc
from uuid import uuid4

# Zato
from zato.common.broker_message import MSG_NS
from zato.common.odb.model import Cluster, MsgNamespace
from zato.common.odb.query import namespace_list
from zato.server.service.internal import AdminService, AdminSIO

class GetList(AdminService):
    """ Returns a list of namespaces available.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_message_namespace_get_list_request'
        response_elem = 'zato_message_namespace_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'value')

    def get_data(self, session):
        return namespace_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)

class Create(AdminService):
    """ Creates a new namespace.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_message_namespace_create_request'
        response_elem = 'zato_message_namespace_create_response'
        input_required = ('cluster_id', 'name', 'value')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input

        with closing(self.odb.session()) as session:
            try:
                cluster = session.query(Cluster).filter_by(id=input.cluster_id).first()

                # Let's see if we already have a definition of that name before committing
                # any stuff into the database.
                existing_one = session.query(MsgNamespace).\
                    filter(Cluster.id==input.cluster_id).\
                    filter(MsgNamespace.name==input.name).first()

                if existing_one:
                    raise Exception('Namespace [{0}] already exists on this cluster'.format(input.name))

                definition = MsgNamespace(None, input.name, input.value, cluster.id)

                session.add(definition)
                session.commit()

            except Exception, e:
                msg = 'Could not create a namespace, e:[%s]'
                self.logger.error(msg, format_exc(e))
                session.rollback()

                raise
            else:
                input.action = MSG_NS.CREATE
                self.broker_client.publish(input)

            self.response.payload.id = definition.id
            self.response.payload.name = definition.name

class Edit(AdminService):
    """ Updates a namespace.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_message_namespace_edit_request'
        response_elem = 'zato_message_namespace_edit_response'
        input_required = ('id', 'cluster_id', 'name', 'value')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:
            try:
                existing_one = session.query(MsgNamespace).\
                    filter(Cluster.id==input.cluster_id).\
                    filter(MsgNamespace.name==input.name).\
                    filter(MsgNamespace.id!=input.id).\
                    first()

                if existing_one:
                    raise Exception('Namespace [{0}] already exists on this cluster'.format(input.name))

                definition = session.query(MsgNamespace).filter_by(id=input.id).one()
                old_name = definition.name

                definition.name = input.name
                definition.value = input.value

                session.add(definition)
                session.commit()

            except Exception, e:
                msg = 'Could not update the namespace, e:[%s]'
                self.logger.error(msg, format_exc(e))
                session.rollback()

                raise
            else:
                input.action = MSG_NS.EDIT
                input.old_name = old_name
                self.broker_client.publish(input)

                self.response.payload.id = definition.id
                self.response.payload.name = definition.name

class Delete(AdminService):
    """ Deletes a namespace.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_message_namespace_delete_request'
        response_elem = 'zato_message_namespace_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                auth = session.query(MsgNamespace).\
                    filter(MsgNamespace.id==self.request.input.id).\
                    one()

                session.delete(auth)
                session.commit()
            except Exception, e:
                msg = 'Could not delete the namespace, e:[%s]'
                self.logger.error(msg, format_exc(e))
                session.rollback()

                raise
            else:
                self.request.input.action = MSG_NS.DELETE
                self.request.input.name = auth.name
                self.broker_client.publish(self.request.input)

########NEW FILE########
__FILENAME__ = xpath
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc
from uuid import uuid4

# Zato
from zato.common import MSG_PATTERN_TYPE
from zato.common.broker_message import MSG_XPATH
from zato.common.odb.model import Cluster, XPath
from zato.common.odb.query import xpath_list
from zato.server.service.internal import AdminService, AdminSIO

# ##############################################################################

class GetList(AdminService):
    """ Returns a list of XPaths available.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_message_xpath_get_list_request'
        response_elem = 'zato_message_xpath_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'value')

    def get_data(self, session):
        return xpath_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)

# ##############################################################################

class _CreateEdit(AdminService):
    def check_xpath(self, value):
        """ Check whether the expression can be evaluated at all,
        making sure all the namespaces needed, if any, are already defined.
        """
        self.msg._xpath_store.compile(value, self.msg._ns_store.ns_map)

class Create(_CreateEdit):
    """ Creates a new XPath.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_message_xpath_create_request'
        response_elem = 'zato_message_xpath_create_response'
        input_required = ('cluster_id', 'name', 'value')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input

        # Sanity check
        self.check_xpath(input.value)

        with closing(self.odb.session()) as session:
            try:
                cluster = session.query(Cluster).filter_by(id=input.cluster_id).first()

                # Let's see if we already have a definition of that name before committing
                # any stuff into the database.
                existing_one = session.query(XPath).\
                    filter(Cluster.id==input.cluster_id).\
                    filter(XPath.name==input.name).first()

                if existing_one:
                    raise Exception('XPath [{0}] already exists on this cluster'.format(input.name))

                definition = XPath(None, input.name, input.value, cluster.id)

                session.add(definition)
                session.commit()

            except Exception, e:
                msg = 'Could not create an XPath, e:[%s]'
                self.logger.error(msg, format_exc(e))
                session.rollback()

                raise
            else:
                input.action = MSG_XPATH.CREATE
                self.broker_client.publish(input)

            self.response.payload.id = definition.id
            self.response.payload.name = definition.name

class Edit(_CreateEdit):
    """ Updates an XPath.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_message_xpath_edit_request'
        response_elem = 'zato_message_xpath_edit_response'
        input_required = ('id', 'cluster_id', 'name', 'value')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input

        # Sanity check
        self.check_xpath(input.value)

        with closing(self.odb.session()) as session:
            try:
                existing_one = session.query(XPath).\
                    filter(Cluster.id==input.cluster_id).\
                    filter(XPath.name==input.name).\
                    filter(XPath.id!=input.id).\
                    first()

                if existing_one:
                    raise Exception('XPath [{0}] already exists on this cluster'.format(input.name))

                definition = session.query(XPath).filter_by(id=input.id).one()
                old_name = definition.name

                definition.name = input.name
                definition.value = input.value

                session.add(definition)
                session.commit()

            except Exception, e:
                msg = 'Could not update the XPath, e:[%s]'
                self.logger.error(msg, format_exc(e))
                session.rollback()

                raise
            else:
                input.action = MSG_XPATH.EDIT
                input.old_name = old_name
                self.broker_client.publish(input)

                self.response.payload.id = definition.id
                self.response.payload.name = definition.name

class Delete(AdminService):
    """ Deletes an XPath.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_message_xpath_delete_request'
        response_elem = 'zato_message_xpath_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                auth = session.query(XPath).\
                    filter(XPath.id==self.request.input.id).\
                    one()

                session.delete(auth)
                session.commit()
            except Exception, e:
                msg = 'Could not delete the XPath, e:[%s]'
                self.logger.error(msg, format_exc(e))
                session.rollback()

                raise
            else:
                self.request.input.action = MSG_XPATH.DELETE
                self.request.input.name = auth.name
                self.request.input.msg_pattern_type = MSG_PATTERN_TYPE.XPATH.id
                self.broker_client.publish(self.request.input)

########NEW FILE########
__FILENAME__ = swift
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from pprint import pprint
from traceback import format_exc

# Bunch
from bunch import Bunch, bunchify

# gevent
from gevent import sleep, spawn

# globre
from globre import match as globre_match

# Zato
from zato.common import NOTIF as COMMON_NOTIF, ZATO_NONE
from zato.common.broker_message import MESSAGE_TYPE, NOTIF
from zato.common.odb.model import NotificationOpenStackSwift, Service
from zato.common.odb.query import notif_cloud_openstack_swift_list
from zato.server.service import Bool, ForceType, Int
from zato.server.service.internal import AdminService, AdminSIO

# ################################################################################################################################

common_required = ('name', 'is_active', 'def_id', 'containers', Int('interval'), 'name_pattern', Bool('name_pattern_neg'),
    Bool('get_data'), Bool('get_data_patt_neg'), 'service_name')

common_optional = ('get_data_patt',)

# ################################################################################################################################

class GetList(AdminService):
    """ Returns a list of OpenStack Swift notification definitions.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_notif_cloud_openstack_swift_get_list_request'
        response_elem = 'zato_notif_cloud_openstack_swift_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'def_name') + common_required
        output_optional = common_optional

    def get_data(self, session):
        return notif_cloud_openstack_swift_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)

# ################################################################################################################################

class _CreateEdit(AdminService):
    source_service_type = ZATO_NONE

    def _get_item(self, session, input):
        raise NotImplementedError()

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:

            existing_one = session.query(NotificationOpenStackSwift.id).\
                filter(NotificationOpenStackSwift.cluster_id==input.cluster_id).\
                filter(NotificationOpenStackSwift.name==input.name).\
                first()

            if self.source_service_type == 'create' and existing_one:
                raise Exception('An OpenStack Swift notification definition [{0}] already exists on this cluster'.format(input.name))

            try:
                old_name = None
                item = self._get_item(session, input)

                if self.source_service_type == 'edit':
                    old_name = item.name

                for name in self.SimpleIO.input_required + self.SimpleIO.input_optional:
                    if isinstance(name, ForceType):
                        name = name.name
                    setattr(item, name, self.request.input.get(name))

                item.service_id = session.query(Service.id).\
                    filter(Service.name==input.service_name).\
                    filter(Service.cluster_id==self.server.cluster_id).\
                    one()

                session.add(item)
                session.commit()

                input.action = NOTIF.CLOUD_OPENSTACK_SWIFT_CREATE_EDIT
                input.notif_type = COMMON_NOTIF.TYPE.OPENSTACK_SWIFT
                input.source_service_type = self.source_service_type
                input.def_name = item.definition.name

                if self.source_service_type == 'edit':
                    input.old_name = old_name

                self.broker_client.publish(input)

                self.response.payload.id = item.id
                self.response.payload.name = item.name
                self.response.payload.def_name = item.definition.name

            except Exception, e:
                msg = 'Could not %s an OpenStack Swift notification definition, e:`%s`'
                self.logger.error(msg, self.source_service_type, format_exc(e))
                session.rollback()

                raise 

# ################################################################################################################################

class Create(_CreateEdit):
    """ Creates a new OpenStack Swift notification definition.
    """
    source_service_type = 'create'

    class SimpleIO(AdminSIO):
        request_elem = 'zato_notif_cloud_openstack_swift_create_request'
        response_elem = 'zato_notif_cloud_openstack_swift_create_response'
        input_required = ('cluster_id',) + common_required
        input_optional = common_optional
        output_required = ('id', 'name', 'def_name')

    def _get_item(self, *ignored):
        return NotificationOpenStackSwift()

# ################################################################################################################################

class Edit(_CreateEdit):
    """ Updates an OpenStack Swift notification definition.
    """
    source_service_type = 'edit'

    class SimpleIO(Create.SimpleIO):
        request_elem = 'zato_notif_cloud_openstack_swift_edit_request'
        response_elem = 'zato_notif_cloud_openstack_swift_edit_response'
        input_required = ('id',) + Create.SimpleIO.input_required

    def _get_item(self, session, input):
        return session.query(NotificationOpenStackSwift).filter_by(id=input.id).one()

# ################################################################################################################################

class Delete(AdminService):
    """ Deletes an OpenStack Swift notification definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_notif_cloud_openstack_swift_delete_request'
        response_elem = 'zato_notif_cloud_openstack_swift_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                item = session.query(NotificationOpenStackSwift).\
                    filter(NotificationOpenStackSwift.id==self.request.input.id).\
                    one()

                session.delete(item)
                session.commit()

                msg = {'action': NOTIF.CLOUD_OPENSTACK_SWIFT_DELETE, 'name': item.name, 'id':item.id}
                self.broker_client.publish(msg)
                
            except Exception, e:
                session.rollback()
                msg = 'Could not delete the OpenStack Swift notification definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)

                raise

# ################################################################################################################################

class RunNotifier(AdminService):
    """ Runs a background gevent-based notifier of new data in OpenStack Swift containers.
    """

    def _name_matches(self, pattern, string, negate):
        """ Matches a string against a pattern and returns True if it found it. 'negate' reverses the result,
        only those not matching the pattern will yield True.
        """
        result = bool(globre_match(pattern, string))
        return not result if negate else result

    def _get_data(self, client, config, container, name):
        try:
            return client.get_object(container, name)[1]
        except Exception, e:
            self.logger.warn('Could not get `%s` from `%s`, e:`%s`', container, name, format_exc(e))

    def _prepare_service_request(self, ext_result, item, container, path, full_name):

        req = Bunch(req_meta=Bunch(), item=Bunch(payload=None))
        req.req_meta.container = container
        req.req_meta.path = path
        req.req_meta.full_name = full_name
        req.result_meta = ext_result[0]
        req.item_meta = bunchify(item)

        return req

    def _run_notifier(self, config):
        """ Invoked as a greenlet - fetches data from a container(s) and invokes the target service.
        """
        # It's possible our config has changed since the last time we run so we need to check the current one.
        current_config = self.server.worker_store.worker_config.notif_cloud_openstack_swift.get(config.name)

        # The notification definition has been deleted in between the invocations of ours so we need to stop now.
        if not current_config:
            self.keep_running = False
            return

        if not current_config.config['is_active']:
            return

        # Ok, overwrite old config with current one.
        config.update(current_config.config)

        # Grab a distributed lock so we are sure it is only us who connect to pull newest data.
        with self.lock(config.name):
            conn = self.cloud.openstack.swift[config.def_name].conn
            with conn.client() as client:
                for container, path, full_name in config.containers:

                    # Results of the call to an external resource - first element is result's metadata
                    # and elements 1: are the actual data, if any.
                    ext_result = client.get_container(container, path=path)

                    # Iterate over elements skipping directories - we're interested only in files.
                    for items in ext_result[1:]:
                        for item in items:
                            if item['content_type'] != 'application/directory':

                                if not self._name_matches(config.name_pattern, item['name'], config.name_pattern_neg):
                                    continue

                                # Prepare a service request ..
                                req = self._prepare_service_request(ext_result, item, container, path, full_name)

                                # .. but don't necessarily pull data from the container.
                                if config.get_data and self._name_matches(config.get_data_patt, item['name'], config.get_data_patt_neg):
                                    req.item.payload = self._get_data(client, config, container, item['name'])

                                self.logger.warn(item)
                                self.logger.warn(config)

                                # Invoke the target service and see what next to do with its response
                                srv_result = self.invoke(config.service_name, req)

                                # Ok, we are to delete the just pulled document. Note that 'srv_result' can be either
                                # an empty string or dict hence two conditions.
                                if 'delete' in srv_result and srv_result.get('delete'):
                                    client.delete_object(container, req.item_meta.name)

    def handle(self):
        self.keep_running = True
        config = bunchify(self.request.payload)

        while self.keep_running:
            spawn(self._run_notifier, config)
            sleep(config.interval)

        self.logger.info('Stopped OpenStack Swift notifier `%s`', config.name)

########NEW FILE########
__FILENAME__ = amqp
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc

# Zato
from zato.common.broker_message import MESSAGE_TYPE, OUTGOING
from zato.common.odb.model import ConnDefAMQP, OutgoingAMQP
from zato.common.odb.query import out_amqp_list
from zato.server.connection.amqp.outgoing import start_connector
from zato.server.service import AsIs, Integer
from zato.server.service.internal import AdminService, AdminSIO

class _AMQPService(AdminService):
    def delete_outgoing(self, outgoing):
        msg = {'action': OUTGOING.AMQP_DELETE, 'name': outgoing.name, 'id':outgoing.id}
        self.broker_client.publish(msg, MESSAGE_TYPE.TO_AMQP_PUBLISHING_CONNECTOR_ALL)

class GetList(AdminService):
    """ Returns a list of outgoing AMQP connections.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_outgoing_amqp_get_list_request'
        response_elem = 'zato_outgoing_amqp_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'def_id', 'delivery_mode', 'priority', 'def_name')
        output_optional = ('content_type', 'content_encoding', 'expiration', AsIs('user_id'), AsIs('app_id'))
        
    def get_data(self, session):
        return out_amqp_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)
        
class Create(AdminService):
    """ Creates a new outgoing AMQP connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_outgoing_amqp_create_request'
        response_elem = 'zato_outgoing_amqp_create_response'
        input_required = ('cluster_id', 'name', 'is_active', 'def_id', 'delivery_mode', 'priority')
        input_optional = ('content_type', 'content_encoding', 'expiration', AsIs('user_id'), AsIs('app_id'))
        output_required = ('id', 'name')
    
    def handle(self):
        input = self.request.input

        input.delivery_mode = int(input.delivery_mode)
        input.priority = int(input.priority)

        if not(input.priority >= 0 and input.priority <= 9):
            msg = 'Priority should be between 0 and 9, not [{0}]'.format(repr(input.priority))
            raise ValueError(msg)
        
        with closing(self.odb.session()) as session:
            # Let's see if we already have a definition of that name before committing
            # any stuff into the database.
            existing_one = session.query(OutgoingAMQP.id).\
                filter(ConnDefAMQP.cluster_id==input.cluster_id).\
                filter(OutgoingAMQP.def_id==ConnDefAMQP.id).\
                filter(OutgoingAMQP.name==input.name).\
                first()
            
            if existing_one:
                raise Exception('An outgoing AMQP connection [{0}] already exists on this cluster'.format(input.name))
            
            try:
                item = OutgoingAMQP()
                item.name = input.name
                item.is_active = input.is_active
                item.def_id = input.def_id
                item.delivery_mode = input.delivery_mode
                item.priority = input.priority
                item.content_type = input.content_type
                item.content_encoding = input.content_encoding 
                item.expiration = input.expiration
                item.user_id = input.user_id
                item.app_id = input.app_id
                
                session.add(item)
                session.commit()
                
                if item.is_active:
                    start_connector(self.server.repo_location, item.id, item.def_id)
                
                self.response.payload.id = item.id
                self.response.payload.name = item.name
                
            except Exception, e:
                msg = "Could not create an outgoing AMQP connection, e:[{e}]".format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise 

class Edit(_AMQPService):
    """ Updates an outgoing AMQP connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_outgoing_amqp_edit_request'
        response_elem = 'zato_outgoing_amqp_edit_response'
        input_required = ('id', 'cluster_id', 'name', 'is_active', 'def_id', 'delivery_mode', Integer('priority'))
        input_optional = ('content_type', 'content_encoding', 'expiration', AsIs('user_id'), AsIs('app_id'))
        output_required = ('id', 'name')
    
    def handle(self):
        
        input = self.request.input

        input.delivery_mode = int(input.delivery_mode)
        input.priority = int(input.priority)

        if not(input.priority >= 0 and input.priority <= 9):
            msg = 'Priority should be between 0 and 9, not [{0}]'.format(repr(input.priority))
            raise ValueError(msg)
        
        with closing(self.odb.session()) as session:
            # Let's see if we already have a definition of that name before committing
            # any stuff into the database.
            existing_one = session.query(OutgoingAMQP.id).\
                filter(ConnDefAMQP.cluster_id==input.cluster_id).\
                filter(OutgoingAMQP.def_id==ConnDefAMQP.id).\
                filter(OutgoingAMQP.name==input.name).\
                filter(OutgoingAMQP.id!=input.id).\
                first()
            
            if existing_one:
                raise Exception('An outgoing AMQP connection [{0}] already exists on this cluster'.format(input.name))
            
            try:
                item = session.query(OutgoingAMQP).filter_by(id=input.id).one()
                item.name = input.name
                item.is_active = input.is_active
                item.def_id = input.def_id
                item.delivery_mode = input.delivery_mode
                item.priority = input.priority
                item.content_type = input.content_type
                item.content_encoding = input.content_encoding
                item.expiration = input.expiration
                item.user_id = input.user_id
                item.app_id = input.app_id
                
                session.add(item)
                session.commit()
                
                self.delete_outgoing(item)
                
                if item.is_active:
                    start_connector(self.server.repo_location, item.id, item.def_id)
                
                self.response.payload.id = item.id
                self.response.payload.name = item.name
                
            except Exception, e:
                msg = 'Could not update the AMQP definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise  
        
class Delete(_AMQPService):
    """ Deletes an outgoing AMQP connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_outgoing_amqp_delete_request'
        response_elem = 'zato_outgoing_amqp_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                channel = session.query(OutgoingAMQP).\
                    filter(OutgoingAMQP.id==self.request.input.id).\
                    one()
                
                session.delete(channel)
                session.commit()
                
                self.delete_outgoing(channel)

            except Exception, e:
                session.rollback()
                msg = 'Could not delete the outgoing AMQP connection, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                
                raise

########NEW FILE########
__FILENAME__ = ftp
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc

# Zato
from zato.common.broker_message import OUTGOING
from zato.common.odb.model import OutgoingFTP
from zato.common.odb.query import out_ftp_list
from zato.server.service import Boolean
from zato.server.service.internal import AdminService, AdminSIO, ChangePasswordBase

class _FTPService(AdminService):
    """ A common class for various FTP-related services.
    """
    def notify_worker_threads(self, params, action=OUTGOING.FTP_CREATE_EDIT):
        """ Notify worker threads of new or updated parameters.
        """
        params['action'] = action
        self.broker_client.publish(params)

class GetList(AdminService):
    """ Returns a list of outgoing FTP connections.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_outgoing_ftp_get_list_request'
        response_elem = 'zato_outgoing_ftp_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'host', 'port')
        output_optional = ('user', 'acct', 'timeout', Boolean('dircache'))
        
    def get_data(self, session):
        return out_ftp_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)

class Create(_FTPService):
    """ Creates a new outgoing FTP connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_outgoing_ftp_create_request'
        response_elem = 'zato_outgoing_ftp_create_response'
        input_required = ('cluster_id', 'name', 'is_active', 'host', 'port', Boolean('dircache'))
        input_optional = ('user', 'acct', 'timeout')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        
        with closing(self.odb.session()) as session:
            existing_one = session.query(OutgoingFTP.id).\
                filter(OutgoingFTP.cluster_id==input.cluster_id).\
                filter(OutgoingFTP.name==input.name).\
                first()

            if existing_one:
                raise Exception('An outgoing FTP connection [{0}] already exists on this cluster'.format(input.name))

            try:
                item = OutgoingFTP()
                item.name = input.name
                item.is_active = input.is_active
                item.cluster_id = input.cluster_id
                item.dircache = input.dircache
                item.host = input.host
                item.port = input.port
                item.user = input.user
                item.acct = input.acct
                item.timeout = input.timeout or None

                session.add(item)
                session.commit()

                self.notify_worker_threads(input)

                self.response.payload.id = item.id
                self.response.payload.name = item.name

            except Exception, e:
                msg = 'Could not create an outgoing FTP connection, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise

class Edit(_FTPService):
    """ Updates an outgoing FTP connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_outgoing_ftp_edit_request'
        response_elem = 'zato_outgoing_ftp_edit_response'
        input_required = ('id', 'cluster_id', 'name', 'is_active', 'host', 'port', Boolean('dircache'))
        input_optional = ('user', 'acct', 'timeout')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:
            existing_one = session.query(OutgoingFTP.id).\
                filter(OutgoingFTP.cluster_id==input.cluster_id).\
                filter(OutgoingFTP.name==input.name).\
                filter(OutgoingFTP.id!=input.id).\
                first()

            if existing_one:
                raise Exception('An outgoing FTP connection [{0}] already exists on this cluster'.format(input.name))

            try:
                item = session.query(OutgoingFTP).filter_by(id=input.id).one()
                old_name = item.name
                item.name = input.name
                item.is_active = input.is_active
                item.cluster_id = input.cluster_id
                item.dircache = input.dircache
                item.host = input.host
                item.port = input.port
                item.user = input.user
                item.acct = input.acct
                item.timeout = input.timeout or None
                
                input.old_name = old_name

                session.add(item)
                session.commit()

                self.notify_worker_threads(input)

                self.response.payload.id = item.id
                self.response.payload.name = item.name

            except Exception, e:
                msg = 'Could not update the outgoing FTP connection, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise

class Delete(_FTPService):
    """ Deletes an outgoing FTP connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_outgoing_ftp_delete_request'
        response_elem = 'zato_outgoing_ftp_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                item = session.query(OutgoingFTP).\
                    filter(OutgoingFTP.id==self.request.input.id).\
                    one()
                old_name = item.name

                session.delete(item)
                session.commit()
                
                self.notify_worker_threads({'name':old_name}, OUTGOING.FTP_DELETE)

            except Exception, e:
                session.rollback()
                msg = 'Could not delete the outgoing FTP connection, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)

                raise

class ChangePassword(ChangePasswordBase):
    """ Changes the password of an outgoing FTP connection.
    """
    class SimpleIO(ChangePasswordBase.SimpleIO):
        request_elem = 'zato_outgoing_ftp_change_password_request'
        response_elem = 'zato_outgoing_ftp_change_password_response'
    
    def handle(self):
        def _auth(instance, password):
            instance.password = password
            
        self._handle(OutgoingFTP, _auth, OUTGOING.FTP_CHANGE_PASSWORD)

########NEW FILE########
__FILENAME__ = jms_wmq
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc

# Zato
from zato.common.broker_message import MESSAGE_TYPE, OUTGOING
from zato.common.odb.model import ConnDefWMQ, OutgoingWMQ
from zato.common.odb.query import out_jms_wmq_list
from zato.server.connection.jms_wmq.outgoing import start_connector
from zato.server.service import Integer
from zato.server.service.internal import AdminService, AdminSIO

class GetList(AdminService):
    """ Returns a list of outgoing JMS WebSphere MQ connections.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_outgoing_jms_wmq_get_list_request'
        response_elem = 'zato_outgoing_jms_wmq_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'def_id', Integer('delivery_mode'), Integer('priority'), 'def_name')
        output_optional = ('expiration',)
        
    def get_data(self, session):
        return out_jms_wmq_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)
        
class Create(AdminService):
    """ Creates a new outgoing JMS WebSphere MQ connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_outgoing_jms_wmq_create_request'
        response_elem = 'zato_outgoing_jms_wmq_create_response'
        input_required = ('cluster_id', 'name', 'is_active', 'def_id', Integer('delivery_mode'), Integer('priority'))
        input_optional = ('expiration',)
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:
            if not(input.priority >= 0 and input.priority <= 9):
                msg = 'Priority should be between 0 and 9, not [{0}]'.format(repr(input.priority))
                raise ValueError(msg)
            
            existing_one = session.query(OutgoingWMQ.id).\
                filter(ConnDefWMQ.cluster_id==input.cluster_id).\
                filter(OutgoingWMQ.def_id==ConnDefWMQ.id).\
                filter(OutgoingWMQ.name==input.name).\
                first()
            
            if existing_one:
                raise Exception('An outgoing JMS WebSphere MQ connection [{0}] already exists on this cluster'.format(input.name))
            
            try:
                item = OutgoingWMQ()
                item.name = input.name
                item.is_active = input.is_active
                item.def_id = input.def_id
                item.delivery_mode = input.delivery_mode
                item.priority = input.priority
                item.expiration = input.expiration
                
                session.add(item)
                session.commit()
                
                if item.is_active:
                    start_connector(self.server.repo_location, item.id, item.def_id)
                
                self.response.payload.id = item.id
                self.response.payload.name = item.name
                
            except Exception, e:
                msg = 'Could not create an outgoing JMS WebSphere MQ connection, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise 

class Edit(AdminService):
    """ Updates an outgoing JMS WebSphere MQ connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_outgoing_jms_wmq_edit_request'
        response_elem = 'zato_outgoing_jms_wmq_edit_response'
        input_required = ('id', 'cluster_id', 'name', 'is_active', 'def_id', Integer('delivery_mode'), Integer('priority'))
        input_optional = ('expiration',)
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:
            if not(input.priority >= 0 and input.priority <= 9):
                msg = 'Priority should be between 0 and 9, not [{0}]'.format(repr(input.priority))
                raise ValueError(msg)
            
            existing_one = session.query(OutgoingWMQ.id).\
                filter(ConnDefWMQ.cluster_id==input.cluster_id).\
                filter(OutgoingWMQ.def_id==ConnDefWMQ.id).\
                filter(OutgoingWMQ.name==input.name).\
                filter(OutgoingWMQ.id!=input.id).\
                first()
            
            if existing_one:
                raise Exception('An outgoing JMS WebSphere MQ connection [{0}] already exists on this cluster'.format(input.name))
            
            try:
                item = session.query(OutgoingWMQ).filter_by(id=input.id).one()
                old_name = item.name
                item.name = input.name
                item.is_active = input.is_active
                item.def_id = input.def_id
                item.delivery_mode = input.delivery_mode
                item.priority = input.priority
                item.expiration = input.expiration
                
                session.add(item)
                session.commit()
                
                input.action = OUTGOING.JMS_WMQ_EDIT
                input.old_name = old_name
                self.broker_client.publish(input, msg_type=MESSAGE_TYPE.TO_JMS_WMQ_CONNECTOR_ALL)
                
                self.response.payload.id = item.id
                self.response.payload.name = item.name
                
            except Exception, e:
                msg = 'Could not update the JMS WebSphere MQ definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise  
        
class Delete(AdminService):
    """ Deletes an outgoing JMS WebSphere MQ connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_outgoing_jms_wmq_delete_request'
        response_elem = 'zato_outgoing_jms_wmq_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                item = session.query(OutgoingWMQ).\
                    filter(OutgoingWMQ.id==self.request.input.id).\
                    one()
                
                session.delete(item)
                session.commit()

                msg = {'action': OUTGOING.JMS_WMQ_DELETE, 'name': item.name,
                       'old_name': item.name, 'id':item.id}
                self.broker_client.publish(msg, MESSAGE_TYPE.TO_JMS_WMQ_CONNECTOR_ALL)
                
            except Exception, e:
                session.rollback()
                msg = 'Could not delete the outgoing JMS WebSphere MQ connection, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                
                raise

########NEW FILE########
__FILENAME__ = sql
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc
from uuid import uuid4

# Zato
from zato.common import ZatoException
from zato.common.broker_message import OUTGOING
from zato.common.odb.model import SQLConnectionPool
from zato.common.odb.query import out_sql_list
from zato.server.service import Integer
from zato.server.service.internal import AdminService, AdminSIO, ChangePasswordBase

class _SQLService(object):
    """ A common class for various SQL-related services.
    """
    def notify_worker_threads(self, params, action=OUTGOING.SQL_CREATE_EDIT):
        """ Notify worker threads of new or updated parameters.
        """
        params['action'] = action
        self.broker_client.publish(params)
        
    def validate_extra(self, cid, extra):
        if extra and not b'=' in extra:
            raise ZatoException(cid, 'extra should be a list of key=value parameters, possibly one-element long, instead of [{}]'.format(extra.decode('utf-8')))

class GetList(AdminService):
    """ Returns a list of outgoing SQL connections.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_outgoing_sql_get_list_request'
        response_elem = 'zato_outgoing_sql_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'cluster_id', 'engine', 'host', Integer('port'), 'db_name', 'username', Integer('pool_size'))
        output_optional = ('extra',)
        
    def get_data(self, session):
        return out_sql_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)

class Create(AdminService, _SQLService):
    """ Creates a new outgoing SQL connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_outgoing_sql_create_request'
        response_elem = 'zato_outgoing_sql_create_response'
        input_required = ('name', 'is_active', 'cluster_id', 'engine', 'host', Integer('port'), 'db_name', 'username', Integer('pool_size'))
        input_optional = ('extra',)
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        input.password = uuid4().hex
        input.extra = input.extra.encode('utf-8') if input.extra else b''
        
        self.validate_extra(self.cid, input.extra.decode('utf-8'))
        
        with closing(self.odb.session()) as session:
            existing_one = session.query(SQLConnectionPool.id).\
                filter(SQLConnectionPool.cluster_id==input.cluster_id).\
                filter(SQLConnectionPool.name==input.name).\
                first()

            if existing_one:
                raise Exception('An outgoing SQL connection [{0}] already exists on this cluster'.format(input.name))

            try:
                item = SQLConnectionPool()
                item.name = input.name
                item.is_active = input.is_active
                item.cluster_id = input.cluster_id
                item.engine = input.engine
                item.host = input.host
                item.port = input.port
                item.db_name = input.db_name
                item.username = input.username
                item.password = input.password
                item.pool_size = input.pool_size
                item.extra = input.extra

                session.add(item)
                session.commit()
                
                self.notify_worker_threads(input)
                
                self.response.payload.id = item.id
                self.response.payload.name = item.name

            except Exception, e:
                msg = 'Could not create an outgoing SQL connection, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise
            
class Edit(AdminService, _SQLService):
    """ Updates an outgoing SQL connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_outgoing_sql_edit_request'
        response_elem = 'zato_outgoing_sql_edit_response'
        input_required = ('id', 'name', 'is_active', 'cluster_id', 'engine', 'host', Integer('port'), 'db_name', 'username', Integer('pool_size'))
        input_optional = ('extra',)
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        input.extra = input.extra.encode('utf-8') if input.extra else ''
        
        self.validate_extra(self.cid, input.extra)
        
        with closing(self.odb.session()) as session:
            existing_one = session.query(SQLConnectionPool.id).\
                filter(SQLConnectionPool.cluster_id==input.cluster_id).\
                filter(SQLConnectionPool.name==input.name).\
                filter(SQLConnectionPool.id!=input.id).\
                first()

            if existing_one:
                raise Exception('An outgoing SQL connection [{0}] already exists on this cluster'.format(input.name))

            try:
                item = session.query(SQLConnectionPool).filter_by(id=input.id).one()
                old_name = item.name
                item.name = input.name
                item.is_active = input.is_active
                item.cluster_id = input.cluster_id
                item.engine = input.engine
                item.host = input.host
                item.port = input.port
                item.db_name = input.db_name
                item.username = input.username
                item.pool_size = input.pool_size
                item.extra = input.extra

                session.add(item)
                session.commit()

                input.password = item.password
                input.old_name = old_name
                self.notify_worker_threads(input)

                self.response.payload.id = item.id
                self.response.payload.name = item.name

            except Exception, e:
                msg = 'Could not update the outgoing SQL connection, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise
            
class Delete(AdminService, _SQLService):
    """ Deletes an outgoing SQL connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_outgoing_sql_delete_request'
        response_elem = 'zato_outgoing_sql_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                item = session.query(SQLConnectionPool).\
                    filter(SQLConnectionPool.id==self.request.input.id).\
                    one()
                old_name = item.name

                session.delete(item)
                session.commit()
                
                self.notify_worker_threads({'name':old_name}, OUTGOING.SQL_DELETE)

            except Exception, e:
                session.rollback()
                msg = 'Could not delete the outgoing SQL connection, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)

                raise

class ChangePassword(ChangePasswordBase):
    """ Changes the password of an outgoing SQL connection. The underlying implementation
    will actually stop and recreate the connection using the new password.
    """
    class SimpleIO(ChangePasswordBase.SimpleIO):
        request_elem = 'zato_outgoing_sql_change_password_request'
        response_elem = 'zato_outgoing_sql_change_password_response'
    
    def handle(self):
        def _auth(instance, password):
            instance.password = password

        self._handle(SQLConnectionPool, _auth, OUTGOING.SQL_CHANGE_PASSWORD)
            
class Ping(AdminService):
    """ Pings an SQL database
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_outgoing_sql_ping_request'
        response_elem = 'zato_outgoing_sql_ping_response'
        input_required = ('id',)
        output_required = ('response_time',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                item = session.query(SQLConnectionPool).\
                    filter(SQLConnectionPool.id==self.request.input.id).\
                    one()

                self.response.payload.response_time = str(self.outgoing.sql.get(item.name, False).pool.ping())

            except Exception, e:
                session.rollback()
                msg = 'Could not ping the outgoing SQL connection, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)

                raise

########NEW FILE########
__FILENAME__ = zmq
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc

# Zato
from zato.common.broker_message import MESSAGE_TYPE, OUTGOING
from zato.common.odb.model import OutgoingZMQ
from zato.common.odb.query import out_zmq_list
from zato.server.connection.zmq_.outgoing import start_connector
from zato.server.service.internal import AdminService, AdminSIO

class GetList(AdminService):
    """ Returns a list of outgoing ZeroMQ connections.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_outgoing_zmq_get_list_request'
        response_elem = 'zato_outgoing_zmq_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'address', 'socket_type')
        
    def get_data(self, session):
        return out_zmq_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)
        
class Create(AdminService):
    """ Creates a new outgoing ZeroMQ connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_outgoing_zmq_create_request'
        response_elem = 'zato_outgoing_zmq_create_response'
        input_required = ('cluster_id', 'name', 'is_active', 'address', 'socket_type')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:
            existing_one = session.query(OutgoingZMQ.id).\
                filter(OutgoingZMQ.cluster_id==input.cluster_id).\
                filter(OutgoingZMQ.name==input.name).\
                first()
            
            if existing_one:
                raise Exception('An outgoing ZeroMQ connection [{0}] already exists on this cluster'.format(input.name))
            
            try:
                item = OutgoingZMQ()
                item.name = input.name
                item.is_active = input.is_active
                item.address = input.address
                item.socket_type = input.socket_type
                item.cluster_id = input.cluster_id
                
                session.add(item)
                session.commit()
                
                if item.is_active:
                    start_connector(self.server.repo_location, item.id)
                
                self.response.payload.id = item.id
                self.response.payload.name = item.name
                
            except Exception, e:
                msg = 'Could not create an outgoing ZeroMQ connection, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise 

class Edit(AdminService):
    """ Updates an outgoing ZeroMQ connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_outgoing_zmq_edit_request'
        response_elem = 'zato_outgoing_zmq_edit_response'
        input_required = ('id', 'cluster_id', 'name', 'is_active', 'address', 'socket_type')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:
            existing_one = session.query(OutgoingZMQ.id).\
                filter(OutgoingZMQ.cluster_id==input.cluster_id).\
                filter(OutgoingZMQ.name==input.name).\
                filter(OutgoingZMQ.id!=input.id).\
                first()
            
            if existing_one:
                raise Exception('An outgoing ZeroMQ connection [{0}] already exists on this cluster'.format(input.name))
            
            try:
                item = session.query(OutgoingZMQ).filter_by(id=input.id).one()
                old_name = item.name
                item.name = input.name
                item.is_active = input.is_active
                item.address = input.address
                item.socket_type = input.socket_type
                
                session.add(item)
                session.commit()
                
                input.action = OUTGOING.ZMQ_EDIT
                input.old_name = old_name
                self.broker_client.publish(input, msg_type=MESSAGE_TYPE.TO_ZMQ_PUBLISHING_CONNECTOR_ALL)
                
                self.response.payload.id = item.id
                self.response.payload.name = item.name
                
            except Exception, e:
                msg = 'Could not update the outgoing ZeroMQ connection, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise  
        
class Delete(AdminService):
    """ Deletes an outgoing ZeroMQ connection.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_outgoing_zmq_delete_request'
        response_elem = 'zato_outgoing_zmq_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                item = session.query(OutgoingZMQ).\
                    filter(OutgoingZMQ.id==self.request.input.id).\
                    one()
                
                session.delete(item)
                session.commit()

                msg = {'action': OUTGOING.ZMQ_DELETE, 'name': item.name, 'id':item.id}
                self.broker_client.publish(msg, MESSAGE_TYPE.TO_ZMQ_PUBLISHING_CONNECTOR_ALL)
                
            except Exception, e:
                session.rollback()
                msg = 'Could not delete the outgoing ZeroMQ connection, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                
                raise

########NEW FILE########
__FILENAME__ = definition
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing

# anyjson
from traceback import format_exc

# datetutil
from dateutil.parser import parse

# Zato
from zato.common import BATCH_DEFAULTS, DELIVERY_STATE, INVOCATION_TARGET, KVDB, ZatoException
from zato.common.odb.model import DeliveryDefinitionBase, DeliveryDefinitionOutconnWMQ, OutgoingWMQ, to_json
from zato.common.odb.query import delivery_definition_list, out_jms_wmq, out_jms_wmq_by_name
from zato.common.util import datetime_to_seconds, validate_input_dict
from zato.server.service import AsIs, Boolean, CSV, Integer, UTC
from zato.server.service.internal import AdminService, AdminSIO
from zato.server.service.internal.pattern.delivery import target_def_class

_target_query_by_id = {
    INVOCATION_TARGET.OUTCONN_WMQ: out_jms_wmq
}

_target_query_by_name = {
    INVOCATION_TARGET.OUTCONN_WMQ: out_jms_wmq_by_name
}

# ##############################################################################

class _DeliveryService(AdminService):
    """ Base class with code common to multiple guaranteed delivery-related services.
    """
    _is_edit = None
            
    def _validate_times(self):
        """ Checks whether times specified constitute at least one second.
        """
        for name in ('expire_after', 'expire_arch_succ_after', 'expire_arch_fail_after', 'check_after',
                'retry_repeats', 'retry_seconds'):
            value = int(self.request.input[name])
            if value < 1:
                msg = '[{}] should be at least 1 instead of [{}]'.format(name, self.request.input[name])
                self.logger.warn(msg)
                raise ValueError(msg)
            
    def _batch_size_from_input(self):
        """ Returns a batch size taking into account handling of invalid input values.
        """
        try:
            batch_size = self.request.input.get('batch_size')
            batch_size = int(batch_size) or BATCH_DEFAULTS.SIZE
        except(TypeError, ValueError), e:
            self.logger.debug('Invalid batch_size in:[%s], e:[%s]', batch_size, format_exc(e))
            batch_size = BATCH_DEFAULTS.SIZE
            
        return batch_size
    
    def _check_def_name(self, session, input):
        """ Let's see if we already have a definition of that name before committing
        any stuff into the database.
        """
        existing_one = session.query(DeliveryDefinitionBase.id).\
            filter(DeliveryDefinitionBase.cluster_id==input.cluster_id).\
            filter(DeliveryDefinitionBase.name==input.name).\
            first()
            
        if existing_one:
            raise Exception('Definition [{}] already exists on this cluster'.format(input.name))
        
# ##############################################################################
    
class GetList(_DeliveryService):
    """ Returns a list of delivery definitions for a given target type on a cluster.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_pattern_delivery_definition_get_list_request'
        response_elem = 'zato_pattern_delivery_definition_get_list_response'
        input_required = ('cluster_id', 'target_type')
        output_required = ('id', 'name', 'target', 'target_type', 
            'expire_after', 'expire_arch_succ_after', 'expire_arch_fail_after', 'check_after', 
            'retry_repeats', 'retry_seconds', 'short_def', 'total_count', 
            'in_progress_count', 'in_doubt_count', 'confirmed_count', 'failed_count')
        output_optional = (UTC('last_updated_utc'), UTC('last_used_utc'), 'callback_list')

    def get_data(self, session, cluster_id, target_type):
        for item in delivery_definition_list(session, cluster_id, target_type):
            
            target_query = _target_query_by_id[target_type]
            target = target_query(session, cluster_id, item.target_id)
           
            out = {
                'target': target.name,
                'target_type': target_type
            }
            
            for name in ('id', 'name', 'expire_after', 'expire_arch_succ_after', 
                  'expire_arch_fail_after', 'check_after', 'retry_repeats', 'retry_seconds', 'short_def',
                  'callback_list', 'last_used_utc'):
                out[name] = getattr(item, name, None)
                
            last_used = getattr(item, 'last_used', None)
            if last_used:
                out['last_used_utc'] = last_used.isoformat()
            
            basic_data = self.delivery_store.get_target_basic_data(item.name)
            for name in ('last_updated_utc', 'total_count', 'in_progress_count', 
                             'in_doubt_count', 'confirmed_count', 'failed_count'):
                out[name] = basic_data.get(name)
            
            yield out

    def handle(self):
        target_type = self.request.input.target_type
        validate_input_dict(('target_type', target_type, INVOCATION_TARGET))
        
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session, self.request.input.cluster_id, target_type)

# ##############################################################################

class _CreateEdit(_DeliveryService):
    """ A common class for both Create and Edit actions.
    """
    _error_msg = None
    
    class SimpleIO(AdminSIO):
        input_required = ('cluster_id', 'target', 'target_type', 'expire_after', 
            'expire_arch_succ_after', 'expire_arch_fail_after', 'check_after', 
            'retry_repeats', 'retry_seconds',)
        input_optional = ('callback_list',)
        output_required = ('id', 'name')
        
    def _get_item(self, session, target_def_class, input):
        raise NotImplementedError('Should be defined by subclasses')
        
    def handle(self):
        with closing(self.odb.session()) as session:
            
            target_type = self.request.input.target_type
            validate_input_dict(('target_type', target_type, INVOCATION_TARGET))
            self._validate_times()
        
            input = self.request.input
            
            if not self._is_edit:
                self._check_def_name(session, input)
            
            target_query = _target_query_by_name[target_type]
            target = target_query(session, input.cluster_id, input.target)
            if not target:
                raise Exception('Target [{}] ({}) does not exist on this cluster'.format(
                    input.target, input.target_type))
                
            try:
                item = self._get_item(session, target_def_class[target_type], input)
                        
                item.target_id = target.id
                item.short_def = '{}-{}-{}'.format(input.check_after, input.retry_repeats, input.retry_seconds)
            
                if not self._is_edit:
                    item.name = input.name
                    
                item.target_type = input.target_type
                item.expire_after = input.expire_after
                item.expire_arch_succ_after = input.expire_arch_succ_after
                item.expire_arch_fail_after = input.expire_arch_fail_after
                item.check_after = input.check_after
                item.retry_repeats = input.retry_repeats
                item.retry_seconds = input.retry_seconds
                item.cluster_id = input.cluster_id
                item.callback_list = input.callback_list.encode('utf-8')
                
                session.add(item)
                session.commit()
                
                self.delivery_store.set_deleted(item.name, False)

                if self._is_edit:
                    self.delivery_store.set_deleted(item.name, True)
                
                self.response.payload.id = item.id
                self.response.payload.name = item.name
                
            except Exception, e:
                msg = self._error_msg.format(format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise 

# ##############################################################################

class Create(_CreateEdit):
    """ Creates a new delivery definition.
    """
    _is_edit = False
    _error_msg = 'Could not create the definition, e:[{}]'
    
    class SimpleIO(_CreateEdit.SimpleIO):
        request_elem = 'zato_pattern_delivery_definition_create_request'
        response_elem = 'zato_pattern_delivery_definition_create_response'
        input_required = ('name',) + _CreateEdit.SimpleIO.input_required
        
    def _get_item(self, _ignored1, target_def_class, _ignored2):
        return target_def_class()

# ##############################################################################

class Edit(_CreateEdit):
    """ Updates an existing delivery definition.
    """
    _is_edit = True
    _error_msg = 'Could not update the definition, e:[{}]'
    
    class SimpleIO(_CreateEdit.SimpleIO):
        request_elem = 'zato_pattern_delivery_definition_edit_request'
        response_elem = 'zato_pattern_delivery_definition_edit_response'
        input_required = ('id',) + _CreateEdit.SimpleIO.input_required
        
    def _get_item(self, session, target_def_class, input):
        return session.query(target_def_class).\
            filter(target_def_class.id==input.id).\
            one()

# ##############################################################################

class Delete(AdminService):
    """ Deletes a guaranteed delivery definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_pattern_delivery_definition_delete_request'
        response_elem = 'zato_pattern_delivery_definition_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                item = session.query(DeliveryDefinitionBase).\
                    filter(DeliveryDefinitionBase.id==self.request.input.id).\
                    one()
                
                item_name = item.name
                
                session.delete(item)
                session.commit()
                
                self.delivery_store.set_deleted(item_name, True)

            except Exception, e:
                session.rollback()
                msg = 'Could not delete the definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                
                raise

# ##############################################################################

########NEW FILE########
__FILENAME__ = consumers
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc

# Bunch
from bunch import Bunch

# Zato
from zato.common import PUB_SUB
from zato.common.broker_message import PUB_SUB_CONSUMER, PUB_SUB_TOPIC
from zato.common.odb.model import Cluster, HTTPSOAP, PubSubConsumer, PubSubTopic
from zato.common.odb.query import pubsub_consumer_list
from zato.common.pubsub import Client
from zato.common.util import new_cid
from zato.server.service import AsIs, Int, UTC
from zato.server.service.internal import AdminService, AdminSIO

# ################################################################################################################################

class GetList(AdminService):
    """ Returns a list of pub/sub consumers available.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_pubsub_consumers_get_list_request'
        response_elem = 'zato_pubsub_consumers_get_list_response'
        input_required = ('cluster_id', 'topic_name')
        output_required = ('id', 'name', 'is_active', 'sec_type', Int('max_backlog'), Int('current_depth'), 
            'sub_key', 'delivery_mode')
        output_optional = (UTC('last_seen'), 'callback')

    def get_data(self, session):
        for item in pubsub_consumer_list(session, self.request.input.cluster_id, self.request.input.topic_name)[0]:
            item.last_seen = self.pubsub.get_consumer_last_seen(item.client_id)
            item.current_depth = self.pubsub.get_consumer_queue_current_depth(item.sub_key)
            yield item

    def handle(self):
        with closing(self.odb.session()) as session:
            for item in self.get_data(session):
                self.response.payload.append(item)

# ################################################################################################################################

class GetInfo(AdminService):
    """ Returns basic information regarding a consumer.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_pubsub_consumers_get_info_request'
        response_elem = 'zato_pubsub_consumers_get_info_response'
        input_required = ('id',)
        output_required = ('cluster_id', 'name', UTC('last_seen'), Int('current_depth'), 'sub_key')

    def handle(self):
        with closing(self.odb.session()) as session:

            consumer = session.query(PubSubConsumer).\
                filter(PubSubConsumer.id==self.request.input.id).\
                one()

            self.response.payload.cluster_id = consumer.cluster_id
            self.response.payload.name = consumer.sec_def.name
            self.response.payload.last_seen = self.pubsub.get_consumer_last_seen(consumer.sec_def.id)
            self.response.payload.current_depth = self.pubsub.get_consumer_queue_current_depth(consumer.sub_key)
            self.response.payload.sub_key = consumer.sub_key
    
# ################################################################################################################################

class _CreateEdit(AdminService):

    def _validate_input(self, input):

        if not input.delivery_mode in (elem.id for elem in PUB_SUB.DELIVERY_MODE):
            msg = 'Invalid delivery_mode `{}`, expected one of `{}`'.format(input.delivery_mode, PUB_SUB.DELIVERY_MODE)
            raise ValueError(msg)

        if input.delivery_mode == PUB_SUB.DELIVERY_MODE.CALLBACK_URL.id and not input.get('callback_id'):
            msg = 'Callback connection missing on input'
            raise ValueError(msg)

    def _get_callback(self, session, input):

        callback_id = input.get('callback_id')
        if callback_id:
            cb = session.query(HTTPSOAP.name, HTTPSOAP.soap_version).\
                filter(HTTPSOAP.id==callback_id).\
                one()
            callback_name = cb.name
            callback_type = PUB_SUB.CALLBACK_TYPE.OUTCONN_SOAP if bool(cb.soap_version) else \
                PUB_SUB.CALLBACK_TYPE.OUTCONN_PLAIN_HTP
        else:
            callback_name, callback_type = None, None

        return callback_id, callback_name, callback_type

# ##############################################################################################################################

class Create(_CreateEdit):
    """ Creates a new pub/sub consumer.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_pubsub_consumers_create_request'
        response_elem = 'zato_pubsub_consumers_create_response'
        input_required = ('cluster_id', 'client_id', 'topic_name', 'is_active', 'max_backlog', 'delivery_mode')
        input_optional = ('callback_id',)
        output_required = ('id', 'name', 'sub_key')

    def handle(self):
        input = self.request.input
        self._validate_input(input)

        with closing(self.odb.session()) as session:
            try:
                # Find a topic by its name so it can be paired with client_id later on
                topic = session.query(PubSubTopic).\
                    filter(PubSubTopic.cluster_id==input.cluster_id).\
                    filter(PubSubTopic.name==input.topic_name).\
                    one()

                callback = self._get_callback(session, input)

                sub_key = new_cid()
                consumer = PubSubConsumer(
                    None, input.is_active, sub_key, input.max_backlog, input.delivery_mode, callback[0],
                    callback[2], topic.id, input.client_id, input.cluster_id)

                session.add(consumer)
                session.commit()

            except Exception, e:
                msg = 'Could not create a consumer, e:`{}`'.format(format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise 
            else:
                input.action = PUB_SUB_CONSUMER.CREATE
                input.client_name = consumer.sec_def.name
                input.sub_key = sub_key
                input.callback_name = callback[1]
                input.callback_type = callback[2]
                self.broker_client.publish(input)

            self.response.payload.id = consumer.id
            self.response.payload.name = consumer.sec_def.name
            self.response.payload.sub_key = sub_key

# ################################################################################################################################

class Edit(_CreateEdit):
    """ Edits a pub/sub consumer.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_pubsub_consumers_edit_request'
        response_elem = 'zato_pubsub_consumers_edit_response'
        input_required = ('id', 'is_active', 'max_backlog', 'delivery_mode')
        input_optional = ('callback_id',)
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        self._validate_input(input)

        with closing(self.odb.session()) as session:
            try:

                callback = self._get_callback(session, input)

                # Find a topic by its name so it can be paired with client_id later on
                consumer = session.query(PubSubConsumer).\
                    filter(PubSubConsumer.id==input.id).\
                    one()

                consumer.is_active = input.is_active
                consumer.max_backlog = input.max_backlog
                consumer.delivery_mode = input.delivery_mode
                consumer.callback_id = callback[0]

                client_id = consumer.sec_def.id
                client_name = consumer.sec_def.name

                topic_id = consumer.topic.id
                topic_name = consumer.topic.name

                session.add(consumer)
                session.commit()

            except Exception, e:
                msg = 'Could not edit a consumer, e:`{}`'.format(format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise 
            else:
                msg = Bunch()
                msg.action = PUB_SUB_CONSUMER.EDIT

                msg.is_active = consumer.is_active
                msg.max_backlog = consumer.max_backlog
                msg.sub_key = consumer.sub_key
                msg.delivery_mode = consumer.delivery_mode
                msg.callback_id = consumer.callback_id

                msg.client_id = client_id
                msg.client_name = client_name

                msg.topic_id = topic_id
                msg.topic_name = topic_name

                msg.callback_name = callback[1]
                msg.callback_type = callback[2]

                self.broker_client.publish(msg)

            self.response.payload.id = consumer.id
            self.response.payload.name = consumer.sec_def.name

# ################################################################################################################################

class Delete(AdminService):
    """ Deletes a consumer.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_pubsub_consumers_delete_request'
        response_elem = 'zato_pubsub_consumers_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                consumer = session.query(PubSubConsumer).\
                    filter(PubSubConsumer.id==self.request.input.id).\
                    one()

                client_id = consumer.sec_def.id
                client_name = consumer.sec_def.name

                topic_id = consumer.topic.id
                topic_name = consumer.topic.name

                session.delete(consumer)
                session.commit()
            except Exception, e:
                msg = 'Could not delete the consumer, e:`{}`'.format(format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise
            else:
                msg = Bunch()
                msg.action = PUB_SUB_CONSUMER.DELETE

                msg.is_active = consumer.is_active
                msg.max_backlog = consumer.max_backlog
                msg.sub_key = consumer.sub_key

                msg.client_id = client_id
                msg.client_name = client_name

                msg.topic_id = topic_id
                msg.topic_name = topic_name

                self.broker_client.publish(msg)

# ################################################################################################################################

########NEW FILE########
__FILENAME__ = message
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc

# Zato
from zato.common import PUB_SUB
from zato.common.pubsub import Message
from zato.server.service import AsIs, Int, UTC
from zato.server.service.internal import AdminService, AdminSIO

# ################################################################################################################################

class _SourceTypeAware(AdminService):
    ZATO_DONT_DEPLOY = True

    source_type_func = {
        'get_list': {
            PUB_SUB.MESSAGE_SOURCE.TOPIC.id: 'get_topic_message_list',
            PUB_SUB.MESSAGE_SOURCE.CONSUMER_QUEUE.id: 'get_consumer_queue_message_list',
        },
        'delete': {
            PUB_SUB.MESSAGE_SOURCE.TOPIC.id: 'delete_from_topic',
            PUB_SUB.MESSAGE_SOURCE.CONSUMER_QUEUE.id: 'delete_from_consumer_queue',
        },
    }

    def get_pubsub_api_func(self, action, source_type):
        return getattr(self.pubsub, self.source_type_func[action][source_type])

class GetList(_SourceTypeAware):
    """ Returns a list of mesages from a topic or consumer queue.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_pubsub_message_get_list_request'
        response_elem = 'zato_pubsub_message_get_list_response'
        input_required = ('cluster_id', 'source_type', 'source_name')
        output_required = (AsIs('msg_id'), 'topic', 'mime_type', Int('priority'), Int('expiration'),
            UTC('creation_time_utc'), UTC('expire_at_utc'), 'producer')

    def get_data(self):
        func = self.get_pubsub_api_func('get_list', self.request.input.source_type)
        for item in func(self.request.input.source_name):
            yield item.to_dict()

    def handle(self):
        self.response.payload[:] = self.get_data()

# ################################################################################################################################

class Get(_SourceTypeAware):
    """ Returns basic information regarding a message from a topic or a consumer queue.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_pubsub_message_get_request'
        response_elem = 'zato_pubsub_message_get_response'
        input_required = ('cluster_id', AsIs('msg_id'))
        output_required = ('topic', 'producer', 'priority', 'mime_type', 'expiration',
            UTC('creation_time_utc'), UTC('expire_at_utc'))
        output_optional = ('payload',)

    def handle(self):
        self.response.payload = self.pubsub.get_message(self.request.input.msg_id)
        
# ################################################################################################################################

class Delete(_SourceTypeAware):
    """ Irrevocably deletes a message from a producer's topic or a consumer's queue.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_pubsub_message_delete_request'
        response_elem = 'zato_pubsub_message_delete_response'
        input_required = ('cluster_id', AsIs('msg_id'), 'source_name', 'source_type')

    def handle(self):
        func = self.get_pubsub_api_func('delete', self.request.input.source_type)
        func(self.request.input.source_name, self.request.input.msg_id)

# ################################################################################################################################

########NEW FILE########
__FILENAME__ = producers
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc

# Bunch
from bunch import Bunch

# Zato
from zato.common.broker_message import PUB_SUB_PRODUCER, PUB_SUB_TOPIC
from zato.common.odb.model import PubSubProducer, PubSubTopic
from zato.common.odb.query import pubsub_producer_list
from zato.server.service import UTC
from zato.server.service.internal import AdminService, AdminSIO

# ################################################################################################################################

class GetList(AdminService):
    """ Returns a list of pub/sub producers available.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_pubsub_producers_get_list_request'
        response_elem = 'zato_pubsub_producers_get_list_response'
        input_required = ('cluster_id', 'topic_name')
        output_required = ('id', 'name', 'is_active', 'sec_type')
        output_optional = (UTC('last_seen'),)

    def get_data(self, session):
        for item in pubsub_producer_list(session, self.request.input.cluster_id, self.request.input.topic_name)[0]:
            item.last_seen = self.pubsub.get_producer_last_seen(item.client_id)
            yield item

    def handle(self):
        with closing(self.odb.session()) as session:
            for item in self.get_data(session):
                self.response.payload.append(item)

# ################################################################################################################################

class Create(AdminService):
    """ Creates a new pub/sub producer.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_pubsub_producers_create_request'
        response_elem = 'zato_pubsub_producers_create_response'
        input_required = ('cluster_id', 'client_id', 'topic_name', 'is_active')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input

        with closing(self.odb.session()) as session:
            try:
                # Find a topic by its name so it can be paired with client_id later on
                topic = session.query(PubSubTopic).\
                    filter(PubSubTopic.cluster_id==input.cluster_id).\
                    filter(PubSubTopic.name==input.topic_name).\
                    one()

                producer = PubSubProducer(None, input.is_active, topic.id, input.client_id, input.cluster_id)

                session.add(producer)
                session.commit()

            except Exception, e:
                msg = 'Could not create a producer, e:`{}`'.format(format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise 
            else:
                input.action = PUB_SUB_PRODUCER.CREATE
                input.name = producer.sec_def.name
                self.broker_client.publish(input)

            self.response.payload.id = producer.id
            self.response.payload.name = producer.sec_def.name

# ################################################################################################################################

class GetInfo(AdminService):
    """ Returns basic information regarding a producer.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_pubsub_topics_get_info_request'
        response_elem = 'zato_pubsub_topics_get_info_response'
        input_required = ('id',)
        output_required = ('cluster_id', 'name', UTC('last_seen'))

    def handle(self):
        with closing(self.odb.session()) as session:

            producer = session.query(PubSubProducer).\
                filter(PubSubProducer.id==self.request.input.id).\
                one()

            self.response.payload.cluster_id = producer.cluster_id
            self.response.payload.name = producer.sec_def.name
            self.response.payload.last_seen = self.pubsub.get_producer_last_seen(producer.sec_def.id)

# ################################################################################################################################

class Edit(AdminService):
    """ Edits a new pub/sub producer.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_pubsub_producers_edit_request'
        response_elem = 'zato_pubsub_producers_edit_response'
        input_required = ('id', 'is_active')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input

        with closing(self.odb.session()) as session:
            try:
                # Find a topic by its name so it can be paired with client_id later on
                producer = session.query(PubSubProducer).\
                    filter(PubSubProducer.id==input.id).\
                    one()

                producer.is_active = input.is_active

                client_id = producer.sec_def.id
                client_name = producer.sec_def.name

                topic_id = producer.topic.id
                topic_name = producer.topic.name

                session.add(producer)
                session.commit()

            except Exception, e:
                msg = 'Could not edit a producer, e:`{}`'.format(format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise 
            else:
                msg = Bunch()
                msg.action = PUB_SUB_PRODUCER.EDIT

                msg.is_active = producer.is_active

                msg.client_id = client_id
                msg.client_name = client_name

                msg.topic_id = topic_id
                msg.topic_name = topic_name

                self.broker_client.publish(msg)

            self.response.payload.id = producer.id
            self.response.payload.name = producer.sec_def.name

# ################################################################################################################################

class Delete(AdminService):
    """ Deletes a producer.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_pubsub_producers_delete_request'
        response_elem = 'zato_pubsub_producers_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                producer = session.query(PubSubProducer).\
                    filter(PubSubProducer.id==self.request.input.id).\
                    one()

                client_id = producer.sec_def.id
                client_name = producer.sec_def.name

                topic_id = producer.topic.id
                topic_name = producer.topic.name

                session.delete(producer)
                session.commit()
            except Exception, e:
                msg = 'Could not delete the producer, e:`{}`'.format(format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise
            else:
                msg = Bunch()
                msg.action = PUB_SUB_PRODUCER.DELETE

                msg.client_id = client_id
                msg.client_name = client_name

                msg.topic_id = topic_id
                msg.topic_name = topic_name

                self.broker_client.publish(msg)

# ################################################################################################################################

########NEW FILE########
__FILENAME__ = topics
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc

# Bunch
from bunch import Bunch

# Zato
from zato.common.broker_message import PUB_SUB_TOPIC
from zato.common.odb.model import Cluster, PubSubTopic
from zato.common.odb.query import pubsub_topic_list
from zato.server.service import AsIs, Int, UTC
from zato.server.service.internal import AdminService, AdminSIO

# ################################################################################################################################

class GetList(AdminService):
    """ Returns a list of topics available.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_pubsub_topics_get_list_request'
        response_elem = 'zato_pubsub_topics_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', Int('current_depth'), Int('max_depth'),
            Int('consumers_count'), Int('producers_count'))
        output_optional = (UTC('last_pub_time'),)

    def get_data(self, session):
        for item in pubsub_topic_list(session, self.request.input.cluster_id, False):
            item.current_depth = self.pubsub.get_topic_depth(item.name)
            item.consumers_count = self.pubsub.get_consumers_count(item.name)
            item.producers_count = self.pubsub.get_producers_count(item.name)
            item.last_pub_time = self.pubsub.get_last_pub_time(item.name)
            yield item

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)

# ################################################################################################################################

class GetInfo(AdminService):
    """ Returns basic information regarding a topic.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_pubsub_topics_get_info_request'
        response_elem = 'zato_pubsub_topics_get_info_response'
        input_required = ('cluster_id', 'name')
        output_required = (Int('current_depth'), Int('consumers_count'), Int('producers_count'), UTC('last_pub_time'))

    def handle(self):
        self.response.payload.current_depth = self.pubsub.get_topic_depth(self.request.input.name)
        self.response.payload.consumers_count = self.pubsub.get_consumers_count(self.request.input.name)
        self.response.payload.producers_count = self.pubsub.get_producers_count(self.request.input.name)
        self.response.payload.last_pub_time = self.pubsub.get_last_pub_time(self.request.input.name)

# ################################################################################################################################

class Publish(AdminService):
    """ Publishes a messages to a topic of choice. If not client_id is given on input the message is published using
    an internal account.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_pubsub_topics_publish_request'
        response_elem = 'zato_pubsub_topics_publish_response'
        input_required = ('cluster_id', 'name', 'mime_type', Int('priority'), Int('expiration'))
        input_optional = ('client_id', 'payload')
        output_required = (AsIs('msg_id'),)

    def handle(self):
        client_id = self.request.input.get('client_id') or self.pubsub.get_default_producer().id

        self.response.payload.msg_id = self.pubsub.publish(
            self.request.input.payload, self.request.input.name, self.request.input.mime_type, self.request.input.priority,
            self.request.input.expiration, client_id=client_id).msg.msg_id

# ################################################################################################################################

class Create(AdminService):
    """ Creates a new topic.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_pubsub_topics_create_request'
        response_elem = 'zato_pubsub_topics_create_response'
        input_required = ('cluster_id', 'name', 'is_active', 'max_depth')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input

        with closing(self.odb.session()) as session:
            try:
                cluster = session.query(Cluster).filter_by(id=input.cluster_id).first()

                # Let's see if we already have a topic of that name before committing
                # any stuff into the database.
                existing_one = session.query(PubSubTopic).\
                    filter(Cluster.id==input.cluster_id).\
                    filter(PubSubTopic.name==input.name).first()

                if existing_one:
                    raise Exception('Topic `{}` already exists on this cluster'.format(input.name))

                topic = PubSubTopic(None, input.name, input.is_active, input.max_depth, cluster.id)

                session.add(topic)
                session.commit()

                # Now that the topic is added we can let our own internal producer publish to it.
                create_prod_req = Bunch()
                create_prod_req.cluster_id = input.cluster_id
                create_prod_req.client_id = self.server.config.pubsub.default_producer.id
                create_prod_req.topic_name = topic.name
                create_prod_req.is_active = True

                self.invoke('zato.pubsub.producers.create', create_prod_req)

            except Exception, e:
                msg = 'Could not create a topic, e:`{}`'.format(format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise 
            else:
                input.action = PUB_SUB_TOPIC.CREATE
                self.broker_client.publish(input)

            self.response.payload.id = topic.id
            self.response.payload.name = topic.name

# ################################################################################################################################

class Edit(AdminService):
    """ Updates a topic.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_pubsub_topics_edit_request'
        response_elem = 'zato_pubsub_topics_edit_response'
        input_required = ('id', 'cluster_id', 'name', 'is_active', 'max_depth')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:
            try:
                existing_one = session.query(PubSubTopic).\
                    filter(Cluster.id==input.cluster_id).\
                    filter(PubSubTopic.name==input.name).\
                    filter(PubSubTopic.id!=input.id).\
                    first()

                if existing_one:
                    raise Exception('Topic `{}` already exists on this cluster'.format(input.name))

                topic = session.query(PubSubTopic).filter_by(id=input.id).one()
                old_name = topic.name

                topic.is_active = input.is_active
                topic.max_depth = input.max_depth

                session.add(topic)
                session.commit()

            except Exception, e:
                msg = 'Could not update the topic, e:`{}'.format(format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise 
            else:
                input.action = PUB_SUB_TOPIC.EDIT
                input.old_name = old_name
                input.name = topic.name
                self.broker_client.publish(input)

                self.response.payload.id = topic.id
                self.response.payload.name = topic.name

# ################################################################################################################################

class Delete(AdminService):
    """ Deletes a topic.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_pubsub_topics_delete_request'
        response_elem = 'zato_pubsub_topics_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                topic = session.query(PubSubTopic).\
                    filter(PubSubTopic.id==self.request.input.id).\
                    one()

                session.delete(topic)
                session.commit()

            except Exception, e:
                msg = 'Could not delete the topic, e:`{}`'.format(format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise
            else:
                self.request.input.action = PUB_SUB_TOPIC.DELETE
                self.request.input.name = topic.name
                self.broker_client.publish(self.request.input)

# ################################################################################################################################

########NEW FILE########
__FILENAME__ = scheduler
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc

# dateutil
from dateutil.parser import parse

# Zato
from zato.common import scheduler_date_time_format, SCHEDULER_JOB_TYPE, ZatoException, ZATO_NONE
from zato.common.broker_message import MESSAGE_TYPE, SCHEDULER
from zato.common.odb.model import Cluster, Job, CronStyleJob, IntervalBasedJob,\
     Service
from zato.common.odb.query import job_by_name, job_list
from zato.server.service.internal import AdminService, AdminSIO

PREDEFINED_CRON_DEFINITIONS = {
    '@yearly': '0 0 1 1 *',
    '@annually': '0 0 1 1 *', # Same as 'yearly'.
    '@monthly': '0 0 1 * *',
    '@weekly': '0 0 * * 0',
    '@daily': '0 0 * * *',
    '@hourly': '0 * * * *',
    }

CRON_EXPRESSION_LEN = 5

_service_name_prefix = 'zato.scheduler.job.'

def _create_edit(action, cid, input, payload, logger, session, broker_client, response):
    """ Creating and updating a job requires a series of very similar steps
    so they've been all put here and depending on the 'action' parameter 
    (be it 'create'/'edit') some additional operations are performed.
    """
    job_type = input.job_type
    cluster_id = input.cluster_id
    name = input.name
    service_name = input.service
    
    if job_type not in(SCHEDULER_JOB_TYPE.ONE_TIME, SCHEDULER_JOB_TYPE.INTERVAL_BASED, 
                           SCHEDULER_JOB_TYPE.CRON_STYLE):
        msg = 'Unrecognized job type [{0}]'.format(job_type)
        logger.error(msg)
        raise ZatoException(cid, msg)
    
    # For finding out if we don't have a job of that name already defined.
    existing_one_base = session.query(Job).\
        filter(Cluster.id==cluster_id).\
        filter(Job.name==name)
    
    if action == 'create':
        existing_one = existing_one_base.first()
    else:
        job_id = input.id
        existing_one = existing_one_base.filter(Job.id != job_id).first()
    
    if existing_one:
        raise ZatoException(cid, 'Job [{0}] already exists on this cluster'.format(name))
    
    # Is the service's name correct?
    service = session.query(Service).\
        filter(Cluster.id==cluster_id).\
        filter(Service.name==service_name).first()
    
    if not service:
        msg = 'Service [{0}] does not exist on this cluster'.format(service_name)
        logger.error(msg)
        raise ZatoException(cid, msg)
    
    # We can create/edit a base Job object now and - optionally - another one
    # if the job type's is either interval-based or Cron-style. The base
    # instance will be enough if it's a one-time job.
    
    extra = input.extra.encode('utf-8')
    is_active = input.is_active
    start_date = parse(input.start_date)
    
    if action == 'create':
        job = Job(None, name, is_active, job_type, start_date, extra, cluster_id=cluster_id, service=service)
    else:
        job = session.query(Job).filter_by(id=job_id).one()
        old_name = job.name
        job.name = name
        job.is_active = is_active
        job.start_date = start_date
        job.service = service
        job.extra = extra
        
    try:
        # Add but don't commit yet.
        session.add(job)

        if job_type == SCHEDULER_JOB_TYPE.INTERVAL_BASED:
            ib_params = ('weeks', 'days', 'hours', 'minutes', 'seconds')
            if not any(input[key] for key in ib_params):
                msg = "At least one of ['weeks', 'days', 'hours', 'minutes', 'seconds'] must be given"
                logger.error(msg)
                raise ZatoException(cid, msg)
            
            if action == 'create':
                ib_job = IntervalBasedJob(None, job)
            else:
                ib_job = session.query(IntervalBasedJob).filter_by(id=job.interval_based.id).one()

            for param in ib_params:
                value = input[param] or None
                if value != ZATO_NONE:
                    setattr(ib_job, param, value)
            
            session.add(ib_job)
            
        elif job_type == SCHEDULER_JOB_TYPE.CRON_STYLE:
            cron_definition = input.cron_definition.strip()
            
            if cron_definition.startswith('@'):
                if not cron_definition in PREDEFINED_CRON_DEFINITIONS:
                    msg = ('If using a predefined definition, it must be '
                             'one of {0} instead of [{1}]').format(
                                 sorted(PREDEFINED_CRON_DEFINITIONS), 
                                 cron_definition)
                    logger.error(msg)
                    raise ZatoException(cid, msg)
                
                cron_definition = PREDEFINED_CRON_DEFINITIONS[cron_definition]
            else:
                splitted = cron_definition.strip().split()
                if not len(splitted) == CRON_EXPRESSION_LEN:
                    msg = ('Expression [{0}] is invalid, it needs to contain '
                           'exactly {1} whitespace-separated fields').format(
                               cron_definition, CRON_EXPRESSION_LEN)
                    logger.error(msg)
                    raise ZatoException(cid, msg)
                cron_definition = ' '.join(splitted)
            
            if action == 'create':
                cs_job = CronStyleJob(None, job)
            else:
                cs_job = session.query(CronStyleJob).filter_by(id=job.cron_style.id).one()
                
            cs_job.cron_definition = cron_definition
            session.add(cs_job)

        # We can commit it all now.
        session.commit()
        
        # Now send it to the broker, but only if the job is active.
        if is_active:
            msg_action = SCHEDULER.CREATE if action == 'create' else SCHEDULER.EDIT
            msg = {'action': msg_action, 'job_type': job_type,
                   'is_active':is_active, 'start_date':start_date.isoformat(),
                   'extra':extra, 'service': service.name,
                   'name': name
                   }
            if action == 'edit':
                msg['old_name'] = old_name

            if job_type == SCHEDULER_JOB_TYPE.INTERVAL_BASED:
                for param in ib_params:
                    value = input[param]
                    msg[param] = int(value) if value else 0
            elif job_type == SCHEDULER_JOB_TYPE.CRON_STYLE:
                msg['cron_definition'] = cron_definition
        else:
            msg = {'action': SCHEDULER.DELETE, 'name': name}
            
        broker_client.publish(msg, MESSAGE_TYPE.TO_SINGLETON)
            
    except Exception, e:
        session.rollback()
        msg = 'Could not complete the request, e:[{e}]'.format(e=format_exc(e))
        logger.error(msg)
        raise
    else:
        response.payload.id = job.id
        response.payload.name = input.name
            
        if job_type == SCHEDULER_JOB_TYPE.CRON_STYLE:
            # Needs to be returned because we might've been performing
            # a substitution like changing '@hourly' into '0 * * * *'.
            response.payload.cron_definition = cs_job.cron_definition

class _CreateEdit(AdminService):
    """ A base class for both creating and editing scheduler jobs.
    """
    class SimpleIO(AdminSIO):
        input_required = ('cluster_id', 'name', 'is_active', 'job_type', 'service', 'start_date')
        input_optional = ('id', 'extra', 'weeks', 'days', 'hours', 'minutes', 'seconds', 'repeats', 'cron_definition')
        output_required = ('id', 'name')
        output_optional = ('cron_definition',)
        default_value = ''
        
    def handle(self):
        with closing(self.odb.session()) as session:
            _create_edit(self.__class__.__name__.lower(), self.cid, self.request.input, self.request.payload, 
                    self.logger, session, self.broker_client, self.response)

class _Get(AdminService):
    class SimpleIO(AdminSIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'job_type', 'start_date', 'service_id', 'service_name')
        output_optional = ('extra', 'weeks', 'days', 'hours', 'minutes', 'seconds', 'repeats', 'cron_definition')
        output_repeated = True
        default_value = ''
        date_time_format = scheduler_date_time_format

class GetList(_Get):
    """ Returns a list of all jobs defined in the SingletonServer's scheduler.
    """
    name = _service_name_prefix + 'get-list'
    
    class SimpleIO(_Get.SimpleIO):
        request_elem = 'zato_scheduler_job_get_list_request'
        response_elem = 'zato_scheduler_job_get_list_response'

    def get_data(self, session):
        return job_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)
            
        for item in self.response.payload.zato_output:
            item.start_date = item.start_date.isoformat()
            
class GetByName(_Get):
    """ Returns a job by its name.
    """
    name = _service_name_prefix + 'get-by-name'
    
    class SimpleIO(_Get.SimpleIO):
        request_elem = 'zato_scheduler_job_get_by_name_request'
        response_elem = 'zato_scheduler_job_get_by_name_response'
        input_required = _Get.SimpleIO.input_required + ('name',)
        output_repeated = False
        
    def get_data(self, session):
        return job_by_name(session, self.server.cluster_id, self.request.input.name)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload = self.get_data(session)
            self.response.payload.start_date = self.response.payload.start_date.isoformat()

class Create(_CreateEdit):
    """ Creates a new scheduler's job.
    """
    name = _service_name_prefix + 'create'
    
    class SimpleIO(_CreateEdit.SimpleIO):
        request_elem = 'zato_scheduler_job_create_request'
        response_elem = 'zato_scheduler_job_create_response'
        
class Edit(_CreateEdit):
    """ Updates a scheduler's job.
    """
    name = _service_name_prefix + 'edit'
    
    class SimpleIO(_CreateEdit.SimpleIO):
        request_elem = 'zato_scheduler_job_edit_request'
        response_elem = 'zato_scheduler_job_edit_response'

class Delete(AdminService):
    """ Deletes a scheduler's job.
    """
    name = _service_name_prefix + 'delete'
    
    class SimpleIO(AdminSIO):
        request_elem = 'zato_scheduler_job_delete_request'
        response_elem = 'zato_scheduler_job_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                job = session.query(Job).\
                    filter(Job.id==self.request.input.id).\
                    one()
                
                session.delete(job)
                session.commit()

                msg = {'action': SCHEDULER.DELETE, 'name': job.name}
                self.broker_client.publish(msg, MESSAGE_TYPE.TO_SINGLETON)
                
            except Exception, e:
                session.rollback()
                msg = 'Could not delete the job, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                
                raise
            
class Execute(AdminService):
    """ Executes a scheduler's job.
    """
    name = _service_name_prefix + 'execute'
    
    class SimpleIO(AdminSIO):
        request_elem = 'zato_scheduler_job_execute_request'
        response_elem = 'zato_scheduler_job_execute_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                job = session.query(Job).\
                    filter(Job.id==self.request.input.id).\
                    one()
                
                msg = {'action': SCHEDULER.EXECUTE, 'name': job.name}
                self.broker_client.publish(msg, MESSAGE_TYPE.TO_SINGLETON)
                
            except Exception, e:
                session.rollback()
                msg = 'Could not execute the job, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                
                raise

########NEW FILE########
__FILENAME__ = apikey
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc
from uuid import uuid4

# Zato
from zato.common import SEC_DEF_TYPE
from zato.common.broker_message import SECURITY
from zato.common.odb.model import Cluster, APIKeySecurity
from zato.common.odb.query import apikey_security_list
from zato.server.service.internal import AdminService, AdminSIO, ChangePasswordBase

class GetList(AdminService):
    """ Returns a list of API keys available.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_apikey_get_list_request'
        response_elem = 'zato_security_apikey_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'username')

    def get_data(self, session):
        return apikey_security_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)

class Create(AdminService):
    """ Creates a new API key.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_apikey_create_request'
        response_elem = 'zato_security_apikey_create_response'
        input_required = ('cluster_id', 'name', 'is_active', 'username')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        input.password = uuid4().hex
        
        with closing(self.odb.session()) as session:
            try:
                cluster = session.query(Cluster).filter_by(id=input.cluster_id).first()
                
                # Let's see if we already have a definition of that name before committing
                # any stuff into the database.
                existing_one = session.query(APIKeySecurity).\
                    filter(Cluster.id==input.cluster_id).\
                    filter(APIKeySecurity.name==input.name).first()

                if existing_one:
                    raise Exception('API key [{0}] already exists on this cluster'.format(input.name))
                
                auth = APIKeySecurity(None, input.name, input.is_active, input.username, input.password, cluster)
                
                session.add(auth)
                session.commit()

            except Exception, e:
                msg = 'Could not create an API key, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise 
            else:
                input.action = SECURITY.APIKEY_CREATE
                input.sec_type = SEC_DEF_TYPE.APIKEY
                self.broker_client.publish(input)

            self.response.payload.id = auth.id
            self.response.payload.name = auth.name

class Edit(AdminService):
    """ Updates an API key.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_apikey_edit_request'
        response_elem = 'zato_security_apikey_edit_response'
        input_required = ('id', 'cluster_id', 'name', 'is_active', 'username')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:
            try:
                existing_one = session.query(APIKeySecurity).\
                    filter(Cluster.id==input.cluster_id).\
                    filter(APIKeySecurity.name==input.name).\
                    filter(APIKeySecurity.id!=input.id).\
                    first()

                if existing_one:
                    raise Exception('API key [{0}] already exists on this cluster'.format(input.name))
                
                definition = session.query(APIKeySecurity).filter_by(id=input.id).one()
                old_name = definition.name
                
                definition.name = input.name
                definition.is_active = input.is_active
                definition.username = input.username

                session.add(definition)
                session.commit()

            except Exception, e:
                msg = 'Could not update the API key, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise 
            else:
                input.action = SECURITY.APIKEY_EDIT
                input.old_name = old_name
                input.sec_type = SEC_DEF_TYPE.APIKEY
                self.broker_client.publish(input)

                self.response.payload.id = definition.id
                self.response.payload.name = definition.name
    
class ChangePassword(ChangePasswordBase):
    """ Changes the password of an API key.
    """
    password_required = False

    class SimpleIO(ChangePasswordBase.SimpleIO):
        request_elem = 'zato_security_apikey_change_password_request'
        response_elem = 'zato_security_apikey_change_password_response'
    
    def handle(self):
        def _auth(instance, password):
            instance.password = password
            
        return self._handle(APIKeySecurity, _auth, SECURITY.APIKEY_CHANGE_PASSWORD)

class Delete(AdminService):
    """ Deletes an API key.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_apikey_delete_request'
        response_elem = 'zato_security_apikey_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                auth = session.query(APIKeySecurity).\
                    filter(APIKeySecurity.id==self.request.input.id).\
                    one()

                session.delete(auth)
                session.commit()
            except Exception, e:
                msg = 'Could not delete the API key, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise
            else:
                self.request.input.action = SECURITY.APIKEY_DELETE
                self.request.input.name = auth.name
                self.broker_client.publish(self.request.input)

########NEW FILE########
__FILENAME__ = aws
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc
from uuid import uuid4

# Zato
from zato.common import SEC_DEF_TYPE
from zato.common.broker_message import SECURITY
from zato.common.odb.model import Cluster, AWSSecurity
from zato.common.odb.query import aws_security_list
from zato.server.service.internal import AdminService, AdminSIO, ChangePasswordBase

class GetList(AdminService):
    """ Returns a list of AWS definitions available.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_aws_get_list_request'
        response_elem = 'zato_security_aws_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'username')

    def get_data(self, session):
        return aws_security_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)

class Create(AdminService):
    """ Creates a new AWS definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_aws_create_request'
        response_elem = 'zato_security_aws_create_response'
        input_required = ('cluster_id', 'name', 'is_active', 'username')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        input.password = uuid4().hex
        
        with closing(self.odb.session()) as session:
            try:
                cluster = session.query(Cluster).filter_by(id=input.cluster_id).first()
                
                # Let's see if we already have a definition of that name before committing
                # any stuff into the database.
                existing_one = session.query(AWSSecurity).\
                    filter(Cluster.id==input.cluster_id).\
                    filter(AWSSecurity.name==input.name).first()

                if existing_one:
                    raise Exception('AWS definition [{0}] already exists on this cluster'.format(input.name))
                
                auth = AWSSecurity(None, input.name, input.is_active, input.username, input.password, cluster)
                
                session.add(auth)
                session.commit()

            except Exception, e:
                msg = 'Could not create an AWS definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise 
            else:
                input.action = SECURITY.AWS_CREATE
                input.sec_type = SEC_DEF_TYPE.AWS
                self.broker_client.publish(input)

            self.response.payload.id = auth.id
            self.response.payload.name = auth.name

class Edit(AdminService):
    """ Updates an AWS definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_aws_edit_request'
        response_elem = 'zato_security_aws_edit_response'
        input_required = ('id', 'cluster_id', 'name', 'is_active', 'username')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:
            try:
                existing_one = session.query(AWSSecurity).\
                    filter(Cluster.id==input.cluster_id).\
                    filter(AWSSecurity.name==input.name).\
                    filter(AWSSecurity.id!=input.id).\
                    first()

                if existing_one:
                    raise Exception('AWS definition [{0}] already exists on this cluster'.format(input.name))
                
                definition = session.query(AWSSecurity).filter_by(id=input.id).one()
                old_name = definition.name
                
                definition.name = input.name
                definition.is_active = input.is_active
                definition.username = input.username

                session.add(definition)
                session.commit()

            except Exception, e:
                msg = 'Could not update the AWS definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise 
            else:
                input.action = SECURITY.AWS_EDIT
                input.old_name = old_name
                input.sec_type = SEC_DEF_TYPE.AWS
                self.broker_client.publish(input)

                self.response.payload.id = definition.id
                self.response.payload.name = definition.name
    
class ChangePassword(ChangePasswordBase):
    """ Changes the password of an AWS definition.
    """
    password_required = False

    class SimpleIO(ChangePasswordBase.SimpleIO):
        request_elem = 'zato_security_aws_change_password_request'
        response_elem = 'zato_security_aws_change_password_response'
    
    def handle(self):
        def _auth(instance, password):
            instance.password = password
            
        return self._handle(AWSSecurity, _auth, SECURITY.AWS_CHANGE_PASSWORD)

class Delete(AdminService):
    """ Deletes an AWS definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_aws_delete_request'
        response_elem = 'zato_security_aws_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                auth = session.query(AWSSecurity).\
                    filter(AWSSecurity.id==self.request.input.id).\
                    one()

                session.delete(auth)
                session.commit()
            except Exception, e:
                msg = 'Could not delete the AWS definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise
            else:
                self.request.input.action = SECURITY.AWS_DELETE
                self.request.input.name = auth.name
                self.broker_client.publish(self.request.input)

########NEW FILE########
__FILENAME__ = basic_auth
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc
from uuid import uuid4

# Zato
from zato.common import SEC_DEF_TYPE
from zato.common.broker_message import SECURITY
from zato.common.odb.model import Cluster, HTTPBasicAuth
from zato.common.odb.query import basic_auth_list
from zato.server.service.internal import AdminService, AdminSIO, ChangePasswordBase

class GetList(AdminService):
    """ Returns a list of HTTP Basic Auth definitions available.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_basic_auth_get_list_request'
        response_elem = 'zato_security_basic_auth_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'username', 'realm')
        
    def get_data(self, session):
        return basic_auth_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)

class Create(AdminService):
    """ Creates a new HTTP Basic Auth definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_basic_auth_create_request'
        response_elem = 'zato_security_basic_auth_create_response'
        input_required = ('cluster_id', 'name', 'is_active', 'username', 'realm')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        input.password = uuid4().hex
        
        with closing(self.odb.session()) as session:
            try:
                cluster = session.query(Cluster).filter_by(id=input.cluster_id).first()
                
                # Let's see if we already have a definition of that name before committing
                # any stuff into the database.
                existing_one = session.query(HTTPBasicAuth).\
                    filter(Cluster.id==input.cluster_id).\
                    filter(HTTPBasicAuth.name==input.name).first()
                
                if existing_one:
                    raise Exception('HTTP Basic Auth definition [{0}] already exists on this cluster'.format(input.name))
                
                auth = HTTPBasicAuth(None, input.name, input.is_active, input.username, 
                    input.realm, input.password, cluster)
                
                session.add(auth)
                session.commit()
                
            except Exception, e:
                msg = 'Could not create an HTTP Basic Auth definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise 
            else:
                input.action = SECURITY.BASIC_AUTH_CREATE
                input.sec_type = SEC_DEF_TYPE.BASIC_AUTH
                self.broker_client.publish(input)
            
            self.response.payload.id = auth.id
            self.response.payload.name = auth.name

class Edit(AdminService):
    """ Updates an HTTP Basic Auth definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_basic_auth_edit_request'
        response_elem = 'zato_security_basic_auth_edit_response'
        input_required = ('id', 'cluster_id', 'name', 'is_active', 'username', 'realm')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:
            try:
                existing_one = session.query(HTTPBasicAuth).\
                    filter(Cluster.id==input.cluster_id).\
                    filter(HTTPBasicAuth.name==input.name).\
                    filter(HTTPBasicAuth.id!=input.id).\
                    first()
                
                if existing_one:
                    raise Exception('HTTP Basic Auth definition [{0}] already exists on this cluster'.format(input.name))
                
                definition = session.query(HTTPBasicAuth).filter_by(id=input.id).one()
                old_name = definition.name
                
                definition.name = input.name
                definition.is_active = input.is_active
                definition.username = input.username
                definition.realm = input.realm
    
                session.add(definition)
                session.commit()
                
            except Exception, e:
                msg = 'Could not update the HTTP Basic Auth definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise 
            else:
                input.action = SECURITY.BASIC_AUTH_EDIT
                input.old_name = old_name
                input.sec_type = SEC_DEF_TYPE.BASIC_AUTH
                self.broker_client.publish(input)
    
                self.response.payload.id = definition.id
                self.response.payload.name = definition.name
    
class ChangePassword(ChangePasswordBase):
    """ Changes the password of an HTTP Basic Auth definition.
    """
    password_required = False
    
    class SimpleIO(ChangePasswordBase.SimpleIO):
        request_elem = 'zato_security_basic_auth_change_password_request'
        response_elem = 'zato_security_basic_auth_change_password_response'
    
    def handle(self):
        def _auth(instance, password):
            instance.password = password
            
        return self._handle(HTTPBasicAuth, _auth, SECURITY.BASIC_AUTH_CHANGE_PASSWORD)

class Delete(AdminService):
    """ Deletes an HTTP Basic Auth definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_basic_auth_delete_request'
        response_elem = 'zato_security_basic_auth_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                auth = session.query(HTTPBasicAuth).\
                    filter(HTTPBasicAuth.id==self.request.input.id).\
                    one()
                
                session.delete(auth)
                session.commit()
            except Exception, e:
                msg = 'Could not delete the HTTP Basic Auth definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise
            else:
                self.request.input.action = SECURITY.BASIC_AUTH_DELETE
                self.request.input.name = auth.name
                self.broker_client.publish(self.request.input)

########NEW FILE########
__FILENAME__ = ntlm
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc
from uuid import uuid4

# Zato
from zato.common import SEC_DEF_TYPE
from zato.common.broker_message import SECURITY
from zato.common.odb.model import Cluster, NTLM
from zato.common.odb.query import ntlm_list
from zato.server.service.internal import AdminService, AdminSIO, ChangePasswordBase

class GetList(AdminService):
    """ Returns a list of NTLM definitions available.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_ntlm_get_list_request'
        response_elem = 'zato_security_ntlm_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'username')

    def get_data(self, session):
        return ntlm_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)

class Create(AdminService):
    """ Creates a new NTLM definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_ntlm_create_request'
        response_elem = 'zato_security_ntlm_create_response'
        input_required = ('cluster_id', 'name', 'is_active', 'username')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        input.password = uuid4().hex
        
        with closing(self.odb.session()) as session:
            try:
                cluster = session.query(Cluster).filter_by(id=input.cluster_id).first()
                
                # Let's see if we already have a definition of that name before committing
                # any stuff into the database.
                existing_one = session.query(NTLM).\
                    filter(Cluster.id==input.cluster_id).\
                    filter(NTLM.name==input.name).first()

                if existing_one:
                    raise Exception('NTLM definition [{0}] already exists on this cluster'.format(input.name))
                
                auth = NTLM(None, input.name, input.is_active, input.username, input.password, cluster)
                
                session.add(auth)
                session.commit()

            except Exception, e:
                msg = 'Could not create an NTLM definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise 
            else:
                input.action = SECURITY.NTLM_CREATE
                input.sec_type = SEC_DEF_TYPE.NTLM
                self.broker_client.publish(input)

            self.response.payload.id = auth.id
            self.response.payload.name = auth.name

class Edit(AdminService):
    """ Updates an NTLM definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_ntlm_edit_request'
        response_elem = 'zato_security_ntlm_edit_response'
        input_required = ('id', 'cluster_id', 'name', 'is_active', 'username')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:
            try:
                existing_one = session.query(NTLM).\
                    filter(Cluster.id==input.cluster_id).\
                    filter(NTLM.name==input.name).\
                    filter(NTLM.id!=input.id).\
                    first()

                if existing_one:
                    raise Exception('NTLM definition [{0}] already exists on this cluster'.format(input.name))
                
                definition = session.query(NTLM).filter_by(id=input.id).one()
                old_name = definition.name
                
                definition.name = input.name
                definition.is_active = input.is_active
                definition.username = input.username

                session.add(definition)
                session.commit()

            except Exception, e:
                msg = 'Could not update the NTLM definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise 
            else:
                input.action = SECURITY.NTLM_EDIT
                input.old_name = old_name
                input.sec_type = SEC_DEF_TYPE.NTLM
                self.broker_client.publish(input)

                self.response.payload.id = definition.id
                self.response.payload.name = definition.name
    
class ChangePassword(ChangePasswordBase):
    """ Changes the password of an NTLM definition.
    """
    password_required = False

    class SimpleIO(ChangePasswordBase.SimpleIO):
        request_elem = 'zato_security_ntlm_change_password_request'
        response_elem = 'zato_security_ntlm_change_password_response'
    
    def handle(self):
        def _auth(instance, password):
            instance.password = password
            
        return self._handle(NTLM, _auth, SECURITY.NTLM_CHANGE_PASSWORD)

class Delete(AdminService):
    """ Deletes an NTLM definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_ntlm_delete_request'
        response_elem = 'zato_security_ntlm_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                auth = session.query(NTLM).\
                    filter(NTLM.id==self.request.input.id).\
                    one()

                session.delete(auth)
                session.commit()
            except Exception, e:
                msg = 'Could not delete the NTLM definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise
            else:
                self.request.input.action = SECURITY.NTLM_DELETE
                self.request.input.name = auth.name
                self.broker_client.publish(self.request.input)

########NEW FILE########
__FILENAME__ = oauth
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc
from uuid import uuid4

# Zato
from zato.common import SEC_DEF_TYPE
from zato.common.broker_message import SECURITY
from zato.common.odb.model import Cluster, OAuth
from zato.common.odb.query import oauth_list
from zato.server.service import Integer
from zato.server.service.internal import AdminService, AdminSIO, ChangePasswordBase

class GetList(AdminService):
    """ Returns a list of OAuth definitions available.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_oauth_get_list_request'
        response_elem = 'zato_security_oauth_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'username', 'proto_version',
            'sig_method', Integer('max_nonce_log'))

    def get_data(self, session):
        return oauth_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)

class Create(AdminService):
    """ Creates a new OAuth definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_oauth_create_request'
        response_elem = 'zato_security_oauth_create_response'
        input_required = ('cluster_id', 'name', 'is_active', 'username', 'proto_version',
            'sig_method', Integer('max_nonce_log'))
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        input.password = uuid4().hex

        with closing(self.odb.session()) as session:
            try:
                cluster = session.query(Cluster).filter_by(id=input.cluster_id).first()

                # Let's see if we already have a definition of that name before committing
                # any stuff into the database.
                existing_one = session.query(OAuth).\
                    filter(Cluster.id==input.cluster_id).\
                    filter(OAuth.name==input.name).first()

                if existing_one:
                    raise Exception('OAuth definition [{0}] already exists on this cluster'.format(input.name))

                auth = OAuth(None, input.name, input.is_active, input.username,
                    input.password, input.proto_version, input.sig_method,
                    input.max_nonce_log, cluster)

                session.add(auth)
                session.commit()

            except Exception, e:
                msg = 'Could not create an OAuth definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise
            else:
                input.action = SECURITY.OAUTH_CREATE
                input.sec_type = SEC_DEF_TYPE.OAUTH
                self.broker_client.publish(input)

            self.response.payload.id = auth.id
            self.response.payload.name = auth.name

class Edit(AdminService):
    """ Updates an OAuth definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_oauth_edit_request'
        response_elem = 'zato_security_oauth_edit_response'
        input_required = ('id', 'cluster_id', 'name', 'is_active', 'username',
            'proto_version', 'sig_method', Integer('max_nonce_log'))
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:
            try:
                existing_one = session.query(OAuth).\
                    filter(Cluster.id==input.cluster_id).\
                    filter(OAuth.name==input.name).\
                    filter(OAuth.id!=input.id).\
                    first()

                if existing_one:
                    raise Exception('OAuth definition [{0}] already exists on this cluster'.format(input.name))

                definition = session.query(OAuth).filter_by(id=input.id).one()
                old_name = definition.name

                definition.name = input.name
                definition.is_active = input.is_active
                definition.username = input.username
                definition.proto_version = input.proto_version
                definition.sig_method = input.sig_method
                definition.max_nonce_log = input.max_nonce_log

                session.add(definition)
                session.commit()

            except Exception, e:
                msg = 'Could not update the OAuth definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise
            else:
                input.action = SECURITY.OAUTH_EDIT
                input.old_name = old_name
                input.sec_type = SEC_DEF_TYPE.OAUTH
                self.broker_client.publish(input)

                self.response.payload.id = definition.id
                self.response.payload.name = definition.name

class ChangePassword(ChangePasswordBase):
    """ Changes the password of an OAuth definition.
    """
    password_required = False

    class SimpleIO(ChangePasswordBase.SimpleIO):
        request_elem = 'zato_security_oauth_change_password_request'
        response_elem = 'zato_security_oauth_change_password_response'

    def handle(self):
        def _auth(instance, password):
            instance.password = password

        return self._handle(OAuth, _auth, SECURITY.OAUTH_CHANGE_PASSWORD)

class Delete(AdminService):
    """ Deletes an OAuth definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_oauth_delete_request'
        response_elem = 'zato_security_oauth_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                auth = session.query(OAuth).\
                    filter(OAuth.id==self.request.input.id).\
                    one()

                session.delete(auth)
                session.commit()
            except Exception, e:
                msg = 'Could not delete the OAuth definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise
            else:
                self.request.input.action = SECURITY.OAUTH_DELETE
                self.request.input.name = auth.name
                self.broker_client.publish(self.request.input)

########NEW FILE########
__FILENAME__ = openstack
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc
from uuid import uuid4

# Zato
from zato.common import SEC_DEF_TYPE
from zato.common.broker_message import SECURITY
from zato.common.odb.model import Cluster, OpenStackSecurity
from zato.common.odb.query import openstack_security_list
from zato.server.service.internal import AdminService, AdminSIO, ChangePasswordBase

class GetList(AdminService):
    """ Returns a list of OpenStack definitions available.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_openstack_get_list_request'
        response_elem = 'zato_security_openstack_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'username')

    def get_data(self, session):
        return openstack_security_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)

class Create(AdminService):
    """ Creates a new OpenStack definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_openstack_create_request'
        response_elem = 'zato_security_openstack_create_response'
        input_required = ('cluster_id', 'name', 'is_active', 'username')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        input.password = uuid4().hex
        
        with closing(self.odb.session()) as session:
            try:
                cluster = session.query(Cluster).filter_by(id=input.cluster_id).first()
                
                # Let's see if we already have a definition of that name before committing
                # any stuff into the database.
                existing_one = session.query(OpenStackSecurity).\
                    filter(Cluster.id==input.cluster_id).\
                    filter(OpenStackSecurity.name==input.name).first()

                if existing_one:
                    raise Exception('OpenStack definition [{0}] already exists on this cluster'.format(input.name))
                
                auth = OpenStackSecurity(None, input.name, input.is_active, input.username, input.password, cluster)
                
                session.add(auth)
                session.commit()

            except Exception, e:
                msg = 'Could not create an OpenStack definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise 
            else:
                input.action = SECURITY.OPENSTACK_CREATE
                input.sec_type = SEC_DEF_TYPE.OPENSTACK
                self.broker_client.publish(input)

            self.response.payload.id = auth.id
            self.response.payload.name = auth.name

class Edit(AdminService):
    """ Updates an OpenStack definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_openstack_edit_request'
        response_elem = 'zato_security_openstack_edit_response'
        input_required = ('id', 'cluster_id', 'name', 'is_active', 'username')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:
            try:
                existing_one = session.query(OpenStackSecurity).\
                    filter(Cluster.id==input.cluster_id).\
                    filter(OpenStackSecurity.name==input.name).\
                    filter(OpenStackSecurity.id!=input.id).\
                    first()

                if existing_one:
                    raise Exception('OpenStack definition [{0}] already exists on this cluster'.format(input.name))
                
                definition = session.query(OpenStackSecurity).filter_by(id=input.id).one()
                old_name = definition.name
                
                definition.name = input.name
                definition.is_active = input.is_active
                definition.username = input.username

                session.add(definition)
                session.commit()

            except Exception, e:
                msg = 'Could not update the OpenStack definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise 
            else:
                input.action = SECURITY.OPENSTACK_EDIT
                input.old_name = old_name
                input.sec_type = SEC_DEF_TYPE.OPENSTACK
                self.broker_client.publish(input)

                self.response.payload.id = definition.id
                self.response.payload.name = definition.name
    
class ChangePassword(ChangePasswordBase):
    """ Changes the password of an OpenStack definition.
    """
    password_required = False

    class SimpleIO(ChangePasswordBase.SimpleIO):
        request_elem = 'zato_security_openstack_change_password_request'
        response_elem = 'zato_security_openstack_change_password_response'
    
    def handle(self):
        def _auth(instance, password):
            instance.password = password
            
        return self._handle(OpenStackSecurity, _auth, SECURITY.OPENSTACK_CHANGE_PASSWORD)

class Delete(AdminService):
    """ Deletes an OpenStack definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_openstack_delete_request'
        response_elem = 'zato_security_openstack_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                auth = session.query(OpenStackSecurity).\
                    filter(OpenStackSecurity.id==self.request.input.id).\
                    one()

                session.delete(auth)
                session.commit()
            except Exception, e:
                msg = 'Could not delete the OpenStack definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise
            else:
                self.request.input.action = SECURITY.OPENSTACK_DELETE
                self.request.input.name = auth.name
                self.broker_client.publish(self.request.input)

########NEW FILE########
__FILENAME__ = tech_account
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc
from uuid import uuid4

# Zato
from zato.common import SEC_DEF_TYPE
from zato.common.broker_message import SECURITY
from zato.common.odb.model import Cluster, TechnicalAccount
from zato.common.odb.query import tech_acc_list
from zato.common.util import tech_account_password
from zato.server.service.internal import AdminService, AdminSIO, ChangePasswordBase

class GetList(AdminService):
    """ Returns a list of technical accounts defined in the ODB. The items are
    sorted by the 'name' attribute.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_tech_account_get_list_request'
        response_elem = 'zato_security_tech_account_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active')
        
    def get_data(self, session):
        return tech_acc_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)
    
class GetByID(AdminService):
    """ Returns a technical account of a given ID.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_tech_account_get_by_id_request'
        response_elem = 'zato_security_tech_account_get_by_id_response'
        input_required = ('id',)
        output_required = ('id', 'name', 'is_active')
        
    def get_data(self, session):
        return session.query(TechnicalAccount.id, 
            TechnicalAccount.name, TechnicalAccount.is_active).\
            filter(TechnicalAccount.id==self.request.input.id).\
            one()

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload = self.get_data(session)
    
class Create(AdminService):
    """ Creates a new technical account.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_tech_account_create_request'
        response_elem = 'zato_security_tech_account_create_response'
        input_required = ('cluster_id', 'name', 'is_active')
        output_required = ('id', 'name')

    def handle(self):
        salt = uuid4().hex
        input = self.request.input
        input.password = tech_account_password(uuid4().hex, salt)
        
        with closing(self.odb.session()) as session:
            cluster = session.query(Cluster).filter_by(id=input.cluster_id).first()
            
            # Let's see if we already have an account of that name before committing
            # any stuff into the database.
            existing_one = session.query(TechnicalAccount).\
                filter(Cluster.id==input.cluster_id).\
                filter(TechnicalAccount.name==input.name).first()
            
            if existing_one:
                raise Exception('Technical account [{0}] already exists on this cluster'.format(input.name))
            
            try:
                tech_account = TechnicalAccount(None, input.name, input.is_active, input.password, salt, cluster=cluster)
                session.add(tech_account)
                session.commit()
                
            except Exception, e:
                msg = 'Could not create a technical account, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise 
            else:
                input.action = SECURITY.TECH_ACC_CREATE
                input.password = input.password
                input.sec_type = SEC_DEF_TYPE.TECH_ACCOUNT
                self.broker_client.publish(input)
            
                self.response.payload.id = tech_account.id
                self.response.payload.name = tech_account.name

class Edit(AdminService):
    """ Updates an existing technical account.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_tech_account_edit_request'
        response_elem = 'zato_security_tech_account_edit_response'
        input_required = ('id', 'cluster_id', 'name', 'is_active')
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:
            existing_one = session.query(TechnicalAccount).\
                filter(Cluster.id==input.cluster_id).\
                filter(TechnicalAccount.name==input.name).\
                filter(TechnicalAccount.id!=input.id).\
                first()
            
            if existing_one:
                raise Exception('Technical account [{0}] already exists on this cluster'.format(input.name))
            
            tech_account = session.query(TechnicalAccount).\
                filter(TechnicalAccount.id==input.id).\
                one()
            old_name = tech_account.name
            
            tech_account.name = input.name
            tech_account.is_active = input.is_active

            try:
                session.add(tech_account)
                session.commit()

            except Exception, e:
                msg = "Could not update the technical account, e:[{e}]".format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise 
            else:
                input.action = SECURITY.TECH_ACC_EDIT
                input.old_name = old_name
                input.sec_type = SEC_DEF_TYPE.TECH_ACCOUNT
                self.broker_client.publish(input)
            
                self.response.payload.id = tech_account.id
                self.response.payload.name = tech_account.name
    
class ChangePassword(ChangePasswordBase):
    """ Changes the password of a technical account.
    """
    class SimpleIO(ChangePasswordBase.SimpleIO):
        request_elem = 'zato_security_tech_account_change_password_request'
        response_elem = 'zato_security_tech_account_change_password_response'
    
    def handle(self):
        salt = uuid4().hex
        
        def _auth(instance, password):
            instance.password = tech_account_password(password, salt)
            instance.salt = salt

        return self._handle(TechnicalAccount, _auth, 
                            SECURITY.TECH_ACC_CHANGE_PASSWORD, salt=salt)
    
class Delete(AdminService):
    """ Deletes a technical account.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_tech_account_delete_request'
        response_elem = 'zato_security_tech_account_delete_response'
        input_required = ('id',)
        input_optional = ('current_tech_account_name',)

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:
            tech_account = session.query(TechnicalAccount).\
                filter(TechnicalAccount.id==input.id).\
                one()
            
            if tech_account.name == input.current_tech_account_name:
                msg = "Can't delete account [{0}], at least one client console uses it".\
                    format(input.current_tech_account_name)
                raise Exception(msg)
            
            try:
                session.delete(tech_account)
                session.commit()
            except Exception, e:
                msg = 'Could not delete the account, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise
            else:
                input.action = SECURITY.TECH_ACC_DELETE
                input.name = tech_account.name
                self.broker_client.publish(input)

########NEW FILE########
__FILENAME__ = wss
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc
from uuid import uuid4

# Zato
from zato.common import SEC_DEF_TYPE
from zato.common.broker_message import SECURITY
from zato.common.odb.model import Cluster, WSSDefinition
from zato.common.odb.query import wss_list
from zato.server.service import Boolean, Integer
from zato.server.service.internal import AdminService, AdminSIO, ChangePasswordBase

class GetList(AdminService):
    """ Returns a list of WS-Security definitions available.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_wss_get_list_request'
        response_elem = 'zato_security_wss_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'password_type', 'username', 
            Boolean('reject_empty_nonce_creat'), Boolean('reject_stale_tokens'), Integer('reject_expiry_limit'), 
            Integer('nonce_freshness_time'))
        
    def get_data(self, session):
        return wss_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)

class Create(AdminService):
    """ Creates a new WS-Security definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_wss_create_request'
        response_elem = 'zato_security_wss_create_response'
        input_required = ('cluster_id', 'name', 'is_active', 'username', 
            'password_type', Boolean('reject_empty_nonce_creat'), Boolean('reject_stale_tokens'),
            Integer('reject_expiry_limit'), Integer('nonce_freshness_time'))
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        
        with closing(self.odb.session()) as session:
            cluster = session.query(Cluster).filter_by(id=input.cluster_id).first()
            # Let's see if we already have a definition of that name before committing
            # any stuff into the database.
            existing_one = session.query(WSSDefinition).\
                filter(Cluster.id==input.cluster_id).\
                filter(WSSDefinition.name==input.name).first()
            
            if existing_one:
                raise Exception('WS-Security definition [{0}] already exists on this cluster'.format(input.name))
            
            password = uuid4().hex
    
            try:
                wss = WSSDefinition(
                    None, input.name, input.is_active, input.username,
                    password, input.password_type, input.reject_empty_nonce_creat,
                    input.reject_stale_tokens, input.reject_expiry_limit, input.nonce_freshness_time,
                    cluster)
                
                session.add(wss)
                session.commit()
                
            except Exception, e:
                msg = "Could not create a WS-Security definition, e:[{e}]".format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise
            else:
                input.action = SECURITY.WSS_CREATE
                input.password = password
                input.sec_type = SEC_DEF_TYPE.WSS
                self.broker_client.publish(self.request.input)
            
            self.response.payload.id = wss.id
            self.response.payload.name = input.name

class Edit(AdminService):
    """ Updates a WS-S definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_wss_edit_request'
        response_elem = 'zato_security_wss_edit_response'
        input_required = (
            'id', 'cluster_id', 'name', 'is_active', 'username',
            'password_type', Boolean('reject_empty_nonce_creat'), Boolean('reject_stale_tokens'),
            Integer('reject_expiry_limit'), Integer('nonce_freshness_time'))
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:
            existing_one = session.query(WSSDefinition).\
                filter(Cluster.id==input.cluster_id).\
                filter(WSSDefinition.name==input.name).\
                filter(WSSDefinition.id!=input.id).\
                first()
            
            if existing_one:
                raise Exception('WS-Security definition [{0}] already exists on this cluster'.format(input.name))
            
            try:
                wss = session.query(WSSDefinition).filter_by(id=input.id).one()
                old_name = wss.name
                
                wss.name = input.name
                wss.is_active = input.is_active
                wss.username = input.username
                wss.password_type = input.password_type
                wss.reject_empty_nonce_creat = input.reject_empty_nonce_creat
                wss.reject_stale_tokens = input.reject_stale_tokens
                wss.reject_expiry_limit = input.reject_expiry_limit
                wss.nonce_freshness_time = input.nonce_freshness_time
    
                session.add(wss)
                session.commit()
                
            except Exception, e:
                msg = "Could not update the WS-Security definition, e:[{e}]".format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise
            else:
                input.action = SECURITY.WSS_EDIT
                input.old_name = old_name
                input.sec_type = SEC_DEF_TYPE.WSS
                self.broker_client.publish(self.request.input)
    
            self.response.payload.id = input.id
            self.response.payload.name = input.name
    
class ChangePassword(ChangePasswordBase):
    """ Changes the password of a WS-Security definition.
    """
    class SimpleIO(ChangePasswordBase.SimpleIO):
        request_elem = 'zato_security_wss_change_password_request'
        response_elem = 'zato_security_wss_change_password_response'
        
    def handle(self):
        def _auth(instance, password):
            instance.password = password
            
        return self._handle(WSSDefinition, _auth, SECURITY.WSS_CHANGE_PASSWORD)
    
class Delete(AdminService):
    """ Deletes a WS-Security definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_wss_delete_request'
        response_elem = 'zato_security_wss_delete_response'
        input_required = ('id',)

    def handle(self):
        
        with closing(self.odb.session()) as session:
            try:
                wss = session.query(WSSDefinition).\
                    filter(WSSDefinition.id==self.request.input.id).\
                    one()

                session.delete(wss)
                session.commit()
            except Exception, e:
                msg = "Could not delete the WS-Security definition, e:[{e}]".format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise
            else:
                self.request.input.action = SECURITY.WSS_DELETE
                self.request.input.name = wss.name
                self.broker_client.publish(self.request.input)

########NEW FILE########
__FILENAME__ = xpath
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from traceback import format_exc
from uuid import uuid4

# Zato
from zato.common import SEC_DEF_TYPE
from zato.common.broker_message import SECURITY
from zato.common.odb.model import Cluster, XPathSecurity
from zato.common.odb.query import xpath_sec_list
from zato.common.util import validate_xpath
from zato.server.service.internal import AdminService, AdminSIO, ChangePasswordBase

class GetList(AdminService):
    """ Returns a list of XPath security definitions available.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_xpath_get_list_request'
        response_elem = 'zato_security_xpath_get_list_response'
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'username', 'username_expr')
        output_optional = ('password_expr',)

    def get_data(self, session):
        return xpath_sec_list(session, self.request.input.cluster_id, False)

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)

class _CreateEdit(AdminService):
    """ A common class for both Create and Edit.
    """
    def validate_input(self):
        validate_xpath(self.request.input.username_expr)
        validate_xpath(self.request.input.get('password_expr') or '/')

class Create(_CreateEdit):
    """ Creates a new XPath security definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_xpath_create_request'
        response_elem = 'zato_security_xpath_create_response'
        input_required = ('cluster_id', 'name', 'is_active', 'username', 'username_expr')
        input_optional = ('password_expr',)
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        input.password = uuid4().hex

        with closing(self.odb.session()) as session:
            try:
                cluster = session.query(Cluster).filter_by(id=input.cluster_id).first()

                # Let's see if we already have a definition of that name before committing
                # any stuff into the database.
                existing_one = session.query(XPathSecurity).\
                    filter(Cluster.id==input.cluster_id).\
                    filter(XPathSecurity.name==input.name).first()

                if existing_one:
                    raise Exception('XPath security definition [{0}] already exists on this cluster'.format(input.name))

                auth = XPathSecurity()
                auth.name = input.name
                auth.is_active = input.is_active
                auth.username = input.username
                auth.password = input.password
                auth.username_expr = input.username_expr
                auth.password_expr = input.get('password_expr')
                auth.cluster_id = cluster.id

                session.add(auth)
                session.commit()

            except Exception, e:
                msg = 'Could not create an XPath security definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise 
            else:
                input.action = SECURITY.XPATH_SEC_CREATE
                input.sec_type = SEC_DEF_TYPE.XPATH_SEC
                self.broker_client.publish(input)

            self.response.payload.id = auth.id
            self.response.payload.name = auth.name

class Edit(_CreateEdit):
    """ Updates an XPath security definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_xpath_edit_request'
        response_elem = 'zato_security_xpath_edit_response'
        input_required = ('id', 'cluster_id', 'name', 'is_active', 'username', 'username_expr')
        input_optional = ('password_expr',)
        output_required = ('id', 'name')

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:
            try:
                existing_one = session.query(XPathSecurity).\
                    filter(Cluster.id==input.cluster_id).\
                    filter(XPathSecurity.name==input.name).\
                    filter(XPathSecurity.id!=input.id).\
                    first()

                if existing_one:
                    raise Exception('XPath security definition [{0}] already exists on this cluster'.format(input.name))
                
                auth = session.query(XPathSecurity).filter_by(id=input.id).one()
                old_name = auth.name

                auth.name = input.name
                auth.is_active = input.is_active
                auth.username = input.username
                auth.username_expr = input.username_expr
                auth.password_expr = input.get('password_expr')

                session.add(auth)
                session.commit()

            except Exception, e:
                msg = 'Could not update the XPath security definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise 
            else:
                input.action = SECURITY.XPATH_SEC_EDIT
                input.old_name = old_name
                input.sec_type = SEC_DEF_TYPE.XPATH_SEC
                self.broker_client.publish(input)

                self.response.payload.id = auth.id
                self.response.payload.name = auth.name

class ChangePassword(ChangePasswordBase):
    """ Changes the password of an XPath security definition.
    """
    password_required = False

    class SimpleIO(ChangePasswordBase.SimpleIO):
        request_elem = 'zato_security_xpath_change_password_request'
        response_elem = 'zato_security_xpath_change_password_response'

    def handle(self):
        def _auth(instance, password):
            instance.password = password
            
        return self._handle(XPathSecurity, _auth, SECURITY.XPATH_SEC_CHANGE_PASSWORD)

class Delete(AdminService):
    """ Deletes an XPath security definition.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_security_xpath_delete_request'
        response_elem = 'zato_security_xpath_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                auth = session.query(XPathSecurity).\
                    filter(XPathSecurity.id==self.request.input.id).\
                    one()

                session.delete(auth)
                session.commit()
            except Exception, e:
                msg = 'Could not delete the XPath security definition, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise
            else:
                self.request.input.action = SECURITY.XPATH_SEC_DELETE
                self.request.input.name = auth.name
                self.broker_client.publish(self.request.input)

########NEW FILE########
__FILENAME__ = server
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from datetime import datetime
from traceback import format_exc

# Bunch
from bunch import Bunch

# Zato
from zato.common import ZatoException
from zato.common.odb.model import Cluster, Server
from zato.server.service.internal import AdminService, AdminSIO

class ClusterWideSingletonKeepAlive(AdminService):
    """ Makes all the other servers know that this particular singleton, the one that
    manages the connectors and scheduler jobs, is indeed still alive.
    """
    def handle(self):
        s1, s2 = self.request.payload.split(';')
        server_id = int(s1.split(':')[1])
        cluster_id = int(s2.split(':')[1])
        
        with closing(self.odb.session()) as session:
            cluster = session.query(Cluster).\
                with_lockmode('update').\
                filter(Cluster.id == cluster_id).\
                one()
            
            server = session.query(Server).\
                filter(Server.id == server_id).\
                one()
            
            cluster.cw_srv_keep_alive_dt = datetime.utcnow()
            session.add(cluster)
            session.commit()

            msg = 'Cluster-wide singleton keep-alive OK, server id:[{}], name:[{}] '.format(server.id, server.name)
            self.logger.info(msg)

class EnsureClusterWideSingleton(AdminService):
    """ Initializes connectors and scheduler jobs.
    """
    def handle(self):
        if self.server.singleton_server:
            if self.server.singleton_server.is_cluster_wide:
                msg = 'Ignoring event, cid:[{}], server id:[{}], name:[{}], singleton is already cluster-wide'.format(
                    self.cid, self.server.id, self.server.name)
                self.logger.debug(msg)
            else:
                if self.server.singleton_server.become_cluster_wide(
                    self.server.connector_server_keep_alive_job_time, self.server.connector_server_grace_time,
                        self.server.id, self.server.cluster_id, False):
                    
                    self.server.singleton_server.scheduler.delete(Bunch(name='zato.server.ensure-cluster-wide-singleton'))
                    self.server.init_connectors()
                else:
                    msg = 'Not becoming a cluster-wide singleton, cid:[{}], server id:[{}], name:[{}]'.format(
                        self.cid, self.server.id, self.server.name)
                    self.logger.info(msg)
        else:
            msg = 'Ignoring event, cid:[{}], server id:[{}], name:[{}] has no singleton attached'.format(self.cid, self.server.id, self.server.name)
            self.logger.debug(msg)


class Edit(AdminService):
    """ Updates a server.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_server_edit_request'
        response_elem = 'zato_server_edit_response'
        input_required = ('id', 'name')
        output_required = ('id', 'cluster_id', 'name', 'host')
        output_optional = ('bind_host', 'bind_port', 'last_join_status', 
            'last_join_mod_date', 'last_join_mod_by', 'up_status', 'up_mod_date')

    def handle(self):
        with closing(self.odb.session()) as session:
            existing_one = session.query(Server).\
                filter(Server.id!=self.request.input.id).\
                filter(Server.name==self.request.input.name).\
                first()

            if existing_one:
                raise Exception('A server of that name [{0}] already exists on this cluster'.format(self.request.input.name))

            try:
                item = session.query(Server).filter_by(id=self.request.input.id).one()
                item.name = self.request.input.name

                session.add(item)
                session.commit()
                
                self.response.payload = item
                
            except Exception, e:
                msg = 'Could not update the server, id:[{}], e:[{}]'.format(self.request.input.id, format_exc(e))
                self.logger.error(msg)
                session.rollback()

                raise
            
class GetByID(AdminService):
    """ Returns a particular server
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_server_get_by_id_request'
        response_elem = 'zato_server_get_by_id_response'
        input_required = ('id',)
        output_required = ('id', 'cluster_id', 'name', 'host')
        output_optional = ('bind_host', 'bind_port', 'last_join_status', 
            'last_join_mod_date', 'last_join_mod_by', 'up_status', 'up_mod_date')
        
    def get_data(self, session):
        return session.query(Server).\
            filter(Server.id==self.request.input.id).\
            one()

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload = self.get_data(session)
            
            for name in('last_join_mod_date', 'up_mod_date'):
                attr = getattr(self.response.payload, name, None)
                if attr:
                    setattr(self.response.payload, name, attr.isoformat())

class Delete(AdminService):
    """ Deletes a server.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_server_delete_request'
        response_elem = 'zato_server_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                server = session.query(Server).\
                    filter(Server.id==self.request.input.id).\
                    one()
                
                # Sanity check
                if server.id == self.server.id:
                    msg = 'A server cannot delete itself, id:[{}], name:[{}]'.format(server.id, server.name)
                    self.logger.error(msg)
                    raise ZatoException(self.cid, msg)
                
                # This will cascade and delete every related object
                session.delete(server)
                session.commit()
                
            except Exception, e:
                session.rollback()
                msg = 'Could not delete the server, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                
                raise

########NEW FILE########
__FILENAME__ = service
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from httplib import BAD_REQUEST, NOT_FOUND
from mimetypes import guess_type
from tempfile import NamedTemporaryFile
from traceback import format_exc
from urlparse import parse_qs
from uuid import uuid4

# anyjson
from anyjson import loads

# validate
from validate import is_boolean

# Zato
from zato.common import BROKER, KVDB, ZatoException
from zato.common.broker_message import SERVICE
from zato.common.odb.model import Cluster, ChannelAMQP, ChannelWMQ, ChannelZMQ, \
     DeployedService, HTTPSOAP, Server, Service
from zato.common.odb.query import service_list
from zato.common.util import hot_deploy, payload_from_request
from zato.server.service import Boolean, Integer
from zato.server.service.internal import AdminService, AdminSIO

_no_such_service_name = uuid4().hex

class GetList(AdminService):
    """ Returns a list of services.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_service_get_list_request'
        response_elem = 'zato_service_get_list_response'
        input_required = ('cluster_id', 'name_filter')
        output_required = ('id', 'name', 'is_active', 'impl_name', 'is_internal', Boolean('may_be_deleted'), 
                           Integer('usage'), Integer('slow_threshold'))
        output_repeated = True
        default_value = ''
        
    def get_data(self, session):

        return_internal = is_boolean(self.server.fs_server_config.misc.return_internal_objects)
        internal_del = is_boolean(self.server.fs_server_config.misc.internal_services_may_be_deleted)

        out = []
        sl = service_list(session, self.request.input.cluster_id, return_internal, False)

        name_filter = self.request.input.get('name_filter')
        if name_filter:
            name_filter = [elem.strip().lower() for elem in name_filter.strip().split() if elem]
        else:
            name_filter = [_no_such_service_name] # So it matches nothing

        for item in sl:
            if self.request.input.name_filter != '*':
                skip_item = False
                for filter in name_filter:
                    if not filter in item.name.lower():
                        skip_item = True
                    
                if skip_item:
                    continue
            
            item.may_be_deleted = internal_del if item.is_internal else True
            item.usage = self.server.kvdb.conn.get('{}{}'.format(KVDB.SERVICE_USAGE, item.name)) or 0
            
            out.append(item)
        
        return out
        
    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)
        
class GetByName(AdminService):
    """ Returns a particular service.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_service_get_by_name_request'
        response_elem = 'zato_service_get_by_name_response'
        input_required = ('cluster_id', 'name')
        output_required = ('id', 'name', 'is_active', 'impl_name', 'is_internal', Boolean('may_be_deleted'),
            Integer('usage'), Integer('slow_threshold'), Integer('time_last'), 
            Integer('time_min_all_time'), Integer('time_max_all_time'), 'time_mean_all_time',)
        
    def get_data(self, session):
        return session.query(Service.id, Service.name, Service.is_active,
            Service.impl_name, Service.is_internal, Service.slow_threshold).\
            filter(Cluster.id==Service.cluster_id).\
            filter(Cluster.id==self.request.input.cluster_id).\
            filter(Service.name==self.request.input.name).\
            one()
        
    def handle(self):
        with closing(self.odb.session()) as session:
            service = self.get_data(session)
            internal_del = is_boolean(self.server.fs_server_config.misc.internal_services_may_be_deleted)
            
            self.response.payload.id = service.id
            self.response.payload.name = service.name
            self.response.payload.is_active = service.is_active
            self.response.payload.impl_name = service.impl_name
            self.response.payload.is_internal = service.is_internal
            self.response.payload.slow_threshold = service.slow_threshold
            self.response.payload.may_be_deleted = internal_del if service.is_internal else True
            self.response.payload.usage = self.server.kvdb.conn.get('{}{}'.format(KVDB.SERVICE_USAGE, service.name)) or 0

            time_key = '{}{}'.format(KVDB.SERVICE_TIME_BASIC, service.name)            
            self.response.payload.time_last = self.server.kvdb.conn.hget(time_key, 'last')
            
            for name in('min_all_time', 'max_all_time', 'mean_all_time'):
                setattr(self.response.payload, 'time_{}'.format(name), float(
                    self.server.kvdb.conn.hget(time_key, name) or 0))
                
            self.response.payload.time_min_all_time = int(self.response.payload.time_min_all_time)
            self.response.payload.time_max_all_time = int(self.response.payload.time_max_all_time)
            self.response.payload.time_mean_all_time = round(self.response.payload.time_mean_all_time, 1)

class Edit(AdminService):
    """ Updates a service.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_service_edit_request'
        response_elem = 'zato_service_edit_response'
        input_required = ('id', 'is_active', Integer('slow_threshold'))
        output_required = ('id', 'name', 'impl_name', 'is_internal', Boolean('may_be_deleted'))

    def handle(self):
        input = self.request.input
        with closing(self.odb.session()) as session:
            try:
                service = session.query(Service).filter_by(id=input.id).one()
                service.is_active = input.is_active
                service.slow_threshold = input.slow_threshold
                
                session.add(service)
                session.commit()
                
                input.action = SERVICE.EDIT
                input.impl_name = service.impl_name
                self.broker_client.publish(input)
                
                self.response.payload = service
                
                internal_del = is_boolean(self.server.fs_server_config.misc.internal_services_may_be_deleted)
                self.response.payload.may_be_deleted = internal_del if service.is_internal else True
                
            except Exception, e:
                msg = 'Could not update the service, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                session.rollback()
                
                raise         
            
class Delete(AdminService):
    """ Deletes a service
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_service_delete_request'
        response_elem = 'zato_service_delete_response'
        input_required = ('id',)

    def handle(self):
        with closing(self.odb.session()) as session:
            try:
                service = session.query(Service).\
                    filter(Service.id==self.request.input.id).\
                    one()

                internal_del = is_boolean(self.server.fs_server_config.misc.internal_services_may_be_deleted)
                
                if service.is_internal and not internal_del:
                    msg = "Can't delete service:[{}], it's an internal one and internal_services_may_be_deleted is not True".format(
                        service.name)
                    raise ZatoException(self.cid, msg)
                
                # This will also cascade to delete the related DeployedService objects
                session.delete(service)
                session.commit()

                msg = {'action': SERVICE.DELETE, 'id': self.request.input.id, 'impl_name':service.impl_name, 
                       'is_internal':service.is_internal}
                self.broker_client.publish(msg)
                
            except Exception, e:
                session.rollback()
                msg = 'Could not delete the service, e:[{e}]'.format(e=format_exc(e))
                self.logger.error(msg)
                
                raise

class GetChannelList(AdminService):
    """ Returns a list of channels of a given type through which the service
    is being exposed.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_service_get_channel_list_request'
        response_elem = 'zato_service_get_channel_list_response'
        input_required = ('id', 'channel_type')
        output_required = ('id', 'name')
        
    def handle(self):
        channel_type_class = {
            'plain_http': HTTPSOAP,
            'soap': HTTPSOAP,
            'amqp': ChannelAMQP,
            'jms-wmq': ChannelWMQ,
            'zmq': ChannelZMQ,
        }

        class_ = channel_type_class[self.request.input.channel_type]
        q_attrs = (class_.id, class_.name)
        
        with closing(self.odb.session()) as session:
            q = session.query(*q_attrs).\
                filter(class_.service_id == self.request.input.id)
            
            if self.request.input.channel_type == 'soap':
                q = q.filter(class_.soap_version != None) # noqa
            elif self.request.input.channel_type == 'plain_http':
                q = q.filter(class_.soap_version == None) # noqa
            
            self.response.payload[:] = q.all()
            
class Invoke(AdminService):
    """ Invokes the service directly, as though it was exposed through some channel
    which doesn't necessarily have to be true.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_service_invoke_request'
        response_elem = 'zato_service_invoke_response'
        input_optional = ('id', 'name', 'payload', 'channel', 'data_format', 'transport', 
            Boolean('async'), Integer('expiration'))
        output_optional = ('response',)

    def handle(self):
        payload = self.request.input.get('payload')
        if payload:
            payload = payload_from_request(self.cid, payload.decode('base64'), 
                self.request.input.data_format, self.request.input.transport)

        id = self.request.input.get('id')
        name = self.request.input.get('name')

        channel = self.request.input.get('channel')
        data_format = self.request.input.get('data_format')
        transport = self.request.input.get('transport')
        expiration = self.request.input.get('expiration') or BROKER.DEFAULT_EXPIRATION

        if name and id:
            raise ZatoException('Cannot accept both id:[{}] and name:[{}]'.format(id, name))

        if self.request.input.get('async'):
            if id:
                impl_name = self.server.service_store.id_to_impl_name[id]
                name = self.server.service_store.service_data(impl_name)['name']
            response = self.invoke_async(name, payload, channel, data_format, transport, expiration)
        else:

            func, id_ = (self.invoke, name) if name else (self.invoke_by_id, id)
            response = func(id_, payload, channel, data_format, transport, serialize=True)

        if isinstance(response, basestring):
            if response:
                self.response.payload.response = response.encode('base64') if response else ''

class GetDeploymentInfoList(AdminService):
    """ Returns detailed information regarding the service's deployment status
    on each of the servers it's been deployed to.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_service_get_deployment_info_list_request'
        response_elem = 'zato_service_get_deployment_info_list_response'
        input_required = ('id',)
        output_required = ('server_id', 'server_name', 'details')
        
    def get_data(self, session):
        return session.query(DeployedService.details,
            Server.name.label('server_name'), 
            Server.id.label('server_id')).\
            outerjoin(Server, DeployedService.server_id==Server.id).\
            filter(DeployedService.service_id==self.request.input.id).\
            all()
        
    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload[:] = self.get_data(session)
            
class GetSourceInfo(AdminService):
    """ Returns information on the service's source code.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_service_get_source_info_request'
        response_elem = 'zato_service_get_source_info_response'
        input_required = ('cluster_id', 'name')
        output_optional = ('service_id', 'server_name', 'source', 'source_path', 'source_hash', 'source_hash_method')
        
    def get_data(self, session):
        return session.query(Service.id.label('service_id'), Server.name.label('server_name'), 
            DeployedService.source, DeployedService.source_path,
            DeployedService.source_hash, DeployedService.source_hash_method).\
            filter(Cluster.id==Service.cluster_id).\
            filter(Cluster.id==self.request.input.cluster_id).\
            filter(Service.name==self.request.input.name).\
            filter(Service.id==DeployedService.service_id).\
            filter(Server.id==DeployedService.server_id).\
            filter(Server.id==self.server.id).\
            one()
        
    def handle(self):
        with closing(self.odb.session()) as session:
            si = self.get_data(session)
            self.response.payload.service_id = si.service_id
            self.response.payload.server_name = si.server_name
            self.response.payload.source = si.source.encode('base64') if si.source else None
            self.response.payload.source_path = si.source_path
            self.response.payload.source_hash = si.source_hash
            self.response.payload.source_hash_method = si.source_hash_method

class GetWSDL(AdminService):
    """ Returns a WSDL for the given service. Either uses a user-uploaded one,
    or, optionally generates one on fly if the service uses SimpleIO.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_service_get_wsdl_request'
        response_elem = 'zato_service_get_wsdl_response'
        input_optional = ('service', 'cluster_id')
        output_required = ('content_type',)
        output_optional = ('wsdl', 'wsdl_name',)

    def handle(self):
        if self.wsgi_environ['QUERY_STRING']:
            use_sio = False
            query = parse_qs(self.wsgi_environ['QUERY_STRING'])
            service_name = query.get('service', (None,))[0]
            cluster_id = query.get('cluster_id', (None,))[0]
        else:
            use_sio = True
            service_name = self.request.input.service
            cluster_id = self.request.input.cluster_id
            
        if not(service_name and cluster_id):
            msg = 'Both [service] and [cluster_id] parameters are required'
            if use_sio:
                raise ValueError(msg)
            else:
                self.response.status_code = BAD_REQUEST
                self.response.payload = msg
                return
        
        with closing(self.odb.session()) as session:
            service = session.query(Service).\
                filter_by(name=service_name, cluster_id=cluster_id).\
                first()
            
            if not service:
                self.response.status_code = NOT_FOUND
                self.response.payload = 'Service [{}] not found'.format(service_name)
                return
            
        if service.wsdl_name:
            content_type = guess_type(service.wsdl_name)[0] or 'application/octet-stream'
        else:
            content_type = 'text/plain'
            
        if use_sio:
            self.response.payload.wsdl = (service.wsdl or '').encode('base64')
            self.response.payload.wsdl_name = service.wsdl_name
            self.response.payload.content_type = content_type
        else:
            if service.wsdl:
                self.set_attachment(service.wsdl_name, service.wsdl, content_type)
            else:
                self.response.status_code = NOT_FOUND
                self.response.payload = 'No WSDL found'
                    
    def set_attachment(self, attachment_name, payload, content_type):
        """ Sets the information that we're returning an attachment to the user.
        """
        self.response.content_type = content_type
        self.response.payload = payload
        self.response.headers['Content-Disposition'] = 'attachment; filename={}'.format(attachment_name)            
            
class SetWSDL(AdminService):
    """ Updates the service's WSDL.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_service_set_wsdl_request'
        response_elem = 'zato_service_set_wsdl_response'
        input_required = ('cluster_id', 'name', 'wsdl', 'wsdl_name')
        
    def handle(self):
        with closing(self.odb.session()) as session:
            service = session.query(Service).\
                filter_by(name=self.request.input.name, cluster_id=self.request.input.cluster_id).\
                one()
            service.wsdl = self.request.input.wsdl.decode('base64')
            service.wsdl_name = self.request.input.wsdl_name
            
            session.add(service)
            session.commit()
            
class HasWSDL(AdminService):
    """ Returns a boolean flag indicating whether the server has a WSDL attached.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_service_has_wsdl_request'
        response_elem = 'zato_service_has_wsdl_response'
        input_required = ('name', 'cluster_id')
        output_required = ('service_id', 'has_wsdl',)
        
    def handle(self):
        with closing(self.odb.session()) as session:
            result = session.query(Service.id, Service.wsdl).\
                filter_by(name=self.request.input.name, cluster_id=self.request.input.cluster_id).\
                one()
            self.response.payload.service_id = result.id
            self.response.payload.has_wsdl = result.wsdl is not None

class GetRequestResponse(AdminService):
    """ Returns a sample request/response along with information on how often
    the pairs should be stored in the DB.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_service_get_request_response_request'
        response_elem = 'zato_service_request_response_response'
        input_required = ('cluster_id', 'name')
        output_required = ('service_id', Integer('sample_req_resp_freq'))
        output_optional = ('sample_cid', 'sample_req_ts', 'sample_resp_ts', 'sample_req', 'sample_resp', )
        
    def get_data(self):
        result = {}
        
        with closing(self.odb.session()) as session:
            result['id'] = session.query(Service.id).\
                filter_by(name=self.request.input.name, cluster_id=self.request.input.cluster_id).\
                one()[0]
        
        result.update(**self.kvdb.conn.hgetall('{}{}'.format(KVDB.REQ_RESP_SAMPLE, self.request.input.name)))
        
        return result
        
    def handle(self):
        result = self.get_data()
        self.response.payload.service_id = result.get('id')
        self.response.payload.sample_cid = result.get('cid')
        self.response.payload.sample_req_ts = result.get('req_ts')
        self.response.payload.sample_resp_ts = result.get('resp_ts')
        self.response.payload.sample_req = result.get('req', '').encode('base64')
        self.response.payload.sample_resp = result.get('resp', '').encode('base64')
        self.response.payload.sample_req_resp_freq = result.get('freq', 0)

class ConfigureRequestResponse(AdminService):
    """ Updates the request/response-related configuration.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_service_configure_request_response_request'
        response_elem = 'zato_service_configure_request_response_response'
        input_required = ('cluster_id', 'name', Integer('sample_req_resp_freq'))
        
    def handle(self):
        key = '{}{}'.format(KVDB.REQ_RESP_SAMPLE, self.request.input.name)
        self.kvdb.conn.hset(key, 'freq', self.request.input.sample_req_resp_freq)
            
class UploadPackage(AdminService):
    """ Returns a boolean flag indicating whether the server has a WSDL attached.
    """
    class SimpleIO(AdminSIO):
        request_elem = 'zato_service_upload_package_request'
        response_elem = 'zato_service_upload_package_response'
        input_required = ('cluster_id', 'payload', 'payload_name')
        
    def handle(self):
        with NamedTemporaryFile(prefix='zato-hd-', suffix=self.request.input.payload_name) as tf:
            tf.write(self.request.input.payload.decode('base64'))
            tf.flush()

            hot_deploy(self.server, self.request.input.payload_name, tf.name, False)
            
class _SlowResponseService(AdminService):
    def get_data(self):
        data = []
        cid_needed = self.request.input.cid if 'cid' in self.SimpleIO.input_required else None
        key = '{}{}'.format(KVDB.RESP_SLOW, self.request.input.name)
        
        for item in self.kvdb.conn.lrange(key, 0, -1):
            item = loads(item)
            
            if cid_needed and cid_needed != item['cid']:
                continue
            
            elem = {}
            for name in('cid', 'req_ts', 'resp_ts', 'proc_time'):
                elem[name] = item[name]
                
            if cid_needed and cid_needed == item['cid']:
                for name in('req', 'resp'):
                    elem[name] = item.get(name, '')
                    
            data.append(elem)

        return data
            
class GetSlowResponseList(_SlowResponseService):
    """ Returns a list of basic information regarding slow responses of a given service.
    """
    @staticmethod
    def get_name():
        return 'zato.service.slow-response.get-list'
        
    class SimpleIO(AdminSIO):
        request_elem = 'zato_service_slow_response_get_list_request'
        response_elem = 'zato_service_slow_response_get_list_response'
        input_required = ('name',)
        output_required = ('cid', 'req_ts', 'resp_ts', Integer('proc_time'))
        
    def handle(self):
        self.response.payload[:] = self.get_data()    
        
class GetSlowResponse(_SlowResponseService):
    """ Returns information regading a particular slow response of a service.
    """
    @staticmethod
    def get_name():
        return 'zato.service.slow-response.get'
        
    class SimpleIO(AdminSIO):
        request_elem = 'zato_service_slow_response_get_request'
        response_elem = 'zato_service_slow_response_get_response'
        input_required = ('cid', 'name')
        output_optional = ('cid', 'req_ts', 'resp_ts', Integer('proc_time'), 'req', 'resp')
    
    def handle(self):
        data = self.get_data()
        if data:
            self.response.payload = data[0]

########NEW FILE########
__FILENAME__ = summary
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from calendar import monthrange
from copy import deepcopy
from datetime import date, datetime, timedelta
from itertools import chain
from sys import maxint

# Bunch
from bunch import Bunch

# dateutil
from dateutil.parser import parse
from dateutil.relativedelta import relativedelta, MO, SU
from dateutil.rrule import DAILY, HOURLY, MINUTELY, MONTHLY, YEARLY

# paodate
from paodate import Date

# SciPy
from scipy import stats as sp_stats

# Zato
from zato.common import KVDB, StatsElem, ZatoException
from zato.server.service import Integer, UTC
from zato.server.service.internal.stats import BaseAggregatingService, STATS_KEYS, StatsReturningService, \
    stop_excluding_rrset

# ##############################################################################

DEFAULT_STATS = {k:0 for k in STATS_KEYS}
DEFAULT_STATS['mean'] = []
DEFAULT_STATS['min'] = maxint

class DT_PATTERNS(object):
    CURRENT_YEAR_START = '%Y-01-01'
    CURRENT_MONTH_START = '%Y-%m-01'
    CURRENT_DAY_START = '%Y-%m-%d 00:00:00'
    
    CURRENT_HOUR_END = '%Y-%m-%d %H:59:59'
    
    PREVIOUS_HOUR_START = '%Y-%m-%d %H:00:00'
    
    PREVIOUS_YEAR_END = '%Y'
    PREVIOUS_MONTH_END = '%Y-%m'
    PREVIOUS_DAY_END = '%Y-%m-%d 23:59:59'
    
    SUMMARY_SUFFIX_PATTERNS = {
        'by-day': '%Y:%m:%d',
        'by-week': '%Y:%m:%d',
        'by-month': '%Y:%m',
        'by-year': '%Y',
    }
    
# ##############################################################################

class SummarySlice(object):
    """ A convenience wrapper for returning slices a given time range should be
    sliced into when returning summaries across arbitrary time ranges.
    """
    def __init__(self, slice_type, start, stop):
        self.slice_type = slice_type
        self.start = start
        self.stop = stop
        self.total_seconds = (self.stop - self.start).total_seconds()
        
    def __repr__(self):
        return '<{} at {} slice_type:[{}], start:[{}], stop:[{}], total_seconds:[{}]>'.format(
            self.__class__.__name__, hex(id(self)), self.slice_type, self.start.isoformat(), 
            self.stop.isoformat(), self.total_seconds)
    
class SliceStats(object):
    """ A wrapper for combining statistics and how many seconds they represent.
    """
    def __init__(self, slice_type, stats, start, stop, total_seconds):
        self.slice_type = slice_type
        self.start = start
        self.stop = stop
        self.stats = stats
        self.total_seconds = total_seconds
        
    def __repr__(self):
        return '<{} at {} slice_type:[{}], stats:[{}], start:[{}], stop:[{}], total_seconds:[{}]>'.format(
            self.__class__.__name__, hex(id(self)), self.slice_type, self.stats, self.start, self.stop, 
            self.total_seconds)

# ##############################################################################

class BaseSummarizingService(BaseAggregatingService):
    """ Base class for services creating summaries.
    """
    def get_minutely_suffixes(self, now, start=None, stop=None):
        if not start:
            start = parse((now - timedelta(hours=1)).strftime(DT_PATTERNS.PREVIOUS_HOUR_START))
        if not stop:
            stop = parse(now.strftime(DT_PATTERNS.CURRENT_HOUR_END))
            
        return (elem.strftime('%Y:%m:%d:%H:%M') for elem in stop_excluding_rrset(MINUTELY, start, stop))
    
    def get_hourly_suffixes(self, now, start=None, stop=None):
        if not start:
            start = parse(now.strftime(DT_PATTERNS.CURRENT_DAY_START))
        if not stop:
            stop = parse((now - timedelta(hours=2)).strftime(DT_PATTERNS.PREVIOUS_HOUR_START))
        
        return (elem.strftime('%Y:%m:%d:%H') for elem in stop_excluding_rrset(HOURLY, start, stop))
    
    def get_daily_suffixes(self, now, start=None, stop=None):
        if not start:
            start = parse(now.strftime(DT_PATTERNS.CURRENT_MONTH_START))
        if not stop:
            stop = parse((now - timedelta(days=1)).strftime(DT_PATTERNS.PREVIOUS_DAY_END))
        
        return (elem.strftime('%Y:%m:%d') for elem in stop_excluding_rrset(DAILY, start, stop))
    
    def get_monthly_suffixes(self, now, start=None, stop=None):
        if not start:
            start = parse(now.strftime(DT_PATTERNS.CURRENT_YEAR_START))
        if not stop:
            delta = relativedelta(now, months=1)
            stop = parse((start - delta).strftime(DT_PATTERNS.PREVIOUS_MONTH_END))
        
        return (elem.strftime('%Y:%m') for elem in stop_excluding_rrset(MONTHLY, start, stop))
        
    def get_yearly_suffixes(self, now, start=None, stop=None):
        if not start:
            start = parse(now.strftime(DT_PATTERNS.CURRENT_YEAR_START))
        if not stop:
            delta = relativedelta(now, years=1)
            stop = parse((start - delta).strftime(DT_PATTERNS.PREVIOUS_YEAR_END))
        
        return (elem.strftime('%Y') for elem in stop_excluding_rrset(YEARLY, start, stop))
    
    def _get_patterns(self, now, start, stop, kvdb_key, method):
        return ('{}*:{}'.format(kvdb_key, elem) for elem in method(now, start, stop))
    
    def get_by_minute_patterns(self, now, start=None, stop=None):
        return self._get_patterns(now, start, stop, KVDB.SERVICE_TIME_AGGREGATED_BY_MINUTE, self.get_minutely_suffixes)
    
    def get_by_hour_patterns(self, now, start=None, stop=None):
        return self._get_patterns(now, start, stop, KVDB.SERVICE_TIME_AGGREGATED_BY_HOUR, self.get_hourly_suffixes)
    
    def get_by_day_patterns(self, now, start=None, stop=None):
        return self._get_patterns(now, start, stop, KVDB.SERVICE_TIME_AGGREGATED_BY_DAY, self.get_daily_suffixes)
    
    def get_by_month_patterns(self, now, start=None, stop=None):
        return self._get_patterns(now, start, stop, KVDB.SERVICE_TIME_AGGREGATED_BY_MONTH, self.get_monthly_suffixes)
    
    def create_summary(self, target, *pattern_names):
        now = datetime.utcnow()
        key_prefix = KVDB.SERVICE_SUMMARY_PREFIX_PATTERN.format(target)
        
        if target == 'by-week':
            start = parse((now + relativedelta(weekday=MO(-1))).strftime('%Y-%m-%d 00:00:00')) # Current week start
            key_suffix = start.strftime(DT_PATTERNS.SUMMARY_SUFFIX_PATTERNS[target])
        else:
            start = parse(now.strftime('%Y-%m-%d 00:00:00')) # Current day start
            key_suffix = now.strftime(DT_PATTERNS.SUMMARY_SUFFIX_PATTERNS[target])
        total_seconds = (now - start).total_seconds()
        
        patterns = []
        for name in pattern_names:
            patterns.append(getattr(self, 'get_by_{}_patterns'.format(name))(now))
        
        services = {}
        
        for elem in chain(*patterns):
            prefix, suffix = elem.split('*')
            suffix = suffix[1:]
            stats = self.collect_service_stats(elem, prefix, suffix, None, False, False, False)
            
            for service_name, values in stats.items():
                stats = services.setdefault(service_name, deepcopy(DEFAULT_STATS))
                
                for name in STATS_KEYS:
                    value = values[name]
                    if name == 'usage':
                        stats[name] += value
                    elif name == 'max':
                        stats[name] = max(stats[name], value)
                    elif name == 'mean':
                        stats[name].append(value)
                    elif name == 'min':
                        stats[name] = min(stats[name], value)
                        
        for service_name, values in services.items():
            values['mean'] = round(sp_stats.tmean(values['mean']), 2)
            values['rate'] = round(values['usage'] / total_seconds, 2)
            
        self.hset_aggr_keys(services, key_prefix, key_suffix)
        
# ##############################################################################

class CreateSummaryByDay(BaseSummarizingService):
    """ Creates a summary for the current day.
    """
    def handle(self):
        self.create_summary('by-day', 'hour', 'minute')

class CreateSummaryByWeek(BaseSummarizingService):
    def handle(self):
        self.create_summary('by-week', 'day', 'hour', 'minute')

class CreateSummaryByMonth(BaseSummarizingService):
    def handle(self):
        self.create_summary('by-month', 'day', 'hour', 'minute')

class CreateSummaryByYear(BaseSummarizingService):
    def handle(self):
        self.create_summary('by-year', 'month', 'day', 'hour', 'minute')
        
# ##############################################################################

class GetSummaryBase(StatsReturningService):
    """ A base class for returning the summary of statistics for a given period.
    """
    class SimpleIO(StatsReturningService.SimpleIO):
        input_required = (UTC('start'), Integer('n'), 'n_type')
        
    stats_key_prefix = None
    
    def get_start_date(self):
        return self.request.input.start
    
    def get_end_date(self, start):
        raise NotImplementedError('Should be implemented by subclasses')

    def get_suffixes(self, start, _ignored):
        # Note that the caller expects a list of patterns while a summary is for
        # a concrete date. Hence we're returning a one-element list to make everyone happy.
        return [start.strftime(DT_PATTERNS.SUMMARY_SUFFIX_PATTERNS[self.summary_type])]
    
    def handle(self):
        self.response.payload[:] = (elem.to_dict() for elem in self.get_stats(
            self.get_start_date(), self.get_end_date(self.request.input.start), 
            n=self.request.input.n, n_type=self.request.input.n_type, needs_trends=False))

class GetSummaryByDay(GetSummaryBase):
    class SimpleIO(GetSummaryBase.SimpleIO):
        request_elem = 'zato_stats_get_summary_by_day_request'
        response_elem = 'zato_stats_get_summary_by_day_response'

    summary_type = 'by-day'
    stats_key_prefix = KVDB.SERVICE_SUMMARY_BY_DAY
    
    def get_end_date(self, start):
        if start == date.today().isoformat():
            return datetime.utcnow().isoformat()
        else:
            return '{}T23:59:59'.format(start)

class GetSummaryByWeek(GetSummaryBase):
    class SimpleIO(GetSummaryBase.SimpleIO):
        request_elem = 'zato_stats_get_summary_by_week_request'
        response_elem = 'zato_stats_get_summary_by_week_response'
    
    summary_type = 'by-week'
    stats_key_prefix = KVDB.SERVICE_SUMMARY_BY_WEEK
    
    def get_start_date(self):
        """ Find the nearest Monday preceding the start date given on input.
        """
        return (parse(self.request.input.start) + relativedelta(weekday=MO(-1))).strftime('%Y-%m-%d')
    
    def get_end_date(self, start):
        start = parse(start)
        today = date.today()
        
        # Is it the current week?
        if start.year == today.year and start.isocalendar()[1] == today.isocalendar()[1]:
            return datetime.utcnow().isoformat()
            
        # It's not the current one, find Sunday nearest to the start
        else:
            return (start + relativedelta(weekday=SU(+1))).strftime('%Y-%m-%d 23:59:59')
    
class GetSummaryByMonth(GetSummaryBase):
    class SimpleIO(GetSummaryBase.SimpleIO):
        request_elem = 'zato_stats_get_summary_by_month_request'
        response_elem = 'zato_stats_get_summary_by_month_response'

    summary_type = 'by-month'
    stats_key_prefix = KVDB.SERVICE_SUMMARY_BY_MONTH
    
    def get_end_date(self, start):
        if start == date.today().strftime('%Y-%m'):
            return datetime.utcnow().isoformat()
        else:
            start = parse(start)
            return '{0}-{1:0>2}-{2}T23:59:59'.format(start.year, start.month, monthrange(start.year, start.month)[1])

class GetSummaryByYear(GetSummaryBase):
    class SimpleIO(GetSummaryBase.SimpleIO):
        request_elem = 'zato_stats_get_summary_by_year_request'
        response_elem = 'zato_stats_get_summary_by_year_response'
    
    summary_type = 'by-year'
    stats_key_prefix = KVDB.SERVICE_SUMMARY_BY_YEAR

    def get_end_date(self, start):
        if date.today().isoformat().startswith(start):
            return datetime.utcnow().isoformat()
        else:
            return '{}-12-31T23:59:59'.format(start)

class GetSummaryByRange(StatsReturningService, BaseSummarizingService):
    """ Returns a summary of statistics across a range of UTC start and stop parameters.
    """
    class SimpleIO(GetSummaryBase.SimpleIO):
        request_elem = 'zato_stats_get_summary_by_range_request'
        response_elem = 'zato_stats_get_summary_by_range_response'
        input_required = GetSummaryBase.SimpleIO.input_required + (UTC('stop'),)
    
    MINIMUM_DIFFERENCE = 3 # In minutes
    SLICE_TYPE_METHOD = {
        KVDB.SERVICE_TIME_AGGREGATED_BY_MINUTE: 'minutely',
        KVDB.SERVICE_TIME_AGGREGATED_BY_HOUR: 'hourly',
        KVDB.SERVICE_SUMMARY_BY_DAY: 'daily',
        KVDB.SERVICE_SUMMARY_BY_MONTH: 'monthly',
        KVDB.SERVICE_SUMMARY_BY_YEAR: 'yearly',
    }
    
    def by_minutes(self, start, stop):
        return SummarySlice(KVDB.SERVICE_TIME_AGGREGATED_BY_MINUTE, start, stop)
        
    def by_hours(self, start, stop):
        return SummarySlice(KVDB.SERVICE_TIME_AGGREGATED_BY_HOUR, start, stop)
        
    def by_days(self, start, stop):
        return SummarySlice(KVDB.SERVICE_SUMMARY_BY_DAY, start, stop)
        
    def by_months(self, start, stop):
        return SummarySlice(KVDB.SERVICE_SUMMARY_BY_MONTH, start, stop)
        
    def by_years(self, start, stop):
        return SummarySlice(KVDB.SERVICE_SUMMARY_BY_YEAR, start, stop)
        
    def _slice_with_inserted_hours(self, start, stop):
        """ start=2012-10-23T20:15:00, stop=2012-10-23T22:11:00
        or start=2012-10-22T17:19:00, stop=2012-10-23T11:49:00
        
        We can extract three pieces in this case
        by-minutes 2012-10-23T20:15:00 - 2012-10-23T21:00:00
        by-hours   2012-10-23T21:00:00 - 2012-10-23T22:00:00
        by-minutes 2012-10-23T21:00:00 - 2012-10-23T22:11:00
        """
        slice_in_between_start = datetime(year=start.year, 
            month=start.month, day=start.day, hour=start.hour) + relativedelta(hours=1)
            
        slice_in_between_stop = datetime(year=stop.year, 
            month=stop.month, day=stop.day, hour=stop.hour)
    
        yield self.by_minutes(start, slice_in_between_start)
        yield self.by_hours(slice_in_between_start, slice_in_between_stop)
        yield self.by_minutes(slice_in_between_stop, stop)
        
    def _slice_full_start_hour(self, start, stop):
        """ start=2012-10-22T17:00:00 stop=2012-10-23T14:37:00
        (or start=2012-10-23T20:00:00, stop=2012-10-23T21:19:00)
        
        We slice it into two pieces
        by-hours   2012-10-11T20:00:00 - 2012-10-11T21:00:00
        by-minutes 2012-10-11T21:00:00 - 2012-10-11T21:19:00
        """
        stop_start_hour = datetime(year=stop.year, month=stop.month, day=stop.day, hour=stop.hour)
        yield self.by_hours(start, stop_start_hour)
        yield self.by_minutes(stop_start_hour, stop)
        
    def _get_slices_by_hours(self, start, stop, delta):
        """ Used when the difference between start and stop is less than one day.
        """
        if start.minute == 0:
            for slice in self._slice_full_start_hour(start, stop):
                yield slice
        else:
            if delta.hours == 1:
                if delta.minutes == 0:
                    # start=2012-10-23T20:00:00, stop=2012-10-23T21:00:00
                    yield self.by_hours(start, stop)
                else:
                    if stop.hour - start.hour == 2:
                        # start=2012-10-23T20:15:00, stop=2012-10-23T22:11:00
                        for slice in self._slice_with_inserted_hours(start, stop):
                            yield slice
                    else:
                        # start=2012-10-23T20:15:00, stop=2012-10-23T21:37:00
                        # There's nothing we can do except slicing it up by minutes
                        yield self.by_minutes(start, stop)
            else:
                # start=2012-10-22T17:19:00, stop=2012-10-23T11:49:00
                for slice in self._slice_with_inserted_hours(start, stop):
                    yield slice
                    
    def _get_slices_by_days(self, start, stop, delta):
        """ start=2012-12-02T19:17:00, stop=2013-01-19T17:19:00
        """
        slice_in_between_start = datetime(year=start.year, month=start.month, day=start.day) + relativedelta(days=1)
        slice_in_between_stop = datetime(year=stop.year, month=stop.month, day=stop.day)
    
        if start.hour or start.minute:
            for slice in self._get_slices_by_hours(start, slice_in_between_start, relativedelta(
                                                       start, slice_in_between_start)):
                yield slice
                
            yield self.by_days(slice_in_between_start, slice_in_between_stop)
            
        else:
            # It's a midnight
            yield self.by_days(start, slice_in_between_stop)
    
        for slice in self._get_slices_by_hours(slice_in_between_stop, stop, relativedelta(slice_in_between_stop, stop)):
            yield slice
            
    def _get_slices_by_months(self, start, stop, delta):
        """ start=2012-11-02T19:17:00, stop=2013-01-19T17:19:00
        """
        slice_in_between_start = datetime(year=start.year, month=start.month, day=1) + relativedelta(months=1)
        slice_in_between_stop = datetime(year=stop.year, month=stop.month, day=1)
    
        if start.day != 1:
            for slice in self._get_slices_by_days(start, slice_in_between_start, relativedelta(
                                                      start, slice_in_between_start)):
                yield slice
                
            yield self.by_months(slice_in_between_start, slice_in_between_stop)
            
        else:
            # First day of a month
            yield self.by_months(start, slice_in_between_stop)
    
        for slice in self._get_slices_by_days(slice_in_between_stop, stop, relativedelta(slice_in_between_stop, stop)):
            yield slice
            
    def _get_slices_by_years(self, start, stop, delta):
        """ start=2012-05-07T19:43:00, stop=2014-11-23T21:19:00
        """
        slice_in_between_start = datetime(year=start.year, month=1, day=1) + relativedelta(years=1)
        slice_in_between_stop = datetime(year=stop.year, month=1, day=1)
    
        for slice in self._get_slices_by_months(start, slice_in_between_start, relativedelta(start, slice_in_between_start)):
            yield slice
            
        yield self.by_years(slice_in_between_start, slice_in_between_stop)
    
        for slice in self._get_slices_by_months(slice_in_between_stop, stop, relativedelta(slice_in_between_stop, stop)):
            yield slice
            
    def _get_slice_period_type(self, start, stop, orig_start, orig_stop):
        """ Returns information regarding whether a given period should be sliced
        by minutes, hours, days, months and/or years.
        """
        start = Date(start)
        stop = Date(stop)
        
        if start > stop:
            msg = 'start:[{}] must not be greater than stop:[{}]'.format(orig_start, orig_stop)
            raise ZatoException(self.cid, msg)
        
        delta = stop - start

        by_mins = False
        by_hours_mins = False
        by_days_hours_mins = False
        by_months_days_hours_mins = False
        
        by_mins = delta.total_minutes <= 60
        by_hours_mins = delta.total_minutes > 60
        by_days_hours_mins = delta.total_days > 1
        by_months_days_hours_mins = delta.total_months > 1
        
        if any((by_days_hours_mins, by_months_days_hours_mins)):
            by_hours_mins = False
        
        if by_months_days_hours_mins:
            by_days_hours_mins = False
            
        return delta, {
            'by_mins': by_mins, 
            'by_hours_mins': by_hours_mins, 
            'by_days_hours_mins': by_days_hours_mins, 
            'by_months_days_hours_mins': by_months_days_hours_mins,
        }
    
    def get_slices(self, orig_start, orig_stop):
        """ Slices the time range into a series of per-minute/-hour/-day/-month or -year statistics.
        """
        slices = []
        start = parse(orig_start)
        stop = parse(orig_stop)
        
        delta, result = self._get_slice_period_type(start, stop, orig_start, orig_stop)
        
        by_mins = result['by_mins']
        by_hours_mins = result['by_hours_mins']
        by_days_hours_mins = result['by_days_hours_mins']
        by_months_days_hours_mins = result['by_months_days_hours_mins']
        
        # Sanity check, find out whether more than one predicate is True.
        predicates = (by_mins, by_hours_mins, by_days_hours_mins, by_months_days_hours_mins)
        sum_preds = sum(int(elem) for elem in predicates)
        if sum_preds > 1:
            msg = 'sum:[{}] of predicates:[{}] is > 1, delta:[{}, {} {} {} {}], start:[{}], stop:[{}]'.format(
                sum_preds, predicates, delta, delta.years, delta.months, delta.days, delta.hours, start, stop)
            raise ZatoException(self.cid, msg)
        
        # We require that start and stop be at least that many minutes apart and, obviosuly,
        # that start lives farther in the past.
        if by_mins and delta.total_minutes < self.MINIMUM_DIFFERENCE:
            raise ValueError(
                'stop and start must be at least [{}] minutes apart, start must be '
                'farther in past; start:[{}], stop:[{}]'.format(
                   self.MINIMUM_DIFFERENCE, orig_start, orig_stop))
                   
        if by_mins:
            # start=2012-10-23T20:13:00, stop=2012-10-23T21:07:00
            slices.append(self.by_minutes(start, stop))
            
        elif by_hours_mins:
            for slice in self._get_slices_by_hours(start, stop, delta):
                slices.append(slice)
                        
        elif by_days_hours_mins or (by_months_days_hours_mins and delta.total_months == 1):
            for slice in self._get_slices_by_days(start, stop, delta):
                slices.append(slice)
                
        elif by_months_days_hours_mins:
            for slice in self._get_slices_by_months(start, stop, delta):
                slices.append(slice)
                
        else:
            for slice in self._get_slices_by_years(start, stop, delta):
                slices.append(slice)
            
        return slices
    
    def merge_slices(self, slices, n=None, n_type=None):
        """ Merges a list of stats slices into a single aggregated elem.
        """
        all_services_stats = Bunch({'usage':0, 'time':0, 'mean':0})
        total_seconds = 0.0
        merged_stats_elems = {}

        for slice in slices:

            seen_repeated_stats = False
            total_seconds += slice.total_seconds
            
            if slice.stats:
                
                for stats_elem in slice.stats:
                    # Each slice has a list of per-service stats. Each of the statistics
                    # has certain data repeated hence it's required we pick this data
                    # once only.
                    if not seen_repeated_stats:
                        all_services_stats.time += stats_elem.all_services_time
                        all_services_stats.usage += stats_elem.all_services_usage
                        seen_repeated_stats = True

                    # Fetch an existing elem or assign a new one
                    merged_stats_elem = merged_stats_elems.setdefault(stats_elem.service_name, StatsElem(stats_elem.service_name))

                    # Total time spent by this service and its total usage
                    merged_stats_elem.time += stats_elem.time
                    merged_stats_elem.usage += stats_elem.usage
                    all_services_stats.mean += stats_elem.mean
                    
                    # Minimum and maximum execution time 
                    merged_stats_elem.min_resp_time = min(merged_stats_elem.min_resp_time, stats_elem.min_resp_time)
                    merged_stats_elem.max_resp_time = max(merged_stats_elem.max_resp_time, stats_elem.max_resp_time)
                    
                    # Temporary data, will be divided by total_seconds later on,
                    # after collecting all the stats.
                    merged_stats_elem.temp_rate += slice.total_seconds * stats_elem.rate
                    
                    # Temporary data, aggregated later on
                    merged_stats_elem.temp_mean += stats_elem.mean
                    merged_stats_elem.temp_mean_count += 1

        if merged_stats_elems:
            mean_all_services = all_services_stats.mean / len(merged_stats_elems)
        else:
            mean_all_services = 0
                
        for value in merged_stats_elems.values():
            
            value.all_services_time = all_services_stats.time
            value.all_services_usage = all_services_stats.usage
            value.time = round(value.time, 1)
            
            if total_seconds:
                value.rate = round(value.temp_rate / total_seconds, 1)
                value.rate = round(value.temp_rate / total_seconds, 1)
                value.mean_all_services = mean_all_services
                
                if value.temp_mean:
                    value.mean = round(value.temp_mean / value.temp_mean_count)
                    
                self.set_percent_of_all_services(all_services_stats, value)
        
        if n:
            for stats_elem in self.yield_top_n(int(n), n_type, merged_stats_elems):
                yield stats_elem
        else:
            for stats_elem in merged_stats_elems.values():
                yield stats_elem
    
    def handle(self):
        
        start = self.request.input.start
        stop = self.request.input.stop
        
        self.logger.debug('Getting slices for start:[{}], stop:[{}]'.format(start, stop))
        
        slices = []
        
        for slice in self.get_slices(start, stop):
            if slice.total_seconds:

                get_suffixes_method = getattr(self, 'get_{}_suffixes'.format(self.SLICE_TYPE_METHOD[slice.slice_type]))
                suffixes = tuple(get_suffixes_method(None, slice.start, slice.stop))
                
                start_iso = slice.start.isoformat()
                stop_iso = slice.stop.isoformat()
                
                stats = self.get_stats(start_iso, stop_iso, needs_trends=False, stats_key_prefix=slice.slice_type, suffixes=suffixes)
                slices.append(SliceStats(slice.slice_type, stats, start_iso, stop_iso, slice.total_seconds))

        self.response.payload[:] = [elem.to_dict() for elem in 
            self.merge_slices(slices, self.request.input.n, self.request.input.n_type) if elem]

########NEW FILE########
__FILENAME__ = trends
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Zato
from zato.server.service import Integer
from zato.server.service.internal.stats import StatsReturningService

class GetTrends(StatsReturningService):
    """ Returns top N slowest or most commonly used services for a given period
    along with their trends.
    """
    class SimpleIO(StatsReturningService.SimpleIO):
        request_elem = 'zato_stats_get_trends_request'
        response_elem = 'zato_stats_get_trends_response'
        input_required = StatsReturningService.SimpleIO.input_required + (Integer('n'), 'n_type')

    def handle(self):
        self.response.payload[:] = (elem.to_dict() for elem in self.get_stats(self.request.input.start, 
            self.request.input.stop, n=int(self.request.input.n), n_type=self.request.input.n_type))

########NEW FILE########
__FILENAME__ = sio
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from copy import deepcopy
from datetime import datetime
from httplib import OK
from itertools import chain
from sys import maxint
from traceback import format_exc

# anyjson
from anyjson import dumps, loads

# Bunch
from bunch import Bunch, bunchify

# Django
from django.http import QueryDict

# lxml
from lxml import etree
from lxml.etree import _Element as EtreeElement
from lxml.objectify import deannotate, Element, ElementMaker

# Paste
from paste.util.converters import asbool

# retools
from retools.lock import Lock, LockTimeout as RetoolsLockTimeout

# SQLAlchemy
from sqlalchemy.util import NamedTuple

# Zato
from zato.common import BROKER, CHANNEL, DATA_FORMAT, KVDB, NO_DEFAULT_VALUE, PARAMS_PRIORITY, ParsingException, \
     path, SIMPLE_IO, TRACE1, URL_TYPE, ZatoException, ZATO_NONE, ZATO_OK
from zato.common.broker_message import SERVICE
from zato.common.util import uncamelify, make_repr, new_cid, service_name_from_impl
from zato.server.connection import request_response, slow_response
from zato.server.connection.amqp.outgoing import PublisherFacade
from zato.server.connection.jms_wmq.outgoing import WMQFacade
from zato.server.connection.zmq_.outgoing import ZMQFacade
from zato.server.message import MessageFacade

logger = logging.getLogger(__name__)

NOT_GIVEN = 'ZATO_NOT_GIVEN'

# ################################################################################################################################

class ValidationException(ZatoException):
    def __init__(self, name, value, missing_elem, template):
        self.name = name
        self.value = value
        self.missing_elem = missing_elem
        super(ValidationException, self).__init__(None, template.format(self.name, self.value, self.missing_elem))

# ################################################################################################################################

class ForceType(object):
    """ Forces a SimpleIO element to use a specific data type.
    """
    def __init__(self, name, *args, **kwargs):
        self.name = name
        self.args = args
        self.kwargs = kwargs

        self.default = kwargs.get('default', NO_DEFAULT_VALUE)

        #
        # Key - bool/data_type,
        # - bool is True if this is a conversion from SIO to external data, False in the other direction
        # - data_type is one of DATA_TYPE
        #
        # Value - method to invoke to de-/serialize given value
        #
        self.serialize_dispatch = {
            (False, DATA_FORMAT.JSON): self.from_json,
            (False, DATA_FORMAT.DICT): self.from_json,
            (False, DATA_FORMAT.XML): self.from_xml,

            (True, DATA_FORMAT.JSON): self.to_json,
            (True, DATA_FORMAT.DICT): self.to_json,
            (True, DATA_FORMAT.XML): self.to_xml,
        }

    def __repr__(self):
        return '<{} at {} name:[{}]>'.format(self.__class__.__name__, hex(id(self)), self.name)

    def from_json(self, value):
        raise NotImplementedError('Subclasses should override it')

    def to_json(self, value):
        raise NotImplementedError('Subclasses should override it')

    def from_xml(self, value):
        raise NotImplementedError('Subclasses should override it')

    def to_xml(self, value):
        raise NotImplementedError('Subclasses should override it')

    def convert(self, value, param_name, data_type, from_sio_to_external):
        return self.serialize_dispatch[(from_sio_to_external, data_type)](value, param_name)

    def get_xml_dict(self, _dict, name):
        xml_dict = Element(name)

        for k, v in _dict.items():
            xml_item = Element('item')

            key = Element('key')
            value = Element('value')

            xml_item.key = key
            xml_item.value = value

            xml_item.key[-1] = k
            xml_item.value[-1] = v

            xml_dict.append(xml_item)

        return xml_dict

# ################################################################################################################################

class AsIs(ForceType):
    """ The object won't be converted by SimpleIO machinery even though normally
    it would've been, for instance, because its name is 'user_id' and should've
    been converted over to an int.
    """

# ################################################################################################################################

class Boolean(ForceType):
    """ Gets transformed into a bool object.
    """
    def from_json(self, value, *ignored):
        return asbool(value)

    from_xml = to_json = to_xml = from_json

# ################################################################################################################################

class CSV(ForceType):
    """ Gets transformed into a comma separated list of items.
    """
    def from_json(self, value, *ignored):
        return value.split(',')

    from_xml = from_json

    def to_json(self, value, *ignored):
        return ','.join(value) if isinstance(value, (list, tuple)) else value

    to_xml = to_json

# ################################################################################################################################

class Dict(ForceType):
    """ JSON dictionary or a key/value in XML.
    """
    def from_json(self, value, *ignored):
        if self.args:
            out = {}
            for key in self.args:
                v = value.get(key, self.default)
                if v == NO_DEFAULT_VALUE:
                    raise ValidationException(self.name, value, key, 'Dict [{}] [{}]  has no key [{}]')
                else:
                    out[key] = v

            return out
        else:
            return value

    to_json = from_json

    def from_xml(self, value, *ignored):
        _dict = {}
        for item in value.iterchildren():
            _dict[item.key.text] = item.value.text
        return _dict

    def to_xml(self, value, param_name):
        return self.get_xml_dict(value, param_name)

# ################################################################################################################################

class Float(ForceType):
    """ Gets transformed into a float object.
    """
    def from_json(self, value, *ignored):
        return float(value)

    from_xml = to_json = to_xml = from_json

# ################################################################################################################################

class Integer(ForceType):
    """ Gets transformed into an int object.
    """
    def from_json(self, value, *ignored):
        return int(value) if value else 0

    from_xml = to_json = to_xml = from_json

# ################################################################################################################################

class List(ForceType):
    """ Transformed into a list of items in JSON or a list of <item> elems in XML.
    """
    def from_json(self, value, *ignored):
        return value

    to_json = from_json

    def from_xml(self, value, *ignored):
        return [elem.text for elem in value.iterchildren()]

    def to_xml(self, value, param_name):
        wrapper = Element(param_name)
        for item_value in value:
            xml_item = Element('item')
            wrapper.append(xml_item)
            wrapper.item[-1] = item_value
        return wrapper

# ################################################################################################################################

class ListOfDicts(ForceType):
    """ Transformed into a list of dictionaries in JSON or a list of
     <my_list_of_dicts>
      <item_dict>
       <item>
         <key>key1</key>
         <value>value1</value>
       </item>
       <item>
         <key>key2</key>
         <value>value2</value>
       </item>
      </item_dict>
      <item_dict>
       <item>
         <key>key3</key>
         <value>value3</value>
       </item>
      </item_dict>
     <my_list_of_dicts>
    elems in XML.
    """
    def from_json(self, value, *ignored):
        return value

    to_json = from_json

    def from_xml(self, value, *ignored):
        list_of_dicts = []

        for item_dict in value.item_dict:
            _dict = {}
            for item in item_dict.iterchildren():
                _dict[item.key.text] = item.value.text
            list_of_dicts.append(_dict)

        return list_of_dicts

    def to_xml(self, value, param_name):
        wrapper = Element(param_name)

        for _dict in value:
            wrapper.append(self.get_xml_dict(_dict, 'dict'))

        return wrapper

# ################################################################################################################################

class Nested(ForceType):
    """ Allows for embedding arbitrary sub-elements, including simple strings, ForceType or other Nested elements.
    """

    def from_json(self, value, *ignored):
        return value

    to_json = from_json

    def __iter__(self):
        return iter(self.args)

# ################################################################################################################################

class Unicode(ForceType):
    """ Gets transformed into a unicode object.
    """
    def from_json(self, value, *ignored):
        return value if isinstance(value, unicode) else value.decode('utf-8')

    from_xml = to_json = to_xml = from_json

# ################################################################################################################################

class UTC(ForceType):
    """ Will have the timezone part removed.
    """
    def from_json(self, value, *ignored):
        return value.replace('+00:00', '')

    from_xml = to_json = to_xml = from_json

# ################################################################################################################################

class ServiceInput(Bunch):
    """ A Bunch holding the input to the service.
    """
    def deepcopy(self):
        return deepcopy(self)

# ################################################################################################################################

COMPLEX_VALUE = (Dict, List, ListOfDicts, Nested)

# ################################################################################################################################

def convert_sio(param, param_name, value, has_simple_io_config, is_xml, bool_parameter_prefixes, int_parameters, 
                int_parameter_suffixes, date_time_format=None, data_format=ZATO_NONE, from_sio_to_external=False):
    try:
        if any(param_name.startswith(prefix) for prefix in bool_parameter_prefixes) or isinstance(param, Boolean):
            value = asbool(value or None) # value can be an empty string and asbool chokes on that

        if value is not None:
            if isinstance(param, ForceType):
                value = param.convert(value, param_name, data_format, from_sio_to_external)
            else:
                if value and value != ZATO_NONE and has_simple_io_config:
                    if any(param_name==elem for elem in int_parameters) or \
                       any(param_name.endswith(suffix) for suffix in int_parameter_suffixes):
                        value = int(value)

        return value

    except Exception, e:
        msg = 'Conversion error, param:`{}`, param_name:`{}`, repr:`{}`, type:`{}`, e:`{}`'.format(
            param, param_name, repr(value), type(value), format_exc(e))
        logger.error(msg)

        raise ZatoException(msg=msg)

# ################################################################################################################################

class SIOConverter(object):
    """ A class which knows how to convert values into the types defined in a service's SimpleIO config.
    """
    def convert(self, *params):
        return convert_sio(*params)

# ################################################################################################################################

def convert_from_json(payload, param_name, cid, *ignored):
    return (payload or {}).get(param_name, NOT_GIVEN)

convert_from_dict = convert_from_json

def convert_from_xml(payload, param_name, cid, is_required, is_complex, default_value, path_prefix, use_text):
    try:
        elem = path('{}.{}'.format(path_prefix, param_name), is_required).get_from(payload)
    except ParsingException, e:
        msg = 'Caught an exception while parsing, payload:[<![CDATA[{}]]>], e:[{}]'.format(
            etree.tostring(payload), format_exc(e))
        raise ParsingException(cid, msg)

    if is_complex:
        value = elem
    else:
        if elem is not None:
            if use_text:
                value = elem.text # We are interested in the text the elem contains ..
            else:
                return elem # .. or in the elem itself.
        else:
            value = default_value

    return value

convert_impl = {
    DATA_FORMAT.JSON: convert_from_json,
    DATA_FORMAT.XML: convert_from_xml,
    DATA_FORMAT.DICT: convert_from_dict,
}

def convert_param(cid, payload, param, data_format, is_required, default_value, path_prefix, use_text, 
                  channel_params, has_simple_io_config, bool_parameter_prefixes, int_parameters, int_parameter_suffixes):
    """ Converts request parameters from any data format supported into Python objects.
    """
    param_name = param.name if isinstance(param, ForceType) else param
    value = convert_impl[data_format](payload, param_name, cid, is_required, isinstance(param, COMPLEX_VALUE), 
                                      default_value, path_prefix, use_text)

    if value == NOT_GIVEN:
        if default_value != NO_DEFAULT_VALUE:
            value = default_value
        else:
            if is_required and not channel_params.get(param_name):
                msg = 'Required input element:`{}` not found, value:`{}`, data_format:`{}`, payload:`{}`'.format(
                    param, value, data_format, payload)
                raise ParsingException(cid, msg)
            else:
                # Not required and not provided on input
                value = ''
    else:
        if value is not None and not isinstance(param, COMPLEX_VALUE):
            value = unicode(value)

        if not isinstance(param, AsIs):
            return param_name, convert_sio(param, param_name, value, has_simple_io_config, data_format==DATA_FORMAT.XML,
                bool_parameter_prefixes, int_parameters, int_parameter_suffixes, None, data_format, False)

    return param_name, value

########NEW FILE########
__FILENAME__ = store
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import imp, inspect, logging, os
from datetime import datetime
from hashlib import sha256
from importlib import import_module
from traceback import format_exc
from uuid import uuid4

# gevent
from gevent.lock import RLock

# pip
from pip.download import is_archive_file

# anyjson
from anyjson import dumps

# PyYAML
try:
    from yaml import CDumper  # Looks awkward but
    Dumper = CDumper          # it's to make import checkers happy
except ImportError:
    from yaml import Dumper   # ditto
    Dumper = Dumper
    
# Spring Python
from springpython.context import InitializingObject

# Zato
from zato.common import DONT_DEPLOY_ATTR_NAME, NoDistributionFound, SourceInfo, TRACE1
from zato.common.util import decompress, deployment_info, fs_safe_now, is_python_file, visit_py_source, \
     visit_py_source_from_distribution
from zato.server.service import Service
from zato.server.service.internal import AdminService

logger = logging.getLogger(__name__)

def get_service_name(class_obj):
    """ Return the name of a service which will be either given us explicitly
    via the 'name' attribute or it will be a concatenation of the name of the
    class and its module's name.
    """
    return getattr(class_obj, 'name', '%s.%s' % (class_obj.__module__, class_obj.__name__))

class ServiceStore(InitializingObject):
    """ A store of Zato services.
    """
    def __init__(self, services=None, service_store_config=None, odb=None):
        self.services = services
        self.service_store_config = service_store_config
        self.odb = odb
        self.id_to_impl_name = {}
        self.name_to_impl_name = {}
        self.update_lock = RLock()

    def _invoke_hook(self, object_, hook_name):
        """ A utility method for invoking various service's hooks.
        """
        try:
            hook = getattr(object_, hook_name)
            hook()
        except Exception:
            msg = 'Error while invoking [%s] on service [%s] ' \
                ' e:[%s]' % (hook_name, object_, format_exc())
            logger.error(msg)

    def new_instance(self, class_name):
        """ Returns a new instance of a service of the given impl name.
        """
        return self.services[class_name]['service_class']()

    def new_instance_by_id(self, service_id):
        impl_name = self.id_to_impl_name[service_id]
        return self.new_instance(impl_name)

    def new_instance_by_name(self, name):
        impl_name = self.name_to_impl_name[name]
        return self.new_instance(impl_name)

    def service_data(self, impl_name):
        """ Returns all the service-related data.
        """
        return self.services[impl_name]

    def decompress(self, archive, work_dir):
        """ Decompresses an archive into a randomly named directory.
        """
        # 6 characters will do, we won't deploy millions of services
        # in the very same (micro-)second after all
        rand = uuid4().hex[:6] 

        dir_name = os.path.join(work_dir, '{}-{}'.format(fs_safe_now(), rand), os.path.split(archive)[1])
        os.makedirs(dir_name)

        # .. unpack the archive into it ..
        decompress(archive, dir_name)

        # .. and return the name of the newly created directory so that the
        # rest of the machinery can pick the services up
        return dir_name

    def import_services_from_anywhere(self, items, base_dir, work_dir=None):
        """ Imports services from any of the supported sources, be it module names,
        individual files, directories or distutils2 packages (compressed or not).
        """
        for item_name in items:
            logger.debug('About to import services from:[%s]', item_name)

            is_internal = item_name.startswith('zato')

            # distutils2 archive, decompress and import from the newly created directory ..
            if is_archive_file(item_name):
                new_path = self.decompress(item_name, work_dir)
                self.import_services_from_dist2_directory(new_path)

            # .. a regular directory or a Distutils2 one ..
            elif os.path.isdir(item_name):
                try:
                    self.import_services_from_directory(item_name, base_dir, True)
                except NoDistributionFound, e:
                    msg = 'Caught an exception e=[{}]'.format(format_exc(e))
                    logger.log(TRACE1, msg)
                    self.import_services_from_directory(item_name, base_dir, False)

            # .. a .py/.pyw
            elif is_python_file(item_name):
                self.import_services_from_file(item_name, is_internal, base_dir)

            # .. must be a module object
            else:
                self.import_services_from_module(item_name, is_internal)

    def import_services_from_file(self, file_name, is_internal, base_dir):
        """ Imports all the services from the path to a file.
        """
        if not os.path.isabs(file_name):
            file_name = os.path.normpath(os.path.join(base_dir, file_name))

        if not os.path.exists(file_name):
            raise ValueError("Could not import services, path:[{}] doesn't exist".format(file_name))

        _, mod_file = os.path.split(file_name)
        mod_name, _ = os.path.splitext(mod_file)

        # Delete compiled bytecode if it exists so that imp.load_source 
        # actually picks up the source module
        for suffix in('c', 'o'):
            path = file_name + suffix
            if os.path.exists(path):
                os.remove(path)

        try:
            mod = imp.load_source(mod_name, file_name)
        except Exception, e:
            msg = 'Could not load source mod_name:[{}] file_name:[{}], e:[{}]'.format(
                mod_name, file_name, format_exc(e))
            logger.error(msg)
        else:
            self._visit_module(mod, is_internal, file_name)

    def import_services_from_directory(self, dir_name, base_dir, dist2):
        """ dir_name points to a directory. 

        If dist2 is True, the directory is assumed to be a Distutils2 one and its
        setup.cfg file is read and all the modules from packages pointed to by the 
        'files' section are scanned for services.

        If dist2 is False, this will be treated as a directory with a flat list
        of Python source code to import, as is the case with services that have
        been hot-deployed.
        """
        func = visit_py_source_from_distribution if dist2 else visit_py_source
        for py_path in func(dir_name):
            self.import_services_from_file(py_path, False, base_dir)

    def import_services_from_module(self, mod_name, is_internal):
        """ Imports all the services from a module specified by the given name.
        """
        mod = import_module(mod_name)
        self._visit_module(mod, is_internal, inspect.getfile(mod))

    def _should_deploy(self, name, item):
        """ Is an object something we can deploy on a server?
        """
        try:
            if issubclass(item, Service):
                if item is not AdminService and item is not Service:
                    if not hasattr(item, DONT_DEPLOY_ATTR_NAME):
                        return True
        except TypeError, e:
            # Ignore non-class objects passed in to issubclass
            logger.log(TRACE1, 'Ignoring exception, name:[{}], item:[{}], e:[{}]'.format(name, item, format_exc(e)))

    def _get_source_code_info(self, mod):
        """ Returns the source code of and the FS path to the given module.
        """
        si = SourceInfo()
        try:
            file_name = mod.__file__
            if file_name[-1] in('c', 'o'):
                file_name = file_name[:-1]

            # We would've used inspect.getsource(mod) hadn't it been apparently using
            # cached copies of the source code
            si.source = open(file_name, 'rb').read()
            
            si.path = inspect.getsourcefile(mod)
            si.hash = sha256(si.source).hexdigest()
            si.hash_method = 'SHA-256'

        except IOError, e:
            logger.log(TRACE1, 'Ignoring IOError, mod:[{}], e:[{}]'.format(mod, format_exc(e)))

        return si

    def _visit_module(self, mod, is_internal, fs_location):
        """ Actually imports services from a module object.
        """
        try:
            for name in sorted(dir(mod)):
                with self.update_lock:
                    item = getattr(mod, name)
                    if self._should_deploy(name, item):

                        should_add = item.before_add_to_store(logger)
                        if should_add:

                            timestamp = datetime.utcnow()#.isoformat()
                            depl_info = deployment_info('service-store', item, timestamp.isoformat(), fs_location)
                            name = item.get_name()
                            impl_name = item.get_impl_name()

                            self.services[impl_name] = {}
                            self.services[impl_name]['name'] = name
                            self.services[impl_name]['deployment_info'] = depl_info
                            self.services[impl_name]['service_class'] = item

                            si = self._get_source_code_info(mod)

                            service_id, is_active, slow_threshold = self.odb.add_service(
                                name, impl_name, is_internal, timestamp, dumps(str(depl_info)), si)

                            self.services[impl_name]['is_active'] = is_active
                            self.services[impl_name]['slow_threshold'] = slow_threshold

                            self.id_to_impl_name[service_id] = impl_name
                            self.name_to_impl_name[name] = impl_name

                            logger.debug('Imported service:[{}]'.format(name))

                            item.after_add_to_store(logger)

                        else:
                            msg = 'Skipping [{}] from [{}], should_add:[{}] is not True'.format(
                                item, fs_location, should_add)
                            logger.info(msg)
        except Exception, e:
            msg = 'Exception while visit mod:[{}], is_internal:[{}], fs_location:[{}], e:[{}]'.format(
                mod, is_internal, fs_location, format_exc(e))
            logger.error(msg)

if __name__ == '__main__':
    store = ServiceStore()
    store.import_services_from_directory('/home/dsuch/tmp/zato-sample-project1')

########NEW FILE########
__FILENAME__ = spring_context
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Bunch
from bunch import Bunch

# Spring Python
from springpython.config import Object, PythonConfig

# Zato
from zato.common import DEFAULT_STATS_SETTINGS, SIMPLE_IO, ZATO_CRYPTO_WELL_KNOWN_DATA
from zato.common.crypto import CryptoManager
from zato.common.delivery import DeliveryStore
from zato.common.kvdb import KVDB
from zato.server.base.parallel import ParallelServer
from zato.server.base.singleton import SingletonServer
from zato.server.connection.sql import PoolStore
from zato.server.odb import ODBManager
from zato.server.scheduler import Scheduler
from zato.server.service.store import ServiceStore

class ZatoContext(PythonConfig):

    # #######################################################
    # Crypto keys

    @Object
    def crypto_manager(self):
        return CryptoManager()

    # #######################################################
    # Services

    @Object
    def service_store(self):
        store = ServiceStore()
        store.odb = self.odb_manager()
        store.services = {}

        return store

    @Object
    def internal_service_modules(self):
        return [
            'zato.server.service.internal',
            'zato.server.service.internal.checks.sio',
            'zato.server.service.internal.channel.amqp',
            'zato.server.service.internal.channel.jms_wmq',
            'zato.server.service.internal.channel.zmq',
            'zato.server.service.internal.cloud.aws.s3',
            'zato.server.service.internal.cloud.openstack.swift',
            'zato.server.service.internal.definition.amqp',
            'zato.server.service.internal.definition.jms_wmq',
            'zato.server.service.internal.helpers',
            'zato.server.service.internal.hot_deploy',
            'zato.server.service.internal.info',
            'zato.server.service.internal.http_soap',
            'zato.server.service.internal.kvdb',
            'zato.server.service.internal.kvdb.data_dict.dictionary',
            'zato.server.service.internal.kvdb.data_dict.impexp',
            'zato.server.service.internal.kvdb.data_dict.translation',
            'zato.server.service.internal.message.namespace',
            'zato.server.service.internal.message.xpath',
            'zato.server.service.internal.message.json_pointer',
            'zato.server.service.internal.notif',
            'zato.server.service.internal.notif.cloud.openstack.swift',
            'zato.server.service.internal.outgoing.amqp',
            'zato.server.service.internal.outgoing.ftp',
            'zato.server.service.internal.outgoing.jms_wmq',
            'zato.server.service.internal.outgoing.sql',
            'zato.server.service.internal.outgoing.zmq',
            'zato.server.service.internal.pattern.delivery',
            'zato.server.service.internal.pattern.delivery.definition',
            'zato.server.service.internal.pubsub',
            'zato.server.service.internal.pubsub.consumers',
            'zato.server.service.internal.pubsub.message',
            'zato.server.service.internal.pubsub.producers',
            'zato.server.service.internal.pubsub.topics',
            'zato.server.service.internal.scheduler',
            'zato.server.service.internal.security',
            'zato.server.service.internal.security.apikey',
            'zato.server.service.internal.security.aws',
            'zato.server.service.internal.security.basic_auth',
            'zato.server.service.internal.security.ntlm',
            'zato.server.service.internal.security.oauth',
            'zato.server.service.internal.security.openstack',
            'zato.server.service.internal.security.tech_account',
            'zato.server.service.internal.security.wss',
            'zato.server.service.internal.security.xpath',
            'zato.server.service.internal.server',
            'zato.server.service.internal.service',
            'zato.server.service.internal.stats',
            'zato.server.service.internal.stats.summary',
            'zato.server.service.internal.stats.trends',
        ]

    @Object
    def service_modules(self):
        return []

    @Object
    def int_parameters(self):
        return SIMPLE_IO.INT_PARAMETERS.VALUES

    @Object
    def int_parameter_suffixes(self):
        return SIMPLE_IO.INT_PARAMETERS.SUFFIXES

    @Object
    def bool_parameter_prefixes(self):
        return SIMPLE_IO.BOOL_PARAMETERS.SUFFIXES

    # #######################################################
    # Delivery store

    @Object
    def delivery_store(self):
        return DeliveryStore(self.kvdb())

    # #######################################################
    # SQL

    @Object
    def odb_manager(self):
        return ODBManager(well_known_data=ZATO_CRYPTO_WELL_KNOWN_DATA)

    @Object
    def sql_pool_store(self):
        return PoolStore()

    # #######################################################
    # Key-value DB

    @Object
    def kvdb(self):
        return KVDB()

    # #######################################################
    # Channels

    @Object
    def soap11_content_type(self):
        return 'application/xml'

    @Object
    def soap12_content_type(self):
        return 'application/soap+xml; charset=utf-8' # We always require UTF-8

    @Object
    def plain_xml_content_type(self):
        return 'application/xml'

    @Object
    def json_content_type(self):
        return 'application/json'

    # #######################################################
    # Servers

    @Object
    def parallel_server(self):

        server = ParallelServer()
        server.odb = self.odb_manager()
        server.service_store = self.service_store()
        server.sql_pool_store = self.sql_pool_store()
        server.int_parameters = self.int_parameters()
        server.int_parameter_suffixes = self.int_parameter_suffixes()
        server.bool_parameter_prefixes = self.bool_parameter_prefixes()
        server.soap11_content_type = self.soap11_content_type()
        server.soap12_content_type = self.soap12_content_type()
        server.plain_xml_content_type = self.plain_xml_content_type()
        server.json_content_type = self.json_content_type()
        server.internal_service_modules = self.internal_service_modules()
        server.service_modules = self.service_modules()
        server.kvdb = self.kvdb()
        server.user_config = Bunch()

        return server

    @Object
    def singleton_server(self):
        server = SingletonServer()
        server.scheduler = self.scheduler()

        return server

    # #######################################################
    # Scheduler management

    @Object
    def scheduler(self):
        return Scheduler()

    @Object
    def startup_jobs(self):
        return [
            {'name': 'zato.stats.process-raw-times', 'seconds':90,
             'service':'zato.stats.process-raw-times',
             'extra':'max_batch_size={}'.format(DEFAULT_STATS_SETTINGS['scheduler_raw_times_batch'])},

            {'name': 'zato.stats.aggregate-by-minute', 'seconds':60,
             'service':'zato.stats.aggregate-by-minute'},

            {'name': 'zato.stats.aggregate-by-hour', 'minutes':10,
             'service':'zato.stats.aggregate-by-hour'},

            {'name': 'zato.stats.aggregate-by-day', 'minutes':60,
             'service':'zato.stats.aggregate-by-day'},

            {'name': 'zato.stats.aggregate-by-month', 'minutes':60,
             'service':'zato.stats.aggregate-by-month'},

            {'name': 'zato.stats.summary.create-summary-by-day', 'minutes':10,
             'service':'zato.stats.summary.create-summary-by-day'},

            {'name': 'zato.stats.summary.create-summary-by-week', 'minutes':10,
             'service':'zato.stats.summary.create-summary-by-week'},

            {'name': 'zato.stats.summary.create-summary-by-month', 'minutes':60,
             'service':'zato.stats.summary.create-summary-by-month'},

            {'name': 'zato.stats.summary.create-summary-by-year', 'minutes':60,
             'service':'zato.stats.summary.create-summary-by-year'},

            {'name': 'zato.pattern.delivery.update-counters', 'seconds':30,
             'service':'zato.pattern.delivery.update-counters'},

            {'name': 'zato.pattern.delivery.dispatch-auto-resubmit', 'seconds':300,
             'service':'zato.pattern.delivery.dispatch-auto-resubmit'},
        ]

########NEW FILE########
__FILENAME__ = stats
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from contextlib import closing
from datetime import datetime

# dateutil
from dateutil.rrule import MINUTELY, rrule

# Zato
from zato.common import KVDB, scheduler_date_time_format
from zato.common.odb.model import Job, IntervalBasedJob, Service

logger = logging.getLogger(__name__)
                
class MaintenanceTool(object):
    """ A tool for performing maintenance-related tasks, such as deleting the statistics.
    """
    def __init__(self, conn):
        self.conn = conn
        
    def delete(self, start, stop, interval):
        with self.conn.pipeline() as p:
            suffixes = (elem.strftime(':%Y:%m:%d:%H:%M') for elem in rrule(MINUTELY, dtstart=start, until=stop))
            for suffix in suffixes:
                for key in self.conn.keys('{}*{}'.format(KVDB.SERVICE_TIME_AGGREGATED_BY_MINUTE, suffix)):
                    p.delete(key)
                    
            p.execute()

########NEW FILE########
__FILENAME__ = test_parallel
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import httplib, os
from ast import literal_eval
from cStringIO import StringIO
from datetime import datetime
from hashlib import sha1
from json import loads
from pprint import pprint
from unittest import TestCase

# Bunch
from bunch import Bunch

# mock
from mock import patch

# nose
from nose.tools import eq_, ok_

# pytz
from pytz import timezone, UTC

# tzlocal
from tzlocal import get_localzone

# Zato
from zato.common import ACCESS_LOG_DT_FORMAT, CHANNEL, DATA_FORMAT, ZATO_NONE
from zato.common.broker_message import CHANNEL as CHANNEL_BROKER_MESSAGE, SERVICE
from zato.common.test import rand_int, rand_string
from zato.common.util import make_repr, new_cid, utcnow
from zato.server.connection.http_soap.channel import RequestDispatcher
from zato.server.connection.http_soap.url_data import URLData
from zato.server.base.parallel import ParallelServer
from zato.server.odb import ODBManager

# ################################################################################################################################

class FakeRequestDispatcher(object):
    def __init__(self, url_data=None, expected_payload=None):
        self.url_data = url_data
        self.expected_payload = expected_payload

    def dispatch(self, *ignored_args, **ignored_kwargs):
        return self.expected_payload

class FakeWorkerStore(object):
    def __init__(self, request_dispatcher=None):
        self.request_dispatcher = request_dispatcher or FakeRequestDispatcher()

class FakeGunicornSocket(object):
    def __init__(self, expected_cert_der, expected_cert_dict):
        self.expected_cert_der = expected_cert_der
        self.expected_cert_dict = expected_cert_dict

    def getpeercert(self, needs_der=False):
        if needs_der:
            return self.expected_cert_der
        return self.expected_cert_dict

    def __repr__(self):
        return self.__class__.__name__

class StartResponse(object):
    def __call__(self, *ignored_args, **ignored_kwargs):
        pass

# ################################################################################################################################

class ParallelServerTestCase(TestCase):
    def test__startup_services(self):

        class FakeBrokerClient(object):
            def __init__(self):
                self.messages = {}
                
            def invoke_async(self, msg):
                self.messages[msg['service']] = msg
                
        broker_client = FakeBrokerClient()
        
        startup_services = Bunch()
        for x in range(10):
            name =  rand_string()
            payload = rand_string()
            startup_services[name] = payload
        
        ps = ParallelServer()
        ps.broker_client = broker_client
        ps.fs_server_config = Bunch()
        ps.fs_server_config.startup_services = startup_services
        
        ps.invoke_startup_services()
        
        for expected_service, expected_payload in startup_services.items():
            msg = Bunch(broker_client.messages[expected_service])
            eq_(msg.action, SERVICE.PUBLISH)
            eq_(msg.channel, CHANNEL.STARTUP_SERVICE)
            eq_(msg.payload, expected_payload)
            eq_(msg.service, expected_service)
            ok_(msg.cid.startswith('K'))
            self.assertEquals(len(msg.cid), 28)
            
    def test__set_tls_info(self):

        expected_cert_dict = rand_string()
        expected_cert_der = rand_string()
        expected_cert_sha1 = sha1(expected_cert_der).hexdigest().upper()
        
        for wsgi_url_scheme in('https', 'http'):
            wsgi_environ = {
                'wsgi.url_scheme': wsgi_url_scheme,
                'gunicorn.socket': FakeGunicornSocket(expected_cert_der, expected_cert_dict),
                'zato.http.response.status': rand_string(),
                'zato.http.channel_item': Bunch(audit_enabled=False),
                'PATH_INFO': rand_string(),
                'REQUEST_METHOD': rand_string(),
                'SERVER_PROTOCOL': rand_string(),
                'HTTP_USER_AGENT': rand_string(),
            }
    
            ps = ParallelServer()
            ps.worker_store = FakeWorkerStore()
            ps.on_wsgi_request(wsgi_environ, StartResponse())
            
            if wsgi_url_scheme == 'https':
                eq_(wsgi_environ['zato.tls.client_cert.dict'], expected_cert_dict)
                eq_(wsgi_environ['zato.tls.client_cert.der'], expected_cert_der)
                eq_(wsgi_environ['zato.tls.client_cert.sha1'], expected_cert_sha1)
            else:
                self.assertTrue('zato.tls.client_cert.dict' not in wsgi_environ)
                self.assertTrue('zato.tls.client_cert.der' not in wsgi_environ)
                self.assertTrue('zato.tls.client_cert.sha1' not in wsgi_environ)

# ################################################################################################################################

class AuditTestCase(TestCase):
    def test_audit(self):
        for expected_audit_enabled in(True, False):
            for expected_status_code in(httplib.OK, httplib.FORBIDDEN):
                for use_x_remote_addr in(True, False):

                    expected_auth_ok = True if expected_status_code == httplib.OK else False
                    expected_invoke_ok  = True if expected_auth_ok is True else False

                    expected_cid = new_cid()
                    expected_url_scheme = rand_string()
                    expected_payload = rand_string()

                    expected_audit_repl_patt_type = rand_string()
                    expected_replace_patterns_json_pointer = []
                    expected_replace_patterns_xpath = []
                    expected_cluster_id = rand_int()
                    expected_id = rand_int()
                    expected_name = rand_string()
                    expected_password = '******'
                    expected_username = rand_string()
                    expected_transport = rand_string()
                    expected_connection = rand_string()
                    expected_data_format = DATA_FORMAT.JSON
                    expected_is_active = True
                    expected_request = rand_string()
                    expected_audit_max_payload = len(expected_request) - 7 # Substracting any value would do

                    expected_channel_item_key1 = rand_string()
                    expected_channel_item_value1 = rand_string()

                    expected_match_target = rand_string()

                    channel_item = {
                        'id': expected_id,
                        'name': expected_name,
                        'transport': expected_transport,
                        'connection': expected_connection,
                        'audit_enabled': expected_audit_enabled,
                        expected_channel_item_key1:expected_channel_item_value1,
                        'audit_repl_patt_type': expected_audit_repl_patt_type,
                        'replace_patterns_json_pointer': expected_replace_patterns_json_pointer,
                        'replace_patterns_xpath': expected_replace_patterns_xpath,
                        'audit_max_payload': expected_audit_max_payload,
                        'is_active': expected_is_active,
                        'data_format': DATA_FORMAT.JSON,
                        'match_target': expected_match_target,
                        'username': expected_username,
                    }

                    wsgi_environ = {
                        'wsgi.url_scheme': expected_url_scheme,
                        'gunicorn.socket': FakeGunicornSocket(None, None),
                        'zato.http.response.status': expected_status_code,
                        'zato.http.channel_item': channel_item,
                        'PATH_INFO': rand_string(),
                        'wsgi.input': StringIO(expected_request),
                        'REQUEST_METHOD': rand_string(),
                        'SERVER_PROTOCOL': rand_string(),
                        'HTTP_USER_AGENT': rand_string(),
                    }

                    expected_remote_addr = rand_string()

                    if use_x_remote_addr:
                        expected_remote_addr_header = 'HTTP_X_FORWARDED_FOR'
                        wsgi_environ[expected_remote_addr_header] = expected_remote_addr
                    else:
                        expected_remote_addr_header = 'REMOTE_ADDR'
                        wsgi_environ[expected_remote_addr_header] = expected_remote_addr

                    class FakeSession:
                        def __init__(self, audit=None):
                            self.audit = audit
                            self.commit_called = False

                        def close(self):
                            pass

                        def commit(self):
                            self.commit_called = True

                        def add(self, audit):
                            self.audit = audit

                    fake_session = FakeSession()

                    class FakeBrokerClient(object):
                        def __init__(self):
                            self.msg = None

                        def publish(self, msg):
                            self.msg = msg

                    class FakeODB(ODBManager):
                        def __init__(self):
                            self.msg = None
                            self.cluster = Bunch(id=expected_cluster_id)

                        def session(self):
                            return fake_session

                    class FakeURLData(URLData):
                        def __init__(self):
                            self.url_sec = {expected_match_target: Bunch(sec_def=ZATO_NONE)}

                        def match(self, *ignored_args, **ignored_kwargs):
                            return True, channel_item

                    class FakeRequestHandler(object):
                        def handle(self, *ignored_args, **ignored_kwargs):
                            return Bunch(payload=expected_payload, content_type='text/plain', headers={}, status_code=expected_status_code)

                    bc = FakeBrokerClient()
                    ws = FakeWorkerStore()
                    ws.request_dispatcher = RequestDispatcher()
                    ws.request_dispatcher.request_handler = FakeRequestHandler()
                    ws.request_dispatcher.url_data = FakeURLData()
                    ws.request_dispatcher.url_data.broker_client = bc
                    ws.request_dispatcher.url_data.odb = FakeODB()

                    ps = ParallelServer()
                    ps.worker_store = ws
                    ps.on_wsgi_request(wsgi_environ, StartResponse(), cid=expected_cid)

                    if expected_audit_enabled:

                        #
                        # Audit 1/2 - Request
                        #

                        # Parsing will confirm the proper value was used
                        datetime.strptime(fake_session.audit.req_time.isoformat(), '%Y-%m-%dT%H:%M:%S.%f')

                        self.assertEquals(fake_session.audit.name, expected_name)
                        self.assertEquals(fake_session.audit.cid, expected_cid)
                        self.assertEquals(fake_session.audit.transport, expected_transport)
                        self.assertEquals(fake_session.audit.connection, expected_connection)
                        self.assertEquals(fake_session.audit.resp_time, None)
                        self.assertEquals(fake_session.audit.user_token, expected_username)
                        self.assertEquals(fake_session.audit.auth_ok, None)
                        self.assertEquals(fake_session.audit.invoke_ok, None)
                        self.assertEquals(fake_session.audit.remote_addr, expected_remote_addr)
                        self.assertEquals(fake_session.audit.req_payload, expected_request[:expected_audit_max_payload])
                        self.assertEquals(fake_session.audit.resp_headers, None)
                        self.assertEquals(fake_session.audit.resp_payload, None)

                        req_headers = literal_eval(fake_session.audit.req_headers)

                        self.assertEquals(req_headers[expected_remote_addr_header], repr(expected_remote_addr))
                        self.assertEquals(req_headers['wsgi.url_scheme'], repr(expected_url_scheme))
                        self.assertEquals(req_headers['gunicorn.socket'], repr(FakeGunicornSocket(None, None)))

                        channel_item = literal_eval(req_headers['zato.http.channel_item'])

                        self.assertEquals(channel_item['audit_max_payload'], expected_audit_max_payload)
                        self.assertEquals(channel_item['name'], expected_name)
                        self.assertEquals(channel_item['username'], expected_username)
                        self.assertEquals(channel_item[expected_channel_item_key1], expected_channel_item_value1)
                        self.assertEquals(channel_item['audit_repl_patt_type'], expected_audit_repl_patt_type)
                        self.assertEquals(channel_item['replace_patterns_json_pointer'], expected_replace_patterns_json_pointer)
                        self.assertEquals(channel_item['is_active'], expected_is_active)
                        self.assertEquals(channel_item['data_format'], expected_data_format)
                        self.assertEquals(channel_item['audit_enabled'], expected_audit_enabled)
                        self.assertEquals(channel_item['password'], expected_password)
                        self.assertEquals(channel_item['transport'], expected_transport)
                        self.assertEquals(channel_item['match_target'], expected_match_target)

                        #
                        # Audit 2/2 - Response
                        #

                        self.assertEquals(bc.msg['action'], CHANNEL_BROKER_MESSAGE.HTTP_SOAP_AUDIT_RESPONSE)
                        self.assertEquals(bc.msg['cid'], expected_cid)
                        self.assertEquals(bc.msg['data_format'], DATA_FORMAT.JSON)
                        self.assertEquals(bc.msg['service'], 'zato.http-soap.set-audit-response-data')

                        payload = loads(bc.msg['payload'])

                        self.assertEquals(payload['auth_ok'], expected_auth_ok)
                        self.assertEquals(payload['invoke_ok'], expected_invoke_ok)
                        self.assertEquals(payload['resp_payload'], expected_payload)

                        # Parsing alone will check its format is valid
                        datetime.strptime(payload['resp_time'], '%Y-%m-%dT%H:%M:%S.%f')

                        wsgi_environ = loads(payload['resp_headers'])

                        self.assertEquals(wsgi_environ['wsgi.url_scheme'], repr(expected_url_scheme))
                        self.assertEquals(wsgi_environ['gunicorn.socket'], repr(FakeGunicornSocket(None, None)))
                        self.assertEquals(wsgi_environ['zato.http.response.status'],
                            "'{} {}'".format(
                                expected_status_code,
                                httplib.responses[expected_status_code],
                            ))

                        channel_item = literal_eval(wsgi_environ['zato.http.channel_item'])

                        self.assertEquals(channel_item[expected_channel_item_key1], expected_channel_item_value1)
                        self.assertEquals(channel_item['audit_enabled'], expected_audit_enabled)
                        self.assertEquals(channel_item['audit_repl_patt_type'], expected_audit_repl_patt_type)
                        self.assertEquals(channel_item['replace_patterns_json_pointer'], expected_replace_patterns_json_pointer)
                        self.assertEquals(channel_item['replace_patterns_xpath'], expected_replace_patterns_xpath)
                        self.assertEquals(channel_item['name'], expected_name)
                        self.assertEquals(channel_item['id'], expected_id)
                        self.assertEquals(channel_item['password'], expected_password)
                        self.assertEquals(channel_item['data_format'], expected_data_format)
                        self.assertEquals(channel_item['transport'], expected_transport)
                        self.assertEquals(channel_item['connection'], expected_connection)
                        self.assertEquals(channel_item['audit_max_payload'], expected_audit_max_payload)
                        self.assertEquals(channel_item['is_active'], expected_is_active)
                    else:
                        # Audit not enabled so no response audit message was published on the broker
                        self.assertTrue(bc.msg is None)

# ################################################################################################################################

class HTTPAccessLogTestCase(TestCase):
    def test_access_log(self):

        def _utcnow(self):
            return datetime(year=2014, month=1, day=12, hour=16, minute=22, second=12, tzinfo=UTC)

        local_tz = get_localzone()
        _now = _utcnow(None)

        local_dt = _now.replace(tzinfo=UTC).astimezone(local_tz)
        local_dt = local_tz.normalize(local_dt)

        request_timestamp = local_dt.strftime(ACCESS_LOG_DT_FORMAT)

        with patch('arrow.factory.ArrowFactory.utcnow', _utcnow):
            response = rand_string() * rand_int()
            cid = new_cid()
            cluster_id = 1

            channel_name = rand_string()
            url_path = '/{}'.format(rand_string())
            user_agent = rand_string()
            http_version = rand_string()
            request_method = rand_string()
            remote_ip = '10.{}.{}.{}'.format(rand_int(), rand_int(), rand_int())
            req_timestamp_utc = utcnow()

            channel_item = {
                'name': channel_name,
                'audit_enabled': False,
                'is_active': True,
                'transport': 'plain_http',
                'data_format': None,
                'match_target': url_path
            }

            wsgi_environ = {
                'gunicorn.socket': FakeGunicornSocket(None, None),
                'wsgi.url_scheme': 'http',
                'wsgi.input': StringIO(response),

                'zato.http.response.status': httplib.OK,
                'zato.http.channel_item': channel_item,
                'zato.request_timestamp_utc': req_timestamp_utc,

                'HTTP_X_FORWARDED_FOR': remote_ip,
                'PATH_INFO': url_path,
                'REQUEST_METHOD': request_method,
                'SERVER_PROTOCOL': http_version,
                'HTTP_USER_AGENT': user_agent,
            }

            class FakeBrokerClient(object):
                def __init__(self):
                    self.msg = None

                def publish(self, msg):
                    self.msg = msg

            class FakeODB(ODBManager):
                def __init__(self):
                    self.msg = None
                    self.cluster = Bunch(id=cluster_id)

                def session(self):
                    return fake_session

            class FakeURLData(URLData):
                def __init__(self):
                    self.url_sec = {url_path: Bunch(sec_def=ZATO_NONE)}

                def match(self, *ignored_args, **ignored_kwargs):
                    return True, channel_item

            class FakeRequestHandler(object):
                def handle(self, *ignored_args, **ignored_kwargs):
                    return Bunch(payload=response, content_type='text/plain', headers={}, status_code=httplib.OK)

            class FakeAccessLogger(object):
                def __init__(self):
                    self.extra = {}

                def info(self, msg, extra):
                    self.extra = extra

                def isEnabledFor(self, ignored):
                    return True

            bc = FakeBrokerClient()
            ws = FakeWorkerStore()
            ws.request_dispatcher = RequestDispatcher()
            ws.request_dispatcher.request_handler = FakeRequestHandler()
            ws.request_dispatcher.url_data = FakeURLData()
            ws.request_dispatcher.url_data.broker_client = bc
            ws.request_dispatcher.url_data.odb = FakeODB()

            ps = ParallelServer()
            ps.worker_store = ws
            ps.access_logger = FakeAccessLogger()
            ps.on_wsgi_request(wsgi_environ, StartResponse(), cid=cid)

            extra = Bunch(ps.access_logger.extra)

            eq_(extra.channel_name, channel_name)
            eq_(extra.user_agent, user_agent)
            eq_(extra.status_code, '200')
            eq_(extra.http_version, http_version)
            eq_(extra.response_size, len(response))
            eq_(extra.cid, cid)
            eq_(extra.path, url_path)
            eq_(extra.method, request_method)
            eq_(extra.remote_ip, remote_ip)
            eq_(extra.req_timestamp_utc, '12/Jan/2014:16:22:12 +0000')
            eq_(extra.req_timestamp, request_timestamp)

# ################################################################################################################################

########NEW FILE########
__FILENAME__ = test_channel
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from cStringIO import StringIO
from unittest import TestCase
from uuid import uuid4

# anyjson
from anyjson import loads

# arrow
import arrow

# Bunch
from bunch import Bunch

# lxml
from lxml import etree

# nose
from nose.tools import eq_

# Zato
from zato.common import CHANNEL, DATA_FORMAT, SIMPLE_IO, URL_PARAMS_PRIORITY, \
     URL_TYPE, zato_namespace, ZATO_NONE, ZATO_OK
from zato.common.util import new_cid
from zato.server.connection.http_soap import channel
from zato.server.service.internal import AdminService, Service

# ##############################################################################

# Tokyo
NON_ASCII_STRING = ''

NS_MAP = {
    'zato': zato_namespace,
    'soap': 'http://schemas.xmlsoap.org/soap/envelope/'
}

# ##############################################################################

class DummyPayload(object):
    def __init__(self, value):
        self.value = value

    def getvalue(self, *ignored_args, **ignored_kwargs):
        return self.value

class DummyResponse(object):
    def __init__(self, payload, result=ZATO_OK, result_details=''):
        self.payload = payload
        self.result = result
        self.result_details = result_details if result_details else uuid4().hex

class DummyService(Service):
    def __init__(self, response=None, cid=None):
        self.response = response
        self.cid = cid if cid else new_cid()

class DummyAdminService(DummyService, AdminService):
    class SimpleIO:
        response_elem = 'zzz'
        namespace = zato_namespace

class DummySecurity(object):
    def url_sec_get(self, *ignored_args, **ignored_kwargs):
        pass

class DummyURLData(object):
    def __init__(self, match_return_value, channel_item_return_value):
        self.match_return_value = match_return_value
        self.channel_item_return_value = channel_item_return_value
        self.cid = None
        self.channel_item = None
        self.path_info = None
        self.payload = None
        self.wsgi_environ = None
        self.url_sec = {}

    def match(self, *ignored_args, **ignored_kwargs):
        return self.match_return_value, self.channel_item_return_value

    def check_security(self, sec, cid, channel_item, path_info, payload, wsgi_environ, post_data):
        self.sec = sec
        self.cid = cid
        self.channel_item = channel_item
        self.path_info = path_info
        self.payload = payload
        self.wsgi_environ = wsgi_environ
        self.post_data = post_data

# ##############################################################################

class MessageHandlingBase(TestCase):
    """ Base class for tests for functionality common to SOAP and plain HTTP messages.
    """
    def get_data(self, data_format, transport, add_string=NON_ASCII_STRING, needs_payload=True,
            payload='', service_class=DummyAdminService):
        handler = channel.RequestHandler()

        expected = {
            'key': 'a' + uuid4().hex + add_string,
            'value': uuid4().hex + NON_ASCII_STRING,
            'result': uuid4().hex,
            'details': uuid4().hex,
            'cid': new_cid(),
            'zato':zato_namespace
        }

        if needs_payload:
            if not payload:
                if data_format == SIMPLE_IO.FORMAT.JSON:
                    payload_value = {expected['key']: expected['value']}
                else:
                    # NOTE: str.format can't handle Unicode arguments http://bugs.python.org/issue7300
                    payload_value = """<%(key)s xmlns="%(zato)s">%(value)s<zato_env>
                          <cid>%(cid)s</cid>
                          <result>%(result)s</result>
                          <details>%(details)s</details>
                        </zato_env>
                      </%(key)s>""" % (expected)
                payload = DummyPayload(payload_value)
        else:
            payload = None

        response = DummyResponse(payload, expected['result'], expected['details'])
        service = service_class(response, expected['cid'])

        handler.set_payload(response, data_format, transport, service)

        return expected, service

# ##############################################################################

class TestSetPayloadAdminServiceTestCase(MessageHandlingBase):

    def _test_xml(self, url_type, needs_payload):
        expected, service = self.get_data(SIMPLE_IO.FORMAT.XML, url_type, '', needs_payload)
        payload = etree.fromstring(service.response.payload)

        parent_path = '/soap:Envelope/soap:Body' if url_type == URL_TYPE.SOAP else ''

        if needs_payload:
            path = parent_path + '/zato:{}/text()'.format(expected['key'])
            xpath = etree.XPath(path, namespaces=NS_MAP)
            value = xpath(payload)[0]
            eq_(value, expected['value'])
        else:
            path = parent_path + '//zato:{}'.format(DummyAdminService.SimpleIO.response_elem)
            xpath = etree.XPath(path, namespaces=NS_MAP)
            value = xpath(payload)[0]
            eq_(value.text.strip(), '')

        zato_env_path_elem = expected['key'] if needs_payload else DummyAdminService.SimpleIO.response_elem

        for name in('cid', 'result', 'details'):
            if not needs_payload and name == 'details':
                continue

            path = parent_path + '/zato:{}/zato:zato_env/zato:{}/text()'.format(zato_env_path_elem, name)
            xpath = etree.XPath(path, namespaces=NS_MAP)

            value = xpath(payload)[0]

            if needs_payload:
                eq_(value, expected[name])
            else:
                if name == 'result':
                    eq_(value, ZATO_OK)
                elif name == 'cid':
                    eq_(value, expected['cid'])

    def test_payload_provided_json_plain_http(self):
        expected, service = self.get_data(SIMPLE_IO.FORMAT.JSON, URL_TYPE.PLAIN_HTTP)
        payload = loads(service.response.payload)

        # Will fail with KeyError so it's a good indicator whether it worked at all or not
        payload[expected['key']]
        eq_(payload[expected['key']], expected['value'])

        zato_env = payload['zato_env']

        for name in('cid', 'result', 'details'):
            eq_(zato_env[name], expected[name])

    def test_payload_provided_xml_plain_http(self):
        self._test_xml(URL_TYPE.PLAIN_HTTP, True)

    def test_payload_provided_xml_soap(self):
        self._test_xml(URL_TYPE.SOAP, True)

    def test_no_payload_xml_plain_http(self):
        self._test_xml(URL_TYPE.PLAIN_HTTP, False)

    def test_no_payload_xml_soap(self):
        self._test_xml(URL_TYPE.SOAP, False)

# ##############################################################################

class TestSetPayloadNonAdminServiceTestCase(MessageHandlingBase):

    def test_payload_provided_basestring(self):
        payload = uuid4().hex
        ignored, service = self.get_data(None, None, '', payload=payload, service_class=DummyService)
        eq_(payload, service.response.payload)

    def test_payload_provided_non_basestring(self):
        payload = DummyPayload(uuid4().hex)
        ignored, service = self.get_data(None, None, '', payload=payload, service_class=DummyService)
        eq_(payload.value, service.response.payload)

# ##############################################################################

class TestRequestDispatcher(MessageHandlingBase):
    def test_soap_quotes(self):
        rd = channel.RequestDispatcher()

        soap_action = '"aaa"'
        soap_action = rd._handle_quotes_soap_action(soap_action)
        self.assertEquals(soap_action, 'aaa')

        soap_action = 'aaa"'
        soap_action = rd._handle_quotes_soap_action(soap_action)
        self.assertEquals(soap_action, 'aaa"')

        soap_action = '"aaa'
        soap_action = rd._handle_quotes_soap_action(soap_action)
        self.assertEquals(soap_action, '"aaa')

        soap_action = 'aaa'
        soap_action = rd._handle_quotes_soap_action(soap_action)
        self.assertEquals(soap_action, 'aaa')

    def test_dispatch_no_url_data(self):
        rd = channel.RequestDispatcher(DummyURLData(False, Bunch(audit_enabled=False)))
        rd.security = DummySecurity()

        cid = uuid4().hex
        ts = arrow.now()

        path_info = uuid4().hex
        wsgi_input = StringIO()
        wsgi_input.write('zzz')

        wsgi_environ = {'PATH_INFO':path_info, 'wsgi.input': wsgi_input}

        response = rd.dispatch(cid, ts, wsgi_environ, None)

        self.assertEquals(wsgi_environ['zato.http.response.status'], '404 Not Found')
        self.assertEquals(
            response, "[{}] Unknown URL:[{}] or SOAP action:[{}]".format(
                cid, path_info, ''))

    def test_check_security_request_handler_handle_are_called(self):

        class DummyRequestHandler(object):
            def __init__(self):
                self.cid = None
                self.url_match = {ZATO_NONE:ZATO_NONE}
                self.channel_item = None
                self.wsgi_environ = {ZATO_NONE:ZATO_NONE}
                self.payload = None
                self.worker_store = None
                self.simple_io_config = None

            def handle(self, cid, url_match, channel_item, wsgi_environ, payload,
                    worker_store, simple_io_config, post_data):
                self.cid = cid
                self.url_match = url_match
                self.channel_item = channel_item
                self.wsgi_environ = wsgi_environ
                self.payload = payload
                self.worker_store = worker_store
                self.simple_io_config = simple_io_config

        cid = uuid4().hex
        req_timestamp = uuid4().hex
        path_info = uuid4().hex
        soap_action = uuid4().hex
        worker_store = uuid4().hex
        simple_io_config = uuid4().hex

        match_return_value = Bunch()
        match_return_value.is_active = True
        match_return_value.transport = uuid4().hex
        match_return_value.data_format = uuid4().hex

        channel_item_return_value = Bunch()
        channel_item_return_value.is_active = True
        channel_item_return_value.transport = uuid4().hex
        channel_item_return_value.data_format = uuid4().hex
        channel_item_return_value.match_target = uuid4().hex
        channel_item_return_value.audit_enabled = False

        payload = uuid4().hex

        wsgi_input = StringIO()
        wsgi_input.write(payload)
        wsgi_input.seek(0)

        wsgi_environ = {
            'PATH_INFO':path_info,
            'HTTP_SOAPACTION':soap_action,
            'wsgi.input':wsgi_input,
            'zato.http.response.headers': {},
        }

        ud = DummyURLData(match_return_value, channel_item_return_value)
        ud.url_sec[channel_item_return_value.match_target] = Bunch(sec_def=ZATO_NONE)

        rd = channel.RequestDispatcher(ud)
        rd.simple_io_config = simple_io_config
        rd.request_handler = DummyRequestHandler()
        rd.dispatch(cid, req_timestamp, wsgi_environ, worker_store)

        eq_(ud.cid, cid)
        eq_(ud.channel_item, channel_item_return_value)
        eq_(ud.path_info, path_info)
        eq_(ud.payload, payload)
        eq_(sorted(ud.wsgi_environ.items()), sorted(wsgi_environ.items()))

        eq_(rd.request_handler.cid, cid)
        eq_(sorted(rd.request_handler.url_match.items()), sorted(match_return_value.items()))
        eq_(rd.request_handler.channel_item, channel_item_return_value)
        eq_(sorted(rd.request_handler.wsgi_environ.items()), sorted(wsgi_environ.items()))
        eq_(rd.request_handler.payload, payload)
        eq_(rd.request_handler.worker_store, worker_store)
        eq_(rd.request_handler.simple_io_config, simple_io_config)

# ##############################################################################

class TestRequestHandler(TestCase):
    def test_handle(self):
        expected_cid = uuid4().hex
        expected_url_match = uuid4().hex
        expected_wsgi_environ = uuid4().hex
        expected_raw_request = uuid4().hex
        expected_simple_io_config = uuid4().hex
        expected_channel = CHANNEL.HTTP_SOAP

        expected_channel_item = Bunch()
        expected_channel_item.service_impl_name = Bunch()
        expected_channel_item.data_format = uuid4().hex
        expected_channel_item.transport = uuid4().hex
        expected_channel_item.params_pri = uuid4().hex

        expected_worker_store = Bunch()
        expected_worker_store.broker_client = uuid4().hex

        expected_channel_params = uuid4().hex

        def _create_channel_params(url_match, channel_item, wsgi_environ, raw_request, post_data=None):
            eq_(url_match, expected_url_match)
            eq_(channel_item, expected_channel_item)
            eq_(wsgi_environ, expected_wsgi_environ)
            eq_(raw_request, expected_raw_request)
            return expected_channel_params

        for merge_url_params_req in(True, False):
            expected_channel_item.merge_url_params_req = merge_url_params_req

            rh = channel.RequestHandler()

            class _Service:
                def update_handle(_self, _set_response_data, service, raw_request,
                        channel, data_format, transport, server, broker_client,
                        worker_store, cid, simple_io_config, wsgi_environ,
                        url_match, channel_item, channel_params,
                        merge_channel_params, params_priority):

                    eq_(_set_response_data, rh._set_response_data)
                    eq_(_self, service)
                    eq_(raw_request, expected_raw_request)
                    eq_(channel, expected_channel)
                    eq_(data_format, expected_channel_item.data_format)
                    eq_(transport, expected_channel_item.transport)
                    eq_(server, rh.server)
                    eq_(broker_client, expected_worker_store.broker_client)
                    eq_(sorted(worker_store.items()), sorted(expected_worker_store.items()))
                    eq_(cid, expected_cid)
                    eq_(simple_io_config, expected_simple_io_config)
                    eq_(wsgi_environ, expected_wsgi_environ)
                    eq_(url_match, expected_url_match)
                    eq_(sorted(channel_item.items()), sorted(expected_channel_item.items()))

                    if merge_url_params_req:
                        eq_(channel_params, expected_channel_params)
                    else:
                        eq_(channel_params, None)

                    eq_(merge_channel_params, merge_url_params_req)
                    eq_(params_priority, expected_channel_item.params_pri)

            class _server:
                class service_store:
                    @staticmethod
                    def new_instance(service_impl_name):
                        _server.service_impl_name = service_impl_name
                        return _Service()

            rh.server = _server
            rh.create_channel_params = _create_channel_params
            rh.handle(expected_cid, expected_url_match, expected_channel_item,
                expected_wsgi_environ, expected_raw_request, expected_worker_store,
                expected_simple_io_config, None)

    def test_create_channel_params(self):

        url_match = Bunch()
        url_match.named = Bunch()
        url_match.named.url_key1 = 'path-{}'.format(uuid4().hex)
        url_match.named.url_key2 = 'path-{}'.format(uuid4().hex)

        qs_key1, qs_value1 = 'url_key1', 'qs-aaa-{}'.format(uuid4().hex)
        qs_key2, qs_value2 = 'url_key2', 'qs-bbbb-{}'.format(uuid4().hex)

        # Same key, different values
        qs_key3_1, qs_value3_1 = 'url_key3', 'qs-key3_1-{}'.format(uuid4().hex)
        qs_key3_2, qs_value3_2 = 'url_key3', 'qs-key3_2-{}'.format(uuid4().hex)

        post_key1, post_value1 = 'post_key1', uuid4().hex
        post_key2, post_value2 = 'post_key2', uuid4().hex

        raw_request = '{}={}&{}={}'.format(post_key1, post_value1, post_key2, post_value2)

        wsgi_environ = {}
        wsgi_environ['QUERY_STRING'] = '{}={}&{}={}&{}={}&{}={}'.format(
            qs_key1, qs_value1, qs_key2, qs_value2, qs_key3_1, qs_value3_1,
            qs_key3_2, qs_value3_2)

        for data_format in DATA_FORMAT:
            for url_params_pri in URL_PARAMS_PRIORITY:

                channel_item = Bunch()
                channel_item.data_format = data_format
                channel_item.url_params_pri = url_params_pri

                rh = channel.RequestHandler()
                channel_params = rh.create_channel_params(url_match, channel_item, wsgi_environ, raw_request)

                get = wsgi_environ['zato.http.GET']

                eq_(get[qs_key1], qs_value1)
                eq_(get[qs_key2], qs_value2)
                eq_(get[qs_key3_1], [qs_value3_1, qs_value3_2])
                eq_(get[qs_key3_2], [qs_value3_1, qs_value3_2])

                if data_format == DATA_FORMAT.POST:
                    eq_(sorted(wsgi_environ['zato.http.POST'].items()), [(post_key1, post_value1), (post_key2, post_value2)])

                if url_params_pri == URL_PARAMS_PRIORITY.PATH_OVER_QS:
                    eq_(channel_params['url_key1'], url_match.named.url_key1)
                    eq_(channel_params['url_key2'], url_match.named.url_key2)
                else:
                    eq_(channel_params['url_key1'], qs_value1)
                    eq_(channel_params['url_key2'], qs_value2)

########NEW FILE########
__FILENAME__ = test_ftp
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from unittest import TestCase

# Bunch
from bunch import Bunch

# mock
from mock import patch

# Zato
from zato.common.test import rand_float, rand_string
from zato.server.connection.ftp import FTPStore

class TestFTP(TestCase):
    def test_timeout_is_float(self):
        """ GH #188 - Parameter 'timeout' should be a float.
        """
        class FTPFacade(object):
            def __init__(self, host, user, password, acct, timeout, port, dircache):
                self.timeout = timeout

        with patch('zato.server.connection.ftp.FTPFacade', FTPFacade):
            store = FTPStore()
    
            conn_name = 'test'
            timeout = '20' # String at that point
            params = Bunch({'name':conn_name, 'is_active':True, 'port':21, 'dircache':True, 'timeout':timeout})
    
            for name in 'host', 'user', 'password', 'acct':
                params[name] = rand_string()
    
            store.add_params([params])
            conn = store.get(conn_name)
            self.assertIsInstance(conn.timeout, float)
########NEW FILE########
__FILENAME__ = test_outgoing
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from unittest import TestCase

# bunch
from bunch import Bunch

# nose
from nose.tools import eq_

# Zato
from zato.common import URL_TYPE
from zato.common.test import rand_float, rand_int, rand_string
from zato.server.connection.http_soap.outgoing import HTTPSOAPWrapper

class _FakeSession(object):
    def __init__(self, *ignored, **kwargs):
        self.pool_size = kwargs.get('pool_maxsize', 'missing')
        self.request_args = None
        self.request_kwargs = None
        
    def request(self, *args, **kwargs):
        self.request_args = args
        self.request_kwargs = kwargs
        
        return Bunch({'status_code':rand_string(), 'text':rand_string()})
        
class _FakeRequestsModule(object):
    def __init__(self):
        self.session_obj = None
        
    def session(self, *args, **kwargs):
        self.session_obj = _FakeSession(*args, **kwargs)
        return self.session_obj

class HTTPSOAPWrapperTestCase(TestCase):
    
    def _get_config(self):
        return {'is_active':True, 'sec_type':rand_string(), 'address_host':rand_string(), 
            'address_url_path':rand_string(), 'ping_method':rand_string(), 'soap_version':'1.1',
            'pool_size':rand_int(), 'serialization_type':'string', 'timeout':rand_int()}
    
    def test_ping_method(self):
        """ https://github.com/zatosource/zato/issues/44 (outconn HTTP/SOAP ping method)
        """
        config = self._get_config()
        expected_ping_method = 'ping-{}'.format(rand_string())
        config['ping_method'] = expected_ping_method
        requests_module = _FakeRequestsModule()
        
        wrapper = HTTPSOAPWrapper(config, requests_module)
        wrapper.ping(rand_string())
        
        ping_method = requests_module.session_obj.request_args[0]
        eq_(expected_ping_method, ping_method)

    def test_pool_size(self):
        """ https://github.com/zatosource/zato/issues/77 (outconn HTTP/SOAP pool size)
        """
        config = self._get_config()
        expected_pool_size = rand_int()
        config['pool_size'] = expected_pool_size
        requests_module = _FakeRequestsModule()
        
        wrapper = HTTPSOAPWrapper(config, requests_module)
        wrapper.ping(rand_string())
        
        eq_(expected_pool_size, requests_module.session_obj.pool_size)

    def test_timeout(self):
        """ https://github.com/zatosource/zato/issues/112 (HTTP timeouts)
        """
        for name in 'ping', 'get', 'delete', 'options', 'post', 'send', 'put', 'patch':
            for transport in URL_TYPE:
                config = self._get_config()
                config['transport'] = transport
                expected_timeout = rand_float()
                config['timeout'] = expected_timeout
                requests_module = _FakeRequestsModule()

                wrapper = HTTPSOAPWrapper(config, requests_module)
                func = getattr(wrapper, name)
                func(rand_string())

                self.assertIn('timeout', requests_module.session_obj.request_kwargs)
                eq_(expected_timeout, requests_module.session_obj.request_kwargs['timeout'])

    def test_set_address(self):
        address_host = rand_string()
        config = self._get_config()
        config['address_host'] = address_host
        requests_module = _FakeRequestsModule()

        for address_url_path in('/zzz', '/cust/{customer}/order/{order}/pid{process}/',):
            config['address_url_path'] = address_url_path
            wrapper = HTTPSOAPWrapper(config, requests_module)
            
            eq_(wrapper.address, '{}{}'.format(address_host, address_url_path))
            
            if address_url_path == '/zzz':
                eq_(wrapper.path_params, [])
            else:
                eq_(wrapper.path_params, ['customer', 'order', 'process'])
        
    def test_format_address(self):
        cid = rand_string()
        address_host = rand_string()
        address_url_path = '/a/{a}/b{b}/c-{c}/{d}d/'
        
        config = self._get_config()
        config['address_host'] = address_host
        config['address_url_path'] = address_url_path
        
        requests_module = _FakeRequestsModule()
        wrapper = HTTPSOAPWrapper(config, requests_module)
        
        try:
            wrapper.format_address(cid, None)
        except ValueError, e:
            eq_(e.message, 'CID:[{}] No parameters given for URL path'.format(cid))
        else:
            self.fail('Expected ValueError (params is None)')
        
        a = rand_string()
        b = rand_string()
        c = rand_string()
        d = rand_string()
        e = rand_string()
        f = rand_string()
        
        params = {'a':a, 'b':b, 'c':c, 'd':d, 'e':e, 'f':f}
        address, non_path_params = wrapper.format_address(cid, params)
        eq_(address, '{}/a/{}/b{}/c-{}/{}d/'.format(address_host, a, b, c, d))
        eq_(non_path_params, {'e':e, 'f':f})
        
        params = {'a':a, 'b':b}
        
        try:
            address, non_path_params = wrapper.format_address(cid, params)
        except ValueError, e:
            eq_(e.message, 'CID:[{}] Could not build URL path'.format(cid))
        else:
            self.fail('Expected ValueError (not enough keys in params)')
    
    def test_http_methods(self):
        address_host = rand_string()
        
        config = self._get_config()
        config['is_active'] = True
        config['soap_version'] = '1.2'
        config['address_host'] = address_host
        
        requests_module = _FakeRequestsModule()
        wrapper = HTTPSOAPWrapper(config, requests_module)
        
        for address_url_path in('/zzz', '/a/{a}/b/{b}'):
            for transport in('soap', rand_string()):
                for name in('get', 'delete', 'options', 'post', 'put', 'patch'):
                    config['transport'] = transport
                    
                    _cid = rand_string()
                    _data = rand_string()
                    
                    expected_http_request_value = rand_string()
                    expected_http_request_value = rand_string()
                    
                    expected_params = rand_string()
                    
                    expected_args1 = rand_string()
                    expected_args2 = rand_string()
                    
                    expected_kwargs1 = rand_string()
                    expected_kwargs2 = rand_string()
                    
                    def http_request(method, cid, data='', params=None, *args, **kwargs):

                        eq_(method, name.upper())
                        eq_(cid, _cid)
                        
                        if name in('get', 'delete', 'options'):
                            eq_(data, '')
                        else:
                            eq_(data, _data)
                            
                        eq_(params, expected_params)
                        eq_(args, (expected_args1, expected_args2))
                        eq_(sorted(kwargs.items()), [('bar', expected_kwargs2), ('foo', expected_kwargs1)])
                        
                        return expected_http_request_value
                    
                    def format_address(cid, params):
                        return expected_http_request_value
                    
                    wrapper.http_request = http_request
                    wrapper.format_address = format_address
                    
                    func = getattr(wrapper, name)
                    
                    if name in('get', 'delete', 'options'):
                        http_request_value = func(
                            _cid, expected_params, expected_args1, expected_args2,
                            foo=expected_kwargs1, bar=expected_kwargs2)
                    else:
                        http_request_value = func(
                            _cid, _data, expected_params, expected_args1, expected_args2,
                            foo=expected_kwargs1, bar=expected_kwargs2)
                    
                    eq_(http_request_value, expected_http_request_value)

########NEW FILE########
__FILENAME__ = test_url_data
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from cStringIO import StringIO
from unittest import TestCase
from uuid import uuid4

# Bunch
from bunch import Bunch

# nose
from nose.tools import eq_

# parse
from parse import compile as parse_compile, Parser, Result

# Zato
from zato.common import DATA_FORMAT, MISC, URL_TYPE, ZATO_NONE
from zato.common.test import rand_string
from zato.common.util import new_cid, payload_from_request
from zato.server.connection.http_soap import Unauthorized, url_data

# ################################################################################################################################

class DummyLock(object):
    def __init__(self):
        self.enter_called = False

    def __enter__(self):
        self.enter_called = True

    def __exit__(self, *ignored_args):
        pass

class Dummy_update_basic_auth(object):
    def __call__(self, name, msg):
        self.name = name
        self.msg = msg

Dummy_update_apikey = Dummy_update_wss = Dummy_update_tech_acc = Dummy_update_ntlm = Dummy_update_basic_auth

class Dummy_update_url_sec(object):
    def __call__(self, msg, security_def_type, delete=False):
        self.msg = msg
        self.security_def_type = security_def_type
        self.delete = delete

class Dummy_delete_channel_data(object):
    def __call__(self, security_def_type, name):
        self.security_def_type = security_def_type
        self.name = name

class Dummy_delete_channel(object):
    def __init__(self, msg=None):
        self.msg = msg

    def __call__(self, msg, *args):
        self.msg = msg

Dummy_create_channel = Dummy_delete_channel

# ################################################################################################################################

class URLDataTestCase(TestCase):

    def test_match(self):
        ud = url_data.URLData([])

        soap_action1 = uuid4().hex
        url_path1 = uuid4().hex
        match_target1 = '{}{}{}'.format(soap_action1, MISC.SEPARATOR, url_path1)

        soap_action2 = uuid4().hex
        url_path2 = uuid4().hex
        match_target2 = '{}{}{}'.format(soap_action2, MISC.SEPARATOR, url_path2)

        soap_action3 = ''
        url_path3 = '/customer/{cid}/order/{oid}'
        match_target3 = '{}{}{}'.format(soap_action3, MISC.SEPARATOR, url_path3)

        item1 = Bunch()
        item1.match_target = match_target1
        item1.match_target_compiled = parse_compile(item1.match_target)

        item2 = Bunch()
        item2.match_target = match_target2
        item2.match_target_compiled = parse_compile(item2.match_target)

        item3 = Bunch()
        item3.match_target = match_target3
        item3.match_target_compiled = parse_compile(item3.match_target)

        ud.channel_data.append(item1)
        ud.channel_data.append(item2)
        ud.channel_data.append(item3)

        match, _ = ud.match(url_path1, soap_action1)
        self.assertIsInstance(match, Result)
        eq_(match.named, {})
        eq_(match.spans, {})

        match, _ = ud.match(url_path2, soap_action2)
        self.assertIsInstance(match, Result)
        eq_(match.named, {})
        eq_(match.spans, {})

        match, _ = ud.match('/customer/123/order/456', soap_action3)
        self.assertIsInstance(match, Result)
        eq_(sorted(match.named.items()), [(u'cid', u'123'), (u'oid', u'456')])
        eq_(sorted(match.spans.items()), [(u'cid', (13, 16)), (u'oid', (23, 26))])

        match, _ = ud.match('/foo/bar', '')
        self.assertIsNone(match)

# ################################################################################################################################

    def test_check_security(self):

        match_target1 = uuid4().hex
        match_target2 = uuid4().hex

        class DummyMatch(object):
            def __init__(self, match_target):
                self.match_target = match_target

        class DummySecWrapper(object):
            def __init__(self, sec_def):
                self.sec_def = sec_def

        class DummySecDef(object):
            sec_type = 'basic_auth'

        class DummyBasicAuth:
            def __init__(self):
                self.cid = ZATO_NONE
                self.sec_def = ZATO_NONE
                self.path_info = ZATO_NONE
                self.payload = ZATO_NONE
                self.wsgi_environ = ZATO_NONE

            def __call__(self, cid, sec_def, path_info, payload, wsgi_environ, post_data):
                self.cid = cid
                self.sec_def = sec_def
                self.path_info = path_info
                self.payload = payload
                self.wsgi_environ = wsgi_environ
                self.post_data = post_data

        dummy_basic_auth = DummyBasicAuth()

        expected_cid = uuid4().hex
        expected_path_info = uuid4().hex
        expected_payload = uuid4().hex
        expected_wsgi_environ = uuid4().hex
        expected_post_data = uuid4().hex

        match1 = DummyMatch(match_target1)
        match2 = DummyMatch(match_target2)

        sec_def1 = DummySecDef()

        wrapper1 = DummySecWrapper(sec_def1)
        wrapper2 = DummySecWrapper(ZATO_NONE)

        url_sec = {
            match_target1: wrapper1,
            match_target2: wrapper2
        }

        ud = url_data.URLData(url_sec=url_sec)
        ud._handle_security_basic_auth = dummy_basic_auth

        ud.check_security(
            wrapper1, expected_cid, match1, expected_path_info,
            expected_payload, expected_wsgi_environ, expected_post_data)

        eq_(dummy_basic_auth.cid, expected_cid)
        eq_(dummy_basic_auth.sec_def, sec_def1)
        eq_(dummy_basic_auth.path_info, expected_path_info)
        eq_(dummy_basic_auth.payload, expected_payload)
        eq_(dummy_basic_auth.wsgi_environ, expected_wsgi_environ)
        eq_(dummy_basic_auth.post_data, expected_post_data)

        dummy_basic_auth = DummyBasicAuth()

        ud = url_data.URLData(url_sec=url_sec)
        ud._handle_security_basic_auth = dummy_basic_auth

        ud.check_security(
            wrapper2, expected_cid, match2, expected_path_info, expected_payload,
            expected_wsgi_environ, None)

        eq_(dummy_basic_auth.cid, ZATO_NONE)
        eq_(dummy_basic_auth.sec_def, ZATO_NONE)
        eq_(dummy_basic_auth.path_info, ZATO_NONE)
        eq_(dummy_basic_auth.payload, ZATO_NONE)
        eq_(dummy_basic_auth.wsgi_environ, ZATO_NONE)

# ################################################################################################################################

    def test_update_url_sec(self):

        for name_attr in('name', 'old_name'):

            target_match1 = uuid4().hex
            target_match2 = uuid4().hex

            sec_def_name1 = uuid4().hex
            sec_def_name2 = uuid4().hex

            url_info1 = Bunch()
            url_info1.sec_def = Bunch()
            url_info1.sec_def.name = sec_def_name1
            url_info1.sec_def.sec_type = 'basic_auth'
            url_info1.sec_def.key1 = uuid4().hex
            url_info1.sec_def.key2 = uuid4().hex
            url_info1.sec_def.key3 = uuid4().hex

            url_info2 = Bunch()
            url_info2.sec_def = Bunch()
            url_info2.sec_def.name = sec_def_name2
            url_info2.sec_def.sec_type = 'basic_auth'

            url_sec = {
                target_match1: url_info1,
                target_match2: url_info2,
            }

            ud = url_data.URLData(url_sec=url_sec)

            msg_attrs = {
                'key1': uuid4().hex,
                'key2': uuid4().hex,
                'key3': uuid4().hex,
                'unexisting-key': uuid4().hex # Note it doesn't exist in url_info1
            }

            msg = Bunch()
            msg[name_attr] = sec_def_name1

            for attr in msg_attrs:
                msg[attr] = msg_attrs[attr]

            ud._update_url_sec(msg, 'basic_auth')

            ud_url_info1 = ud.url_sec[target_match1]

            eq_(ud_url_info1.sec_def.key1, msg['key1'])
            eq_(ud_url_info1.sec_def.key2, msg['key2'])
            eq_(ud_url_info1.sec_def.key3, msg['key3'])
            self.assertNotIn('unexisting-key', ud_url_info1.sec_def)

            ud_url_info2 = ud.url_sec[target_match2]

            self.assertNotIn('key1', ud_url_info2.sec_def)
            self.assertNotIn('key2', ud_url_info2.sec_def)
            self.assertNotIn('key3', ud_url_info2.sec_def)
            self.assertNotIn('unexisting-key', ud_url_info2.sec_def)

            ud = url_data.URLData(url_sec=url_sec)
            ud._update_url_sec(msg, 'basic_auth', True)

            try:
                ud.url_sec[target_match1]
            except KeyError:
                pass
            else:
                self.fail('Expected KeyError here, {} should have been deleted'.format(
                    target_match1))

            ud_url_info2 = ud.url_sec[target_match2]

            self.assertNotIn('key1', ud_url_info2.sec_def)
            self.assertNotIn('key2', ud_url_info2.sec_def)
            self.assertNotIn('key3', ud_url_info2.sec_def)
            self.assertNotIn('unexisting-key', ud_url_info2.sec_def)

# ################################################################################################################################

    def test_delete_channel_data(self):

        sec1 = Bunch()
        sec1.sec_type = uuid4().hex
        sec1.security_name = uuid4().hex

        sec2 = Bunch()
        sec2.sec_type = uuid4().hex
        sec2.security_name = uuid4().hex

        ud = url_data.URLData(channel_data=[sec1, sec2])
        eq_(len(ud.channel_data), 2)

        ud._delete_channel_data(sec1.sec_type, sec1.security_name)
        eq_(len(ud.channel_data), 1)

        channel_data = ud.channel_data[0]
        eq_(channel_data.sec_type, sec2.sec_type)
        eq_(channel_data.security_name, sec2.security_name)

        ud._delete_channel_data(uuid4().hex, uuid4().hex)
        eq_(len(ud.channel_data), 1)

        # Still the same
        channel_data = ud.channel_data[0]
        eq_(channel_data.sec_type, sec2.sec_type)
        eq_(channel_data.security_name, sec2.security_name)

# ################################################################################################################################

    def test_update_basic_auth(self):
        ud = url_data.URLData()
        ud.basic_auth_config = {}

        name1 = uuid4().hex
        name2 = uuid4().hex

        value1 = uuid4().hex
        value2 = uuid4().hex

        config1 = {
            'value1': value1,
            'value2': value2,
        }

        ud._update_basic_auth(name1, config1)

        eq_(len(ud.basic_auth_config), 1)
        self.assertTrue(name1 in ud.basic_auth_config)
        eq_(sorted(ud.basic_auth_config[name1].config.items()), [(u'value1', value1), (u'value2', value2)])

# ################################################################################################################################

    def test_handle_security_apikey(self):
        username, password = uuid4().hex, uuid4().hex
        ud = url_data.URLData()
        cid = new_cid()
        sec_def = Bunch(username=username, password=password)
        path_info = '/'
        body = ''

        # No header at that point
        wsgi_environ = {}

        try:
            ud._handle_security_apikey(cid, sec_def, path_info, body, wsgi_environ)
        except Unauthorized:
            pass
        else:
            self.fail('No header sent, expected Unauthorized')

        # Correct header name but invalid key
        wsgi_environ[username] = uuid4().hex

        try:
            ud._handle_security_apikey(cid, sec_def, path_info, body, wsgi_environ)
        except Unauthorized:
            pass
        else:
            self.fail('Invalid key, expected Unauthorized')

        # Both header and key are valid, not exception at this point
        wsgi_environ[username] = password

        ud._handle_security_apikey(cid, sec_def, path_info, body, wsgi_environ)

# ################################################################################################################################

    def test_handle_security_xpath_sec(self):

        test_data = [
            [True, rand_string(), rand_string()],
            [False, rand_string(), rand_string()],
            [True, rand_string(), None],
            [False, rand_string(), None]
        ]

        username_expr = "//*[local-name()='mydoc']/@user"
        for is_valid, valid_username, password in test_data:

            password_expr = "//*[local-name()='mydoc']/@password" if password else None
            xml_username = valid_username if is_valid else rand_string()

            cid = rand_string()
            ud = url_data.URLData()
            sec_def = Bunch(username=valid_username, password=password, username_expr=username_expr, password_expr=password_expr)

            xml = """<soapenv:Envelope xmlns:soapenv="http://schemas.xmlsoap.org/soap/envelope/" xmlns:foo="http://foo.example.com">
                <soapenv:Header/>
                <soapenv:Body>
                  <foo:mydoc user="{}" password="{}"/>
                </soapenv:Body>
                </soapenv:Envelope>""".format(xml_username, password)

            payload = payload_from_request(cid, xml, DATA_FORMAT.XML, URL_TYPE.SOAP)

            if is_valid:
                result = ud._handle_security_xpath_sec(cid, sec_def, None, None, {'zato.request.payload':payload})
                self.assertEqual(result, True)
            else:
                try:
                    ud._handle_security_xpath_sec(cid, sec_def, None, None, {'zato.request.payload':payload})
                except Unauthorized:
                    pass
                else:
                    self.fail('Expected Unauthorized, `{}`, `{}`, `{}`, `{}`, `{}`'.format(
                        is_valid, valid_username, xml_username, password, xml))

# ################################################################################################################################

    def test_apikey_get(self):

        name1, value1 = uuid4().hex, uuid4().hex

        dummy_lock = DummyLock()

        ud = url_data.URLData()
        ud.url_sec_lock = dummy_lock
        ud.apikey_config = {name1: value1}

        value = ud.apikey_get(name1)
        eq_(value, value1)
        eq_(dummy_lock.enter_called, True)

        value = ud.apikey_get(uuid4().hex)
        eq_(value, None)

# ################################################################################################################################

    def test_on_broker_msg_SECURITY_APIKEY_CREATE(self):

        dummy_lock = DummyLock()
        dummy_update_apikey = Dummy_update_apikey()

        ud = url_data.URLData()
        ud.url_sec_lock = dummy_lock
        ud._update_apikey = dummy_update_apikey

        msg = Bunch()
        msg.name = uuid4().hex
        msg.key1 = uuid4().hex
        msg.key2 = uuid4().hex
        msg.key3 = uuid4().hex

        ud.on_broker_msg_SECURITY_APIKEY_CREATE(msg)

        eq_(dummy_lock.enter_called, True)
        eq_(dummy_update_apikey.name, msg.name)
        eq_(dummy_update_apikey.msg.key1, msg.key1)
        eq_(dummy_update_apikey.msg.key2, msg.key2)
        eq_(dummy_update_apikey.msg.key3, msg.key3)

# ################################################################################################################################

    def test_on_broker_msg_SECURITY_APIKEY_EDIT(self):

        dummy_lock = DummyLock()
        dummy_update_apikey = Dummy_update_apikey()
        dummy_update_url_sec = Dummy_update_url_sec()

        old_name = uuid4().hex

        ud = url_data.URLData()
        ud.apikey_config = {old_name: uuid4().hex}
        ud.url_sec_lock = dummy_lock
        ud._update_apikey = dummy_update_apikey
        ud._update_url_sec = dummy_update_url_sec

        msg = Bunch()
        msg.old_name = old_name
        msg.name = uuid4().hex
        msg.key1 = uuid4().hex
        msg.key2 = uuid4().hex
        msg.key3 = uuid4().hex

        ud.on_broker_msg_SECURITY_APIKEY_EDIT(msg)

        eq_(dummy_lock.enter_called, True)

        eq_(dummy_update_apikey.name, msg.name)
        eq_(dummy_update_apikey.msg.key1, msg.key1)
        eq_(dummy_update_apikey.msg.key2, msg.key2)
        eq_(dummy_update_apikey.msg.key3, msg.key3)

        eq_(dummy_update_url_sec.msg.old_name, msg.old_name)
        eq_(dummy_update_url_sec.msg.name, msg.name)
        eq_(dummy_update_url_sec.msg.key1, msg.key1)
        eq_(dummy_update_url_sec.msg.key2, msg.key2)
        eq_(dummy_update_url_sec.msg.key3, msg.key3)
        eq_(dummy_update_url_sec.security_def_type, 'apikey')
        eq_(dummy_update_url_sec.delete, False)

        self.assertNotIn(old_name, ud.apikey_config)

# ################################################################################################################################

    def test_on_broker_msg_SECURITY_APIKEY_DELETE(self):

        dummy_lock = DummyLock()
        dummy_update_apikey = Dummy_update_apikey()
        dummy_update_url_sec = Dummy_update_url_sec()
        dummy_delete_channel_data = Dummy_delete_channel_data()

        name = uuid4().hex

        ud = url_data.URLData()
        ud.apikey_config = {name: uuid4().hex}
        ud.url_sec_lock = dummy_lock
        ud._update_apikey = dummy_update_apikey
        ud._update_url_sec = dummy_update_url_sec
        ud._delete_channel_data = dummy_delete_channel_data

        msg = Bunch()
        msg.name = name
        msg.key1 = uuid4().hex
        msg.key2 = uuid4().hex
        msg.key3 = uuid4().hex

        ud.on_broker_msg_SECURITY_APIKEY_DELETE(msg)

        eq_(dummy_lock.enter_called, True)

        eq_(dummy_update_url_sec.msg.name, msg.name)
        eq_(dummy_update_url_sec.msg.key1, msg.key1)
        eq_(dummy_update_url_sec.msg.key2, msg.key2)
        eq_(dummy_update_url_sec.msg.key3, msg.key3)
        eq_(dummy_update_url_sec.security_def_type, 'apikey')
        eq_(dummy_update_url_sec.delete, True)

        self.assertNotIn(name, ud.apikey_config)

        eq_(dummy_delete_channel_data.name, name)
        eq_(dummy_delete_channel_data.security_def_type, 'apikey')

# ################################################################################################################################

    def test_on_broker_msg_SECURITY_APIKEY_CHANGE_PASSWORD(self):

        dummy_lock = DummyLock()
        dummy_update_url_sec = Dummy_update_url_sec()

        name = uuid4().hex
        old_password = uuid4().hex
        new_pasword = uuid4().hex

        ud = url_data.URLData()
        ud.apikey_config = {name: {'config':{'password':old_password}}}
        ud.url_sec_lock = dummy_lock
        ud._update_url_sec = dummy_update_url_sec

        msg = Bunch()
        msg.name = name
        msg.password = new_pasword
        msg.key1 = uuid4().hex
        msg.key2 = uuid4().hex
        msg.key3 = uuid4().hex

        ud.on_broker_msg_SECURITY_APIKEY_CHANGE_PASSWORD(msg)

        eq_(dummy_lock.enter_called, True)

        eq_(dummy_update_url_sec.msg.name, msg.name)
        eq_(dummy_update_url_sec.msg.key1, msg.key1)
        eq_(dummy_update_url_sec.msg.key2, msg.key2)
        eq_(dummy_update_url_sec.msg.key3, msg.key3)
        eq_(dummy_update_url_sec.security_def_type, 'apikey')
        eq_(dummy_update_url_sec.delete, False)

        eq_(ud.apikey_config[name]['config']['password'], new_pasword)

# ################################################################################################################################

    def test_basic_auth_get(self):

        name1, value1 = uuid4().hex, uuid4().hex

        dummy_lock = DummyLock()

        ud = url_data.URLData()
        ud.url_sec_lock = dummy_lock
        ud.basic_auth_config = {name1: value1}

        value = ud.basic_auth_get(name1)
        eq_(value, value1)
        eq_(dummy_lock.enter_called, True)

        value = ud.basic_auth_get(uuid4().hex)
        eq_(value, None)

# ################################################################################################################################

    def test_on_broker_msg_SECURITY_BASIC_AUTH_CREATE(self):

        dummy_lock = DummyLock()
        dummy_update_basic_auth = Dummy_update_basic_auth()

        ud = url_data.URLData()
        ud.url_sec_lock = dummy_lock
        ud._update_basic_auth = dummy_update_basic_auth

        msg = Bunch()
        msg.name = uuid4().hex
        msg.key1 = uuid4().hex
        msg.key2 = uuid4().hex
        msg.key3 = uuid4().hex

        ud.on_broker_msg_SECURITY_BASIC_AUTH_CREATE(msg)

        eq_(dummy_lock.enter_called, True)
        eq_(dummy_update_basic_auth.name, msg.name)
        eq_(dummy_update_basic_auth.msg.key1, msg.key1)
        eq_(dummy_update_basic_auth.msg.key2, msg.key2)
        eq_(dummy_update_basic_auth.msg.key3, msg.key3)

# ################################################################################################################################

    def test_on_broker_msg_SECURITY_BASIC_AUTH_EDIT(self):

        dummy_lock = DummyLock()
        dummy_update_basic_auth = Dummy_update_basic_auth()
        dummy_update_url_sec = Dummy_update_url_sec()

        old_name = uuid4().hex

        ud = url_data.URLData()
        ud.basic_auth_config = {old_name: uuid4().hex}
        ud.url_sec_lock = dummy_lock
        ud._update_basic_auth = dummy_update_basic_auth
        ud._update_url_sec = dummy_update_url_sec

        msg = Bunch()
        msg.old_name = old_name
        msg.name = uuid4().hex
        msg.key1 = uuid4().hex
        msg.key2 = uuid4().hex
        msg.key3 = uuid4().hex

        ud.on_broker_msg_SECURITY_BASIC_AUTH_EDIT(msg)

        eq_(dummy_lock.enter_called, True)

        eq_(dummy_update_basic_auth.name, msg.name)
        eq_(dummy_update_basic_auth.msg.key1, msg.key1)
        eq_(dummy_update_basic_auth.msg.key2, msg.key2)
        eq_(dummy_update_basic_auth.msg.key3, msg.key3)

        eq_(dummy_update_url_sec.msg.old_name, msg.old_name)
        eq_(dummy_update_url_sec.msg.name, msg.name)
        eq_(dummy_update_url_sec.msg.key1, msg.key1)
        eq_(dummy_update_url_sec.msg.key2, msg.key2)
        eq_(dummy_update_url_sec.msg.key3, msg.key3)
        eq_(dummy_update_url_sec.security_def_type, 'basic_auth')
        eq_(dummy_update_url_sec.delete, False)

        self.assertNotIn(old_name, ud.basic_auth_config)

# ################################################################################################################################

    def test_on_broker_msg_SECURITY_BASIC_AUTH_DELETE(self):

        dummy_lock = DummyLock()
        dummy_update_basic_auth = Dummy_update_basic_auth()
        dummy_update_url_sec = Dummy_update_url_sec()
        dummy_delete_channel_data = Dummy_delete_channel_data()

        name = uuid4().hex

        ud = url_data.URLData()
        ud.basic_auth_config = {name: uuid4().hex}
        ud.url_sec_lock = dummy_lock
        ud._update_basic_auth = dummy_update_basic_auth
        ud._update_url_sec = dummy_update_url_sec
        ud._delete_channel_data = dummy_delete_channel_data

        msg = Bunch()
        msg.name = name
        msg.key1 = uuid4().hex
        msg.key2 = uuid4().hex
        msg.key3 = uuid4().hex

        ud.on_broker_msg_SECURITY_BASIC_AUTH_DELETE(msg)

        eq_(dummy_lock.enter_called, True)

        eq_(dummy_update_url_sec.msg.name, msg.name)
        eq_(dummy_update_url_sec.msg.key1, msg.key1)
        eq_(dummy_update_url_sec.msg.key2, msg.key2)
        eq_(dummy_update_url_sec.msg.key3, msg.key3)
        eq_(dummy_update_url_sec.security_def_type, 'basic_auth')
        eq_(dummy_update_url_sec.delete, True)

        self.assertNotIn(name, ud.basic_auth_config)

        eq_(dummy_delete_channel_data.name, name)
        eq_(dummy_delete_channel_data.security_def_type, 'basic_auth')

# ################################################################################################################################

    def test_on_broker_msg_SECURITY_BASIC_AUTH_CHANGE_PASSWORD(self):

        dummy_lock = DummyLock()
        dummy_update_url_sec = Dummy_update_url_sec()

        name = uuid4().hex
        old_password = uuid4().hex
        new_pasword = uuid4().hex

        ud = url_data.URLData()
        ud.basic_auth_config = {name: {'config':{'password':old_password}}}
        ud.url_sec_lock = dummy_lock
        ud._update_url_sec = dummy_update_url_sec

        msg = Bunch()
        msg.name = name
        msg.password = new_pasword
        msg.key1 = uuid4().hex
        msg.key2 = uuid4().hex
        msg.key3 = uuid4().hex

        ud.on_broker_msg_SECURITY_BASIC_AUTH_CHANGE_PASSWORD(msg)

        eq_(dummy_lock.enter_called, True)

        eq_(dummy_update_url_sec.msg.name, msg.name)
        eq_(dummy_update_url_sec.msg.key1, msg.key1)
        eq_(dummy_update_url_sec.msg.key2, msg.key2)
        eq_(dummy_update_url_sec.msg.key3, msg.key3)
        eq_(dummy_update_url_sec.security_def_type, 'basic_auth')
        eq_(dummy_update_url_sec.delete, False)

        eq_(ud.basic_auth_config[name]['config']['password'], new_pasword)

# ################################################################################################################################

    def test_update_ntlm(self):
        ud = url_data.URLData()
        ud.ntlm_config = {}

        name1 = uuid4().hex
        name2 = uuid4().hex

        value1 = uuid4().hex
        value2 = uuid4().hex

        config1 = {
            'value1': value1,
            'value2': value2,
        }

        ud._update_ntlm(name1, config1)

        eq_(len(ud.ntlm_config), 1)
        self.assertTrue(name1 in ud.ntlm_config)
        eq_(sorted(ud.ntlm_config[name1].config.items()), [(u'value1', value1), (u'value2', value2)])

# ################################################################################################################################

    def test_ntlm_get(self):

        name1, value1 = uuid4().hex, uuid4().hex

        dummy_lock = DummyLock()

        ud = url_data.URLData()
        ud.url_sec_lock = dummy_lock
        ud.ntlm_config = {name1: value1}

        value = ud.ntlm_get(name1)
        eq_(value, value1)
        eq_(dummy_lock.enter_called, True)

        value = ud.ntlm_get(uuid4().hex)
        eq_(value, None)

# ################################################################################################################################

    def test_on_broker_msg_SECURITY_NTLM_CREATE(self):

        dummy_lock = DummyLock()
        dummy_update_ntlm = Dummy_update_ntlm()

        ud = url_data.URLData()
        ud.url_sec_lock = dummy_lock
        ud._update_ntlm = dummy_update_ntlm

        msg = Bunch()
        msg.name = uuid4().hex
        msg.key1 = uuid4().hex
        msg.key2 = uuid4().hex
        msg.key3 = uuid4().hex

        ud.on_broker_msg_SECURITY_NTLM_CREATE(msg)

        eq_(dummy_lock.enter_called, True)
        eq_(dummy_update_ntlm.name, msg.name)
        eq_(dummy_update_ntlm.msg.key1, msg.key1)
        eq_(dummy_update_ntlm.msg.key2, msg.key2)
        eq_(dummy_update_ntlm.msg.key3, msg.key3)

# ################################################################################################################################

    def test_on_broker_msg_SECURITY_NTLM_EDIT(self):

        dummy_lock = DummyLock()
        dummy_update_ntlm = Dummy_update_ntlm()
        dummy_update_url_sec = Dummy_update_url_sec()

        old_name = uuid4().hex

        ud = url_data.URLData()
        ud.ntlm_config = {old_name: uuid4().hex}
        ud.url_sec_lock = dummy_lock
        ud._update_ntlm = dummy_update_ntlm
        ud._update_url_sec = dummy_update_url_sec

        msg = Bunch()
        msg.old_name = old_name
        msg.name = uuid4().hex
        msg.key1 = uuid4().hex
        msg.key2 = uuid4().hex
        msg.key3 = uuid4().hex

        ud.on_broker_msg_SECURITY_NTLM_EDIT(msg)

        eq_(dummy_lock.enter_called, True)

        eq_(dummy_update_ntlm.name, msg.name)
        eq_(dummy_update_ntlm.msg.key1, msg.key1)
        eq_(dummy_update_ntlm.msg.key2, msg.key2)
        eq_(dummy_update_ntlm.msg.key3, msg.key3)

        eq_(dummy_update_url_sec.msg.old_name, msg.old_name)
        eq_(dummy_update_url_sec.msg.name, msg.name)
        eq_(dummy_update_url_sec.msg.key1, msg.key1)
        eq_(dummy_update_url_sec.msg.key2, msg.key2)
        eq_(dummy_update_url_sec.msg.key3, msg.key3)
        eq_(dummy_update_url_sec.security_def_type, 'ntlm')
        eq_(dummy_update_url_sec.delete, False)

        self.assertNotIn(old_name, ud.ntlm_config)

# ################################################################################################################################

    def test_on_broker_msg_SECURITY_NTLM_DELETE(self):

        dummy_lock = DummyLock()
        dummy_update_ntlm = Dummy_update_ntlm()
        dummy_update_url_sec = Dummy_update_url_sec()
        dummy_delete_channel_data = Dummy_delete_channel_data()

        name = uuid4().hex

        ud = url_data.URLData()
        ud.ntlm_config = {name: uuid4().hex}
        ud.url_sec_lock = dummy_lock
        ud._update_ntlm = dummy_update_ntlm
        ud._update_url_sec = dummy_update_url_sec
        ud._delete_channel_data = dummy_delete_channel_data

        msg = Bunch()
        msg.name = name
        msg.key1 = uuid4().hex
        msg.key2 = uuid4().hex
        msg.key3 = uuid4().hex

        ud.on_broker_msg_SECURITY_NTLM_DELETE(msg)

        eq_(dummy_lock.enter_called, True)

        eq_(dummy_update_url_sec.msg.name, msg.name)
        eq_(dummy_update_url_sec.msg.key1, msg.key1)
        eq_(dummy_update_url_sec.msg.key2, msg.key2)
        eq_(dummy_update_url_sec.msg.key3, msg.key3)
        eq_(dummy_update_url_sec.security_def_type, 'ntlm')
        eq_(dummy_update_url_sec.delete, True)

        self.assertNotIn(name, ud.ntlm_config)

        eq_(dummy_delete_channel_data.name, name)
        eq_(dummy_delete_channel_data.security_def_type, 'ntlm')

# ################################################################################################################################

    def test_on_broker_msg_SECURITY_NTLM_CHANGE_PASSWORD(self):

        dummy_lock = DummyLock()
        dummy_update_url_sec = Dummy_update_url_sec()

        name = uuid4().hex
        old_password = uuid4().hex
        new_pasword = uuid4().hex

        ud = url_data.URLData()
        ud.ntlm_config = {name: {'config':{'password':old_password}}}
        ud.url_sec_lock = dummy_lock
        ud._update_url_sec = dummy_update_url_sec

        msg = Bunch()
        msg.name = name
        msg.password = new_pasword
        msg.key1 = uuid4().hex
        msg.key2 = uuid4().hex
        msg.key3 = uuid4().hex

        ud.on_broker_msg_SECURITY_NTLM_CHANGE_PASSWORD(msg)

        eq_(dummy_lock.enter_called, True)

        eq_(dummy_update_url_sec.msg.name, msg.name)
        eq_(dummy_update_url_sec.msg.key1, msg.key1)
        eq_(dummy_update_url_sec.msg.key2, msg.key2)
        eq_(dummy_update_url_sec.msg.key3, msg.key3)
        eq_(dummy_update_url_sec.security_def_type, 'ntlm')
        eq_(dummy_update_url_sec.delete, False)

        eq_(ud.ntlm_config[name]['config']['password'], new_pasword)

# ################################################################################################################################

    def test_update_tech_acc(self):
        ud = url_data.URLData()
        ud.tech_acc_config = {}

        name1 = uuid4().hex
        name2 = uuid4().hex

        value1 = uuid4().hex
        value2 = uuid4().hex

        config1 = {
            'value1': value1,
            'value2': value2,
        }

        ud._update_tech_acc(name1, config1)

        eq_(len(ud.tech_acc_config), 1)
        self.assertTrue(name1 in ud.tech_acc_config)
        eq_(sorted(ud.tech_acc_config[name1].config.items()), [(u'value1', value1), (u'value2', value2)])

# ################################################################################################################################

    def test_tech_acc_get(self):

        name1, value1 = uuid4().hex, uuid4().hex

        dummy_lock = DummyLock()

        ud = url_data.URLData()
        ud.url_sec_lock = dummy_lock
        ud.tech_acc_config = {name1: value1}

        value = ud.tech_acc_get(name1)
        eq_(value, value1)
        eq_(dummy_lock.enter_called, True)

        value = ud.tech_acc_get(uuid4().hex)
        eq_(value, None)

# ################################################################################################################################

    def test_on_broker_msg_SECURITY_TECH_ACC_CREATE(self):

        dummy_lock = DummyLock()
        dummy_update_tech_acc = Dummy_update_tech_acc()

        ud = url_data.URLData()
        ud.url_sec_lock = dummy_lock
        ud._update_tech_acc = dummy_update_tech_acc

        msg = Bunch()
        msg.name = uuid4().hex
        msg.key1 = uuid4().hex
        msg.key2 = uuid4().hex
        msg.key3 = uuid4().hex

        ud.on_broker_msg_SECURITY_TECH_ACC_CREATE(msg)

        eq_(dummy_lock.enter_called, True)
        eq_(dummy_update_tech_acc.name, msg.name)
        eq_(dummy_update_tech_acc.msg.key1, msg.key1)
        eq_(dummy_update_tech_acc.msg.key2, msg.key2)
        eq_(dummy_update_tech_acc.msg.key3, msg.key3)

# ################################################################################################################################

    def test_on_broker_msg_SECURITY_TECH_ACC_EDIT(self):

        dummy_lock = DummyLock()
        dummy_update_tech_acc = Dummy_update_tech_acc()
        dummy_update_url_sec = Dummy_update_url_sec()

        old_name = uuid4().hex

        ud = url_data.URLData()
        ud.tech_acc_config = {old_name: uuid4().hex}
        ud.url_sec_lock = dummy_lock
        ud._update_tech_acc = dummy_update_tech_acc
        ud._update_url_sec = dummy_update_url_sec

        msg = Bunch()
        msg.old_name = old_name
        msg.name = uuid4().hex
        msg.key1 = uuid4().hex
        msg.key2 = uuid4().hex
        msg.key3 = uuid4().hex

        ud.on_broker_msg_SECURITY_TECH_ACC_EDIT(msg)

        eq_(dummy_lock.enter_called, True)

        eq_(dummy_update_tech_acc.name, msg.name)
        eq_(dummy_update_tech_acc.msg.key1, msg.key1)
        eq_(dummy_update_tech_acc.msg.key2, msg.key2)
        eq_(dummy_update_tech_acc.msg.key3, msg.key3)

        eq_(dummy_update_url_sec.msg.old_name, msg.old_name)
        eq_(dummy_update_url_sec.msg.name, msg.name)
        eq_(dummy_update_url_sec.msg.key1, msg.key1)
        eq_(dummy_update_url_sec.msg.key2, msg.key2)
        eq_(dummy_update_url_sec.msg.key3, msg.key3)
        eq_(dummy_update_url_sec.security_def_type, 'tech_acc')
        eq_(dummy_update_url_sec.delete, False)

        self.assertNotIn(old_name, ud.tech_acc_config)

# ################################################################################################################################

    def test_on_broker_msg_SECURITY_TECH_ACC_DELETE(self):

        dummy_lock = DummyLock()
        dummy_update_tech_acc = Dummy_update_tech_acc()
        dummy_update_url_sec = Dummy_update_url_sec()
        dummy_delete_channel_data = Dummy_delete_channel_data()

        name = uuid4().hex

        ud = url_data.URLData()
        ud.tech_acc_config = {name: uuid4().hex}
        ud.url_sec_lock = dummy_lock
        ud._update_tech_acc = dummy_update_tech_acc
        ud._update_url_sec = dummy_update_url_sec
        ud._delete_channel_data = dummy_delete_channel_data

        msg = Bunch()
        msg.name = name
        msg.key1 = uuid4().hex
        msg.key2 = uuid4().hex
        msg.key3 = uuid4().hex

        ud.on_broker_msg_SECURITY_TECH_ACC_DELETE(msg)

        eq_(dummy_lock.enter_called, True)

        eq_(dummy_update_url_sec.msg.name, msg.name)
        eq_(dummy_update_url_sec.msg.key1, msg.key1)
        eq_(dummy_update_url_sec.msg.key2, msg.key2)
        eq_(dummy_update_url_sec.msg.key3, msg.key3)
        eq_(dummy_update_url_sec.security_def_type, 'tech_acc')
        eq_(dummy_update_url_sec.delete, True)

        self.assertNotIn(name, ud.tech_acc_config)

        eq_(dummy_delete_channel_data.name, name)
        eq_(dummy_delete_channel_data.security_def_type, 'tech_acc')

# ################################################################################################################################

    def test_on_broker_msg_SECURITY_TECH_ACC_CHANGE_PASSWORD(self):

        dummy_lock = DummyLock()
        dummy_update_url_sec = Dummy_update_url_sec()

        name = uuid4().hex
        old_password = uuid4().hex
        new_pasword = uuid4().hex

        ud = url_data.URLData()
        ud.tech_acc_config = {name: {'config':{'password':old_password}}}
        ud.url_sec_lock = dummy_lock
        ud._update_url_sec = dummy_update_url_sec

        msg = Bunch()
        msg.name = name
        msg.password = new_pasword
        msg.key1 = uuid4().hex
        msg.key2 = uuid4().hex
        msg.key3 = uuid4().hex

        ud.on_broker_msg_SECURITY_TECH_ACC_CHANGE_PASSWORD(msg)

        eq_(dummy_lock.enter_called, True)

        eq_(dummy_update_url_sec.msg.name, msg.name)
        eq_(dummy_update_url_sec.msg.key1, msg.key1)
        eq_(dummy_update_url_sec.msg.key2, msg.key2)
        eq_(dummy_update_url_sec.msg.key3, msg.key3)
        eq_(dummy_update_url_sec.security_def_type, 'tech_acc')
        eq_(dummy_update_url_sec.delete, False)

        eq_(ud.tech_acc_config[name]['config']['password'], new_pasword)

# ################################################################################################################################

    def test_update_wss(self):
        ud = url_data.URLData()
        ud.wss_config = {}

        name1 = uuid4().hex
        name2 = uuid4().hex

        value1 = uuid4().hex
        value2 = uuid4().hex

        config1 = {
            'value1': value1,
            'value2': value2,
        }

        ud._update_wss(name1, config1)

        eq_(len(ud.wss_config), 1)
        self.assertTrue(name1 in ud.wss_config)
        eq_(sorted(ud.wss_config[name1].config.items()), [(u'value1', value1), (u'value2', value2)])

# ################################################################################################################################

    def test_wss_get(self):

        name1, value1 = uuid4().hex, uuid4().hex

        dummy_lock = DummyLock()

        ud = url_data.URLData()
        ud.url_sec_lock = dummy_lock
        ud.wss_config = {name1: value1}

        value = ud.wss_get(name1)
        eq_(value, value1)
        eq_(dummy_lock.enter_called, True)

        value = ud.wss_get(uuid4().hex)
        eq_(value, None)

# ################################################################################################################################

    def test_on_broker_msg_SECURITY_WSS_CREATE(self):

        dummy_lock = DummyLock()
        dummy_update_wss = Dummy_update_wss()

        ud = url_data.URLData()
        ud.url_sec_lock = dummy_lock
        ud._update_wss = dummy_update_wss

        msg = Bunch()
        msg.name = uuid4().hex
        msg.key1 = uuid4().hex
        msg.key2 = uuid4().hex
        msg.key3 = uuid4().hex

        ud.on_broker_msg_SECURITY_WSS_CREATE(msg)

        eq_(dummy_lock.enter_called, True)
        eq_(dummy_update_wss.name, msg.name)
        eq_(dummy_update_wss.msg.key1, msg.key1)
        eq_(dummy_update_wss.msg.key2, msg.key2)
        eq_(dummy_update_wss.msg.key3, msg.key3)

# ################################################################################################################################

    def test_on_broker_msg_SECURITY_WSS_EDIT(self):

        dummy_lock = DummyLock()
        dummy_update_wss = Dummy_update_wss()
        dummy_update_url_sec = Dummy_update_url_sec()

        old_name = uuid4().hex

        ud = url_data.URLData()
        ud.wss_config = {old_name: uuid4().hex}
        ud.url_sec_lock = dummy_lock
        ud._update_wss = dummy_update_wss
        ud._update_url_sec = dummy_update_url_sec

        msg = Bunch()
        msg.old_name = old_name
        msg.name = uuid4().hex
        msg.key1 = uuid4().hex
        msg.key2 = uuid4().hex
        msg.key3 = uuid4().hex

        ud.on_broker_msg_SECURITY_WSS_EDIT(msg)

        eq_(dummy_lock.enter_called, True)

        eq_(dummy_update_wss.name, msg.name)
        eq_(dummy_update_wss.msg.key1, msg.key1)
        eq_(dummy_update_wss.msg.key2, msg.key2)
        eq_(dummy_update_wss.msg.key3, msg.key3)

        eq_(dummy_update_url_sec.msg.old_name, msg.old_name)
        eq_(dummy_update_url_sec.msg.name, msg.name)
        eq_(dummy_update_url_sec.msg.key1, msg.key1)
        eq_(dummy_update_url_sec.msg.key2, msg.key2)
        eq_(dummy_update_url_sec.msg.key3, msg.key3)
        eq_(dummy_update_url_sec.security_def_type, 'wss')
        eq_(dummy_update_url_sec.delete, False)

        self.assertNotIn(old_name, ud.wss_config)

# ################################################################################################################################

    def test_on_broker_msg_SECURITY_WSS_DELETE(self):

        dummy_lock = DummyLock()
        dummy_update_wss = Dummy_update_wss()
        dummy_update_url_sec = Dummy_update_url_sec()
        dummy_delete_channel_data = Dummy_delete_channel_data()

        name = uuid4().hex

        ud = url_data.URLData()
        ud.wss_config = {name: uuid4().hex}
        ud.url_sec_lock = dummy_lock
        ud._update_wss = dummy_update_wss
        ud._update_url_sec = dummy_update_url_sec
        ud._delete_channel_data = dummy_delete_channel_data

        msg = Bunch()
        msg.name = name
        msg.key1 = uuid4().hex
        msg.key2 = uuid4().hex
        msg.key3 = uuid4().hex

        ud.on_broker_msg_SECURITY_WSS_DELETE(msg)

        eq_(dummy_lock.enter_called, True)

        eq_(dummy_update_url_sec.msg.name, msg.name)
        eq_(dummy_update_url_sec.msg.key1, msg.key1)
        eq_(dummy_update_url_sec.msg.key2, msg.key2)
        eq_(dummy_update_url_sec.msg.key3, msg.key3)
        eq_(dummy_update_url_sec.security_def_type, 'wss')
        eq_(dummy_update_url_sec.delete, True)

        self.assertNotIn(name, ud.wss_config)

        eq_(dummy_delete_channel_data.name, name)
        eq_(dummy_delete_channel_data.security_def_type, 'wss')

# ################################################################################################################################

    def test_on_broker_msg_SECURITY_WSS_CHANGE_PASSWORD(self):

        dummy_lock = DummyLock()
        dummy_update_url_sec = Dummy_update_url_sec()

        name = uuid4().hex
        old_password = uuid4().hex
        new_pasword = uuid4().hex

        ud = url_data.URLData()
        ud.wss_config = {name: {'config':{'password':old_password}}}
        ud.url_sec_lock = dummy_lock
        ud._update_url_sec = dummy_update_url_sec

        msg = Bunch()
        msg.name = name
        msg.password = new_pasword
        msg.key1 = uuid4().hex
        msg.key2 = uuid4().hex
        msg.key3 = uuid4().hex

        ud.on_broker_msg_SECURITY_WSS_CHANGE_PASSWORD(msg)

        eq_(dummy_lock.enter_called, True)

        eq_(dummy_update_url_sec.msg.name, msg.name)
        eq_(dummy_update_url_sec.msg.key1, msg.key1)
        eq_(dummy_update_url_sec.msg.key2, msg.key2)
        eq_(dummy_update_url_sec.msg.key3, msg.key3)
        eq_(dummy_update_url_sec.security_def_type, 'wss')
        eq_(dummy_update_url_sec.delete, False)

        eq_(ud.wss_config[name]['config']['password'], new_pasword)

# ################################################################################################################################

    def test_channel_item_from_msg(self):

        def get_msg(needs_security_id):
            msg = Bunch()

            for name in('connection', 'data_format', 'host', 'id', 'is_active', 'is_internal', 'method', 'name', 'ping_method', 
                'pool_size', 'service_id',  'impl_name', 'service_name', 'soap_action', 'soap_version', 'transport', 'url_path',
                'merge_url_params_req', 'url_params_pri', 'params_pri', 'audit_max_payload', 'audit_repl_patt_type',
                'replace_patterns_json_pointer', 'replace_patterns_xpath'):
                msg[name] = uuid4().hex

            if needs_security_id:
                for name in('sec_type', 'security_id', 'security_name'):
                    msg[name] = uuid4().hex

            return msg

# ################################################################################################################################

        def check_channel_item(match_target, msg, channel_item, needs_security_id):

            eq_(channel_item.service_impl_name, msg.impl_name)
            eq_(channel_item.match_target, match_target)
            self.assertIsInstance(channel_item.match_target_compiled, Parser)

            for name in('connection', 'data_format', 'host', 'id', 'is_active',
                'is_internal', 'method', 'name', 'ping_method', 'pool_size',
                'service_id',  'impl_name', 'service_name',
                'soap_action', 'soap_version', 'transport', 'url_path',
                'merge_url_params_req', 'url_params_pri', 'params_pri'):
                eq_(msg[name], channel_item[name])

            if needs_security_id:
                eq_(len(channel_item.keys()), 31)
                for name in('sec_type', 'security_id', 'security_name'):
                    eq_(msg[name], channel_item[name])
            else:
                eq_(len(channel_item.keys()), 28)

        for needs_security_id in(True, False):
            msg = get_msg(needs_security_id)
            match_target = uuid4().hex
            channel_item = url_data.URLData()._channel_item_from_msg(msg, match_target)
            check_channel_item(match_target, msg, channel_item, needs_security_id)

# ################################################################################################################################

    def test_sec_info_from_msg(self):

        security_name = uuid4().hex
        basic_auth_config = {
            security_name: {'config':{uuid4().hex:uuid4().hex, uuid4().hex:uuid4().hex}}
        }

        for sec_name in(None, security_name):

            msg = Bunch()
            msg.security_name = security_name
            msg.sec_type = 'basic_auth'
            msg.is_active = uuid4().hex
            msg.data_format = uuid4().hex
            msg.transport = uuid4().hex

            ud = url_data.URLData()
            ud.basic_auth_config = basic_auth_config

            sec_info = ud._sec_info_from_msg(msg)

            eq_(sec_info.is_active, msg.is_active)
            eq_(sec_info.data_format, msg.data_format)
            eq_(sec_info.transport, msg.transport)

            if msg.security_name:
                for k, v in basic_auth_config[security_name]['config'].items():
                    eq_(sec_info.sec_def[k], v)
            else:
                eq_(sec_info.sec_def, ZATO_NONE)

# ################################################################################################################################

    def test_create_channel(self):

        channel_item = uuid4().hex
        sec_info = uuid4().hex
        soap_action = uuid4().hex
        url_path = uuid4().hex
        match_target = '{}{}{}'.format(soap_action, MISC.SEPARATOR, url_path)

        def _dummy_channel_item_from_msg(*ignored):
            return channel_item

        def _dummy_sec_info_from_msg(*ignored):
            return sec_info

        msg = Bunch()
        msg.soap_action = soap_action
        msg.url_path = url_path

        ud = url_data.URLData()
        ud._channel_item_from_msg = _dummy_channel_item_from_msg
        ud._sec_info_from_msg = _dummy_sec_info_from_msg
        ud.channel_data = []
        ud.url_sec = {}

        ud._create_channel(msg, {})

        self.assertIn(match_target, ud.url_sec)
        eq_(ud.url_sec[match_target], sec_info)

        eq_(len(ud.channel_data), 1)
        eq_(ud.channel_data[0], channel_item)

# ################################################################################################################################

    def test_delete_channel(self):

        old_soap_action = uuid4().hex
        old_url_path = uuid4().hex

        item1 = Bunch()
        item1.match_target = uuid4().hex

        item2 = Bunch()
        item2.match_target = '{}{}{}'.format(old_soap_action, MISC.SEPARATOR, old_url_path)

        item3 = Bunch()
        item3.match_target = uuid4().hex

        ud = url_data.URLData()
        ud.channel_data = [item1, item2, item3]

        ud.url_sec = {}
        for item in ud.channel_data:
            ud.url_sec[item.match_target] = uuid4().hex

        msg = Bunch()
        msg.old_soap_action = old_soap_action
        msg.old_url_path = old_url_path

        ud._delete_channel(msg)

        self.assertNotIn(item2, ud.channel_data)
        self.assertNotIn(item2.match_target, ud.url_sec)

# ################################################################################################################################

    def test_on_broker_msg_CHANNEL_HTTP_SOAP_CREATE_EDIT(self):

        no_old_name_msg = uuid4().hex
        dummy_lock = DummyLock()
        dummy_delete_channel = Dummy_delete_channel(no_old_name_msg)
        dummy_create_channel = Dummy_create_channel()

        ud = url_data.URLData()
        ud.url_sec_lock = dummy_lock
        ud._delete_channel = dummy_delete_channel
        ud._create_channel = dummy_create_channel

        old_name = uuid4().hex
        key = uuid4().hex
        value = uuid4().hex

        for _old_name in(None, old_name):
            msg = Bunch()
            msg.old_name = old_name
            msg[key] = value

            ud.on_broker_msg_CHANNEL_HTTP_SOAP_CREATE_EDIT(msg)

            if msg.old_name:
                eq_(dummy_delete_channel.msg.old_name, msg.old_name)
                eq_(dummy_delete_channel.msg[key], msg[key])
            else:
                eq_(dummy_delete_channel.msg, no_old_name_msg)

            eq_(sorted(dummy_create_channel.msg.items()), sorted(msg.items()))
            eq_(dummy_lock.enter_called, True)

# ################################################################################################################################

    def test_on_broker_msg_CHANNEL_HTTP_SOAP_DELETE(self):

        dummy_lock = DummyLock()
        dummy_delete_channel = Dummy_delete_channel()

        ud = url_data.URLData()
        ud.url_sec_lock = dummy_lock
        ud._delete_channel = dummy_delete_channel

        key1 = uuid4().hex
        value1 = uuid4().hex

        key2 = uuid4().hex
        value2 = uuid4().hex

        msg = Bunch()
        msg[key1] = value1
        msg[key2] = value2

        ud.on_broker_msg_CHANNEL_HTTP_SOAP_DELETE(msg)

        eq_(dummy_delete_channel.msg[key1], msg[key1])
        eq_(dummy_delete_channel.msg[key2], msg[key2])

        eq_(dummy_lock.enter_called, True)

# ################################################################################################################################

########NEW FILE########
__FILENAME__ = test_sio_live
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import glob, os, shutil, time
from json import dumps, loads
from logging import getLogger
from unittest import TestCase

# Bunch
from bunch import Bunch, bunchify

# configobj
from configobj import ConfigObj

# etree
from lxml import etree

# nose
from nose.tools import eq_

# Paste
from paste.util.converters import asbool

# Zato
from zato.cli.util import Util
from zato.client import JSONClient, SOAPClient, XMLClient
from zato.common import ZatoException
from zato.common.test import rand_bool, rand_string
from zato.common.util import new_cid
from zato.server.service import Bool, Dict, Nested
from zato.server.service.reqresp.sio import ValidationException

# Zato - test services
from . import zato_test_live_sio 

logger = getLogger(__name__)

DEV_CONFIG_FILE = os.path.expanduser(os.path.sep.join(['~', '.zato', 'dev.ini']))
SERVER_CONFIG_FILE = os.path.sep.join(['config', 'repo', 'server.conf'])
URL_PATH_PATTERN = '/zato/test-live/{}/{}'

class SIOLiveTestCase(TestCase):

    def setUp(self):
        """ If it's a development environment, set up the client and deploy test services + objects.
        """
        self.should_run = False

        # Run the tests only if it's a development box
        if os.path.exists(DEV_CONFIG_FILE):
            config = ConfigObj(DEV_CONFIG_FILE)

            server_fs_loc = os.path.expanduser(config['server1']['fs_location'])
            pickup_dir = os.path.join(server_fs_loc, 'pickup-dir')

            self.util = Util(server_fs_loc)
            self.util.set_zato_client()

            test_pattern = os.path.join(os.path.dirname(__file__), 'zato_test_live_*')
            for item in glob.glob(test_pattern):
                shutil.copy(item, pickup_dir)

            # Needed because uploading a package is asynchronous so we don't want to run the tests
            # until the package is ready.
            time.sleep(0.2)

            self.should_run = True

    def tearDown(self):
        """ Do away with all the test services and objects possibly created earlier.
        """
        if self.should_run:
            for item in self.util.client.invoke(
                    'zato.service.get-list', {'cluster_id': self.util.client.cluster_id, 'name_filter': 'zato-test-live'}):
                self.util.client.invoke('zato.service.delete', {'id': item['id']})

        self.util = None

    def set_up_client_and_channel(self, service, data_format, transport):
        path = URL_PATH_PATTERN.format(service, new_cid())
        self.util.client.invoke('zato.http-soap.create', {
            'cluster_id': self.util.client.cluster_id,
            'name': path,
            'is_active': True,
            'connection': 'channel',
            'transport': transport,
            'is_internal': True,
            'url_path': path,
            'service': service,
            'security_id': None,
            'data_format': data_format
        })

        if data_format == 'json':
            client_class = JSONClient
        else:
            client_class = XMLClient

        return client_class(self.util.client.address, path)

# ################################################################################################################################

    def get_xml_soap_config(self):

        # Plain XML config
        request_wrapper_plain_xml = '{}'
        xpath_string_pattern_plain_xml = '//{}'
        transport_plain_xml = 'plain_http'

        # SOAP 1.1 config
        request_wrapper_soap_11 = """<soap:Envelope xmlns:soap="http://schemas.xmlsoap.org/soap/envelope/">
            <soap:Body>{}</soap:Body>
            </soap:Envelope>
        """
        xpath_string_pattern_soap_11 = "//*[local-name()='{}']"
        transport_soap_11 = 'soap'

        return [
            [request_wrapper_plain_xml, xpath_string_pattern_plain_xml, transport_plain_xml],
            [request_wrapper_soap_11, xpath_string_pattern_soap_11, transport_soap_11],
        ]

    def get_xml_value_from_response(self, xpath_string_pattern, response, name):
        expr = xpath_string_pattern.format(name)
        actual = response.xpath(expr)

        if not actual:
            raise Exception('Could not find {} in {}'.format(expr, etree.tostring(response, pretty_print=True)))
        else:
            return actual[0]

# ################################################################################################################################

    def _invoke(self, client, unserialize_func, service=None, request=None):
        """ Invokes a service using AnyServiceInvoker.
        """
        request = request or {}
        if service:
            response = client.invoke(service, request)
        else:
            response = client.invoke(request)

        if response.ok:
            if not response.data:
                raise Exception('No response.data in {}'.format(response))

            return bunchify(response.data)
        else:
            raise Exception(response.details)

    def invoke_asi(self, service, request=None):
        """ Invokes a service using AnyServiceInvoker.
        """
        return self._invoke(self.util.client, bunchify, service, request)

    def invoke_json(self, client, request=None):
        """ Invokes a service using JSONClient.
        """
        return self._invoke(client, bunchify, request)

    def invoke_xml(self, client, request=None):
        """ Invokes a service using XMLClient.
        """
        return self._invoke(client, bunchify, request)

# ################################################################################################################################

    def _run_tests_output_assigned_manually(self, service_name, service_class):

        # No input provided hence we expect a proper message on output
        try:
            response = self.invoke_asi(service_name)
        except Exception, e:
            self.assertIn('Missing input', e.message)

        test_data = service_class.test_data

# ################################################################################################################################

        # JSON request/response over AnyServiceInvoker
        response = self.invoke_asi(service_name, test_data)
        service_class.check_json(response.response, False)

# ################################################################################################################################

        # JSON request/response over JSONClient
        response = self.invoke_json(
            self.set_up_client_and_channel(service_name, 'json', 'plain_http'), test_data)
        service_class.check_json(response.response, False)

# ################################################################################################################################


        request = """<request>
                    <should_as_is>True</should_as_is>
                    <is_boolean>True</is_boolean>
                    <should_boolean>False</should_boolean>
                    <csv1>1,2,3,4</csv1>
                    <dict>
                     <item><key>a</key><value>b</value></item>
                     <item><key>c</key><value>d</value></item>
                    </dict>
                    <float>2.3</float>
                    <integer>190</integer>
                    <integer2>0</integer2>
                    <list>
                     <item>1</item>
                     <item>2</item>
                     <item>3</item>
                    </list>

                    <list_of_dicts>

                     <item_dict>
                      <item>
                        <key>1</key>
                        <value>11</value>
                      </item>
                      <item>
                        <key>2</key>
                        <value>22</value>
                      </item>
                     </item_dict>

                     <item_dict>
                      <item>
                        <key>3</key>
                        <value>33</value>
                      </item>
                     </item_dict>

                     <item_dict>
                      <item>
                        <key>4</key>
                        <value>44</value>
                      </item>
                      <item>
                        <key>5</key>
                        <value>55</value>
                      </item>
                      <item>
                        <key>3</key>
                        <value>33</value>
                      </item>
                      <item>
                        <key>2</key>
                        <value>22</value>
                      </item>
                      <item>
                        <key>1</key>
                        <value>11</value>
                      </item>
                     </item_dict>

                    </list_of_dicts>

                    <unicode1>zzz</unicode1>
                    <unicode2>z</unicode2>
                    <utc>2012-01-12T03:12:19+00:00</utc>
                </request>"""


        for request_wrapper, xpath_string_pattern, transport in self.get_xml_soap_config():

            # XML request/response over XMLClient
            client = self.set_up_client_and_channel(service_name, 'xml', transport)
            response = self.invoke_xml(client, request_wrapper.format(request).encode('utf-8'))

            for name in('should_as_is', 'is_boolean', 'should_boolean', 'csv1', 'float', 'integer', 'integer2',\
                        'unicode1', 'unicode2', 'utc'):

                expected = test_data[name]
                actual = self.get_xml_value_from_response(xpath_string_pattern, response, name)

                if name in ('is_boolean', 'should_boolean'):
                    expected = asbool(expected)

                if name == 'float':
                    expected = float(expected)

                if name in ('integer', 'integer2'):
                    expected = int(expected)

                if name == 'utc':
                    expected = expected.replace('+00:00', '')

                eq_(actual, expected, 'name:`{}` actual:`{}` expected:`{}`'.format(name, repr(actual), repr(expected)))

# ################################################################################################################################

    def test_channels_output_assigned_manually(self):
        if not self.should_run:
            return

        service_data = (
            ('zato-test-live-sio.roundtrip', zato_test_live_sio.Roundtrip),
            ('zato-test-live-sio.from-dict', zato_test_live_sio.FromDict),
            ('zato-test-live-sio.passthrough-to-roundtrip', zato_test_live_sio.PassthroughToRoundtrip),
            ('zato-test-live-sio.passthrough-to-from-dict', zato_test_live_sio.PassthroughToFromDict),
        )

        for service_info in service_data:
            self._run_tests_output_assigned_manually(*service_info)

# ################################################################################################################################

    def test_channels_output_from_sqlalchemy(self):
        if not self.should_run:
            return

        service_name = 'zato-test-live-sio.from-sql-alchemy'

        expected = [
            ('impl_name', 'zato.server.service.internal.Ping'),
            ('is_active', True),
            ('is_internal', True),
            ('name', 'zato.ping'),
            ('slow_threshold', 99999)
        ]

# ################################################################################################################################

        # JSON request/response over AnyServiceInvoker

        response = self.invoke_asi(service_name, {})
        eq_(sorted(response.response.items()), expected)

# ################################################################################################################################

        # JSON request/response over JSONClient
        response = self.invoke_json(self.set_up_client_and_channel(service_name, 'json', 'plain_http'), {})
        eq_(sorted(response.response.items()), expected)

# ################################################################################################################################

        for request_wrapper, xpath_string_pattern, transport in self.get_xml_soap_config():

            # XML request/response over XMLClient
            client = self.set_up_client_and_channel(service_name, 'xml', transport)
            response = self.invoke_xml(client, request_wrapper.format('<dummy/>').encode('utf-8'))

            actual_items = {}

            for name in ('name', 'is_active', 'impl_name', 'is_internal', 'slow_threshold'):
                actual_items[name] = self.get_xml_value_from_response(xpath_string_pattern, response, name)

            eq_(sorted(actual_items.items()), expected)

# ################################################################################################################################


########NEW FILE########
__FILENAME__ = zato_test_live_sio
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from contextlib import closing
from copy import deepcopy
from logging import getLogger

# Bunch
from bunch import bunchify

# nose
from nose.tools import eq_

# Zato
from zato.common.odb.model import Cluster, Service as ServiceModel
from zato.server.service import AsIs, Boolean, CSV, Dict, Float, ForceType, Integer, List, ListOfDicts, Service, Unicode, UTC

logger = getLogger(__name__)

# ################################################################################################################################

class _TestBase(Service):

    test_data = bunchify({
        'should_as_is': 'True',
        'is_boolean': 'True',
        'should_boolean': 'False',
        'csv1': '1,2,3,4',
        'dict': {'a':'b', 'c':'d'},
        'float': '2.3',
        'integer': '190',
        'integer2': '0',
        'list': ['1', '2', '3'],
        'list_of_dicts': [{'1':'11', '2':'22'}, {'3':'33'}, {'4':'44', '5':'55', '3':'33', '2':'22', '1':'11'}],
        'unicode1': 'zzz',
        'unicode2': 'z',
        'utc': '2012-01-12T03:12:19+00:00'
    })

    class SimpleIO:
        input_required = (AsIs('should_as_is'), 'is_boolean', 'should_boolean', CSV('csv1'), Dict('dict'), Float('float'),
            Integer('integer'), Integer('integer2'), List('list'), ListOfDicts('list_of_dicts'), Unicode('unicode1'),
            Unicode('unicode2'), UTC('utc'))

        output_required = (AsIs('should_as_is'), 'is_boolean', 'should_boolean', CSV('csv1'), CSV('csv2'), CSV('csv3'),
            Dict('dict'), Float('float'), Integer('integer'), Integer('integer2'), List('list'), ListOfDicts('list_of_dicts'),
            Unicode('unicode1'), Unicode('unicode2'), UTC('utc'))

    @staticmethod
    def check_json(data, testing_request):

        eq_(data.should_as_is, 'True')
        eq_(data.is_boolean, True)
        eq_(data.should_boolean, False)

        if testing_request:
            eq_(data.csv1, ['1', '2', '3', '4'])
        else:
            eq_(data.csv1, '1,2,3,4')
            eq_(data.csv2, '5,6,7,8')
            eq_(data.csv3, '9,10,11,12')

        eq_(sorted(data.dict.items()), [('a', 'b'), ('c', 'd')])
        eq_(data.float, 2.3)
        eq_(data.integer, 190)
        eq_(data.integer2, 0)
        eq_(data.list, ['1', '2', '3'])

        # Note that in list_of_dicts all the keys will be automatically stringified, as required by JSON

        lod = data.list_of_dicts
        eq_(len(lod), 3)
        eq_(sorted(lod[0].items()), [('1', '11'), ('2', '22')])
        eq_(sorted(lod[1].items()), [('3', '33')])
        eq_(sorted(lod[2].items()), [('1', '11'), ('2', '22'), ('3', '33'), ('4', '44'), ('5', '55')])

        eq_(data.unicode1, 'zzz')
        eq_(data.unicode2, 'z')
        eq_(data.utc, '2012-01-12T03:12:19')

    def set_payload_csv(self):
        self.response.payload.csv2 = ['5', '6', '7', '8']
        self.response.payload.csv3 = ('9', '10', '11', '12')

# ################################################################################################################################

class Roundtrip(_TestBase):
    """ Assigns to response all the data received on input.
    """
    def handle(self):
        self.__class__.check_json(self.request.input, True)
        for name in self.SimpleIO.input_required:
            if isinstance(name, ForceType):
                name = name.name
            setattr(self.response.payload, name, self.__class__.test_data[name])
        self.set_payload_csv()

# ################################################################################################################################

class FromDict(_TestBase):
    """ Returns response based on a dictionary.
    """
    def handle(self):
        self.__class__.check_json(self.request.input, True)
        self.response.payload = deepcopy(self.test_data.toDict())
        self.set_payload_csv()

# ################################################################################################################################

class PassthroughToRoundtrip(_TestBase):
    """ Passes everything on to the next service.
    """
    passthrough_to = 'zato-test-live-sio.roundtrip'

# ################################################################################################################################

class PassthroughToFromDict(_TestBase):
    """ Passes everything on to the next service.
    """
    passthrough_to = 'zato-test-live-sio.from-dict'

# ################################################################################################################################

class FromSQLAlchemy(Service):
    """ Creates response from an SQLAlchemy model.
    """
    class SimpleIO:
        output_required = ('name', 'is_active', 'impl_name', 'is_internal', Integer('slow_threshold'))

    def handle(self):
        with closing(self.odb.session()) as session:
            self.response.payload = session.query(ServiceModel.name, ServiceModel.is_active,
                ServiceModel.impl_name, ServiceModel.is_internal, ServiceModel.slow_threshold).\
                filter(Cluster.id==ServiceModel.cluster_id).\
                filter(Cluster.id==self.server.cluster_id).\
                filter(ServiceModel.name=='zato.ping').\
                one()

########NEW FILE########
__FILENAME__ = test_amqp
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Bunch
from bunch import Bunch

# mock
from mock import patch

# Zato
from zato.common import zato_namespace
from zato.common.broker_message import CHANNEL, MESSAGE_TYPE
from zato.common.odb.model import ChannelAMQP, Service
from zato.common.test import rand_bool, rand_int, rand_string, ServiceTestCase
from zato.server.service.internal.channel.amqp import Create, Edit, Delete, GetList

# ##############################################################################

class _Base(ServiceTestCase):
    def get_fake_channel_amqp(self):
        class FakeChannelAMQP(object):
            id = self.id
            def_id = self.def_id
            name = self.name
            
        return FakeChannelAMQP
    
    def get_fake_start_connector(self, request_data):
        def fake_start_connector(repo_location, id, def_id):
            self.assertTrue(isinstance(repo_location, basestring))
            self.assertEquals(id, self.id)
            self.assertEquals(def_id, request_data['def_id'])
            
        return fake_start_connector

# ##############################################################################

class GetListTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetList
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'cluster_id': rand_int()}
    
    def get_response_data(self):
        return Bunch(
            {'id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(), 'queue':rand_string(), 
             'consumer_tag_prefix':rand_string(), 'def_name':rand_string(), 'def_id':rand_int(), 
             'service_name':rand_string(), 'data_format':rand_string()}
        )
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_channel_amqp_get_list_request')
        self.assertEquals(self.sio.response_elem, 'zato_channel_amqp_get_list_response')
        self.assertEquals(self.sio.input_required, ('cluster_id',))
        self.assertEquals(self.sio.output_required, ('id', 'name', 'is_active', 'queue', 'consumer_tag_prefix', 
            'def_name', 'def_id', 'service_name', 'data_format'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.channel.amqp.get-list')
        self.check_impl_list(self.service_class, ChannelAMQP, 
            self.get_request_data(), self.get_response_data(), 
            self.sio.request_elem, self.sio.response_elem)
        
# ##############################################################################

class CreateTestCase(_Base):
    
    def setUp(self):
        self.service_class = Create
        self.sio = self.service_class.SimpleIO
        self.id = rand_int()
        self.def_id = rand_int()
        self.name = rand_string()
        self.mock_data = {
            'odb': [{'session.query.filter.filter.filter.first': False},
                    {'session.query.filter.filter.first': Service()},
                    ],
            }
    
    def get_request_data(self):
        return {'cluster_id':rand_int(), 'name':self.name, 'is_active':rand_bool(), 'def_id':self.def_id,
                'queue':rand_string(), 'consumer_tag_prefix':rand_string(), 'service':rand_string(),
                'data_format':rand_string()}
    
    def get_response_data(self):
        return Bunch({'id':self.id, 'name':self.name})
    
    def test_sio(self):
        
        self.assertEquals(self.sio.request_elem, 'zato_channel_amqp_create_request')
        self.assertEquals(self.sio.response_elem, 'zato_channel_amqp_create_response')
        self.assertEquals(self.sio.input_required, ('cluster_id', 'name', 'is_active', 'def_id', 'queue', 'consumer_tag_prefix', 'service'))
        self.assertEquals(self.sio.input_optional, ('data_format',))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.channel.amqp.create')
        
        request_data = self.get_request_data()
        with patch('zato.server.service.internal.channel.amqp.start_connector', self.get_fake_start_connector(request_data)):
            with patch('zato.server.service.internal.channel.amqp.ChannelAMQP', self.get_fake_channel_amqp()):
                self.check_impl(self.service_class, request_data, self.get_response_data(), 
                    self.sio.response_elem, self.mock_data)
                
# ##############################################################################
            
class EditTestCase(_Base):
    
    def setUp(self):
        self.service_class = Edit
        self.sio = self.service_class.SimpleIO
        self.id = rand_int()
        self.def_id = rand_int()
        self.name = rand_string()
        self.mock_data = {
            'odb': [{'session.query.filter.filter.filter.filter.first': False},
                    {'session.query.filter.filter.first': Service()},
                    {'session.query.filter_by.one': ChannelAMQP(self.id)},
                    ]
            }
        
    def broker_client_publish(self, msg, msg_type):
        self.assertEquals(msg['action'], CHANNEL.AMQP_DELETE)
        self.assertEquals(msg['name'], self.name)
        self.assertEquals(msg_type, MESSAGE_TYPE.TO_AMQP_CONNECTOR_ALL)
    
    def get_request_data(self):
        return {'id': self.id, 'cluster_id':rand_int(), 'name':self.name, 'is_active':rand_bool(), 'queue':rand_string(), 
             'consumer_tag_prefix':rand_string(), 'def_id':self.def_id, 'service':rand_string(), 'data_format':rand_string()}
    
    def get_response_data(self):
        return Bunch({'id':self.id, 'name':self.name})
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_channel_amqp_edit_request')
        self.assertEquals(self.sio.response_elem, 'zato_channel_amqp_edit_response')
        self.assertEquals(self.sio.input_required, ('id', 'cluster_id', 'name', 'is_active', 'def_id', 'queue', 'consumer_tag_prefix', 'service'))
        self.assertEquals(self.sio.input_optional, ('data_format',))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.channel.amqp.edit')
        
        request_data = self.get_request_data()
        with patch('zato.server.service.internal.channel.amqp.start_connector', self.get_fake_start_connector(request_data)):
            with patch('zato.server.service.internal.channel.amqp.ChannelAMQP', self.get_fake_channel_amqp()):
                self.check_impl(self.service_class, request_data, self.get_response_data(), 
                    self.sio.response_elem, self.mock_data)

# ##############################################################################

class DeleteTestCase(_Base):
    
    def setUp(self):
        self.service_class = Delete
        self.sio = self.service_class.SimpleIO
        self.id = rand_int()
        self.name = rand_string()
        self.mock_data = {
            'odb': [{'session.query.filter.one': ChannelAMQP(self.id, self.name)}
                    ]
            }
        
    def broker_client_publish(self, msg, msg_type):
        self.assertEquals(msg['action'], CHANNEL.AMQP_DELETE)
        self.assertEquals(msg['id'], self.id)
        self.assertEquals(msg['name'], self.name)
        self.assertEquals(msg_type, MESSAGE_TYPE.TO_AMQP_CONNECTOR_ALL)
    
    def get_request_data(self):
        return {'id': self.id}
    
    def get_response_data(self):
        return Bunch()
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_channel_amqp_delete_request')
        self.assertEquals(self.sio.response_elem, 'zato_channel_amqp_delete_response')
        self.assertEquals(self.sio.input_required, ('id',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.channel.amqp.delete')
        self.check_impl(self.service_class, self.get_request_data(), self.get_response_data(), 
                            self.sio.response_elem, self.mock_data)

########NEW FILE########
__FILENAME__ = test_jms_wmq
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Bunch
from bunch import Bunch

# Zato
from zato.common import zato_namespace
from zato.common.test import rand_bool, rand_int, rand_string, ServiceTestCase
from zato.server.service.internal.channel.jms_wmq import Create, Edit, Delete, GetList

################################################################################

class GetListTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetList
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'cluster_id': rand_int()}
    
    def get_response_data(self):
        return Bunch(
            {'id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(), 'def_id':rand_int(), 
             'def_name':rand_string(), 'queue':rand_string(),
             'service_name':rand_string(), 'data_format':rand_string()}
        )
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_channel_jms_wmq_get_list_request')
        self.assertEquals(self.sio.response_elem, 'zato_channel_jms_wmq_get_list_response')
        self.assertEquals(self.sio.input_required, ('cluster_id',))
        self.assertEquals(self.sio.output_required, ('id', 'name', 'is_active', 'def_id', 'def_name', 'queue', 'service_name'))
        self.assertEquals(self.sio.output_optional, ('data_format',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.channel.jms-wmq.get-list')
        
##############################################################################

class CreateTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Create
        self.sio = self.service_class.SimpleIO      
    
    def get_request_data(self):
        return {'cluster_id':rand_int(), 'name':self.name, 'is_active':rand_bool(), 'def_id':self.def_id, 'queue':rand_bool(), 
             'service':rand_string(),'data_format':rand_string()}
    
    def get_response_data(self):
        return Bunch({'id':self.id, 'name':self.name})
    
    def test_sio(self):
        
        self.assertEquals(self.sio.request_elem, 'zato_channel_jms_wmq_create_request')
        self.assertEquals(self.sio.response_elem, 'zato_channel_jms_wmq_create_response')
        self.assertEquals(self.sio.input_required, ('cluster_id', 'name', 'is_active', 'def_id', 'queue', 'service'))
        self.assertEquals(self.sio.input_optional, ('data_format',))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
        def test_impl(self):
            self.assertEquals(self.service_class.get_name(), 'zato.channel.jms-wmq.create')
       
###############################################################################
            
class EditTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Edit
        self.sio = self.service_class.SimpleIO
        
    def get_request_data(self):
        return {'id': self.id, 'cluster_id':rand_int(), 'name':self.name, 'is_active':rand_bool(), 'def_id':self.def_id,
            'queue':rand_string(), 'service':rand_string(), 'data_format':rand_string()}
    
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':self.name})
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_channel_jms_wmq_edit_request')
        self.assertEquals(self.sio.response_elem, 'zato_channel_jms_wmq_edit_response')
        self.assertEquals(self.sio.input_required, ('id', 'cluster_id', 'name', 'is_active', 'def_id', 'queue', 'service'))
        self.assertEquals(self.sio.input_optional, ('data_format',))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.channel.jms-wmq.edit')

##############################################################################

class DeleteTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Delete
        self.sio = self.service_class.SimpleIO
  
    def get_request_data(self):
        return {'id': self.id}
    
    def get_response_data(self):
        return Bunch()
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_channel_jms_wmq_delete_request')
        self.assertEquals(self.sio.response_elem, 'zato_channel_jms_wmq_delete_response')
        self.assertEquals(self.sio.input_required, ('id',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.channel.jms-wmq.delete')

########NEW FILE########
__FILENAME__ = test_zmq
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Bunch
from bunch import Bunch

# Zato
from zato.common import zato_namespace
from zato.common.test import rand_bool, rand_int, rand_string, ServiceTestCase
from zato.server.service.internal.channel.zmq import Create, Edit, Delete, GetList

################################################################################

class GetListTestCase(ServiceTestCase):

    def setUp(self):
        self.service_class = GetList
        self.sio = self.service_class.SimpleIO

    def get_request_data(self):
        return {'cluster_id': rand_int()}

    def get_response_data(self):
        return Bunch(
            {'id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(), 'address':rand_string(),
             'socket_type':rand_string(), 'sub_key':rand_string(),
             'service_name':rand_string(), 'data_format':rand_string()}
        )

    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_channel_zmq_get_list_request')
        self.assertEquals(self.sio.response_elem, 'zato_channel_zmq_get_list_response')
        self.assertEquals(self.sio.input_required, ('cluster_id',))
        self.assertEquals(self.sio.output_required, ('id', 'name', 'is_active', 'address', 'socket_type', 'service_name', 'data_format'))
        self.assertEquals(self.sio.output_optional, ('sub_key',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')

    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.channel.zmq.get-list')

##############################################################################

class CreateTestCase(ServiceTestCase):

    def setUp(self):
        self.service_class = Create
        self.sio = self.service_class.SimpleIO

    def get_request_data(self):
        return {'cluster_id':rand_int(), 'name':self.name, 'is_active':rand_bool(), 'address':rand_string(),
             'socket_type':rand_string(),'service':rand_string(),
             'sub_key':rand_string(),'data_format':rand_string()}

    def get_response_data(self):
        return Bunch({'id':self.id, 'name':self.name})

    def test_sio(self):

        self.assertEquals(self.sio.request_elem, 'zato_channel_zmq_create_request')
        self.assertEquals(self.sio.response_elem, 'zato_channel_zmq_create_response')
        self.assertEquals(self.sio.input_required, ('cluster_id', 'name', 'is_active', 'address', 'socket_type', 'service'))
        self.assertEquals(self.sio.input_optional, ('sub_key', 'data_format',))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')

        def test_impl(self):
            self.assertEquals(self.service_class.get_name(), 'zato.channel.zmq.create')

###############################################################################

class EditTestCase(ServiceTestCase):

    def setUp(self):
        self.service_class = Edit
        self.sio = self.service_class.SimpleIO

    def get_request_data(self):
        return {'id':rand_int(), 'cluster_id':rand_int(), 'name':self.name, 'is_active':rand_bool(), 'address':rand_string(),
             'socket_type':rand_string(),'service':rand_string(), 'sub_key':rand_string(),'data_format':rand_string()}

    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':self.name})

    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_channel_zmq_edit_request')
        self.assertEquals(self.sio.response_elem, 'zato_channel_zmq_edit_response')
        self.assertEquals(self.sio.input_required, ('id', 'cluster_id', 'name', 'is_active', 'address', 'socket_type', 'service'))
        self.assertEquals(self.sio.input_optional, ('sub_key', 'data_format',))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')

    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.channel.zmq.edit')

##############################################################################

class DeleteTestCase(ServiceTestCase):

    def setUp(self):
        self.service_class = Delete
        self.sio = self.service_class.SimpleIO

    def get_request_data(self):
        return {'id': self.id}

    def get_response_data(self):
        return Bunch()

    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_channel_zmq_delete_request')
        self.assertEquals(self.sio.response_elem, 'zato_channel_zmq_delete_response')
        self.assertEquals(self.sio.input_required, ('id',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')

    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.channel.zmq.delete')

########NEW FILE########
__FILENAME__ = test_amqp
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Bunch
from bunch import Bunch

# Zato
from zato.common import zato_namespace
from zato.common.test import rand_bool, rand_int, rand_string, ServiceTestCase
from zato.server.service.internal.definition.amqp import GetList, GetByID, Create, Edit, Delete, ChangePassword

################################################################################

class GetListTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetList
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'cluster_id': rand_int()}
    
    def get_response_data(self):
        return Bunch(
            {'id':rand_int(), 'name':rand_string(), 'host':rand_string(), 'port':rand_int(),
             'vhost':rand_string(), 'username':rand_string(), 'frame_max':rand_int(),
             'heartbeat':rand_int(), 'output_repeated':rand_bool()}
        )
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_definition_amqp_get_list_request')
        self.assertEquals(self.sio.response_elem, 'zato_definition_amqp_get_list_response')
        self.assertEquals(self.sio.input_required, ('cluster_id',))
        self.assertEquals(self.sio.output_required, ('id', 'name', 'host', 'port', 'vhost', 'username', 'frame_max', 'heartbeat'))
        self.assertEquals(self.sio.output_repeated, (True))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.definition.amqp.get-list')
        
##############################################################################

class GetByIDTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetByID
        self.sio = self.service_class.SimpleIO
        
    def get_request_data(self):
        return {'id':self.id, 'cluster_id':self.cluster_id}   
    
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':self.name, 'host':rand_string(), 'port':rand_int(), 
             'vhost':rand_string(),'username':rand_string(),
             'frame_max':rand_int(),'heartbeat':rand_int()})
    
    def test_sio(self):        
        self.assertEquals(self.sio.request_elem, 'zato_definition_amqp_get_by_id_request')
        self.assertEquals(self.sio.response_elem, 'zato_definition_amqp_get_by_id_response')
        self.assertEquals(self.sio.input_required, ('id', 'cluster_id'))
        self.assertEquals(self.sio.output_required, ('id', 'name', 'host', 'port', 'vhost', 'username', 'frame_max', 'heartbeat'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        
        def test_impl(self):
            self.assertEquals(self.service_class.get_name(), 'zato.definition.amqp.get_by_id')
       
###############################################################################
class CreateTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Create
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'cluster_id':rand_int(), 'name':self.name, 'host':rand_string(),
                'port':rand_int(), 'vhost':rand_string(), 'username':rand_string(),
                'frame_max':rand_int(), 'heartbeat':rand_int()}
    
    def get_response_data(self):
        return Bunch({'id':self.id, 'name':self.name})
    
    def test_sio(self):
        
        self.assertEquals(self.sio.request_elem, 'zato_definition_amqp_create_request')
        self.assertEquals(self.sio.response_elem, 'zato_definition_amqp_create_response')
        self.assertEquals(self.sio.input_required, ('cluster_id', 'name', 'host', 'port', 'vhost', 'username', 'frame_max', 'heartbeat'))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.definition.amqp.create')

###############################################################################      
            
class EditTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Edit
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'id': rand_int(), 'cluster_id':rand_int(), 'name':self.name, 'host':rand_string(),
            'port':rand_int(), 'vhost':rand_string(), 'username':rand_string(), 'frame_max':rand_int(), 'heartbeat':rand_int()}
    
    def get_response_data(self):
        return Bunch({'id':self.id, 'name':self.name})
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_definition_amqp_edit_request')
        self.assertEquals(self.sio.response_elem, 'zato_definition_amqp_edit_response')
        self.assertEquals(self.sio.input_required, ('id', 'cluster_id', 'name', 'host', 'port', 'vhost', 'username', 'frame_max', 'heartbeat'))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.definition.amqp.edit')

##############################################################################

class DeleteTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Delete
        self.sio = self.service_class.SimpleIO
                
    def get_request_data(self):
        return {'id': rand_int()}
    
    def get_response_data(self):
        return Bunch()
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_definition_amqp_delete_request')
        self.assertEquals(self.sio.response_elem, 'zato_definition_amqp_delete_response')
        self.assertEquals(self.sio.input_required, ('id',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.definition.amqp.delete')

##############################################################################

class ChangePasswordCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = ChangePassword
        self.sio = self.service_class.SimpleIO
        
    def get_request_data(self):
        return({'id':rand_int(), 'password1':rand_string(), 'password2':rand_string()})
    
    def get_response_data(self):
        return Bunch()
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_definition_amqp_change_password_request')
        self.assertEquals(self.sio.response_elem, 'zato_definition_amqp_change_password_response')
        self.assertEquals(self.sio.input_required, ('id', 'password1', 'password2'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.definition.amqp.change-password')

########NEW FILE########
__FILENAME__ = test_jms_wmq
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Bunch
from bunch import Bunch

# Zato
from zato.common import zato_namespace
from zato.common.test import rand_bool, rand_int, rand_string, ServiceTestCase
from zato.server.service import Boolean, Integer
from zato.server.service.internal.definition.jms_wmq import Create, GetByID, Edit, Delete, GetList

################################################################################

class GetListTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetList
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'cluster_id': rand_int()}
    
    def get_response_data(self):
        return Bunch(
            {'id':rand_int(), 'name':self.name, 'host':rand_string(), 'port':rand_int(),
             'queue_manager':rand_int(), 'channel':rand_string(),
             'cache_open_send_queues':rand_bool(), 'cache_open_receive_queues':rand_bool(),
             'use_shared_connections':rand_bool(), 'ssl':rand_bool(),
             'needs_mcd':rand_bool(), 'max_chars_printed':rand_int(),
             'ssl_cipher_spec':rand_string(), 'ssl_key_repository':rand_string()}
        )
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_definition_jms_wmq_get_list_request')
        self.assertEquals(self.sio.response_elem, 'zato_definition_jms_wmq_get_list_response')
        self.assertEquals(self.sio.input_required, ('cluster_id',))
        self.assertEquals(self.sio.output_required, ('id', 'name', 'host', 'port', 'queue_manager', 'channel', 
                                                     self.wrap_force_type(Boolean('cache_open_send_queues')),
                                                     self.wrap_force_type(Boolean('cache_open_receive_queues')),
                                                     self.wrap_force_type(Boolean('use_shared_connections')),
                                                     self.wrap_force_type(Boolean('ssl')), 'needs_mcd',
                                                     self.wrap_force_type(Integer('max_chars_printed'))))
        self.assertEquals(self.sio.output_optional,('ssl_cipher_spec', 'ssl_key_repository'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.definition.jms-wmq.get-list')
        
##############################################################################

class GetByIDTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetByID
        self.sio = self.service_class.SimpleIO      
    
    def get_request_data(self):
        return {'id':rand_int(), 'cluster_id':rand_int()}
    
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':self.name, 'host':rand_string(), 'port':rand_int(),
             'queue_manager':rand_int(), 'channel':rand_string(),
             'cache_open_send_queues':rand_bool(), 'cache_open_receive_queues':rand_bool(),
             'use_shared_connections':rand_bool(), 'ssl':rand_bool(),
             'needs_mcd':rand_bool(), 'max_chars_printed':rand_int(),
             'ssl_cipher_spec':rand_string(), 'ssl_key_repository':rand_string()})
    
    def test_sio(self):
        
        self.assertEquals(self.sio.request_elem, 'zato_definition_jms_wmq_get_by_id_request')
        self.assertEquals(self.sio.response_elem, 'zato_definition_jms_wmq_get_by_id_response')
        self.assertEquals(self.sio.input_required,('id', 'cluster_id'))
        self.assertEquals(self.sio.output_required, ('id', 'name', 'host', 'port', 'queue_manager', 'channel',
                                                     self.wrap_force_type(Boolean('cache_open_send_queues')),
                                                     self.wrap_force_type(Boolean('cache_open_receive_queues')),
                                                     self.wrap_force_type(Boolean('use_shared_connections')),
                                                     self.wrap_force_type(Boolean('ssl')), 'needs_mcd',
                                                     self.wrap_force_type(Integer('max_chars_printed'))))
        self.assertEquals(self.sio.output_optional,('ssl_cipher_spec', 'ssl_key_repository'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
        def test_impl(self):
            self.assertEquals(self.service_class.get_name(), 'zato.definition.jms-wmq.get-by-id')
       
###############################################################################
class CreateTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Create
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return ({'cluster_id':rand_int(), 'name':self.name, 'host':rand_string(),
                 'port':rand_int(), 'queue_manager':rand_string(), 'channel':rand_string(),
                 'cache_open_send_queues':rand_bool(), 'cache_open_receive_queues':rand_bool(),
                 'use_shared_connections':rand_bool(), 'ssl':rand_bool(), 'needs_mcd':rand_bool(),
                 'max_chars_printed':rand_int(), 'ssl_cipher_spec':rand_string(), 'ssl_key_repository':rand_string()})
        
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':rand_string()})        
    
    def test_sio(self):
        
        self.assertEquals(self.sio.request_elem, 'zato_definition_jms_wmq_create_request')
        self.assertEquals(self.sio.response_elem, 'zato_definition_jms_wmq_create_response')
        self.assertEquals(self.sio.input_required, ('cluster_id', 'name', 'host', 'port', 'queue_manager', 'channel',
                                                    self.wrap_force_type(Boolean('cache_open_send_queues')),
                                                    self.wrap_force_type(Boolean('cache_open_receive_queues')),
                                                    self.wrap_force_type(Boolean('use_shared_connections')),
                                                    self.wrap_force_type(Boolean('ssl')), 'needs_mcd',
                                                    self.wrap_force_type(Integer('max_chars_printed'))))
        self.assertEquals(self.sio.input_optional, ('ssl_cipher_spec', 'ssl_key_repository'))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.definition.jms-wmq.create')

############################################################################### 
           
class EditTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Edit
        self.sio = self.service_class.SimpleIO
    
    def get_response_data(self):
            return ({'id':rand_int(), 'cluster_id':rand_int(), 'name':self.name, 'host':rand_string(),
                          'port':rand_int(), 'queue_manager':rand_string(), 'channel':rand_string(),
                          'cache_open_send_queues':rand_bool(), 'cache_open_receive_queues':rand_bool(),
                          'use_shared_connections':rand_bool(), 'ssl':rand_bool(), 'needs_mcd':rand_bool(),
                          'max_chars_printed':rand_int()})
        
    def get_request_data(self):
            return Bunch({'id':rand_int(), 'name':rand_string()})        
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_definition_jms_wmq_edit_request')
        self.assertEquals(self.sio.response_elem, 'zato_definition_jms_wmq_edit_response')
        self.assertEquals(self.sio.input_required, ('id', 'cluster_id', 'name', 'host', 'port', 'queue_manager', 'channel',
                                                    self.wrap_force_type(Boolean('cache_open_send_queues')),
                                                    self.wrap_force_type(Boolean('cache_open_receive_queues')),
                                                    self.wrap_force_type(Boolean('use_shared_connections')),
                                                    self.wrap_force_type(Boolean('ssl')), 'needs_mcd',
                                                    self.wrap_force_type(Integer('max_chars_printed'))))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.definition.jms-wmq.edit')

##############################################################################

class DeleteTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Delete
        self.sio = self.service_class.SimpleIO
  
    def get_request_data(self):
        return {'id': rand_int()}
    
    def get_response_data(self):
        return Bunch()
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_definition_jms_wmq_delete_request')
        self.assertEquals(self.sio.response_elem, 'zato_definition_jms_wmq_delete_response')
        self.assertEquals(self.sio.input_required, ('id',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.definition.jms-wmq.delete')

########NEW FILE########
__FILENAME__ = test_dictionary
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Bunch
from bunch import Bunch

# Zato
from zato.common import zato_namespace
from zato.common.test import rand_int, rand_string, ServiceTestCase
#from zato.server.service import Boolean, Integer
from zato.server.service.internal.kvdb.data_dict.dictionary import GetList, Create, Edit, GetSystemList, GetKeyList, GetValueList, GetLastID, Delete

################################################################################

class GetListTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetList
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {}
    
    def get_response_data(self):
        return Bunch({'id': rand_int(), 'system':rand_string(), 'key':rand_string(), 'value':rand_string()})
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_kvdb_data_dict_dictionary_get_list_request')
        self.assertEquals(self.sio.response_elem, 'zato_kvdb_data_dict_dictionary_get_list_response')
        self.assertEquals(self.sio.output_required, ('id', 'system', 'key', 'value'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.kvdb.data-dict.dictionary.get-list')
       
##############################################################################

class CreateTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Create
        self.sio = self.service_class.SimpleIO
        
        def get_request_data(self):
            return {'system':rand_string(), 'key':rand_string(), 'value':rand_string(), 'id': rand_int()}
            
        def get_response_data(self):
            return Bunch({'id':rand_int()})        
    
    def test_sio(self):
        
        self.assertEquals(self.sio.request_elem, 'zato_kvdb_data_dict_dictionary_create_request')
        self.assertEquals(self.sio.response_elem, 'zato_kvdb_data_dict_dictionary_create_response')
        self.assertEquals(self.sio.input_required, ('system', 'key', 'value'))
        self.assertEquals(self.sio.input_optional, ('id',))
        self.assertEquals(self.sio.output_required, ('id',))        
        self.assertEquals(self.sio.namespace, zato_namespace)
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.kvdb.data-dict.dictionary.create')

############################################################################### 
          
class EditTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Edit
        self.sio = self.service_class.SimpleIO
        
        def get_request_data(self):
            return {'system':rand_string(), 'key':rand_string(), 'value':rand_string(), 'id': rand_int()}
                    
        def get_response_data(self):
            return Bunch({'id':rand_int()})        
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_kvdb_data_dict_dictionary_edit_request')
        self.assertEquals(self.sio.response_elem, 'zato_kvdb_data_dict_dictionary_edit_response')
        self.assertEquals(self.sio.input_required, ('system', 'key', 'value'))
        self.assertEquals(self.sio.input_optional, ('id',))
        self.assertEquals(self.sio.output_required, ('id',))        
        self.assertEquals(self.sio.namespace, zato_namespace)
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.kvdb.data-dict.dictionary.edit')

##############################################################################

class DeleteTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Delete
        self.sio = self.service_class.SimpleIO
  
    def get_request_data(self):
        return {'id': rand_int()}
    
    def get_response_data(self):
        return Bunch({'id':rand_int()})
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_kvdb_data_dict_dictionary_delete_request')
        self.assertEquals(self.sio.response_elem, 'zato_kvdb_data_dict_dictionary_delete_response')
        self.assertEquals(self.sio.input_required, ('id',))
        self.assertEquals(self.sio.output_required, ('id',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.kvdb.data-dict.dictionary.delete')
        
##############################################################################

class GetSystemListTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetSystemList
        self.sio = self.service_class.SimpleIO
  
    def get_request_data(self):
        return {}
    
    def get_response_data(self):
        return Bunch({'name': rand_string()})
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_kvdb_data_dict_dictionary_get_system_list_request')
        self.assertEquals(self.sio.response_elem, 'zato_kvdb_data_dict_dictionary_get_system_list_response')
        self.assertEquals(self.sio.output_required, ('name',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.kvdb.data-dict.dictionary.get-system-list')
        
##############################################################################

class GetKeyListTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetKeyList
        self.sio = self.service_class.SimpleIO
  
    def get_request_data(self):
        return {'system': rand_string()}
    
    def get_response_data(self):
        return Bunch({'name':rand_string()})
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_kvdb_data_dict_dictionary_get_key_list_request')
        self.assertEquals(self.sio.response_elem, 'zato_kvdb_data_dict_dictionary_get_key_list_response')
        self.assertEquals(self.sio.input_required, ('system',))
        self.assertEquals(self.sio.output_required, ('name',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.kvdb.data-dict.dictionary.get-key-list')
        
##############################################################################

class GetValueListTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetValueList
        self.sio = self.service_class.SimpleIO
  
    def get_request_data(self):
        return {'system': rand_string(), 'key':rand_string()}
    
    def get_response_data(self):
        return Bunch({'name':rand_string()})
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_kvdb_data_dict_dictionary_get_value_list_request')
        self.assertEquals(self.sio.response_elem, 'zato_kvdb_data_dict_dictionary_get_value_list_response')
        self.assertEquals(self.sio.input_required, ('system', 'key'))
        self.assertEquals(self.sio.output_required, ('name',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.kvdb.data-dict.dictionary.get-value-list')
        
class GetLastIDTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetLastID
        self.sio = self.service_class.SimpleIO
  
    def get_request_data(self):
        return {}, ''
    
    def get_response_data(self):
        return Bunch({'value':rand_int()})
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_kvdb_data_dict_dictionary_get_last_id_request')
        self.assertEquals(self.sio.response_elem, 'zato_kvdb_data_dict_dictionary_get_last_id_response')
        self.assertEquals(self.sio.output_optional, ('value',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.kvdb.data-dict.dictionary.get-last-id')

########NEW FILE########
__FILENAME__ = test_impexp
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Bunch
from bunch import Bunch

# Zato
from zato.common import zato_namespace
from zato.common.test import rand_string, ServiceTestCase
from zato.server.service.internal.kvdb.data_dict.impexp import Import

##############################################################################

class ImportTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Import
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'data':rand_string()}
    
    def get_response_data(self):
        return Bunch()
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_kvdb_data_dict_impexp_import_request')
        self.assertEquals(self.sio.response_elem, 'zato_kvdb_data_dict_impexp_import_response')
        self.assertEquals(self.sio.input_required, ('data',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.kvdb.data-dict.impexp.import')

########NEW FILE########
__FILENAME__ = test_translation
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Bunch
from bunch import Bunch

# Zato
from zato.common import zato_namespace
from zato.common.test import rand_int, rand_string, ServiceTestCase
#from zato.server.service import Boolean, Integer
from zato.server.service.internal.kvdb.data_dict.translation import GetList, Create, Edit, Delete, Translate, GetLastID

################################################################################

class GetListTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetList
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {}
    
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'system1':rand_string(), 'key1':rand_string(), 'value1':rand_string,
                      'system2':rand_string(), 'key2':rand_string(), 'value2':rand_string,
                      'id1':rand_int(), 'id2':rand_int()})
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_kvdb_data_dict_translation_get_list_request')
        self.assertEquals(self.sio.response_elem, 'zato_kvdb_data_dict_translation_get_list_response')
        self.assertEquals(self.sio.output_required, ('id', 'system1', 'key1', 'value1', 'system2', 'key2', 'value2', 'id1', 'id2'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_required')    
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.kvdb.data-dict.translation.get-list')
       
##############################################################################

class CreateTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Create
        self.sio = self.service_class.SimpleIO
        
        def get_request_data(self):
            return {'system1':rand_string(), 'key1':rand_string(), 'value1':rand_string(),
                    'system2':rand_string(), 'key2':rand_string(), 'value2':rand_string()}
           
        def get_response_data(self):
            return Bunch({'id':rand_int()})    
    
    def test_sio(self):
        
        self.assertEquals(self.sio.request_elem, 'zato_kvdb_data_dict_translation_create_request')
        self.assertEquals(self.sio.response_elem, 'zato_kvdb_data_dict_translation_create_response')
        self.assertEquals(self.sio.input_required, ('system1', 'key1', 'value1', 'system2', 'key2', 'value2'))
        self.assertEquals(self.sio.output_required, ('id',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')        

    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.kvdb.data-dict.translation.create')

############################################################################### 
          
class EditTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Edit
        self.sio = self.service_class.SimpleIO
        
        def get_request_data(self):
            return {'id':rand_int(), 'system1':rand_string(), 'key1':rand_string(), 'value1':rand_string(),
                    'system2':rand_string(),'key2':rand_string(), 'value2':rand_string()}
                   
        def get_response_data(self):
            return Bunch({'id':rand_int()})        
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_kvdb_data_dict_translation_edit_request')
        self.assertEquals(self.sio.response_elem, 'zato_kvdb_data_dict_translation_edit_response')
        self.assertEquals(self.sio.input_required, ('id', 'system1', 'key1', 'value1', 'system2', 'key2', 'value2'))
        self.assertEquals(self.sio.output_required, ('id',))        
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')        

    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.kvdb.data-dict.translation.edit')

##############################################################################

class DeleteTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Delete
        self.sio = self.service_class.SimpleIO
  
    def get_request_data(self):
        return {'id': rand_int()}
    
    def get_response_data(self):
        return Bunch()
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_kvdb_data_dict_translation_delete_request')
        self.assertEquals(self.sio.response_elem, 'zato_kvdb_data_dict_translation_delete_response')
        self.assertEquals(self.sio.input_required, ('id',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.kvdb.data-dict.translation.delete')
        
##############################################################################

class TranslateTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Translate
        self.sio = self.service_class.SimpleIO
        
        def get_request_data(self):
            return {'system1':rand_string(), 'key1':rand_string(), 'value1':rand_string(), 'system2':rand_string(), 'key2':rand_string()}
            
        def get_response_data(self):
            return Bunch({'value2':rand_string(), 'repr':rand_string(), 'hex':rand_string(), 'sha1':rand_string(), 'sha256':rand_string()})        
    
    def test_sio(self):
        
        self.assertEquals(self.sio.request_elem, 'zato_kvdb_data_dict_translation_translate_request')
        self.assertEquals(self.sio.response_elem, 'zato_kvdb_data_dict_translation_translate_response')
        self.assertEquals(self.sio.input_required, ('system1', 'key1', 'value1', 'system2', 'key2'))
        self.assertEquals(self.sio.output_optional, ('value2', 'repr', 'hex', 'sha1', 'sha256'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')  
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')        
        self.assertEquals(self.sio.namespace, zato_namespace)
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.kvdb.data-dict.translation.translate')

############################################################################### 
        
class GetLastIDCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetLastID
        self.sio = self.service_class.SimpleIO
  
    def get_request_data(self):
        return {}
    
    def get_response_data(self):
        return Bunch({'value':rand_int()})
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_kvdb_data_dict_translation_get_last_id_request')
        self.assertEquals(self.sio.response_elem, 'zato_kvdb_data_dict_translation_get_last_id_response')
        self.assertEquals(self.sio.output_optional, ('value',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.kvdb.data-dict.translation.get-last-id')

########NEW FILE########
__FILENAME__ = test_swift
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

# stdlib
from unittest import TestCase

# Zato
from zato.server.service.internal.notif.cloud.openstack.swift import RunNotifier

class SwiftTestCase(TestCase):
    def test_name_matches(self):

        service = RunNotifier()

        test_data = (
            ('**', 'abc', False, True),
            ('**', 'abc', True, False),

            ('a**', 'abc', False, True),
            ('a**', 'abc', True, False),

            ('a*', 'abc/def', False, False),
            ('a*', 'abc/def', True, True),

            ('a*/*', 'abc/def', False, True),
            ('a*/*', 'abc/def', True, False),

            ('a*/d?f', 'abc/def', False, True),
            ('a*/d?f', 'abc/def', True, False),

            ('a*\\\*', r'abc\def', False, True),
            ('a*\\\*', r'abc\def', True, False),

        )

        for pattern, string, negate, expected in test_data:
            result = service._name_matches(pattern, string, negate)
            self.assertEquals(result, expected, '`{}` != `{}`, {} {} {}'.format(result, expected, pattern, string, negate))

########NEW FILE########
__FILENAME__ = test_amqp
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Bunch
from bunch import Bunch

# Zato
from zato.common import zato_namespace
from zato.common.test import rand_bool, rand_int, rand_string, ServiceTestCase
from zato.server.service import AsIs, Integer
from zato.server.service.internal.outgoing.amqp import Create, Edit, Delete, GetList

##############################################################################

class GetListTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetList
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'cluster_id': rand_int()}
    
    def get_response_data(self):
        return Bunch(
            {'id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(), 'def_id':rand_int(), 
             'delivery_mode':rand_int(), 'priority':rand_int(), 'def_name':rand_string(), 
             'content_type':rand_string(), 'content_encoding':rand_string(),
             'cexpiration':rand_int(), 'user_id':rand_string(),
             'app_id':rand_string()}
        )
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_outgoing_amqp_get_list_request')
        self.assertEquals(self.sio.response_elem, 'zato_outgoing_amqp_get_list_response')
        self.assertEquals(self.sio.input_required, ('cluster_id',))
        self.assertEquals(self.sio.output_required, ('id', 'name', 'is_active', 'def_id', 'delivery_mode', 'priority', 'def_name'))
        self.assertEquals(self.sio.output_optional, ('content_type', 'content_encoding', 'expiration',
            self.wrap_force_type(AsIs('user_id')), self.wrap_force_type(AsIs('app_id'))))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.outgoing.amqp.get-list')
        
##############################################################################

class CreateTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Create
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'cluster_id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(), 'def_id':rand_int(),
                'delivery_mode':rand_int(),'priority':rand_int(), 'content_type':rand_string(), 'content_encoding':rand_string(),
                'expiration':rand_int(), 'user_id':rand_string(), 'app_id':rand_string()}
    
    def get_response_data(self):
        return Bunch({'id':self.id, 'name':self.name})
    
    def test_sio(self):
        
        self.assertEquals(self.sio.request_elem, 'zato_outgoing_amqp_create_request')
        self.assertEquals(self.sio.response_elem, 'zato_outgoing_amqp_create_response')
        self.assertEquals(self.sio.input_required, ('cluster_id', 'name', 'is_active', 'def_id', 'delivery_mode', 'priority'))
        self.assertEquals(self.sio.input_optional, ('content_type', 'content_encoding', 'expiration',
                                                    self.wrap_force_type(AsIs('user_id')), self.wrap_force_type(AsIs('app_id'))))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.outgoing.amqp.create')

               
##############################################################################
            
class EditTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Edit
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'id':rand_int(), 'cluster_id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(), 'def_id':rand_int(),
                'delivery_mode':rand_string(),'priority':rand_int(), 'content_type':rand_string(), 'content_encoding':rand_string(),
                'expiration':rand_int(), 'user_id':rand_string(), 'app_id':rand_string()}
    
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':rand_string()})
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_outgoing_amqp_edit_request')
        self.assertEquals(self.sio.response_elem, 'zato_outgoing_amqp_edit_response')
        self.assertEquals(self.sio.input_required, ('id', 'cluster_id', 'name', 'is_active', 'def_id', 'delivery_mode',
                                                    self.wrap_force_type(Integer('priority'))))
        self.assertEquals(self.sio.input_optional, ('content_type', 'content_encoding', 'expiration',
                                                    self.wrap_force_type(AsIs('user_id')), self.wrap_force_type(AsIs('app_id'))))       
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.outgoing.amqp.edit')

##############################################################################

class DeleteTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Delete
        self.sio = self.service_class.SimpleIO
         
    def get_request_data(self):
        return {'id': rand_int()}
    
    def get_response_data(self):
        return Bunch()
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_outgoing_amqp_delete_request')
        self.assertEquals(self.sio.response_elem, 'zato_outgoing_amqp_delete_response')
        self.assertEquals(self.sio.input_required, ('id',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.outgoing.amqp.delete')

########NEW FILE########
__FILENAME__ = test_ftp
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Bunch
from bunch import Bunch

# Zato
from zato.common import zato_namespace
from zato.common.test import rand_bool, rand_int, rand_string, ServiceTestCase
from zato.server.service import Boolean
from zato.server.service.internal.outgoing.ftp import GetList, Create, Edit, Delete, ChangePassword

##############################################################################

class GetListTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetList
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'cluster_id': rand_int()}
    
    def get_response_data(self):
        return Bunch(
            {'id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(), 'host':rand_string(), 
             'port':rand_int(), 'user':rand_string(), 'acct':rand_string(), 
             'timeout':rand_int(), 'dircache':rand_bool()}
        )
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_outgoing_ftp_get_list_request')
        self.assertEquals(self.sio.response_elem, 'zato_outgoing_ftp_get_list_response')
        self.assertEquals(self.sio.input_required, ('cluster_id',))
        self.assertEquals(self.sio.output_required, ('id', 'name', 'is_active', 'host', 'port'))
        self.assertEquals(self.sio.output_optional, ('user', 'acct', 'timeout', self.wrap_force_type(Boolean('dircache'))))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.outgoing.ftp.get-list')
        
##############################################################################

class CreateTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Create
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'cluster_id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(), 'host':rand_string(),
                'port':rand_int(),'dircache':rand_bool(), 'user':rand_string(), 'acct':rand_string(), 'timeout':rand_int()}
    
    def get_response_data(self):
        return Bunch({'id':self.id, 'name':self.name})
    
    def test_sio(self):
        
        self.assertEquals(self.sio.request_elem, 'zato_outgoing_ftp_create_request')
        self.assertEquals(self.sio.response_elem, 'zato_outgoing_ftp_create_response')
        self.assertEquals(self.sio.input_required, ('cluster_id', 'name', 'is_active', 'host', 'port', self.wrap_force_type(Boolean('dircache'))))
        self.assertEquals(self.sio.input_optional, ('user', 'acct', 'timeout'))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.outgoing.ftp.create')
              
##############################################################################
           
class EditTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Edit
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'id':rand_int(), 'cluster_id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(),
                'host':rand_string(),'port':rand_int(), 'dircache':rand_bool(), 'user':rand_string(), 'acct':rand_string(),
                'timeout':rand_int()}
    
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':rand_string()})
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_outgoing_ftp_edit_request')
        self.assertEquals(self.sio.response_elem, 'zato_outgoing_ftp_edit_response')
        self.assertEquals(self.sio.input_required, ('id', 'cluster_id', 'name', 'is_active', 'host', 'port',
                                                    self.wrap_force_type(Boolean('dircache'))))
        self.assertEquals(self.sio.input_optional, ('user', 'acct', 'timeout'))       
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.outgoing.ftp.edit')

##############################################################################

class DeleteTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Delete
        self.sio = self.service_class.SimpleIO
         
    def get_request_data(self):
        return {'id':rand_int()}
    
    def get_response_data(self):
        return Bunch()
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_outgoing_ftp_delete_request')
        self.assertEquals(self.sio.response_elem, 'zato_outgoing_ftp_delete_response')
        self.assertEquals(self.sio.input_required, ('id',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.outgoing.ftp.delete')
        
##############################################################################
        
class ChangePasswordTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = ChangePassword
        self.sio = self.service_class.SimpleIO
         
    def get_request_data(self):
        return {'id':rand_int(), 'password1':rand_string(), 'password2':rand_string()}
    
    def get_response_data(self):
        return Bunch()
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_outgoing_ftp_change_password_request')
        self.assertEquals(self.sio.response_elem, 'zato_outgoing_ftp_change_password_response')
        self.assertEquals(self.sio.input_required, ('id', 'password1', 'password2'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.outgoing.ftp.change-password')

########NEW FILE########
__FILENAME__ = test_jms_wmq
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Bunch
from bunch import Bunch

# Zato
from zato.common import zato_namespace
from zato.common.test import rand_bool, rand_int, rand_string, ServiceTestCase
from zato.server.service import Integer
from zato.server.service.internal.outgoing.jms_wmq import Create, Edit, Delete, GetList

##############################################################################

class GetListTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetList
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'cluster_id': rand_int()}
    
    def get_response_data(self):
        return Bunch(
            {'id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(), 'def_id':rand_int(), 
             'delivery_mode':rand_int(), 'priority':rand_int(), 'def_name':rand_string(), 
             'expiration':rand_int()}
        )
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_outgoing_jms_wmq_get_list_request')
        self.assertEquals(self.sio.response_elem, 'zato_outgoing_jms_wmq_get_list_response')
        self.assertEquals(self.sio.input_required, ('cluster_id',))
        self.assertEquals(self.sio.output_required, ('id', 'name', 'is_active', 'def_id',
                                                     self.wrap_force_type(Integer('delivery_mode')),
                                                     self.wrap_force_type(Integer('priority')), 'def_name'))
        self.assertEquals(self.sio.output_optional, ('expiration',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.outgoing.jms-wmq.get-list')
        
##############################################################################

class CreateTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Create
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'cluster_id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(), 'def_id':rand_int(),
                'delivery_mode':rand_int(),'priority':rand_int(), 'expiration':rand_int()}
    
    def get_response_data(self):
        return Bunch({'id':self.id, 'name':self.name})
    
    def test_sio(self):
        
        self.assertEquals(self.sio.request_elem, 'zato_outgoing_jms_wmq_create_request')
        self.assertEquals(self.sio.response_elem, 'zato_outgoing_jms_wmq_create_response')
        self.assertEquals(self.sio.input_required, ('cluster_id', 'name', 'is_active', 'def_id',
                                                    self.wrap_force_type(Integer('delivery_mode')),
                                                    self.wrap_force_type(Integer('priority'))))
        self.assertEquals(self.sio.input_optional, ('expiration',))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.outgoing.jms-wmq.create')

               
##############################################################################
            
class EditTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Edit
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'id':rand_int(), 'cluster_id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(), 'def_id':rand_int(),
                'delivery_mode':rand_int(), 'priority':rand_int(), 'expiration':rand_int()}
    
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':rand_string()})
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_outgoing_jms_wmq_edit_request')
        self.assertEquals(self.sio.response_elem, 'zato_outgoing_jms_wmq_edit_response')
        self.assertEquals(self.sio.input_required, ('id', 'cluster_id', 'name', 'is_active', 'def_id',
                                                    self.wrap_force_type(Integer('delivery_mode')),
                                                    self.wrap_force_type(Integer('priority'))))
        self.assertEquals(self.sio.input_optional, ('expiration',))       
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.outgoing.jms-wmq.edit')

##############################################################################

class DeleteTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Delete
        self.sio = self.service_class.SimpleIO
         
    def get_request_data(self):
        return {'id':rand_int()}
    
    def get_response_data(self):
        return Bunch()
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_outgoing_jms_wmq_delete_request')
        self.assertEquals(self.sio.response_elem, 'zato_outgoing_jms_wmq_delete_response')
        self.assertEquals(self.sio.input_required, ('id',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.outgoing.jms-wmq.delete')

########NEW FILE########
__FILENAME__ = test_sql
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Bunch
from bunch import Bunch

# Zato
from zato.common import zato_namespace
from zato.common.test import rand_bool, rand_float, rand_int, rand_string, ServiceTestCase
from zato.server.service import Integer
from zato.server.service.internal.outgoing.sql import GetList, Create, Edit, Delete, ChangePassword, Ping

##############################################################################

class GetListTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetList
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'cluster_id': rand_int()}
    
    def get_response_data(self):
        return Bunch(
            {'id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(), 'cluster_id':rand_int(), 'engine':rand_string(),
             'host':rand_string(), 'port':rand_int(), 'db_name':rand_string(), 'username':rand_string(), 'pool_size':rand_int(), 
             'extra':rand_string()}
        )
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_outgoing_sql_get_list_request')
        self.assertEquals(self.sio.response_elem, 'zato_outgoing_sql_get_list_response')
        self.assertEquals(self.sio.input_required, ('cluster_id',))
        self.assertEquals(self.sio.output_required, ('id', 'name', 'is_active', 'cluster_id', 'engine', 'host',
                                                     self.wrap_force_type(Integer('port')), 'db_name', 'username',
                                                     self.wrap_force_type(Integer('pool_size'))))
        self.assertEquals(self.sio.output_optional, ('extra',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.outgoing.sql.get-list')
       
##############################################################################

class CreateTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Create
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'name':rand_string(), 'is_active':rand_bool(), 'cluster_id':rand_int(), 'engine':rand_string(),
             'host':rand_string(), 'port':rand_int(), 'db_name':rand_string(), 'username':rand_string(), 'pool_size':rand_int(), 
             'extra':rand_string()}
    
    def get_response_data(self):
        return Bunch({'id':self.id, 'name':self.name})
    
    def test_sio(self):
        
        self.assertEquals(self.sio.request_elem, 'zato_outgoing_sql_create_request')
        self.assertEquals(self.sio.response_elem, 'zato_outgoing_sql_create_response')
        self.assertEquals(self.sio.input_required, ('name', 'is_active', 'cluster_id', 'engine', 'host',
                                                     self.wrap_force_type(Integer('port')), 'db_name', 'username',
                                                     self.wrap_force_type(Integer('pool_size'))))
        self.assertEquals(self.sio.input_optional, ('extra',))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.outgoing.sql.create')

               
##############################################################################
            
class EditTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Edit
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(), 'cluste_id':rand_int(), 'engine':rand_string(),
                'host':rand_string(), 'port':rand_int(), 'db_name':rand_string(), 'username':rand_string(), 'pool_size':rand_int(), 'extra':rand_string()}
    
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':rand_string()})
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_outgoing_sql_edit_request')
        self.assertEquals(self.sio.response_elem, 'zato_outgoing_sql_edit_response')
        self.assertEquals(self.sio.input_required, ('id', 'name', 'is_active', 'cluster_id', 'engine', 'host',
                                                    self.wrap_force_type(Integer('port')), 'db_name', 'username',
                                                    self.wrap_force_type(Integer('pool_size'))))
        self.assertEquals(self.sio.input_optional, ('extra',))       
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.outgoing.sql.edit')

##############################################################################

class DeleteTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Delete
        self.sio = self.service_class.SimpleIO
         
    def get_request_data(self):
        return {'id': self.id}
    
    def get_response_data(self):
        return Bunch()
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_outgoing_sql_delete_request')
        self.assertEquals(self.sio.response_elem, 'zato_outgoing_sql_delete_response')
        self.assertEquals(self.sio.input_required, ('id',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.outgoing.sql.delete')
        
##############################################################################
        
class ChangePasswordTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = ChangePassword
        self.sio = self.service_class.SimpleIO
         
    def get_request_data(self):
        return {'id':rand_int(), 'password1':rand_string(), 'password2':rand_string()}
    
    def get_response_data(self):
        return Bunch()
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_outgoing_sql_change_password_request')
        self.assertEquals(self.sio.response_elem, 'zato_outgoing_sql_change_password_response')
        self.assertEquals(self.sio.input_required, ('id', 'password1', 'password2'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.outgoing.sql.change-password')
        
##############################################################################
        
class PingTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Ping
        self.sio = self.service_class.SimpleIO
         
    def get_request_data(self):
        return {'id':rand_int()}
    
    def get_response_data(self):
        return Bunch({'response_time':rand_float()})
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_outgoing_sql_ping_request')
        self.assertEquals(self.sio.response_elem, 'zato_outgoing_sql_ping_response')
        self.assertEquals(self.sio.input_required, ('id',))
        self.assertEquals(self.sio.output_required, ('response_time',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.outgoing.sql.ping')

########NEW FILE########
__FILENAME__ = test_zmq
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Bunch
from bunch import Bunch

# Zato
from zato.common import zato_namespace
from zato.common.test import rand_bool, rand_int, rand_string, ServiceTestCase
from zato.server.service.internal.outgoing.zmq import GetList, Create, Edit, Delete

##############################################################################

class GetListTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetList
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'cluster_id': rand_int()}
    
    def get_response_data(self):
        return Bunch(
            {'id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(), 'address':rand_string(), 'socket_type':rand_string()}
        )
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_outgoing_zmq_get_list_request')
        self.assertEquals(self.sio.response_elem, 'zato_outgoing_zmq_get_list_response')
        self.assertEquals(self.sio.input_required, ('cluster_id',))
        self.assertEquals(self.sio.output_required, ('id', 'name', 'is_active', 'address', 'socket_type'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.outgoing.zmq.get-list')
       
##############################################################################

class CreateTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Create
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'cluster_id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(), 'address':rand_string(), 'socket_type':rand_string()}
    
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':rand_string()})
    
    def test_sio(self):
        
        self.assertEquals(self.sio.request_elem, 'zato_outgoing_zmq_create_request')
        self.assertEquals(self.sio.response_elem, 'zato_outgoing_zmq_create_response')
        self.assertEquals(self.sio.input_required, ('cluster_id', 'name', 'is_active', 'address', 'socket_type'))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.outgoing.zmq.create')

               
##############################################################################
            
class EditTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Edit
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'id':rand_int(), 'cluster_id':rand_string(), 'name':rand_string(), 'is_active':rand_bool(), 'address':rand_int(), 'socket_type':rand_string()}
    
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':self.name})
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_outgoing_zmq_edit_request')
        self.assertEquals(self.sio.response_elem, 'zato_outgoing_zmq_edit_response')
        self.assertEquals(self.sio.input_required, ('id', 'cluster_id', 'name', 'is_active', 'address', 'socket_type'))    
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.outgoing.zmq.edit')

##############################################################################

class DeleteTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Delete
        self.sio = self.service_class.SimpleIO
         
    def get_request_data(self):
        return {'id':rand_int()}
    
    def get_response_data(self):
        return Bunch()
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_outgoing_zmq_delete_request')
        self.assertEquals(self.sio.response_elem, 'zato_outgoing_zmq_delete_response')
        self.assertEquals(self.sio.input_required, ('id',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.outgoing.zmq.delete')
        
##############################################################################

########NEW FILE########
__FILENAME__ = test_basic_auth
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Bunch
from bunch import Bunch

# Zato
from zato.common import zato_namespace
from zato.common.test import rand_bool, rand_int, rand_string, ServiceTestCase
from zato.server.service.internal.security.basic_auth import GetList, Create, Edit, ChangePassword, Delete

################################################################################

class GetListTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetList
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'cluster_id': rand_int()}
    
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':self.name, 'is_active':rand_bool(), 'username':rand_string(),
             'realm':rand_string()}
        )
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_security_basic_auth_get_list_request')
        self.assertEquals(self.sio.response_elem, 'zato_security_basic_auth_get_list_response')
        self.assertEquals(self.sio.input_required, ('cluster_id',))
        self.assertEquals(self.sio.output_required, ('id', 'name', 'is_active', 'username', 'realm'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.security.basic-auth.get-list')
        
##############################################################################

class CreateTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Create
        self.sio = self.service_class.SimpleIO      
    
    def get_request_data(self):
        return {'cluster_id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(), 'username':rand_string(), 'realm':rand_string()}
    
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':rand_string()})
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_security_basic_auth_create_request')
        self.assertEquals(self.sio.response_elem, 'zato_security_basic_auth_create_response')
        self.assertEquals(self.sio.input_required,('cluster_id', 'name', 'is_active', 'username', 'realm'))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
        def test_impl(self):
            self.assertEquals(self.service_class.get_name(), 'zato.security.basic-auth.create')
       
###############################################################################
class EditTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Edit
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return ({'id':rand_int(), 'cluster_id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(),
                 'username':rand_string(), 'realm':rand_string()})
        
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':rand_string()})        
    
    def test_sio(self):
        
        self.assertEquals(self.sio.request_elem, 'zato_security_basic_auth_edit_request')
        self.assertEquals(self.sio.response_elem, 'zato_security_basic_auth_edit_response')
        self.assertEquals(self.sio.input_required, ('id', 'cluster_id', 'name', 'is_active', 'username', 'realm'))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.security.basic-auth.edit')
        
############################################################################### 
           
class ChangePasswordTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = ChangePassword
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'id':rand_int(), 'password1':rand_string(), 'password2':rand_string()}
    
    def get_response_data(self):
        return Bunch()    
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_security_basic_auth_change_password_request')
        self.assertEquals(self.sio.response_elem, 'zato_security_basic_auth_change_password_response')
        self.assertEquals(self.sio.input_required, ('id', 'password1', 'password2'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.security.basic-auth.change-password')

##############################################################################

class DeleteTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Delete
        self.sio = self.service_class.SimpleIO
  
    def get_request_data(self):
        return {'id': rand_int()}
    
    def get_response_data(self):
        return Bunch()
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_security_basic_auth_delete_request')
        self.assertEquals(self.sio.response_elem, 'zato_security_basic_auth_delete_response')
        self.assertEquals(self.sio.input_required, ('id',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.security.basic-auth.delete')

########NEW FILE########
__FILENAME__ = test_tech_account
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Bunch
from bunch import Bunch

# Zato
from zato.common import zato_namespace
from zato.common.test import rand_bool, rand_int, rand_string, ServiceTestCase
from zato.server.service.internal.security.tech_account import GetList, GetByID, Create, Edit, ChangePassword, Delete

################################################################################

class GetListTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetList
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'cluster_id': rand_int()}
    
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':self.name, 'is_active':rand_bool()}
        )
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_security_tech_account_get_list_request')
        self.assertEquals(self.sio.response_elem, 'zato_security_tech_account_get_list_response')
        self.assertEquals(self.sio.input_required, ('cluster_id',))
        self.assertEquals(self.sio.output_required, ('id', 'name', 'is_active'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.security.tech-account.get-list')
        
##############################################################################

class GetByIDTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetByID
        self.sio = self.service_class.SimpleIO      
    
    def get_request_data(self):
        return {'id':rand_int()}
    
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':self.name, 'is_active':rand_bool()})
    
    def test_sio(self):        
        self.assertEquals(self.sio.request_elem, 'zato_security_tech_account_get_by_id_request')
        self.assertEquals(self.sio.response_elem, 'zato_security_tech_account_get_by_id_response')
        self.assertEquals(self.sio.input_required,('id',))
        self.assertEquals(self.sio.output_required, ('id', 'name', 'is_active'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
        def test_impl(self):
            self.assertEquals(self.service_class.get_name(), 'zato.security.tech-account.get-by-id')
       
###############################################################################
class CreateTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Create
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return ({'cluster_id':rand_int(), 'name':rand_string(), 'is_active':rand_bool()})
        
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':rand_string()})        
    
    def test_sio(self):
        
        self.assertEquals(self.sio.request_elem, 'zato_security_tech_account_create_request')
        self.assertEquals(self.sio.response_elem, 'zato_security_tech_account_create_response')
        self.assertEquals(self.sio.input_required, ('cluster_id', 'name', 'is_active'))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.security.tech-account.create')
        
###############################################################################

class EditTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Edit
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return ({'id':rand_int(), 'cluster_id':rand_int(), 'name':rand_string(), 'is_active':rand_bool()})
        
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':rand_string()})        
    
    def test_sio(self):        
        self.assertEquals(self.sio.request_elem, 'zato_security_tech_account_edit_request')
        self.assertEquals(self.sio.response_elem, 'zato_security_tech_account_edit_response')
        self.assertEquals(self.sio.input_required, ('id', 'cluster_id', 'name', 'is_active'))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.security.tech-account.edit')
        
###############################################################################         

class ChangePasswordTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = ChangePassword
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'id':rand_int(), 'password1':rand_string(), 'password2':rand_string()}
    
    def get_response_data(self):
        return Bunch()    
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_security_tech_account_change_password_request')
        self.assertEquals(self.sio.response_elem, 'zato_security_tech_account_change_password_response')
        self.assertEquals(self.sio.input_required, ('id', 'password1', 'password2'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.security.tech-account.change-password')

##############################################################################

class DeleteTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Delete
        self.sio = self.service_class.SimpleIO
  
    def get_request_data(self):
        return {'id': rand_int(), 'current_tech_account_name':rand_string()}
    
    def get_response_data(self):
        return Bunch()
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_security_tech_account_delete_request')
        self.assertEquals(self.sio.response_elem, 'zato_security_tech_account_delete_response')
        self.assertEquals(self.sio.input_required, ('id',))
        self.assertEquals(self.sio.input_optional, ('current_tech_account_name',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.security.tech-account.delete')

########NEW FILE########
__FILENAME__ = test_wss
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Bunch
from bunch import Bunch

# Zato
from zato.common import zato_namespace
from zato.common.test import rand_bool, rand_int, rand_string, ServiceTestCase
from zato.server.service import Boolean, Integer
from zato.server.service.internal.security.wss import GetList, Create, Edit, ChangePassword, Delete

################################################################################

class GetListTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetList
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'cluster_id': rand_int()}
    
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':self.name, 'is_active':rand_bool(), 'password_type':rand_string(), 'username':rand_string(),
                      'reject_empty_nonce_creat':rand_bool(), 'reject_stale_tokens':rand_bool(), 'reject_expiry_limit':rand_int(),
                      'nonce_freshness_time':rand_int()}
        )
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_security_wss_get_list_request')
        self.assertEquals(self.sio.response_elem, 'zato_security_wss_get_list_response')
        self.assertEquals(self.sio.input_required, ('cluster_id',))
        self.assertEquals(self.sio.output_required, ('id', 'name', 'is_active', 'password_type', 'username',
                                                     self.wrap_force_type(Boolean('reject_empty_nonce_creat')),
                                                     self.wrap_force_type(Boolean('reject_stale_tokens')),
                                                     self.wrap_force_type(Integer('reject_expiry_limit')),
                                                     self.wrap_force_type(Integer('nonce_freshness_time'))))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.security.wss.get-list')
   
###############################################################################

class CreateTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Create
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return ({'cluster_id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(), 'username':rand_string(),
                 'password_type':rand_string(), 'reject_empty_nonce_creat':rand_bool(), 'reject_stale_tokens':rand_bool(), 'reject_expiry_limit':rand_int(),
                      'nonce_freshness_time':rand_int()}
                )
        
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':rand_string()})        
        
    def test_sio(self):
        
        self.assertEquals(self.sio.request_elem, 'zato_security_wss_create_request')
        self.assertEquals(self.sio.response_elem, 'zato_security_wss_create_response')
        self.assertEquals(self.sio.input_required, ('cluster_id', 'name', 'is_active', 'username', 'password_type',
                                                     self.wrap_force_type(Boolean('reject_empty_nonce_creat')),
                                                     self.wrap_force_type(Boolean('reject_stale_tokens')),
                                                     self.wrap_force_type(Integer('reject_expiry_limit')),
                                                     self.wrap_force_type(Integer('nonce_freshness_time'))))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.security.wss.create')
        
###############################################################################

class EditTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Edit
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return ({'id':rand_int(), 'cluster_id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(), 'username':rand_string(),
                 'password_type':rand_string(), 'reject_empty_nonce_creat':rand_bool(), 'reject_stale_tokens':rand_bool(), 'reject_expiry_limit':rand_int(),
                 'nonce_freshness_time':rand_int()}
                )
        
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':rand_string()})        
    
    def test_sio(self):        
        self.assertEquals(self.sio.request_elem, 'zato_security_wss_edit_request')
        self.assertEquals(self.sio.response_elem, 'zato_security_wss_edit_response')
        self.assertEquals(self.sio.input_required, ('id', 'cluster_id', 'name', 'is_active', 'username', 'password_type',
                                                     self.wrap_force_type(Boolean('reject_empty_nonce_creat')),
                                                     self.wrap_force_type(Boolean('reject_stale_tokens')),
                                                     self.wrap_force_type(Integer('reject_expiry_limit')),
                                                     self.wrap_force_type(Integer('nonce_freshness_time'))))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.security.wss.edit')
        
###############################################################################         

class ChangePasswordTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = ChangePassword
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'id':rand_int(), 'password1':rand_string(), 'password2':rand_string()}
    
    def get_response_data(self):
        return Bunch()    
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_security_wss_change_password_request')
        self.assertEquals(self.sio.response_elem, 'zato_security_wss_change_password_response')
        self.assertEquals(self.sio.input_required, ('id', 'password1', 'password2'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.security.wss.change-password')

##############################################################################

class DeleteTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Delete
        self.sio = self.service_class.SimpleIO
  
    def get_request_data(self):
        return {'id': rand_int()}
    
    def get_response_data(self):
        return Bunch()
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_security_wss_delete_request')
        self.assertEquals(self.sio.response_elem, 'zato_security_wss_delete_response')
        self.assertEquals(self.sio.input_required, ('id',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.security.wss.delete')

########NEW FILE########
__FILENAME__ = test_summary
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# dateutil
from dateutil.parser import parse

# nose
from nose.tools import eq_

# Zato
from zato.common.test import ServiceTestCase
from zato.server.service.internal.stats.summary import GetSummaryByRange

class GetSummaryByRangeTestCase(ServiceTestCase):
    
    def test_get_slice_period_type(self):
        
        service = GetSummaryByRange()

        def _check_expected(orig_start, orig_stop, by_mins, by_hours_mins, by_days_hours_mins, by_months_days_hours_mins):
            start = parse(orig_start)
            stop = parse(orig_stop)
            
            delta, result = service._get_slice_period_type(start, stop, orig_start, orig_stop)
            
            expected = {
                'by_mins': by_mins,
                'by_hours_mins': by_hours_mins,
                'by_days_hours_mins': by_days_hours_mins,
                'by_months_days_hours_mins': by_months_days_hours_mins,
                }
            for k, v in expected.items():
                eq_(result[k], v, 'start:[{}], stop:[{}], result:[{}], k:[{}], values:[{}], delta:[{}]'.format(
                    start, stop, result, k, str((by_mins, by_hours_mins, by_days_hours_mins, by_months_days_hours_mins)),
                str((delta))))
        
        # Minutes only 1)
        start = '2012-10-14T23:56:49'
        stop = '2012-10-15T00:56:49'
        _check_expected(start, stop, True, False, False, False)
        
        # Minutes only 2)
        start = '2007-01-18T19:18:11'
        stop = '2007-01-18T19:38:19'
        _check_expected(start, stop, True, False, False, False)

        # Hours and minutes 1)
        start = '2012-10-14T22:56:49'
        stop = '2012-10-15T00:56:49'
        _check_expected(start, stop, False, True, False, False)
        
        # Hours and minutes 2)
        start = '2009-03-21T03:19:11'
        stop = '2009-03-21T17:32:39'
        _check_expected(start, stop, False, True, False, False)
        
        # Days, hours and minutes 1)
        start = '2012-10-13T22:56:49'
        stop = '2012-10-15T00:56:49'
        _check_expected(start, stop, False, False, True, False)
        
        # Days, hours and minutes 2) (leap year)
        start = '2012-02-28T23:56:49'
        stop = '2012-03-01T00:01:12'
        _check_expected(start, stop, False, False, True, False)

        # Months, days, hours and minutes 1)
        start = '2010-10-13T22:56:49'
        stop = '2012-10-15T00:56:49'
        _check_expected(start, stop, False, False, False, True)
        
        # Months, days, hours and minutes 2)
        start = '208-08-11T18:01:34'
        stop = '2012-11-23T03:42:15'
        _check_expected(start, stop, False, False, False, True)

########NEW FILE########
__FILENAME__ = test_http_soap
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Bunch
from bunch import Bunch

# Zato
from zato.common import zato_namespace
from zato.common.test import ForceTypeWrapper, rand_bool, rand_int, rand_string, ServiceTestCase
from zato.server.service import Bool
from zato.server.service.internal.http_soap import GetList, Create, Edit, Delete, Ping

################################################################################

class GetListTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetList
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'cluster_id': rand_int(), 'connection':rand_string(), 'transport':rand_string()}
    
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':self.name, 'is_active':rand_bool(), 'is_internal':rand_bool(),
            'url_path':rand_string(), 'service_id':rand_int(), 'service_name':rand_string(), 'security_id':rand_int(),
            'security_name':rand_int(), 'sec_type':rand_string(), 'method':rand_string(), 'soap_action':rand_string(),
            'soap_version':rand_string(), 'data_format':rand_string(), 'host':rand_string(), 'ping_method':rand_string(),
            'pool_size':rand_int()}
        )
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_http_soap_get_list_request')
        self.assertEquals(self.sio.response_elem, 'zato_http_soap_get_list_response')
        self.assertEquals(self.sio.input_required, ('cluster_id', 'connection', 'transport'))
        self.assertEquals(self.sio.output_required, ('id', 'name', 'is_active', 'is_internal', 'url_path'))
        self.assertEquals(self.sio.output_optional, ('service_id', 'service_name', 'security_id', 'security_name', 'sec_type',
            'method', 'soap_action', 'soap_version', 'data_format', 'host', 
            'ping_method', 'pool_size', 'merge_url_params_req', 'url_params_pri', 'params_pri', 'serialization_type', 'timeout'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.http-soap.get-list')
   
###############################################################################

class CreateTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Create
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return ({'cluster_id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(), 'connection':rand_string(),
                 'transport':rand_string(), 'is_internal':rand_bool(), 'url_path':rand_string(), 'service':rand_string(),
                 'security_id':rand_int(), 'method':rand_string(), 'soap_action':rand_string(), 'soap_version':rand_string(),
                 'data_format':rand_string(), 'host':rand_string()}
                )
        
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':rand_string()})        
    
    def test_sio(self):
        
        self.assertEquals(self.sio.request_elem, 'zato_http_soap_create_request')
        self.assertEquals(self.sio.response_elem, 'zato_http_soap_create_response')
        self.assertEquals(self.sio.input_required, ('cluster_id', 'name', 'is_active', 'connection', 'transport', 'is_internal', 'url_path'))
        self.assertEquals(self.sio.input_optional, ('service', 'security_id', 'method', 'soap_action', 'soap_version', 'data_format', 'host', 
            'ping_method', 'pool_size', ForceTypeWrapper(Bool('merge_url_params_req')), 'url_params_pri', 'params_pri',
            'serialization_type', 'timeout'))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.http-soap.create')
        
###############################################################################

class EditTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Edit
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return ({'cluster_id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(), 'connection':rand_string(),
                 'transport':rand_string(), 'url_path':rand_string(), 'service':rand_string(), 'security':rand_string(),
                 'security_id':rand_int(), 'method':rand_string(), 'soap_action':rand_string(), 'soap_version':rand_string(),
                 'data_format':rand_string(), 'host':rand_string()}
                )
        
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':rand_string(), })          
    
    def test_sio(self):        
        self.assertEquals(self.sio.request_elem, 'zato_http_soap_edit_request')
        self.assertEquals(self.sio.response_elem, 'zato_http_soap_edit_response')
        self.assertEquals(self.sio.input_required, ('id', 'cluster_id', 'name', 'is_active', 'connection', 'transport', 'url_path'))
        self.assertEquals(self.sio.input_optional, ('service', 'security_id', 'method', 'soap_action', 'soap_version', 'data_format', 'host', 
            'ping_method', 'pool_size', ForceTypeWrapper(Bool('merge_url_params_req')), 'url_params_pri', 'params_pri', 'serialization_type', 'timeout')) 
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.http-soap.edit')

##############################################################################

class DeleteTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Delete
        self.sio = self.service_class.SimpleIO
  
    def get_request_data(self):
        return {'id': rand_int()}
    
    def get_response_data(self):
        return Bunch()
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_http_soap_delete_request')
        self.assertEquals(self.sio.response_elem, 'zato_http_soap_delete_response')
        self.assertEquals(self.sio.input_required, ('id',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.http-soap.delete')
        
##############################################################################

class PingTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Ping
        self.sio = self.service_class.SimpleIO
  
    def get_request_data(self):
        return {'id': rand_int()}
    
    def get_response_data(self):
        return Bunch({'info':rand_string()})
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_http_soap_ping_request')
        self.assertEquals(self.sio.response_elem, 'zato_http_soap_ping_response')
        self.assertEquals(self.sio.input_required, ('id',))
        self.assertEquals(self.sio.output_required, ('info',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.http-soap.ping')

########NEW FILE########
__FILENAME__ = test_scheduler
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Bunch
from bunch import Bunch

# Zato
from zato.common import zato_namespace
from zato.common.test import rand_bool, rand_datetime, rand_int, rand_string, ServiceTestCase
from zato.server.service.internal.scheduler import GetList, GetByName, Create, Edit, Delete, Execute

################################################################################

class GetListTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetList
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'cluster_id': rand_int()}
    
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':self.name, 'is_active':rand_bool(), 'job_type':rand_string(),
                      'start_date':rand_datetime(), 'service_id':rand_int(), 'service_name':rand_string(),
                      'extra':rand_string(), 'weeks':rand_int(), 'days':rand_int(), 'minutes':rand_int(), 'seconds':rand_int(),
                      'repeats':rand_int(), 'cron_definition':rand_string(), '':True}
        )
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_scheduler_job_get_list_request')
        self.assertEquals(self.sio.response_elem, 'zato_scheduler_job_get_list_response')
        self.assertEquals(self.sio.input_required, ('cluster_id',))
        self.assertEquals(self.sio.output_required, ('id', 'name', 'is_active', 'job_type', 'start_date', 'service_id', 'service_name'))
        self.assertEquals(self.sio.output_optional, ('extra', 'weeks', 'days', 'hours', 'minutes', 'seconds', 'repeats', 'cron_definition'))
        self.assertEquals(self.sio.output_repeated, (True))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.scheduler.job.get-list')
        
###############################################################################   


class GetByNameTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetByName
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return {'cluster_id': rand_int(), 'name':rand_string()}
    
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':self.name, 'is_active':rand_bool(), 'job_type':rand_string(),
                      'start_date':rand_datetime(), 'service_id':rand_int(), 'service_name':rand_string(),
                      'extra':rand_string(), 'weeks':rand_int(), 'days':rand_int(), 'minutes':rand_int(), 'seconds':rand_int(),
                      'repeats':rand_int(), 'cron_definition':rand_string(), '':True}
        )
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_scheduler_job_get_by_name_request')
        self.assertEquals(self.sio.response_elem, 'zato_scheduler_job_get_by_name_response')
        self.assertEquals(self.sio.input_required, ('cluster_id', 'name'))
        self.assertEquals(self.sio.output_required, ('id', 'name', 'is_active', 'job_type', 'start_date', 'service_id', 'service_name'))
        self.assertEquals(self.sio.output_optional, ('extra', 'weeks', 'days', 'hours', 'minutes', 'seconds', 'repeats', 'cron_definition'))
        self.assertEquals(self.sio.output_repeated, (False))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.scheduler.job.get-by-name')
        
###############################################################################

class CreateTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Create
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return ({'cluster_id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(), 'job_type':rand_string(),
                 'service':rand_string(), 'start_date':rand_datetime(), 'id':rand_int(), 'extra':rand_string(),
                 'weeks':rand_int(), 'days':rand_int(), 'hours':rand_int(), 'minutes':rand_int(),
                 'seconds':rand_int(), 'repeats':rand_int(), 'cron_definition':rand_string()}
                )
        
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':rand_string(), 'cron_definition':rand_string()})        
    
    def test_sio(self):
        
        self.assertEquals(self.sio.request_elem, 'zato_scheduler_job_create_request')
        self.assertEquals(self.sio.response_elem, 'zato_scheduler_job_create_response')
        self.assertEquals(self.sio.input_required, ('cluster_id', 'name', 'is_active', 'job_type', 'service', 'start_date'))
        self.assertEquals(self.sio.input_optional, ('id', 'extra', 'weeks', 'days', 'hours', 'minutes', 'seconds', 'repeats', 'cron_definition'))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.output_optional, ('cron_definition',))
        self.assertEquals(self.sio.default_value, (''))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.scheduler.job.create')
        
###############################################################################

class EditTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Edit
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return ({'cluster_id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(), 'job_type':rand_string(),
                 'service':rand_string(), 'start_date':rand_datetime(), 'id':rand_int(), 'extra':rand_string(),
                 'weeks':rand_int(), 'days':rand_int(), 'hours':rand_int(), 'minutes':rand_int(),
                 'seconds':rand_int(), 'repeats':rand_int(), 'cron_definition':rand_string()}
                )
        
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'name':rand_string(), 'cron_definition':rand_string()})
    
    def test_sio(self):
        
        self.assertEquals(self.sio.request_elem, 'zato_scheduler_job_edit_request')
        self.assertEquals(self.sio.response_elem, 'zato_scheduler_job_edit_response')
        self.assertEquals(self.sio.input_required, ('cluster_id', 'name', 'is_active', 'job_type', 'service', 'start_date'))
        self.assertEquals(self.sio.input_optional, ('id', 'extra', 'weeks', 'days', 'hours', 'minutes', 'seconds', 'repeats', 'cron_definition'))
        self.assertEquals(self.sio.output_required, ('id', 'name'))
        self.assertEquals(self.sio.output_optional, ('cron_definition',))
        self.assertEquals(self.sio.default_value, (''))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.scheduler.job.edit')

##############################################################################

class DeleteTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Delete
        self.sio = self.service_class.SimpleIO
  
    def get_request_data(self):
        return {'id': rand_int()}
    
    def get_response_data(self):
        return Bunch()
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_scheduler_job_delete_request')
        self.assertEquals(self.sio.response_elem, 'zato_scheduler_job_delete_response')
        self.assertEquals(self.sio.input_required, ('id',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.scheduler.job.delete')
        
##############################################################################

class ExecuteTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Execute
        self.sio = self.service_class.SimpleIO
  
    def get_request_data(self):
        return {'id': rand_int()}
    
    def get_response_data(self):
        return Bunch()
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_scheduler_job_execute_request')
        self.assertEquals(self.sio.response_elem, 'zato_scheduler_job_execute_response')
        self.assertEquals(self.sio.input_required, ('id',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.scheduler.job.execute')

########NEW FILE########
__FILENAME__ = test_server
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Bunch
from bunch import Bunch

# Zato
from zato.common import zato_namespace
from zato.common.test import rand_int, rand_string, ServiceTestCase
from zato.server.service.internal.server import Edit, Delete, GetByID

################################################################################

class EditestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Edit
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return ({'id':rand_int(), 'name':rand_string()}
                )
        
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'cluste_id':rand_int(), 'name':rand_string(), 'host':rand_string(),
                      'bind_host':rand_string(), 'bind_port':rand_string(), 'last_join_status':rand_string(),
                      'last_join_mod_status':rand_string(), 'up_status':rand_string(), 'up_mod_date':rand_string()})        
    
    def test_sio(self):
        
        self.assertEquals(self.sio.request_elem, 'zato_server_edit_request')
        self.assertEquals(self.sio.response_elem, 'zato_server_edit_response')
        self.assertEquals(self.sio.input_required, ('id', 'name'))
        self.assertEquals(self.sio.output_required, ('id', 'cluster_id', 'name', 'host'))
        self.assertEquals(self.sio.output_optional, ('bind_host', 'bind_port', 'last_join_status',
                                                     'last_join_mod_date', 'last_join_mod_by', 'up_status', 'up_mod_date'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.server.edit')
        
###############################################################################

class GetByIDTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = GetByID
        self.sio = self.service_class.SimpleIO
    
    def get_request_data(self):
        return ({'id':rand_int()}
                )
        
    def get_response_data(self):
        return Bunch({'id':rand_int(), 'cluste_id':rand_int(), 'name':rand_string(), 'host':rand_string(),
                      'bind_host':rand_string(), 'bind_port':rand_string(), 'last_join_status':rand_string(),
                      'last_join_mod_status':rand_string(), 'up_status':rand_string(), 'up_mod_date':rand_string()})          
    
    def test_sio(self):
        
        self.assertEquals(self.sio.request_elem, 'zato_server_get_by_id_request')
        self.assertEquals(self.sio.response_elem, 'zato_server_get_by_id_response')
        self.assertEquals(self.sio.input_required, ('id',))
        self.assertEquals(self.sio.output_required, ('id', 'cluster_id', 'name', 'host'))
        self.assertEquals(self.sio.output_optional, ('bind_host', 'bind_port', 'last_join_status',
                                                     'last_join_mod_date', 'last_join_mod_by', 'up_status', 'up_mod_date'))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.server.get-by-id')

##############################################################################

class DeleteTestCase(ServiceTestCase):
    
    def setUp(self):
        self.service_class = Delete
        self.sio = self.service_class.SimpleIO
  
    def get_request_data(self):
        return {'id': rand_int()}
    
    def get_response_data(self):
        return Bunch()
    
    def test_sio(self):
        self.assertEquals(self.sio.request_elem, 'zato_server_delete_request')
        self.assertEquals(self.sio.response_elem, 'zato_server_delete_response')
        self.assertEquals(self.sio.input_required, ('id',))
        self.assertEquals(self.sio.namespace, zato_namespace)
        self.assertRaises(AttributeError, getattr, self.sio, 'input_optional')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_required')
        self.assertRaises(AttributeError, getattr, self.sio, 'output_repeated')
        
    def test_impl(self):
        self.assertEquals(self.service_class.get_name(), 'zato.server.delete')

########NEW FILE########
__FILENAME__ = test_service
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# anyjson
from anyjson import loads

# nose
from nose.tools import eq_

# Bunch
from bunch import Bunch

# Zato
from zato.common.odb.model import Service
from zato.common.test import Expected, rand_bool, rand_int, rand_string, ServiceTestCase
from zato.server.service.internal.service import GetList, GetByName

def get_data():
    return Bunch({'id':rand_int(), 'name':rand_string(), 'is_active':rand_bool(), 
        'impl_name':rand_string(), 'is_internal':rand_bool()})

class GetListTestCase(ServiceTestCase):
    def test_response(self):
        request = {'cluster_id': rand_int()}
        
        expected_keys = get_data().keys()
        expected_data = tuple(get_data() for x in range(rand_int(10)))
        expected = Expected()
        
        for datum in expected_data:
            item = Service()
            for key in expected_keys:
                value = getattr(datum, key)
                setattr(item, key, value)
            expected.add(item)
            
        instance = self.invoke(GetList, request, expected)
        response = loads(instance.response.payload.getvalue())[GetList.SimpleIO.response_elem]
        
        for idx, item in enumerate(response):
            expected = expected_data[idx]
            given = Bunch(item)
            
            for key in expected_keys:
                given_value = getattr(given, key)
                expected_value = getattr(expected, key)
                eq_(given_value, expected_value)

class GetByNameTestCase(ServiceTestCase):
    def test_response(self):
        request = {'cluster_id':rand_int(), 'name':rand_string()}
        
        expected_id = rand_int()
        expected_name = rand_string()
        expected_is_active = rand_bool()
        expected_impl_name = rand_string()
        expected_is_internal = rand_bool()
        
        service = Service()
        service.id = expected_id
        service.name = expected_name
        service.is_active = expected_is_active
        service.impl_name = expected_impl_name
        service.is_internal = expected_is_internal
        
        expected = Expected()
        expected.add(service)
        
        instance = self.invoke(GetByName, request, expected)
        response = Bunch(loads(instance.response.payload.getvalue())['zato_service_get_by_name_response'])
        
        eq_(response.id, expected_id)
        eq_(response.name, expected_name)
        eq_(response.is_active, expected_is_active)
        eq_(response.impl_name, expected_impl_name)
        eq_(response.is_internal, expected_is_internal)
        eq_(response.usage, 0)

########NEW FILE########
__FILENAME__ = test_sio
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from unittest import TestCase

# nose
from nose.tools import eq_

# Zato
from zato.common.test import rand_bool, rand_string
from zato.server.service import Bool, Dict, Nested
from zato.server.service.reqresp.sio import ValidationException

class SIOTestCase(TestCase):
    def test_dict_no_keys_specified(self):
        d = Dict('d')
        value = {rand_string(): rand_string(), rand_string(): rand_string()}

        ret_value = d.from_json(value)
        eq_(value, ret_value)

    def test_dict_keys_all_exist(self):
        d = Dict('d', 'k1', 'k2')
        value = {'k1':'v1', 'k2':'v2', 'k3':'v3'} # k3 is superfluous and should not be returned

        ret_value = d.from_json(value)
        eq_(sorted(ret_value.items()), [('k1', 'v1'), ('k2', 'v2')])

    def test_dict_keys_missing_no_default_value(self):
        d = Dict('d', 'k1', 'k2', 'k3', 'k4')
        value = {'k1':'v1', 'k2':'v2', 'k3':'v3'} # k4 doesn't exist so an exception should be raised

        try:
            d.from_json(value)
        except ValidationException, e:
            eq_(e.name, 'd')
            eq_(sorted(e.value.items()), [('k1', 'v1'), ('k2', 'v2'), ('k3', 'v3')])
            eq_(e.missing_elem, 'k4')
        else:
            self.fail('Expected a ValidationException here')

    def test_dict_keys_missing_has_default_value(self):
        default = rand_string()
        d = Dict('d', 'k1', 'k2', 'k3', 'k4', default=default)
        value = {'k1':'v1', 'k2':'v2', 'k3':'v3'} # k4 doesn't exist but no exception is raised because a default value is set

        ret_value = d.from_json(value)
        eq_(sorted(ret_value.items()), [('k1', 'v1'), ('k2', 'v2'), ('k3', 'v3'), ('k4', default)])

    def test_nested_from_json(self):

        n = Nested('elem', 'sub1', Bool('my_bool1'), 'sub2', 'sub3', Dict('my_dict1', 'key1', 'key2'))

        expected_sub1_1 = rand_string()
        expected_sub2_1 = rand_string()
        expected_sub3_1 = rand_string()
        expected_my_bool1_1 = rand_bool()
        expected_key1_1 = rand_string()
        expected_key2_1 = rand_string()

        value1 = {'elem': {
            'sub1': expected_sub1_1,
            'sub2': expected_sub2_1,
            'my_bool1': expected_my_bool1_1,
            'sub3': expected_sub3_1,
            'my_dict1' : {
                'key1': expected_key1_1,
                'key2': expected_key2_1,
            }
        }}

        ret_value = n.from_json(value1)

        eq_(ret_value,
            {'elem':
             {'my_bool1': expected_my_bool1_1, 'sub2': expected_sub2_1, 'sub3': expected_sub3_1,
              'my_dict1': {'key2': expected_key2_1, 'key1': expected_key1_1},
              'sub1': expected_sub1_1}}
        )

    def test_nested_to_json(self):

        n = Nested('elem', 'sub1', Bool('my_bool1'), 'sub2', 'sub3', Dict('my_dict1', 'key1', 'key2'))

        expected_sub1_2 = rand_string()
        expected_sub2_2 = rand_string()
        expected_sub3_2 = rand_string()
        expected_my_bool1_2 = rand_bool()
        expected_key1_2 = rand_string()
        expected_key2_2 = rand_string()

        value2 = {'elem': {
            'sub1': expected_sub1_2,
            'sub2': expected_sub2_2,
            'my_bool1': expected_my_bool1_2,
            'sub3': expected_sub3_2,
            'my_dict1' : {
                'key1': expected_key1_2,
                'key2': expected_key2_2,
            }
        }}

        ret_value = n.to_json(value2)

        eq_(ret_value,
            {'elem':
             {'my_bool1': expected_my_bool1_2, 'sub2': expected_sub2_2, 'sub3': expected_sub3_2,
              'my_dict1': {'key2': expected_key2_2, 'key1': expected_key1_2},
              'sub1': expected_sub1_2}}
        )

########NEW FILE########
__FILENAME__ = test_service
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import ast
from json import loads
from logging import getLogger, INFO
from time import time
from unittest import TestCase
from uuid import uuid4

# Bunch
from bunch import Bunch

# faker
from faker import Faker

# lxml
from lxml import etree, objectify

# nose
from nose.tools import eq_

# retools
from retools.lock import LockTimeout

# Zato
from zato.common import CHANNEL, DATA_FORMAT, KVDB, PARAMS_PRIORITY, \
     SCHEDULER_JOB_TYPE, URL_TYPE
from zato.common.test import FakeKVDB, rand_string, rand_int, ServiceTestCase
from zato.server.service import List, Service
from zato.server.service.reqresp import HTTPRequestData, Request

logger = getLogger(__name__)
faker = Faker()

# ################################################################################################################################

class HooksTestCase(ServiceTestCase):
    def test_hooks(self):
        
        class MyJob(Service):
            def handle(self):
                pass
            
            def before_handle(self):
                self.environ['before_handle_called'] = True
            
            def before_job(self):
                self.environ['before_job_called'] = True
            
            def before_one_time_job(self):
                self.environ['before_one_time_job_called'] = True
            
            def after_handle(self):
                self.environ['after_handle_called'] = True
            
            def after_job(self):
                self.environ['after_job_called'] = True
            
            def after_one_time_job(self):
                self.environ['after_one_time_job_called'] = True
            
        instance = self.invoke(MyJob, {}, {}, channel=CHANNEL.SCHEDULER, job_type=SCHEDULER_JOB_TYPE.ONE_TIME)
        
        for name in('before_handle', 'before_job', 'before_one_time_job', 'after_handle', 'after_job', 'after_one_time_job'):
            eq_(instance.environ['{}_called'.format(name)], True)

# ################################################################################################################################

class TestLogInputOutput(ServiceTestCase):
    def test_log_input_output(self):
        
        class MyLogger(object):
            def __init__(self):
                self.level = None
                self.msg = None
                
            def log(self, level, msg):
                self.level = level
                self.msg = msg
                
        class DummyService(Service):
            def handle(self):
                self.logger = MyLogger()
        
        instance = self.invoke(DummyService, {}, {})
        
        level = uuid4().hex
        user_msg = uuid4().hex
        
        instance._log_input_output(user_msg, level, {}, True)
        eq_(instance.logger.level, level)
        self.assertTrue(instance.logger.msg.startswith('{} '.format(user_msg)))
        
        instance.log_input()
        eq_(instance.logger.level, INFO)
        msg = ast.literal_eval(instance.logger.msg)
        eq_(sorted(msg), ['channel', 'cid', 'data_format', 'environ', 
                           'impl_name', 'invocation_time', 'job_type', 'name', 
                           'request.payload', 'slow_threshold', u'usage', 
                           'wsgi_environ'])

        instance.log_output()
        eq_(instance.logger.level, INFO)
        msg = ast.literal_eval(instance.logger.msg)
        eq_(sorted(msg), ['channel', 'cid', 'data_format', 'environ', 
                           'handle_return_time', 'impl_name', 'invocation_time', 
                           'job_type', 'name', 'processing_time', 'processing_time_raw', 
                           'response.payload', 'slow_threshold', 'usage', 
                           'wsgi_environ', 'zato.http.response.headers'])

# ################################################################################################################################

class TestLock(ServiceTestCase):
    def test_lock_ok(self):
        """ Succesfully grab a service lock.
        """ 
        my_kvdb = FakeKVDB()
        my_kvdb.conn.setnx_return_value = True
        
        lock_name = rand_string()
        expires = 500 + rand_int() # It's 500 which means DummyService.invoke has that many seconds to complete
        timeout = rand_int()
        
        class DummyService(Service):
            kvdb = my_kvdb
            def handle(self):
                with self.lock(lock_name, expires, timeout):
                    pass
                
        instance = DummyService()
        instance.handle()
        
        eq_(my_kvdb.conn.delete_args, KVDB.LOCK_SERVICE_PREFIX + lock_name)
        eq_(my_kvdb.conn.expire_args, (KVDB.LOCK_SERVICE_PREFIX + lock_name, expires))
        
        # First arg is the lock_name that can ne checked directly but the other
        # one is the expiration time that we can check only approximately,
        # anything within 3 seconds range is OK. The value of 3 is the maximum
        # time allowed for execution of DummyService's invoke method which is
        # way more than needed but let's use 3 to be on the safe side when the
        # test is run on a very slow system.
        eq_(my_kvdb.conn.setnx_args[0], KVDB.LOCK_SERVICE_PREFIX + lock_name)
        expires_approx = time() + expires
        self.assertAlmostEquals(my_kvdb.conn.setnx_args[1], expires_approx, delta=3)
        
        
    def test_lock_timeout(self):
        """ A timeout is caught while trying to obtain a service lock.
        """
        my_kvdb = FakeKVDB()
        my_kvdb.conn.setnx_return_value = False
        
        lock_name = rand_string()
        expires = rand_int()
        timeout = -1
        
        class DummyService(Service):
            kvdb = my_kvdb
            def handle(self):
                with self.lock(lock_name, expires, timeout):
                    pass
                
        instance = DummyService()
        
        try:
            instance.handle()
        except LockTimeout, e:
            eq_(e.message, 'Timeout while waiting for lock')
        else:
            self.fail('LockTimeout not raised')
            
# ################################################################################################################################

class TestHTTPRequestData(TestCase):
    def test_empty(self):
        data = HTTPRequestData()
        self.assertEquals(data.GET, None)
        self.assertEquals(data.POST, None)
        self.assertEquals(data.method, None)
        
    def test_non_empty(self):
        get1, get2 = uuid4().hex, uuid4().hex
        post1, post2 = uuid4().hex, uuid4().hex
        request_method = uuid4().hex
        
        wsgi_environ = {
            'REQUEST_METHOD': request_method,
            'zato.http.GET': {'get1':get1, 'get2':get2},
            'zato.http.POST': {'post1':post1, 'post2':post2},
        }
        
        data = HTTPRequestData()
        data.init(wsgi_environ)
        
        self.assertEquals(data.method, request_method)
        self.assertEquals(sorted(data.GET.items()), [('get1', get1), ('get2', get2)])
        self.assertEquals(sorted(data.POST.items()), [('post1', post1), ('post2', post2)])

# ################################################################################################################################

class TestRequest(TestCase):
    def test_init_no_sio(self):
        is_sio = False
        cid = uuid4().hex
        data_format = uuid4().hex
        io = uuid4().hex
        
        wsgi_environ = {
            'zato.http.GET': {uuid4().hex:uuid4().hex}, 
            'zato.http.POST': {uuid4().hex:uuid4().hex}, 
            'REQUEST_METHOD': uuid4().hex, 
        }
        
        for transport in(None, URL_TYPE.PLAIN_HTTP, URL_TYPE.SOAP):
            request = Request(None)
            request.http.init(wsgi_environ)
            request.init(is_sio, cid, io, data_format, transport, wsgi_environ)

            eq_(request.http.method, wsgi_environ['REQUEST_METHOD'])
            eq_(sorted(request.http.GET.items()), sorted(wsgi_environ['zato.http.GET'].items()))
            eq_(sorted(request.http.POST.items()), sorted(wsgi_environ['zato.http.POST'].items()))

    def test_init_sio(self):

        is_sio = True
        cid = uuid4().hex
        data_format = uuid4().hex
        transport = uuid4().hex
        
        io_default = {'dummy':'dummy'}
        io_custom = Bunch({
            'request_elem': uuid4().hex,
            'input_required': ['a', 'b', 'c'],
            'input_optional': ['d', 'e', 'f'],
            'default_value': uuid4().hex,
            'use_text': uuid4().hex,
        })
        
        wsgi_environ = {
            'zato.http.GET': {uuid4().hex:uuid4().hex}, 
            'zato.http.POST': {uuid4().hex:uuid4().hex}, 
            'REQUEST_METHOD': uuid4().hex, 
        }
        
        def _get_params(request_params, *ignored):
            # 'g' is never overridden
            if request_params is io_custom['input_required']:
                return {'a':'a-req', 'b':'b-req', 'c':'c-req', 'g':'g-msg'}
            else:
                return {'d':'d-opt', 'e':'e-opt', 'f':'f-opt', 'g':'g-msg'}
        
        request = Request(logger)
        request.payload = None
        request.raw_request = io_default
        request.get_params = _get_params
        
        request.channel_params['a'] = 'channel_param_a'
        request.channel_params['b'] = 'channel_param_b'
        request.channel_params['c'] = 'channel_param_c'
        request.channel_params['d'] = 'channel_param_d'
        request.channel_params['e'] = 'channel_param_e'
        request.channel_params['f'] = 'channel_param_f'
        request.channel_params['h'] = 'channel_param_h' # Never overridden
        
        for io in(io_default, io_custom):
            for params_priority in PARAMS_PRIORITY:
                request.params_priority = params_priority
                request.http.init(wsgi_environ)
                request.payload = io
                request.init(is_sio, cid, io, data_format, transport, wsgi_environ)

                if io is io_default:
                    eq_(sorted(request.input.items()), 
                        sorted({'a': 'channel_param_a', 'b': 'channel_param_b', 'c': 'channel_param_c',
                         'd': 'channel_param_d', 'e': 'channel_param_e', 'f': 'channel_param_f',
                         'h':'channel_param_h'}.items()))
                else:
                    if params_priority == PARAMS_PRIORITY.CHANNEL_PARAMS_OVER_MSG:
                        eq_(sorted(request.input.items()), 
                            sorted({'a': 'channel_param_a', 'b': 'channel_param_b', 'c': 'channel_param_c',
                             'd': 'channel_param_d', 'e': 'channel_param_e', 'f': 'channel_param_f',
                             'g': 'g-msg',
                             'h':'channel_param_h'}.items()))
                    else:
                        eq_(sorted(request.input.items()), 
                            sorted({'a': 'a-req', 'b': 'b-req', 'c': 'c-req',
                             'd': 'd-opt', 'e': 'e-opt', 'f': 'f-opt',
                             'g': 'g-msg',
                             'h':'channel_param_h'}.items()))
                        
# ################################################################################################################################

class TestSIOListDataType(ServiceTestCase):
    # https://github.com/zatosource/zato/issues/114
    
    def test_sio_list_data_type_input_json(self):
        cid = rand_string()
        data_format = DATA_FORMAT.JSON
        transport = rand_string()
        
        sio_config = {'int_parameters': [rand_string()]} # Not really used but needed
        
        service_sio = Bunch()
        service_sio.input_required = ('first_name', 'last_name', List('emails'))
        
        expected_first_name = faker.first_name()
        expected_last_name = faker.last_name()
        expected_emails = sorted([faker.email(), faker.email()])
        
        r = Request(getLogger(__name__), sio_config)
        r.payload = {
            'first_name': expected_first_name,
            'last_name': expected_last_name,
            'emails': expected_emails,
            }
        
        r.init(True, cid, service_sio, data_format, transport, {})
        
        eq_(r.input.first_name, expected_first_name)
        eq_(r.input.last_name, expected_last_name)
        eq_(r.input.emails, expected_emails)

    def test_sio_list_data_type_input_xml(self):
        cid = rand_string()
        data_format = DATA_FORMAT.XML
        transport = rand_string()
        
        sio_config = {'int_parameters': [rand_string()]} # Not really used but needed
        
        service_sio = Bunch()
        service_sio.input_required = ('first_name', 'last_name', List('emails'))
        
        expected_first_name = faker.first_name()
        expected_last_name = faker.last_name()
        expected_emails = sorted([faker.email(), faker.email()])
        
        r = Request(getLogger(__name__), sio_config)
        r.payload = etree.fromstring("""<request>
          <first_name>{}</first_name>
          <last_name>{}</last_name>
          <emails>
           <item>{}</item>
           <item>{}</item>
          </emails>
        </request>""".format(
            expected_first_name, expected_last_name, expected_emails[0], expected_emails[1]))
        
        r.init(True, cid, service_sio, data_format, transport, {})
        
        eq_(r.input.first_name, expected_first_name)
        eq_(r.input.last_name, expected_last_name)
        eq_(r.input.emails, expected_emails)

    def test_sio_list_data_type_output_json(self):
        expected_first_name = faker.first_name()
        expected_last_name = faker.last_name()
        expected_emails = sorted([faker.email(), faker.email()])

        class MyService(Service):
            class SimpleIO:
                output_required = ('first_name', 'last_name', List('emails'))
                
            def handle(self):
                self.response.payload.first_name = expected_first_name
                self.response.payload.last_name = expected_last_name
                self.response.payload.emails = expected_emails
            
        instance = self.invoke(MyService, {}, None, data_format=DATA_FORMAT.JSON)
        response = loads(instance.response.payload.getvalue(True))['response']
        
        eq_(response['first_name'], expected_first_name)
        eq_(response['last_name'], expected_last_name)
        eq_(response['emails'], expected_emails)
        
    def test_sio_list_data_type_output_xml(self):
        expected_first_name = faker.first_name()
        expected_last_name = faker.last_name()
        expected_emails = sorted([faker.email(), faker.email()])

        class MyService(Service):
            class SimpleIO:
                output_required = ('first_name', 'last_name', List('emails'))
                
            def handle(self):
                self.response.payload.first_name = expected_first_name
                self.response.payload.last_name = expected_last_name
                self.response.payload.emails = expected_emails
                
        instance = self.invoke(MyService, {}, None, data_format=DATA_FORMAT.XML)
        response = instance.response.payload.getvalue(True)
        
        data = objectify.fromstring(response).xpath('/response/item')[0]
        
        eq_(data.first_name.text, expected_first_name)
        eq_(data.last_name.text, expected_last_name)
        eq_(data.emails.xpath('item'), expected_emails)

# ################################################################################################################################

class TestNav(TestCase):
    # # https://github.com/zatosource/zato/issues/209

    def test_dictnav(self):

        key1, key2, key3 = 'a', 'b', 'c'
        value = rand_string()

        d = {
            'flat': 123,
            'nested':{
                key1: {key2: {key3: value}}
            }
        }

        class MyService(Service):
            def handle(self):
                dn = self.dictnav(self.request.input)
                response = {
                    'key1': sorted(dn.get(['nested', 'a']).items()),
                    'value': dn.get(['nested', 'a', 'b', 'c']),
                    'has_key_flat_true': dn.has_key('flat', False),
                    'has_key_flat_false': dn.has_key(rand_string(), True),
                    'has_key_nested_true': dn.has_key('b'),
                    'has_key_nested_false': dn.has_key(rand_string()),
                    'has_path': dn.has_path(['nested', 'a', 'b', 'c']),
                }
                self.response.payload = response

        service = MyService()
        service.request.input = d
        service.handle()

        eq_(service.response.payload['key1'], [('b', {'c': value})])
        eq_(service.response.payload['value'], value)
        eq_(service.response.payload['has_key_flat_true'], True)
        eq_(service.response.payload['has_key_flat_false'], False)
        eq_(service.response.payload['has_key_nested_true'], True)
        eq_(service.response.payload['has_key_nested_false'], False)
        eq_(service.response.payload['has_path'], True)

    def test_listnav(self):
        self.test_dictnav() # Right now dictnav and listnav do the same thing
########NEW FILE########
__FILENAME__ = test_message
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from copy import deepcopy
from json import dumps
from logging import getLogger
from unittest import TestCase
from uuid import uuid4

# Bunch
from bunch import Bunch, bunchify, unbunchify

# lxml
from lxml import etree

# xmldict
from xmltodict import parse, unparse

# Zato
from zato.common.test import rand_string
from zato.server.message import JSONPointerStore, Mapper, XPathStore

logger = getLogger(__name__)

def config_value(value):
    return Bunch({'value':value})

# ################################################################################################################################

class TestJSONPointerStore(TestCase):

    def test_add(self):
        jps = JSONPointerStore()

        name1, expr1 = '1', config_value('/{}/{}'.format(*rand_string(2)))
        name2, expr2 = '2', config_value('/aaa/{}/{}'.format(*rand_string(2)))
        name3, expr3 = '3', config_value('/aaa/{}/{}'.format(*rand_string(2)))
        name4, expr4 = '2', config_value('/aaa/{}/{}'.format(*rand_string(2)))

        jps.add(name1, expr1)
        self.assertIn(name1, jps.data)
        self.assertEquals(expr1.value, jps.data[name1].path)

        jps.add(name2, expr2)
        self.assertIn(name2, jps.data)
        self.assertEquals(expr2.value, jps.data[name2].path)

        jps.add(name3, expr3)
        self.assertIn(name3, jps.data)
        self.assertEquals(expr3.value, jps.data[name3].path)

        # name4's value is '2' so it overrides 2

        jps.add(name4, expr4)
        self.assertIn(name4, jps.data)

        self.assertEquals(expr4.value, jps.data[name2].path)
        self.assertEquals(expr4.value, jps.data[name4].path)

    def test_get(self):
        jps = JSONPointerStore()

        c_value, d_value = rand_string(2)

        doc = {
            'a': {
                'b': [
                    {'c': c_value},
                    {'d': d_value},
                ]
            },
            'e': None,
            'f': 0
        }

        name1, expr1 = '1', config_value('/a')
        name2, expr2 = '2', config_value('/a/b')
        name3, expr3 = '3', config_value('/a/b/0')
        name4, expr4 = '4', config_value('/a/b/1')
        name5, expr5 = '5', config_value('/a/b/0/c')

        # This will return default because the path points to None
        name6, expr6 = '6', config_value('/e')

        # This will return default because there is no such path
        name7, expr7 = '7', config_value('/e/e2/e3')

        # This will not return None because 0 is not None even though it's False in boolean sense
        name8, expr8 = '8', config_value('/f')

        jps.add(name1, expr1)
        value = jps.get(name1, doc)
        self.assertListEqual(value.keys(), ['b'])

        jps.add(name2, expr2)
        value = jps.get(name2, doc)
        self.assertDictEqual(value[0], {'c':c_value})
        self.assertDictEqual(value[1], {'d':d_value})

        jps.add(name3, expr3)
        value = jps.get(name3, doc)
        self.assertDictEqual(value, {'c':c_value})

        jps.add(name4, expr4)
        value = jps.get(name4, doc)
        self.assertDictEqual(value, {'d':d_value})

        jps.add(name5, expr5)
        value = jps.get(name5, doc)
        self.assertEquals(value, c_value)

        default1 = rand_string()
        default2 = rand_string()

        jps.add(name6, expr6)
        value = jps.get(name6, doc, default1)
        self.assertEquals(value, default1)

        jps.add(name7, expr7)
        value = jps.get(name7, doc, default2)
        self.assertEquals(value, default2)

        jps.add(name8, expr8)
        value = jps.get(name8, doc)
        self.assertEquals(value, 0)

    def test_set_defaults(self):
        jps = JSONPointerStore()

        value1 = {'b':{}}
        value2 = {'c':{}}

        doc = {}

        name1, expr1 = '1', config_value('/a')
        name2, expr2 = '2', config_value('/a/b')

        jps.add(name1, expr1)
        jps.add(name2, expr2)

        jps.set(name1, doc, value1)
        value = jps.get(name1, doc)
        self.assertEquals(value, value1)

        jps.set(name2, doc, value2)
        value = jps.get(name2, doc)
        self.assertDictEqual(value, value2)

    def test_set_in_place(self):
        jps = JSONPointerStore()

        doc = {'a':'b'}
        value_random = rand_string()

        name1, expr1 = '1', config_value('/a')

        jps.add(name1, expr1)

        # in_place is False so a new doc is created and the previous one should be retained
        new_doc = jps.set(name1, doc, value_random, True, in_place=False)

        value = jps.get(name1, new_doc)
        self.assertEquals(value, value_random)

        value = jps.get(name1, doc)
        self.assertEquals(value, 'b')

    def test_set_skip_missing(self):
        jps = JSONPointerStore()
        doc = {}

        name1, expr1 = '1', config_value('/a')
        name2, expr2 = '2', config_value('/b')

        value1, value2 = rand_string(2)
        default1, default2 = rand_string(2)

        jps.add(name1, expr1)
        jps.add(name2, expr2)

        # value is equal to default1 because it is never set by jps.set
        jps.set(name1, doc, value1, True)
        value = jps.get(name1, doc, default1)
        self.assertEquals(value, default1)
        self.assertDictEqual(doc, {})

        jps.set(name2, doc, value2)
        value = jps.get(name2, doc, default2)
        self.assertEquals(value, value2)
        self.assertDictEqual(doc, {'b':value2})

    def test_set_create_missing(self):
        jps = JSONPointerStore()
        doc = {}

        name1, expr1, value1 = '1', config_value('/a/b/c/d'), rand_string()
        name2, expr2, value2 = '2', config_value('/a/b/c/dd'), rand_string()
        name3, expr3, value3 = '3', config_value('/a/b/cc/d'), rand_string()

        jps.add(name1, expr1)
        jps.add(name2, expr2)
        jps.add(name3, expr3)

        # Creates all the missing path parts in the empty document
        jps.set(name1, doc, value1)
        jps.set(name2, doc, value2)
        jps.set(name3, doc, value3)

        doc = bunchify(doc)

        self.assertEquals(doc.a.b.c.d, value1)
        self.assertEquals(doc.a.b.c.dd, value2)
        self.assertEquals(doc.a.b.cc.d, value3)

# ################################################################################################################################

class TestXPathStore(TestCase):
    def test_store_replace(self):

        expr1 = '/root/elem1'
        expr2 = '//jt:elem2'
        expr3 = '//list1/item1'
        expr4 = '//item2/key'

        ns_map={'jt':'just-testing'}

        for idx, expr in enumerate([expr1, expr2, expr3, expr4]):
            msg = """
                <root>
                  <elem1>elem1</elem1>
                  <elem2 xmlns="just-testing">elem2</elem2>
                  <list1>
                      <item1>item-a</item1>
                      <item1>item-b</item1>
                      <item2>
                          <key>key</key>
                      </item2>
                  </list1>
                </root>
            """.encode('utf-8')

            doc = etree.fromstring(msg)

            new_value = uuid4().hex

            config = Bunch()
            config.name = str(idx)
            config.value = expr

            xps = XPathStore()
            xps.add(config.name, config, ns_map=ns_map)

            replaced = xps.set(config.name, doc, new_value, ns_map)
            result = xps.get(config.name, doc)

            self.assertTrue(len(result) > 0)

            if isinstance(result, list):
                for item in result:
                    logger.warn('%r %r %r %r %s', idx, expr, item, result, etree.tostring(doc, pretty_print=1))
                    self.assertEquals(item, new_value)
            else:
                self.assertEquals(result, new_value)

    def test_get(self):
        msg = """
            <root>
                <a>123</a>
                <b>456</b>
            </root>
        """.encode('utf-8')

        config1 = Bunch()
        config1.name = '1'
        config1.value = '//a'

        config2 = Bunch()
        config2.name = '2'
        config2.value = '//zzz'
        default = rand_string()

        xps = XPathStore()
        xps.add(config1.name, config1)
        xps.add(config2.name, config2)

        doc = etree.fromstring(msg)

        value = xps.get('1', doc)
        self.assertEquals(value, '123')

        value = xps.get('2', doc, default)
        self.assertEquals(value, default)

    def test_set(self):
        msg = """
            <root>
                <a>123</a>
                <b>456</b>
            </root>
        """.encode('utf-8')

        config1 = Bunch()
        config1.name = '1'
        config1.value = '//a'
        new_value = rand_string()

        config2 = Bunch()
        config2.name = '2'
        config2.value = '/zzz'
        default = rand_string()

        xps = XPathStore()
        xps.add(config1.name, config1)
        xps.add(config2.name, config2)

        doc = etree.fromstring(msg)

        xps.set('1', doc, new_value)
        value = xps.get('1', doc)
        self.assertEquals(value, new_value)

        xps.set('2', doc, new_value)
        value = xps.get('2', doc)
        self.assertEquals(value, None)

# ################################################################################################################################

class TestMapper(TestCase):
    def test_map(self):
        source = {
            'a': {
                'b': [1, 2, '3', 4],
                'c': {'d':'123'}
        }}

        m = Mapper(source)

        # 1:1 mappings
        m.map('/aa', '/a/b')
        m.map('/bb', '/a/c/d')

        # Force conversion to int
        m.map('/cc/dd', 'int:/a/c/d')

        # Manually signal /cc/ee/ff should be a list here ..
        m.set('/cc/ee/ff', [])
        m.map('/cc/ee/ff/19', 'int:/a/c/d')

        target = bunchify(m.target)

        self.assertListEqual(target.aa, [1, 2, '3', 4])
        self.assertEquals(target.bb, '123')
        self.assertEquals(target.cc.dd, 123)
        self.assertEquals(target.cc.ee.ff, [None] * 19 + [123])

########NEW FILE########
__FILENAME__ = debug_settings
#DATABASE_ENGINE = 'postgresql_psycopg2'
#DATABASE_NAME = 'zato1'
#DATABASE_USER = 'zato1'
#DATABASE_PASSWORD = 'zato1'
#DATABASE_HOST = 'localhost'
#DATABASE_PORT = '5432'
#SITE_ID=1
#SECRET_KEY='foobar'

#db_type='postgresql'
#config_dir='.'

########NEW FILE########
__FILENAME__ = main
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

try:
    import pymysql
    pymysql.install_as_MySQLdb()
except ImportError:
    pass

# stdlib
import json, os
from logging import getLogger
from wsgiref.simple_server import make_server

# Django
from django.core.management import call_command, execute_manager

# Zato
from zato.admin.zato_settings import update_globals
from zato.common.repo import RepoManager
from zato.common.util import store_pidfile

def main():
    store_pidfile(os.path.abspath('.'))
    repo_dir = os.path.join('.', 'config', 'repo')

    # Update Django settings
    config = json.loads(open(os.path.join(repo_dir, 'web-admin.conf')).read())
    config['config_dir'] = os.path.abspath('.')
    update_globals(config)

    # Store the PID so that the server can be later stopped by its PID.
    open('./.web-admin.pid', 'w').write(str(os.getpid()))

    os.environ['DJANGO_SETTINGS_MODULE'] = 'zato.admin.settings'
    call_command('loaddata', os.path.join(repo_dir, 'initial-data.json'))

    RepoManager(repo_dir).ensure_repo_consistency()

    # Cannot be imported before update_globals does its job of updating settings' configuration
    from zato.admin import settings

    execute_manager(settings, ['zato-web-admin', 'runserver', '--noreload', '{host}:{port}'.format(**config)])

if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = manage
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

try:
    import pymysql
    pymysql.install_as_MySQLdb()
except ImportError:
    pass

from django.core.management import execute_manager
try:
    import settings # Assumed to be in the same directory.
except ImportError:
    import sys
    sys.stderr.write("Error: Can't find the file 'settings.py' in the directory containing %r. It appears you've customized things.\nYou'll have to run django-admin.py, passing it your settings module.\n(If the file settings.py does indeed exist, it's causing an ImportError somehow.)\n" % __file__) # noqa
    sys.exit(1)

if __name__ == "__main__":
    execute_manager(settings)

########NEW FILE########
__FILENAME__ = middleware
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django.conf import settings
from django.contrib.auth.views import login
from django.core.urlresolvers import resolve
from django.http import HttpResponseRedirect

# Django-OpenID
from django_openid_auth.views import login_complete

# Bunch
from bunch import Bunch

# Zato
from zato.admin.settings import ADMIN_INVOKE_NAME, ADMIN_INVOKE_PASSWORD, \
    ADMIN_INVOKE_PATH,SASession
from zato.admin.web.forms import ChooseClusterForm
from zato.admin.web.models import ClusterColorMarker, UserProfile
from zato.client import AnyServiceInvoker
from zato.common.odb.model import Cluster


# Code below is taken from http://djangosnippets.org/snippets/136/
# Slightly modified for Zato's purposes.

###
# Copyright (c) 2006-2007, Jared Kuolt
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
#     * Redistributions of source code must retain the above copyright notice,
#       this list of conditions and the following disclaimer.
#     * Redistributions in binary form must reproduce the above copyright
#       notice, this list of conditions and the following disclaimer in the
#       documentation and/or other materials provided with the distribution.
#     * Neither the name of the SuperJared.com nor the names of its
#       contributors may be used to endorse or promote products derived from
#       this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.
###

class ZatoMiddleware(object):

    def process_request(self, req):

        # Makes each Django view have an access to a 'zato.odb' attribute of the
        # request object. The attribute is an SQLAlchemy session to the database
        # defined in app's settings.py
        req.zato = Bunch()
        req.zato.odb = SASession()
        req.zato.args = Bunch() # Arguments read from URL

        try:
            resolved_kwargs = resolve(req.path).kwargs
            req.zato.id = resolved_kwargs.get('id')
            req.zato.cluster_id = req.GET.get('cluster') or req.POST.get('cluster_id') or \
                resolved_kwargs.get('cluster_id') or resolved_kwargs.get('cluster')

            if req.zato.cluster_id:
                req.zato.cluster = req.zato.odb.query(Cluster).filter_by(id=req.zato.cluster_id).one()

                url = 'http://{}:{}'.format(req.zato.cluster.lb_host, req.zato.cluster.lb_port)
                auth = (ADMIN_INVOKE_NAME, ADMIN_INVOKE_PASSWORD)
                req.zato.client = AnyServiceInvoker(url, ADMIN_INVOKE_PATH, auth, to_bunch=True)

            req.zato.clusters = req.zato.odb.query(Cluster).order_by('name').all()
            req.zato.choose_cluster_form = ChooseClusterForm(req.zato.clusters, req.GET)

            if not req.user.is_anonymous():
                try:
                    user_profile = UserProfile.objects.get(user=req.user)
                except UserProfile.DoesNotExist:
                    user_profile = UserProfile(user=req.user)
                    user_profile.save()
                req.zato.user_profile = user_profile
            else:
                req.zato.user_profile = None
        except Exception:
            req.zato.odb.rollback()
            raise

    def process_template_response(self, req, resp):
        try:
            ccm = ClusterColorMarker.objects.get(cluster_id=req.zato.cluster_id, user_profile=req.zato.user_profile)
        except ClusterColorMarker.DoesNotExist:
            pass
        else:
            resp.context_data['cluster_color'] = ccm.color

        resp.render()
        
        return resp

########NEW FILE########
__FILENAME__ = settings
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

# stdlib
import logging, logging.config, os

# SQLAlchemy
from sqlalchemy.orm import sessionmaker, scoped_session
from sqlalchemy import create_engine

# Zato
from zato.common import engine_def, engine_def_sqlite, TRACE1
from zato.common.odb.util import get_engine_url
from zato_settings import * # noqa

if 'DEBUG' not in globals():
    DEBUG = os.environ.get('ZATO_WEB_ADMIN_DEBUG', False)

if DEBUG:
    try:
        from debug_settings import * # noqa
    except ImportError:
        pass

logging.addLevelName('TRACE1', TRACE1)
if 'log_config' in globals():
    logging.config.fileConfig(log_config)
else:
    logging.basicConfig(level=logging.DEBUG)

MESSAGE_STORAGE = 'django.contrib.messages.storage.session.SessionStorage'

INTERNAL_IPS = ('127.0.0.1',)

# If you set this to False, Django will make some optimizations so as not
# to load the internationalization machinery.
USE_I18N = True

# Absolute path to the directory that holds media.
# Example: '/home/media/media.lawrence.com/'
MEDIA_ROOT = os.path.join(os.path.dirname(__file__), 'static')

# URL that handles the media served from MEDIA_ROOT. Make sure to use a
# trailing slash if there is a path component (optional in other cases).
# Examples: 'http://media.lawrence.com', 'http://example.com/media/'
MEDIA_URL = '/static/'

# URL prefix for admin media -- CSS, JavaScript and images. Make sure to use a
# trailing slash.
# Examples: 'http://foo.com/media/', '/media/'.
ADMIN_MEDIA_PREFIX = '/media/'

# List of callables that know how to import templates from various sources.
TEMPLATE_LOADERS = (
    'django.template.loaders.filesystem.load_template_source',
    'django.template.loaders.app_directories.load_template_source',
)

MIDDLEWARE_CLASSES = (
    'django.middleware.common.CommonMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.middleware.csrf.CsrfResponseMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'zato.admin.middleware.ZatoMiddleware',
)

ROOT_URLCONF = 'zato.admin.urls'

TEMPLATE_DIRS = (
    os.path.join(os.path.dirname(__file__), 'templates'),
)

INSTALLED_APPS = (
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.sites',
    'django.contrib.messages',
    'django.contrib.humanize',
    'django_openid_auth',
    'debug_toolbar',
    'django_settings',
    'zato.admin.web',
)

AUTHENTICATION_BACKENDS = (
    'django_openid_auth.auth.OpenIDBackend',
    'django.contrib.auth.backends.ModelBackend',
)

# Its value is injected from web-admin.conf zato.admin.zato_settings.update_globals
if globals().get('OPENID_SSO_SERVER_URL'):
    LOGIN_URL = '/openid/login/'
else:
    LOGIN_URL = '/accounts/login/'

LOGIN_REDIRECT_URL = '/'

# Some values below, e.g. db_type, DATABASE_USER and others are magically injected
# here by the 'zato start /path/to/zato/admin' command. The command in turn
# fetches values from the 'web-admin.conf' file.

if 'DATABASES' in globals():

    # So that Django doesn't complain about an unknown engine type
    if db_type.startswith('mysql'):
        db_type = 'mysql'

    db_data = DATABASES['default']
    db_data['ENGINE'] = 'django.db.backends.' + django_sqlalchemy_engine[db_type]
    
    for name in('ENGINE', 'NAME', 'USER', 'PASSWORD', 'HOST', 'PORT'):
        globals()['DATABASE_{}'.format(name)] = DATABASES['default'][name]

    db_data['db_type'] = db_type

    # Crypto
    ssl_key_file = os.path.abspath(os.path.join(config_dir, SSL_KEY_FILE))
    ssl_cert_file = os.path.abspath(os.path.join(config_dir, SSL_CERT_FILE))
    ssl_ca_certs = os.path.abspath(os.path.join(config_dir, SSL_CA_CERTS))
    
    # SQLAlchemy setup
    SASession = scoped_session(sessionmaker())
    engine = create_engine(get_engine_url(db_data))
    SASession.configure(bind=engine)
    
    TEMPLATE_DEBUG = True
else:
    ADMIN_INVOKE_NAME = 'dummy'
    ADMIN_INVOKE_PASSWORD = 'dummy'
    DATABASES = {}
    DATABASES['default'] = {}
    DATABASES['default']['ENGINE'] = 'django.db.backends.sqlite3'
    
    ssl_key_file = 'dummy'
    ssl_cert_file = 'dummy'
    ssl_ca_certs = 'dummy'
    
    os.environ['DJANGO_SETTINGS_MODULE'] = 'zato.admin.settings'
    
    DATABASE_ENGINE = DATABASES['default']['ENGINE']
    DATABASE_NAME = 'dummy'
    DATABASE_USER = 'dummy'
    DATABASE_PASSWORD = 'dummy'
    DATABASE_HOST = 'dummy'
    DATABASE_PORT = 123456

########NEW FILE########
__FILENAME__ = urls
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django.conf.urls.defaults import * # noqa
from django.contrib.auth.decorators import login_required
from django.contrib.auth.views import login

# Zato
from zato.admin import settings
from zato.admin.web.views import account, cluster, http_soap, kvdb, load_balancer, main, scheduler, service, stats
from zato.admin.web.views.channel import amqp as channel_amqp
from zato.admin.web.views.channel import jms_wmq as channel_jms_wmq
from zato.admin.web.views.channel import zmq as channel_zmq
from zato.admin.web.views.cloud.aws import s3 as cloud_aws_s3
from zato.admin.web.views.cloud.openstack import swift as cloud_openstack_swift
from zato.admin.web.views.definition import amqp as def_amqp
from zato.admin.web.views.definition import jms_wmq as def_jms_wmq
from zato.admin.web.views.kvdb.data_dict import dictionary, impexp, translation
from zato.admin.web.views.message import json_pointer, namespace, xpath
from zato.admin.web.views.notif.cloud.openstack import swift as notif_cloud_openstack_swift
from zato.admin.web.views.outgoing import amqp as out_amqp
from zato.admin.web.views.outgoing import ftp as out_ftp
from zato.admin.web.views.outgoing import jms_wmq as out_jms_wmq
from zato.admin.web.views.outgoing import sql as out_sql
from zato.admin.web.views.outgoing import zmq as out_zmq
from zato.admin.web.views.pattern import delivery as pattern_delivery
from zato.admin.web.views.pattern.delivery import definition as pattern_delivery_def
from zato.admin.web.views.pubsub import topics as pubsub_topics
from zato.admin.web.views.pubsub import consumers as pubsub_consumers
from zato.admin.web.views.pubsub import message as pubsub_message
from zato.admin.web.views.pubsub import producers as pubsub_producers
from zato.admin.web.views.security import apikey, aws, basic_auth, ntlm, oauth, openstack as openstack_security, tech_account, \
     wss, xpath as xpath_sec

urlpatterns = patterns('',

# ################################################################################################################################

    # Main URLs

# ################################################################################################################################

    (r'^accounts/login/$', login, {'template_name': 'zato/login.html'}),

    (r'^$', main.index_redirect),
    url(r'^zato/$',
        login_required(main.index), name='main-page'),
    url(r'^logout/$',
        login_required(main.logout), name='logout'),

# ################################################################################################################################

    # User accounts

    url(r'^account/settings/basic/$',
        login_required(account.settings_basic), name='account-settings-basic'),
    url(r'^account/settings/basic/save/$',
        login_required(account.settings_basic_save), name='account-settings-basic-save'),

# ################################################################################################################################

    # Clusters

    url(r'^zato/cluster/$',
        login_required(cluster.index), name='cluster'),
    url(r'^zato/cluster/edit/$',
        login_required(cluster.edit), name='cluster-edit'),
    url(r'^zato/cluster/delete/(?P<id>.*)/$',
        login_required(cluster.delete), name='cluster-delete'),
    url(r'^zato/cluster/servers-state/(?P<cluster_id>.*)$',
        login_required(cluster.get_servers_state), name='cluster-servers-state'),
    url(r'^zato/cluster/get/by-id/(?P<cluster_id>.*)$',
        login_required(cluster.get_by_id), name='cluster-get-by-id'),
    url(r'^zato/cluster/get/by-name/(?P<cluster_name>.*)/$',
        login_required(cluster.get_by_name), name='cluster-get-by-name'),
    url(r'^zato/cluster/servers/$',
        login_required(cluster.servers), name='cluster-servers'),
    url(r'^zato/cluster/servers/edit/$',
        login_required(cluster.servers_edit), name='cluster-servers-edit'),
    url(r'^zato/cluster/servers/load-balancer/(?P<action>.*)/(?P<server_id>.*)/$',
        login_required(cluster.servers_add_remove_lb), name='cluster-servers-add-remove-lb'),
    url(r'^zato/cluster/servers/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(cluster.ServerDelete()), name=cluster.ServerDelete.url_name),

# ################################################################################################################################

    # Load balancer

    url(r'^zato/load-balancer/get-addresses/cluster/(?P<cluster_id>.*)/$',
        login_required(load_balancer.get_addresses), name='lb-get-addresses'),
    url(r'^zato/load-balancer/manage/cluster/(?P<cluster_id>\d+)/validate-save/$',
        login_required(load_balancer.validate_save), name='lb-manage-validate-save'),
    url(r'^zato/load-balancer/manage/cluster/(?P<cluster_id>.*)/$', login_required(load_balancer.manage), name='lb-manage'),
    url(r'^zato/load-balancer/manage/source-code/cluster/(?P<cluster_id>.*)/validate-save$',
        login_required(load_balancer.validate_save_source_code), name='lb-manage-source-code-validate-save'),
    url(r'^zato/load-balancer/manage/source-code/cluster/(?P<cluster_id>.*)/$',
        login_required(load_balancer.manage_source_code), name='lb-manage-source-code'),
    url(r'^zato/load-balancer/remote-command/(?P<cluster_id>.*)/$',
        login_required(load_balancer.remote_command), name='lb-remote-command'),

# ################################################################################################################################

    # Services

    url(r'^zato/service/$',
        login_required(service.Index()), name=service.Index.url_name),
    url(r'^zato/service/details$',
        login_required(service.Index()), name=service.Index.url_name),
    url(r'^zato/service/last-stats/(?P<service_id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(service.last_stats), name='service-last-stats'),
    url(r'^zato/service/cluster/(?P<cluster_id>.*)/upload/$',
        login_required(service.package_upload), name='service-package-upload'),
    url(r'^zato/service/create/$',
        login_required(service.create), name='service-create'),
    url(r'^zato/service/edit/$',
        login_required(service.Edit()), name=service.Edit.url_name),
    url(r'^zato/service/invoke/(?P<name>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(service.invoke), name='service-invoke'),
    url(r'^zato/service/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(service.Delete()), name=service.Delete.url_name),
    url(r'^zato/service/overview/(?P<service_name>.*)/$',
        login_required(service.overview), name='service-overview'),
    url(r'^zato/service/invoker/(?P<service_name>.*)/$',
        login_required(service.invoker), name='service-invoker'),
    url(r'^zato/service/source-info/(?P<service_name>.*)/$',
        login_required(service.source_info), name='service-source-info'),
    url(r'^zato/service/wsdl/(?P<service_name>.*)/cluster/(?P<cluster_id>.*)/upload/$',
        login_required(service.wsdl_upload), name='service-wsdl-upload'),
    url(r'^zato/service/wsdl/(?P<service_name>.*)/cluster/(?P<cluster_id>.*)/download/$',
        login_required(service.wsdl_download), name='service-wsdl-download'),
    url(r'^zato/service/wsdl/(?P<service_name>.*)/$', login_required(service.wsdl), name='service-wsdl'),
    url(r'^zato/service/request-response/(?P<service_name>.*)/cluster/(?P<cluster_id>.*)/configure/$',
        login_required(service.request_response_configure), name='service-request-response-configure'),
    url(r'^zato/service/request-response/(?P<service_name>.*)/$',
        login_required(service.request_response), name='service-request-response'),
    url(r'^zato/service/slow-response/details/(?P<cid>.*)/(?P<service_name>.*)/$',
        login_required(service.slow_response_details), name='service-slow-response-details'),
    url(r'^zato/service/slow-response/(?P<service_name>.*)/$',
        login_required(service.slow_response), name='service-slow-response'),

# ################################################################################################################################

    # Patterns ..

# ################################################################################################################################

    # Delivery

    url(r'^zato/pattern/delivery/(?P<def_name>.*)/(?P<target_type>.*)/(?P<target>.*)/(?P<state>.*)/(?P<cluster_id>.*)/$',
        login_required(pattern_delivery.Index()), name=pattern_delivery.Index.url_name),
    url(r'^zato/pattern/delivery/delete/(?P<task_id>.*)/(?P<cluster_id>.*)/$',
        login_required(pattern_delivery.Delete()), name=pattern_delivery.Delete.url_name),
    url(r'^zato/pattern/delivery/delete-many/(?P<cluster_id>.*)/$',
        login_required(pattern_delivery.delete_many), name='pattern-delivery-delete-many'),
    url(r'^zato/pattern/delivery/details/(?P<task_id>.*)/$',
        login_required(pattern_delivery.Details()), name=pattern_delivery.Details.url_name),
    url(r'^zato/pattern/delivery/edit/(?P<task_id>.*)/(?P<cluster_id>.*)/$',
        login_required(pattern_delivery.Edit()), name=pattern_delivery.Edit.url_name),
    url(r'^zato/pattern/delivery/resubmit/(?P<task_id>.*)/(?P<cluster_id>.*)/$',
        login_required(pattern_delivery.Resubmit()), name=pattern_delivery.Resubmit.url_name),
    url(r'^zato/pattern/delivery/resubmit-many/(?P<cluster_id>.*)/$',
        login_required(pattern_delivery.resubmit_many), name='pattern-delivery-resubmit-many'),

    url(r'^zato/pattern/delivery/definition/$',
        login_required(pattern_delivery_def.Index()), name=pattern_delivery_def.Index.url_name),
    url(r'^zato/pattern/delivery/definition/create/$',
        login_required(pattern_delivery_def.Create()), name=pattern_delivery_def.Create.url_name),
    url(r'^zato/pattern/delivery/definition/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(pattern_delivery_def.Delete()), name=pattern_delivery_def.Delete.url_name),
    url(r'^zato/pattern/delivery/definition/edit/$',
        login_required(pattern_delivery_def.Edit()), name=pattern_delivery_def.Edit.url_name),

# ################################################################################################################################

    # Messages..

# ################################################################################################################################

    # .. Namespace
    url(r'^zato/messages/namespace/$',
        login_required(namespace.Index()), name=namespace.Index.url_name),
    url(r'^zato/messages/namespace/create/$',
        login_required(namespace.Create()), name=namespace.Create.url_name),
    url(r'^zato/messages/namespace/edit/$',
        login_required(namespace.Edit()), name=namespace.Edit.url_name),
    url(r'^zato/messages/namespace/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(namespace.Delete()), name=namespace.Delete.url_name),

# ################################################################################################################################

    # .. XPath
    url(r'^zato/messages/xpath/$',
        login_required(xpath.Index()), name=xpath.Index.url_name),
    url(r'^zato/messages/xpath/create/$',
        login_required(xpath.Create()), name=xpath.Create.url_name),
    url(r'^zato/messages/xpath/edit/$',
        login_required(xpath.Edit()), name=xpath.Edit.url_name),
    url(r'^zato/messages/xpath/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(xpath.Delete()), name=xpath.Delete.url_name),

# ################################################################################################################################

    # .. JSON Pointer
    url(r'^zato/messages/json-pointer/$',
        login_required(json_pointer.Index()), name=json_pointer.Index.url_name),
    url(r'^zato/messages/json-pointer/create/$',
        login_required(json_pointer.Create()), name=json_pointer.Create.url_name),
    url(r'^zato/messages/json-pointer/edit/$',
        login_required(json_pointer.Edit()), name=json_pointer.Edit.url_name),
    url(r'^zato/messages/json-pointer/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(json_pointer.Delete()), name=json_pointer.Delete.url_name),

# ################################################################################################################################

    # Security..

# ################################################################################################################################

    # .. API keys

    url(r'^zato/security/apikey/$',
        login_required(apikey.Index()), name=apikey.Index.url_name),
    url(r'^zato/security/apikey/$',
        login_required(apikey.Index()), name=apikey.Index.url_name),
    url(r'^zato/security/apikey/create/$',
        login_required(apikey.Create()), name=apikey.Create.url_name),
    url(r'^zato/security/apikey/edit/$',
        login_required(apikey.Edit()), name=apikey.Edit.url_name),
    url(r'^zato/security/apikey/change-password/$',
        login_required(apikey.change_password), name='security-apikey-change-password'),
    url(r'^zato/security/apikey/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(apikey.Delete()), name=apikey.Delete.url_name),

# ################################################################################################################################

    # .. AWS

    url(r'^zato/security/aws/$',
        login_required(aws.Index()), name=aws.Index.url_name),
    url(r'^zato/security/aws/$',
        login_required(aws.Index()), name=aws.Index.url_name),
    url(r'^zato/security/aws/create/$',
        login_required(aws.Create()), name=aws.Create.url_name),
    url(r'^zato/security/aws/edit/$',
        login_required(aws.Edit()), name=aws.Edit.url_name),
    url(r'^zato/security/aws/change-password/$',
        login_required(aws.change_password), name='security-aws-change-password'),
    url(r'^zato/security/aws/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(aws.Delete()), name=aws.Delete.url_name),

# ################################################################################################################################

    # .. HTTP Basic Auth

    url(r'^zato/security/basic-auth/$',
        login_required(basic_auth.Index()), name=basic_auth.Index.url_name),
    url(r'^zato/security/basic-auth/$',
        login_required(basic_auth.Index()), name=basic_auth.Index.url_name),
    url(r'^zato/security/basic-auth/create/$',
        login_required(basic_auth.Create()), name=basic_auth.Create.url_name),
    url(r'^zato/security/basic-auth/edit/$',
        login_required(basic_auth.Edit()), name=basic_auth.Edit.url_name),
    url(r'^zato/security/basic-auth/change-password/$',
        login_required(basic_auth.change_password), name='security-basic-auth-change-password'),
    url(r'^zato/security/basic-auth/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(basic_auth.Delete()), name=basic_auth.Delete.url_name),

# ################################################################################################################################

    # .. NTLM

    url(r'^zato/security/ntlm/$',
        login_required(ntlm.Index()), name=ntlm.Index.url_name),
    url(r'^zato/security/ntlm/$',
        login_required(ntlm.Index()), name=ntlm.Index.url_name),
    url(r'^zato/security/ntlm/create/$',
        login_required(ntlm.Create()), name=ntlm.Create.url_name),
    url(r'^zato/security/ntlm/edit/$',
        login_required(ntlm.Edit()), name=ntlm.Edit.url_name),
    url(r'^zato/security/ntlm/change-password/$',
        login_required(ntlm.change_password), name='security-ntlm-change-password'),
    url(r'^zato/security/ntlm/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(ntlm.Delete()), name=ntlm.Delete.url_name),

# ################################################################################################################################

    # .. OAuth

    url(r'^zato/security/oauth/$',
        login_required(oauth.Index()), name=oauth.Index.url_name),
    url(r'^zato/security/oauth/$',
        login_required(oauth.Index()), name=oauth.Index.url_name),
    url(r'^zato/security/oauth/create/$',
        login_required(oauth.Create()), name=oauth.Create.url_name),
    url(r'^zato/security/oauth/edit/$',
        login_required(oauth.Edit()), name=oauth.Edit.url_name),
    url(r'^zato/security/oauth/change-password/$',
        login_required(oauth.change_secret), name='security-oauth-change-secret'),
    url(r'^zato/security/oauth/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(oauth.Delete()), name=oauth.Delete.url_name),

# ################################################################################################################################

    # .. OpenStack security

    url(r'^zato/security/openstack_security/$',
        login_required(openstack_security.Index()), name=openstack_security.Index.url_name),
    url(r'^zato/security/openstack_security/$',
        login_required(openstack_security.Index()), name=openstack_security.Index.url_name),
    url(r'^zato/security/openstack_security/create/$',
        login_required(openstack_security.Create()), name=openstack_security.Create.url_name),
    url(r'^zato/security/openstack_security/edit/$',
        login_required(openstack_security.Edit()), name=openstack_security.Edit.url_name),
    url(r'^zato/security/openstack_security/change-password/$',
        login_required(openstack_security.change_password), name='security-openstack-change-password'),
    url(r'^zato/security/openstack_security/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(openstack_security.Delete()), name=openstack_security.Delete.url_name),


# ################################################################################################################################

    # .. Technical accounts

    url(r'^zato/security/tech-account/$',
        login_required(tech_account.Index()), name=tech_account.Index.url_name),
    url(r'^zato/security/tech-account/create/$',
        login_required(tech_account.Create()), name=tech_account.Create.url_name),
    url(r'^zato/security/tech-account/edit/$',
        login_required(tech_account.Edit()), name=tech_account.Edit.url_name),
    url(r'^zato/security/tech-account/change-password/$',
        login_required(tech_account.change_password), name='security-tech-account-change-password'),
    url(r'^zato/security/tech-account/get/by-id/(?P<tech_account_id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(tech_account.get_by_id), name='security-tech-account-get-by-id'),
    url(r'^zato/security/tech-account/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(tech_account.delete), name='security-tech-account-delete'),

# ################################################################################################################################

    # .. WS-Security

    url(r'^zato/security/wss/$',
        login_required(wss.index), name='security-wss'),
    url(r'^zato/security/wss/create/$',
        login_required(wss.create), name='security-wss-create'),
    url(r'^zato/security/wss/edit/$',
        login_required(wss.edit), name='security-wss-edit'),
    url(r'^zato/security/wss/change-password/$',
        login_required(wss.change_password), name='security-wss-change-password'),
    url(r'^zato/security/wss/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(wss.Delete()), name=wss.Delete.url_name),

# ################################################################################################################################

    # .. XPath

    url(r'^zato/security/xpath/$',
        login_required(xpath_sec.Index()), name=xpath_sec.Index.url_name),
    url(r'^zato/security/xpath/$',
        login_required(xpath_sec.Index()), name=xpath_sec.Index.url_name),
    url(r'^zato/security/xpath/create/$',
        login_required(xpath_sec.Create()), name=xpath_sec.Create.url_name),
    url(r'^zato/security/xpath/edit/$',
        login_required(xpath_sec.Edit()), name=xpath_sec.Edit.url_name),
    url(r'^zato/security/xpath/change-password/$',
        login_required(xpath_sec.change_password), name='security-xpath-change-password'),
    url(r'^zato/security/xpath/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(xpath_sec.Delete()), name=xpath_sec.Delete.url_name),

# ################################################################################################################################

    # Scheduler

    url(r'^zato/scheduler/$', login_required(scheduler.index), name='scheduler'),
    url(r'^zato/scheduler/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(scheduler.Delete()), name=scheduler.Delete.url_name),
    url(r'^zato/scheduler/execute/(?P<job_id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(scheduler.execute), name='scheduler-job-execute'),
    url(r'^zato/scheduler/get-definition/(?P<start_date>.*)/(?P<repeat>.*)/'
        '(?P<weeks>.*)/(?P<days>.*)/(?P<hours>.*)/(?P<minutes>.*)/(?P<seconds>.*)/$',
        login_required(scheduler.get_definition), name='scheduler-job-get-definition'),

# ################################################################################################################################

    # Definitions

# ################################################################################################################################

    # .. AMQP

    url(r'^zato/definition/amqp/$',
        login_required(def_amqp.Index()), name=def_amqp.Index.url_name),
    url(r'^zato/definition/amqp/create/$',
        login_required(def_amqp.Create()), name=def_amqp.Create.url_name),
    url(r'^zato/definition/amqp/edit/$',
        login_required(def_amqp.Edit()), name=def_amqp.Edit.url_name),
    url(r'^zato/definition/amqp/change-password/$',
        login_required(def_amqp.change_password), name='def-amqp-change-password'),
    url(r'^zato/definition/amqp/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(def_amqp.Delete()), name=def_amqp.Delete.url_name),

# ################################################################################################################################

    # .. JMS WebSphere MQ

    url(r'^zato/definition/jms-wmq/$',
        login_required(def_jms_wmq.Index()), name=def_jms_wmq.Index.url_name),
    url(r'^zato/definition/jms-wmq/create/$',
        login_required(def_jms_wmq.Create()), name=def_jms_wmq.Create.url_name),
    url(r'^zato/definition/jms-wmq/edit/$',
        login_required(def_jms_wmq.Edit()), name=def_jms_wmq.Edit.url_name),
    url(r'^zato/definition/jms-wmq/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(def_jms_wmq.Delete()), name=def_jms_wmq.Delete.url_name),

# ################################################################################################################################

    # Outgoing connections

# ################################################################################################################################

    # .. AMQP

    url(r'^zato/outgoing/amqp/$',
        login_required(out_amqp.Index()), name=out_amqp.Index.url_name),
    url(r'^zato/outgoing/amqp/create/$',
        login_required(out_amqp.create), name='out-amqp-create'),
    url(r'^zato/outgoing/amqp/edit/$',
        login_required(out_amqp.edit), name='out-amqp-edit'),
    url(r'^zato/outgoing/amqp/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(out_amqp.Delete()), name=out_amqp.Delete.url_name),

# ################################################################################################################################

    # .. FTP

    url(r'^zato/outgoing/ftp/$',
        login_required(out_ftp.Index()), name=out_ftp.Index.url_name),
    url(r'^zato/outgoing/ftp/create/$',
        login_required(out_ftp.Create()), name=out_ftp.Create.url_name),
    url(r'^zato/outgoing/ftp/edit/$',
        login_required(out_ftp.Edit()), name=out_ftp.Edit.url_name),
    url(r'^zato/outgoing/ftp/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(out_ftp.Delete()), name=out_ftp.Delete.url_name),
    url(r'^zato/outgoing/ftp/change-password/$',
        login_required(out_ftp.change_password), name='out-ftp-change-password'),

# ################################################################################################################################

    # .. JMS WebSphere MQ

    url(r'^zato/outgoing/jms-wmq/$', 
        login_required(out_jms_wmq.index), name='out-jms-wmq'),
    url(r'^zato/outgoing/jms-wmq/create/$',
        login_required(out_jms_wmq.create), name='out-jms-wmq-create'),
    url(r'^zato/outgoing/jms-wmq/edit/$',
        login_required(out_jms_wmq.edit), name='out-jms-wmq-edit'),
    url(r'^zato/outgoing/jms-wmq/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(out_jms_wmq.Delete()), name=out_jms_wmq.Delete.url_name),

# ################################################################################################################################

    # SQL connection pools

    url(r'^zato/outgoing/sql/$',
        login_required(out_sql.index), name='out-sql'),
    url(r'^zato/outgoing/sql/create/$',
        login_required(out_sql.create), name='out-sql-create'),
    url(r'^zato/outgoing/sql/ping/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(out_sql.ping), name='out-sql-ping'),
    url(r'^zato/outgoing/sql/edit/$',
        login_required(out_sql.edit), name='out-sql-edit'),
    url(r'^zato/outgoing/sql/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(out_sql.Delete()), name=out_sql.Delete.url_name),
    url(r'^zato/outgoing/sql/change-password/$',
        login_required(out_sql.change_password), name='out-sql-change-password'),

# ################################################################################################################################

    # .. ZeroMQ
    url(r'^zato/outgoing/zmq/$',
        login_required(out_zmq.Index()), name=out_zmq.Index.url_name),
    url(r'^zato/outgoing/zmq/create/$',
        login_required(out_zmq.Create()), name=out_zmq.Create.url_name),
    url(r'^zato/outgoing/zmq/edit/$',
        login_required(out_zmq.Edit()), name=out_zmq.Edit.url_name),
    url(r'^zato/outgoing/zmq/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(out_zmq.Delete()), name=out_zmq.Delete.url_name),

# ################################################################################################################################

    # Channels

# ################################################################################################################################

    # .. AMQP
    url(r'^zato/channel/amqp/$', 
        login_required(channel_amqp.Index()), name=channel_amqp.Index.url_name),
    url(r'^zato/channel/amqp/create/$',
        login_required(channel_amqp.create), name='channel-amqp-create'),
    url(r'^zato/channel/amqp/edit/$',
        login_required(channel_amqp.edit), name='channel-amqp-edit'),
    url(r'^zato/channel/amqp/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(channel_amqp.Delete()), name=channel_amqp.Delete.url_name),

# ################################################################################################################################

    # .. JMS WebSphere MQ
    url(r'^zato/channel/jms-wmq/$', 
        login_required(channel_jms_wmq.Index()), name=channel_jms_wmq.Index.url_name),
    url(r'^zato/channel/jms-wmq/create/$',
        login_required(channel_jms_wmq.create), name='channel-jms-wmq-create'),
    url(r'^zato/channel/jms-wmq/edit/$',
        login_required(channel_jms_wmq.edit), name='channel-jms-wmq-edit'),
    url(r'^zato/channel/jms-wmq/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(channel_jms_wmq.Delete()), name=channel_jms_wmq.Delete.url_name),

# ################################################################################################################################

    # .. ZeroMQ
    url(r'^zato/channel/zmq/$',
        login_required(channel_zmq.Index()), name=channel_zmq.Index.url_name),
    url(r'^zato/channel/zmq/create/$',
        login_required(channel_zmq.Create()), name=channel_zmq.Create.url_name),
    url(r'^zato/channel/zmq/edit/$',
        login_required(channel_zmq.Edit()), name=channel_zmq.Edit.url_name),
    url(r'^zato/channel/zmq/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(channel_zmq.Delete()), name=channel_zmq.Delete.url_name),

# ################################################################################################################################

    # HTTP/SOAP

    url(r'^zato/http-soap/$',
        login_required(http_soap.index), name='http-soap'),
    url(r'^zato/http-soap/details/(?P<connection>.*)/(?P<transport>.*)/(?P<id>.*)/(?P<name>.*)/(?P<cluster_id>.*)/$', 
        login_required(http_soap.details), name='http-soap-details'),
    url(r'^zato/http-soap/audit/set-state/(?P<connection>.*)/(?P<transport>.*)/(?P<id>.*)/(?P<name>.*)/(?P<cluster_id>.*)/$',
        login_required(http_soap.audit_set_state), name='http-soap-audit-set-state'),
    url(r'^zato/http-soap/audit/set-config/(?P<connection>.*)/(?P<transport>.*)/(?P<id>.*)/(?P<name>.*)/(?P<cluster_id>.*)/$',
        login_required(http_soap.audit_set_config), name='http-soap-audit-set-config'),
    url(r'^zato/http-soap/audit/log/(?P<connection>.*)/(?P<transport>.*)/(?P<conn_id>.*)/(?P<conn_name>.*)/(?P<cluster_id>.*)/$',
        login_required(http_soap.audit_log), name='http-soap-audit-log'),
    url(r'^zato/http-soap/audit/item/(?P<connection>.*)/(?P<transport>.*)/(?P<conn_id>.*)/(?P<conn_name>.*)/(?P<cluster_id>.*)/(?P<id>.*)/$',
        login_required(http_soap.audit_item), name='http-soap-audit-item'),

# ################################################################################################################################

    url(r'^zato/http-soap/create/$',
        login_required(http_soap.create), name='http-soap-create'),
    url(r'^zato/http-soap/edit/$',
        login_required(http_soap.edit), name='http-soap-edit'),
    url(r'^zato/http-soap/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(http_soap.delete), name='http-soap-delete'),
    url(r'^zato/http-soap/ping/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(http_soap.ping), name='http-soap-ping'),
    url(r'^zato/http-soap/reload-wsdl/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(http_soap.reload_wsdl), name='http-soap-reload-wsdl'),

# ################################################################################################################################

    # .. ZeroMQ

    url(r'^zato/channel/zmq/$',
        login_required(channel_zmq.Index()), name=channel_zmq.Index.url_name),
    url(r'^zato/channel/zmq/create/$',
        login_required(channel_zmq.Create()), name=channel_zmq.Create.url_name),
    url(r'^zato/channel/zmq/edit/$',
        login_required(channel_zmq.Edit()), name=channel_zmq.Edit.url_name),
    url(r'^zato/channel/zmq/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(channel_zmq.Delete()), name=channel_zmq.Delete.url_name),

# ################################################################################################################################

    # Notifications

# ################################################################################################################################

    # .. OpenStack Swift

    url(r'^zato/notif/cloud/openstack/swift/$',
        login_required(notif_cloud_openstack_swift.Index()), name=notif_cloud_openstack_swift.Index.url_name),
    url(r'^zato/notif/cloud/openstack/swift/create/$',
        login_required(notif_cloud_openstack_swift.Create()), name=notif_cloud_openstack_swift.Create.url_name),
    url(r'^zato/notif/cloud/openstack/swift/edit/$',
        login_required(notif_cloud_openstack_swift.Edit()), name=notif_cloud_openstack_swift.Edit.url_name),
    url(r'^zato/notif/cloud/openstack/swift/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(notif_cloud_openstack_swift.Delete()), name=notif_cloud_openstack_swift.Delete.url_name),

# ################################################################################################################################

    # Cloud

# ################################################################################################################################
    
    # .. OpenStack - S3

    url(r'^zato/cloud/aws/s3/$',
        login_required(cloud_aws_s3.Index()), name=cloud_aws_s3.Index.url_name),
    url(r'^zato/cloud/aws/s3/create/$',
        login_required(cloud_aws_s3.Create()), name=cloud_aws_s3.Create.url_name),
    url(r'^zato/cloud/aws/s3/edit/$',
        login_required(cloud_aws_s3.Edit()), name=cloud_aws_s3.Edit.url_name),
    url(r'^zato/cloud/aws/s3/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(cloud_aws_s3.Delete()), name=cloud_aws_s3.Delete.url_name),

# ################################################################################################################################
    
    # .. OpenStack - Swift

    url(r'^zato/cloud/openstack/swift/$',
        login_required(cloud_openstack_swift.Index()), name=cloud_openstack_swift.Index.url_name),
    url(r'^zato/cloud/openstack/swift/create/$',
        login_required(cloud_openstack_swift.Create()), name=cloud_openstack_swift.Create.url_name),
    url(r'^zato/cloud/openstack/swift/edit/$',
        login_required(cloud_openstack_swift.Edit()), name=cloud_openstack_swift.Edit.url_name),
    url(r'^zato/cloud/openstack/swift/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(cloud_openstack_swift.Delete()), name=cloud_openstack_swift.Delete.url_name),

# ################################################################################################################################

    # Key/value DB

    url(r'^zato/kvdb/remote-command/$',
        login_required(kvdb.remote_command), name='kvdb-remote-command'),
    url(r'^zato/kvdb/remote-command/execute/$',
        login_required(kvdb.remote_command_execute), name='kvdb-remote-command-execute'),
    url(r'^zato/kvdb/data-dict/dictionary/$',
        login_required(dictionary.Index()), name=dictionary.Index.url_name),
    url(r'^zato/kvdb/data-dict/dictionary/create/$',
        login_required(dictionary.Create()), name=dictionary.Create.url_name),
    url(r'^zato/kvdb/data-dict/dictionary/edit/$',
        login_required(dictionary.Edit()), name=dictionary.Edit.url_name),
    url(r'^zato/kvdb/data-dict/dictionary/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(dictionary.Delete()), name=dictionary.Delete.url_name),

# ################################################################################################################################

    url(r'^zato/kvdb/data-dict/translation/$',
        login_required(translation.Index()), name=translation.Index.url_name),
    url(r'^zato/kvdb/data-dict/translation/create/$',
        login_required(translation.Create()), name=translation.Create.url_name),
    url(r'^zato/kvdb/data-dict/translation/edit/$',
        login_required(translation.Edit()), name=translation.Edit.url_name),
    url(r'^zato/kvdb/data-dict/translation/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(translation.Delete()), name=translation.Delete.url_name),
    url(r'^zato/kvdb/data-dict/translation/get-key-list/$',
        login_required(translation.get_key_list), name='kvdb-data-dict-translation-get-key-list'),
    url(r'^zato/kvdb/data-dict/translation/get-value-list/$',
        login_required(translation.get_value_list), name='kvdb-data-dict-translation-get-value-list'),
    url(r'^zato/kvdb/data-dict/translation/translate/$',
        login_required(translation.translate), name='kvdb-data-dict-translation-translate'),

# ################################################################################################################################

    url(r'^zato/kvdb/data-dict/impexp/$',
        login_required(impexp.index), name='kvdb-data-dict-impexp'),
    url(r'^zato/kvdb/data-dict/impexp/cluster/(?P<cluster_id>.*)/import/$',
        login_required(impexp.import_), name='kvdb-data-dict-impexp-import'),
    url(r'^zato/kvdb/data-dict/impexp/cluster/(?P<cluster_id>.*)/export/$',
        login_required(impexp.export), name='kvdb-data-dict-impexp-export'),

# ################################################################################################################################

    # Pub/sub

    url(r'^zato/pubsub/consumers/cluster/(?P<cluster_id>.*)/topic/(?P<topic_name>.*)$',
        login_required(pubsub_consumers.Index()), name=pubsub_consumers.Index.url_name),
    url(r'^zato/pubsub/consumers/create/$',
        login_required(pubsub_consumers.Create()), name=pubsub_consumers.Create.url_name),
    url(r'^zato/pubsub/consumers/edit/$',
        login_required(pubsub_consumers.Edit()), name=pubsub_consumers.Edit.url_name),
    url(r'^zato/pubsub/consumers/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(pubsub_consumers.Delete()), name=pubsub_consumers.Delete.url_name),

    url(r'^zato/pubsub/message/cluster/(?P<cluster_id>.*)/consumer-queue/(?P<sub_key>\w+)/(?P<topic_name>.*)$',
        login_required(pubsub_message.index_consumer_queue), name='pubsub-message-consumer-queue'),
    url(r'^zato/pubsub/message/cluster/(?P<cluster_id>.*)/topic/(?P<topic_name>.*)$',
        login_required(pubsub_message.index_topic), name='pubsub-message-topic'),
    url(r'^zato/pubsub/message/(?P<source_type>[a-z\-]+)/msg/(?P<msg_id>\w+)/cluster/(?P<cluster_id>\w+)/topic/(?P<topic_name>.*)$',
        login_required(pubsub_message.details), name='pubsub-message-details'),
    url(r'^zato/pubsub/message/delete/$',
        login_required(pubsub_message.delete), name='pubsub-message-delete'),

    url(r'^zato/pubsub/topics/publish/cluster/(?P<cluster_id>.*)/topic/(?P<topic>.*)$',
        login_required(pubsub_topics.publish), name='pubsub-topics-publish'),
    url(r'^zato/pubsub/topics/publish/action/cluster/(?P<cluster_id>.*)/topic/(?P<topic>.*)$',
        login_required(pubsub_topics.publish_action), name='pubsub-topics-publish-action'),

    url(r'^zato/pubsub/producers/cluster/(?P<cluster_id>.*)/topic/(?P<topic_name>.*)$',
        login_required(pubsub_producers.Index()), name=pubsub_producers.Index.url_name),
    url(r'^zato/pubsub/producers/create/$',
        login_required(pubsub_producers.Create()), name=pubsub_producers.Create.url_name),
    url(r'^zato/pubsub/producers/edit/$',
        login_required(pubsub_producers.Edit()), name=pubsub_producers.Edit.url_name),
    url(r'^zato/pubsub/producers/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(pubsub_producers.Delete()), name=pubsub_producers.Delete.url_name),

    url(r'^zato/pubsub/topics/$',
        login_required(pubsub_topics.Index()), name=pubsub_topics.Index.url_name),
    url(r'^zato/pubsub/topics/create/$',
        login_required(pubsub_topics.Create()), name=pubsub_topics.Create.url_name),
    url(r'^zato/pubsub/topics/edit/$',
        login_required(pubsub_topics.Edit()), name=pubsub_topics.Edit.url_name),
    url(r'^zato/pubsub/topics/delete/(?P<id>.*)/cluster/(?P<cluster_id>.*)/$',
        login_required(pubsub_topics.Delete()), name=pubsub_topics.Delete.url_name),

    # Statistics

    url(r'^zato/stats/trends/data/$',
        login_required(stats.stats_trends_data), name='stats-trends-data'),
    url(r'^zato/stats/trends/(?P<choice>.*)/$',
        login_required(stats.trends), name='stats-trends'),
    url(r'^zato/stats/summary/data/$',
        login_required(stats.stats_summary_data), name='stats-summary-data'),
    url(r'^zato/stats/summary/(?P<choice>.*)/$',
        login_required(stats.summary), name='stats-summary'),
    url(r'^zato/stats/settings/$',
        login_required(stats.settings), name='stats-settings'),
    url(r'^zato/stats/settings/save/$',
        login_required(stats.settings_save), name='stats-settings-save'),
    url(r'^zato/stats/maintenance/$',
        login_required(stats.maintenance), name='stats-maintenance'),
    url(r'^zato/stats/maintenance/delete/$',
        login_required(stats.maintenance_delete), name='stats-maintenance-delete'),

# ################################################################################################################################

    # OpenID
    (r'^openid/', include('django_openid_auth.urls')),

# ################################################################################################################################

)

if settings.DEBUG:
    urlpatterns += patterns('',
        (r'^static/(?P<path>.*)$', 'django.views.static.serve', {'document_root': settings.MEDIA_ROOT}),
    )

########NEW FILE########
__FILENAME__ = account
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

# pytz
from pytz import common_timezones

# Zato
from zato.admin.web import DATE_FORMATS, TIME_FORMATS

class BasicSettingsForm(forms.Form):
    """ All the basic settings not including cluster color markers.
    """
    timezone = forms.ChoiceField()
    date_format = forms.ChoiceField()
    time_format = forms.ChoiceField()
    
    def __init__(self, initial, *args, **kwargs):
        super(BasicSettingsForm, self).__init__(initial, *args, **kwargs)
        
        for field in self.fields:
            self.fields[field].choices[:] = []
        
        for tz in common_timezones:
            self.fields['timezone'].choices.append([tz, tz])
            
        for item in sorted(DATE_FORMATS):
            self.fields['date_format'].choices.append([item, item])
        
        for item in sorted(TIME_FORMATS):
            self.fields['time_format'].choices.append([item, '{}-hour'.format(item)])

########NEW FILE########
__FILENAME__ = amqp
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from operator import itemgetter

# Django
from django import forms

# Zato
from zato.admin.web.forms import DataFormatForm

class CreateForm(DataFormatForm):
    name = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    def_id = forms.ChoiceField(widget=forms.Select())
    queue = forms.CharField(widget=forms.TextInput(attrs={'style':'width:50%'}))
    consumer_tag_prefix = forms.CharField(widget=forms.TextInput(attrs={'style':'width:50%'}))
    service = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))

    def __init__(self, prefix=None, post_data=None):
        super(CreateForm, self).__init__(post_data, prefix=prefix)
        self.fields['def_id'].choices = []
            
    def set_def_id(self, def_ids):
        # Sort AMQP definitions by their names.
        def_ids = sorted(def_ids.iteritems(), key=itemgetter(1))

        for id, name in def_ids:
            self.fields['def_id'].choices.append([id, name])

class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())

########NEW FILE########
__FILENAME__ = jms_wmq
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from operator import itemgetter

# Django
from django import forms

# Zato
from zato.admin.web.forms import DataFormatForm

class CreateForm(DataFormatForm):
    name = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    def_id = forms.ChoiceField(widget=forms.Select())
    queue = forms.CharField(widget=forms.TextInput(attrs={'style':'width:50%'}))
    service = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))

    def __init__(self, prefix=None, post_data=None):
        super(CreateForm, self).__init__(post_data, prefix=prefix)
        self.fields['def_id'].choices = []
            
    def set_def_id(self, def_ids):
        # Sort definitions by their names.
        def_ids = sorted(def_ids.iteritems(), key=itemgetter(1))

        for id, name in def_ids:
            self.fields['def_id'].choices.append([id, name])

class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())

########NEW FILE########
__FILENAME__ = soap
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

class DefinitionForm(forms.Form):
    id = forms.CharField(widget=forms.HiddenInput())
    url_pattern = forms.CharField(widget=forms.TextInput(attrs={"class":"required", "style":"width:90%"}))

########NEW FILE########
__FILENAME__ = zmq
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

# Zato
from zato.admin.web.forms import DataFormatForm
from zato.common import ZMQ_CHANNEL_TYPES

class CreateForm(DataFormatForm):
    name = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    address = forms.CharField(widget=forms.TextInput(attrs={'style':'width:50%'}))
    socket_type = forms.ChoiceField(widget=forms.Select())
    service = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    sub_key = forms.CharField(widget=forms.TextInput(attrs={'style':'width:50%'}))

    def __init__(self, prefix=None, post_data=None):
        super(CreateForm, self).__init__(post_data, prefix=prefix)
        
        self.fields['socket_type'].choices = []
        for name in sorted(ZMQ_CHANNEL_TYPES):
            self.fields['socket_type'].choices.append([name, name])

class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())

########NEW FILE########
__FILENAME__ = s3
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

# Zato
from zato.admin.web.forms import add_security_select
from zato.common import CLOUD

class CreateForm(forms.Form):

    name = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    pool_size = forms.CharField(initial=CLOUD.AWS.S3.DEFAULTS.POOL_SIZE, widget=forms.TextInput(attrs={'style':'width:15%'}))
    debug_level = forms.CharField(initial=CLOUD.AWS.S3.DEFAULTS.DEBUG_LEVEL, widget=forms.TextInput(attrs={'style':'width:15%'}))
    content_type = forms.CharField(initial=CLOUD.AWS.S3.DEFAULTS.CONTENT_TYPE, widget=forms.TextInput(attrs={'style':'width:100%'}))

    suppr_cons_slashes = forms.BooleanField(initial=True, required=False, widget=forms.CheckboxInput())
    address = forms.CharField(initial=CLOUD.AWS.S3.DEFAULTS.ADDRESS, widget=forms.TextInput(attrs={'style':'width:100%'}))
    metadata_ = forms.CharField(widget=forms.Textarea(attrs={'style':'width:100%'}))

    bucket = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    encrypt_at_rest = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    storage_class = forms.ChoiceField(widget=forms.Select())

    security_id = forms.ChoiceField(widget=forms.Select())

    def __init__(self, security_list=None, storage_class_list=None, prefix=None, post_data=None):
        super(CreateForm, self).__init__(post_data, prefix=prefix)
        add_security_select(self, security_list, False, 'security_id')

        self.fields['storage_class'].choices = []
        for name in CLOUD.AWS.S3.STORAGE_CLASS:
            self.fields['storage_class'].choices.append([name, name])

class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())
    suppr_cons_slashes = forms.BooleanField(required=False, widget=forms.CheckboxInput())
    encrypt_at_rest = forms.BooleanField(required=False, widget=forms.CheckboxInput())


########NEW FILE########
__FILENAME__ = swift
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

# Zato
from zato.common import CLOUD

class CreateForm(forms.Form):
    name = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    auth_version = forms.CharField(
        initial=CLOUD.OPENSTACK.SWIFT.DEFAULTS.AUTH_VERSION, widget=forms.TextInput(attrs={'style':'width:100%'}))
    pool_size = forms.CharField(
        initial=CLOUD.OPENSTACK.SWIFT.DEFAULTS.POOL_SIZE, widget=forms.TextInput(attrs={'style':'width:20%'}))
    auth_url = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    user = forms.CharField(widget=forms.TextInput(attrs={'style':'width:50%'}))
    tenant_name = forms.CharField(widget=forms.TextInput(attrs={'style':'width:50%'}))
    key = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    retries = forms.CharField(
        initial=CLOUD.OPENSTACK.SWIFT.DEFAULTS.RETRIES, widget=forms.TextInput(attrs={'style':'width:100%'}))
    starting_backoff = forms.CharField(
        initial=CLOUD.OPENSTACK.SWIFT.DEFAULTS.BACKOFF_STARTING, widget=forms.TextInput(attrs={'style':'width:100%'}))
    max_backoff = forms.CharField(
        initial=CLOUD.OPENSTACK.SWIFT.DEFAULTS.BACKOFF_MAX, widget=forms.TextInput(attrs={'style':'width:20%'}))
    should_validate_cert = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    cacert = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    should_retr_ratelimit = forms.BooleanField(required=False, widget=forms.CheckboxInput())
    needs_tls_compr = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    is_snet = forms.BooleanField(required=False, widget=forms.CheckboxInput())
    custom_options = forms.CharField(widget=forms.Textarea(attrs={'style':'width:100%'}))

    def __init__(self, prefix=None, post_data=None):
        super(CreateForm, self).__init__(post_data, prefix=prefix)

class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())
    should_validate_cert = forms.BooleanField(required=False, widget=forms.CheckboxInput())
    needs_tls_compr = forms.BooleanField(required=False, widget=forms.CheckboxInput())

########NEW FILE########
__FILENAME__ = cluster
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

# Zato
from zato.common.util import make_repr

# We let the user delete a cluster only if the answer on the form is equal to the
# one given below.
OK_TO_DELETE = 'GO AHEAD'

class EditClusterForm(forms.Form):
    name = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:100%'}))
    description = forms.CharField(widget=forms.Textarea(), required=False)

    lb_host = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    lb_port = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    lb_agent_port = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))

    def __repr__(self):
        return make_repr(self)

class DeleteClusterForm(forms.Form):
    answer = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:10%'}))
    cluster_id = forms.CharField(widget=forms.HiddenInput(attrs={'class':'required'}))

    def clean_answer(self):
        data = self.cleaned_data['answer']
        if data != OK_TO_DELETE:
            msg = "Can't delete the cluster, answer [{data}] wasn't equal to [{expected}]".format(
                data=data, expected=OK_TO_DELETE)
            raise Exception(msg)

        return data
    
class EditServerForm(forms.Form):
    name = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:100%'}))
    old_name = forms.CharField(widget=forms.HiddenInput(attrs={'class':'required'}))

########NEW FILE########
__FILENAME__ = amqp
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# pika
from pika.spec import FRAME_MAX_SIZE, PORT

# Django
from django import forms

# Zato
from zato.common.util import make_repr


class CreateForm(forms.Form):
    name = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    host = forms.CharField(widget=forms.TextInput(attrs={'style':'width:50%'}))
    port = forms.CharField(initial=PORT, widget=forms.TextInput(attrs={'style':'width:20%'}))
    vhost = forms.CharField(initial='/', widget=forms.TextInput(attrs={'style':'width:50%'}))
    username = forms.CharField(widget=forms.TextInput(attrs={'style':'width:50%'}))
    frame_max = forms.CharField(initial=FRAME_MAX_SIZE, widget=forms.TextInput(attrs={'style':'width:20%'}))
    heartbeat = forms.CharField(initial=0, widget=forms.TextInput(attrs={'style':'width:10%'}))

    def __repr__(self):
        return make_repr(self)
    
class EditForm(CreateForm):
    pass

########NEW FILE########
__FILENAME__ = jms_wmq
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

PORT = 1414
MAX_CHARS = 100

class CreateForm(forms.Form):
    name = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    host = forms.CharField(widget=forms.TextInput(attrs={'style':'width:50%'}))
    port = forms.CharField(initial=PORT, widget=forms.TextInput(attrs={'style':'width:20%'}))
    queue_manager = forms.CharField(widget=forms.TextInput(attrs={'style':'width:50%'}))
    channel = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    cache_open_send_queues = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    cache_open_receive_queues = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    use_shared_connections = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    ssl = forms.BooleanField(required=False, widget=forms.CheckboxInput())
    ssl_cipher_spec = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    ssl_key_repository = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    needs_mcd = forms.BooleanField(required=False, widget=forms.CheckboxInput())
    max_chars_printed = forms.CharField(initial=MAX_CHARS, widget=forms.TextInput(attrs={'style':'width:20%'}))

class EditForm(CreateForm):
    cache_open_send_queues = forms.BooleanField(required=False, widget=forms.CheckboxInput())
    cache_open_receive_queues = forms.BooleanField(required=False, widget=forms.CheckboxInput())
    use_shared_connections = forms.BooleanField(required=False, widget=forms.CheckboxInput())

########NEW FILE########
__FILENAME__ = http_soap
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

# Zato
from zato.admin.web.forms import add_security_select, ChooseClusterForm as _ChooseClusterForm, DataFormatForm
from zato.common import BATCH_DEFAULTS, DEFAULT_HTTP_PING_METHOD, DEFAULT_HTTP_POOL_SIZE, HTTP_SOAP_SERIALIZATION_TYPE, \
     MISC, MSG_PATTERN_TYPE, PARAMS_PRIORITY, SOAP_VERSIONS, URL_PARAMS_PRIORITY, ZATO_NONE

params_priority = (
    (PARAMS_PRIORITY.CHANNEL_PARAMS_OVER_MSG, 'URL over message'),
    (PARAMS_PRIORITY.MSG_OVER_CHANNEL_PARAMS, 'Message over URL'),
)

url_params_priority = (
    (URL_PARAMS_PRIORITY.QS_OVER_PATH, 'QS over path'),
    (URL_PARAMS_PRIORITY.PATH_OVER_QS, 'Path over QS'),
)

class CreateForm(DataFormatForm):
    name = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    host = forms.CharField(initial='http://', widget=forms.TextInput(attrs={'style':'width:100%'}))
    url_path = forms.CharField(initial='/', widget=forms.TextInput(attrs={'style':'width:100%'}))
    merge_url_params_req = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    url_params_pri = forms.ChoiceField(widget=forms.Select())
    params_pri = forms.ChoiceField(widget=forms.Select())
    serialization_type = forms.ChoiceField(widget=forms.Select())
    method = forms.CharField(widget=forms.TextInput(attrs={'style':'width:20%'}))
    soap_action = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    soap_version = forms.ChoiceField(widget=forms.Select())
    service = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    ping_method = forms.CharField(widget=forms.TextInput(attrs={'style':'width:20%'}))
    pool_size = forms.CharField(widget=forms.TextInput(attrs={'style':'width:10%'}))
    timeout = forms.CharField(widget=forms.TextInput(attrs={'style':'width:10%'}), initial=MISC.DEFAULT_HTTP_TIMEOUT)
    security = forms.ChoiceField(widget=forms.Select())
    connection = forms.CharField(widget=forms.HiddenInput())
    transport = forms.CharField(widget=forms.HiddenInput())

    def __init__(self, security_list=[], soap_versions=SOAP_VERSIONS, prefix=None, post_data=None):
        super(CreateForm, self).__init__(post_data, prefix=prefix)

        self.fields['url_params_pri'].choices = []
        for value, label in url_params_priority:
            self.fields['url_params_pri'].choices.append([value, label])

        self.fields['params_pri'].choices = []
        for value, label in params_priority:
            self.fields['params_pri'].choices.append([value, label])

        self.fields['serialization_type'].choices = []
        for item in HTTP_SOAP_SERIALIZATION_TYPE:
            self.fields['serialization_type'].choices.append([item.id, item.name])

        self.fields['soap_version'].choices = []
        for name in sorted(soap_versions):
            self.fields['soap_version'].choices.append([name, name])

        self.fields['ping_method'].initial = DEFAULT_HTTP_PING_METHOD
        self.fields['pool_size'].initial = DEFAULT_HTTP_POOL_SIZE

        add_security_select(self, security_list)

class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())
    merge_url_params_req = forms.BooleanField(required=False, widget=forms.CheckboxInput())

class ChooseClusterForm(_ChooseClusterForm):
    connection = forms.CharField(widget=forms.HiddenInput())
    transport = forms.CharField(widget=forms.HiddenInput())

class ReplacePatternsForm(forms.Form):
    audit_repl_patt_type = forms.ChoiceField(widget=forms.Select())
    pattern_list = forms.CharField(widget=forms.Textarea(attrs={'rows':13, 'cols':70}), required=False)
    audit_max_payload = forms.CharField(widget=forms.TextInput(attrs={'style':'width:20%'}))

    def __init__(self, initial=None):
        super(ReplacePatternsForm, self).__init__(initial=initial)

        self.fields['audit_repl_patt_type'].choices = []
        self.fields['audit_repl_patt_type'].choices.append(['', '----------'])

        for item in MSG_PATTERN_TYPE:
            self.fields['audit_repl_patt_type'].choices.append([item.id, item.name])

class AuditLogEntryList(forms.Form):
    """ List of audit log entries for a given HTTP/SOAP object.
    """
    start = forms.CharField(widget=forms.TextInput(attrs={'style':'width:150px; height:19px'}))
    stop = forms.CharField(widget=forms.TextInput(attrs={'style':'width:150px; height:19px'}))
    current_batch = forms.CharField(initial=BATCH_DEFAULTS.PAGE_NO, widget=forms.TextInput(attrs={'style':'width:50px; height:19px'}))
    batch_size = forms.CharField(initial=BATCH_DEFAULTS.SIZE, widget=forms.TextInput(attrs={'style':'width:50px; height:19px'}))

########NEW FILE########
__FILENAME__ = dictionary
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

class CreateForm(forms.Form):
    system = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    key = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    value = forms.CharField(widget=forms.Textarea(attrs={'style':'width:100%'}))

class EditForm(CreateForm):
    pass

########NEW FILE########
__FILENAME__ = translation
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

# Zato
from zato.admin.web.forms import INITIAL_CHOICES

class _Base(forms.Form):
    system1 = forms.ChoiceField()
    key1 = forms.ChoiceField()
    value1 = forms.ChoiceField()
    system2 = forms.ChoiceField()
    key2 = forms.ChoiceField()
    
    def __init__(self, systems=[], *args, **kwargs):
        super(_Base, self).__init__(*args, **kwargs)
        for name, value in self.fields.items():
            if isinstance(value, forms.ChoiceField):
                self.fields[name].choices = [INITIAL_CHOICES]
                
        for system_id, system in systems:
            for name in('system1', 'system2'):
                self.fields[name].choices.append([system_id, system])

class CreateForm(_Base):
    value2 = forms.ChoiceField()
    
class EditForm(CreateForm):
    pass

class TranslateForm(_Base):
    pass

########NEW FILE########
__FILENAME__ = load_balancer
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from operator import itemgetter

# Django
from django import forms

# Zato
from zato.common.haproxy import timeouts, http_log
from zato.common.util import make_repr

def populate_choices(form, fields_choices):
    """ A convenience function used in several places for populating a given
    form's SELECT choices.
    """
    for field_name, choices in fields_choices:
        form.fields[field_name].choices = []
        choices = sorted(choices.items(), key=itemgetter(0))
        for choice_id, choice_info in choices:
            choice_name = choice_info[1]
            form.fields[field_name].choices.append([choice_id, choice_name])

class ManageLoadBalancerForm(forms.Form):
    """ Form for the graphical management of HAProxy.
    """
    global_log_host = forms.CharField(widget=forms.TextInput(attrs={"class":"required", "style":"width:70%"}))
    global_log_port = forms.CharField(widget=forms.TextInput(attrs={"class":"required validate-digits", "style":"width:70%"}))
    global_log_facility = forms.CharField(widget=forms.TextInput(attrs={"class":"required", "style":"width:70%"}))
    global_log_level = forms.CharField(widget=forms.TextInput(attrs={"class":"required", "style":"width:70%"}))

    timeout_connect = forms.CharField(widget=forms.TextInput(attrs={"class":"required validate-digits", "style":"width:30%"}))
    timeout_client = forms.CharField(widget=forms.TextInput(attrs={"class":"required validate-digits", "style":"width:30%"}))
    timeout_server = forms.CharField(widget=forms.TextInput(attrs={"class":"required validate-digits", "style":"width:30%"}))

    http_plain_bind_address = forms.CharField(widget=forms.TextInput(attrs={"class":"required", "style":"width:70%"}))
    http_plain_bind_port = forms.CharField(widget=forms.TextInput(attrs={"class":"required validate-digits", "style":"width:30%"}))
    http_plain_log_http_requests = forms.ChoiceField()
    http_plain_maxconn = forms.CharField(widget=forms.TextInput(attrs={"class":"required validate-digits", "style":"width:30%"}))
    http_plain_monitor_uri = forms.CharField(widget=forms.TextInput(attrs={"class":"required", "style":"width:70%"}))

    def __init__(self, initial={}):
        super(ManageLoadBalancerForm, self).__init__(initial=initial)

        fields_choices = (
            ("http_plain_log_http_requests", http_log),
        )
        populate_choices(self, fields_choices)

    def __repr__(self):
        return make_repr(self)

class ManageLoadBalancerSourceCodeForm(forms.Form):
    """ Form for the source code-level management of HAProxy.
    """
    source_code = forms.CharField(widget=forms.Textarea(attrs={"style":"overflow:auto; width:100%; white-space: pre-wrap;height:400px"}))

class RemoteCommandForm(forms.Form):
    """ Form for the direct interface to HAProxy's commands.
    """
    command = forms.ChoiceField()
    timeout = forms.ChoiceField()
    extra = forms.CharField(widget=forms.TextInput(attrs={"style":"width:40%"}))
    result = forms.CharField(widget=forms.Textarea(attrs={"style":"overflow:auto; width:100%; white-space: pre-wrap;height:400px"}))

    def __init__(self, commands, initial={}):
        super(RemoteCommandForm, self).__init__(initial=initial)

        fields_choices = (
            ("command", commands),
            ("timeout", timeouts),
        )
        populate_choices(self, fields_choices)

    def __repr__(self):
        return make_repr(self)

########NEW FILE########
__FILENAME__ = json_pointer
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

class CreateForm(forms.Form):
    id = forms.CharField(widget=forms.HiddenInput())
    name = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:100%'}))
    value = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:100%'}))

class EditForm(CreateForm):
    pass

########NEW FILE########
__FILENAME__ = namespace
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

class CreateForm(forms.Form):
    id = forms.CharField(widget=forms.HiddenInput())
    name = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:100%'}))
    value = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:100%'}))

class EditForm(CreateForm):
    pass

########NEW FILE########
__FILENAME__ = xpath
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

class CreateForm(forms.Form):
    id = forms.CharField(widget=forms.HiddenInput())
    name = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:100%'}))
    value = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:100%'}))

class EditForm(CreateForm):
    pass

########NEW FILE########
__FILENAME__ = swift
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

# Zato
from zato.admin.web.forms import add_security_select
from zato.common import NOTIF

class CreateForm(forms.Form):

    name = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))

    interval = forms.CharField(initial=NOTIF.DEFAULT.CHECK_INTERVAL, widget=forms.TextInput(attrs={'style':'width:10%'}))
    name_pattern = forms.CharField(initial=NOTIF.DEFAULT.NAME_PATTERN, widget=forms.TextInput(attrs={'style':'width:100%'}))

    containers = forms.CharField(widget=forms.Textarea(attrs={'style':'width:100%'}))
    service_name = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))

    name_pattern_neg = forms.BooleanField(required=False, widget=forms.CheckboxInput())

    get_data = forms.BooleanField(required=False, widget=forms.CheckboxInput())
    get_data_patt = forms.CharField(initial=NOTIF.DEFAULT.GET_DATA_PATTERN, widget=forms.TextInput(attrs={'style':'width:70%'}))
    get_data_patt_neg = forms.BooleanField(required=False, widget=forms.CheckboxInput())

    def_id = forms.ChoiceField(widget=forms.Select())

    def __init__(self, def_list=None, prefix=None, post_data=None):
        super(CreateForm, self).__init__(post_data, prefix=prefix)

        self.fields['def_id'].choices = []
        for item in def_list:
            self.fields['def_id'].choices.append([item.id, item.name])

class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())
    get_data = forms.BooleanField(required=False, widget=forms.CheckboxInput())
    get_data_patt_neg = forms.BooleanField(required=False, widget=forms.CheckboxInput())

########NEW FILE########
__FILENAME__ = amqp
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from operator import itemgetter

# Django
from django import forms

# Zato
from zato.admin.settings import delivery_friendly_name
from zato.common.odb import AMQP_DEFAULT_PRIORITY


class CreateForm(forms.Form):
    name = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    delivery_mode = forms.ChoiceField(widget=forms.Select())
    priority = forms.CharField(initial=AMQP_DEFAULT_PRIORITY, widget=forms.TextInput(attrs={'style':'width:5%'}))
    content_type = forms.CharField(widget=forms.TextInput(attrs={'style':'width:50%'}))
    content_encoding = forms.CharField(widget=forms.TextInput(attrs={'style':'width:50%'}))
    expiration = forms.CharField(widget=forms.TextInput(attrs={'style':'width:20%'}))
    user_id = forms.CharField(widget=forms.TextInput(attrs={'style':'width:50%'}))
    app_id = forms.CharField(widget=forms.TextInput(attrs={'style':'width:50%'}))
    def_id = forms.ChoiceField(widget=forms.Select())

    def __init__(self, prefix=None, post_data=None):
        super(CreateForm, self).__init__(post_data, prefix=prefix)
        
        self.fields['delivery_mode'].choices = []
        self.fields['def_id'].choices = []

        # Sort modes by their friendly name.
        modes = sorted(delivery_friendly_name.iteritems(), key=itemgetter(1))

        for mode, friendly_name in modes:
            self.fields['delivery_mode'].choices.append([mode, friendly_name])
            
    def set_def_id(self, def_ids):
        # Sort AMQP definitions by their names.
        def_ids = sorted(def_ids.iteritems(), key=itemgetter(1))

        for id, name in def_ids:
            self.fields['def_id'].choices.append([id, name])

class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())

########NEW FILE########
__FILENAME__ = ftp
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from ftplib import FTP_PORT

# Django
from django import forms

class CreateForm(forms.Form):
    name = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    host = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    port = forms.CharField(initial=FTP_PORT, widget=forms.TextInput(attrs={'style':'width:10%'}))
    user = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    acct = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    timeout = forms.CharField(widget=forms.TextInput(attrs={'style':'width:10%'}))
    dircache = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    
    def __init__(self, prefix=None, post_data=None):
        super(CreateForm, self).__init__(post_data, prefix=prefix)

class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())
    dircache = forms.BooleanField(required=False, widget=forms.CheckboxInput())

########NEW FILE########
__FILENAME__ = jms_wmq
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from operator import itemgetter

# Django
from django import forms

# Zato
from zato.admin.settings import delivery_friendly_name
from zato.common.odb import WMQ_DEFAULT_PRIORITY

class CreateForm(forms.Form):
    name = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    delivery_mode = forms.ChoiceField(widget=forms.Select())
    priority = forms.CharField(initial=WMQ_DEFAULT_PRIORITY, widget=forms.TextInput(attrs={'style':'width:5%'}))
    expiration = forms.CharField(widget=forms.TextInput(attrs={'style':'width:20%'}))
    def_id = forms.ChoiceField(widget=forms.Select())

    def __init__(self, prefix=None, post_data=None):
        super(CreateForm, self).__init__(post_data, prefix=prefix)
        
        self.fields['delivery_mode'].choices = []
        self.fields['def_id'].choices = []

        # Sort modes by their friendly name.
        modes = sorted(delivery_friendly_name.iteritems(), key=itemgetter(1))

        for mode, friendly_name in modes:
            self.fields['delivery_mode'].choices.append([mode, friendly_name])
            
    def set_def_id(self, def_ids):
        # Sort definitions by their names.
        def_ids = sorted(def_ids.iteritems(), key=itemgetter(1))

        for id, name in def_ids:
            self.fields['def_id'].choices.append([id, name])

class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())

########NEW FILE########
__FILENAME__ = sql
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from operator import itemgetter

# Django
from django import forms

# Zato
from zato.admin.settings import engine_friendly_name

class CreateForm(forms.Form):
    name = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:100%'}))
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    engine = forms.ChoiceField(widget=forms.Select(attrs={'class':'required'}))
    host = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:50%'}))
    port = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:20%'}))
    db_name = forms.CharField(widget=forms.TextInput(attrs={'class':'required'}))
    username = forms.CharField(widget=forms.TextInput(attrs={'class':'required'}))
    pool_size = forms.IntegerField(initial=1, widget=forms.TextInput(attrs={'class':'required validate-digits', 'style':'width:30px'}))
    extra = forms.CharField(widget=forms.Textarea())

    def __init__(self, prefix=None, post_data=None):
        super(CreateForm, self).__init__(post_data, prefix=prefix)
        self.fields['engine'].choices = []

        # Sort engines by their friendly name.
        engines = sorted(engine_friendly_name.iteritems(), key=itemgetter(1))

        for engine, friendly_name in engines:
            self.fields['engine'].choices.append([engine, friendly_name])

class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())

########NEW FILE########
__FILENAME__ = zmq
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

# Zato
from zato.common import ZMQ_OUTGOING_TYPES

class CreateForm(forms.Form):
    name = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    address = forms.CharField(widget=forms.TextInput(attrs={'style':'width:50%'}))
    socket_type = forms.ChoiceField(widget=forms.Select())

    def __init__(self, prefix=None, post_data=None):
        super(CreateForm, self).__init__(post_data, prefix=prefix)
        
        self.fields['socket_type'].choices = []
        for name in sorted(ZMQ_OUTGOING_TYPES):
            self.fields['socket_type'].choices.append([name, name])

class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())

########NEW FILE########
__FILENAME__ = definition
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

# stdlib
from operator import itemgetter

# Django
from django import forms

# Zato
from zato.admin.web.forms import INITIAL_CHOICES_DICT
from zato.common import BATCH_DEFAULTS, INVOCATION_TARGET

# It's a pity these have to be repeated here in addition to what is in zato.admin.web
# but here the names are shorter.
_targets = {
    INVOCATION_TARGET.CHANNEL_AMQP: 'Channel - AMQP',
    INVOCATION_TARGET.CHANNEL_WMQ: 'Channel - WebSphere MQ',
    INVOCATION_TARGET.CHANNEL_ZMQ: 'Channel - ZeroMQ',
    INVOCATION_TARGET.OUTCONN_AMQP: 'Outgoing conn. - AMQP',
    INVOCATION_TARGET.OUTCONN_WMQ: 'Outgoing conn. - WebSphere MQ',
    INVOCATION_TARGET.OUTCONN_ZMQ: 'Outgoing conn. - ZeroMQ',
    INVOCATION_TARGET.SERVICE: 'Service',
}
_targets.update(INITIAL_CHOICES_DICT)

class DeliveryTargetForm(forms.Form):
    target_type = forms.ChoiceField(widget=forms.Select())

    def __init__(self, data=None):
        super(DeliveryTargetForm, self).__init__(data)
        self.fields['target_type'].choices = []
        for id, name in sorted(_targets.iteritems(), key=itemgetter(1)):
            self.fields['target_type'].choices.append([id, name])
            
class CreateForm(forms.Form):
    name = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    target = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))
    
    check_after = forms.CharField(widget=forms.TextInput(attrs={'class':'validate-digits', 'style':'width:18%'}))
    retry_repeats = forms.CharField(initial=5, widget=forms.TextInput(attrs={'class':'validate-digits', 'style':'width:12%'}))
    retry_seconds = forms.CharField(initial=600, widget=forms.TextInput(attrs={'class':'validate-digits', 'style':'width:18%'}))
    
    expire_after = forms.CharField(widget=forms.TextInput(attrs={'class':'validate-digits', 'style':'width:18%'}))
    expire_arch_succ_after = forms.CharField(initial=72, widget=forms.TextInput(attrs={'class':'validate-digits', 'style':'width:12%'}))
    expire_arch_fail_after = forms.CharField(initial=168, widget=forms.TextInput(attrs={'class':'validate-digits', 'style':'width:12%'}))
    
    callback_list = forms.CharField(widget=forms.Textarea(attrs={'rows':7}), required=False)
    
class EditForm(CreateForm):
    pass

class InstanceListForm(forms.Form):
    """ List of delivery instances.
    """
    start = forms.CharField(widget=forms.TextInput(attrs={'style':'width:150px; height:19px'}))
    stop = forms.CharField(widget=forms.TextInput(attrs={'style':'width:150px; height:19px'}))
    current_batch = forms.CharField(initial=BATCH_DEFAULTS.PAGE_NO, widget=forms.TextInput(attrs={'style':'width:50px; height:19px'}))
    batch_size = forms.CharField(initial=BATCH_DEFAULTS.SIZE, widget=forms.TextInput(attrs={'style':'width:50px; height:19px'}))

########NEW FILE########
__FILENAME__ = consumers
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from operator import attrgetter

# Django
from django import forms

# Zato
from zato.common import PUB_SUB

class CreateForm(forms.Form):
    cluster_id = forms.CharField(widget=forms.HiddenInput())
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    client_id = forms.ChoiceField(widget=forms.Select())
    delivery_mode = forms.ChoiceField(widget=forms.Select())
    callback_id = forms.ChoiceField(widget=forms.Select())
    max_backlog = forms.CharField(
        initial=PUB_SUB.DEFAULT_MAX_BACKLOG, widget=forms.TextInput(attrs={'class':'required', 'style':'width:20%'}))

    def __init__(self, prefix=None, post_data=None, client_ids=None, callback_ids=None):
        super(CreateForm, self).__init__(post_data, prefix=prefix)
        for name in('client_id', 'delivery_mode', 'client_id', 'callback_id'):
            self.fields[name].choices = []

        self.set_items(PUB_SUB.DELIVERY_MODE, 'delivery_mode')
        self.set_items(client_ids or [], 'client_id')
        self.set_items(callback_ids or [], 'callback_id')

    def set_items(self, ids, field_name):
        ids = sorted(ids, key=attrgetter('name'))

        for item in ids:
            self.fields[field_name].choices.append([item.id, item.name])

class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())

########NEW FILE########
__FILENAME__ = producers
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from operator import attrgetter

# Django
from django import forms

# Zato
from zato.common import PUB_SUB

class CreateForm(forms.Form):
    cluster_id = forms.CharField(widget=forms.HiddenInput())
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    client_id = forms.ChoiceField(widget=forms.Select())

    def __init__(self, prefix=None, post_data=None):
        super(CreateForm, self).__init__(post_data, prefix=prefix)
        self.fields['client_id'].choices = []
            
    def set_client_id(self, client_ids):
        # Sort clients by their names.
        client_ids = sorted(client_ids, key=attrgetter('name'))

        for item in client_ids:
            self.fields['client_id'].choices.append([item.id, item.name])

class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())

########NEW FILE########
__FILENAME__ = topics
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

# Zato
from zato.common import PUB_SUB

class CreateForm(forms.Form):
    id = forms.CharField(widget=forms.HiddenInput())
    name = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:90%'}))
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    max_depth = forms.CharField(initial=PUB_SUB.DEFAULT_MAX_DEPTH,
        widget=forms.TextInput(attrs={'class':'required', 'style':'width:50%'}))

class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())
    name = forms.CharField(widget=forms.HiddenInput(attrs={'class':'required', 'style':'width:90%'}))

########NEW FILE########
__FILENAME__ = scheduler
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

class _Base(forms.Form):
    id = forms.CharField(widget=forms.HiddenInput())
    name = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:100%'}))
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    service = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:100%'}))
    extra = forms.CharField(widget=forms.Textarea(attrs={'style':'width:100%'}))
    start_date = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:30%; height:19px'}))
    
class OneTimeSchedulerJobForm(_Base):
    pass

class IntervalBasedSchedulerJobForm(_Base):
    # Attributes specific to interval-based jobs.
    weeks = forms.CharField(widget=forms.TextInput(attrs={'class':'validate-digits', 'style':'width:8%'}))
    days = forms.CharField(widget=forms.TextInput(attrs={'class':'validate-digits', 'style':'width:8%'}))
    hours = forms.CharField(widget=forms.TextInput(attrs={'class':'validate-digits', 'style':'width:8%'}))
    minutes = forms.CharField(widget=forms.TextInput(attrs={'class':'validate-digits', 'style':'width:8%'}))
    seconds = forms.CharField(widget=forms.TextInput(attrs={'class':'validate-digits', 'style':'width:8%'}))
    start_date = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:30%; height:19px'}))
    repeats = forms.CharField(widget=forms.TextInput(attrs={'style':'width:8%'}))
    
class CronStyleSchedulerJobForm(_Base):
    cron_definition = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:100%'}))

########NEW FILE########
__FILENAME__ = apikey
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

class CreateForm(forms.Form):
    id = forms.CharField(widget=forms.HiddenInput())
    name = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:90%'}))
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    username = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:90%'}))

class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())

########NEW FILE########
__FILENAME__ = aws
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

class CreateForm(forms.Form):
    id = forms.CharField(widget=forms.HiddenInput())
    name = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:90%'}))
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    username = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:90%'}))

class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())

########NEW FILE########
__FILENAME__ = basic_auth
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

class CreateForm(forms.Form):
    id = forms.CharField(widget=forms.HiddenInput())
    name = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:90%'}))
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    username = forms.CharField(widget=forms.TextInput(attrs={'class':'required'}))
    realm = forms.CharField(widget=forms.TextInput(attrs={'class':'required'}))
    
class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())

########NEW FILE########
__FILENAME__ = ntlm
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

class CreateForm(forms.Form):
    id = forms.CharField(widget=forms.HiddenInput())
    name = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:90%'}))
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    username = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:90%'}))

class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())

########NEW FILE########
__FILENAME__ = oauth
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

# Zato
from zato.common import MISC, NONCE_STORE

class CreateForm(forms.Form):
    id = forms.CharField(widget=forms.HiddenInput())
    name = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:90%'}))
    username = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:90%'}))
    sig_method = forms.ChoiceField(widget=forms.Select())    
    max_nonce_log = forms.IntegerField(initial=NONCE_STORE.DEFAULT_MAX_LOG,
        widget=forms.TextInput( attrs={'class':'required validate-digits', 'style':'width:20%'}))

    def __init__(self, prefix=None, post_data=None):
        super(CreateForm, self).__init__(post_data, prefix=prefix)
        self.fields['sig_method'].choices = []

        for sig_method in MISC.OAUTH_SIG_METHODS:
            self.fields['sig_method'].choices.append([sig_method, sig_method])

class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())

########NEW FILE########
__FILENAME__ = openstack
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

class CreateForm(forms.Form):
    id = forms.CharField(widget=forms.HiddenInput())
    name = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:90%'}))
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    username = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:90%'}))

class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())

########NEW FILE########
__FILENAME__ = tech_account
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

# Zato
from zato.common.util import make_repr


class CreateForm(forms.Form):
    name = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:100%'}))
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))

    def __repr__(self):
        return make_repr(self)
    
class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())

########NEW FILE########
__FILENAME__ = wss
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

class CreateForm(forms.Form):
    id = forms.CharField(widget=forms.HiddenInput())
    name = forms.CharField(widget=forms.TextInput(attrs={"class":"required", "style":"width:90%"}))
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    username = forms.CharField(widget=forms.TextInput(attrs={"class":"required", "style":"width:90%"}))
    reject_empty_nonce_creat = forms.BooleanField(widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    reject_stale_tokens = forms.BooleanField(widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    reject_expiry_limit = forms.IntegerField(widget=forms.TextInput(attrs={"class":"required validate-digits", "style":"width:20%"}))
    nonce_freshness_time = forms.IntegerField(widget=forms.TextInput(attrs={"class":"required validate-digits", "style":"width:20%"}))
            
class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())
    reject_empty_nonce_creat = forms.BooleanField(widget=forms.CheckboxInput())
    reject_stale_tokens = forms.BooleanField(widget=forms.CheckboxInput())

########NEW FILE########
__FILENAME__ = xpath
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

class CreateForm(forms.Form):
    id = forms.CharField(widget=forms.HiddenInput())
    name = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:100%'}))
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    username = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:100%'}))
    username_expr = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:100%'}))
    password_expr = forms.CharField(widget=forms.TextInput(attrs={'style':'width:100%'}))

class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput())

########NEW FILE########
__FILENAME__ = service
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

# Zato
from zato.admin.web.forms import UploadForm

class CreateForm(forms.Form):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'checked':'checked'}))
    slow_threshold = forms.CharField(widget=forms.TextInput(attrs={'style':'width:15%'}))

class EditForm(CreateForm):
    is_active = forms.BooleanField(required=False, widget=forms.CheckboxInput(attrs={'style':'text-align:left'}))
    
class WSDLUploadForm(UploadForm):
    pass

########NEW FILE########
__FILENAME__ = stats
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django import forms

# Zato
from zato.admin.web.forms import INITIAL_CHOICES

class NForm(forms.Form):
    n = forms.IntegerField(widget=forms.TextInput(attrs={'style':'width:30px', 'id':'n'}))

class CompareForm(forms.Form):
    compare_to = forms.ChoiceField(widget=forms.Select(attrs={'id':'shift'}))
    
    def __init__(self, compare_to=[], *args, **kwargs):
        super(CompareForm, self).__init__(*args, **kwargs)
        for name, value in self.fields.items():
            if isinstance(value, forms.ChoiceField):
                self.fields[name].choices = [INITIAL_CHOICES]
                
        for name, label in compare_to:
            self.fields['compare_to'].choices.append([name, label])
            
        self.fields['compare_to'].choices.append(['custom', 'Choose a time span ..'])

class SettingsForm(forms.Form):
    """ Various statistics settings.
    """
    scheduler_raw_times_interval = forms.CharField(widget=forms.TextInput(attrs={'style':'width:20%'}))
    scheduler_raw_times_batch = forms.CharField(widget=forms.TextInput(attrs={'style':'width:20%'}))
    scheduler_per_minute_aggr_interval = forms.CharField(widget=forms.TextInput(attrs={'style':'width:20%'}))
    atttention_slow_threshold = forms.CharField(widget=forms.TextInput(attrs={'style':'width:20%'}))
    atttention_top_threshold = forms.CharField(widget=forms.TextInput(attrs={'style':'width:20%'}))
    
class MaintenanceForm(forms.Form):
    """ Statistics maintenance.
    """
    start = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:150px; height:19px'}))
    stop = forms.CharField(widget=forms.TextInput(attrs={'class':'required', 'style':'width:150px; height:19px'}))

########NEW FILE########
__FILENAME__ = models
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django.db import models
from django.contrib.auth.models import User

# Zato
from zato.admin.web import DATE_FORMATS, MONTH_YEAR_FORMATS, TIME_FORMATS

class UserProfile(models.Model):
    class Meta:
        db_table = 'user_profile'
        
    user = models.ForeignKey(User, unique=True)
    timezone = models.CharField(max_length=100, null=True, default='UTC')
    date_format = models.CharField(max_length=100, null=True, default='dd-mm-yyyy')
    time_format = models.CharField(max_length=10, null=True, default='24')
    
    def __init__(self, *args, **kwargs):
        super(UserProfile, self).__init__(*args, **kwargs)
        self.date_format_py = DATE_FORMATS[self.date_format]
        self.time_format_py = TIME_FORMATS[self.time_format]
        self.month_year_format_py = MONTH_YEAR_FORMATS[self.date_format]
        self.month_year_format_strptime = self.month_year_format_py.replace('m', '%m').replace('y', '%y').replace('Y', '%Y')
        self.year_format_py = 'Y'
        self.date_time_format_py = '{} {}'.format(self.date_format_py, self.time_format_py)
    
    def __repr__(self):
        return '<{} at {} user:[{}] timezone:[{}] date_format_py:[{}] time_format_py:[{}] month_year_format_py:[{}] date_time_format_py:[{}]>'.format(
            self.__class__.__name__, hex(id(self)), self.user, self.timezone, self.date_format_py,
            self.time_format_py, self.month_year_format_py, self.date_time_format_py)
    
    __unicode__ = __repr__
    
class ClusterColorMarker(models.Model):
    class Meta:
        db_table = 'cluster_color_marker'
    
    user_profile = models.ForeignKey(UserProfile, related_name='cluster_color_markers')
    cluster_id = models.IntegerField()
    color = models.CharField(max_length=6) # RGB

    def __repr__(self):
        return '<{} at {} user_profile:[{}] cluster_id:[{}] color:[{}]>'.format(
            self.__class__.__name__, hex(id(self)), self.user_profile, self.cluster_id, self.color)
    
    __unicode__ = __repr__

########NEW FILE########
__FILENAME__ = extras
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

from django import template

register = template.Library()

# Taken from http://djangosnippets.org/snippets/38/ and slightly updated

@register.filter
def bunchget(obj, args):
    """ Try to get an attribute from an object.

    Example: {% if block|getattr:"editable,True" %}

    Beware that the default is always a string, if you want this
    to return False, pass an empty second argument:
    {% if block|getattr:"editable," %}
    """
    args = str(args).split(',')
    if len(args) == 1:
        (attribute, default) = [args[0], ''] 
    else:
        (attribute, default) = args
        
    if attribute in obj:
        return obj[attribute]
    
    return default

# Taken from http://stackoverflow.com/a/16609498

@register.simple_tag
def url_replace(request, field, value):
    dict_ = request.GET.copy()
    dict_[field] = value

    return dict_.urlencode()
########NEW FILE########
__FILENAME__ = account
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging

# Django
from django.contrib import messages
from django.core.urlresolvers import reverse
from django.shortcuts import redirect
from django.template.response import TemplateResponse

# Zato
from zato.admin.web.forms.account import BasicSettingsForm
from zato.admin.web.models import ClusterColorMarker
from zato.admin.web.views import method_allowed

logger = logging.getLogger(__name__)

DEFAULT_PROMPT = 'Click to pick a color'

@method_allowed('GET')
def settings_basic(req):
    initial = {}
    for attr in('timezone', 'date_format', 'time_format'):
        initial[attr] = getattr(req.zato.user_profile, attr)
        
    return_data = {'clusters':req.zato.clusters, 'default_prompt':DEFAULT_PROMPT, 'form':BasicSettingsForm(initial)}
    
    cluster_colors = {str(getattr(item, 'cluster_id')):getattr(item, 'color') for item in req.zato.user_profile.cluster_color_markers.all()}
    return_data['cluster_colors'] = cluster_colors

    return TemplateResponse(req, 'zato/account/settings.html', return_data)

@method_allowed('POST')
def settings_basic_save(req):
    
    for attr in('timezone', 'date_format', 'time_format'):
        setattr(req.zato.user_profile, attr, req.POST[attr])
    req.zato.user_profile.save()

    for key, value in req.POST.items():
        if key.startswith('color_') and value != DEFAULT_PROMPT:
            cluster_id = key.replace('color_', '')
            
            if 'checkbox_{}'.format(cluster_id) in req.POST:
                try:
                    ccm = ClusterColorMarker.objects.get(cluster_id=cluster_id, user_profile=req.zato.user_profile)
                except ClusterColorMarker.DoesNotExist:
                    ccm = ClusterColorMarker()
                    ccm.cluster_id = cluster_id
                    ccm.user_profile = req.zato.user_profile
                ccm.color = value
                ccm.save()
            else:
                ClusterColorMarker.objects.filter(cluster_id=cluster_id, user_profile=req.zato.user_profile).delete()
            
    msg = 'Settings saved'
    messages.add_message(req, messages.INFO, msg, extra_tags='success')
    return redirect(reverse('account-settings-basic'))

########NEW FILE########
__FILENAME__ = amqp
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from traceback import format_exc

# Django
from django.http import HttpResponse, HttpResponseServerError

# anyjson
from anyjson import dumps

# Zato
from zato.admin.web.forms.channel.amqp import CreateForm, EditForm
from zato.admin.web.views import Delete as _Delete, get_definition_list, \
     Index as _Index, method_allowed
from zato.common.odb.model import ChannelAMQP

logger = logging.getLogger(__name__)

def _get_edit_create_message(params, prefix=''):
    """ Creates a base dictionary which can be used by both 'edit' and 'create' actions.
    """
    return {
        'id': params.get('id'),
        'cluster_id': params['cluster_id'],
        'name': params[prefix + 'name'],
        'is_active': bool(params.get(prefix + 'is_active')),
        'def_id': params[prefix + 'def_id'],
        'queue': params[prefix + 'queue'],
        'consumer_tag_prefix': params[prefix + 'consumer_tag_prefix'],
        'service': params[prefix + 'service'],
        'data_format': params.get(prefix + 'data_format'),
    }

def _edit_create_response(client, verb, id, name, def_id, cluster_id):
    response = client.invoke('zato.definition.amqp.get-by-id', {'id':def_id, 'cluster_id':cluster_id})
    return_data = {'id': id,
                   'message': 'Successfully {0} the AMQP channel [{1}]'.format(verb, name),
                   'def_name': response.data.name
                }
    return HttpResponse(dumps(return_data), mimetype='application/javascript')

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'channel-amqp'
    template = 'zato/channel/amqp.html'
    service_name = 'zato.channel.amqp.get-list'
    output_class = ChannelAMQP
    
    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'queue', 'consumer_tag_prefix', 
            'def_name', 'def_id', 'service_name', 'data_format')
        output_repeated = True
    
    def handle(self):
        create_form = CreateForm()
        edit_form = EditForm(prefix='edit')
        
        if self.req.zato.cluster_id:
            def_ids = get_definition_list(self.req.zato.client, self.req.zato.cluster, 'amqp')
            create_form.set_def_id(def_ids)
            edit_form.set_def_id(def_ids)
        
        return {
            'create_form': create_form,
            'edit_form': edit_form,
        }

@method_allowed('POST')
def create(req):
    try:
        response = req.zato.client.invoke('zato.channel.amqp.create', _get_edit_create_message(req.POST))
        return _edit_create_response(req.zato.client, 'created', response.data.id, 
            req.POST['name'], req.POST['def_id'], req.POST['cluster_id'])
    except Exception, e:
        msg = 'Could not create an AMQP channel, e:[{e}]'.format(e=format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)

    
@method_allowed('POST')
def edit(req):
    try:
        req.zato.client.invoke('zato.channel.amqp.edit', _get_edit_create_message(req.POST, 'edit-'))
        return _edit_create_response(req.zato.client, 'updated', req.POST['id'], req.POST['edit-name'], 
            req.POST['edit-def_id'], req.POST['cluster_id'])
        
    except Exception, e:
        msg = 'Could not update the AMQP channel, e:[{e}]'.format(e=format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)
    
class Delete(_Delete):
    url_name = 'channel-amqp-delete'
    error_message = 'Could not delete the AMQP channel'
    service_name = 'zato.channel.amqp.delete'

########NEW FILE########
__FILENAME__ = jms_wmq
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from traceback import format_exc

# Django
from django.http import HttpResponse, HttpResponseServerError

# anyjson
from anyjson import dumps

# Zato
from zato.admin.web.forms.channel.jms_wmq import CreateForm, EditForm
from zato.admin.web.views import Delete as _Delete, get_definition_list, Index as _Index, method_allowed
from zato.common.odb.model import ChannelWMQ

logger = logging.getLogger(__name__)
        
def _get_edit_create_message(params, prefix=''):
    """ Creates a base dictionary which can be used by both 'edit' and 'create' actions.
    """
    return {
        'id': params.get('id'),
        'cluster_id': params['cluster_id'],
        'name': params[prefix + 'name'],
        'is_active': bool(params.get(prefix + 'is_active')),
        'def_id': params[prefix + 'def_id'],
        'queue': params[prefix + 'queue'],
        'service': params[prefix + 'service'],
        'data_format': params.get(prefix + 'data_format'),
    }

def _edit_create_response(client, verb, id, name, cluster_id, def_id):
    response = client.invoke('zato.definition.jms-wmq.get-by-id', {'id':def_id, 'cluster_id': cluster_id})
    return_data = {'id': id,
                   'message': 'Successfully {0} the JMS WebSphere MQ channel [{1}]'.format(verb, name),
                   'def_name': response.data.name}
    
    return HttpResponse(dumps(return_data), mimetype='application/javascript')

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'channel-jms-wmq'
    template = 'zato/channel/jms_wmq.html'
    service_name = 'zato.channel.jms-wmq.get-list'
    output_class = ChannelWMQ
    
    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'queue', 'def_name', 'def_id', 'service_name', 'data_format')
        output_repeated = True
    
    def handle(self):
        create_form = CreateForm()
        edit_form = EditForm(prefix='edit')
        
        if self.req.zato.cluster_id:
            def_ids = get_definition_list(self.req.zato.client, self.req.zato.cluster, 'jms-wmq')
            create_form.set_def_id(def_ids)
            edit_form.set_def_id(def_ids)
        
        return {
            'create_form': create_form,
            'edit_form': edit_form,
        }

@method_allowed('POST')
def create(req):
    try:
        response = req.zato.client.invoke('zato.channel.jms-wmq.create', _get_edit_create_message(req.POST))
        return _edit_create_response(req.zato.client, 'created', response.data.id, req.POST['name'], req.POST['cluster_id'], req.POST['def_id'])
    except Exception, e:
        msg = 'Could not create a JMS WebSphere MQ channel, e:[{e}]'.format(e=format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)

    
@method_allowed('POST')
def edit(req):
    try:
        req.zato.client.invoke('zato.channel.jms-wmq.edit', _get_edit_create_message(req.POST, 'edit-'))
        return _edit_create_response(req.zato.client, 'updated', req.POST['id'], req.POST['edit-name'], req.POST['cluster_id'], req.POST['edit-def_id'])
    except Exception, e:
        msg = 'Could not update the JMS WebSphere MQ channel, e:[{e}]'.format(e=format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)
    
class Delete(_Delete):
    url_name = 'channel-jms-wmq-delete'
    error_message = 'Could not delete the JMS WebSphere MQ channel'
    service_name = 'zato.channel.jms-wmq.delete'

########NEW FILE########
__FILENAME__ = zmq
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging

# Zato
from zato.admin.web.forms.channel.zmq import CreateForm, EditForm
from zato.admin.web.views import CreateEdit, Delete as _Delete, Index as _Index
from zato.common.odb.model import ChannelZMQ

logger = logging.getLogger(__name__)

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'channel-zmq'
    template = 'zato/channel/zmq.html'
    service_name = 'zato.channel.zmq.get-list'
    output_class = ChannelZMQ
    
    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'address', 'socket_type', 'sub_key', 'service_name', 'data_format')
        output_repeated = True
    
    def handle(self):
        return {
            'create_form': CreateForm(),
            'edit_form': EditForm(prefix='edit'),
        }

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'
    
    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('name', 'is_active', 'address', 'socket_type', 'sub_key', 'service', 'data_format')
        output_required = ('id', 'name')

    def success_message(self, item):
        return 'Successfully {0} the Zero MQ channel [{1}]'.format(self.verb, item.name)

class Create(_CreateEdit):
    url_name = 'channel-zmq-create'
    service_name = 'zato.channel.zmq.create'

class Edit(_CreateEdit):
    url_name = 'channel-zmq-edit'
    form_prefix = 'edit-'
    service_name = 'zato.channel.zmq.edit'

class Delete(_Delete):
    url_name = 'channel-zmq-delete'
    error_message = 'Could not delete the Zero MQ channel'
    service_name = 'zato.channel.zmq.delete'

########NEW FILE########
__FILENAME__ = s3
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging

# Zato
from zato.admin.web.forms.cloud.aws.s3 import CreateForm, EditForm
from zato.admin.web.views import get_security_id_from_select, CreateEdit, Delete as _Delete, Index as _Index, SecurityList
from zato.common.odb.model import AWSS3

logger = logging.getLogger(__name__)

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'cloud-aws-s3'
    template = 'zato/cloud/aws/s3.html'
    service_name = 'zato.cloud.aws.s3.get-list'
    output_class = AWSS3

    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'pool_size', 'address', 'debug_level', 'suppr_cons_slashes',
            'content_type', 'security_id', 'encrypt_at_rest', 'storage_class')
        output_optional = ('metadata_', 'bucket')
        output_repeated = True

    def handle(self):
        if self.req.zato.cluster_id:
            sec_list = SecurityList.from_service(self.req.zato.client, self.req.zato.cluster.id, ['aws'])
        else:
            sec_list = []

        return {
            'create_form': CreateForm(sec_list),
            'edit_form': EditForm(sec_list, prefix='edit'),
        }

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('cluster_id', 'name', 'is_active', 'pool_size', 'address', 'debug_level', 'suppr_cons_slashes',
            'content_type', 'security_id', 'encrypt_at_rest', 'storage_class')
        input_optional = ('metadata_', 'bucket')
        output_required = ('id', 'name')

    def on_after_set_input(self):
        self.input_dict['security_id'] = get_security_id_from_select(self.input, '', 'security_id')

    def success_message(self, item):
        return 'Successfully {0} the AWS S3 connection [{1}]'.format(self.verb, item.name)

class Create(_CreateEdit):
    url_name = 'cloud-aws-s3-create'
    service_name = 'zato.cloud.aws.s3.create'

class Edit(_CreateEdit):
    url_name = 'cloud-aws-s3-edit'
    form_prefix = 'edit-'
    service_name = 'zato.cloud.aws.s3.edit'

class Delete(_Delete):
    url_name = 'cloud-aws-s3-delete'
    error_message = 'Could not delete the AWS S3 connection'
    service_name = 'zato.cloud.aws.s3.delete'

########NEW FILE########
__FILENAME__ = swift
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging

# Zato
from zato.admin.web.forms.cloud.openstack.swift import CreateForm, EditForm
from zato.admin.web.views import CreateEdit, Delete as _Delete, Index as _Index
from zato.common.odb.model import OpenStackSwift

logger = logging.getLogger(__name__)

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'cloud-openstack-swift'
    template = 'zato/cloud/openstack/swift.html'
    service_name = 'zato.cloud.openstack.swift.get-list'
    output_class = OpenStackSwift

    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = (
            'id', 'name', 'is_active', 'auth_url', 'retries', 'starting_backoff', 'max_backoff', 'auth_version', 'key', 'pool_size')
        output_optional = (
            'user', 'is_snet', 'tenant_name', 'should_validate_cert', 'cacert', 'should_retr_ratelimit', 'needs_tls_compr',
            'custom_options')
        output_repeated = True

    def handle(self):
        return {
            'create_form': CreateForm(),
            'edit_form': EditForm(prefix='edit'),
        }

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('cluster_id', 'name', 'is_active', 'auth_url', 'retries', 'starting_backoff', 'max_backoff',
           'auth_version', 'key', 'user', 'is_snet', 'tenant_name', 'should_validate_cert', 'cacert', 'should_retr_ratelimit',
           'needs_tls_compr', 'custom_options', 'pool_size')
        output_required = ('id', 'name')

    def success_message(self, item):
        return 'Successfully {0} the OpenStack Swift connection [{1}]'.format(self.verb, item.name)

class Create(_CreateEdit):
    url_name = 'cloud-openstack-swift-create'
    service_name = 'zato.cloud.openstack.swift.create'

class Edit(_CreateEdit):
    url_name = 'cloud-openstack-swift-edit'
    form_prefix = 'edit-'
    service_name = 'zato.cloud.openstack.swift.edit'

class Delete(_Delete):
    url_name = 'cloud-openstack-swift-delete'
    error_message = 'Could not delete the OpenStack Swift connection'
    service_name = 'zato.cloud.openstack.swift.delete'

########NEW FILE########
__FILENAME__ = cluster
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from string import whitespace
from traceback import format_exc

# anyjson
from anyjson import dumps

# Bunch
from bunch import Bunch

# Django
from django.http import HttpResponse, HttpResponseServerError
from django.template import loader
from django.template.response import TemplateResponse

# pytz
from pytz import UTC

# Zato
from zato.admin.web import from_utc_to_user
from zato.admin.web.forms.cluster import DeleteClusterForm, EditClusterForm, EditServerForm
from zato.admin.web.views import Delete as _Delete, get_lb_client, method_allowed, set_servers_state
from zato.admin.settings import DATABASE_ENGINE, DATABASE_HOST, DATABASE_NAME, DATABASE_PORT, \
     DATABASE_USER, sqlalchemy_django_engine
from zato.common import SERVER_UP_STATUS
from zato.common.odb.model import Cluster, Server

logger = logging.getLogger(__name__)

def _edit_create_response(item, verb):
    if item.lb_config:
        has_lb_config = True
        addresses = loader.render_to_string('zato/cluster/addresses.html', {'item':item})
    else:
        has_lb_config = False
        addresses = ''

    return_data = {
        'id': item.id,
        'message': 'Successfully {0} the cluster [{1}]'.format(verb, item.name),
        'addresses': addresses,
        'has_lb_config': has_lb_config
        }
    return HttpResponse(dumps(return_data), mimetype='application/javascript')

def _create_edit(req, verb, item, form_class, prefix=''):

    join = '-' if prefix else ''

    try:
        for s in whitespace:
            if s in req.POST[prefix + join + 'name']:
                return HttpResponseServerError('Cluster name must not contain whitespace.')

        description = req.POST[prefix + join + 'description'].strip()
        description = description if description else None

        item.name = req.POST[prefix + join + 'name'].strip()
        item.description = description

        item.lb_host = req.POST[prefix + join + 'lb_host'].strip()
        item.lb_port = req.POST[prefix + join + 'lb_port'].strip()
        item.lb_agent_port = req.POST[prefix + join + 'lb_agent_port'].strip()

        try:
            req.zato.odb.add(item)
            req.zato.odb.commit()
            
            try:
                item.lb_config = get_lb_client(item).get_config()
            except Exception, e:
                item.lb_config = None
                msg = "Exception caught while fetching the load balancer's config, e:[{0}]".format(format_exc(e))
                logger.error(msg)                    
            
            return _edit_create_response(item, verb)
        
        except Exception, e:
            msg = 'Exception caught, e:[{0}]'.format(format_exc(e))
            logger.error(msg)

            return HttpResponseServerError(msg)

    except Exception, e:
        req.zato.odb.rollback()
        return HttpResponseServerError(str(format_exc(e)))

def _get_server_data(client, server_name):
    """ Gets the server's state as seen by the load balancer.
    """
    lb_server_data = client.get_server_data_dict(server_name)
    if lb_server_data:
        in_lb = True
        state = lb_server_data[server_name]['state']
        lb_address = lb_server_data[server_name]['address']
    else:
        in_lb = False
        state = '(unknown)'
        lb_address = '(unknown)'
        
    return Bunch({
        'in_lb': in_lb,
        'state': state,
        'lb_address': lb_address,
        })

def _common_edit_message(client, success_msg, id, name, host, up_status, up_mod_date, cluster_id, user_profile, fetch_lb_data=True):
    """ Returns a common JSON message for both the actual 'edit' and 'add/remove to/from LB' actions.
    """
    return_data = {
        'id': id,
        'name': name,

        'host': host if host else '(unknown)',
        'up_status': up_status if up_status else '(unknown)',
        'up_mod_date': from_utc_to_user(up_mod_date+'+00:00', user_profile) if up_mod_date else '(unknown)',
        'cluster_id': cluster_id if cluster_id else '',
        
        'lb_state': '(unknown)',
        'lb_address': '(unknown)',
        'in_lb': '(unknown)',
        'message': success_msg.format(name)
    }

    if fetch_lb_data:
        lb_server_data = _get_server_data(client, name)
        
        return_data.update({
            'lb_state': lb_server_data.state,
            'lb_address': lb_server_data.lb_address,
            'in_lb': lb_server_data.in_lb,
        })
    
    return HttpResponse(dumps(return_data), mimetype='application/javascript')


@method_allowed('GET')
def index(req):

    initial = {}
    initial['odb_type'] = sqlalchemy_django_engine[DATABASE_ENGINE.replace('django.db.backends.', '')]
    initial['odb_host'] = DATABASE_HOST
    initial['odb_port'] = DATABASE_PORT
    initial['odb_user'] = DATABASE_USER
    initial['odb_db_name'] = DATABASE_NAME

    delete_form = DeleteClusterForm(prefix='delete')

    items = req.zato.odb.query(Cluster).order_by('name').all()
    for item in items:
        client = get_lb_client(item)

        try:
            lb_config = client.get_config()
            item.lb_config = lb_config

            # Assign the flags indicating whether servers are DOWN or in the MAINT mode.
            set_servers_state(item, client)

        except Exception, e:
            msg = 'Could not invoke agent, client:[{client!r}], e:[{e}]'.format(client=client,
                                                                e=format_exc(e))
            logger.error(msg)
            item.lb_config = None

    return_data = {'delete_form':delete_form,
                   'edit_form':EditClusterForm(prefix='edit'), 'items':items}

    return TemplateResponse(req, 'zato/cluster/index.html', return_data)

@method_allowed('POST')
def edit(req):
    return _create_edit(req, 'updated', 
        req.zato.odb.query(Cluster).filter_by(id=req.POST['id']).one(), EditClusterForm, 'edit')

def _get(req, **filter):
    cluster = req.zato.odb.query(Cluster).filter_by(**filter).one()
    return HttpResponse(cluster.to_json(), mimetype='application/javascript')

@method_allowed('GET')
def get_by_id(req, cluster_id):
    return _get(req, id=cluster_id)

@method_allowed('GET')
def get_by_name(req, cluster_name):
    return _get(req, name=cluster_name)

@method_allowed('GET')
def get_servers_state(req, cluster_id):
    cluster = req.zato.odb.query(Cluster).filter_by(id=cluster_id).one()
    client = get_lb_client(cluster)

    # Assign the flags indicating whether servers are DOWN or in the MAINT mode.
    try:
        set_servers_state(cluster, client)
    except Exception, e:
        msg = "Failed to invoke the load-balancer's agent and set the state of servers, e:[{e}]".format(e=format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)

    return TemplateResponse(req, 'zato/cluster/servers_state.html', {'cluster':cluster})

@method_allowed('POST')
def delete(req, id):
    """ Deletes a cluster *permanently*.
    """
    try:
        cluster = req.zato.odb.query(Cluster).filter_by(id=id).one()

        req.zato.odb.delete(cluster)
        req.zato.odb.commit()

    except Exception, e:
        msg = 'Could not delete the cluster, e:[{e}]'.format(e=format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)
    else:
        return HttpResponse()
    
@method_allowed('GET')
def servers(req):
    """ A view for server management.
    """
    items = req.zato.odb.query(Server).order_by('name').all()
    
    try:
        client = get_lb_client(req.zato.get('cluster'))
        server_data_dict = client.get_server_data_dict()
        bck_http_plain = client.get_config()['backend']['bck_http_plain']
        lb_client_invoked = True
    except Exception, e:
        logger.error(format_exc(e))
        lb_client_invoked = False
    
    if lb_client_invoked:
        def _update_item(server_name, lb_address, lb_state):
            for item in items:
                if item.name == server_name:
                    item.in_lb = True
                    item.lb_address = lb_address
                    item.lb_state = lb_state
                    
                    if item.up_mod_date:
                        item.up_mod_date_user = from_utc_to_user(item.up_mod_date.replace(tzinfo=UTC).isoformat(), req.zato.user_profile)
                       
                    if item.up_status == SERVER_UP_STATUS.RUNNING:
                        item.may_be_deleted = False
                    else:
                        item.may_be_deleted = True

        for server_name in bck_http_plain:
            lb_address = '{}:{}'.format(bck_http_plain[server_name]['address'], bck_http_plain[server_name]['port'])
            _update_item(server_name, lb_address, server_data_dict[server_name]['state'])

    return_data = {
        'items':items,
        'choose_cluster_form':req.zato.choose_cluster_form,
        'zato_clusters':req.zato.clusters,
        'cluster':req.zato.get('cluster'),
        'edit_form':EditServerForm(prefix='edit')
    }
    
    return TemplateResponse(req, 'zato/cluster/servers.html', return_data)

@method_allowed('POST')
def servers_edit(req):
    """ Updates a server in both ODB and the load balancer.
    """
    try:
        client = get_lb_client(req.zato.cluster)
        
        server_id = req.POST['id']
        server = req.zato.odb.query(Server).filter_by(id=server_id).one()
        
        if client.get_server_data_dict(server.name):
            fetch_lb_data = True
            client.rename_server(req.POST['edit-old_name'], req.POST['edit-name'])
        else:
            fetch_lb_data = False

        response = req.zato.client.invoke('zato.cluster.server.edit', {'id':server_id, 'name':req.POST['edit-name']})
        
        return _common_edit_message(client, 'Server [{}] updated', 
            response.data.id, response.data.name, response.data.host,
            response.data.up_status, response.data.up_mod_date,
            req.zato.cluster_id, req.zato.user_profile, fetch_lb_data)
    
    except Exception, e:
        return HttpResponseServerError(format_exc(e))

@method_allowed('POST')
def servers_add_remove_lb(req, action, server_id):
    """ Adds or removes a server from the load balancer's configuration.
    """
    server = req.zato.odb.query(Server).filter_by(id=server_id).one()
    up_mod_date = server.up_mod_date.isoformat() if server.up_mod_date else ''
    
    client = get_lb_client(req.zato.cluster)
    client.add_remove_server(action, server.name)
    
    if action == 'add':
        success_msg = 'added to'
        fetch_lb_data = True
    else:
        success_msg = 'removed from'
        fetch_lb_data = False
    
    return _common_edit_message(client, 
        'Server [{{}}] {} the load balancer'.format(success_msg),
        server.id, server.name, server.host, server.up_status, up_mod_date,
        server.cluster_id, req.zato.user_profile, fetch_lb_data)

class ServerDelete(_Delete):
    url_name = 'cluster-servers-delete'
    error_message = 'Could not delete the server'
    service_name = 'zato.server.delete'
    
    def __call__(self, req, *args, **kwargs):
        response = req.zato.client.invoke('zato.server.get-by-id', {'id':req.zato.id})

        server = req.zato.odb.query(Server).filter_by(id=req.zato.id).one()

        client = get_lb_client(req.zato.cluster) # Checks whether the server is known by LB
        if client.get_server_data_dict(server.name):
            client.add_remove_server('remove', response.data.name)
            
        return super(ServerDelete, self).__call__(req, *args, **kwargs)

########NEW FILE########
__FILENAME__ = amqp
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging

# Zato
from zato.admin.web.views import change_password as _change_password
from zato.admin.web.forms import ChangePasswordForm
from zato.admin.web.forms.definition.amqp import CreateForm, EditForm
from zato.admin.web.views import CreateEdit, Delete as _Delete, Index as _Index, method_allowed
from zato.common.odb.model import ConnDefAMQP

logger = logging.getLogger(__name__)

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'def-amqp'
    template = 'zato/definition/amqp.html'
    service_name = 'zato.definition.amqp.get-list'
    output_class = ConnDefAMQP
    
    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'host', 'port', 'vhost', 'username', 'frame_max', 'heartbeat')
        output_repeated = True
    
    def handle(self):
        return {
            'create_form': CreateForm(),
            'edit_form': EditForm(prefix='edit'),
            'change_password_form': ChangePasswordForm()
        }

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('name', 'host', 'port', 'vhost', 'username', 'frame_max', 'heartbeat')
        output_required = ('id',)
        
    def success_message(self, item):
        return 'Successfully {0} the AMQP definition [{1}]'.format(self.verb, item.name)

class Create(_CreateEdit):
    url_name = 'def-amqp-create'
    service_name = 'zato.definition.amqp.create'

class Edit(_CreateEdit):
    url_name = 'def-amqp-edit'
    form_prefix = 'edit-'
    service_name = 'zato.definition.amqp.edit'

@method_allowed('POST')
def change_password(req):
    return _change_password(req, 'zato.definition.amqp.change-password')

class Delete(_Delete):
    url_name = 'def-amqp-delete'
    error_message = 'Could not delete the AMQP definition'
    service_name = 'zato.definition.amqp.delete'

########NEW FILE########
__FILENAME__ = jms_wmq
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging

# Zato
from zato.admin.web.forms.definition.jms_wmq import CreateForm, EditForm
from zato.admin.web.views import CreateEdit, Delete as _Delete, Index as _Index
from zato.common.odb.model import ConnDefWMQ

logger = logging.getLogger(__name__)

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'def-jms-wmq'
    template = 'zato/definition/jms_wmq.html'
    service_name = 'zato.definition.jms-wmq.get-list'
    output_class = ConnDefWMQ
    
    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'host', 'port', 'queue_manager', 'channel', 'cache_open_send_queues', 
            'cache_open_receive_queues', 'use_shared_connections', 'ssl', 'ssl_cipher_spec', 'ssl_key_repository', 'needs_mcd', 'max_chars_printed')
        output_repeated = True
        
    def handle(self):
        return {
            'create_form': CreateForm(),
            'edit_form': EditForm(prefix='edit'),
        }

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('name', 'host', 'port', 'queue_manager', 'channel', 'cache_open_send_queues', 'cache_open_receive_queues', 
            'use_shared_connections', 'ssl', 'ssl_cipher_spec', 'ssl_key_repository', 'needs_mcd', 'max_chars_printed')
        output_required = ('id',)
        
    def success_message(self, item):
        return 'Successfully {0} the JMS WebSphere MQ definition [{1}]'.format(self.verb, item.name)

class Create(_CreateEdit):
    url_name = 'def-jms-wmq-create'
    service_name = 'zato.definition.jms-wmq.create'
    
class Edit(_CreateEdit):
    url_name = 'def-jms-wmq-edit'
    form_prefix = 'edit-'
    service_name = 'zato.definition.jms-wmq.edit'

class Delete(_Delete):
    url_name = 'def-jms-wmq-delete'
    error_message = 'Could not delete the JMS WebSphere MQ definition'
    service_name = 'zato.definition.jms-wmq.delete'

########NEW FILE########
__FILENAME__ = http_soap
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from cStringIO import StringIO
from pprint import pprint
from traceback import format_exc

# anyjson
from anyjson import dumps, loads

# Django
from django.http import HttpResponse, HttpResponseRedirect, HttpResponseServerError
from django.template.response import TemplateResponse

# Paste
from paste.util.converters import asbool

# Zato
from zato.admin.web import from_utc_to_user
from zato.admin.web.forms.http_soap import AuditLogEntryList, ChooseClusterForm, CreateForm, EditForm, ReplacePatternsForm
from zato.admin.web.views import get_js_dt_format, get_security_id_from_select, method_allowed, SecurityList
from zato.common import BATCH_DEFAULTS, DEFAULT_HTTP_PING_METHOD, DEFAULT_HTTP_POOL_SIZE, HTTP_SOAP_SERIALIZATION_TYPE, \
     MSG_PATTERN_TYPE, PARAMS_PRIORITY, SEC_DEF_TYPE_NAME, SOAP_CHANNEL_VERSIONS, SOAP_VERSIONS, URL_PARAMS_PRIORITY, URL_TYPE, \
     ZatoException, ZATO_NONE
from zato.common import MISC, SEC_DEF_TYPE
from zato.common.odb.model import HTTPSOAP

logger = logging.getLogger(__name__)

CONNECTION = {
    'channel': 'channel',
    'outgoing': 'outgoing connection',
    }

CONNECTION_PLURAL = {
    'channel': 'channels',
    'outgoing': 'outgoing connections',
    }

TRANSPORT = {
    'plain_http': 'Plain HTTP',
    'soap': 'SOAP',
    }

def _get_edit_create_message(params, prefix=''):
    """ A bunch of attributes that can be used by both 'edit' and 'create' actions
    for channels and outgoing connections.
    """
    security_id = get_security_id_from_select(params, prefix)

    return {
        'is_internal': False,
        'connection': params['connection'],
        'transport': params['transport'],
        'id': params.get('id'),
        'cluster_id': params['cluster_id'],
        'name': params[prefix + 'name'],
        'is_active': bool(params.get(prefix + 'is_active')),
        'host': params.get(prefix + 'host'),
        'url_path': params[prefix + 'url_path'],
        'merge_url_params_req': bool(params.get(prefix + 'merge_url_params_req')),
        'url_params_pri': params.get(prefix + 'url_params_pri', URL_PARAMS_PRIORITY.DEFAULT),
        'params_pri': params.get(prefix + 'params_pri', PARAMS_PRIORITY.DEFAULT),
        'serialization_type': params.get(prefix + 'serialization_type', HTTP_SOAP_SERIALIZATION_TYPE.DEFAULT.id),
        'method': params.get(prefix + 'method'),
        'soap_action': params.get(prefix + 'soap_action', ''),
        'soap_version': params.get(prefix + 'soap_version', None),
        'data_format': params.get(prefix + 'data_format', None),
        'service': params.get(prefix + 'service'),
        'ping_method': params.get(prefix + 'ping_method'),
        'pool_size': params.get(prefix + 'pool_size'),
        'timeout': params.get(prefix + 'timeout'),
        'security_id': security_id,
    }

def _edit_create_response(id, verb, transport, connection, name):

    return_data = {'id': id,
                   'transport': transport,
                   'message': 'Successfully {0} the {1} {2} [{3}], check server logs for details'.format(
                       verb,
                       TRANSPORT[transport],
                       CONNECTION[connection],
                       name),
                }

    return HttpResponse(dumps(return_data), mimetype='application/javascript')

@method_allowed('GET')
def index(req):
    connection = req.GET.get('connection')
    transport = req.GET.get('transport')
    items = []
    _security = SecurityList()

    if not all((connection, transport)):
        log_msg = "Redirecting to / because at least one of ('connection', 'transport') GET parameters was missing"
        logger.debug(log_msg)
        return HttpResponseRedirect('/')
    
    create_form = None
    edit_form = None

    colspan = 16
    
    if transport == 'soap':
        colspan += 2

    if req.zato.cluster_id:
        for def_item in req.zato.client.invoke('zato.security.get-list', {'cluster_id': req.zato.cluster.id}):
            # Outgoing plain HTTP connections may use HTTP Basic Auth only,
            # outgoing SOAP connections may use either WSS or HTTP Basic Auth.
            if connection == 'outgoing':
                if transport == URL_TYPE.PLAIN_HTTP and def_item.sec_type not in (
                    SEC_DEF_TYPE.BASIC_AUTH, SEC_DEF_TYPE.TECH_ACCOUNT, SEC_DEF_TYPE.APIKEY):
                    continue
                elif transport == URL_TYPE.SOAP and def_item.sec_type not in (
                    SEC_DEF_TYPE.BASIC_AUTH, SEC_DEF_TYPE.NTLM, SEC_DEF_TYPE.WSS):
                    continue

            _security.append(def_item)

        _soap_versions = SOAP_CHANNEL_VERSIONS if connection == 'channel' else SOAP_VERSIONS

        create_form = CreateForm(_security, _soap_versions)
        edit_form = EditForm(_security, _soap_versions, prefix='edit')

        input_dict = {
            'cluster_id': req.zato.cluster_id,
            'connection': connection,
            'transport': transport,
        }
        for item in req.zato.client.invoke('zato.http-soap.get-list', input_dict):

            _security_name = item.security_name
            if _security_name:
                security_name = '{0}<br/>{1}'.format(SEC_DEF_TYPE_NAME[item.sec_type], _security_name)
            else:
                security_name = 'No security'

            _security_id = item.security_id
            if _security_id:
                security_id = '{0}/{1}'.format(item.sec_type, _security_id)
            else:
                security_id = ZATO_NONE

            item = HTTPSOAP(item.id, item.name, item.is_active, item.is_internal, connection, 
                    transport, item.host, item.url_path, item.method, item.soap_action,
                    item.soap_version, item.data_format, item.ping_method, 
                    item.pool_size, item.merge_url_params_req, item.url_params_pri, item.params_pri, 
                    item.serialization_type, item.timeout, service_id=item.service_id, service_name=item.service_name,
                    security_id=security_id, security_name=security_name)
            items.append(item)

    return_data = {'zato_clusters':req.zato.clusters,
        'cluster_id':req.zato.cluster_id,
        'choose_cluster_form':ChooseClusterForm(req.zato.clusters, req.GET),
        'items':items,
        'create_form':create_form,
        'edit_form':edit_form,
        'connection':connection,
        'transport':transport,
        'connection_label':CONNECTION[connection],
        'connection_label_plural':CONNECTION_PLURAL[connection],
        'transport_label':TRANSPORT[transport],
        'colspan': colspan,
        'default_http_ping_method':DEFAULT_HTTP_PING_METHOD,
        'default_http_pool_size':DEFAULT_HTTP_POOL_SIZE,
        'default_http_timeout':MISC.DEFAULT_HTTP_TIMEOUT,
        }

    return TemplateResponse(req, 'zato/http_soap/index.html', return_data)

@method_allowed('POST')
def create(req):
    try:
        response = req.zato.client.invoke('zato.http-soap.create', _get_edit_create_message(req.POST))
        if response.has_data:
            return _edit_create_response(response.data.id, 'created',
                req.POST['transport'], req.POST['connection'], req.POST['name'])
        else:
            raise ZatoException(msg=response.details)
    except Exception, e:
        msg = 'Could not create the object, e:[{e}]'.format(e=format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)

@method_allowed('POST')
def edit(req):
    try:
        response = req.zato.client.invoke('zato.http-soap.edit', _get_edit_create_message(req.POST, 'edit-'))
        if response.has_data:
            return _edit_create_response(response.data.id, 'updated',
                req.POST['transport'], req.POST['connection'], req.POST['edit-name'])
        else:
            raise ZatoException(msg=response.details)
    except Exception, e:
        msg = 'Could not perform the update, e:[{e}]'.format(e=format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)

def _id_only_service(req, service, id, error_template):
    try:
        result = req.zato.client.invoke(service, {'id': id})
        if not result.ok:
            raise Exception(result.details)
        else:
            return result
    except Exception, e:
        msg = error_template.format(e=format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)

@method_allowed('POST')
def delete(req, id, cluster_id):
    _id_only_service(req, 'zato.http-soap.delete', id, 'Could not delete the object, e:[{e}]')
    return HttpResponse()

@method_allowed('POST')
def ping(req, id, cluster_id):
    ret = _id_only_service(req, 'zato.http-soap.ping', id, 'Could not ping the connection, e:[{e}]')
    if isinstance(ret, HttpResponseServerError):
        return ret
    return HttpResponse(ret.data.info)

@method_allowed('POST')
def reload_wsdl(req, id, cluster_id):
    ret = _id_only_service(req, 'zato.http-soap.reload-wsdl', id, 'Could not reload the WSDL, e:[{e}]')
    if isinstance(ret, HttpResponseServerError):
        return ret
    return HttpResponse('WSDL reloaded, check server logs for details')

@method_allowed('GET')
def details(req, **kwargs):
    return_data = kwargs

    audit_config = req.zato.client.invoke('zato.http-soap.get-audit-config', {'id': kwargs['id']})
    return_data.update(audit_config.data)

    patterns_response = req.zato.client.invoke('zato.http-soap.get-audit-replace-patterns', {'id': kwargs['id']})

    if audit_config.data.audit_repl_patt_type == MSG_PATTERN_TYPE.JSON_POINTER.id:
        pattern_list = patterns_response.data.patterns_json_pointer
    else:
        pattern_list = patterns_response.data.patterns_xpath

    return_data['pattern_list'] = '\n'.join(pattern_list)
    return_data['replace_patterns_form'] = ReplacePatternsForm(initial=return_data)
    
    return TemplateResponse(req, 'zato/http_soap/details.html', return_data)

@method_allowed('POST')
def audit_set_state(req, **kwargs):
    try:
        request = {'id':kwargs['id'], 'audit_enabled': not asbool(req.POST['audit_enabled'])}

        response = req.zato.client.invoke('zato.http-soap.set-audit-state', request)
        if not response.ok:
            raise Exception(response.details)

        return HttpResponse('OK')
    except Exception, e:
        msg = format_exc(e)
        logger.error(msg)
        return HttpResponseServerError(msg)

@method_allowed('POST')
def audit_set_config(req, **kwargs):
    try:
        args = {
            'id':kwargs['id'],
            'pattern_list': req.POST['pattern_list'].splitlines(), 
            'audit_repl_patt_type': req.POST['audit_repl_patt_type'],
            'audit_max_payload': req.POST['audit_max_payload'],
        }

        calls = (
            ('zato.http-soap.set-audit-replace-patterns', ('id', 'pattern_list', 'audit_repl_patt_type')),
            ('zato.http-soap.set-audit-config', ('id', 'audit_max_payload')),
        )

        for service_name, keys in calls:
            request = {key: args[key] for key in keys}
            response = req.zato.client.invoke(service_name, request)
            if not response.ok:
                raise Exception(response.details)
        
        return HttpResponse('OK')
    except Exception, e:
        msg = format_exc(e)
        logger.error(msg)
        return HttpResponseServerError(msg)

@method_allowed('GET')
def audit_log(req, **kwargs):
    out = kwargs
    out['req'] = req

    out.update(get_js_dt_format(req.zato.user_profile))

    for key in('batch_size', 'current_batch', 'start', 'stop', 'state', 'query'):
        value = req.GET.get(key)
        if value:
            out[key] = value

    out['form'] = AuditLogEntryList(initial=out)
    
    request = {
        'conn_id': out['conn_id'],
        'start': out.get('start', ''),
        'stop': out.get('stop'),
        'current_batch': out.get('current_batch', BATCH_DEFAULTS.PAGE_NO),
        'batch_size': out.get('batch_size', BATCH_DEFAULTS.SIZE),
        'query': out.get('query', ''),
    }

    out['items'] = []
    
    response = req.zato.client.invoke('zato.http-soap.get-audit-item-list', request)
    if response.ok:
        for item in response.data:
            item.req_time = from_utc_to_user(item.req_time_utc+'+00:00', req.zato.user_profile)
            item.resp_time = from_utc_to_user(item.resp_time_utc+'+00:00', req.zato.user_profile) if item.resp_time_utc else '(None)'
            out['items'].append(item)
        
    out.update(**req.zato.client.invoke('zato.http-soap.get-audit-batch-info', request).data)
    
    return TemplateResponse(req, 'zato/http_soap/audit/log.html', out)

@method_allowed('GET')
def audit_item(req, **kwargs):
    try:
        out = kwargs
        response = req.zato.client.invoke('zato.http-soap.get-audit-item', {'id':kwargs['id']})
        if response.ok:
            out.update(**response.data)

            for name in('req', 'resp'):
                headers = '{}_headers'.format(name)
                if out.get(headers):
                    buff = StringIO()
                    pprint(loads(out[headers]), buff, width=160)
                    out['{}_pp'.format(headers)] = buff.getvalue()
                    buff.close()
        else:
            raise Exception(response.details)
        return TemplateResponse(req, 'zato/http_soap/audit/item.html', out)
    except Exception, e:
        msg = format_exc(e)
        logger.error(msg)
        return HttpResponseServerError(msg)

########NEW FILE########
__FILENAME__ = dictionary
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Zato
from zato.admin.web.forms.kvdb.data_dict.dictionary import CreateForm, EditForm
from zato.admin.web.views import CreateEdit, Delete as _Delete, Index as _Index

class DictItem(object):
    pass

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'kvdb-data-dict-dictionary'
    template = 'zato/kvdb/data_dict/dictionary.html'
    service_name = 'zato.kvdb.data-dict.dictionary.get-list'
    output_class = DictItem
    
    class SimpleIO(_Index.SimpleIO):
        output_required = ('id', 'system', 'key', 'value')
        output_repeated = True

    def handle(self):
        return {
            'create_form': CreateForm(),
            'edit_form': EditForm(prefix='edit'),
        }

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('system', 'key', 'value')
        output_required = ('id',)
        
    def success_message(self, item):
        return 'Successfully {} the dictionary entry system:[{}], key:[{}], value:[{}]'.format(
            self.verb, self.input_dict['system'], self.input_dict['key'], self.input_dict['value'])

class Create(_CreateEdit):
    url_name = 'kvdb-data-dict-dictionary-create'
    service_name = 'zato.kvdb.data-dict.dictionary.create'

class Edit(_CreateEdit):
    url_name = 'kvdb-data-dict-dictionary-edit'
    form_prefix = 'edit-'
    service_name = 'zato.kvdb.data-dict.dictionary.edit'

class Delete(_Delete):
    url_name = 'kvdb-data-dict-dictionary-delete'
    error_message = 'Could not delete the data dictionary'
    service_name = 'zato.kvdb.data-dict.dictionary.delete'

########NEW FILE########
__FILENAME__ = impexp
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from datetime import datetime
from json import dumps
from traceback import format_exc

# Django
from django.http import HttpResponse, HttpResponseServerError
from django.template.response import TemplateResponse

# Zato
from zato.admin.web.views import method_allowed
from zato.common.util import current_host, translation_name

logger = logging.getLogger(__name__)

@method_allowed('GET')
def index(req):
    return_data = {
        'zato_clusters':req.zato.clusters,
        'cluster_id':req.zato.cluster_id,
        'choose_cluster_form':req.zato.choose_cluster_form,
    }
    
    return TemplateResponse(req, 'zato/kvdb/data_dict/impexp.html', return_data)

@method_allowed('POST')
def import_(req, cluster_id):
    try:
        data = req.read()
        data.decode('bz2') # A preliminary check to weed out files obviously incorrect
        req.zato.client.invoke('zato.kvdb.data-dict.impexp.import', {'data':data.encode('base64')})
    except Exception, e:
        msg = 'Could not import the data dictionaries, e:[{}]'.format(format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)
    else:
        return HttpResponse(dumps({'success': True}))

@method_allowed('GET')
def export(req, cluster_id):
    
    def _get_last_id(service):
        response = req.zato.client.invoke(service, {})
        if response.has_data:
            return response.data.value
        
    def _get_last_dict_id():
        return _get_last_id('zato.kvdb.data-dict.dictionary.get-last-id')
    
    def _get_last_translation_id():
        return _get_last_id('zato.kvdb.data-dict.translation.get-last-id')

    def _get_dict_list():
        for item in req.zato.client.invoke('zato.kvdb.data-dict.dictionary.get-list', {}):
            yield item.id, item.system, item.key, item.value
    
    def _get_translation_list():
        for item in req.zato.client.invoke('zato.kvdb.data-dict.translation.get-list', {}):
            yield item.id, item.system1, item.key1, item.value1, item.system2, \
                  item.key2, item.value2, item.id1, item.id2
    
    return_data = {'meta': {'current_host':current_host(), 'timestamp_utc':datetime.utcnow().isoformat(), 'user':req.user.username}}
    return_data['data'] = {'dict_list':[], 'translation_list':[]}
    
    return_data['data']['last_dict_id'] = _get_last_dict_id()
    return_data['data']['last_translation_id'] = _get_last_translation_id()
    
    for id, system, key, value in _get_dict_list():
        return_data['data']['dict_list'].append({'id':id, 'system':system, 'key':key, 'value':value})
        
    for id, system1, key1, value1, system2, key2, value2, id1, id2 in _get_translation_list():
        return_data['data']['translation_list'].append(
            {translation_name(system1, key1, value1, system2, key2): {'id':id, 'value2':value2, 'id1':id1, 'id2':id2}})
    
    response = HttpResponse(dumps(return_data, indent=4).encode('bz2'), mimetype='application/x-bzip2')
    response['Content-Disposition'] = 'attachment; filename={}'.format('zato-data-dict-export.json.bz2')

    return response

########NEW FILE########
__FILENAME__ = translation
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging

# anyjson
from anyjson import dumps

# Django
from django.http import HttpResponse
from django.template.response import TemplateResponse

# Zato
from zato.admin.web.forms.kvdb.data_dict.translation import CreateForm, EditForm, TranslateForm
from zato.admin.web.views import CreateEdit, Delete as _Delete, Index as _Index, method_allowed
from zato.common import ZATO_NONE

logger = logging.getLogger(__name__)

def _get_systems(client):
    systems = []
    for item in client.invoke('zato.kvdb.data-dict.dictionary.get-system-list', {}):
        systems.append([item.name] * 2)
    return systems

class DictItem(object):
    pass

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'kvdb-data-dict-translation'
    template = 'zato/kvdb/data_dict/translation/index.html'
    service_name = 'zato.kvdb.data-dict.translation.get-list'
    output_class = DictItem
    
    class SimpleIO(_Index.SimpleIO):
        output_required = ('id', 'system1', 'key1', 'value1', 'system2', 'key2', 'value2')
        output_repeated = True

    def handle(self):
        systems = _get_systems(self.req.zato.client)
        return {
            'create_form': CreateForm(systems),
            'edit_form': EditForm(systems, prefix='edit'),
        }

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'
    
    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('system1', 'key1', 'value1', 'system2', 'key2', 'value2')
        output_required = ('id',)
        
    def success_message(self, item):
        return 'Successfully {} the translation between system1:[{}], key1:[{}], value1:[{}] and system2:[{}], key2:[{}], value2:[{}]'.format(
            self.verb, self.input_dict['system1'], self.input_dict['key1'], self.input_dict['value1'],
            self.input_dict['system2'], self.input_dict['key2'], self.input_dict['value2'])

class Create(_CreateEdit):
    url_name = 'kvdb-data-dict-translation-create'
    service_name = 'zato.kvdb.data-dict.translation.create'

class Edit(_CreateEdit):
    url_name = 'kvdb-data-dict-translation-edit'
    form_prefix = 'edit-'
    service_name = 'zato.kvdb.data-dict.translation.edit'

class Delete(_Delete):
    url_name = 'kvdb-data-dict-translation-delete'
    error_message = 'Could not delete the data translation'
    service_name = 'zato.kvdb.data-dict.translation.delete'

def _get_key_value_list(req, service_name, input_dict):
    return_data = []
    for item in req.zato.client.invoke(service_name, input_dict):
        return_data.append({'name':item.name})
    
    return HttpResponse(dumps(return_data), mimetype='application/javascript')

@method_allowed('GET')
def get_key_list(req):
    return _get_key_value_list(req, 'zato.kvdb.data-dict.dictionary.get-key-list', {'system':req.GET['system']})

@method_allowed('GET')
def get_value_list(req):
    return _get_key_value_list(req, 'zato.kvdb.data-dict.dictionary.get-value-list', {'system':req.GET['system'], 'key':req.GET['key']})

@method_allowed('GET', 'POST')
def translate(req):
    
    result_names = ('system1', 'key1', 'value1', 'system2', 'key2')
    
    post_data = {}
    for name in result_names:
        post_data[name] = req.POST.get(name, '')

    def _translate():
        result = {}
        response = req.zato.client.invoke('zato.kvdb.data-dict.translation.translate', post_data)
        
        if response.has_data:
            for name in('value2', 'repr', 'hex', 'sha1', 'sha256'):
                value = getattr(response.data, name, None)
                if value and value != ZATO_NONE:
                    result[name] = value
        
        return result

    if req.zato.get('cluster'):
        translate_form = TranslateForm(_get_systems(req.zato.client), req.POST)
    else:
        translate_form = None
        
    return_data = {
        'zato_clusters':req.zato.clusters,
        'cluster_id':req.zato.cluster_id,
        'choose_cluster_form':req.zato.choose_cluster_form,
        'translate_form':translate_form,
        'postback':post_data,
        'translation_result': _translate() if req.method == 'POST' else None,
        'show_translation': req.method == 'POST'
    }
    return TemplateResponse(req, 'zato/kvdb/data_dict/translation/translate.html', return_data)

########NEW FILE########
__FILENAME__ = load_balancer
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import json, logging
from traceback import format_exc

# OrderedDict is new in 2.7
try:
    from collections import OrderedDict
except ImportError:
    from ordereddict import OrderedDict

# Django
from django.http import HttpResponse, HttpResponseServerError
from django.template.response import TemplateResponse

# Zato
from zato.admin.web import from_utc_to_user
from zato.admin.web.forms.load_balancer import ManageLoadBalancerForm, RemoteCommandForm, \
     ManageLoadBalancerSourceCodeForm
from zato.admin.web.views import get_lb_client, method_allowed
from zato.common.haproxy import haproxy_stats, Config
from zato.common.odb.model import Cluster

logger = logging.getLogger(__name__)

def _haproxy_alive(client):
    """ Check whether HAProxy is up and running. If 'status' is True then HAProxy
    is alive, sets 'status' to False otherwise and fills in the 'error' attribute
    with the details of an exception caught.
    """
    haproxy_alive = {}
    try:
        client.is_haproxy_alive()
    except Exception, e:
        haproxy_alive["status"] = False
        haproxy_alive["error"] = format_exc(e)
    else:
        haproxy_alive["status"] = True

    return haproxy_alive

def _haproxy_stat_config(client=None, lb_config=None):
    """ Return the configuration of the HAProxy HTTP stats interface.
    """
    if not lb_config:
        lb_config = client.get_config()

    # Stats URI is optional
    try:
        stats_uri = lb_config["defaults"]["stats_uri"]
    except KeyError:
        return None, None
    else:
        stats_port = lb_config["frontend"]["front_http_plain"]["bind"]["port"]
        return stats_uri, stats_port

def _get_validate_save_flag(cluster_id, req_post):
    """ A convenience function for checking we were told to validate & save
    a config or was it a request for validating it only.
    """
    if "validate_save" in req_post:
        save = True
    elif "validate" in req_post:
        save = False
    else:
        msg = "Expected a flag indicating what to do with input data. cluster_id:[{cluster_id}] req.POST:[{post}]"
        msg = msg.format(cluster_id=cluster_id, post=req_post)
        logger.error(msg)
        raise Exception(msg)

    return save

def _client_validate_save(req, func, *args):
    """ A convenience function for validating or validating & saving a config
    file on a remote SSL XML-RPC server.
    """
    save = args[1]
    try:
        func(*args)
    except Exception, e:
        msg = 'Caught an exception while invoking the load-balancer agent, e:[{}]'.format(format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)
    else:
        if save:
            return HttpResponse('Config validated and saved successfully')
        else:
            return HttpResponse("Config is valid, it's safe to save it")

@method_allowed("GET", "POST")
def remote_command(req, cluster_id):
    """ Execute a HAProxy command.
    """
    cluster = req.zato.odb.query(Cluster).filter_by(id=cluster_id).one()
    client = get_lb_client(cluster)

    haproxy_alive = _haproxy_alive(client)
    cluster.stats_uri, cluster.stats_port = _haproxy_stat_config(client=client)

    # We need to know the HAProxy version before we can build up the select box
    # on the form.
    commands = haproxy_stats[("1", "3")]

    version_info = tuple(client.haproxy_version_info())
    if version_info >= ("1", "4"):
        commands.update(haproxy_stats[("1", "4")])

    if req.method == "POST":
        result = client.execute_command(req.POST["command"], req.POST["timeout"], req.POST.get("extra", ""))
        if not result.strip():
            result = "(empty result)"

        initial={"result":result}
        for k, v in req.POST.items():
            if k != "result":
                initial[k] = v
        form = RemoteCommandForm(commands, initial)
    else:
        form = RemoteCommandForm(commands)

    return_data = {"form":form, "cluster":cluster, "haproxy_alive":haproxy_alive}

    return TemplateResponse(req, 'zato/load_balancer/remote_command.html', return_data)

@method_allowed("GET")
def manage(req, cluster_id):
    """ GUI for managing HAProxy configuration.
    """
    cluster = req.zato.odb.query(Cluster).filter_by(id=cluster_id).one()
    client = get_lb_client(cluster)

    lb_start_time = from_utc_to_user(client.get_uptime_info(), req.zato.user_profile)
    lb_config = client.get_config()
    lb_work_config = client.get_work_config()
    lb_work_config['verify_fields'] = ', '.join(['%s=%s' % (k,v) for (k, v) in sorted(lb_work_config['verify_fields'].items())])
    
    form_data = {
        'global_log_host': lb_config['global_']['log']['host'],
        'global_log_port': lb_config['global_']['log']['port'],
        'global_log_level': lb_config['global_']['log']['level'],
        'global_log_facility': lb_config['global_']['log']['facility'],

        'timeout_connect': lb_config['defaults']['timeout_connect'],
        'timeout_client': lb_config['defaults']['timeout_client'],
        'timeout_server': lb_config['defaults']['timeout_server'],

        'http_plain_bind_address':lb_config['frontend']['front_http_plain']['bind']['address'],
        'http_plain_bind_port':lb_config['frontend']['front_http_plain']['bind']['port'],
        'http_plain_log_http_requests':lb_config['frontend']['front_http_plain']['log_http_requests'],
        'http_plain_maxconn':lb_config['frontend']['front_http_plain']['maxconn'],
        'http_plain_monitor_uri':lb_config['frontend']['front_http_plain']['monitor_uri'],
        }

    backends = {}
    for backend_type in lb_config['backend']:
        for name in lb_config['backend'][backend_type]:
            # Is it a server?
            if 'address' in lb_config['backend'][backend_type][name]:
                if not name in backends:
                    backends[name] = {}
                backends[name][backend_type] = {}
                backends[name][backend_type]['address'] = lb_config['backend'][backend_type][name]['address']
                backends[name][backend_type]['port'] = lb_config['backend'][backend_type][name]['port']
                backends[name][backend_type]['extra'] = lb_config['backend'][backend_type][name]['extra']

    backends = OrderedDict(sorted(backends.items(), key=lambda t: t[0]))
    form = ManageLoadBalancerForm(initial=form_data)
    haproxy_alive = _haproxy_alive(client)
    cluster.stats_uri, cluster.stats_port = _haproxy_stat_config(lb_config=lb_config)
    servers_state = client.get_servers_state()

    return_data = {'cluster':cluster, 'lb_start_time':lb_start_time,
                   'lb_config':lb_config, 'lb_work_config':lb_work_config,
                   'form':form, 'backends':backends, 'haproxy_alive':haproxy_alive,
                   'servers_state':servers_state}

    return TemplateResponse(req, 'zato/load_balancer/manage.html', return_data)

@method_allowed("POST")
def validate_save(req, cluster_id):
    """ A common handler for both validating and saving a HAProxy config using
    a pretty GUI form.
    """
    save = _get_validate_save_flag(cluster_id, req.POST)

    cluster = req.zato.odb.query(Cluster).filter_by(id=cluster_id).one()
    client = get_lb_client(cluster)

    lb_config = Config()
    lb_config.global_["log"] = {}

    lb_config.frontend["front_http_plain"] = {}
    lb_config.frontend["front_http_plain"]["bind"] = {}

    lb_config.global_["log"]["host"] = req.POST["global_log_host"]
    lb_config.global_["log"]["port"] = req.POST["global_log_port"]
    lb_config.global_["log"]["level"] = req.POST["global_log_level"]
    lb_config.global_["log"]["facility"] = req.POST["global_log_facility"]

    lb_config.defaults["timeout_connect"] = req.POST["timeout_connect"]
    lb_config.defaults["timeout_client"] = req.POST["timeout_client"]
    lb_config.defaults["timeout_server"] = req.POST["timeout_server"]

    lb_config.frontend["front_http_plain"]["bind"]["address"] = req.POST["http_plain_bind_address"]
    lb_config.frontend["front_http_plain"]["bind"]["port"] = req.POST["http_plain_bind_port"]
    lb_config.frontend["front_http_plain"]["log_http_requests"] = req.POST["http_plain_log_http_requests"]
    lb_config.frontend["front_http_plain"]["maxconn"] = req.POST["http_plain_maxconn"]
    lb_config.frontend["front_http_plain"]["monitor_uri"] = req.POST["http_plain_monitor_uri"]

    for key, value in req.POST.items():
        if key.startswith("bck_http"):
            for token in("address", "port", "extra"):
                splitted = key.split(token)
                if splitted[0] == key:
                    continue # We don't have the token in that key.

                backend_type, backend_name = splitted

                # Get rid of underscores left over from the .split above.
                backend_type = backend_type[:-1]
                backend_name = backend_name[1:]

                lb_config.backend.setdefault(backend_type, {})
                lb_config.backend[backend_type].setdefault(backend_name, {})
                lb_config.backend[backend_type][backend_name][token] = value

    # Invoke the LB agent
    return _client_validate_save(req, client.validate_save, lb_config, save)

@method_allowed("GET")
def manage_source_code(req, cluster_id):
    """ Source code view for managing HAProxy configuration.
    """
    cluster = req.zato.odb.query(Cluster).filter_by(id=cluster_id).one()
    client = get_lb_client(cluster)
    cluster.stats_uri, cluster.stats_port = _haproxy_stat_config(client=client)

    haproxy_alive = _haproxy_alive(client)
    source_code = client.get_config_source_code()
    form = ManageLoadBalancerSourceCodeForm(initial={"source_code":source_code})

    return_data = {"form": form, "haproxy_alive":haproxy_alive, "cluster":cluster}

    return TemplateResponse(req, 'zato/load_balancer/manage_source_code.html', return_data)

@method_allowed("POST")
def validate_save_source_code(req, cluster_id):
    """ A common handler for both validating and saving a HAProxy config using
    the raw HAProxy config file's view.
    """
    cluster = req.zato.odb.query(Cluster).filter_by(id=cluster_id).one()
    save = _get_validate_save_flag(cluster_id, req.POST)

    # Invoke the LB agent
    client = get_lb_client(cluster)
    return _client_validate_save(req, client.validate_save_source_code, req.POST["source_code"], save)

@method_allowed("GET")
def get_addresses(req, cluster_id):
    """ Return JSON-formatted addresses known to HAProxy.
    """
    cluster = req.zato.odb.query(Cluster).filter_by(id=cluster_id).one()
    client = get_lb_client(cluster)

    addresses = {}
    addresses["cluster"] = {"lb_host": cluster.lb_host, "lb_agent_port":cluster.lb_agent_port}

    try:
        lb_config = client.get_config()
    except Exception, e:
        msg = "Could not get load balancer's config, client:[{client!r}], e:[{e}]".format(client=client,
                                                            e=format_exc(e))
        logger.error(msg)
        lb_config = None

    addresses["cluster"]["lb_config"] = lb_config

    return HttpResponse(json.dumps(addresses))

########NEW FILE########
__FILENAME__ = main
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# Django
from django.contrib.auth import logout as _logout
from django.contrib.auth.decorators import login_required
from django.http import HttpResponseRedirect
from django.template.response import TemplateResponse

# Zato
from zato.admin.web.views import method_allowed

@method_allowed('GET')
def index_redirect(req):
    return HttpResponseRedirect('/zato')

@method_allowed('GET')
def index(req):
    return TemplateResponse(req, 'zato/index.html')

@method_allowed('GET')
def logout(req):
    _logout(req)
    return index_redirect(req)

@method_allowed('GET')
def my_account(req):
    pass

########NEW FILE########
__FILENAME__ = json_pointer
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging

# Zato
from zato.admin.web.forms.message.json_pointer import CreateForm, EditForm
from zato.admin.web.views import CreateEdit, Delete as _Delete, Index as _Index, method_allowed
from zato.common.odb.model import JSONPointer

logger = logging.getLogger(__name__)

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'message-json-pointer'
    template = 'zato/message/json_pointer.html'
    service_name = 'zato.message.json-pointer.get-list'
    output_class = JSONPointer

    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'value')
        output_repeated = True

    def handle(self):
        return {
            'create_form': CreateForm(),
            'edit_form': EditForm(prefix='edit')
        }

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('name', 'value')
        output_required = ('id', 'name')

    def success_message(self, item):
        return 'Successfully {0} the JSON Pointer [{1}]'.format(self.verb, item.name)

class Create(_CreateEdit):
    url_name = 'message-json-pointer-create'
    service_name = 'zato.message.json-pointer.create'

class Edit(_CreateEdit):
    url_name = 'message-json-pointer-edit'
    form_prefix = 'edit-'
    service_name = 'zato.message.json-pointer.edit'

class Delete(_Delete):
    url_name = 'message-json-pointer-delete'
    error_message = 'Could not delete the JSON Pointer'
    service_name = 'zato.message.json-pointer.delete'

########NEW FILE########
__FILENAME__ = namespace
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging

# Zato
from zato.admin.web.forms.message.namespace import CreateForm, EditForm
from zato.admin.web.views import CreateEdit, Delete as _Delete, Index as _Index, method_allowed
from zato.common.odb.model import MsgNamespace

logger = logging.getLogger(__name__)

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'message-namespace'
    template = 'zato/message/namespace.html'
    service_name = 'zato.message.namespace.get-list'
    output_class = MsgNamespace

    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'value')
        output_repeated = True

    def handle(self):
        return {
            'create_form': CreateForm(),
            'edit_form': EditForm(prefix='edit')
        }

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('name', 'value')
        output_required = ('id', 'name')

    def success_message(self, item):
        return 'Successfully {0} the namespace [{1}]'.format(self.verb, item.name)

class Create(_CreateEdit):
    url_name = 'message-namespace-create'
    service_name = 'zato.message.namespace.create'

class Edit(_CreateEdit):
    url_name = 'message-namespace-edit'
    form_prefix = 'edit-'
    service_name = 'zato.message.namespace.edit'

class Delete(_Delete):
    url_name = 'message-namespace-delete'
    error_message = 'Could not delete the namespace'
    service_name = 'zato.message.namespace.delete'

########NEW FILE########
__FILENAME__ = xpath
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging

# Zato
from zato.admin.web.forms.message.xpath import CreateForm, EditForm
from zato.admin.web.views import CreateEdit, Delete as _Delete, Index as _Index, method_allowed
from zato.common.odb.model import XPath

logger = logging.getLogger(__name__)

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'message-xpath'
    template = 'zato/message/xpath.html'
    service_name = 'zato.message.xpath.get-list'
    output_class = XPath

    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'value')
        output_repeated = True

    def handle(self):
        return {
            'create_form': CreateForm(),
            'edit_form': EditForm(prefix='edit')
        }

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('name', 'value')
        output_required = ('id', 'name')

    def success_message(self, item):
        return 'Successfully {0} the XPath [{1}]'.format(self.verb, item.name)

class Create(_CreateEdit):
    url_name = 'message-xpath-create'
    service_name = 'zato.message.xpath.create'

class Edit(_CreateEdit):
    url_name = 'message-xpath-edit'
    form_prefix = 'edit-'
    service_name = 'zato.message.xpath.edit'

class Delete(_Delete):
    url_name = 'message-xpath-delete'
    error_message = 'Could not delete the XPath'
    service_name = 'zato.message.xpath.delete'

########NEW FILE########
__FILENAME__ = swift
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging

# Zato
from zato.admin.web.forms.notif.cloud.openstack.swift import CreateForm, EditForm
from zato.admin.web.views import get_security_id_from_select, CreateEdit, Delete as _Delete, Index as _Index, SecurityList
from zato.common.odb.model import NotificationOpenStackSwift as NotifOSS

logger = logging.getLogger(__name__)

common_required = ('name', 'is_active', 'def_id', 'containers', 'interval', 'name_pattern', 'name_pattern_neg', 'get_data',
    'get_data_patt_neg', 'service_name')

common_optional = ('get_data_patt',)

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'notif-cloud-openstack-swift'
    template = 'zato/notif/cloud/openstack/swift.html'
    service_name = 'zato.notif.cloud.openstack.swift.get-list'
    output_class = NotifOSS

    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'def_name',) + common_required
        output_optional = common_optional
        output_repeated = True

    def handle(self):

        def_list = []
        if self.req.zato.cluster_id:
            service_name = 'zato.cloud.openstack.swift.get-list'
            response = self.req.zato.client.invoke(service_name, {'cluster_id':self.req.zato.cluster_id})
            if response.has_data:
                def_list = response.data

        return {
            'create_form': CreateForm(def_list),
            'edit_form': EditForm(def_list, prefix='edit'),
        }

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('cluster_id',) + common_required
        input_optional = common_optional
        output_required = ('id', 'name', 'def_name')

    def success_message(self, item):
        return 'Successfully {0} the OpenStack Swift notification [{1}]'.format(self.verb, item.name)

class Create(_CreateEdit):
    url_name = 'notif-cloud-openstack-swift-create'
    service_name = 'zato.notif.cloud.openstack.swift.create'

class Edit(_CreateEdit):
    url_name = 'notif-cloud-openstack-swift-edit'
    form_prefix = 'edit-'
    service_name = 'zato.notif.cloud.openstack.swift.edit'

class Delete(_Delete):
    url_name = 'notif-cloud-openstack-swift-delete'
    error_message = 'Could not delete the OpenStack Swift notification'
    service_name = 'zato.notif.cloud.openstack.swift.delete'

########NEW FILE########
__FILENAME__ = amqp
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from traceback import format_exc

# Django
from django.http import HttpResponse, HttpResponseServerError

# anyjson
from anyjson import dumps

# Zato
from zato.admin.settings import delivery_friendly_name
from zato.admin.web.forms.outgoing.amqp import CreateForm, EditForm
from zato.admin.web.views import Delete as _Delete, get_definition_list, \
     Index as _Index, method_allowed
from zato.common.odb.model import OutgoingAMQP

logger = logging.getLogger(__name__)
        
def _get_edit_create_message(params, prefix=''):
    """ Creates a base dictionary which can be used by both 'edit' and 'create' actions.
    """
    return {
        'id': params.get('id'),
        'cluster_id': params['cluster_id'],
        'name': params[prefix + 'name'],
        'is_active': bool(params.get(prefix + 'is_active')),
        'def_id': params[prefix + 'def_id'],
        'delivery_mode': params[prefix + 'delivery_mode'],
        'priority': params[prefix + 'priority'],
        'content_type': params.get(prefix + 'content_type'),
        'content_encoding': params.get(prefix + 'content_encoding'),
        'expiration': params.get(prefix + 'expiration'),
        'user_id': params.get(prefix + 'user_id'),
        'app_id': params.get(prefix + 'app_id'),
    }

def _edit_create_response(client, verb, id, name, delivery_mode_text, def_id, cluster_id):
    response = client.invoke('zato.definition.amqp.get-by-id', {'id':def_id, 'cluster_id': cluster_id})
    return_data = {'id': id,
                   'message': 'Successfully {0} the outgoing AMQP connection [{1}]'.format(verb, name),
                   'delivery_mode_text': delivery_mode_text,
                   'def_name': response.data.name
                }
    return HttpResponse(dumps(return_data), mimetype='application/javascript')

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'out-amqp'
    template = 'zato/outgoing/amqp.html'
    
    service_name = 'zato.outgoing.amqp.get-list'
    output_class = OutgoingAMQP
    
    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'delivery_mode', 'priority',
            'content_type', 'content_encoding', 'expiration', 'user_id', 'app_id', 'delivery_mode_text', 'def_name', 'def_id')
        output_repeated = True
    
    def handle(self):
        create_form = CreateForm()
        edit_form = EditForm(prefix='edit')
        
        if self.req.zato.cluster_id:
            def_ids = get_definition_list(self.req.zato.client, self.req.zato.cluster, 'amqp')
            create_form.set_def_id(def_ids)
            edit_form.set_def_id(def_ids)
            
        for item in self.items:
            item.delivery_mode_text = delivery_friendly_name[item.delivery_mode]
        
        return {
            'create_form': create_form,
            'edit_form': edit_form,
        }

@method_allowed('POST')
def create(req):
    try:
        request = _get_edit_create_message(req.POST)
        response = req.zato.client.invoke('zato.outgoing.amqp.create', request)
        delivery_mode_text = delivery_friendly_name[int(req.POST['delivery_mode'])]

        return _edit_create_response(req.zato.client, 'created', response.data.id, 
            req.POST['name'], delivery_mode_text, req.POST['def_id'], req.POST['cluster_id'])
    except Exception, e:
        msg = 'Could not create an outgoing AMQP connection, e:[{e}]'.format(e=format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)

@method_allowed('POST')
def edit(req):
    try:
        request = _get_edit_create_message(req.POST, 'edit-')
        req.zato.client.invoke('zato.outgoing.amqp.edit', request)
        delivery_mode_text = delivery_friendly_name[int(req.POST['edit-delivery_mode'])]

        return _edit_create_response(req.zato.client, 'updated', req.POST['id'], req.POST['edit-name'],
            delivery_mode_text, req.POST['edit-def_id'], req.POST['cluster_id'])
    except Exception, e:
        msg = 'Could not update the outgoing AMQP connection, e:[{e}]'.format(e=format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)
    
class Delete(_Delete):
    url_name = 'out-amqp-delete'
    error_message = 'Could not delete the outgoing AMQP connection'
    service_name = 'zato.outgoing.amqp.delete'

########NEW FILE########
__FILENAME__ = ftp
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging

# Zato
from zato.admin.web.forms import ChangePasswordForm
from zato.admin.web.forms.outgoing.ftp import CreateForm, EditForm
from zato.admin.web.views import change_password as _change_password, CreateEdit, Delete as _Delete, Index as _Index, method_allowed
from zato.common.odb.model import OutgoingFTP

logger = logging.getLogger(__name__)

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'out-ftp'
    template = 'zato/outgoing/ftp.html'
    service_name = 'zato.outgoing.ftp.get-list'
    output_class = OutgoingFTP
    
    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'host', 'user', 'acct', 'timeout', 'port', 'dircache')
        output_repeated = True
    
    def handle(self):
        return {
            'create_form': CreateForm(),
            'edit_form': EditForm(prefix='edit'),
            'change_password_form': ChangePasswordForm()
        }

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('name', 'is_active', 'host', 'user', 'timeout', 'acct', 'port', 'dircache')
        output_required = ('id', 'name')
        
    def success_message(self, item):
        return 'Successfully {0} the outgoing FTP connection [{1}]'.format(self.verb, item.name)
    
class Create(_CreateEdit):
    url_name = 'out-ftp-create'
    service_name = 'zato.outgoing.ftp.create'

class Edit(_CreateEdit):
    url_name = 'out-ftp-edit'
    form_prefix = 'edit-'
    service_name = 'zato.outgoing.ftp.edit'

class Delete(_Delete):
    url_name = 'out-ftp-delete'
    error_message = 'Could not delete the outgoing FTP connection'
    service_name = 'zato.outgoing.ftp.delete'

@method_allowed('POST')
def change_password(req):
    return _change_password(req, 'zato.outgoing.ftp.change-password')

########NEW FILE########
__FILENAME__ = jms_wmq
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from traceback import format_exc

# Django
from django.http import HttpResponse, HttpResponseServerError
from django.template.response import TemplateResponse

# anyjson
from anyjson import dumps

# Zato
from zato.admin.settings import delivery_friendly_name
from zato.admin.web.forms.outgoing.jms_wmq import CreateForm, EditForm
from zato.admin.web.views import Delete as _Delete, get_definition_list, method_allowed
from zato.common.odb.model import OutgoingWMQ

logger = logging.getLogger(__name__)
        
def _get_edit_create_message(params, prefix=''):
    """ Creates a base dictionary which can be used by both 'edit' and 'create' actions.
    """
    return {
        'id': params.get('id'),
        'cluster_id': params['cluster_id'],
        'name': params[prefix + 'name'],
        'is_active': bool(params.get(prefix + 'is_active')),
        'def_id': params[prefix + 'def_id'],
        'delivery_mode': params[prefix + 'delivery_mode'],
        'priority': params[prefix + 'priority'],
        'expiration': params.get(prefix + 'expiration'),
    }

def _edit_create_response(client, verb, id, name, delivery_mode_text, cluster_id, def_id):
    response = client.invoke('zato.definition.jms-wmq.get-by-id', {'id':def_id, 'cluster_id':cluster_id})    
    return_data = {'id': id,
                   'message': 'Successfully {0} the outgoing JMS WebSphere MQ connection [{1}]'.format(verb, name),
                   'delivery_mode_text': delivery_mode_text,
                   'def_name': response.data.name
                }
    
    return HttpResponse(dumps(return_data), mimetype='application/javascript')

@method_allowed('GET')
def index(req):
    items = []
    create_form = CreateForm()
    edit_form = EditForm(prefix='edit')

    if req.zato.cluster_id and req.method == 'GET':
        def_ids = get_definition_list(req.zato.client, req.zato.cluster, 'jms-wmq')
        create_form.set_def_id(def_ids)
        edit_form.set_def_id(def_ids)

        for item in req.zato.client.invoke('zato.outgoing.jms-wmq.get-list', {'cluster_id': req.zato.cluster_id}):
            _item = OutgoingWMQ(item.id, item.name, item.is_active, item.delivery_mode, 
                item.priority, item.expiration, item.def_id, delivery_friendly_name[item.delivery_mode], 
                item.def_name)
            items.append(_item)

    return_data = {'zato_clusters':req.zato.clusters,
        'cluster_id':req.zato.cluster_id,
        'choose_cluster_form':req.zato.choose_cluster_form,
        'items':items,
        'create_form':create_form,
        'edit_form':edit_form,
        }

    return TemplateResponse(req, 'zato/outgoing/jms_wmq.html', return_data)

@method_allowed('POST')
def create(req):
    try:
        response = req.zato.client.invoke('zato.outgoing.jms-wmq.create', _get_edit_create_message(req.POST))
        delivery_mode_text = delivery_friendly_name[int(req.POST['delivery_mode'])]

        return _edit_create_response(req.zato.client, 'created', response.data.id, 
            req.POST['name'], delivery_mode_text, req.POST['cluster_id'], req.POST['def_id'])
    except Exception, e:
        msg = 'Could not create an outgoing JMS WebSphere MQ connection, e:[{e}]'.format(e=format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)

    
@method_allowed('POST')
def edit(req):
    try:
        request = _get_edit_create_message(req.POST, 'edit-')
        req.zato.client.invoke('zato.outgoing.jms-wmq.edit', request)
        delivery_mode_text = delivery_friendly_name[int(req.POST['edit-delivery_mode'])]

        return _edit_create_response(req.zato.client, 'updated', req.POST['id'], req.POST['edit-name'],
            delivery_mode_text, req.POST['cluster_id'], req.POST['edit-def_id'])
        
    except Exception, e:
        msg = 'Could not update the outgoing JMS WebSphere MQ connection, e:[{e}]'.format(e=format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)
    
   
class Delete(_Delete):
    url_name = 'out-jms-wmq-delete'
    error_message = 'Could not delete the outgoing JMS WebSphere MQ connection'
    service_name = 'zato.outgoing.jms-wmq.delete'

########NEW FILE########
__FILENAME__ = sql
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

# stdlib
import logging
from traceback import format_exc

# Django
from django.http import HttpResponse, HttpResponseServerError
from django.template.response import TemplateResponse

# anyjson
from anyjson import dumps

# Zato
from zato.admin.settings import engine_friendly_name
from zato.admin.web.views import change_password as _change_password
from zato.admin.web.forms import ChangePasswordForm
from zato.admin.web.forms.outgoing.sql import CreateForm, EditForm
from zato.admin.web.views import Delete as _Delete, method_allowed
from zato.common.odb.model import SQLConnectionPool

logger = logging.getLogger(__name__)

def _get_edit_create_message(params, prefix=''):
    """ Creates a base dictionary which can be used by both 'edit' and 'create' actions.
    """
    return {
        'id': params.get('id'),
        'cluster_id': params['cluster_id'],
        'name': params[prefix + 'name'],
        'is_active': bool(params.get(prefix + 'is_active')),
        'engine': params[prefix + 'engine'],
        'host': params[prefix + 'host'],
        'port': params[prefix + 'port'],
        'db_name': params[prefix + 'db_name'],
        'username': params[prefix + 'username'],
        'pool_size': params[prefix + 'pool_size'],
        'extra': params.get(prefix + 'extra'),
    }

def _edit_create_response(verb, id, name, engine, cluster_id):
    """ A common function for producing return data for create and edit actions.
    """
    return_data = {'id': id,
                   'message': 'Successfully {0} the outgoing SQL connection [{1}]'.format(verb, name.encode('utf-8')),
                   'engine_text': engine_friendly_name[engine],
                   'cluster_id': cluster_id,
                }

    return HttpResponse(dumps(return_data), mimetype='application/javascript')

@method_allowed('GET')
def index(req):
    """ Lists all the SQL connections.
    """
    items = []
    create_form = CreateForm()
    edit_form = EditForm(prefix='edit')
    change_password_form = ChangePasswordForm()

    if req.zato.cluster_id and req.method == 'GET':
        for item in req.zato.client.invoke('zato.outgoing.sql.get-list', {'cluster_id': req.zato.cluster_id}):

            _item = SQLConnectionPool()
            
            for name in('id', 'name', 'is_active', 'engine', 'host', 'port', 'db_name', 'username', 'pool_size'):
                value = getattr(item, name)
                setattr(_item, name, value)
            
            _item.extra = item.extra or ''
            _item.engine_text = engine_friendly_name[_item.engine]
            items.append(_item)

    return_data = {'zato_clusters':req.zato.clusters,
        'cluster_id':req.zato.cluster_id,
        'choose_cluster_form':req.zato.choose_cluster_form,
        'items':items,
        'create_form':create_form,
        'edit_form':edit_form,
        'change_password_form': change_password_form
        }

    return TemplateResponse(req, 'zato/outgoing/sql.html', return_data)

@method_allowed('POST')
def create(req):
    """ Creates a new SQL connection.
    """
    try:
        request = _get_edit_create_message(req.POST)
        engine = request['engine']
        response = req.zato.client.invoke('zato.outgoing.sql.create', request)

        return _edit_create_response('created', response.data.id, req.POST['name'], engine, req.zato.cluster.id)

    except Exception, e:
        msg = 'Could not create an outgoing SQL connection, e:[{e}]'.format(e=format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)


@method_allowed('POST')
def edit(req):
    """ Updates an SQL connection.
    """
    try:
        request = _get_edit_create_message(req.POST, 'edit-')
        engine = request['engine']
        req.zato.client.invoke('zato.outgoing.sql.edit', request)

        return _edit_create_response('updated', req.POST['id'], req.POST['edit-name'], engine, req.zato.cluster.id)

    except Exception, e:
        msg = 'Could not update the outgoing SQL connection, e:[{e}]'.format(e=format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)

class Delete(_Delete):
    url_name = 'out-sql-delete'
    error_message = 'Could not delete the SQL connection'
    service_name = 'zato.outgoing.sql.delete'

@method_allowed('POST')
def ping(req, cluster_id, id):
    """ Pings a database and returns the time it took, in milliseconds.
    """
    response = req.zato.client.invoke('zato.outgoing.sql.ping', {'id':id})
    
    if response.ok:
        return TemplateResponse(req, 'zato/outgoing/sql-ping-ok.html', 
            {'response_time':'%.3f' % float(response.data.response_time)})
    else:
        return HttpResponseServerError(response.details)

@method_allowed('POST')
def change_password(req):
    return _change_password(req, 'zato.outgoing.sql.change-password')

########NEW FILE########
__FILENAME__ = zmq
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging

# Zato
from zato.admin.web.forms.outgoing.zmq import CreateForm, EditForm
from zato.admin.web.views import CreateEdit, Delete as _Delete, Index as _Index
from zato.common.odb.model import OutgoingZMQ

logger = logging.getLogger(__name__)

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'out-zmq'
    template = 'zato/outgoing/zmq.html'
    service_name = 'zato.outgoing.zmq.get-list'
    output_class = OutgoingZMQ
    
    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'address', 'socket_type')
        output_repeated = True
    
    def handle(self):
        return {
            'create_form': CreateForm(),
            'edit_form': EditForm(prefix='edit'),
        }

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('name', 'is_active', 'address', 'socket_type')
        output_required = ('id',)
        
    def success_message(self, item):
        return 'Successfully {0} the outgoing Zero MQ connection [{1}]'.format(self.verb, item.name)

class Create(_CreateEdit):
    url_name = 'out-zmq-create'
    service_name = 'zato.outgoing.zmq.create'

class Edit(_CreateEdit):
    url_name = 'out-zmq-edit'
    form_prefix = 'edit-'
    service_name = 'zato.outgoing.zmq.edit'

class Delete(_Delete):
    url_name = 'out-zmq-delete'
    error_message = 'Could not delete the outgoing Zero MQ connection'
    service_name = 'zato.outgoing.zmq.delete'

########NEW FILE########
__FILENAME__ = definition
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from traceback import format_exc

# anyjson
from anyjson import dumps

# Django
from django.http import HttpResponse, HttpResponseServerError

# Zato
from zato.admin.web import from_utc_to_user, from_user_to_utc, TARGET_TYPE_HUMAN
from zato.admin.web.forms.pattern.delivery.definition import CreateForm, DeliveryTargetForm, EditForm, InstanceListForm
from zato.admin.web.views import CreateEdit, Delete as _Delete, Index as _Index, get_js_dt_format, method_allowed
from zato.common.model import DeliveryItem

logger = logging.getLogger(__name__)

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'pattern-delivery'
    template = 'zato/pattern/delivery/definition/index.html'
    service_name = 'zato.pattern.delivery.definition.get-list'
    output_class = DeliveryItem
    
    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id', 'target_type')
        output_required = ('id', 'name', 'callback_list', 'last_updated_utc', 'last_used_utc', 'target', 'target_type', 
            'expire_after', 'expire_arch_succ_after', 'expire_arch_fail_after', 'check_after', 
            'retry_repeats', 'retry_seconds', 'short_def', 'total_count', 
            'in_progress_count', 'in_doubt_count', 'confirmed_count', 'failed_count')
        output_repeated = True
        
    def on_before_append_item(self, item):
        if getattr(item, 'callback_list', None):
            item.callback_list = '\n'.join(item.callback_list.split(','))
            
        for name_utc in('last_updated_utc', 'last_used_utc'):
            value = getattr(item, name_utc, None)
            if value:
                name = name_utc.replace('_utc', '')
                setattr(item, name, from_utc_to_user(value + '+00:00', self.req.zato.user_profile))
            
        return item
        
    def handle(self):
        target_type = self.req.GET.get('target_type')
        return {
            'delivery_target_form': DeliveryTargetForm(self.req.GET),
            'create_form': CreateForm(),
            'edit_form': EditForm(prefix='edit'),
            'target_type': target_type,
            'target_type_human': TARGET_TYPE_HUMAN[target_type] if target_type else '',
        }

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ['name', 'target', 'target_type', 'expire_after',
            'expire_arch_succ_after', 'expire_arch_fail_after', 'check_after', 
            'retry_repeats', 'retry_seconds', 'callback_list']
        output_required = ['id', 'name', 'target', 'short_def']
        
    def __call__(self, req, initial_input_dict={}, initial_return_data={}, *args, **kwargs):
        self.set_input(req)
        initial_input_dict['callback_list'] = ','.join(elem for elem in (self.input.get('callback_list', None) or '').split())
        initial_return_data['name'] = self.input.name
        initial_return_data['target'] = self.input.target
        initial_return_data['short_def'] = '{}-{}-{}'.format(
            self.input.check_after, self.input.retry_repeats, self.input.retry_seconds)
        
        return super(_CreateEdit, self).__call__(req, initial_input_dict, initial_return_data, args, kwargs)
        
class Create(_CreateEdit):
    url_name = 'pattern-delivery-create'
    service_name = 'zato.pattern.delivery.definition.create'
    
    def success_message(self, item):
        return 'Definition [{}] created successfully'.format(item.name)
    
class Edit(_CreateEdit):
    url_name = 'pattern-delivery-edit'
    form_prefix = 'edit-'
    service_name = 'zato.pattern.delivery.definition.edit'
    
    def success_message(self, item):
        return 'Definition [{}] updated successfully'.format(item.name)

class Delete(_Delete):
    url_name = 'pattern-delivery-delete'
    error_message = 'Could not delete delivery'
    service_name = 'zato.pattern.delivery.definition.delete'

########NEW FILE########
__FILENAME__ = consumers
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from json import dumps
from traceback import format_exc

# Django
from django.core.urlresolvers import reverse
from django.http import HttpResponse, HttpResponseRedirect, HttpResponseServerError
from django.template.response import TemplateResponse

# Zato
from zato.admin.web import from_utc_to_user
from zato.admin.web.forms.pubsub.consumers import CreateForm, EditForm
from zato.admin.web.views import CreateEdit, Delete as _Delete, Index as _Index, method_allowed
from zato.common import PUB_SUB
from zato.common.odb.model import PubSubConsumer

logger = logging.getLogger(__name__)

# ################################################################################################################################

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'pubsub-consumers'
    template = 'zato/pubsub/consumers/index.html'
    service_name = 'zato.pubsub.consumers.get-list'
    output_class = PubSubConsumer

    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id', 'topic_name')
        output_required = ('id', 'name', 'is_active', 'last_seen', 'max_backlog', 'current_depth', 'sub_key', 'delivery_mode')
        output_optional = ('callback_id',)
        output_repeated = True

    def handle(self):
        if self.req.zato.cluster_id:
            client_ids = self.req.zato.client.invoke('zato.security.get-list', {'cluster_id': self.req.zato.cluster.id}).data

            callback_ids = self.req.zato.client.invoke(
                'zato.http-soap.get-list', {
                    'cluster_id': self.req.zato.cluster.id, 'connection':'outgoing', 'transport':'plain_http'
                }).data
        else:
            client_ids = None
            callback_ids = None

        create_form = CreateForm(client_ids=client_ids, callback_ids=callback_ids)
        edit_form = EditForm(prefix='edit', callback_ids=callback_ids)

        return {
            'create_form': create_form,
            'edit_form': edit_form,
            'DEFAULT_MAX_BACKLOG': PUB_SUB.DEFAULT_MAX_BACKLOG
        }

    def _handle_item_list(self, item_list):
        super(Index, self)._handle_item_list(item_list)
        for item in self.items:
            item.callback_id = item.callback_id or ''
            if item.last_seen:
                item.last_seen = from_utc_to_user(item.last_seen + '+00:00', self.req.zato.user_profile)

# ################################################################################################################################

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('id', 'cluster_id', 'client_id', 'is_active', 'topic_name', 'max_backlog', 'delivery_mode')
        input_optional = ('callback_id',)
        output_required = ('id', 'name', 'last_seen', 'current_depth', 'sub_key')

    def success_message(self, item):
        # 'message' is implemented in post_process_return_data so that we know the name of the consumer
        pass

    def post_process_return_data(self, return_data):
        is_active = False
        for name in('is_active', 'edit-is_active'):
            if name in self.req.POST:
                is_active = True
                break

        return_data['is_active'] = is_active
        return_data['topic_name'] = self.req.POST['topic_name']
        return_data['message'] = 'Successfully {} consumer `{}`'.format(self.verb, return_data['name'])

        return_data['last_seen'] = None
        return_data['current_depth'] = 0

        client_id = self.req.POST.get('id')
        if client_id:
            response = self.req.zato.client.invoke('zato.pubsub.consumers.get-info', {'id': client_id})

            if response.ok:
                return_data['current_depth'] = response.data.current_depth
                return_data['sub_key'] = response.data.sub_key
                if response.data.last_seen:
                    return_data['last_seen'] = from_utc_to_user(response.data.last_seen + '+00:00', self.req.zato.user_profile)

        return return_data

# ################################################################################################################################

class Create(_CreateEdit):
    url_name = 'pubsub-consumers-create'
    service_name = 'zato.pubsub.consumers.create'

    def post_process_return_data(self, return_data):
        return_data['last_seen'] = None
        return super(Create, self).post_process_return_data(return_data)

# ################################################################################################################################

class Edit(_CreateEdit):
    url_name = 'pubsub-consumers-edit'
    form_prefix = 'edit-'
    service_name = 'zato.pubsub.consumers.edit'

# ################################################################################################################################

class Delete(_Delete):
    url_name = 'pubsub-consumers-delete'
    error_message = 'Could not delete the consumer'
    service_name = 'zato.pubsub.consumers.delete'

# ################################################################################################################################

########NEW FILE########
__FILENAME__ = message
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from json import dumps, loads
from traceback import format_exc

# Django
from django.http import HttpResponse, HttpResponseServerError
from django.template.response import TemplateResponse

# lxml
from lxml import etree

# Paste
from paste.util.converters import asbool

# Pygments
from pygments import highlight
from pygments.lexers.web import JSONLexer
from pygments.lexers import MakoXmlLexer, PythonLexer
from pygments.formatters import HtmlFormatter

# Zato
from zato.admin.web import from_utc_to_user, last_hour_start_stop
from zato.admin.web.views import method_allowed
from zato.common import PUB_SUB
from zato.common.pubsub import Message

data_format_lexer = {
    'json': JSONLexer,
    'xml': MakoXmlLexer
}

def known_data_format(data):
    data_format = None
    try:
        etree.fromstring(data)
        data_format = 'xml'
    except etree.XMLSyntaxError:
        try:
            loads(data)
            data_format = 'json'
        except ValueError:
            pass

    return data_format

# ################################################################################################################################

def _index(req, cluster_id, topic_name, source_name, source_type):
    items = []
    input_dict = {
        'cluster_id': cluster_id,
        'source_name':source_name,
        'source_type': source_type
    }
    
    for _item in req.zato.client.invoke('zato.pubsub.message.get-list', input_dict):
        _item = Message(**_item)
        _item.creation_time = from_utc_to_user(_item.creation_time_utc+'+00:00', req.zato.user_profile)
        _item.expire_at = from_utc_to_user(_item.expire_at_utc+'+00:00', req.zato.user_profile)
        _item.id = _item.msg_id
        items.append(_item)

    return_data = {
        'topic_name': topic_name,
        'cluster_id': req.zato.cluster_id,
        'items': items,
        'source_type': source_type,
        'source_name': source_name
        }
        
    return TemplateResponse(req, 'zato/pubsub/message/index.html', return_data)

# ################################################################################################################################

@method_allowed('GET')
def index_topic(req, cluster_id, topic_name):
    return _index(req, cluster_id, topic_name, topic_name, PUB_SUB.MESSAGE_SOURCE.TOPIC.id)

# ################################################################################################################################

@method_allowed('GET')
def index_consumer_queue(req, cluster_id, sub_key, topic_name):
    return _index(req, cluster_id, topic_name, sub_key, PUB_SUB.MESSAGE_SOURCE.CONSUMER_QUEUE.id)

# ################################################################################################################################

@method_allowed('GET')
def details(req, source_type, cluster_id, msg_id, topic_name):

    item = None
    pretty_print = asbool(req.GET.get('pretty_print'))

    input_dict = {
        'cluster_id': cluster_id,
        'msg_id': msg_id,
    }
    response = req.zato.client.invoke('zato.pubsub.message.get', input_dict)

    if response.has_data:
        item = Message()
        for name in('topic', 'producer', 'priority', 'mime_type', 'expiration', 'creation_time_utc', 'expire_at_utc', 'payload'):
            setattr(item, name, getattr(response.data, name, None))

        item.creation_time = from_utc_to_user(item.creation_time_utc+'+00:00', req.zato.user_profile)
        item.expire_at = from_utc_to_user(item.expire_at_utc+'+00:00', req.zato.user_profile)

    return_data = {
        'cluster_id': req.zato.cluster_id,
        'item': item,
        'pretty_print': not pretty_print,
        'msg_id': msg_id,
        'topic_name': topic_name,
        'source_type': source_type,
        'sub_key': req.GET.get('sub_key')
        }

    return TemplateResponse(req, 'zato/pubsub/message/details.html', return_data)

# ################################################################################################################################

@method_allowed('POST')
def delete(req):
    try:
        response = req.zato.client.invoke('zato.pubsub.message.delete', {
            'cluster_id': req.zato.cluster_id,
            'msg_id': req.POST['id'],
            'source_name': req.POST['source_name'],
            'source_type': req.POST['source_type'],
        })
        if response.ok:
            return HttpResponse(dumps(''), mimetype='application/javascript')
        else:
            raise Exception(response.details)
    except Exception, e:
        return HttpResponseServerError(format_exc(e))

# ################################################################################################################################

########NEW FILE########
__FILENAME__ = producers
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from json import dumps
from traceback import format_exc

# Django
from django.core.urlresolvers import reverse
from django.http import HttpResponse, HttpResponseRedirect, HttpResponseServerError
from django.template.response import TemplateResponse

# Zato
from zato.admin.web import from_utc_to_user
from zato.admin.web.forms.pubsub.producers import CreateForm, EditForm
from zato.admin.web.views import CreateEdit, Delete as _Delete, Index as _Index, method_allowed
from zato.common import PUB_SUB
from zato.common.odb.model import PubSubProducer

logger = logging.getLogger(__name__)

# ################################################################################################################################

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'pubsub-producers'
    template = 'zato/pubsub/producers/index.html'
    service_name = 'zato.pubsub.producers.get-list'
    output_class = PubSubProducer

    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id', 'topic_name')
        output_required = ('id', 'name', 'is_active', 'last_seen')
        output_repeated = True

    def handle(self):
        create_form = CreateForm()
        edit_form = EditForm(prefix='edit')

        if self.req.zato.cluster_id:
            client_ids = self.req.zato.client.invoke('zato.security.get-list', {'cluster_id': self.req.zato.cluster.id})
            create_form.set_client_id(client_ids.data)

        return {
            'create_form': create_form,
            'edit_form': edit_form
        }

    def _handle_item_list(self, item_list):
        super(Index, self)._handle_item_list(item_list)
        for item in self.items:
            if item.last_seen:
                item.last_seen = from_utc_to_user(item.last_seen + '+00:00', self.req.zato.user_profile)

# ################################################################################################################################

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('id', 'cluster_id', 'client_id', 'is_active', 'topic_name')
        output_required = ('id', 'name', 'last_seen')

    def success_message(self, item):
        # 'message' is implemented in post_process_return_data so that we know the name of the producer
        pass

    def post_process_return_data(self, return_data):
        is_active = False
        for name in('is_active', 'edit-is_active'):
            if name in self.req.POST:
                is_active = True
                break

        return_data['is_active'] = is_active
        return_data['topic_name'] = self.req.POST['topic_name']
        return_data['message'] = 'Successfully {} producer `{}`'.format(self.verb, return_data['name'])

        return_data['last_seen'] = None

        client_id = self.req.POST.get('id')
        if client_id:
            response = self.req.zato.client.invoke('zato.pubsub.producers.get-info', {'id': client_id})
    
            if response.ok:
                if response.data.last_seen:
                    return_data['last_seen'] = from_utc_to_user(response.data.last_seen + '+00:00', self.req.zato.user_profile)

        return return_data

# ################################################################################################################################

class Create(_CreateEdit):
    url_name = 'pubsub-producers-create'
    service_name = 'zato.pubsub.producers.create'

    def post_process_return_data(self, return_data):
        return_data['last_seen'] = None
        return super(Create, self).post_process_return_data(return_data)

# ################################################################################################################################

class Edit(_CreateEdit):
    url_name = 'pubsub-producers-edit'
    form_prefix = 'edit-'
    service_name = 'zato.pubsub.producers.edit'

# ################################################################################################################################

class Delete(_Delete):
    url_name = 'pubsub-producers-delete'
    error_message = 'Could not delete the producer'
    service_name = 'zato.pubsub.producers.delete'

# ################################################################################################################################

########NEW FILE########
__FILENAME__ = topics
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from json import dumps
from traceback import format_exc

# Django
from django.core.urlresolvers import reverse
from django.http import HttpResponse, HttpResponseRedirect, HttpResponseServerError
from django.template.response import TemplateResponse

# Zato
from zato.admin.web import from_utc_to_user
from zato.admin.web.forms.pubsub.topics import CreateForm, EditForm
from zato.admin.web.views import CreateEdit, Delete as _Delete, Index as _Index, method_allowed
from zato.common import PUB_SUB
from zato.common.odb.model import PubSubTopic

logger = logging.getLogger(__name__)

# ################################################################################################################################

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'pubsub-topics'
    template = 'zato/pubsub/topics/index.html'
    service_name = 'zato.pubsub.topics.get-list'
    output_class = PubSubTopic

    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'current_depth',\
            'max_depth', 'consumers_count', 'producers_count', 'last_pub_time')
        output_repeated = True

    def handle(self):
        return {
            'default_max_depth': PUB_SUB.DEFAULT_MAX_DEPTH,
            'create_form': CreateForm(),
            'edit_form': EditForm(prefix='edit'),
        }

    def _handle_item_list(self, item_list):
        super(Index, self)._handle_item_list(item_list)
        for item in self.items:
            if item.last_pub_time:
                item.last_pub_time = from_utc_to_user(item.last_pub_time + '+00:00', self.req.zato.user_profile)

# ################################################################################################################################

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('cluster_id', 'is_active', 'max_depth')
        input_optional = ('name',)
        output_required = ('id', 'name')

    def __call__(self, req, initial_input_dict={}, initial_return_data={}, *args, **kwargs):

        edit_name = req.POST.get('edit-name')
        name = req.POST.get('name', edit_name)

        initial_return_data = {
            'current_depth': 0,
            'consumers_count': 0,
            'producers_count': 0,
            'last_pub_time': None,
            'cluster_id': req.zato.cluster_id,
            'name': name,
        }

        if edit_name:
            response = req.zato.client.invoke('zato.pubsub.topics.get-info', {
                'cluster_id': req.zato.cluster_id,
                'name': edit_name
            })

            if response.ok:
                initial_return_data.update(response.data)
                initial_return_data['last_pub_time'] = from_utc_to_user(
                    initial_return_data['last_pub_time'] + '+00:00', req.zato.user_profile)

        return super(_CreateEdit, self).__call__(
            req, initial_input_dict={}, initial_return_data=initial_return_data, *args, **kwargs)

    def success_message(self, item):
        return 'Successfully {0} the topic [{1}]'.format(self.verb, item.name)

# ################################################################################################################################

class Create(_CreateEdit):
    url_name = 'pubsub-topics-create'
    service_name = 'zato.pubsub.topics.create'

# ################################################################################################################################

class Edit(_CreateEdit):
    url_name = 'pubsub-topics-edit'
    form_prefix = 'edit-'
    service_name = 'zato.pubsub.topics.edit'

# ################################################################################################################################

class Delete(_Delete):
    url_name = 'pubsub-topics-delete'
    error_message = 'Could not delete the topic'
    service_name = 'zato.pubsub.topics.delete'

# ################################################################################################################################

@method_allowed('GET')
def publish(req, cluster_id, topic):

    return_data = {
        'cluster_id': cluster_id,
        'topic': topic,
        'default_mime_type': PUB_SUB.DEFAULT_MIME_TYPE,
        'default_priority': PUB_SUB.DEFAULT_PRIORITY,
        'default_expiration': int(PUB_SUB.DEFAULT_EXPIRATION),
    }

    return TemplateResponse(req, 'zato/pubsub/topics/publish.html', return_data)

# ################################################################################################################################

@method_allowed('POST')
def publish_action(req, cluster_id, topic):

    try:
        request = {'cluster_id': req.zato.cluster_id}
        request.update({k:v for k, v in req.POST.items() if k and v})
        response = req.zato.client.invoke('zato.pubsub.topics.publish', request)

        if response.ok:
            msg = 'Published message `{}` to topic `{}`'.format(response.data.msg_id, req.POST['name'])
            return HttpResponse(dumps({'msg': msg}), mimetype='application/javascript')
        else:
            raise Exception(response.details)
    except Exception, e:
        msg = 'Caught an exception, e:`{}`'.format(format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)

########NEW FILE########
__FILENAME__ = pubsub
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging

# Zato
from zato.admin.web.forms import ChangePasswordForm
from zato.admin.web.forms.security.basic_auth import CreateForm, EditForm
from zato.admin.web.views import change_password as _change_password, CreateEdit, Delete as _Delete, Index as _Index, method_allowed
from zato.common.odb.model import HTTPBasicAuth

logger = logging.getLogger(__name__)

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'security-basic-auth'
    template = 'zato/security/basic-auth.html'
    service_name = 'zato.security.basic-auth.get-list'
    output_class = HTTPBasicAuth
    
    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'username', 'realm')
        output_repeated = True

    def handle(self):
        return {
            'create_form': CreateForm(),
            'edit_form': EditForm(prefix='edit'),
            'change_password_form': ChangePasswordForm()
        }

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('name', 'is_active', 'username', 'realm')
        output_required = ('id', 'name')
        
    def success_message(self, item):
        return 'Successfully {0} the HTTP Basic Auth definition [{1}]'.format(self.verb, item.name)

class Create(_CreateEdit):
    url_name = 'security-basic-auth-create'
    service_name = 'zato.security.basic-auth.create'

class Edit(_CreateEdit):
    url_name = 'security-basic-auth-edit'
    form_prefix = 'edit-'
    service_name = 'zato.security.basic-auth.edit'

class Delete(_Delete):
    url_name = 'security-basic-auth-delete'
    error_message = 'Could not delete the HTTP Basic Auth definition'
    service_name = 'zato.security.basic-auth.delete'
    
@method_allowed('POST')
def change_password(req):
    return _change_password(req, 'zato.security.basic-auth.change-password')

########NEW FILE########
__FILENAME__ = scheduler
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

""" Views related to the management of server's scheduler jobs.
"""

# stdlib
import logging
from cStringIO import StringIO
from datetime import datetime
from traceback import format_exc

# anyjson
from anyjson import dumps

# dateutil
from dateutil.parser import parse

# Django
from django.http import HttpResponse, HttpResponseServerError
from django.template.response import TemplateResponse

# pytz
from pytz import UTC

# Zato
from zato.admin.web import from_user_to_utc, from_utc_to_user
from zato.admin.web.views import get_js_dt_format, get_sample_dt, method_allowed, Delete as _Delete
from zato.admin.settings import job_type_friendly_names
from zato.admin.web.forms.scheduler import CronStyleSchedulerJobForm, \
     IntervalBasedSchedulerJobForm, OneTimeSchedulerJobForm
from zato.common import SCHEDULER_JOB_TYPE, TRACE1, ZatoException
from zato.common.odb.model import CronStyleJob, IntervalBasedJob, Job
from zato.common.util import pprint

logger = logging.getLogger(__name__)

create_one_time_prefix = 'create-one_time'
create_interval_based_prefix = 'create-interval_based'
create_cron_style_prefix = 'create-cron_style'
edit_one_time_prefix = 'edit-one_time'
edit_interval_based_prefix = 'edit-interval_based'
edit_cron_style_prefix = 'edit-cron_style'

def _get_start_date(start_date):
    if not start_date:
        return ''
        
    if not isinstance(start_date, datetime):
        start_date = parse(start_date)

    return start_date.replace(tzinfo=UTC)

def _one_time_job_def(user_profile, start_date):
    start_date = _get_start_date(start_date)
    return 'Execute once on {0} at {1}'.format(
        from_utc_to_user(start_date, user_profile, 'date'),
        from_utc_to_user(start_date, user_profile, 'time'))

def _interval_based_job_def(user_profile, start_date, repeats, weeks, days, hours, minutes, seconds):

    buf = StringIO()

    if start_date:
        buf.write('Start on {0} at {1}.'.format(
            from_utc_to_user(start_date, user_profile, 'date'),
            from_utc_to_user(start_date, user_profile, 'time')))

    if not repeats:
        buf.write(' Repeat indefinitely.')
    else:
        if repeats == 1:
            buf.write(' Execute once.')
        elif repeats == 2:
            buf.write(' Repeat twice.')
        # .. my hand is itching to add 'repeats thrice.' here ;-)
        elif repeats > 2:
            buf.write(' Repeat ')
            buf.write(str(repeats))
            buf.write(' times.')

    interval = []
    buf.write(' Interval: ')
    for name, value in (('week',weeks), ('day',days),
                    ('hour',hours), ('minute',minutes),
                    ('second',seconds)):
        if value:
            value = int(value)
            interval.append('{0} {1}{2}'.format(value, name, 's' if value > 1 else ''))

    buf.write(', '.join(interval))
    buf.write('.')

    return buf.getvalue()

def _get_success_message(action, job_type, job_name):

    msg = 'Successfully {0} the {1} job [{2}]'
    verb = 'created' if action == 'create' else 'updated'
    job_type = job_type.replace('_', '-')
    
    return msg.format(verb, job_type, job_name)
        

def _cron_style_job_def(user_profile, start_date, cron_definition):
    start_date = _get_start_date(start_date)

    buf = StringIO()
    buf.write('Start on {0} at {1}.'.format(
        from_utc_to_user(start_date, user_profile, 'date'),
        from_utc_to_user(start_date, user_profile, 'time')))
    buf.write('<br/>{0}'.format(cron_definition))
    
    return buf.getvalue()

def _get_create_edit_message(user_profile, cluster, params, form_prefix=""):
    """ A dictionary of core data which can be used by both 'edit' and 'create'
    actions, regardless of the job's type.
    """
    start_date = params.get(form_prefix + 'start_date', '')
    if start_date:
        start_date = from_user_to_utc(start_date, user_profile)

    return {
        'name': params[form_prefix + 'name'],
        'cluster_id': cluster.id,
        'id': params.get(form_prefix + 'id', ''),
        'is_active': bool(params.get(form_prefix + 'is_active')),
        'service': params.get(form_prefix + 'service', ''),
        'extra': params.get(form_prefix + 'extra', ''),
        'start_date': start_date.isoformat(),
    }
    
def _get_create_edit_one_time_message(user_profile, cluster, params, form_prefix=''):
    """ Creates a base document which can be used by both 'edit' and 'create'
    actions. Used when creating one_time jobs.
    """
    input_dict = _get_create_edit_message(user_profile, cluster, params, form_prefix)
    input_dict['job_type'] = SCHEDULER_JOB_TYPE.ONE_TIME

    return input_dict

def _get_create_edit_interval_based_message(user_profile, cluster, params, form_prefix=''):
    """ A dictionary of core data which can be used by both 'edit' and 'create'
    actions. Used when creating interval_based jobs.
    """
    input_dict =_get_create_edit_message(user_profile, cluster, params, form_prefix)
    input_dict['job_type'] = SCHEDULER_JOB_TYPE.INTERVAL_BASED
    input_dict['weeks'] = params.get(form_prefix + 'weeks', '')
    input_dict['days'] = params.get(form_prefix + 'days', '')
    input_dict['hours'] = params.get(form_prefix + 'hours', '')
    input_dict['seconds'] = params.get(form_prefix + 'seconds', '')
    input_dict['minutes'] = params.get(form_prefix + 'minutes', '')
    input_dict['repeats'] = params.get(form_prefix + 'repeats', '')

    return input_dict

def _get_create_edit_cron_style_message(user_profile, cluster, params, form_prefix=''):
    """ A dictionary of core data which can be used by both 'edit' and 'create'
    actions. Used when creating cron_style jobs.
    """
    input_dict =_get_create_edit_message(user_profile, cluster, params, form_prefix)
    input_dict['job_type'] = SCHEDULER_JOB_TYPE.CRON_STYLE
    input_dict['cron_definition'] = params[form_prefix + 'cron_definition']

    return input_dict

def _create_one_time(client, user_profile, cluster, params):
    """ Creates a one_time scheduler job.
    """
    logger.debug('About to create a one_time job, cluster.id:[{0}], params:[{1}]'.format(cluster.id, params))
    
    input_dict = _get_create_edit_one_time_message(user_profile, cluster, params, create_one_time_prefix+'-')
    response = client.invoke('zato.scheduler.job.create', input_dict)
    
    logger.debug('Successfully created a one_time job, cluster.id:[{0}], params:[{1}]'.format(cluster.id, params))

    return {'id': response.data.id, 'definition_text':_one_time_job_def(user_profile, input_dict['start_date'])}

def _create_interval_based(client, user_profile, cluster, params):
    """ Creates an interval_based scheduler job.
    """
    logger.debug('About to create an interval_based job, cluster.id:[{0}], params:[{1}]'.format(cluster.id, params))
    
    input_dict = _get_create_edit_interval_based_message(user_profile, cluster, params, create_interval_based_prefix+'-')
    response = client.invoke('zato.scheduler.job.create', input_dict)
    logger.debug('Successfully created an interval_based job, cluster.id:[{0}], params:[{1}]'.format(cluster.id, params))

    start_date = input_dict.get('start_date')
    if start_date:
        start_date = _get_start_date(start_date)
    repeats = params.get('create-interval_based-repeats')
    weeks = params.get('create-interval_based-weeks')
    days = params.get('create-interval_based-days')
    hours = params.get('create-interval_based-hours')
    minutes = params.get('create-interval_based-minutes')
    seconds = params.get('create-interval_based-seconds')

    definition = _interval_based_job_def(user_profile, start_date, repeats, weeks, days, hours, minutes, seconds)

    return {'id': response.data.id, 'definition_text':definition}

def _create_cron_style(client, user_profile, cluster, params):
    """ Creates a cron_style scheduler job.
    """
    logger.debug('About to create a cron_style job, cluster.id:[{0}], params:[{1}]'.format(cluster.id, params))

    input_dict = _get_create_edit_cron_style_message(user_profile, cluster, params, create_cron_style_prefix+'-')
    response = client.invoke('zato.scheduler.job.create', input_dict)
    cron_definition = response.data.cron_definition
    logger.debug('Successfully created a cron_style job, cluster.id:[{0}], params:[{1}]'.format(cluster.id, params))

    return {'id': response.data.id, 
            'definition_text':_cron_style_job_def(user_profile,
                input_dict['start_date'], cron_definition),
            'cron_definition': cron_definition}

def _edit_one_time(client, user_profile, cluster, params):
    """ Updates a one_time scheduler job.
    """
    logger.debug('About to change a one_time job, cluster.id:[{0}, params:[{1}]]'.format(cluster.id, params))

    input_dict = _get_create_edit_one_time_message(user_profile, cluster, params, edit_one_time_prefix+'-')
    client.invoke('zato.scheduler.job.edit', input_dict)
    logger.debug('Successfully updated a one_time job, cluster.id:[{0}], params:[{1}]'.format(cluster.id, params))

    return {'definition_text':_one_time_job_def(user_profile, input_dict['start_date']), 'id':params['edit-one_time-id']}

def _edit_interval_based(client, user_profile, cluster, params):
    """ Creates an interval_based scheduler job.
    """
    logger.debug('About to change an interval_based job, cluster.id:[{0}, params:[{1}]]'.format(cluster.id, params))

    input_dict = _get_create_edit_interval_based_message(user_profile, cluster, params, edit_interval_based_prefix+'-')
    client.invoke('zato.scheduler.job.edit', input_dict)
    logger.debug('Successfully updated an interval_based job, cluster.id:[{0}], params:[{1}]'.format(cluster.id, params))

    start_date = input_dict.get('start_date')
    if start_date:
        start_date = _get_start_date(start_date)
    repeats = params.get('edit-interval_based-repeats')
    weeks = params.get('edit-interval_based-weeks')
    days = params.get('edit-interval_based-days')
    hours = params.get('edit-interval_based-hours')
    minutes = params.get('edit-interval_based-minutes')
    seconds = params.get('edit-interval_based-seconds')

    definition = _interval_based_job_def(user_profile, start_date, repeats, weeks, days, hours, minutes, seconds)

    return {'definition_text':definition, 'id':params['edit-interval_based-id']}

def _edit_cron_style(client, user_profile, cluster, params):
    """ Creates an cron_style scheduler job.
    """
    logger.debug('About to change a cron_style job, cluster.id:[{0}, params:[{1}]]'.format(cluster.id, params))

    input_dict = _get_create_edit_cron_style_message(user_profile, cluster, params, edit_cron_style_prefix+'-')
    response = client.invoke('zato.scheduler.job.edit', input_dict)
    cron_definition = response.data.cron_definition
    logger.debug('Successfully updated a cron_style job, cluster.id:[{0}], params:[{1}]'.format(cluster.id, params))

    start_date = _get_start_date(input_dict.get('start_date'))
    definition = _cron_style_job_def(user_profile, start_date, cron_definition)

    return {'definition_text':definition, 'cron_definition': cron_definition, 'id':params['edit-cron_style-id']}

@method_allowed('GET', 'POST')
def index(req):
    try:
        jobs = []
        
        # Build a list of schedulers for a given Zato cluster.
        if req.zato.cluster_id and req.method == 'GET':
    
            # We have a server to pick the schedulers from, try to invoke it now.
            response = req.zato.client.invoke('zato.scheduler.job.get-list', {'cluster_id': req.zato.cluster_id})
            
            if response.has_data:
                for job_elem in response.data:
                    
                    id = job_elem.id
                    name = job_elem.name
                    is_active = job_elem.is_active
                    job_type = job_elem.job_type
                    start_date = job_elem.start_date
                    service_name = job_elem.service_name
                    extra = job_elem.extra
                    job_type_friendly = job_type_friendly_names[job_type]
                    
                    job = Job(id, name, is_active, job_type, 
                              from_utc_to_user(start_date+'+00:00', req.zato.user_profile),
                              extra, service_name=service_name, 
                              job_type_friendly=job_type_friendly)
                    
                    if job_type == SCHEDULER_JOB_TYPE.ONE_TIME:
                        definition_text=_one_time_job_def(req.zato.user_profile, start_date)
                        
                    elif job_type == SCHEDULER_JOB_TYPE.INTERVAL_BASED:
                        definition_text = _interval_based_job_def(req.zato.user_profile,
                            _get_start_date(job_elem.start_date),
                            job_elem.repeats, job_elem.weeks, job_elem.days,
                            job_elem.hours, job_elem.minutes, job_elem.seconds)
                        
                        weeks = job_elem.weeks or ''
                        days = job_elem.days or ''
                        hours = job_elem.hours or ''
                        minutes = job_elem.minutes or ''
                        seconds = job_elem.seconds or ''
                        repeats = job_elem.repeats or ''
                        
                        ib_job = IntervalBasedJob(None, None, weeks, days, hours, minutes,
                                            seconds, repeats)
                        job.interval_based = ib_job
                        
                    elif job_type == SCHEDULER_JOB_TYPE.CRON_STYLE:
                        cron_definition = job_elem.cron_definition or ''
                        definition_text=_cron_style_job_def(req.zato.user_profile, start_date, cron_definition)
                        
                        cs_job = CronStyleJob(None, None, cron_definition)
                        job.cron_style = cs_job
                        
                    else:
                        msg = 'Unrecognized job type, name:[{0}], type:[{1}]'.format(name, job_type)
                        logger.error(msg)
                        raise ZatoException(msg)
    
                    job.definition_text = definition_text
                    jobs.append(job)
            else:
                logger.info('No jobs found, response:[{}]'.format(response))
    
        if req.method == 'POST':

            action = req.POST.get('zato_action', '')
            if not action:
                msg = 'req.POST contains no [zato_action] parameter.'
                logger.error(msg)
                return HttpResponseServerError(msg)
    
            job_type = req.POST.get('job_type', '')
            if action != 'execute' and not job_type:
                msg = 'req.POST contains no [job_type] parameter.'
                logger.error(msg)
                return HttpResponseServerError(msg)
    
            job_name = req.POST['{0}-{1}-name'.format(action, job_type)]
    
            # Try to match the action and a job type with an action handler..
            handler_name = '_' + action
            if action != 'execute':
                handler_name += '_' + job_type
    
            handler = globals().get(handler_name)
            if not handler:
                msg = ('No handler found for action [{0}], job_type:[{1}], '
                       'req.POST:[{2}], req.GET:[{3}].'.format(action, job_type,
                          pprint(req.POST), pprint(req.GET)))
    
                logger.error(msg)
                return HttpResponseServerError(msg)
    
            # .. invoke the action handler.
            try:
                response = handler(req.zato.client, req.zato.user_profile, req.zato.cluster, req.POST)
                response = response if response else ''
                if response:
                    response['message'] = _get_success_message(action, job_type, job_name)
                    response = dumps(response)
                return HttpResponse(response, mimetype='application/javascript')
            except Exception, e:
                msg = ('Could not invoke action [%s], job_type:[%s], e:[%s]'
                       'req.POST:[%s], req.GET:[%s]') % (action, job_type,
                          format_exc(), pprint(req.POST), pprint(req.GET))
    
                logger.error(msg)
                return HttpResponseServerError(msg)

        return_data = {'zato_clusters':req.zato.clusters,
            'cluster_id':req.zato.cluster_id,
            'choose_cluster_form':req.zato.choose_cluster_form,
            'jobs':jobs, 
            'friendly_names':job_type_friendly_names.items(),
            'create_one_time_form':OneTimeSchedulerJobForm(prefix=create_one_time_prefix),
            'create_interval_based_form':IntervalBasedSchedulerJobForm(prefix=create_interval_based_prefix),
            'create_cron_style_form':CronStyleSchedulerJobForm(prefix=create_cron_style_prefix),
            'edit_one_time_form':OneTimeSchedulerJobForm(prefix=edit_one_time_prefix),
            'edit_interval_based_form':IntervalBasedSchedulerJobForm(prefix=edit_interval_based_prefix),
            'edit_cron_style_form':CronStyleSchedulerJobForm(prefix=edit_cron_style_prefix),
            'sample_dt': get_sample_dt(req.zato.user_profile),
            }
        
        return_data.update(get_js_dt_format(req.zato.user_profile))

        return TemplateResponse(req, 'zato/scheduler.html', return_data)
    except Exception, e:
        msg = '<pre>Could not invoke the method, e:[{0}]</pre>'.format(format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)


class Delete(_Delete):
    url_name = 'scheduler-job-delete'
    error_message = 'Could not delete the job'
    service_name = 'zato.scheduler.job.delete'
    
@method_allowed('POST')
def execute(req, job_id, cluster_id):
    """ Executes a scheduler's job.
    """
    try:
        req.zato.client.invoke('zato.scheduler.job.execute', {'id':job_id})
    except Exception, e:
        msg = 'Could not execute the job. job_id:[{0}], cluster_id:[{1}], e:[{2}]'.format(job_id, cluster_id, format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)
    else:
        # 200 OK
        return HttpResponse()

@method_allowed('POST')
def get_definition(req, start_date, repeats, weeks, days, hours, minutes, seconds):
    start_date = _get_start_date(start_date)

    definition = _interval_based_job_def(start_date, repeats, weeks, days, hours, minutes, seconds)
    logger.log(TRACE1, 'definition:[{}]'.format(definition))

    return HttpResponse(definition)

########NEW FILE########
__FILENAME__ = apikey
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging

# Zato
from zato.admin.web.forms import ChangePasswordForm
from zato.admin.web.forms.security.apikey import CreateForm, EditForm
from zato.admin.web.views import change_password as _change_password, CreateEdit, Delete as _Delete, Index as _Index, method_allowed
from zato.common.odb.model import APIKeySecurity

logger = logging.getLogger(__name__)

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'security-apikey'
    template = 'zato/security/apikey.html'
    service_name = 'zato.security.apikey.get-list'
    output_class = APIKeySecurity
    
    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'username')
        output_repeated = True

    def handle(self):
        return {
            'create_form': CreateForm(),
            'edit_form': EditForm(prefix='edit'),
            'change_password_form': ChangePasswordForm()
        }

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('name', 'is_active', 'username')
        output_required = ('id', 'name')
        
    def success_message(self, item):
        return 'Successfully {0} the API key [{1}]'.format(self.verb, item.name)

class Create(_CreateEdit):
    url_name = 'security-apikey-create'
    service_name = 'zato.security.apikey.create'

class Edit(_CreateEdit):
    url_name = 'security-apikey-edit'
    form_prefix = 'edit-'
    service_name = 'zato.security.apikey.edit'

class Delete(_Delete):
    url_name = 'security-apikey-delete'
    error_message = 'Could not delete the API key'
    service_name = 'zato.security.apikey.delete'
    
@method_allowed('POST')
def change_password(req):
    return _change_password(req, 'zato.security.apikey.change-password', success_msg='API key updated')

########NEW FILE########
__FILENAME__ = aws
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging

# Zato
from zato.admin.web.forms import ChangePasswordForm
from zato.admin.web.forms.security.aws import CreateForm, EditForm
from zato.admin.web.views import change_password as _change_password, CreateEdit, Delete as _Delete, Index as _Index, method_allowed
from zato.common.odb.model import AWSSecurity

logger = logging.getLogger(__name__)

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'security-aws'
    template = 'zato/security/aws.html'
    service_name = 'zato.security.aws.get-list'
    output_class = AWSSecurity
    
    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'username')
        output_repeated = True

    def handle(self):
        return {
            'create_form': CreateForm(),
            'edit_form': EditForm(prefix='edit'),
            'change_password_form': ChangePasswordForm()
        }

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('name', 'is_active', 'username')
        output_required = ('id', 'name')
        
    def success_message(self, item):
        return 'Successfully {0} the AWS definition [{1}]'.format(self.verb, item.name)

class Create(_CreateEdit):
    url_name = 'security-aws-create'
    service_name = 'zato.security.aws.create'

class Edit(_CreateEdit):
    url_name = 'security-aws-edit'
    form_prefix = 'edit-'
    service_name = 'zato.security.aws.edit'

class Delete(_Delete):
    url_name = 'security-aws-delete'
    error_message = 'Could not delete the aws definition'
    service_name = 'zato.security.aws.delete'
    
@method_allowed('POST')
def change_password(req):
    return _change_password(req, 'zato.security.aws.change-password', success_msg='Access key updated')

########NEW FILE########
__FILENAME__ = basic_auth
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging

# Zato
from zato.admin.web.forms import ChangePasswordForm
from zato.admin.web.forms.security.basic_auth import CreateForm, EditForm
from zato.admin.web.views import change_password as _change_password, CreateEdit, Delete as _Delete, Index as _Index, method_allowed
from zato.common.odb.model import HTTPBasicAuth

logger = logging.getLogger(__name__)

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'security-basic-auth'
    template = 'zato/security/basic-auth.html'
    service_name = 'zato.security.basic-auth.get-list'
    output_class = HTTPBasicAuth
    
    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'username', 'realm')
        output_repeated = True

    def handle(self):
        return {
            'create_form': CreateForm(),
            'edit_form': EditForm(prefix='edit'),
            'change_password_form': ChangePasswordForm()
        }

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('name', 'is_active', 'username', 'realm')
        output_required = ('id', 'name')
        
    def success_message(self, item):
        return 'Successfully {0} the HTTP Basic Auth definition [{1}]'.format(self.verb, item.name)

class Create(_CreateEdit):
    url_name = 'security-basic-auth-create'
    service_name = 'zato.security.basic-auth.create'

class Edit(_CreateEdit):
    url_name = 'security-basic-auth-edit'
    form_prefix = 'edit-'
    service_name = 'zato.security.basic-auth.edit'

class Delete(_Delete):
    url_name = 'security-basic-auth-delete'
    error_message = 'Could not delete the HTTP Basic Auth definition'
    service_name = 'zato.security.basic-auth.delete'
    
@method_allowed('POST')
def change_password(req):
    return _change_password(req, 'zato.security.basic-auth.change-password')

########NEW FILE########
__FILENAME__ = ntlm
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging

# Zato
from zato.admin.web.forms import ChangePasswordForm
from zato.admin.web.forms.security.ntlm import CreateForm, EditForm
from zato.admin.web.views import change_password as _change_password, CreateEdit, Delete as _Delete, Index as _Index, method_allowed
from zato.common.odb.model import NTLM

logger = logging.getLogger(__name__)

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'security-ntlm'
    template = 'zato/security/ntlm.html'
    service_name = 'zato.security.ntlm.get-list'
    output_class = NTLM
    
    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'username')
        output_repeated = True

    def handle(self):
        return {
            'create_form': CreateForm(),
            'edit_form': EditForm(prefix='edit'),
            'change_password_form': ChangePasswordForm()
        }

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('name', 'is_active', 'username')
        output_required = ('id', 'name')
        
    def success_message(self, item):
        return 'Successfully {0} the NTLM definition [{1}]'.format(self.verb, item.name)

class Create(_CreateEdit):
    url_name = 'security-ntlm-create'
    service_name = 'zato.security.ntlm.create'

class Edit(_CreateEdit):
    url_name = 'security-ntlm-edit'
    form_prefix = 'edit-'
    service_name = 'zato.security.ntlm.edit'

class Delete(_Delete):
    url_name = 'security-ntlm-delete'
    error_message = 'Could not delete the NTLM definition'
    service_name = 'zato.security.ntlm.delete'
    
@method_allowed('POST')
def change_password(req):
    return _change_password(req, 'zato.security.ntlm.change-password')

########NEW FILE########
__FILENAME__ = oauth
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging

# Zato
from zato.admin.web.forms import ChangePasswordForm
from zato.admin.web.forms.security.oauth import CreateForm, EditForm
from zato.admin.web.views import change_password as _change_password, \
     CreateEdit, Delete as _Delete, Index as _Index, method_allowed
from zato.common import NONCE_STORE
from zato.common.odb.model import OAuth

logger = logging.getLogger(__name__)

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'security-oauth'
    template = 'zato/security/oauth.html'
    service_name = 'zato.security.oauth.get-list'
    output_class = OAuth
    
    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'username', \
            'proto_version', 'sig_method', 'max_nonce_log')
        output_repeated = True

    def handle(self):
        return {
            'create_form': CreateForm(),
            'edit_form': EditForm(prefix='edit'),
            'change_password_form': ChangePasswordForm(),
            'default_max_nonce_log': NONCE_STORE.DEFAULT_MAX_LOG,
        }

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('name', 'is_active', 'username', \
            'proto_version', 'sig_method', 'max_nonce_log')
        output_required = ('id', 'name')
        
    def success_message(self, item):
        return 'Successfully {0} the OAuth definition [{1}]'.format(self.verb, item.name)

class Create(_CreateEdit):
    url_name = 'security-oauth-create'
    service_name = 'zato.security.oauth.create'

class Edit(_CreateEdit):
    url_name = 'security-oauth-edit'
    form_prefix = 'edit-'
    service_name = 'zato.security.oauth.edit'

class Delete(_Delete):
    url_name = 'security-oauth-delete'
    error_message = 'Could not delete the OAuth definition'
    service_name = 'zato.security.oauth.delete'
    
@method_allowed('POST')
def change_secret(req):
    return _change_password(req, 'zato.security.oauth.change-password')

########NEW FILE########
__FILENAME__ = openstack
# -*- coding: utf-8 -*-

"""
Copyright (C) 2013 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging

# Zato
from zato.admin.web.forms import ChangePasswordForm
from zato.admin.web.forms.security.openstack import CreateForm, EditForm
from zato.admin.web.views import change_password as _change_password, CreateEdit, Delete as _Delete, Index as _Index, method_allowed
from zato.common.odb.model import OpenStackSecurity

logger = logging.getLogger(__name__)

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'security-openstack'
    template = 'zato/security/openstack.html'
    service_name = 'zato.security.openstack.get-list'
    output_class = OpenStackSecurity
    
    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'username')
        output_repeated = True

    def handle(self):
        return {
            'create_form': CreateForm(),
            'edit_form': EditForm(prefix='edit'),
            'change_password_form': ChangePasswordForm()
        }

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('name', 'is_active', 'username')
        output_required = ('id', 'name')
        
    def success_message(self, item):
        return 'Successfully {0} the OpenStack definition [{1}]'.format(self.verb, item.name)

class Create(_CreateEdit):
    url_name = 'security-openstack-create'
    service_name = 'zato.security.openstack.create'

class Edit(_CreateEdit):
    url_name = 'security-openstack-edit'
    form_prefix = 'edit-'
    service_name = 'zato.security.openstack.edit'

class Delete(_Delete):
    url_name = 'security-openstack-delete'
    error_message = 'Could not delete the OpenStack definition'
    service_name = 'zato.security.openstack.delete'
    
@method_allowed('POST')
def change_password(req):
    return _change_password(req, 'zato.security.openstack.change-password')

########NEW FILE########
__FILENAME__ = tech_account
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from traceback import format_exc

# Django
from django.http import HttpResponse, HttpResponseServerError

# Zato
from zato.admin.web.forms import ChangePasswordForm
from zato.admin.web.forms.security.tech_account import CreateForm, EditForm
from zato.admin.web.views import change_password as _change_password, CreateEdit, Index as _Index, method_allowed
from zato.common.odb.model import TechnicalAccount

logger = logging.getLogger(__name__)
    
@method_allowed('POST')
def change_password(req):
    return _change_password(req, 'zato.security.tech-account.change-password')
    
    
@method_allowed('GET')
def get_by_id(req, id_, cluster_id):
    try:
        response = req.zato.client.invoke('zato.security.tech-account.get-by-id', {'id':id_})
    except Exception, e:
        msg = 'Could not fetch the technical account, e:[{e}]'.format(e=format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)
    else:
        tech_account = TechnicalAccount()
        tech_account.id = response.data.id
        tech_account.name = response.data.name
        tech_account.is_active = response.data.is_active

        return HttpResponse(tech_account.to_json(), mimetype='application/javascript')
    
class Index(_Index):
    method_allowed = 'GET'
    url_name = 'security-tech-account'
    template = 'zato/security/tech-account.html'
    
    service_name = 'zato.security.tech-account.get-list'
    output_class = TechnicalAccount
    
    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active')
        output_repeated = True

    def handle(self):
        return {
            'create_form': CreateForm(),
            'edit_form': EditForm(prefix='edit'),
            'change_password_form': ChangePasswordForm()
        }

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('name', 'is_active')
        output_required = ('id', 'name')
        
    def success_message(self, item):
        return 'Successfully {0} the technical account [{1}]'.format(self.verb, item.name)

class Create(_CreateEdit):
    url_name = 'security-tech-account-create'
    service_name = 'zato.security.tech-account.create'

class Edit(_CreateEdit):
    url_name = 'security-tech-account-edit'
    form_prefix = 'edit-'
    service_name = 'zato.security.tech-account.edit'

@method_allowed('POST')
def delete(req, id, cluster_id):
    try:
        req.zato.client.invoke('zato.security.tech-account.delete', {'id': id})
    except Exception, e:
        msg = 'Could not delete the technical account, e:[{e}]'.format(e=format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)
    else:
        return HttpResponse()

########NEW FILE########
__FILENAME__ = wss
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from json import dumps
from traceback import format_exc

# Django
from django.http import HttpResponse, HttpResponseServerError
from django.template.response import TemplateResponse

# Zato
from zato.admin.web.forms import ChangePasswordForm
from zato.admin.web.forms.security.wss import CreateForm, EditForm
from zato.admin.web.views import change_password as _change_password, Delete as _Delete, method_allowed
from zato.common import ZATO_WSS_PASSWORD_TYPES
from zato.common.odb.model import WSSDefinition

logger = logging.getLogger(__name__)

def _edit_create_response(service_response, action, name, password_type):
    return_data = {'id': service_response.data.id,
        'message': 'Successfully {0} the WS-Security definition [{1}]'.format(action, name),
        'password_type_raw':password_type,
        'password_type':ZATO_WSS_PASSWORD_TYPES[password_type]}
    
    return HttpResponse(dumps(return_data), mimetype='application/javascript')

def _get_edit_create_message(params, prefix=''):
    """ Creates a base dictionary which can be used by both 'edit' and 'create' actions.
    """
    return {
        'id': params.get('id'),
        'cluster_id': params['cluster_id'],
        'name': params[prefix + 'name'],
        'is_active': bool(params.get(prefix + 'is_active')),
        'username': params[prefix + 'username'],
        'password_type': 'clear_text',
        'reject_empty_nonce_creat': bool(params.get(prefix + 'reject_empty_nonce_creat')),
        'reject_stale_tokens': bool(params.get(prefix + 'reject_stale_tokens')),
        'reject_expiry_limit': params[prefix + 'reject_expiry_limit'],
        'nonce_freshness_time': params[prefix + 'nonce_freshness_time'],
    }

@method_allowed('GET')
def index(req):
    items = []
    create_form = CreateForm()
    edit_form = EditForm(prefix='edit')
    change_password_form = ChangePasswordForm()

    if req.zato.cluster_id and req.method == 'GET':

        for item in req.zato.client.invoke('zato.security.wss.get-list', {'cluster_id':req.zato.cluster_id}):
            wss = WSSDefinition(item.id, item.name, item.is_active, item.username, None,
                    ZATO_WSS_PASSWORD_TYPES[item.password_type], item.reject_empty_nonce_creat, 
                    item.reject_stale_tokens, item.reject_expiry_limit, item.nonce_freshness_time, 
                    password_type_raw=item.password_type)

            items.append(wss)

    return_data = {'zato_clusters':req.zato.clusters,
        'cluster_id':req.zato.cluster_id,
        'choose_cluster_form':req.zato.choose_cluster_form,
        'items':items,
        'create_form': create_form,
        'edit_form': edit_form,
        'change_password_form': change_password_form
        }

    return TemplateResponse(req, 'zato/security/wss.html', return_data)

@method_allowed('POST')
def edit(req):
    """ Updates WS-S definitions's parameters (everything except for the password).
    """
    try:
        response = req.zato.client.invoke('zato.security.wss.edit', _get_edit_create_message(req.POST, prefix='edit-'))
        return _edit_create_response(response, 'updated', req.POST['edit-name'], req.POST['edit-password_type'])
    except Exception, e:
        msg = 'Could not update the WS-Security definition, e:[{e}]'.format(e=format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)

@method_allowed('POST')
def create(req):
    try:
        response = req.zato.client.invoke('zato.security.wss.create', _get_edit_create_message(req.POST))
        return _edit_create_response(response, 'created', req.POST['name'], req.POST['password_type'])
    except Exception, e:
        msg = "Could not create a WS-Security definition, e:[{e}]".format(e=format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)
    
class Delete(_Delete):
    url_name = 'security-wss-delete'
    error_message = 'Could not delete the WS-Security definition'
    service_name = 'zato.security.wss.delete'

@method_allowed('POST')
def change_password(req):
    return _change_password(req, 'zato.security.wss.change-password')

########NEW FILE########
__FILENAME__ = xpath
# -*- coding: utf-8 -*-

"""
Copyright (C) 2014 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging

# Zato
from zato.admin.web.forms import ChangePasswordForm
from zato.admin.web.forms.security.xpath import CreateForm, EditForm
from zato.admin.web.views import change_password as _change_password, CreateEdit, Delete as _Delete, Index as _Index, method_allowed
from zato.common.odb.model import XPathSecurity

logger = logging.getLogger(__name__)

class Index(_Index):
    method_allowed = 'GET'
    url_name = 'security-xpath'
    template = 'zato/security/xpath.html'
    service_name = 'zato.security.xpath.get-list'
    output_class = XPathSecurity
    
    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        output_required = ('id', 'name', 'is_active', 'username', 'username_expr')
        output_optional = ('password_expr',)
        output_repeated = True

    def handle(self):
        return {
            'create_form': CreateForm(),
            'edit_form': EditForm(prefix='edit'),
            'change_password_form': ChangePasswordForm()
        }

class _CreateEdit(CreateEdit):
    method_allowed = 'POST'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('name', 'is_active', 'username', 'username_expr')
        input_optional = ('password_expr',)
        output_required = ('id', 'name')
        
    def success_message(self, item):
        return 'Successfully {0} the XPath security definition [{1}]'.format(self.verb, item.name)

class Create(_CreateEdit):
    url_name = 'security-xpath-create'
    service_name = 'zato.security.xpath.create'

class Edit(_CreateEdit):
    url_name = 'security-xpath-edit'
    form_prefix = 'edit-'
    service_name = 'zato.security.xpath.edit'

class Delete(_Delete):
    url_name = 'security-xpath-delete'
    error_message = 'Could not delete the XPath security definition'
    service_name = 'zato.security.xpath.delete'
    
@method_allowed('POST')
def change_password(req):
    return _change_password(req, 'zato.security.xpath.change-password', success_msg='XPath security definition updated')

########NEW FILE########
__FILENAME__ = service
# -*- coding: utf-8 -*-

"""
Copyright (C) 2011 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
import json as stdlib_json
from collections import namedtuple
from datetime import datetime
from traceback import format_exc

# anyjson
from anyjson import dumps, loads

# dateutil
from dateutil.relativedelta import relativedelta

# Django
from django.core.urlresolvers import reverse
from django.http import HttpResponse, HttpResponseRedirect, HttpResponseServerError
from django.template.response import TemplateResponse

# lxml
from lxml import etree

# Paste
from paste.util.converters import asbool

# Pygments
from pygments import highlight
from pygments.lexers.web import JSONLexer
from pygments.lexers import MakoXmlLexer, PythonLexer
from pygments.formatters import HtmlFormatter

# validate
from validate import is_boolean

# Zato
from zato.admin.web import from_utc_to_user, last_hour_start_stop
from zato.admin.web.forms.service import CreateForm, EditForm
from zato.admin.web.views import CreateEdit, Delete as _Delete, Index as _Index, method_allowed
from zato.common import DATA_FORMAT, SourceInfo, ZATO_NONE
from zato.common.odb.model import Service

logger = logging.getLogger(__name__)

ExposedThrough = namedtuple('ExposedThrough', ['id', 'name', 'url'])
DeploymentInfo = namedtuple('DeploymentInfo', ['server_name', 'details'])

class SlowResponse(object):
    def __init__(self, cid=None, service_name=None, threshold=None, req_ts=None, 
            resp_ts=None, proc_time=None, req=None, resp=None, req_html=None, resp_html=None):
        self.cid = cid
        self.service_name = service_name
        self.threshold = threshold
        self.req_ts = req_ts
        self.resp_ts = resp_ts
        self.proc_time = proc_time
        self.req = req
        self.resp = resp
        self.req_html = req_html 
        self.resp_html = resp_html

data_format_lexer = {
    'json': JSONLexer,
    'xml': MakoXmlLexer
}

def known_data_format(data):
    data_format = None
    try:
        etree.fromstring(data)
        data_format = 'xml'
    except etree.XMLSyntaxError:
        try:
            loads(data)
            data_format = 'json'
        except ValueError:
            pass

    return data_format

def get_public_wsdl_url(cluster, service_name):
    """ Returns an address under which a service's WSDL is publically available.
    """
    return 'http://{}:{}/zato/wsdl?service={}&cluster_id={}'.format(cluster.lb_host, 
        cluster.lb_port, service_name, cluster.id)

def _get_channels(client, cluster, id, channel_type):
    """ Returns a list of channels of a given type for the given service.
    """
    input_dict = {
        'id': id,
        'channel_type': channel_type
    }
    out = []

    for item in client.invoke('zato.service.get-channel-list', input_dict):

        if channel_type in('plain_http', 'soap'):
            url = reverse('http-soap')
            url += '?connection=channel&transport={}'.format(channel_type)
            url += '&cluster={}'.format(cluster.id)
        else:
            url = reverse('channel-' + channel_type)
            url += '?cluster={}'.format(cluster.id)

        url += '&highlight={}'.format(item.id)

        channel = ExposedThrough(item.id, item.name, url)
        out.append(channel)

    return out
    
def _get_service(req, name):
    """ Returns service details by its name.
    """
    service = Service(name=name)
    
    input_dict = {
        'name': name,
        'cluster_id': req.zato.cluster_id
    }
    response = req.zato.client.invoke('zato.service.get-by-name', input_dict)
    
    if response.has_data:
        for name in('id', 'slow_threshold'):
            setattr(service, name, getattr(response.data, name))
        
    return service
    
def get_pretty_print(value, data_format):
    if data_format == 'xml':
        parser = etree.XMLParser(remove_blank_text=True)
        tree = etree.fromstring(value, parser)
        return etree.tostring(tree, pretty_print=True, xml_declaration=True, encoding='UTF-8')
    else:
        value = loads(value)
        return stdlib_json.dumps(value, sort_keys=True, indent=2)

class Index(_Index):
    """ A view for listing the services along with their basic statistics.
    """
    method_allowed = 'GET'
    url_name = 'service'
    template = 'zato/service/index.html'
    service_name = 'zato.service.get-list'
    output_class = Service

    class SimpleIO(_Index.SimpleIO):
        input_required = ('cluster_id',)
        input_optional = ('name_filter',)
        output_required = ('id', 'name', 'is_active', 'is_internal', 'impl_name', 
            'may_be_deleted', 'usage', 'slow_threshold')
        output_repeated = True

    def handle(self):
        return {
            'create_form': CreateForm(),
            'edit_form': EditForm(prefix='edit')
        }

@method_allowed('POST')
def create(req):
    pass

class Edit(CreateEdit):
    method_allowed = 'POST'
    url_name = 'service-edit'
    form_prefix = 'edit-'
    service_name = 'zato.service.edit'

    class SimpleIO(CreateEdit.SimpleIO):
        input_required = ('id', 'is_active', 'slow_threshold')
        output_required = ('id', 'name', 'impl_name', 'is_internal', 'usage', 'may_be_deleted')

    def success_message(self, item):
        return 'Successfully {0} the service [{1}]'.format(self.verb, item.name)

@method_allowed('GET')
def overview(req, service_name):
    cluster_id = req.GET.get('cluster')
    service = None

    create_form = CreateForm()
    edit_form = EditForm(prefix='edit')

    if cluster_id and req.method == 'GET':

        input_dict = {
            'name': service_name,
            'cluster_id': req.zato.cluster_id
        }
        
        response = req.zato.client.invoke('zato.service.get-by-name', input_dict)
        if response.has_data:
            service = Service()
            
            for name in('id', 'name', 'is_active', 'impl_name', 'is_internal', 
                  'usage', 'time_last', 'time_min_all_time', 'time_max_all_time', 
                  'time_mean_all_time'):

                value = getattr(response.data, name)
                if name in('is_active', 'is_internal'):
                    value = is_boolean(value)

                setattr(service, name, value)

            now = datetime.utcnow()
            start = now+relativedelta(minutes=-60)
                
            response = req.zato.client.invoke('zato.stats.get-by-service', {'service_id':service.id, 'start':start, 'stop':now})
            if response.has_data:
                for name in('mean_trend', 'usage_trend', 'min_resp_time', 'max_resp_time', 'mean', 'usage', 'rate'):
                    value = getattr(response.data, name)
                    if not value or value == ZATO_NONE:
                        value = ''

                    setattr(service, 'time_{}_1h'.format(name), value)

            for channel_type in('plain_http', 'soap', 'amqp', 'jms-wmq', 'zmq'):
                channels = _get_channels(req.zato.client, req.zato.cluster, service.id, channel_type)
                getattr(service, channel_type.replace('jms-', '') + '_channels').extend(channels)

            for item in req.zato.client.invoke('zato.service.get-deployment-info-list', {'id': service.id}):
                service.deployment_info.append(DeploymentInfo(item.server_name, loads(item.details)))
                
            # TODO: There needs to be a new service added zato.service.scheduler.job.get-by-service
            #       or .get-list should start accept a service name. Right now we pull all the
            #       jobs which is suboptimal.
            response = req.zato.client.invoke('zato.scheduler.job.get-list', {'cluster_id':cluster_id})
            if response.has_data:
                for item in response.data:
                    if item.service_name == service_name:
                        url = reverse('scheduler')
                        url += '?cluster={}'.format(cluster_id)
                        url += '&highlight={}'.format(item.id)
                        service.scheduler_jobs.append(ExposedThrough(item.id, item.name, url))

    return_data = {'zato_clusters':req.zato.clusters,
        'service': service,
        'cluster_id':cluster_id,
        'choose_cluster_form':req.zato.choose_cluster_form,
        'create_form':create_form,
        'edit_form':edit_form,
        }

    return TemplateResponse(req, 'zato/service/overview.html', return_data)

@method_allowed('GET')
def source_info(req, service_name):

    service = Service(name=service_name)
    input_dict = {
        'cluster_id': req.zato.cluster_id,
        'name': service_name
    }

    response = req.zato.client.invoke('zato.service.get-source-info', input_dict)

    if response.has_data:
        service.id = response.data.service_id

        source = response.data.source.decode('base64') if response.data.source else ''
        if source:
            source_html = highlight(source, PythonLexer(stripnl=False), HtmlFormatter(linenos='table'))

            service.source_info = SourceInfo()
            service.source_info.source = source
            service.source_info.source_html = source_html
            service.source_info.path = response.data.source_path
            service.source_info.hash = response.data.source_hash
            service.source_info.hash_method = response.data.source_hash_method
            service.source_info.server_name = response.data.server_name

    return_data = {
        'cluster_id':req.zato.cluster_id,
        'service':service,
        }

    return TemplateResponse(req, 'zato/service/source-info.html', return_data)

@method_allowed('GET')
def wsdl(req, service_name):
    service = Service(name=service_name)
    has_wsdl = False
    wsdl_public_url = get_public_wsdl_url(req.zato.cluster, service_name)

    input_dict = {
        'name': service_name,
        'cluster_id': req.zato.cluster_id
    }
    
    response = req.zato.client.invoke('zato.service.has-wsdl', input_dict)
    if response.has_data:
        service.id = response.data.service_id
        has_wsdl = response.data.has_wsdl

    return_data = {
        'cluster_id':req.zato.cluster_id,
        'service':service,
        'has_wsdl':has_wsdl,
        'wsdl_public_url':wsdl_public_url,
        }

    return TemplateResponse(req, 'zato/service/wsdl.html', return_data)

@method_allowed('POST')
def wsdl_upload(req, service_name, cluster_id):
    """ Handles a WSDL file upload.
    """
    try:
        input_dict = {
            'name': service_name,
            'cluster_id': cluster_id,
            'wsdl': req.read().encode('base64'),
            'wsdl_name': req.GET['qqfile']
        }
        req.zato.client.invoke('zato.service.set-wsdl', input_dict)

        return HttpResponse(dumps({'success': True}))

    except Exception, e:
        msg = 'Could not upload the WSDL, e:[{e}]'.format(e=format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)

@method_allowed('GET')
def wsdl_download(req, service_name, cluster_id):
    return HttpResponseRedirect(get_public_wsdl_url(req.zato.cluster, service_name))

@method_allowed('GET')
def request_response(req, service_name):
    service = Service(name=service_name)
    pretty_print = asbool(req.GET.get('pretty_print'))
    
    input_dict = {
        'name': service_name,
        'cluster_id': req.zato.cluster_id
    }
    
    service_response = req.zato.client.invoke('zato.service.get-request-response', input_dict)
    if service_response.ok:
        request = (service_response.data.sample_req if service_response.data.sample_req else '').decode('base64')
        request_data_format = known_data_format(request)
        if request_data_format:
            if pretty_print:
                request = get_pretty_print(request, request_data_format)
            service.sample_req_html = highlight(request, data_format_lexer[request_data_format](), 
                HtmlFormatter(linenos='table'))

        response = (service_response.data.sample_resp if service_response.data.sample_resp else '').decode('base64')
        response_data_format = known_data_format(response)
        if response_data_format:
            if pretty_print:
                response = get_pretty_print(response, response_data_format)
            service.sample_resp_html = highlight(response, data_format_lexer[response_data_format](), 
                HtmlFormatter(linenos='table'))

        service.sample_req = request
        service.sample_resp = response

        ts = {}
        for name in('req', 'resp'):
            full_name = 'sample_{}_ts'.format(name)
            value = getattr(service_response.data, full_name, '')
            if value:
                value = from_utc_to_user(value+'+00:00', req.zato.user_profile)
            ts[full_name] = value
                
        service.id = service_response.data.service_id
        service.sample_cid = service_response.data.sample_cid
        service.sample_req_ts = ts['sample_req_ts']
        service.sample_resp_ts = ts['sample_resp_ts']
        service.sample_req_resp_freq = service_response.data.sample_req_resp_freq

    return_data = {
        'cluster_id': req.zato.cluster_id,
        'service': service,
        'pretty_print': not pretty_print,
        }

    return TemplateResponse(req, 'zato/service/request-response.html', return_data)

@method_allowed('POST')
def request_response_configure(req, service_name, cluster_id):
    try:
        input_dict = {
            'name': service_name,
            'cluster_id': req.zato.cluster_id,
            'sample_req_resp_freq': req.POST['sample_req_resp_freq']
        }
        req.zato.client.invoke('zato.service.configure-request-response', input_dict)
        return HttpResponse('Saved successfully')

    except Exception, e:
        msg = 'Could not update the configuration, e:[{e}]'.format(e=format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)

class Delete(_Delete):
    url_name = 'service-delete'
    error_message = 'Could not delete the service'
    service_name = 'zato.service.delete'

@method_allowed('POST')
def package_upload(req, cluster_id):
    """ Handles a service package file upload.
    """
    try:
        input_dict = {
            'cluster_id': cluster_id,
            'payload': req.read().encode('base64'),
            'payload_name': req.GET['qqfile']
        }
        req.zato.client.invoke('zato.service.upload-package', input_dict)

        return HttpResponse(dumps({'success': True}))

    except Exception, e:
        msg = 'Could not upload the service package, e:[{e}]'.format(e=format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)
    
@method_allowed('POST')
def last_stats(req, service_id, cluster_id):
    
    return_data = {
        'rate': '(error)',
        'mean': '(error)',
        'mean_trend': '(error)',
        }
    
    try:
        start, stop = last_hour_start_stop(datetime.utcnow())
        response = req.zato.client.invoke('zato.stats.get-by-service', {'service_id': service_id, 'start':start, 'stop':stop})
        
        if response.has_data:
            for key in return_data:
                value = getattr(response.data, key) or ''
                
                if value and key.endswith('trend') and value != ZATO_NONE:
                    value = [int(float(elem)) for elem in value.split(',')]

                if value == '0.0':
                    value = '<0.1'

                return_data[key] = value if value != ZATO_NONE else '0'

    except Exception, e:
        msg = 'Caught an exception while invoking zato.service.get-by-service, e:[{}]'.format(format_exc(e))
        logger.error(msg)
    
    return HttpResponse(dumps(return_data), mimetype='application/javascript')


@method_allowed('GET')
def slow_response(req, service_name):

    items = []
    input_dict = {
        'name': service_name,
    }
    
    for _item in req.zato.client.invoke('zato.service.slow-response.get-list', input_dict):
        item = SlowResponse()
        item.cid = _item.cid
        item.req_ts = from_utc_to_user(_item.req_ts+'+00:00', req.zato.user_profile)
        item.resp_ts = from_utc_to_user(_item.resp_ts+'+00:00', req.zato.user_profile)
        item.proc_time = _item.proc_time
        item.service_name = service_name
        
        items.append(item)
        
    return_data = {
        'cluster_id': req.zato.cluster_id,
        'service': _get_service(req, service_name),
        'items': items,
        }
        
    return TemplateResponse(req, 'zato/service/slow-response.html', return_data)
    
@method_allowed('GET')
def slow_response_details(req, cid, service_name):

    item = None
    service = _get_service(req, service_name)
    pretty_print = asbool(req.GET.get('pretty_print'))
    
    input_dict = {
        'cid': cid,
        'name': service_name,
    }
    response = req.zato.client.invoke('zato.service.slow-response.get', input_dict)
    
    if response.has_data:
        cid = response.data.cid
        if cid != ZATO_NONE:
            item = SlowResponse()
            item.cid = response.data.cid
            item.req_ts = from_utc_to_user(response.data.req_ts+'+00:00', req.zato.user_profile)
            item.resp_ts = from_utc_to_user(response.data.resp_ts+'+00:00', req.zato.user_profile)
            item.proc_time = response.data.proc_time
            item.service_name = service_name
            item.threshold = service.slow_threshold
            
            for name in('req', 'resp'):
                value = getattr(response.data, name)
                if value:
                    #value = value.decode('base64')
                    if isinstance(value, dict):
                        value = dumps(value)
                        data_format = 'json'
                    else:
                        data_format = known_data_format(value)
                        
                    if data_format:
                        if pretty_print:
                            value = get_pretty_print(value, data_format)
                        attr_name = name + '_html'
                        setattr(item, attr_name, highlight(value, 
                             data_format_lexer[data_format](), HtmlFormatter(linenos='table')))

    return_data = {
        'cluster_id': req.zato.cluster_id,
        'service': service,
        'item': item,
        'pretty_print': not pretty_print,
        }
        
    return TemplateResponse(req, 'zato/service/slow-response-details.html', return_data)

@method_allowed('GET')
def invoker(req, service_name):

    return_data = {
        'cluster_id': req.zato.cluster_id,
        'service': _get_service(req, service_name),
        }

    return TemplateResponse(req, 'zato/service/invoker.html', return_data)

@method_allowed('POST')
def invoke(req, name, cluster_id):
    """ Executes a service directly, even if it isn't exposed through any channel.
    """
    try:
        input_dict = {}
        for attr in('payload', 'data_format', 'transport'):
            input_dict[attr] = req.POST.get(attr, '')
            input_dict['to_json'] = True if input_dict.get('data_format') == DATA_FORMAT.JSON else False
        
        response = req.zato.client.invoke(name, **input_dict)

    except Exception, e:
        msg = 'Could not invoke the service. name:[{}], cluster_id:[{}], e:[{}]'.format(
            name, cluster_id, format_exc(e))
        logger.error(msg)
        return HttpResponseServerError(msg)
    else:
        try:
            if response.ok:
                return HttpResponse(response.inner_service_response or '(None)')
            else:
                return HttpResponseServerError(response.details)
        except Exception, e:
            return HttpResponseServerError(format_exc(e))

########NEW FILE########
__FILENAME__ = stats
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import logging
from copy import deepcopy
from cStringIO import StringIO
from csv import DictWriter
from datetime import datetime

# anyjson
from anyjson import dumps

# Bunch
from bunch import Bunch

# dateutil
from dateutil.parser import parse
from dateutil.relativedelta import MO, relativedelta

# Django
from django.contrib import messages
from django.core.urlresolvers import reverse
from django.http import HttpResponse
from django.shortcuts import redirect
from django.template import loader
from django.template.response import TemplateResponse

# django-settings
from django_settings.models import PositiveInteger, Setting

# pytz
from pytz import timezone, utc

# Zato
from zato.admin.web import from_user_to_utc, from_utc_to_user
from zato.admin.web.forms.stats import MaintenanceForm, NForm, SettingsForm
from zato.admin.web.views import get_js_dt_format, get_sample_dt, method_allowed
from zato.common import DEFAULT_STATS_SETTINGS, StatsElem
from zato.common.util import from_local_to_utc, make_repr, now, utcnow

logger = logging.getLogger(__name__)

SUMMARY_PREFIX = 'summary-'

class JobAttrForm(object):
    def __init__(self, form_name, job_attr):
        self.form_name = form_name
        self.job_attr = job_attr

    def __repr__(self):
        return '<{} at {} form_name:[{}], job_attr:[{}]>'.format(self.__class__.__name__, hex(id(self)),
            self.form_name, repr(self.job_attr))

class JobAttrFormMapping(object):
    def __init__(self, job_name, attrs):
        self.job_name = job_name
        self.attrs = attrs

    def __repr__(self):
        return '<{} at {} job_name:[{}], attrs:[{}]>'.format(self.__class__.__name__, hex(id(self)),
            self.job_name, repr(self.attrs))

class DateInfo(object):
    def __init__(self, utc_start, utc_stop, user_start, user_stop, label=None, step=None):
        self.utc_start = utc_start
        self.utc_stop = utc_stop
        self.user_start = user_start
        self.user_stop = user_stop or ''
        self.label = label
        self.step = step

    def __repr__(self):
        return make_repr(self)
    
    def __getitem__(self, name):
        return object.__getattribute__(self, name)

# A mapping a job type, its name and the execution interval unit
job_mappings = {
    JobAttrFormMapping('zato.stats.process-raw-times', 
        [JobAttrForm('raw_times', 'seconds'), JobAttrForm('raw_times_batch', {'extra':'max_batch_size'})]),
    JobAttrFormMapping('zato.stats.aggregate-by-minute', [JobAttrForm('per_minute_aggr', 'seconds')]),
    }

compare_to = {
    'last_hour':[
        ('last_hour_prev_hour', 'hour'),
        ('last_hour_prev_hour_day', 'hour/day'),
        ('last_hour_prev_hour_day_week', 'hour/day/week'),
    ],
    'today': [
        ('today_prev_day', 'day'),
        ('today_prev_day_week', 'day/week'),
    ],
    'yesterday': [
        ('yesterday_prev_day', 'day'),
        ('yesterday_prev_day_week', 'day/week'),
    ],
    'this_week': [
        ('this_week_prev_week', 'week'),
        ('this_week_prev_week_month', 'week/month'),
    ],
    'this_month': [
        ('this_month_prev_month', 'month'),
        ('this_month_prev_month_year', 'month/year'),
    ],
    'this_year': [
        ('this_year_prev_year', 'year'),
    ],
}

start_delta_kwargs = {
    'last_hour_prev': {'hours':-1},
    'last_hour_next': {'hours':1},
    'last_hour_prev_hour': {'hours':-1},
    'last_hour_prev_hour_day': {'days':-1},
    'last_hour_prev_hour_day_week': {'weeks':-1},
    
    'today_prev': {'days':-1},
    'today_next': {'days':1},
    'today_prev_day': {'days':-1},
    'today_prev_day_week': {'weeks':-1},
    
    'yesterday_prev': {'days':-1},
    'yesterday_next': {'days':1},
    'yesterday_prev_day': {'days':-1},
    'yesterday_prev_day_week': {'weeks':-1},
    
    'this_week_prev': {'weeks':-1},
    'this_week_next': {'weeks':1},
    'this_week_prev_week': {'weeks':-1},
    'this_week_prev_week_month': {'months':-1},
    
    'this_month_prev': {'months':-1},
    'this_month_next': {'months':1},
    'this_month_prev_month': {'months':-1},
    'this_month_prev_month_year': {'years':-1},
    
    'this_year_prev': {'years':-1},
    'this_year_next': {'years':1},
    'this_year_prev_year': {'years':-1},
}

skip_by_duration = {
    'last_hour_prev': 'hour',
    'last_hour_next': 'hour',
    'last_hour_prev_hour': 'hour',
    'last_hour_prev_hour_day': 'hour',
    'last_hour_prev_hour_day_week': 'hour',
    
    'today_prev': 'day',
    'today_next': 'day',
    'today_prev_day': 'day',
    'today_prev_day_week': 'day',
    
    'yesterday_prev': 'day',
    'yesterday_next': 'day',
    'yesterday_prev_day': 'day',
    'yesterday_prev_day_week': 'day',
    
    'this_week_prev': 'week',
    'this_week_next': 'week',
    'this_week_prev_week': 'week',
    'this_week_prev_week_month': 'week',
    
    'this_month_prev': 'month',
    'this_month_next': 'month',
    'this_month_prev_month': 'month',
    'this_month_prev_month_year': 'month',
    
    'this_year_prev': 'year',
    'this_year_next': 'year',
    'this_year_prev_year': 'year',
}

stop_delta_kwargs = {
    'hour': {'hours':1},
    'day': {'days':1},
    'week': {'weeks':1},
    'month': {'months':1},
    'year': {'years':1},
}

user_format = {
    'hour': 'date_time',
    'day': 'date',
    'week': 'date',
    'month': 'month_year',
    'year': 'year',
}

def shift(utc_base_date, user_start, user_profile, shift_type, duration, format):
    """ Shifts the base date by the amount specified and returns resulting start
    and stop dates in UTC and user timezone.
    """
    if shift_type not in start_delta_kwargs:
        raise ValueError('Unknown shift_type:[{}]'.format(shift_type))
    
    _start_delta_kwargs = start_delta_kwargs[shift_type]

    # Special-case month duration because UTC '2012-09-30 22:00:00+00:00' (which is 2012-10-01 CEST)
    # minus one month happens to be '2012-08-30 22:00:00+00:00' instead of '2012-09-31 22:00:00+00:00'
    # so it's 2012-08-30 CEST instead of 2012-09-01. In other words, we would've jumped from Oct 2012 to Aug 2012 directly.
    
    if duration != 'month':
        utc_start = utc_base_date + relativedelta(**_start_delta_kwargs)
    else:
        user_start = datetime.strptime(user_start, user_profile.month_year_format_strptime)
        current_month_start = datetime(user_start.year, user_start.month, 1)
        prev_month_start = current_month_start + relativedelta(**_start_delta_kwargs)
        utc_start = from_local_to_utc(prev_month_start, user_profile.timezone)
    
    _stop_delta_kwargs = stop_delta_kwargs[duration]
    utc_stop = utc_start + relativedelta(**_stop_delta_kwargs)
    
    user_start = from_utc_to_user(utc_start, user_profile, format)
    user_stop = from_utc_to_user(utc_stop, user_profile, format)
    
    return DateInfo(utc_start.isoformat(), utc_stop.isoformat(), user_start, user_stop)

def get_default_date(date_type, user_profile, format):
    """ Returns default start and stop date in UTC and user's timezone depending
    on the stats type and duration requested.
    """
    def get_today(_user_profile, _format):
        """ user_start is today's midnight but it needs to be in user's TZ. user_stop is current time simply,
        in user's timezone again.
        """
        user_now = now(timezone(_user_profile.timezone)).replace(tzinfo=None)
        user_today_midnight = datetime(user_now.year, user_now.month, user_now.day)
        
        utc_start = from_local_to_utc(user_today_midnight, _user_profile.timezone)
        utc_stop = from_local_to_utc(user_now, _user_profile.timezone)
        
        user_start = from_utc_to_user(utc_start, _user_profile, _format)
        user_stop = None
        
        return utc_start, utc_stop, user_start, user_stop
    
    if date_type == 'last_hour':
        # stop is what current time is now so return it in UTC and user's TZ
        # along with start which will be equal to stop - 1 hour.
        utc_stop = utc.fromutc(utcnow())
        utc_start = utc.fromutc(utc_stop + relativedelta(hours=-1))
        
        user_start = from_utc_to_user(utc_start, user_profile)
        user_stop = from_utc_to_user(utc_stop, user_profile)
        
        label = 'Last hour'
        step = 'hour'
        
    elif date_type == 'today':
        utc_start, utc_stop, user_start, user_stop = get_today(user_profile, format)
        label = 'Today'
        step = 'day'
    
    elif date_type == 'yesterday':
        # Yesterday's start is today's start - 1 day
        today_utc_start, today_utc_stop, today_user_start, user_stop = get_today(user_profile, format)
        
        utc_start = today_utc_start + relativedelta(days=-1)
        utc_stop = utc_start + relativedelta(days=1)
        
        user_start = from_utc_to_user(utc_start, user_profile, format)
        
        label = 'Yesterday'
        step = 'day'
        
    elif date_type == 'this_week':
        # This week extends from Monday midnight to right now
        user_now = now(timezone(user_profile.timezone)).replace(tzinfo=None)
        user_prev_monday = user_now + relativedelta(weekday=MO(-1))
        user_prev_monday = datetime(year=user_prev_monday.year, month=user_prev_monday.month, day=user_prev_monday.day)
        
        utc_start = from_local_to_utc(user_prev_monday, user_profile.timezone)
        utc_stop = from_local_to_utc(user_now, user_profile.timezone)
        
        user_start = from_utc_to_user(utc_start, user_profile, format)
        user_stop = from_utc_to_user(utc_stop, user_profile, format)
        
        label = 'This week'
        step = 'week'
        
    elif date_type == 'this_month':
        # From midnight the first day of month up until now
        user_now = now(timezone(user_profile.timezone)).replace(tzinfo=None)
        user_1st_of_month = datetime(year=user_now.year, month=user_now.month, day=1)
        
        utc_start = from_local_to_utc(user_1st_of_month, user_profile.timezone)
        utc_stop = from_local_to_utc(user_now, user_profile.timezone)
        
        user_start = from_utc_to_user(utc_start, user_profile, format)
        user_stop = None
        
        label = 'This month'
        step = 'month'
        
    elif date_type == 'this_year':
        # From midnight the first day of year up until now
        user_now = now(timezone(user_profile.timezone)).replace(tzinfo=None)
        user_new_year = datetime(year=user_now.year, month=1, day=1)
        
        utc_start = from_local_to_utc(user_new_year, user_profile.timezone)
        utc_stop = from_local_to_utc(user_now, user_profile.timezone)
        
        user_start = from_utc_to_user(utc_start, user_profile, format)
        user_stop = None
        
        label = 'This year'
        step = 'year'
    
    else:
        raise ValueError('Unrecognized date_type:[{}]'.format(date_type))
    
    return DateInfo(utc_start.isoformat(), utc_stop.isoformat(), user_start, user_stop, label, step)

# ##############################################################################


def _get_stats(client, start, stop, n, n_type, stats_type=None):
    """ Returns at most n statistics elements of a given n_type for the period
    between start and stop.
    """
    out = []
    input_dict = {'start':start, 'n':n, 'n_type':n_type}
    
    if stop:
        input_dict['stop'] = stop
        
    if stats_type == 'trends':
        service_name = 'zato.stats.trends.get-trends'
    else:
        service_name = 'zato.stats.summary.get-summary-by-range'
    
    response = client.invoke(service_name, input_dict)
    
    if response.has_data:
        for item in response.data:
            out.append(StatsElem.from_json(item))
            
    return out

# ##############################################################################

def _stats_data_csv(user_profile, req_input, client, ignored, stats_type, is_custom):
    
    n_type_keys = {
        'mean': ['start', 'stop', 'service_name', 'mean', 'mean_all_services', 
                  'usage_perc_all_services', 'time_perc_all_services', 'all_services_usage', 'mean_trend'],
        'usage': ['start', 'stop', 'service_name', 'usage', 'rate', 'usage_perc_all_services', 
                  'time_perc_all_services', 'all_services_usage', 'usage_trend'],
        }
    
    buff = StringIO()
    writer = DictWriter(buff, n_type_keys[req_input.n_type], extrasaction='ignore')
    writer.writeheader()
    
    for stat in _get_stats(client, req_input.utc_start, req_input.utc_stop, req_input.n, req_input.n_type, stats_type):
        d = stat.to_dict()
        d['start'] = req_input.user_start
        d['stop'] = req_input.user_stop if stats_type == 'trends' or is_custom else ''
        writer.writerow(d)
        
    out = buff.getvalue()
    buff.close()
        
    response = HttpResponse(out, mimetype='text/csv')
    response['Content-Disposition'] = 'attachment; filename={}'.format('zato-stats.csv')
    
    return response

def _stats_data_html(user_profile, req_input, client, cluster, stats_type, is_custom):
    
    is_trends = stats_type == 'trends'
    if is_trends:
        data_url = reverse('stats-trends-data')
    else:
        data_url = reverse('stats-summary-data')
        
    return_data = {
        'has_stats':False, 
        'utc_start':req_input.utc_start, 
        'utc_stop':req_input.utc_stop,
        'user_start':req_input.user_start, 
        'user_stop':req_input.user_stop,
        'is_custom': is_custom,
        'is_trends': is_trends,
    }
    
    settings = {}
    
    # We will deal with these ignored keys one by one later on
    ignored_keys = ['format']
    if not is_custom:
        ignored_keys.extend(('utc_start', 'utc_stop'))
        
    query_data = '&amp;'.join('{}={}'.format(key, value) for key, value in req_input.items() if key not in ignored_keys)

    for name in req_input:
        if name.startswith('orig_'):
            target_name = name.replace('orig_', '')
            query_data += '&amp;{}={}'.format(target_name, req_input[name])
    
    if req_input.n:
        for name in('atttention_slow_threshold', 'atttention_top_threshold'):
            settings[name] = int(Setting.objects.get_value(name, default=DEFAULT_STATS_SETTINGS[name]))
            
    for name in('mean', 'usage'):
        d = {'cluster_id':cluster.id, 'side':req_input.side, 'needs_trends': is_trends}
        if req_input.n:

            stats = _get_stats(client, req_input.utc_start, req_input.utc_stop, req_input.n, name, stats_type)
            
            # I.e. whether it's not an empty list (assuming both stats will always be available or neither will be)
            return_data['has_stats'] = len(stats)
            
            return_data['{}_csv_href'.format(name)] = '{}?{}&amp;format=csv&amp;n_type={}&amp;cluster={}'.format(
                data_url, query_data, name, cluster.id)
            
            d.update({name:stats})
            d.update(settings)
            
        return_data[name] = loader.render_to_string('zato/stats/trends-table-{}.html'.format(name), d)
        
    for name in('user_start', 'user_stop'):
        return_data['{}_label'.format(name)] = return_data[name]
        
    return HttpResponse(dumps(return_data), mimetype='application/javascript')

def _stats_data_test(*ignored_args, **ignored_kwargs):
    """ A fake stats-returning function which is actually mocked out in tests only.
    """
    raise NotImplementedError('This function should not be called directly')

def stats_data(req, stats_type):
    """ n and n_type will always be given. format may be None and will
    default to 'html'. Also, either start/stop or left_start/left_stop/shift
    will be present - if the latter, start and stop will be computed as left_start/left_stop
    shifted by the value pointed to by shift.
    """
    req_input = Bunch.fromkeys(('utc_start', 'utc_stop', 'user_start', 'user_stop',
        'n', 'n_type', 'format', 'left-start', 'left-stop', 'right-start', 'right-stop', 
        'shift', 'side', 'custom_range'))
    
    for name in req_input:
        req_input[name] = req.GET.get(name, '') or req.POST.get(name, '')
        
    # Now, this may look odd but for some reason UTC timestamps submitted
    # in the form of '2012-10-31T21:47:11.592868+00:00' get translated
    # by Django into '2012-10-31T21:47:11.592868+00:00' so the plus sign disappears.
    # We bring it back taking an advantage of the fact that ' 00:00' alone is never
    # a proper string of characters in a UTC timestamp.
    for name in('utc_start', 'utc_stop'):
        req_input[name] = req_input[name].replace(' 00:00', '+00:00')
        req_input['orig_{}'.format(name)] = req_input[name]
        
    try:
        req_input.n = int(req_input.n)
    except ValueError:
        req_input.n = 0
        
    req_input.format = req_input.format or 'html'
    is_custom = False

    if req_input.shift:
        duration = skip_by_duration[req_input.shift]
        format = user_format[duration]

        shift_info = shift(parse(req_input.utc_start), req_input.user_start, req.zato.user_profile, req_input.shift, duration, format)
        
        for date_type in('utc', 'user'):
            for direction in('start', 'stop'):
                full_name = '{}_{}'.format(date_type, direction)
                req_input[full_name] = shift_info[full_name]
        
    elif req_input.custom_range:
        is_custom = True
        req_input['utc_start'] = utc.fromutc(from_user_to_utc(req_input.user_start, req.zato.user_profile)).isoformat()
        req_input['utc_stop'] = utc.fromutc(from_user_to_utc(req_input.user_stop, req.zato.user_profile)).isoformat()
        
        req_input['user_start'] = req_input.user_start
        req_input['user_stop'] = req_input.user_stop
        
    return globals()['_stats_data_{}'.format(req_input.format)](req.zato.user_profile, 
        req_input, req.zato.client, req.zato.cluster, stats_type, is_custom)

@method_allowed('GET', 'POST')
def stats_trends_data(req):
    return stats_data(req, 'trends')

@method_allowed('GET', 'POST')
def stats_summary_data(req):
    return stats_data(req, '{}{}'.format(SUMMARY_PREFIX, req.POST.get('choice', 'missing-value')))

def trends_summary(req, choice, stats_title, is_summary):
    if choice == 'this_month':
        format = 'month_year'
    elif choice == 'this_year':
        format = 'year'
    else:
        format = 'date'
        
    info = get_default_date(choice, req.zato.user_profile, format)
    
    try:
        n = int(req.GET.get('n', 10))
    except ValueError:
        n = 10
        
    _compare_to = compare_to[choice]
        
    return_data = {
        'utc_start': info.utc_start,
        'utc_stop': info.utc_stop,
        'user_start': info.user_start,
        'user_stop': info.user_stop,
        'n': n,
        'choice': choice, 
        'label': info.label, 
        'n_form': NForm(initial={'n':n}),
        'compare_to': _compare_to,
        'zato_clusters': req.zato.clusters,
        'cluster_id': req.zato.cluster_id,
        'choose_cluster_form':req.zato.choose_cluster_form,
        'sample_dt': get_sample_dt(req.zato.user_profile),
        'stats_title': stats_title,
        'step': info.step,
        'needs_stop': choice == 'last_hour',
    }
    
    return_data.update(get_js_dt_format(req.zato.user_profile))
    return TemplateResponse(req, 'zato/stats/trends_summary.html', return_data)

@method_allowed('GET')
def trends(req, choice):
    return trends_summary(req, choice, 'Trends', False)

@method_allowed('GET')
def summary(req, choice):
    return trends_summary(req, choice, 'Summary', True)

# ##############################################################################
    
@method_allowed('GET')
def settings(req):
    
    if req.zato.get('cluster'):
        
        _settings = {}
        defaults = deepcopy(DEFAULT_STATS_SETTINGS)
        
        for mapping in job_mappings:

            response = req.zato.client.invoke('zato.scheduler.job.get-by-name', {'cluster_id':req.zato.cluster.id, 'name': mapping.job_name})
            if response.has_data:
            
                for attr in mapping.attrs:
                    try:
                        attr.job_attr['extra']
                    except TypeError:
                        setting_base_name = 'scheduler_{}_interval'.format(attr.form_name)
                        setting_unit_name = 'scheduler_{}_interval_unit'.format(attr.form_name)
                        
                        defaults[setting_unit_name] = attr.job_attr
                        _settings[setting_base_name] = getattr(response.data, attr.job_attr)
                    else:
                        # A sample response.data.extra is, for instance, 'max_batch_size=123456'
                        _settings['scheduler_{}'.format(attr.form_name)] = response.data.extra.split('=')[1]

        for name in DEFAULT_STATS_SETTINGS:
            if not name.startswith('scheduler'):
                _settings[name] = Setting.objects.get_value(name, default=DEFAULT_STATS_SETTINGS[name])
    else:
        form, defaults, _settings = None, None, {}

    return_data = {
        'zato_clusters': req.zato.clusters,
        'cluster_id': req.zato.cluster_id,
        'choose_cluster_form':req.zato.choose_cluster_form,
        'form': SettingsForm(initial=_settings),
        'defaults':defaults,
    }

    return TemplateResponse(req, 'zato/stats/settings.html', return_data)

@method_allowed('POST')
def settings_save(req):
    
    for name in DEFAULT_STATS_SETTINGS:
        if not name.startswith('scheduler'):
            value = req.POST[name]
            Setting.objects.set_value(name, PositiveInteger, value)

    for mapping in job_mappings:

        response = req.zato.client.invoke('zato.scheduler.job.get-by-name', {'cluster_id':req.zato.cluster.id, 'name': mapping.job_name})
        if response.has_data:
            
            # Gotta love dictionary comprehensions!
            params = {attr: getattr(response.data, attr) for attr in(
                'id', 'name', 'is_active', 'job_type', 'start_date', 'extra')}
        
            for attr in mapping.attrs:
                
                try:
                    attr.job_attr['extra']
                except TypeError:
                    key = attr.job_attr
                    value = req.POST['scheduler_{}_interval'.format(attr.form_name)]
                else:
                    key = 'extra'
                    value = '{}={}'.format(attr.job_attr['extra'], req.POST['scheduler_{}'.format(attr.form_name)])
                    
                params[key] = value
                
            params['service'] = response.data.service_name
            params['cluster_id'] = req.zato.cluster.id
                
            req.zato.client.invoke('zato.scheduler.job.edit', params)

    msg = 'Settings saved'
    messages.add_message(req, messages.INFO, msg, extra_tags='success')
        
    return redirect('{}?cluster={}'.format(reverse('stats-settings'), req.zato.cluster_id))

# ##############################################################################

@method_allowed('GET')
def maintenance(req):
    return_data = {
        'zato_clusters': req.zato.clusters,
        'cluster_id': req.zato.cluster_id,
        'choose_cluster_form':req.zato.choose_cluster_form,
        'form': MaintenanceForm()
    }
    
    return_data.update(get_js_dt_format(req.zato.user_profile))
    
    return TemplateResponse(req, 'zato/stats/maintenance.html', return_data)

@method_allowed('POST')
def maintenance_delete(req):
    start = from_user_to_utc(req.POST['start'], req.zato.user_profile)
    stop = from_user_to_utc(req.POST['stop'], req.zato.user_profile)
    
    req.zato.client.invoke('zato.stats.delete', {'start':start, 'stop':stop})
    
    logger.warn('[{}]'.format(stop.isoformat() + '+00:00'))
    
    msg = 'Submitted a request to delete statistics from [{}] to [{}]. Check the server logs for details.'.format(
        from_utc_to_user(start.isoformat() + '+00:00', req.zato.user_profile), 
        from_utc_to_user(stop.isoformat() + '+00:00', req.zato.user_profile))
        
    messages.add_message(req, messages.INFO, msg, extra_tags='success')
        
    return redirect('{}?cluster={}'.format(reverse('stats-maintenance'), req.zato.cluster_id))

# ##############################################################################

########NEW FILE########
__FILENAME__ = zato_settings
# -*- coding: utf-8 -*-

"""
Copyright (C) 2010 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
import os

# Zato
from zato.common import SCHEDULER_JOB_TYPE
from zato.common.util import decrypt

SSL_KEY_FILE = './config/repo/web-admin-priv-key.pem'
SSL_CERT_FILE = './config/repo/web-admin-cert.pem'
SSL_CA_CERTS = './config/repo/web-admin-ca-certs.pem'

LB_AGENT_CONNECT_TIMEOUT=500 # In milliseconds

def update_globals(config, base_dir='.'):
    globals()['DATABASES'] = {'default': {}}
    priv_key = open(os.path.abspath(os.path.join(base_dir, SSL_KEY_FILE))).read()
    for k, v in config.items():
        if k.startswith('DATABASE_'):
            default = globals()['DATABASES']['default']
            k = k.replace('DATABASE_', '', 1)
            if k == 'PASSWORD' and config['db_type'] != 'sqlite':
                v = decrypt(v, priv_key)
            default[k] = str(v)
        else:
            if k == 'ADMIN_INVOKE_PASSWORD':
                v = decrypt(v, priv_key)
            elif k == 'log_config':
                v = os.path.join(base_dir, v)
            globals()[k] = v            

# ##############################################################################

# Maps SQLAlchemy engine's name to a UI-friendly one.
engine_friendly_name = {
    'postgresql': 'PostgreSQL',
    'oracle': 'Oracle',
    'mysql': 'MySQL',
    'mysql+pymysql': 'MySQL',

    # These are not supported /yet/.
    #'mssql': 'MS SQL Server',
    #'access': 'MS Access',
    #'firebird': 'Firebird',
    #'db2': 'DB2',
    #'informix':'Informix'
}

odb_engine_friendly_name = {
    'postgresql': 'PostgreSQL',
    'oracle': 'Oracle',
    'mysql+pymysql': 'MySQL',
}

django_sqlalchemy_engine = {
    'postgresql': 'postgresql_psycopg2',
    'mysql':'mysql',
    'oracle':'oracle',
    'sqlite':'sqlite3',
    'dummy':'dummy'
}

sqlalchemy_django_engine = dict((v,k) for k,v in django_sqlalchemy_engine.items())

# Maps job types as they are used by servers into UI friendly names.
job_type_friendly_names = {
    SCHEDULER_JOB_TYPE.ONE_TIME: 'one-time',
    SCHEDULER_JOB_TYPE.INTERVAL_BASED: 'interval-based',
    SCHEDULER_JOB_TYPE.CRON_STYLE: 'cron-style',
}


# Maps AMQP delivery modes to UI-friendly names
delivery_friendly_name = {
    1:'Non-persistent',
    2:'Persistent',
}

########NEW FILE########
__FILENAME__ = test_stats
# -*- coding: utf-8 -*-

"""
Copyright (C) 2012 Dariusz Suchojad <dsuch at zato.io>

Licensed under LGPLv3, see LICENSE.txt for terms and conditions.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

# stdlib
from datetime import datetime
from unittest import TestCase

# dateutil
from dateutil.parser import parse

# mock
from mock import patch

# nose
from nose.tools import eq_

# pytz
from pytz import utc

# Zato
from zato.admin.web import from_utc_to_user
from zato.admin.web.models import UserProfile
from zato.admin.web.views.stats import get_default_date, shift
from zato.common.util import utcnow

class StatsTestCase(TestCase):
    def setUp(self):
        self.user_profile = UserProfile()
        self.user_profile.timezone = 'Europe/Berlin'
        self.user_profile.date_format_py = 'd-m-Y'
        self.user_profile.time_format_py = 'H:i:s'
        self.user_profile.month_year_format_py = 'm-Y'
        self.user_profile.date_time_format_py = 'd-m-Y H:i:s'
        
    def _fake_now(self):
        return datetime(2012, 3, 1, 0, 47, 24, 54903, tzinfo=utc) # 1st of March in a leap year
        
    def _utcnow(self):
        return self._fake_now()
    
    def _now(self, *ignored):
        return self._fake_now()

class TrendsTestCase(StatsTestCase):
    def test_start_stop_last_hour(self):
        with patch('zato.common.util._utcnow', self._utcnow):
            info = get_default_date('last_hour', self.user_profile, 'date_time')
            eq_(info.utc_start, '2012-02-29T23:47:24.054903+00:00')
            eq_(info.utc_stop, '2012-03-01T00:47:24.054903+00:00')
            eq_(info.user_start, '01-03-2012 00:47:24')
            eq_(info.user_stop, '01-03-2012 01:47:24')
            eq_(info.label, 'Last hour')
            eq_(info.step, 'hour')
            
    def test_shift_prev_hour(self):
        with patch('zato.common.util._utcnow', self._utcnow):
            now = utcnow()
            info = shift(now, from_utc_to_user(now, self.user_profile), self.user_profile, 'last_hour_prev', 'hour', 'date_time')
            eq_(info.utc_start, '2012-02-29T23:47:24.054903+00:00')
            eq_(info.utc_stop, '2012-03-01T00:47:24.054903+00:00')
            eq_(info.user_start, '01-03-2012 00:47:24')
            eq_(info.user_stop, '01-03-2012 01:47:24')
            eq_(info.step, None)
            
    def test_shift_prev_hour2(self):
        now = parse('2012-10-30T21:09:02.141791+00:00')
        info = shift(now, '2012-10-30 23:09:02', self.user_profile, 'last_hour_prev', 'hour', 'date_time')
        eq_(info.utc_start, '2012-10-30T20:09:02.141791+00:00')
        eq_(info.utc_stop, '2012-10-30T21:09:02.141791+00:00')
        eq_(info.user_start, '30-10-2012 21:09:02')
        eq_(info.user_stop, '30-10-2012 22:09:02')
        eq_(info.step, None)

    def test_shift_prev_day(self):
        with patch('zato.common.util._utcnow', self._utcnow):
            now = utcnow()
            info = shift(now, from_utc_to_user(now, self.user_profile), self.user_profile, 'today_prev_day', 'hour', 'date_time')
            eq_(info.utc_start, '2012-02-29T00:47:24.054903+00:00')
            eq_(info.utc_stop, '2012-02-29T01:47:24.054903+00:00')
            eq_(info.user_start, '29-02-2012 01:47:24')
            eq_(info.user_stop, '29-02-2012 02:47:24')
            eq_(info.step, None)

    def test_shift_prev_week(self):
        with patch('zato.common.util._utcnow', self._utcnow):
            now = utcnow()
            info = shift(now, from_utc_to_user(now, self.user_profile), self.user_profile, 'today_prev_day_week', 'hour', 'date_time')
            eq_(info.utc_start, '2012-02-23T00:47:24.054903+00:00')
            eq_(info.utc_stop, '2012-02-23T01:47:24.054903+00:00')
            eq_(info.user_start, '23-02-2012 01:47:24')
            eq_(info.user_stop, '23-02-2012 02:47:24')
            eq_(info.step, None)

class SummaryTestCase(StatsTestCase):
    def test_start_stop_today(self):
        with patch('zato.common.util._now', self._now):
            info = get_default_date('today', self.user_profile, 'date')
            eq_(info.utc_start, '2012-02-29T23:00:00+00:00')
            eq_(info.utc_stop, '2012-02-29T23:47:24.054903+00:00')
            eq_(info.user_start, '01-03-2012')
            eq_(info.user_stop, '')
            eq_(info.label, 'Today')
            eq_(info.step, 'day')
            
    def test_start_stop_yesterday(self):
        with patch('zato.common.util._now', self._now):
            info = get_default_date('yesterday', self.user_profile, 'date')
            eq_(info.utc_start, '2012-02-28T23:00:00+00:00')
            eq_(info.utc_stop, '2012-02-29T23:00:00+00:00')
            eq_(info.user_start, '29-02-2012')
            eq_(info.user_stop, '')
            eq_(info.label, 'Yesterday')
            eq_(info.step, 'day')
            
    def test_start_stop_this_week(self):
        with patch('zato.common.util._now', self._now):
            info = get_default_date('this_week', self.user_profile, 'date')
            eq_(info.utc_start, '2012-02-26T23:00:00+00:00')
            eq_(info.utc_stop, '2012-02-29T23:47:24.054903+00:00')
            eq_(info.user_start, '27-02-2012')
            eq_(info.user_stop, '01-03-2012') # The date now() returns
            eq_(info.label, 'This week')
            eq_(info.step, 'week')
            
    def test_start_stop_this_month(self):
        with patch('zato.common.util._now', self._now):
            info = get_default_date('this_month', self.user_profile, 'month_year')
            eq_(info.utc_start, '2012-02-29T23:00:00+00:00')
            eq_(info.utc_stop, '2012-02-29T23:47:24.054903+00:00')
            eq_(info.user_start, '03-2012')
            eq_(info.user_stop, '')
            eq_(info.label, 'This month')
            eq_(info.step, 'month')
            
    def test_start_stop_this_year(self):
        with patch('zato.common.util._now', self._now):
            info = get_default_date('this_year', self.user_profile, 'year')
            eq_(info.utc_start, '2011-12-31T23:00:00+00:00')
            eq_(info.utc_stop, '2012-02-29T23:47:24.054903+00:00')
            eq_(info.user_start, '2012')
            eq_(info.user_stop, '')
            eq_(info.label, 'This year')
            eq_(info.step, 'year')
            
    def test_shift_prev_day_by_day(self):
        now = parse('2012-03-21T00:39:19+00:00')
        info = shift(now, from_utc_to_user(now, self.user_profile), self.user_profile, 'today_prev_day', 'day', 'date')
        eq_(info.utc_start, '2012-03-20T00:39:19+00:00')
        eq_(info.utc_stop, '2012-03-21T00:39:19+00:00')
        eq_(info.user_start, '20-03-2012')
        eq_(info.user_stop, '21-03-2012')
        eq_(info.step, None)
        
    def test_shift_prev_week_by_day(self):
        now = parse('2012-03-21T00:39:19+00:00')
        info = shift(now, from_utc_to_user(now, self.user_profile), self.user_profile, 'today_prev_day_week', 'day', 'date')
        eq_(info.utc_start, '2012-03-14T00:39:19+00:00')
        eq_(info.utc_stop, '2012-03-15T00:39:19+00:00')
        eq_(info.user_start, '14-03-2012')
        eq_(info.user_stop, '15-03-2012')
        eq_(info.step, None)

    def test_shift_prev_week_by_week(self):
        now = parse('2012-10-22T00:00:00+00:00')
        info = shift(now, from_utc_to_user(now, self.user_profile), self.user_profile, 'today_prev_day_week', 'week', 'date')
        eq_(info.utc_start, '2012-10-15T00:00:00+00:00')
        eq_(info.utc_stop, '2012-10-22T00:00:00+00:00')
        eq_(info.user_start, '15-10-2012')
        eq_(info.user_stop, '22-10-2012')
        eq_(info.step, None)

    def test_shift_prev_month_by_month(self):
        now = parse('2012-10-01T00:00:00+00:00')
        info = shift(now, from_utc_to_user(now, self.user_profile, 'month_year'), self.user_profile, 'this_month_prev_month', 'month', 'month_year')
        eq_(info.utc_start, '2012-08-31T22:00:00+00:00')
        eq_(info.utc_stop, '2012-09-30T22:00:00+00:00')
        eq_(info.user_start, '09-2012')
        eq_(info.user_stop, '10-2012')
        eq_(info.step, None)

    def test_shift_prev_year_by_year(self):
        now = parse('2012-01-01T00:00:00+00:00')
        info = shift(now, from_utc_to_user(now, self.user_profile), self.user_profile, 'this_year_prev', 'year', 'year')
        eq_(info.utc_start, '2011-01-01T00:00:00+00:00')
        eq_(info.utc_stop, '2012-01-01T00:00:00+00:00')
        eq_(info.user_start, '2011')
        eq_(info.user_stop, '2012')
        eq_(info.step, None)

########NEW FILE########
