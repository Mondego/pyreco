__FILENAME__ = evilplugin
"""
This is a plugin that should do everything wrong, for debugging Purposes
"""
__kupfer_name__ = u"Evil Plugin"
__kupfer_sources__ = (
	"EvilSource",
	"EvilInstantiationSource",
)
__description__ = u"Evil for debugging purposes (necessary evil)"
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"


from kupfer.objects import Leaf, Action, Source

class EvilError (Exception):
	pass

class EvilInstantiationSource (Source):
	def __init__(self):
		raise EvilError

class EvilSource (Source):
	def __init__(self):
		Source.__init__(self, u"Evil Source")

	def initialize(self):
		raise EvilError

	def get_items(self):
		raise EvilError

	def get_icon_name(self):
		raise EvilError

	def provides(self):
		pass


########NEW FILE########
__FILENAME__ = google_translate
# -*- coding: UTF-8 -*-
'''
Translate TextLeaf by Google Translate.

'''
__kupfer_name__ = _("Google Translate")
__kupfer_actions__ = ("Translate", "TranslateUrl", 'OpenTranslatePage')
__description__ = _("Translate text with Google Translate")
__version__ = "2011-09-14"
__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"

import httplib
import locale
import urllib
import re
import socket

from kupfer.objects import Source, Action, TextLeaf, Leaf, UrlLeaf
from kupfer import icons, utils, pretty
from kupfer.plugin import ssl_support


try:
	import cjson
	json_decoder = cjson.decode
except ImportError:
	import json
	json_decoder = json.loads


_GOOGLE_TRANSLATE_HOST = 'ajax.googleapis.com'
_GOOGLE_TRANSLATE_PATH = '/ajax/services/language/translate?'
_GOOGLE_TRANS_LANG_PATH = '/#'
_GOOGLE_TRANS_LANG_HOST = 'translate.google.com'

_HEADER = {
		'Content-type':'application/x-www-form-urlencoded',
		'Accept': 'text/xml,application/xml,application/xhtml+xml,text/html',
		'Accept-charset': 'utf-8;q=0.7'
}

def _parse_encoding_header(response, default="UTF-8"):
	"""Parse response's header for an encoding, that is return 'utf-8' for:
	text/html; charset=utf-8
	"""
	ctype = response.getheader("content-type", "")
	parts = ctype.split("charset=", 1)
	if len(parts) > 1:
		return parts[-1]
	return default


def _translate(text, lang):
	''' Translate @text to @lang. '''
	query_param = urllib.urlencode(dict(v="1.0",langpair="|"+lang,
		                                q=text.encode('utf-8')))
	try:
		if ssl_support.is_supported():
			conn = ssl_support.VerifiedHTTPSConnection(_GOOGLE_TRANSLATE_HOST,
			                                           timeout=5)
			pretty.print_debug(__name__, "Connected to",
			                   _GOOGLE_TRANSLATE_HOST, "using SSL")
		else:
			conn = httplib.HTTPConnection(_GOOGLE_TRANSLATE_HOST, timeout=5)
		conn.request("POST", _GOOGLE_TRANSLATE_PATH, query_param, _HEADER)
		resp = conn.getresponse()
		if resp.status != 200:
			raise ValueError('invalid response %d, %s' % (resp.status,
					resp.reason))

		response_data = resp.read()
		encoding = _parse_encoding_header(resp)
		response_data = response_data.decode(encoding, 'replace')
		pretty.print_debug(__name__, "Translate response:", repr(response_data))
		try:
			resp = json_decoder(response_data)
			yield resp['responseData']['translatedText'], ''
		except:
			pretty.print_exc(__name__)
			yield text, ''

	except socket.timeout:
		yield  _("Google Translate connection timed out"), ""
	except (httplib.HTTPException, ValueError), err:
		pretty.print_error(__name__, '_translate error', repr(text), lang, err)
		yield  _("Error connecting to Google Translate"), ""

	finally:
		conn.close()


_RE_GET_LANG_SELECT = re.compile(
		r'\<select[\w\d\s="\'-]*name=tl[\w\d\s="\']*\>(.*)\<\/select\>',
		re.UNICODE|re.MULTILINE|re.IGNORECASE)
_RE_GET_LANG = re.compile(r"""\<option[ \w]+ value="?([\w\-]+)"?\> # code 'zh-TW'
                              ([^<]+?)             # match localized lang name
                              \</option\>
                           """, re.UNICODE|re.IGNORECASE|re.VERBOSE)

def _load_languages():
	''' Load available languages from Google.
		Generator: (lang_code, lang name) 
	'''
	user_language = locale.getlocale(locale.LC_MESSAGES)[0]
	pretty.print_debug(__name__, '_load_languages')
	try:
		conn = httplib.HTTPConnection(_GOOGLE_TRANS_LANG_HOST)
		conn.connect()
		conn.sock.settimeout(10) # set timeout to 10 sec
		headers = {
			"Accept-Language": "%s, en;q=0.7" % user_language,
		}
		conn.request("GET", _GOOGLE_TRANS_LANG_PATH, headers=headers)
		resp = conn.getresponse()
		if resp.status != 200:
			raise ValueError('invalid response %d, %s' % (resp.status,
					resp.reason))
		
		result = resp.read().decode(_parse_encoding_header(resp), "replace")
		result = _RE_GET_LANG_SELECT.findall(result)
		if result:
			for key, name in _RE_GET_LANG.findall(result[0]):
				yield key, name

	except socket.timeout:
		pretty.print_error(__name__, 'Timed out when loading languages')
	except (httplib.HTTPException, ValueError, socket.error), err:
		pretty.print_error(__name__, '_load_languages error', type(err), err)

	finally:
		conn.close()


class Translate (Action):
	def __init__(self):
		Action.__init__(self, _("Translate To..."))

	def activate(self, leaf, iobj):
		text = unicode(leaf.object)
		dest_lang = iobj.object
		return _TranslateQuerySource(text, dest_lang, unicode(iobj))

	def is_factory(self):
		return True

	def item_types(self):
		yield TextLeaf
	
	def valid_for_item(self, leaf):
		return len(leaf.object.strip()) > 0
	
	def get_description(self):
		return _("Translate text with Google Translate")

	def get_icon_name(self):
		return "accessories-dictionary"

	def requires_object(self):
		return True

	def object_types(self):
		yield _Language
	
	def object_source(self, for_item=None):
		return _LangSource()


class TranslationLeaf(TextLeaf):
	def __init__(self, translation, descr):
		TextLeaf.__init__(self, translation)
		self._descrtiption = descr

	def get_description(self):
		return self._descrtiption or TextLeaf.get_description(self)


class _TranslateQuerySource(Source):
	def __init__(self, text, lang, language_name):
		Source.__init__(self, name=_("Translate into %s") % language_name)
		self._text = text
		self._lang = lang

	def repr_key(self):
		return (hash(self._text), self._lang)

	def get_items(self):
		for translation, desc in _translate(self._text, self._lang):
			yield TranslationLeaf(translation.replace('\\n ', '\n'), desc)


class _Language(Leaf):
	serializable = 1
	def get_gicon(self):
		return icons.ComposedIcon("text-x-generic","preferences-desktop-locale")


# cache for Languages (load it once)
_LANG_CACHE = None

class _LangSource(Source):

	def __init__(self):
		Source.__init__(self, _("Languages"))

	def get_items(self):
		global _LANG_CACHE
		if not _LANG_CACHE:
			_LANG_CACHE = tuple((
					_Language(key, name.title())
					for key, name in _load_languages()
			))
		return _LANG_CACHE

	def provides(self):
		yield _Language

	def get_icon_name(self):
		return "preferences-desktop-locale"


class TranslateUrl(Action):
	def __init__(self):
		Action.__init__(self, _("Translate To..."))

	def activate(self, leaf, iobj):
		dest_lang = iobj.object
		params = urllib.urlencode(dict(u=leaf.object, sl='auto', tl=dest_lang ))
		url = 'http://translate.google.com/translate?' + params
		utils.show_url(url)

	def item_types(self):
		yield UrlLeaf
	
	def valid_for_item(self, leaf):
		return leaf.object.startswith('http://') or leaf.object.startswith('www.')
	
	def get_description(self):
		return _("Show translated page in browser")

	def get_icon_name(self):
		return "accessories-dictionary"

	def requires_object(self):
		return True

	def object_types(self):
		yield _Language
	
	def object_source(self, for_item=None):
		return _LangSource()


class OpenTranslatePage (Action):
	def __init__(self):
		Action.__init__(self, _("Show Translation To..."))

	def activate(self, leaf, iobj):
		text = urllib.quote(unicode(leaf.object).encode('utf-8'))
		dest_lang = iobj.object
		url = 'http://' + _GOOGLE_TRANSLATE_HOST + _GOOGLE_TRANS_LANG_PATH + \
				"#auto|" + dest_lang + "|" + text
		utils.show_url(url)

	def item_types(self):
		yield TextLeaf
	
	def valid_for_item(self, leaf):
		return len(leaf.object.strip()) > 0
	
	def get_description(self):
		return _("Show translation in browser")

	def get_icon_name(self):
		return "accessories-dictionary"

	def requires_object(self):
		return True

	def object_types(self):
		yield _Language
	
	def object_source(self, for_item=None):
		return _LangSource()



########NEW FILE########
__FILENAME__ = icon_names
"""
A quick hack to search the icons of the `Icon Naming Specification`__, shown
as available on the current system.

__ http://standards.freedesktop.org/icon-naming-spec/icon-naming-spec-latest.html
"""
__kupfer_name__ = _("Icon Names")
__kupfer_sources__ = (
		"StandardIconsSource",
		"IconThemeSource",
	)
__description__ = _("Browse the icons of the Icon Naming Specification")
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"


import urllib
from xml.etree import cElementTree as ET

import gtk

from kupfer.objects import Leaf, Action, Source, SourceLeaf
from kupfer import uiutils


ICON_SPEC_ADDRESS = "http://standards.freedesktop.org/icon-naming-spec/icon-naming-spec-0.8.90.xml"

class ShowDescription(Action):
	def __init__(self):
		Action.__init__(self, _("Show Full Description"))
	def activate(self, leaf):
		uiutils.show_large_type(leaf.description)

class IconName (Leaf):
	def __init__(self, obj, desc, category):
		Leaf.__init__(self, obj, obj)
		self.description = desc
		if desc:
			self.kupfer_add_alias(desc.splitlines()[0])
	def get_actions(self):
		yield ShowDescription()
	def get_description(self):
		return self.description.splitlines()[0] if self.description else None
	def get_icon_name(self):
		return self.object

class IconNamesSource (Source):
	def get_items(self):
		for name, desc, info in self._get_all_items():
			yield IconName(name, desc, info)

class StandardIconsSource (IconNamesSource):
	def __init__(self):
		return Source.__init__(self, _("Standard Icon Names"))
	def _get_all_items(self):
		parsed = ET.parse(urllib.urlopen(ICON_SPEC_ADDRESS))
		root = parsed.getroot()

		icon_names = {}
		def first(lst):
			return iter(lst).next()

		def flatten(tag):
			"""return text of @tag and its immediate children"""
			return tag.text + "".join(c.text+c.tail for c in tag.getchildren())

		names = first(s for s in root.findall("sect1") if s.get("id") == "names")
		for table in names.findall("table"):
			category_name = table.get("id")
			rows = table.find("tgroup").find("tbody")
			for row in rows:
				icon_names.setdefault(category_name, []).append(
						tuple(flatten(e).strip() for e in row.findall("entry")))

		for category in icon_names:
			for name, desc in icon_names[category]:
				yield name, desc, category

	def get_icon_name(self):
		return "emblem-photos"

class IconThemeCategorySource (IconNamesSource):
	def __init__(self, category):
		IconNamesSource.__init__(self, category or "All Icons")
		self.category = category

	def repr_key(self):
		return self.category
	def _get_all_items(self):
		it = gtk.icon_theme_get_default()
		for icon_name in it.list_icons(self.category):
			desc = str(it.get_icon_sizes(icon_name))
			yield icon_name, desc, self.category

	def should_sort_lexically(self):
		return True

class IconThemeSource (Source):
	def __init__(self):
		Source.__init__(self, _("All Icon Theme Icons"))
	def get_items(self):
		it = gtk.icon_theme_get_default()
		yield SourceLeaf(IconThemeCategorySource(None))
		for ctx in it.list_contexts():
			yield SourceLeaf(IconThemeCategorySource(ctx))
	def get_icon_name(self):
		it = gtk.icon_theme_get_default()
		return it.get_example_icon_name()

########NEW FILE########
__FILENAME__ = nautilusselection
__kupfer_name__ = _("Selected File")
__kupfer_sources__ = ("SelectionSource", )
__description__ = _("Provides current nautilus selection, using Kupfer's Nautilus Extension")
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import dbus
import gobject
import gio

from kupfer.objects import Source
from kupfer.objects import FileLeaf, SourceLeaf
from kupfer.obj.compose import MultipleLeaf
from kupfer.obj.helplib import PicklingHelperMixin
from kupfer.weaklib import DbusWeakCallback
from kupfer import plugin_support

plugin_support.check_dbus_connection()

class SelectedFile (FileLeaf):
	qf_id = "selectedfile"
	def __init__(self, filepath):
		"""@filepath is a filesystem byte string `str`"""
		basename = gobject.filename_display_basename(filepath)
		FileLeaf.__init__(self, filepath, _('Selected File "%s"') % basename)

	def __repr__(self):
		return "<%s %s>" % (__name__, self.qf_id)

class SelectedFiles (MultipleLeaf):
	qf_id = "selectedfile"
	def __init__(self, paths):
		files = [FileLeaf(path) for path in paths]
		MultipleLeaf.__init__(self, files, _("Selected Files"))

	def __repr__(self):
		return "<%s %s>" % (__name__, self.qf_id)

class InvisibleSourceLeaf (SourceLeaf):
	"""Hack to hide this source"""
	def is_valid(self):
		return False

class SelectionSource (Source, PicklingHelperMixin):
	def __init__(self):
		Source.__init__(self, _("Selected File"))
		self.unpickle_finish()

	def unpickle_finish(self):
		self._selection = []

	def initialize(self):
		session_bus = dbus.Bus()
		callback = DbusWeakCallback(self._selected_signal)
		callback.token = session_bus.add_signal_receiver(
				callback,
				"SelectionChanged",
				dbus_interface="se.kaizer.FileSelection",
				byte_arrays=True)

	def _selected_signal(self, selection, window_id):
		# The SelectionChanged signal carries an array of unicode URIs
		paths = filter(None, [gio.File(uri).get_path() for uri in selection])
		self._selection = paths
		self.mark_for_update()

	def get_items(self):
		if len(self._selection) == 1:
			yield SelectedFile(self._selection[0])
		elif len(self._selection) > 1:
			yield SelectedFiles(self._selection)

	def get_description(self):
		return None
	def provides(self):
		yield FileLeaf
		yield MultipleLeaf
	def get_leaf_repr(self):
		return InvisibleSourceLeaf(self)

########NEW FILE########
__FILENAME__ = runningapplications
__kupfer_name__ = _("Running Applications")
__kupfer_sources__ = ("RunningApplicationsSource",)
__description__ = _("Currently active applications")
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import gio

from kupfer.objects import Source, AppLeaf
from kupfer import launch

class RunningApplicationsSource (Source):
	"""List currently running applications """
	def __init__(self):
		Source.__init__(self, _("Running Applications"))
		self.all_apps = []

	def initialize(self):
		self.all_apps = gio.app_info_get_all()

	def is_dynamic(self):
		return True

	def get_items(self):
		is_running = launch.application_is_running
		return (AppLeaf(ai) for ai in self.all_apps if is_running(ai))

	def provides(self):
		yield AppLeaf

	def get_description(self):
		return _("Running applications")

	def get_icon_name(self):
		return "gnome-applications"


########NEW FILE########
__FILENAME__ = tracker
"""
Tracker plugins are versioned by the D-Bus API version
This is version works with the "original" tracker 0.6.x dbus API.
"""
__kupfer_name__ = _("Tracker 0.6")
__kupfer_sources__ = ("TrackerTagsSource", )
__kupfer_text_sources__ = ()
__kupfer_contents__ = ("TrackerQuerySource", )
__kupfer_actions__ = (
		"TrackerSearch",
		"TrackerSearchHere",
		"TrackerAddTag",
		"TrackerRemoveTag",
	)
__description__ = _("Tracker desktop search integration")
__version__ = "2010-01-03"
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import os
from xml.etree.cElementTree import ElementTree

import gobject

from kupfer.objects import Action, Source, Leaf
from kupfer.objects import TextLeaf, SourceLeaf, FileLeaf
from kupfer.obj.objects import ConstructFileLeaf
from kupfer import utils, pretty
from kupfer import kupferstring
from kupfer import plugin_support



plugin_support.check_dbus_connection()

SERVICE_NAME = "org.freedesktop.Tracker"
SEARCH_OBJECT_PATH = "/org/freedesktop/Tracker/Search"
SEARCH_INTERFACE = "org.freedesktop.Tracker.Search"

class TrackerSearch (Action):
	def __init__(self):
		Action.__init__(self, _("Search in Tracker"))

	def activate(self, leaf):
		utils.spawn_async(["tracker-search-tool", leaf.object])
	def get_description(self):
		return _("Open Tracker Search Tool and search for this term")
	def get_icon_name(self):
		return "system-search"
	def item_types(self):
		yield TextLeaf


class TrackerSearchHere (Action):
	def __init__(self):
		Action.__init__(self, _("Get Tracker Results..."))

	def is_factory(self):
		return True

	def activate(self, leaf):
		return TrackerQuerySource(leaf.object)

	def get_description(self):
		return _("Show Tracker results for query")
	def get_icon_name(self):
		return "tracker"
	def item_types(self):
		yield TextLeaf

class TrackerQuerySource (Source):
	def __init__(self, query):
		Source.__init__(self, name=_('Results for "%s"') % query)
		self.query = query
		self.max_items = 50

	def repr_key(self):
		return self.query

	def get_items(self):
		try:
			import dbus
		except ImportError:
			pretty.print_info(__name__, "Dbus not available!")
			return
		bus = dbus.SessionBus()
		try:
			tobj = bus.get_object(SERVICE_NAME, SEARCH_OBJECT_PATH)
			searchobj = dbus.Interface(tobj, SEARCH_INTERFACE)
		except dbus.DBusException, exc:
			pretty.print_error(__name__, exc)
			pretty.print_error(__name__, "Could not connect to Tracker")
			return

		# Text interface
		# (i) live_query_id, (s) service, (s) search_text,
		# (i) offset, (i) max_hits
		# Returns array of strings for results
		try:
			file_hits = searchobj.Text(1, "Files", self.query, 0, self.max_items)
		except dbus.DBusException, exc:
			pretty.print_error(__name__, exc)
			return

		for filestr in file_hits:
			# A bit of encoding carousel
			# dbus strings are subclasses of unicode
			# but FileLeaf expects a filesystem encoded object
			bytes = filestr.decode("UTF-8", "replace")
			filename = gobject.filename_from_utf8(bytes)
			yield ConstructFileLeaf(filename)

	def get_description(self):
		return _('Results for "%s"') % self.query
	def get_icon_name(self):
		return "tracker"

	@classmethod
	def decorates_type(cls):
		return FileLeaf
	@classmethod
	def decorate_item(cls, leaf):
		# FIXME: Very simplified .savedSearch parsing, so far we only support
		# the query, without additional filtering. The simplest form of
		# .savedSearch file is saved by nautilus as following:
		# <query version="1.0">
		#   <text>QUERY GOES HERE</text>
		# </query>

		if not leaf.object.endswith(".savedSearch"):
			return None
		try:
			et = ElementTree(file=leaf.object)
			query = et.getroot().find("text").text
			return cls(query)
		except Exception:
			return None

# FIXME: Use dbus for this communication
def cmd_output_lines(cmd):
	return kupferstring.fromlocale(os.popen(cmd).read()).splitlines()

def get_tracker_tags(for_file=None):
	if not for_file:
		for tagline in cmd_output_lines("tracker-tag --list")[1:]:
			tag, count = tagline.rsplit(",", 1)
			tag = tag.strip()
			yield tag
	else:
		output = cmd_output_lines("tracker-tag --list '%s'" % for_file)
		for tagline in output[1:]:
			fil, tagstr = tagline.rsplit(": ", 1)
			tags = tagstr.strip().split("|")
			for t in filter(None, tags):
				yield t

def get_tracker_tag_items(tag):
	output = cmd_output_lines("tracker-tag -s '%s'" % tag)
	for tagline in output[1:]:
		yield tagline.strip()

class TrackerFileTagsSource (Source):
	"""Tracker tags for a specific file"""
	def __init__(self, fil=None):
		""" All tags for file @fil or all tags known if None"""
		Source.__init__(self, _("Tracker tags"))
		self.for_file = fil
	def get_items(self):
		for tag in get_tracker_tags(self.for_file):
			yield TrackerTag(tag)
	def get_description(self):
		return _("Tracker tags")
	def get_icon_name(self):
		return "tracker"
	def provides(self):
		yield TrackerTag

class TrackerTagsSource (Source):
	"""Browse items tagged in Tracker"""
	def __init__(self):
		Source.__init__(self, _("Tracker Tags"))
	def get_items(self):
		for tag in get_tracker_tags():
			src = TrackerTagObjectsSource(tag)
			yield SourceLeaf(src)
	def get_description(self):
		return _("Browse Tracker's tags")
	def get_icon_name(self):
		return "tracker"
	def provides(self):
		yield TrackerTag

class TrackerTag (Leaf):
	""" Represents a tag without actions """
	def __init__(self, tag):
		Leaf.__init__(self, tag, tag)
	def get_description(self):
		return _("Tag %s") % self.object
	def get_icon_name(self):
		return "user-bookmarks"

class TrackerTagObjectsSource (Source):
	"""This source shows all items of one tracker tag"""
	def __init__(self, tag):
		Source.__init__(self, _("Tag %s") % tag)
		self.tag = tag
	def is_dynamic(self):
		return True
	def get_items(self):
		return (ConstructFileLeaf(f) for f in get_tracker_tag_items(self.tag))
	def get_description(self):
		return _("Objects tagged %s with Tracker") % self.tag
	def get_icon_name(self):
		return "user-bookmarks"

class TrackerAddTag (Action):
	""" Add tracker tags.

	FIXME: Only tracker-indexed directories can be tagged
	I don't know how to check that effectively. 
	So we allow everything here
	"""
	def __init__(self):
		Action.__init__(self, _("Add Tag..."))
	def activate(self, leaf, obj):
		lpath = leaf.object
		tag = obj.object
		utils.spawn_async(["tracker-tag", "--add=%s" % tag, lpath])

	def requires_object(self):
		return True

	def item_types(self):
		yield FileLeaf
	def object_types(self):
		yield TextLeaf
		yield TrackerTag

	def object_source(self, for_item=None):
		# FIXME: We list all tags. We don't want to list tags it already has
		return TrackerFileTagsSource()

	def valid_object(self, obj, for_item):
		if isinstance(obj, TextLeaf):
			# FIXME: Do tag syntax checking here
			return (u" " not in obj.object)
		return True

	def get_description(self):
		return _("Add tracker tag to file")
	def get_icon_name(self):
		return "list-add"

class TrackerRemoveTag (Action):
	def __init__(self):
		Action.__init__(self, _("Remove Tag..."))
	def activate(self, leaf, obj):
		lpath = leaf.object
		tag = obj.object
		utils.spawn_async(["tracker-tag", "--remove=%s" % tag, lpath])

	def requires_object(self):
		return True

	def item_types(self):
		yield FileLeaf
	def object_types(self):
		yield TrackerTag

	def object_source(self, for_item):
		path = for_item.object
		return TrackerFileTagsSource(path)

	def get_description(self):
		return _("Remove tracker tag from file")
	def get_icon_name(self):
		return "list-remove"


########NEW FILE########
__FILENAME__ = _ssl
"""
Implement SSL Support in Kupfer using Python's 'ssl' module.
This plugin is named to be loaded first of all if it is activated.

This extension is not part of Kupfer itself because OpenSSL (Python's 'ssl')
is incompatible with the GNU GPLv3, even if both a open source. There is
nothing prohibiting a user to use this plugin.
"""
__kupfer_name__ = _("SSL Support")
__description__ = _("Enable OpenSSL support in Kupfer.")
__version__ = ""
__author__ = ""

import sys
from kupfer import pretty

# unblock openssl modules
for modname in ['ssl', '_ssl']:
	if sys.modules.get(modname, 1) is None:
		pretty.print_debug(__name__, "Unblocking module '%s'" % modname)
		del sys.modules[modname]

try:
	import ssl
except ImportError:
	ssl = None

import httplib

from kupfer import pretty

__all__ = ['VerifiedHTTPSConnection']


if ssl:
	# NOTE: Below we use inline imports so that the class is
	#       transferrable to another module without dependencies on
	#       module-globals!
	class VerifiedHTTPSConnection(httplib.HTTPConnection):
		"""
		Raises RuntimeError if SSL is not supported
		"""
		default_port = 443
		CA_CERT_LOCATIONS = (
			"/etc/ssl/certs/ca-certificates.crt", # Debian
			"/etc/pki/tls/certs/ca-bundle.crt",   # Red Hat
		)
		use_certificate_file = None

		def __init__(self, *args, **kwargs):
			import httplib
			if not self.is_ssl_supported():
				raise RuntimeError("SSL not supported")
			self.key_file = None
			self.cert_file = None
			httplib.HTTPConnection.__init__(self, *args, **kwargs)

		def connect(self):
			import ssl
			import socket
			sock = socket.create_connection((self.host, self.port),self.timeout)
			if self._tunnel_host:
				self.sock = sock
				self._tunnel()
			# wrap the socket using verification with the root
			self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file,
				 cert_reqs=ssl.CERT_REQUIRED, ca_certs=self.use_certificate_file)

		@classmethod
		def is_ssl_supported(cls):
			import os
			from kupfer import pretty

			if cls.use_certificate_file is not None:
				return True
			for caf in cls.CA_CERT_LOCATIONS:
				if os.path.exists(caf):
					cls.use_certificate_file = caf
					pretty.print_debug(__name__, "Using CA Certificates file", caf)
					return True
			pretty.print_error(__name__, "SSL Error: No CA Certificates file found")
			return False

from kupfer.plugin import ssl_support
# "install" into kupfer.plugin.ssl_support
for x in __all__:
	setattr(ssl_support, x, globals().get(x,None))


########NEW FILE########
__FILENAME__ = debug
"""
Debugging routines, can only be used when Kupfer is run from the Source
directory.
"""

import atexit

def mem_stats():
	import gc
	print "DEBUG: OBJ STATS"

	print "enabled:", gc.isenabled()
	print "objs", len(gc.get_objects())
	print "collected (now)", gc.collect()

	# after collection
	hist = {}
	for obj in gc.get_objects():
		key = str(type(obj))
		if key not in hist:
			hist[key] =1
		else:
			hist[key] += 1
	
	best = hist.items()
	best.sort(key=lambda x:x[1], reverse=True)
	print "\n".join("%s: %d" % (k,v) for k,v in best[:10])

	our = []
	gtk = []
	for item in best:
		if "objects." in item[0] or "kupfer." in item[0]:
			our.append(item)
		if "gtk" in item[0]:
			gtk.append(item)
	
	#print "---just gtk (top)"
	#print "\n".join("%s: %d" % (k,v) for k,v in gtk[:10])
	print "---Just our objects (all > 1)"
	print "\n".join("%s: %d" % (k,v) for k,v in our if v > 1)

def make_histogram(vect, nbins=7):
	"""make a histogram out of @vect"""
	mi,ma = 0, max(vect)
	bins = [0]*nbins
	bin_size = ma/nbins + 1
	def brange(i):
		return xrange(i*bin_size, (i+1)*bin_size)
	for acc in vect:
		for i in xrange(nbins):
			if acc in brange(i):
				bins[i] += 1
				break
	# headers
	print " ".join("%10s" % ("[%2d, %2d)" % (min(brange(i)), max(brange(i))),) for i in xrange(nbins))
	print " ".join("%10d" % bins[i] for i in xrange(nbins))
	

def icon_stats():
	from kupfer.icons import icon_cache
	print "DEBUG: ICON STATS"

	c = 0
	tot_acc = 0
	tot_pix = 0
	acc_vect = []
	for size in icon_cache:
		for k in icon_cache[size]:
			rec = icon_cache[size][k]
			acc = rec["accesses"]
			acc_vect.append(acc)
			if not acc:
				c += 1
			tot_acc += acc
			icon = rec["icon"]
			tot_pix += icon.get_height() * icon.get_width()
		print "Cached icons:",  len(icon_cache[size])
		print "Unused cache entries", c
		print "Total accesses", tot_acc
		print make_histogram(acc_vect)
		print "Sum pixels", tot_pix
		print "Cached icon keys:"
		for k in sorted(icon_cache[size],
				key=lambda k: icon_cache[size][k]["accesses"]):
			print k, icon_cache[size][k]["accesses"]

def install():
	"""Install atexit handlers for debug information"""
	atexit.register(mem_stats)
	#atexit.register(icon_stats)

########NEW FILE########
__FILENAME__ = config
"""
Module for confiugration and misc things
"""

import xdg.BaseDirectory as base
import os

PACKAGE_NAME="kupfer"

class ResourceLookupError (StandardError):
	pass

def has_capability(cap):
	return not bool(os.getenv("KUPFER_NO_%s" % cap, False))

def get_cache_home():
	"""
	Directory where cache files should be put
	Guaranteed to exist
	"""
	cache_home = base.xdg_cache_home or os.path.expanduser("~/.cache")
	cache_dir = os.path.join(cache_home, PACKAGE_NAME)
	if not os.path.exists(cache_dir):
		try:
			os.makedirs(cache_dir, mode=0700)
		except OSError, e:
			print e
			return None
	return cache_dir

def get_cache_file(path=()):
	cache_home = base.xdg_cache_home or os.path.expanduser("~/.cache")
	cache_dir = os.path.join(cache_home, *path)
	if not os.path.exists(cache_dir):
		return None
	return cache_dir

def get_data_file(filename, package=PACKAGE_NAME):
	"""
	Return path to @filename if it exists
	anywhere in the data paths, else raise ResourceLookupError.
	"""
	data_paths = []
	try:
		from . import version_subst
	except ImportError:
		first_datadir = "./data"
	else:
		first_datadir = os.path.join(version_subst.DATADIR, package)

	data_paths.append(first_datadir)
	for data_path in base.load_data_paths(package):
		if not data_path in data_paths:
			data_paths.append(data_path)

	for direc in data_paths:
		file_path = os.path.join(direc, filename)
		if os.path.exists(file_path):
			return file_path
	if package == PACKAGE_NAME:
		raise ResourceLookupError("Resource %s not found" % filename)
	else:
		raise ResourceLookupError("Resource %s in package %s not found" %
			(filename, package))

def save_data_file(filename):
	"""
	Return filename in the XDG data home directory, where the
	directory is guaranteed to exist
	"""
	direc = base.save_data_path(PACKAGE_NAME)
	if not direc:
		return None
	filepath = os.path.join(direc, filename)
	return filepath

def get_data_home():
	"""
	Directory where data is to be saved
	Guaranteed to exist
	"""
	return base.save_data_path(PACKAGE_NAME)

def get_data_dirs(name="", package=PACKAGE_NAME):
	"""
	Iterate over all data dirs of @name that exist
	"""
	return base.load_data_paths(os.path.join(package, name))

def get_config_file(filename, package=PACKAGE_NAME):
	"""
	Return path to @package/@filename if it exists anywhere in the config
	paths, else return None
	"""
	return base.load_first_config(package, filename)

def get_config_files(filename):
	"""
	Iterator to @filename in all
	config paths, with most important (takes precendence)
	files first
	"""
	return base.load_config_paths(PACKAGE_NAME, filename) or ()

def save_config_file(filename):
	"""
	Return filename in the XDG data home directory, where the
	directory is guaranteed to exist
	"""
	direc = base.save_config_path(PACKAGE_NAME)
	if not direc:
		return None
	filepath = os.path.join(direc, filename)
	return filepath

########NEW FILE########
__FILENAME__ = conspickle
import fnmatch
import io
import pickle
import sys

class universalset (object):
	def __contains__(self, item):
		return True

class ConservativeUnpickler (pickle.Unpickler):
	"""An Unpickler that refuses to import new modules

	>>> import pickle

	>>> import kupfer.objects
	>>> ConservativeUnpickler.loads(pickle.dumps(kupfer.objects.FileLeaf("A")))
	<builtin.FileLeaf A>

	>>> ConservativeUnpickler.loads(pickle.dumps(eval))
	Traceback (most recent call last):
	    ...
	UnpicklingError: Refusing unsafe __builtin__.eval

	>>> import sys
	>>> import kupfer.obj.base
	>>> pdata = pickle.dumps(kupfer.obj.base.Leaf(1, "A"))
	>>> del sys.modules["kupfer.obj.base"]
	>>> ConservativeUnpickler.loads(pdata)
	Traceback (most recent call last):
	    ...
	UnpicklingError: Refusing to load module kupfer.obj.base
	"""
	safe_modules = {
		"__builtin__" : set(["set", "sum", "object"]),
		"copy_reg" : set(["_reconstructor"]),
		"kupfer.*" : universalset(),
	}
	@classmethod
	def is_safe_symbol(cls, module, name):
		for pattern in cls.safe_modules:
			if fnmatch.fnmatchcase(module, pattern):
				return name in cls.safe_modules[pattern]
		return False

	def find_class(self, module, name):
		if module not in sys.modules:
			raise pickle.UnpicklingError("Refusing to load module %s" % module)
		if not self.is_safe_symbol(module, name):
			raise pickle.UnpicklingError("Refusing unsafe %s.%s" % (module, name))
		return pickle.Unpickler.find_class(self, module, name)

	@classmethod
	def loads(cls, pickledata):
		unpickler = cls(io.BytesIO(pickledata))
		return unpickler.load()

class BasicUnpickler (ConservativeUnpickler):
	"""An Unpickler that can only unpickle persistend ids and select builtins

	>>> import pickle

	>>> import kupfer.objects
	>>> BasicUnpickler.loads(pickle.dumps(kupfer.objects.FileLeaf("A")))
	Traceback (most recent call last):
	    ...
	UnpicklingError: Refusing unsafe kupfer.obj.objects.FileLeaf
	"""

	safe_modules = {
		"__builtin__" : set(["object"]),
		"copy_reg" : set(["_reconstructor"]),
		"kupfer.puid" : set(["SerializedObject"]),
	}

if __name__ == '__main__':
	import doctest
	doctest.testmod()

########NEW FILE########
__FILENAME__ = actioncompat

def _get_leaf_members(leaf):
	"""
	Return an iterator to members of @leaf, if it is a multiple leaf
	"""
	try:
		return leaf.get_multiple_leaf_representation()
	except AttributeError:
		return (leaf, )

def action_valid_for_item(action, leaf):
	return all(action.valid_for_item(L) for L in _get_leaf_members(leaf))

def actions_for_item(leaf, sourcecontroller):
	if leaf is None:
		return []
	actions = None
	for L in _get_leaf_members(leaf):
		l_actions = set(L.get_actions())
		l_actions.update(sourcecontroller.get_actions_for_leaf(L))
		if actions is None:
			actions = l_actions
		else:
			actions.intersection_update(l_actions)
	return actions

def iobject_source_for_action(action, for_item):
	for leaf in _get_leaf_members(for_item):
		return action.object_source(leaf)

def iobjects_valid_for_action(action, for_item):
	"""
	Return a filtering *function* that will let through
	those leaves that are good iobjects for @action and @for_item.
	"""
	def valid_object(leaf, for_item):
		_valid_object = action.valid_object
		for L in _get_leaf_members(leaf):
			for I in _get_leaf_members(for_item):
				if not _valid_object(L, for_item=I):
					return False
		return True

	types = tuple(action.object_types())
	def type_obj_check(iobjs):
		for i in iobjs:
			if (isinstance(i, types) and valid_object(i, for_item=for_item)):
				yield i
	def type_check(itms):
		for i in itms:
			if isinstance(i, types):
				yield i

	if hasattr(action, "valid_object"):
		return type_obj_check
	else:
		return type_check


########NEW FILE########
__FILENAME__ = commandexec
"""
The main logic for executing constructed commands.

A command is normally a tuple of (object, action, indirect object).
Where, of course, the indirect object is often not needed (in this module we
then pass None in its stead).

This code was once a shining machine; While adding the "comma trick" and
support for "multiple dispatch" was easy in the rest of the program, it shed
its casualties here: While the main process is simple, we deal here with all
the exceptions that are, at the moment, tacked on.

The ActionExecutionContext (ACE) keeps track of its nested invocation, so that
we can catch the results of commands executed inside other commands. The
delegation mechanism allows a user of the ACE to indicate that the result of
the command should be passed on from the earlier (more nested) invocation.

Multiple dispatch is straightforward if the action implements the multiple
dispatch protocol. Is the protocol not implemented, the command is simply
"multiplied out": executed once for each object, or once for each combination
of object and indirect object.

With multiple command execution (and delegation), we must then process and
merge multiple return values.
"""
from __future__ import with_statement

import collections
import contextlib
import itertools
import sys

import gobject

from kupfer import pretty
from kupfer import task
from kupfer import uiutils
from kupfer.objects import OperationError
from kupfer.obj.objects import SourceLeaf
from kupfer.obj.sources import MultiSource
from kupfer.obj.compose import MultipleLeaf

RESULT_NONE, RESULT_OBJECT, RESULT_SOURCE, RESULT_ASYNC = (1, 2, 3, 4)
RESULTS_SYNC = (RESULT_OBJECT, RESULT_SOURCE)

_MAX_LAST_RESULTS = 10

_action_exec_context = None
def DefaultActionExecutionContext():
	global _action_exec_context
	if _action_exec_context is None:
		_action_exec_context = ActionExecutionContext()
	return _action_exec_context

class ActionExecutionError (Exception):
	pass

def _get_leaf_members(leaf):
	"""
	Return an iterator to members of @leaf, if it is a multiple leaf
	"""
	# NOTE : This function duplicates one in core/actionlogic.py
	try:
		return leaf.get_multiple_leaf_representation()
	except AttributeError:
		return (leaf, )

def _is_multiple(leaf):
	return hasattr(leaf, "get_multiple_leaf_representation")

def _wants_context(action):
	return action.wants_context()

def activate_action(context, obj, action, iobj):
	""" Activate @action in simplest manner """
	kwargs = {}
	if _wants_context(action):
		kwargs['ctx'] = context
	if not _is_multiple(obj) and not _is_multiple(iobj):
		return _activate_action_single(obj, action, iobj, kwargs)
	else:
		return _activate_action_multiple(obj, action, iobj, kwargs)

def _activate_action_single(obj, action, iobj, kwargs):
	if action.requires_object():
		ret = action.activate(obj, iobj, **kwargs)
	else:
		ret = action.activate(obj, **kwargs)
	return ret

def _activate_action_multiple(obj, action, iobj, kwargs):
	if not hasattr(action, "activate_multiple"):
		iobjs = (None, ) if iobj is None else _get_leaf_members(iobj)
		return _activate_action_multiple_multiplied(_get_leaf_members(obj),
				action, iobjs, kwargs)

	if action.requires_object():
		ret = action.activate_multiple(_get_leaf_members(obj),
				_get_leaf_members(iobj), **kwargs)
	else:
		ret = action.activate_multiple(_get_leaf_members(obj), **kwargs)
	return ret

def _activate_action_multiple_multiplied(objs, action, iobjs, kwargs):
	"""
	Multiple dispatch by "mulitplied" invocation of the simple activation

	Return an iterable of the return values.
	"""
	rets = []
	for L in objs:
		for I in iobjs:
			ret = _activate_action_single(L, action, I, kwargs)
			rets.append(ret)
	ctx = DefaultActionExecutionContext()
	ret = ctx._combine_action_result_multiple(action, rets)
	return ret

def parse_action_result(action, ret):
	"""Return result type for @action and return value @ret"""
	def valid_result(ret):
		return ret and (not hasattr(ret, "is_valid") or ret.is_valid())

	# handle actions returning "new contexts"
	res = RESULT_NONE
	if action.is_factory() and valid_result(ret):
		res = RESULT_SOURCE
	if action.has_result() and valid_result(ret):
		res = RESULT_OBJECT
	elif action.is_async() and valid_result(ret):
		res = RESULT_ASYNC
	return res

class ExecutionToken (object):
	"""
	A token object that an ``Action`` carries with it
	from ``activate``.

	Must be used for access to current execution context,
	and to access the environment.
	"""
	def __init__(self, aectx, async_token, ui_ctx):
		self._aectx = aectx
		self._token = async_token
		self._ui_ctx = ui_ctx

	def register_late_result(self, result_object, show=True):
		self._aectx.register_late_result(self._token, result_object, show=show,
		                                 ctxenv=self._ui_ctx)

	def register_late_error(self, exc_info=None):
		self._aectx.register_late_error(self._token, exc_info)

	def delegated_run(self, *objs):
		return self._aectx.run(*objs, delegate=True, ui_ctx=self._ui_ctx)

	@property
	def environment(self):
		"""This is a property for the current environment,
		acess env variables like this::

			ctx.environment.get_timestamp()

		Raises RuntimeError when not available.
		"""
		if self._ui_ctx is not None:
			return self._ui_ctx
		else:
			raise RuntimeError("Environment Context not available")

class ActionExecutionContext (gobject.GObject, pretty.OutputMixin):
	"""
	command-result (result_type, result)
		Emitted when a command is carried out, with its resulting value
	"""
	__gtype_name__ = "ActionExecutionContext"
	def __init__(self):
		gobject.GObject.__init__(self)
		self.task_runner = task.TaskRunner(end_on_finish=False)
		self._nest_level = 0
		self._delegate = False
		self._command_counter = itertools.count()
		self.last_command_id = -1
		self.last_command = None
		self.last_executed_command = None
		self.last_results = collections.deque([], _MAX_LAST_RESULTS)

	def check_valid(self, obj, action, iobj):
		pass

	@contextlib.contextmanager
	def _nesting(self):
		try:
			self._nest_level += 1
			self._delegate = False
			yield
		finally:
			self._nest_level -= 1

	def _is_nested(self):
		return self._nest_level

	@contextlib.contextmanager
	def _error_conversion(self, *cmdtuple):
		try:
			yield
		except OperationError:
			self._do_error_conversion(cmdtuple, sys.exc_info())

	def _do_error_conversion(self, cmdtuple, exc_info):
		if not self.operation_error(exc_info, cmdtuple):
			raise
		etype, value, tb = exc_info
		raise ActionExecutionError, value, tb

	def get_async_token(self):
		"""Get an action execution for current execution

		Return a token for the currently active command execution.
		The token must be used for posting late results or late errors.
		"""
		return (self.last_command_id, self.last_executed_command)

	def make_execution_token(self, ui_ctx):
		"""
		Return an ExecutionToken for @self and @ui_ctx
		"""
		return ExecutionToken(self, self.get_async_token(), ui_ctx)

	def operation_error(self, exc_info, cmdtuple):
		"Error when executing action. Return True when error was handled"
		if self._is_nested():
			return
		etype, value, tb = exc_info
		obj, action, iobj = cmdtuple
		# TRANS: When an error occurs in an action to be carried out,
		# TRANS: then this is the heading of the error notification
		return uiutils.show_notification(
				_("Could not to carry out '%s'") % action,
				unicode(value), icon_name="kupfer")

	def register_late_error(self, token, exc_info=None):
		"Register an error in exc_info. The error must be an OperationError"
		if exc_info is None:
			exc_info = sys.exc_info()
		if isinstance(exc_info, Exception):
			exc_info = (type(exc_info), exc_info, None)
		command_id, cmdtuple = token
		self._do_error_conversion(cmdtuple, exc_info)

	def register_late_result(self, token, result, show=True, ctxenv=None):
		"""Register a late result

		Result must be a Leaf (as in result object, not factory or async)

		If @show, possibly display the result to the user.
		"""
		self.output_debug("Late result", repr(result), "for", token)
		command_id, (_ign1, action, _ign2) = token
		if result is None:
			raise ActionExecutionError("Late result from %s was None" % action)
		res_name = unicode(result)
		res_desc = result.get_description()
		if res_desc:
			description = "%s (%s)" % (res_name, res_desc)
		else:
			description = res_name
		uiutils.show_notification(_('"%s" produced a result') % action,
				description)

		# If only registration was requsted, remove the command id info
		if not show:
			command_id = -1
		self.emit("late-command-result", command_id, RESULT_OBJECT, result,
		                                 ctxenv)
		self._append_result(RESULT_OBJECT, result)

	def _append_result(self, res_type, result):
		if res_type == RESULT_OBJECT:
			self.last_results.append(result)

	def run(self, obj, action, iobj, delegate=False, ui_ctx=None):
		"""
		Activate the command (obj, action, iobj), where @iobj may be None

		Return a tuple (DESCRIPTION; RESULT)

		If a command carries out another command as part of its execution,
		and wishes to delegate to it, pass True for @delegate.
		"""
		self.last_command_id = self._command_counter.next()
		self.last_executed_command = (obj, action, iobj)

		if not action or not obj:
			raise ActionExecutionError("Primary Object and Action required")
		if iobj is None and action.requires_object():
			raise ActionExecutionError("%s requires indirect object" % action)

		# The execution token object for the current invocation
		execution_token = self.make_execution_token(ui_ctx)
		with self._error_conversion(obj, action, iobj):
			with self._nesting():
				ret = activate_action(execution_token, obj, action, iobj)

		# remember last command, but not delegated commands.
		if not delegate:
			self.last_command = self.last_executed_command

		# Delegated command execution was previously requested: we take
		# the result of the nested execution context
		if self._delegate:
			res, ret = ret
			return self._return_result(res, ret, ui_ctx)

		res = parse_action_result(action, ret)
		if res == RESULT_ASYNC:
			# Register the task then "clear" the result
			self.output_debug("Registering async task", ret)
			self.task_runner.add_task(ret)
			res, ret = RESULT_NONE, None

		# Delegated command execution was requested: we pass
		# through the result of the action to the parent execution context
		if delegate and self._is_nested():
			self._delegate = True

		return self._return_result(res, ret, ui_ctx)

	def _return_result(self, res, ret, ui_ctx):
		if not self._is_nested():
			self._append_result(res, ret)
			self.emit("command-result", res, ret, ui_ctx)
		return res, ret


	def _combine_action_result_multiple(self, action, retvals):
		self.output_debug("Combining", repr(action), retvals,
				"delegate=%s" % self._delegate)

		def _make_retvalue(res, values):
			"Construct a return value for type res"
			if res == RESULT_SOURCE:
				return values[0] if len(values) == 1 else MultiSource(values)
			if res == RESULT_OBJECT:
				return values[0] if len(values) == 1 else MultipleLeaf(values)
			if res == RESULT_ASYNC:
				# Register all tasks now, and return None upwards
				for task in values:
					self.output_debug("Registering async task", task)
					self.task_runner.add_task(task)
			return None

		if not self._delegate:
			values = []
			res = RESULT_NONE
			for ret in retvals:
				res_type = parse_action_result(action, ret)
				if res_type != RESULT_NONE:
					values.append(ret)
					res = res_type
			return _make_retvalue(res, values)
		else:
			# Re-parse result values
			res = RESULT_NONE
			resmap = {}
			for ret in retvals:
				if ret is None:
					continue
				res_type, ret_obj = ret
				if res_type != RESULT_NONE:
					res = res_type
					resmap.setdefault(res_type, []).append(ret_obj)

			# register tasks
			tasks = resmap.pop(RESULT_ASYNC, [])
			_make_retvalue(RESULT_ASYNC, tasks)

			if len(resmap) == 1:
				# Return the only of the Source or Object case
				key, values = resmap.items()[0]
				return key, _make_retvalue(key, values)
			elif len(resmap) > 1:
				# Put the source in a leaf and return a multiple leaf
				source = _make_retvalue(RESULT_SOURCE, resmap[RESULT_SOURCE])
				objects = resmap[RESULT_OBJECT]
				objects.append(SourceLeaf(source))
				return RESULT_OBJECT, _make_retvalue(RESULT_OBJECT, objects)
			return RESULT_NONE, None


# Signature: Action result type, action result, gui_context
gobject.signal_new("command-result", ActionExecutionContext,
		gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN,
		(gobject.TYPE_INT, gobject.TYPE_PYOBJECT, gobject.TYPE_PYOBJECT))

# Signature: Command ID, Action result type, action result, gui_context
gobject.signal_new("late-command-result", ActionExecutionContext,
		gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN,
		(gobject.TYPE_INT, gobject.gobject.TYPE_INT,
			gobject.TYPE_PYOBJECT, gobject.TYPE_PYOBJECT))

########NEW FILE########
__FILENAME__ = data
from __future__ import with_statement

import itertools
import operator
import os
import sys

import gobject
gobject.threads_init()

from kupfer.obj import base, sources, compose
from kupfer import pretty, scheduler
from kupfer import datatools
from kupfer.core import actioncompat
from kupfer.core import commandexec
from kupfer.core import execfile
from kupfer.core import pluginload
from kupfer.core import qfurl
from kupfer.core import search, learn
from kupfer.core import settings

from kupfer.core.sources import GetSourceController

# "Enums"
# Which pane
SourcePane, ActionPane, ObjectPane = (1,2,3)

# In two-pane or three-pane mode
SourceActionMode, SourceActionObjectMode = (1,2)

DATA_SAVE_INTERVAL_S = 3660

def identity(x):
	return x

def is_iterable(obj):
	return hasattr(obj, "__iter__")

def dress_leaves(seq, action):
	"""yield items of @seq "dressed" by the source controller"""
	sc = GetSourceController()
	for itm in seq:
		sc.decorate_object(itm.object, action=action)
		yield itm

def peekfirst(seq):
	"""This function will return (firstitem, iter)
	where firstitem is the first item of @seq or None if empty,
	and iter an equivalent copy of @seq
	"""
	seq = iter(seq)
	for itm in seq:
		old_iter = itertools.chain((itm, ), seq)
		return (itm, old_iter)
	return (None, seq)

class Searcher (object):
	"""
	This class searches KupferObjects efficiently, and
	stores searches in a cache for a very limited time (*)

	(*) As of this writing, the cache is used when the old key
	is a prefix of the search key.
	"""

	def __init__(self):
		self._source_cache = {}
		self._old_key = None

	def search(self, sources, key, score=True, item_check=None, decorator=None):
		"""
		@sources is a sequence listing the inputs, which should be
		Sources, TextSources or sequences of KupferObjects

		If @score, sort by rank.
		filters (with identity() as default):
			@item_check: Check items before adding to search pool
			@decorator: Decorate items before access

		Return (first, match_iter), where first is the first match,
		and match_iter an iterator to all matches, including the first match.
		"""
		if not self._old_key or not key.startswith(self._old_key):
			self._source_cache.clear()
		self._old_key = key

		if not item_check: item_check = identity
		if not decorator: decorator = identity

		match_iters = []
		for src in sources:
			fixedrank = 0
			can_cache = True
			rankables = None
			if is_iterable(src):
				items = item_check(src)
				can_cache = False
			else:
				# Look in source cache for stored rankables
				try:
					rankables = self._source_cache[src]
				except KeyError:
					try:
						items = item_check(src.get_text_items(key))
						fixedrank = src.get_rank()
						can_cache = False
					except AttributeError:
						items = item_check(src.get_leaves())

			if not rankables:
				rankables = search.make_rankables(items)

			if score:
				if fixedrank:
					rankables = search.add_rank_objects(rankables, fixedrank)
				elif key:
					rankables = search.score_objects(rankables, key)
				matches = search.bonus_objects(rankables, key)
				if can_cache:
					# we fork off a copy of the iterator to save
					matches, self._source_cache[src] = itertools.tee(matches)
			else:
				# we only want to list them
				matches = rankables

			match_iters.append(matches)
		
		matches = itertools.chain(*match_iters)
		if score:
			matches = sorted(matches, key=operator.attrgetter("rank"),
					reverse=True)

		def as_set_iter(seq):
			key = operator.attrgetter("object")
			return datatools.UniqueIterator(seq, key=key)

		def valid_check(seq):
			"""yield items of @seq that are valid"""
			for itm in seq:
				obj = itm.object
				if (not hasattr(obj, "is_valid")) or obj.is_valid():
					yield itm

		# Check if the items are valid as the search
		# results are accessed through the iterators
		unique_matches = as_set_iter(matches)
		match, match_iter = peekfirst(decorator(valid_check(unique_matches)))
		return match, match_iter

	def rank_actions(self, objects, key, leaf, item_check=None, decorator=None):
		"""
		rank @objects, which should be a sequence of KupferObjects,
		for @key, with the action ranker algorithm.

		@leaf is the Leaf the action is going to be invoked on

		Filters and return value like .score().
		"""
		if not item_check: item_check = identity
		if not decorator: decorator = identity

		rankables = search.make_rankables(item_check(objects))
		if key:
			rankables = search.score_objects(rankables, key)
			matches = search.bonus_objects(rankables, key)
		else:
			matches = search.score_actions(rankables, leaf)
		matches = sorted(matches, key=operator.attrgetter("rank"), reverse=True)

		match, match_iter = peekfirst(decorator(matches))
		return match, match_iter

class Pane (gobject.GObject):
	"""
	signals:
		search-result (match, match_iter, context)
	"""
	__gtype_name__ = "Pane"
	def __init__(self):
		super(Pane, self).__init__()
		self.selection = None
		self.latest_key = None
		self.outstanding_search = -1
		self.outstanding_search_id = -1
		self.searcher = Searcher()

	def select(self, item):
		self.selection = item
	def get_selection(self):
		return self.selection
	def reset(self):
		self.selection = None
	def get_latest_key(self):
		return self.latest_key
	def get_can_enter_text_mode(self):
		return False
	def get_should_enter_text_mode(self):
		return False
	def emit_search_result(self, match, match_iter, context):
		self.emit("search-result", match, match_iter, context)

gobject.signal_new("search-result", Pane, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN, (gobject.TYPE_PYOBJECT, gobject.TYPE_PYOBJECT, 
		gobject.TYPE_PYOBJECT))

class LeafPane (Pane, pretty.OutputMixin):
	__gtype_name__ = "LeafPane"

	def __init__(self):
		super(LeafPane, self).__init__()
		self.source_stack = []
		self.source = None
		self.object_stack = []

	def _load_source(self, src):
		"""Try to get a source from the SourceController,
		if it is already loaded we get it from there, else
		returns @src"""
		sc = GetSourceController()
		return sc.get_canonical_source(src)

	def get_source(self):
		return self.source

	def source_rebase(self, src):
		self.source_stack = []
		self.source = self._load_source(src)
		self.refresh_data()

	def push_source(self, src):
		self.source_stack.append(self.source)
		self.source = self._load_source(src)
		self.refresh_data()

	def pop_source(self):
		"""Return True if succeeded"""
		if not len(self.source_stack):
			return False
		self.source = self.source_stack.pop()
		return True

	def is_at_source_root(self):
		"""Return True if we have no source stack"""
		return not self.source_stack

	def object_stack_push(self, obj):
		self.object_stack.append(obj)

	def object_stack_pop(self):
		return self.object_stack.pop()

	def get_can_enter_text_mode(self):
		return self.is_at_source_root()

	def get_should_enter_text_mode(self):
		return False

	def refresh_data(self):
		self.emit("new-source", self.source)

	def browse_up(self):
		"""Try to browse up to previous sources, from current
		source"""
		succ = self.pop_source()
		if not succ:
			if self.source.has_parent():
				self.source_rebase(self.source.get_parent())
				succ = True
		if succ:
			self.refresh_data()
		return succ

	def browse_down(self, alternate=False):
		"""Browse into @leaf if it's possible
		and save away the previous sources in the stack
		if @alternate, use the Source's alternate method"""
		leaf = self.get_selection()
		if leaf and leaf.has_content():
			self.push_source(leaf.content_source(alternate=alternate))
			return True
		return False

	def reset(self):
		"""Pop all sources and go back to top level"""
		Pane.reset(self)
		while self.pop_source():
			pass
		self.refresh_data()

	def soft_reset(self):
		Pane.reset(self)
		while self.pop_source():
			pass
		return self.source

	def search(self, key=u"", context=None, text_mode=False):
		"""
		filter for action @item
		"""
		self.latest_key = key
		sources = [ self.get_source() ] if not text_mode else []
		if key and self.is_at_source_root():
			# Only use text sources when we are at root catalog
			sc = GetSourceController()
			textsrcs = sc.get_text_sources()
			sources.extend(textsrcs)

		decorator = lambda seq: dress_leaves(seq, action=None)
		match, match_iter = self.searcher.search(sources, key, score=bool(key),
				decorator=decorator)
		self.emit_search_result(match, match_iter, context)

gobject.signal_new("new-source", LeafPane, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN, (gobject.TYPE_PYOBJECT,))

class PrimaryActionPane (Pane):
	def __init__(self):
		super(PrimaryActionPane, self).__init__()
		self.set_item(None)

	def set_item(self, item):
		"""Set which @item we are currently listing actions for"""
		self.current_item = item
		self._action_valid_cache = {}

	def search(self, key=u"", context=None, text_mode=False):
		"""Search: Register the search method in the event loop

		using @key, promising to return
		@context in the notification about the result, having selected
		@item in SourcePane

		If we already have a call to search, we remove the "source"
		so that we always use the most recently requested search."""

		self.latest_key = key
		leaf = self.current_item
		actions = actioncompat.actions_for_item(leaf, GetSourceController())

		def is_valid_cached(action):
			"""Check if @action is valid for current item"""
			cache = self._action_valid_cache
			valid = cache.get(action)
			if valid is None:
				valid = actioncompat.action_valid_for_item(action, leaf)
				cache[action] = valid
			return valid

		def valid_decorator(seq):
			"""Check if actions are valid before access"""
			for obj in seq:
				if is_valid_cached(obj.object):
					yield obj

		match, match_iter = self.searcher.rank_actions(actions, key, leaf,
				decorator=valid_decorator)
		self.emit_search_result(match, match_iter, context)

class SecondaryObjectPane (LeafPane):
	__gtype_name__ = "SecondaryObjectPane"
	def __init__(self):
		LeafPane.__init__(self)
		self.current_item = None
		self.current_action = None

	def reset(self):
		LeafPane.reset(self)
		self.searcher = Searcher()

	def set_item_and_action(self, item, act):
		self.current_item = item
		self.current_action = act
		if item and act:
			ownsrc = actioncompat.iobject_source_for_action(act, item)
			if ownsrc:
				self.source_rebase(ownsrc)
			else:
				sc = GetSourceController()
				self.source_rebase(sc.root_for_types(act.object_types()))
		else:
			self.reset()

	def get_can_enter_text_mode(self):
		"""Check if there are any reasonable text sources for this action"""
		atroot = self.is_at_source_root()
		types = tuple(self.current_action.object_types())
		sc = GetSourceController()
		textsrcs = sc.get_text_sources()
		return (atroot and
			any(sc.good_source_for_types(s, types) for s in textsrcs))

	def get_should_enter_text_mode(self):
		return (self.is_at_source_root() and
		        hasattr(self.get_source(), "get_text_items"))

	def search(self, key=u"", context=None, text_mode=False):
		"""
		filter for action @item
		"""
		self.latest_key = key
		sources = []
		if not text_mode or hasattr(self.get_source(), "get_text_items"):
			sources.append(self.get_source())
		if key and self.is_at_source_root():
			# Only use text sources when we are at root catalog
			sc = GetSourceController()
			textsrcs = sc.get_text_sources()
			sources.extend(textsrcs)

		item_check = actioncompat.iobjects_valid_for_action(self.current_action,
				self.current_item)
		decorator = lambda seq: dress_leaves(seq, action=self.current_action)

		match, match_iter = self.searcher.search(sources, key, score=True,
				item_check=item_check, decorator=decorator)
		self.emit_search_result(match, match_iter, context)

class DataController (gobject.GObject, pretty.OutputMixin):
	"""
	Sources <-> Actions controller

	The data controller must be created before main program commences,
	so it can register itself at the scheduler correctly.
	"""
	__gtype_name__ = "DataController"

	def __init__(self):
		super(DataController, self).__init__()

		self.source_pane = LeafPane()
		self.object_pane = SecondaryObjectPane()
		self.source_pane.connect("new-source", self._new_source)
		self.object_pane.connect("new-source", self._new_source)
		self.action_pane = PrimaryActionPane()
		self._panectl_table = {
			SourcePane : self.source_pane,
			ActionPane : self.action_pane,
			ObjectPane : self.object_pane,
			}
		for pane, ctl in self._panectl_table.items():
			ctl.connect("search-result", self._pane_search_result, pane)
		self.mode = None
		self._search_ids = itertools.count(1)
		self._latest_interaction = -1
		self._execution_context = commandexec.DefaultActionExecutionContext()
		self._execution_context.connect("command-result",
				self._command_execution_result)
		self._execution_context.connect("late-command-result",
				self._late_command_execution_result)

		self._save_data_timer = scheduler.Timer()

		sch = scheduler.GetScheduler()
		sch.connect("load", self._load)
		sch.connect("display", self._display)
		sch.connect("finish", self._finish)

	def register_text_sources(self, plugin_id, srcs):
		"""Pass in text sources as @srcs

		we register text sources """
		sc = GetSourceController()
		sc.add_text_sources(plugin_id, srcs)
	
	def register_action_decorators(self, plugin_id, actions):
		# Keep a mapping: Decorated Leaf Type -> List of actions
		decorate_types = {}
		for action in actions:
			for appl_type in action.item_types():
				decorate_types.setdefault(appl_type, []).append(action)
		if not decorate_types:
			return
		sc = GetSourceController()
		sc.add_action_decorators(plugin_id, decorate_types)

	def register_content_decorators(self, plugin_id, contents):
		"""
		Register the sequence of classes @contents as
		potential content decorators. Classes not conforming to
		the decoration protocol (most importantly, ``.decorates_type()``)
		will be skipped
		"""
		# Keep a mapping:
		# Decorated Leaf Type -> Set of content decorator types
		decorate_item_types = {}
		for c in contents:
			try:
				applies = c.decorates_type()
			except AttributeError:
				continue
			decorate_item_types.setdefault(applies, set()).add(c)
		if not decorate_item_types:
			return
		sc = GetSourceController()
		sc.add_content_decorators(plugin_id, decorate_item_types)

	def register_action_generators(self, plugin_id, generators):
		sc = GetSourceController()
		for generator in generators:
			sc.add_action_generator(plugin_id, generator)

	def _load(self, sched):
		"""Begin Data Controller work when we get application 'load' signal

		Load the data model from saved configuration and caches
		"""
		setctl = settings.GetSettingsController()
		setctl.connect("plugin-enabled-changed", self._plugin_enabled)
		setctl.connect("plugin-toplevel-changed", self._plugin_catalog_changed)

		self._load_all_plugins()
		D_s, d_s = self._get_directory_sources()
		sc = GetSourceController()
		sc.add(None, D_s, toplevel=True)
		sc.add(None, d_s, toplevel=False)
		sc.initialize()
		learn.load()

	def _display(self, sched):
		self._reload_source_root()
		self._save_data_timer.set(DATA_SAVE_INTERVAL_S, self._save_data)

	def _get_directory_sources(self):
		"""
		Return a tuple of S_sources, s_sources for
		directory sources directly included and for
		catalog inclusion respectively
		"""

		s_sources = []
		S_sources = []

		setctl = settings.GetSettingsController()
		source_config = setctl.get_config

		def dir_source(opt):
			return sources.DirectorySource(opt)

		def file_source(opt, depth=1):
			abs = os.path.abspath(os.path.expanduser(opt))
			return sources.FileSource((abs,), depth)

		for coll, direct in zip((s_sources, S_sources), (False, True)):
			for item in setctl.get_directories(direct):
				if not os.path.isdir(item):
					continue
				coll.append(dir_source(item))

		dir_depth = source_config("DeepDirectories", "Depth")

		for item in source_config("DeepDirectories","Catalog"):
			s_sources.append(file_source(item, dir_depth))
		for item in source_config("DeepDirectories", "Direct"):
			S_sources.append(file_source(item, dir_depth))

		return S_sources, s_sources

	def _load_all_plugins(self):
		"""
		Insert all plugin sources into the catalog
		"""
		from kupfer.core import plugins

		setctl = settings.GetSettingsController()
		for item in sorted(plugins.get_plugin_ids()):
			if not setctl.get_plugin_enabled(item):
				continue
			sources = self._load_plugin(item)
			self._insert_sources(item, sources, initialize=False)

	def _load_plugin(self, plugin_id):
		"""
		Load @plugin_id, register all its Actions, Content and TextSources.
		Return its sources.
		"""
		with pluginload.exception_guard(plugin_id):
			plugin = pluginload.load_plugin(plugin_id)
			self.register_text_sources(plugin_id, plugin.text_sources)
			self.register_action_decorators(plugin_id, plugin.action_decorators)
			self.register_content_decorators(plugin_id, plugin.content_decorators)
			self.register_action_generators(plugin_id, plugin.action_generators)
			return set(plugin.sources)
		return set()

	def _plugin_enabled(self, setctl, plugin_id, enabled):
		from kupfer.core import plugins
		if enabled and not plugins.is_plugin_loaded(plugin_id):
			sources = self._load_plugin(plugin_id)
			self._insert_sources(plugin_id, sources, initialize=True)
		elif not enabled:
			self._remove_plugin(plugin_id)

	def _remove_plugin(self, plugin_id):
		sc = GetSourceController()
		if sc.remove_objects_for_plugin_id(plugin_id):
			self._reload_source_root()
		pluginload.remove_plugin(plugin_id)

	def _reload_source_root(self):
		self.output_debug("Reloading source root")
		sc = GetSourceController()
		self.source_pane.source_rebase(sc.root)

	def _plugin_catalog_changed(self, setctl, plugin_id, toplevel):
		self._reload_source_root()

	def _insert_sources(self, plugin_id, sources, initialize=True):
		if not sources:
			return
		sc = GetSourceController()
		setctl = settings.GetSettingsController()
		for src in sources:
			is_toplevel = setctl.get_source_is_toplevel(plugin_id, src)
			sc.add(plugin_id, (src, ), toplevel=is_toplevel,
			       initialize=initialize)
		if initialize:
			self._reload_source_root()

	def _finish(self, sched):
		"Close down the data model, save user data, and write caches to disk"
		GetSourceController().finalize()
		self._save_data(final_invocation=True)
		self.output_info("Saving cache...")
		GetSourceController().save_cache()

	def _save_data(self, final_invocation=False):
		"""Save Learning data and User's configuration data in sources
		(Recurring timer)
		"""
		self.output_info("Saving data...")
		learn.save()
		GetSourceController().save_data()
		if not final_invocation:
			self._save_data_timer.set(DATA_SAVE_INTERVAL_S, self._save_data)

	def _new_source(self, ctr, src):
		if ctr is self.source_pane:
			pane = SourcePane
		elif ctr is self.object_pane:
			pane = ObjectPane
		root = ctr.is_at_source_root()
		self.emit("source-changed", pane, src, root)

	def reset(self):
		self.source_pane.reset()
		self.action_pane.reset()

	def soft_reset(self, pane):
		if pane is ActionPane:
			return
		panectl = self._panectl_table[pane]
		return panectl.soft_reset()

	def cancel_search(self, pane=None):
		"""Cancel any outstanding search, or the search for @pane"""
		panes = (pane, ) if pane else iter(self._panectl_table)
		for pane in panes:
			ctl = self._panectl_table[pane]
			if ctl.outstanding_search > 0:
				gobject.source_remove(ctl.outstanding_search)
				ctl.outstanding_search = -1

	def search(self, pane, key=u"", context=None, interactive=False, lazy=False,
			text_mode=False):
		"""Search: Register the search method in the event loop

		Will search in @pane's base using @key, promising to return
		@context in the notification about the result.

		if @interactive, the search result will return immediately
		if @lazy, will slow down search result reporting
		"""

		self.cancel_search(pane)
		self._latest_interaction = self._execution_context.last_command_id
		ctl = self._panectl_table[pane]
		ctl.outstanding_search_id = self._search_ids.next()
		wrapcontext = (ctl.outstanding_search_id, context)
		if interactive:
			ctl.search(key, wrapcontext, text_mode)
		else:
			timeout = 300 if lazy else 0 if not key else 50//len(key)
			ctl.outstanding_search = gobject.timeout_add(timeout, ctl.search, 
					key, wrapcontext, text_mode)

	def _pane_search_result(self, panectl, match,match_iter, wrapcontext, pane):
		search_id, context = wrapcontext
		if not search_id is panectl.outstanding_search_id:
			self.output_debug("Skipping late search", match, context)
			return True
		self.emit("search-result", pane, match, match_iter, context)

	def select(self, pane, item):
		"""Select @item in @pane to self-update
		relevant places"""
		# If already selected, do nothing
		panectl = self._panectl_table[pane]
		if item == panectl.get_selection():
			return
		self.cancel_search()
		panectl.select(item)
		if pane is SourcePane:
			assert not item or isinstance(item, base.Leaf), \
					"Selection in Source pane is not a Leaf!"
			# populate actions
			citem = self._get_pane_object_composed(self.source_pane)
			self.action_pane.set_item(citem)
			self.search(ActionPane, interactive=True)
			if self.mode == SourceActionObjectMode:
				self.object_stack_clear(ObjectPane)
				self._populate_third_pane()
		elif pane is ActionPane:
			assert not item or isinstance(item, base.Action), \
					"Selection in Source pane is not an Action!"
			self.object_stack_clear(ObjectPane)
			if item and item.requires_object():
				newmode = SourceActionObjectMode
			else:
				newmode = SourceActionMode
			if newmode != self.mode:
				self.mode = newmode
				self.emit("mode-changed", self.mode, item)
			if self.mode == SourceActionObjectMode:
				self._populate_third_pane()
		elif pane is ObjectPane:
			assert not item or isinstance(item, base.Leaf), \
					"Selection in Object pane is not a Leaf!"

	def _populate_third_pane(self):
		citem = self._get_pane_object_composed(self.source_pane)
		action = self.action_pane.get_selection()
		self.object_pane.set_item_and_action(citem, action)
		self.search(ObjectPane, lazy=True)

	def get_can_enter_text_mode(self, pane):
		panectl = self._panectl_table[pane]
		return panectl.get_can_enter_text_mode()

	def get_should_enter_text_mode(self, pane):
		panectl = self._panectl_table[pane]
		return panectl.get_should_enter_text_mode()

	def validate(self):
		"""Check if all selected items are still valid
		(for example after being spawned again, old item
		still focused)

		This will trigger .select() with None if items
		are not valid..
		"""
		def valid_check(obj):
			return not (hasattr(obj, "is_valid") and not obj.is_valid())

		for pane, panectl in self._panectl_table.items():
			sel = panectl.get_selection()
			if not valid_check(sel):
				self.emit("pane-reset", pane, None)
				self.select(pane, None)
			if self._has_object_stack(pane):
				new_stack = [o for o in panectl.object_stack if valid_check(o)]
				if new_stack != panectl.object_stack:
					self._set_object_stack(pane, new_stack)

	def browse_up(self, pane):
		"""Try to browse up to previous sources, from current
		source"""
		if pane is SourcePane:
			return self.source_pane.browse_up()
		if pane is ObjectPane:
			return self.object_pane.browse_up()
	
	def browse_down(self, pane, alternate=False):
		"""Browse into @leaf if it's possible
		and save away the previous sources in the stack
		if @alternate, use the Source's alternate method"""
		if pane is ActionPane:
			return
		# record used object if we browse down
		panectl = self._panectl_table[pane]
		sel, key = panectl.get_selection(), panectl.get_latest_key()
		if panectl.browse_down(alternate=alternate):
			learn.record_search_hit(sel, key)

	def activate(self, ui_ctx):
		"""
		Activate current selection

		@ui_ctx: GUI environment context object
		"""
		leaf, action, sobject = self._get_current_command_objects()

		# register search to learning database
		learn.record_search_hit(leaf, self.source_pane.get_latest_key())
		learn.record_search_hit(action, self.action_pane.get_latest_key())
		if sobject and self.mode is SourceActionObjectMode:
			learn.record_search_hit(sobject, self.object_pane.get_latest_key())

		try:
			ctx = self._execution_context
			res, ret = ctx.run(leaf, action, sobject, ui_ctx=ui_ctx)
		except commandexec.ActionExecutionError:
			self.output_exc()
			return

		if res not in commandexec.RESULTS_SYNC:
			self.emit("launched-action")

	def execute_file(self, filepath, ui_ctx, on_error):
		try:
			cmd_objs = execfile.parse_kfcom_file(filepath)
			ctx = self._execution_context
			ctx.run(*cmd_objs, ui_ctx=ui_ctx)
			return True
		except commandexec.ActionExecutionError:
			self.output_exc()
			return
		except execfile.ExecutionError:
			on_error(sys.exc_info())
			return False

	def _insert_object(self, pane, obj):
		"Insert @obj in @pane: prepare the object, then emit pane-reset"
		self._decorate_object(obj)
		self.emit("pane-reset", pane, search.wrap_rankable(obj))

	def _decorate_object(self, *objects):
		sc = GetSourceController()
		for obj in objects:
			sc.decorate_object(obj)

	def insert_objects(self, pane, objects):
		"Select @objects in @pane"
		if pane != SourcePane:
			raise ValueError("Can only insert in first pane")
		self._decorate_object(objects[:-1])
		self._set_object_stack(pane, objects[:-1])
		self._insert_object(pane, objects[-1])

	def _command_execution_result(self, ctx, result_type, ret, uictx):
		if result_type == commandexec.RESULT_SOURCE:
			self.object_stack_clear_all()
			self.source_pane.push_source(ret)
		elif result_type == commandexec.RESULT_OBJECT:
			self.object_stack_clear_all()
			self._insert_object(SourcePane, ret)
		else:
			return
		self.emit("command-result", result_type, uictx)

	def _late_command_execution_result(self, ctx, id_, result_type, ret, uictx):
		"Receive late command result"
		if self._latest_interaction < id_:
			self._command_execution_result(ctx, result_type, ret, uictx)

	def find_object(self, url):
		"""Find object with URI @url and select it in the first pane"""
		sc = GetSourceController()
		qf = qfurl.qfurl(url=url)
		found = qf.resolve_in_catalog(sc.sources)
		if found and not found == self.source_pane.get_selection():
			self._insert_object(SourcePane, found)

	def mark_as_default(self, pane):
		"""
		Make the object selected on @pane as default
		for the selection in previous pane.
		"""
		if pane is SourcePane or pane is ObjectPane:
			raise RuntimeError("Setting default on pane 1 or 3 not supported")
		obj = self.source_pane.get_selection()
		act = self.action_pane.get_selection()
		assert obj and act
		learn.set_correlation(act, obj)

	def get_object_has_affinity(self, pane):
		"""
		Return ``True`` if we have any recorded affinity
		for the object selected in @pane
		"""
		panectl = self._panectl_table[pane]
		selection = panectl.get_selection()
		if not selection:
			return None
		return learn.get_object_has_affinity(selection)

	def erase_object_affinity(self, pane):
		"""
		Erase all learned and configured affinity for
		the selection of @pane
		"""
		panectl = self._panectl_table[pane]
		selection = panectl.get_selection()
		if not selection:
			return None
		return learn.erase_object_affinity(selection)

	def compose_selection(self):
		leaf, action, iobj = self._get_current_command_objects()
		if leaf is None:
			return
		self.object_stack_clear_all()
		obj = compose.ComposedLeaf(leaf, action, iobj)
		self._insert_object(SourcePane, obj)

	def _get_pane_object_composed(self, pane):
		objects = list(pane.object_stack)
		sel = pane.get_selection()
		if sel and sel not in objects:
			objects.append(sel)
		if not objects:
			return None
		elif len(objects) == 1:
			return objects[0]
		else:
			return compose.MultipleLeaf(objects)

	def _get_current_command_objects(self):
		"""
		Return a tuple of current (obj, action, iobj)
		"""
		objects = self._get_pane_object_composed(self.source_pane)
		action = self.action_pane.get_selection()
		if objects is None or action is None:
			return (None, None, None)
		iobjects = self._get_pane_object_composed(self.object_pane)
		if self.mode == SourceActionObjectMode:
			if not iobjects:
				return (None, None, None)
		else:
			iobjects = None
		return (objects, action, iobjects)

	def _has_object_stack(self, pane):
		return pane in (SourcePane, ObjectPane)

	def _set_object_stack(self, pane, newstack):
		panectl = self._panectl_table[pane]
		panectl.object_stack[:] = list(newstack)
		self.emit("object-stack-changed", pane)

	def object_stack_push(self, pane, object_):
		"""
		Push @object_ onto the stack
		"""
		if not self._has_object_stack(pane):
			return
		panectl = self._panectl_table[pane]
		if object_ not in panectl.object_stack:
			panectl.object_stack_push(object_)
			self.emit("object-stack-changed", pane)
		return True

	def object_stack_pop(self, pane):
		if not self._has_object_stack(pane):
			return
		panectl = self._panectl_table[pane]
		obj = panectl.object_stack_pop()
		self._insert_object(pane, obj)
		self.emit("object-stack-changed", pane)
		return True

	def object_stack_clear(self, pane):
		if not self._has_object_stack(pane):
			return
		panectl = self._panectl_table[pane]
		panectl.object_stack[:] = []
		self.emit("object-stack-changed", pane)

	def object_stack_clear_all(self):
		"""
		Clear the object stack for all panes
		"""
		for pane in self._panectl_table:
			self.object_stack_clear(pane)

	def get_object_stack(self, pane):
		if not self._has_object_stack(pane):
			return ()
		panectl = self._panectl_table[pane]
		return panectl.object_stack

# pane cleared or set with new item
# pane, item
gobject.signal_new("pane-reset", DataController, gobject.SIGNAL_RUN_LAST,
	gobject.TYPE_BOOLEAN, (gobject.TYPE_INT, gobject.TYPE_PYOBJECT,))

# pane, match, iter to matches, context
gobject.signal_new("search-result", DataController, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN, (gobject.TYPE_INT, gobject.TYPE_PYOBJECT, gobject.TYPE_PYOBJECT, gobject.TYPE_PYOBJECT))

gobject.signal_new("source-changed", DataController, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN, (int, object, bool))

# mode, None(?)
gobject.signal_new("mode-changed", DataController, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN, (gobject.TYPE_INT, gobject.TYPE_PYOBJECT,))

# object stack update signal
# arguments: pane
gobject.signal_new("object-stack-changed", DataController, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN, (gobject.TYPE_INT, ))
# when an command returned a result
# arguments: result type, gui_context
gobject.signal_new("command-result", DataController, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN, (gobject.TYPE_INT, gobject.TYPE_PYOBJECT))

# when an action was launched
# arguments: none
gobject.signal_new("launched-action", DataController, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN, ())



########NEW FILE########
__FILENAME__ = execfile
import hashlib
import pickle
import os

import gio
import glib

from kupfer import pretty
from kupfer import puid
from kupfer import conspickle

KUPFER_COMMAND_SHEBANG="#!/usr/bin/env kupfer-exec\n"

class ExecutionError (Exception):
	pass

def parse_kfcom_file(filepath):
	"""Extract the serialized command inside @filepath

	The file must be executable (comparable to a shell script)
	>>> parse_kfcom_file(__file__)  # doctest: +ELLIPSIS
	Traceback (most recent call last):
	    ...
	ExecutionError: ... (not executable)

	Return commands triple
	"""
	fobj = open(filepath, "rb")
	if not os.access(filepath, os.X_OK):
		raise ExecutionError(_('No permission to run "%s" (not executable)') %
				glib.filename_display_basename(filepath))

	# strip shebang away
	data = fobj.read()
	if data.startswith("#!") and "\n" in data:
		shebang, data = data.split("\n", 1)

	try:
		id_ = conspickle.BasicUnpickler.loads(data)
		command_object = puid.resolve_unique_id(id_)
	except pickle.UnpicklingError, err:
		raise ExecutionError("Could not parse: %s" % unicode(err))
	except Exception:
		raise ExecutionError('"%s" is not a saved command' %
				os.path.basename(filepath))
	if command_object is None:
		raise ExecutionError(_('Command in "%s" is not available') %
				glib.filename_display_basename(filepath))

	try:
		return tuple(command_object.object)
	except (AttributeError, TypeError):
		raise ExecutionError('"%s" is not a saved command' %
				os.path.basename(filepath))
	finally:
		glib.idle_add(update_icon, command_object, filepath)

def save_to_file(command_leaf, filename):
	fd = os.open(filename, os.O_CREAT | os.O_EXCL | os.O_WRONLY, 0o777)
	wfile = os.fdopen(fd, "wb")
	try:
		wfile.write(KUPFER_COMMAND_SHEBANG)
		pickle.dump(puid.get_unique_id(command_leaf), wfile, 0)
	finally:
		wfile.close()

def _write_thumbnail(gfile, pixbuf):
	uri = gfile.get_uri()
	hashname = hashlib.md5(uri).hexdigest()
	thumb_dir = os.path.expanduser("~/.thumbnails/normal")
	if not os.path.exists(thumb_dir):
		os.makedirs(thumb_dir, 0700)
	thumb_filename = os.path.join(thumb_dir, hashname + ".png")
	pixbuf.save(thumb_filename, "png")
	return thumb_filename

def update_icon(kobj, filepath):
	"Give @filepath a custom icon taken from @kobj"
	icon_key = "metadata::custom-icon"
	icon_namespace = icon_key.split(":")[0]

	gfile = gio.File(filepath)
	finfo = gfile.query_info(icon_key)
	custom_icon_uri = finfo.get_attribute_string(icon_key)
	if custom_icon_uri and gio.File(custom_icon_uri).query_exists():
		return
	if icon_namespace in (N.name for N in gfile.query_writable_namespaces()):
		pretty.print_debug(__name__, "Updating icon for", filepath)
		thumb_filename = _write_thumbnail(gfile, kobj.get_pixbuf(128))
		gfile.set_attribute_string(icon_key, gio.File(thumb_filename).get_uri())


if __name__ == '__main__':
	import doctest
	doctest.testmod()

########NEW FILE########
__FILENAME__ = learn
import cPickle as pickle
import os

from kupfer import config
from kupfer import conspickle
from kupfer import pretty

mnemonics_filename = "mnemonics.pickle"
CORRELATION_KEY = 'kupfer.bonus.correlation'

## this is a harmless default
_default_actions = {
	'<builtin.AppLeaf gnome-terminal>': '<builtin.LaunchAgain>',
	'<builtin.AppLeaf xfce4-terminal>': '<builtin.LaunchAgain>',
}
_register = {}
_favorites = set()


class Mnemonics (object):
	"""
	Class to describe a collection of mnemonics
	as well as the total count
	"""
	def __init__(self):
		self.mnemonics = dict()
		self.count = 0
	def __repr__(self):
		return "<%s %d %s>" % (self.__class__.__name__, self.count, "".join(["%s: %d, " % (m,c) for m,c in self.mnemonics.iteritems()]))
	def increment(self, mnemonic=None):
		if mnemonic:
			mcount = self.mnemonics.get(mnemonic, 0)
			self.mnemonics[mnemonic] = mcount + 1
		self.count += 1

	def decrement(self):
		"""Decrement total count and the least mnemonic"""
		if self.mnemonics:
			key = min(self.mnemonics, key=lambda k: self.mnemonics[k])
			if self.mnemonics[key] <= 1:
				del self.mnemonics[key]
			else:
				self.mnemonics[key] -= 1
		self.count = max(self.count -1, 0)

	def __nonzero__(self):
		return self.count
	def get_count(self):
		return self.count
	def get_mnemonics(self):
		return self.mnemonics

class Learning (object):
	@classmethod
	def _unpickle_register(cls, pickle_file):
		try:
			pfile = open(pickle_file, "rb")
		except IOError, e:
			return None
		try:
			data = conspickle.ConservativeUnpickler.loads(pfile.read())
			assert isinstance(data, dict), "Stored object not a dict"
			pretty.print_debug(__name__, "Reading from %s" % (pickle_file, ))
		except (pickle.PickleError, Exception), e:
			data = None
			pretty.print_error(__name__, "Error loading %s: %s" % (pickle_file, e))
		finally:
			pfile.close()
		return data

	@classmethod
	def _pickle_register(self, reg, pickle_file):
		## Write to tmp then rename over for atomicity
		tmp_pickle_file = "%s.%s" % (pickle_file, os.getpid())
		pretty.print_debug(__name__, "Saving to %s" % (pickle_file, ))
		with open(tmp_pickle_file, "wb") as output:
			output.write(pickle.dumps(reg, pickle.HIGHEST_PROTOCOL))
		os.rename(tmp_pickle_file, pickle_file)
		return True

def record_search_hit(obj, key=u""):
	"""
	Record that KupferObject @obj was used, with the optional
	search term @key recording
	"""
	name = repr(obj)
	if name not in _register:
		_register[name] = Mnemonics()
	_register[name].increment(key)

def get_record_score(obj, key=u""):
	"""
	Get total score for KupferObject @obj,
	bonus score is given for @key matches
	"""
	name = repr(obj)
	fav = 7 * (name in _favorites)
	if name not in _register:
		return fav
	mns = _register[name]
	if not key:
		cnt = mns.get_count()
		return fav + 50 * (1 - 1.0/(cnt + 1))

	stats = mns.get_mnemonics()
	closescr = sum(stats[m] for m in stats if m.startswith(key))
	mnscore = 30 * (1 - 1.0/(closescr + 1))
	exact = stats.get(key, 0)
	mnscore += 50 * (1 - 1.0/(exact + 1))
	return fav + mnscore


def get_correlation_bonus(obj, for_leaf):
	"""
	Get the bonus rank for @obj when used with @for_leaf
	"""
	if _register.setdefault(CORRELATION_KEY, {}).get(repr(for_leaf)) == repr(obj):
		return 50
	else:
		return 0

def set_correlation(obj, for_leaf):
	"""
	Register @obj to get a bonus when used with @for_leaf
	"""
	_register.setdefault(CORRELATION_KEY, {})[repr(for_leaf)] = repr(obj)

def _get_mnemonic_items(in_register):
	return [(k,v) for k,v in in_register.items() if k != CORRELATION_KEY]

def get_object_has_affinity(obj):
	"""
	Return if @obj has any positive score in the register
	"""
	return bool(_register.get(repr(obj)) or
	            _register.get(CORRELATION_KEY, {}).get(repr(obj)))

def erase_object_affinity(obj):
	"""
	Remove all track of affinity for @obj
	"""
	_register.pop(repr(obj), None)
	_register.get(CORRELATION_KEY, {}).pop(repr(obj), None)

def _prune_register():
	"""
	Remove items with chance (len/25000)

	Assuming homogenous records (all with score one) we keep:
	x_n+1 := x_n * (1 - chance)

	To this we have to add the expected number of added mnemonics per
	invocation, est. 10, and we can estimate a target number of saved mnemonics.
	"""
	import random
	random.seed()
	rand = random.random

	goalitems = 500
	flux = 2.0
	alpha = flux/goalitems**2

	chance = min(0.1, len(_register)*alpha)
	for leaf, mn in _get_mnemonic_items(_register):
		if rand() > chance:
			continue
		mn.decrement()
		if not mn:
			del _register[leaf]

	l = len(_register)
	pretty.print_debug(__name__, "Pruned register (%d mnemonics)" % l)

def load():
	"""
	Load learning database
	"""
	global _register

	filepath = config.get_config_file(mnemonics_filename)
	if filepath:
		_register = Learning._unpickle_register(filepath)
	if not _register:
		_register = {}
	if CORRELATION_KEY not in _register:
		_register[CORRELATION_KEY] = _default_actions

def save():
	"""
	Save the learning record
	"""
	if not _register:
		pretty.print_debug(__name__, "Not writing empty register")
		return
	if len(_register) > 100:
		_prune_register()
	filepath = config.save_config_file(mnemonics_filename)
	Learning._pickle_register(_register, filepath)

def add_favorite(obj):
	_favorites.add(repr(obj))

def remove_favorite(obj):
	_favorites.discard(repr(obj))

def is_favorite(obj):
	return repr(obj) in _favorites

########NEW FILE########
__FILENAME__ = pluginload
import contextlib

from kupfer import pretty

from kupfer.core import plugins
from kupfer.core.plugins import (load_plugin_sources, sources_attribute,
		action_decorators_attribute, text_sources_attribute,
		content_decorators_attribute, action_generators_attribute,
		initialize_plugin)

class PluginDescription (object):
	text_sources = ()
	action_decorators = ()
	content_decorators = ()
	action_generators = ()
	sources = ()

def load_plugin(plugin_id):
	"""
	@S_sources are to be included directly in the catalog,
	@s_souces as just as subitems
	"""
	sources = []
	text_sources = []
	action_decorators = []
	content_decorators = []
	action_generators = []

	item = plugin_id

	initialize_plugin(item)
	if not plugins.is_plugin_loaded(item):
		return PluginDescription()
	text_sources.extend(load_plugin_sources(item, text_sources_attribute))
	action_decorators.extend(load_plugin_sources(item,
		action_decorators_attribute))
	action_generators.extend(load_plugin_sources(item,
		action_generators_attribute))

	# Register all Sources as (potential) content decorators
	content_decorators.extend(load_plugin_sources(item,
		sources_attribute, instantiate=False))
	content_decorators.extend(load_plugin_sources(item,
		content_decorators_attribute, instantiate=False))
	sources.extend(load_plugin_sources(item))

	desc = PluginDescription()

	desc.text_sources = text_sources
	desc.action_decorators = action_decorators
	desc.content_decorators = content_decorators
	desc.sources = sources
	desc.action_generators = action_generators
	return desc

@contextlib.contextmanager
def exception_guard(name, callback=None, *args):
	"Guard for exceptions, print traceback and call @callback if any is raised"
	try:
		yield
	except Exception:
		import traceback
		pretty.print_error(__name__, "Loading %s raised an exception:" % name)
		traceback.print_exc()
		pretty.print_error(__name__, "This error is probably a bug in", name)
		pretty.print_error(__name__, "Please file a bug report")
		if callback is not None:
			callback(*args)

def remove_plugin(plugin_id):
	plugins.unimport_plugin(plugin_id)

########NEW FILE########
__FILENAME__ = plugins
import pkgutil
import sys

from kupfer import pretty
from kupfer.core import settings
# import kupfer.icons on demand later

sources_attribute = "__kupfer_sources__"
text_sources_attribute = "__kupfer_text_sources__"
content_decorators_attribute = "__kupfer_contents__"
action_decorators_attribute = "__kupfer_actions__"
action_generators_attribute = "__kupfer_action_generators__"
settings_attribute = "__kupfer_settings__"

initialize_attribute = "initialize_plugin"
finalize_attribute = "finalize_plugin"

info_attributes = [
		"__kupfer_name__",
		"__version__",
		"__description__",
		"__author__",
	]

class NotEnabledError (Exception):
	"Plugin may not be imported since it is not enabled"

def get_plugin_ids():
	"""Enumerate possible plugin ids;
	return a sequence of possible plugin ids, not
	guaranteed to be plugins"""
	from kupfer import plugin

	def is_plugname(plug):
		return plug != "__init__" and not plug.endswith("_support")

	for importer, modname, ispkg in pkgutil.iter_modules(plugin.__path__):
		if is_plugname(modname):
			yield modname

class FakePlugin (object):
	def __init__(self, plugin_id, attributes, exc_info):
		self.is_fake_plugin = True
		self.exc_info = exc_info
		self.__name__ = plugin_id
		vars(self).update(attributes)
	def __repr__(self):
		return "<%s %s>" % (type(self).__name__, self.__name__)

def get_plugin_info():
	"""Generator, yields dictionaries of plugin descriptions

	with at least the fields:
	name
	localized_name
	version
	description
	author
	"""
	for plugin_name in sorted(get_plugin_ids()):
		try:
			plugin = import_plugin_any(plugin_name)
			if not plugin:
				continue
			plugin = vars(plugin)
		except ImportError, e:
			pretty.print_error(__name__, "import plugin '%s':" % plugin_name, e)
			continue
		localized_name = plugin.get("__kupfer_name__", None)
		desc = plugin.get("__description__", "")
		vers = plugin.get("__version__", "")
		author = plugin.get("__author__", "")
		# skip false matches;
		# all plugins have to have @localized_name
		if localized_name is None:
			continue
		yield {
			"name": plugin_name,
			"localized_name": localized_name,
			"version": vers,
			"description": desc or u"",
			"author": author,
			"provides": (),
		}

def get_plugin_desc():
	"""Return a formatted list of plugins suitable for printing to terminal"""
	import textwrap
	infos = list(get_plugin_info())
	verlen = max(len(r["version"]) for r in infos)
	idlen = max(len(r["name"]) for r in infos)
	maxlen = 78
	left_margin = 2 + idlen + 1 + verlen + 1
	desc = []
	for rec in infos:
		# Wrap the description and align continued lines
		wrapped = textwrap.wrap(rec["description"], maxlen - left_margin)
		description = (u"\n" + u" "*left_margin).join(wrapped)
		desc.append("  %s %s %s" %
			(
				rec["name"].ljust(idlen),
				rec["version"].ljust(verlen),
				description,
			))
	return "\n".join(desc)

_imported_plugins = {}
_plugin_hooks = {}

def _truncate_code(code, find_attributes):
	"Truncate @code where all of @find_attributes have been stored."
	import dis
	import types

	found_info_attributes = set(find_attributes)
	def _new_code(c, codestring):
		newcode = types.CodeType(c.co_argcount,
		                         c.co_nlocals,
		                         c.co_stacksize,
		                         c.co_flags,
		                         codestring,
		                         c.co_consts,
		                         c.co_names,
		                         c.co_varnames,
		                         c.co_filename,
		                         c.co_name,
		                         c.co_firstlineno,
		                         c.co_lnotab)
		return newcode

	none_index = list(code.co_consts).index(None)
	i = 0
	end = len(code.co_code)
	while i < end:
		if not found_info_attributes:
			# Insert an instruction to return [None] right here
			# then truncate the code at this point
			endinstr = [
				dis.opmap["LOAD_CONST"],
				none_index & 255,
				none_index >> 8,
				dis.opmap["RETURN_VALUE"],
			]
			c = list(code.co_code)
			c[i:] = map(chr, endinstr)
			ncode = _new_code(code, ''.join(c))
			return ncode

		op = ord(code.co_code[i])
		name = dis.opname[op]

		if op >= dis.HAVE_ARGUMENT:
			b1 = ord(code.co_code[i+1])
			b2 = ord(code.co_code[i+2])
			num = b2 * 256 + b1

			if name == 'STORE_NAME':
				global_name = code.co_names[num]
				found_info_attributes.discard(global_name)

			i += 3
		else:
			i += 1
	pretty.print_debug(__name__, "Code used until end:", code)
	return code

def _import_plugin_fake(modpath, error=None):
	"""
	Return an object that has the plugin info attributes we can rescue
	from a plugin raising on import.

	@error: If applicable, a tuple of exception info
	"""
	loader = pkgutil.get_loader(modpath)
	if not loader:
		return None

	code = loader.get_code(modpath)
	if not code:
		return None

	try:
		filename = loader.get_filename()
	except AttributeError:
		try:
			filename = loader.archive + loader.prefix
		except AttributeError:
			filename = "<%s>" % modpath

	env = {
		"__name__": modpath,
		"__file__": filename,
	}
	code = _truncate_code(code, info_attributes)
	try:
		eval(code, env)
	except Exception, exc:
		pretty.print_debug(__name__, "Loading", modpath, exc)
	attributes = dict((k, env.get(k)) for k in info_attributes)
	attributes.update((k, env.get(k)) for k in ["__name__", "__file__"])
	return FakePlugin(modpath, attributes, error)

def _import_hook_fake(pathcomps):
	modpath = ".".join(pathcomps)
	return _import_plugin_fake(modpath)

def _import_hook_true(pathcomps):
	"""@pathcomps path components to the import"""
	path = ".".join(pathcomps)
	fromlist = pathcomps[-1:]
	try:
		setctl = settings.GetSettingsController()
		if not setctl.get_plugin_enabled(pathcomps[-1]):
			raise NotEnabledError("%s is not enabled" % pathcomps[-1])
		plugin = __import__(path, fromlist=fromlist)
	except ImportError, exc:
		# Try to find a fake plugin if it exists
		plugin = _import_plugin_fake(path, error=sys.exc_info())
		if not plugin:
			raise
		pretty.print_error(__name__, "Could not import plugin '%s': %s" %
				(plugin.__name__, exc))
	else:
		pretty.print_debug(__name__, "Loading %s" % plugin.__name__)
		pretty.print_debug(__name__, "  from %s" % plugin.__file__)
	return plugin

def _import_plugin_true(name):
	"""Try to import the plugin from the package, 
	and then from our plugin directories in $DATADIR
	"""
	plugin = None
	try:
		plugin = _staged_import(name, _import_hook_true)
	except ImportError:
		# Reraise to send this up
		raise
	except NotEnabledError:
		raise
	except Exception:
		# catch any other error for plugins and write traceback
		import traceback
		traceback.print_exc()
		pretty.print_error(__name__, "Could not import plugin '%s'" % name)
	return plugin

def _staged_import(name, import_hook):
	"Import plugin @name using @import_hook"
	plugin = None
	try:
		plugin = import_hook(_plugin_path(name))
	except ImportError, e:
		if name not in e.args[0]:
			raise
	return plugin


def import_plugin(name):
	if is_plugin_loaded(name):
		return _imported_plugins[name]
	plugin = None
	try:
		plugin = _import_plugin_true(name)
	except NotEnabledError:
		plugin = _staged_import(name, _import_hook_fake)
	finally:
		# store nonexistant plugins as None here
		_imported_plugins[name] = plugin
	return plugin

def import_plugin_any(name):
	if name in _imported_plugins:
		return _imported_plugins[name]
	return _staged_import(name, _import_hook_fake)

def _plugin_path(name):
	return ("kupfer", "plugin", name)


# Plugin Attributes
def get_plugin_attributes(plugin_name, attrs, warn=False):
	"""Generator of the attributes named @attrs
	to be found in plugin @plugin_name
	if the plugin is not found, we write an error
	and yield nothing.

	if @warn, we print a warning if a plugin does not have
	a requested attribute
	"""
	try:
		plugin = import_plugin(plugin_name)
	except ImportError, e:
		pretty.print_info(__name__, "Skipping plugin %s: %s" % (plugin_name, e))
		return
	for attr in attrs:
		try:
			obj = getattr(plugin, attr)
		except AttributeError, e:
			if warn:
				pretty.print_info(__name__, "Plugin %s: %s" % (plugin_name, e))
			yield None
		else:
			yield obj

def get_plugin_attribute(plugin_name, attr):
	"""Get single plugin attribute"""
	attrs = tuple(get_plugin_attributes(plugin_name, (attr,)))
	obj, = (attrs if attrs else (None, ))
	return obj

def load_plugin_sources(plugin_name, attr=sources_attribute, instantiate=True):
	sources = get_plugin_attribute(plugin_name, attr)
	if not sources:
		return
	for source in get_plugin_attributes(plugin_name, sources, warn=True):
		if source:
			if instantiate:
				yield source()
			else:
				yield source
		else:
			pretty.print_info(__name__, "Source not found for %s" % plugin_name)


# Plugin Initialization & Error
def is_plugin_loaded(plugin_name):
	return (plugin_name in _imported_plugins and
			not getattr(_imported_plugins[plugin_name], "is_fake_plugin", None))

def _loader_hook(modpath):
	modname = ".".join(modpath)
	loader = pkgutil.find_loader(modname)
	if not loader:
		raise ImportError("No loader found for %s" % modname)
	if not loader.is_package(modname):
		raise ImportError("Is not a package")
	return loader

PLUGIN_ICON_FILE = "icon-list"
icons = None

def _load_icons(plugin_name):
	global icons
	if icons is None:
		from kupfer import icons

	try:
		loader = _staged_import(plugin_name, _loader_hook)
	except ImportError, exc:
		return
	modname = ".".join(_plugin_path(plugin_name))

	try:
		icon_file = pkgutil.get_data(modname, PLUGIN_ICON_FILE)
	except IOError as exc:
		# icon-list file just missing, let is pass silently
		return

	def get_icon_data(basename):
		return pkgutil.get_data(modname, basename)
	icons.parse_load_icon_list(icon_file, get_icon_data, plugin_name)

def initialize_plugin(plugin_name):
	"""Initialize plugin.
	Find settings attribute if defined, and initialize it
	"""
	_load_icons(plugin_name)
	settings_dict = get_plugin_attribute(plugin_name, settings_attribute)
	if settings_dict:
		settings_dict.initialize(plugin_name)
	initialize = get_plugin_attribute(plugin_name, initialize_attribute)
	if initialize:
		initialize(plugin_name)
	finalize = get_plugin_attribute(plugin_name, finalize_attribute)
	if finalize:
		register_plugin_unimport_hook(plugin_name, finalize, plugin_name)

def unimport_plugin(plugin_name):
	"""Remove @plugin_name from the plugin list and dereference its
	python modules.
	"""
	# Run unimport hooks
	if plugin_name in _plugin_hooks:
		try:
			for callback, args in reversed(_plugin_hooks[plugin_name]):
				callback(*args)
		except:
			pretty.print_error(__name__, "Error finalizing", plugin_name)
			pretty.print_exc(__name__)
		del _plugin_hooks[plugin_name]
	del _imported_plugins[plugin_name]
	plugin_module_name = ".".join(_plugin_path(plugin_name))
	pretty.print_debug(__name__, "Dereferencing module", plugin_module_name)
	if plugin_module_name in sys.modules:
		sys.modules.pop(plugin_module_name)
	for mod in list(sys.modules):
		if mod.startswith(plugin_module_name + "."):
			pretty.print_debug(__name__, "Dereferencing module", mod)
			sys.modules.pop(mod)

def register_plugin_unimport_hook(plugin_name, callback, *args):
	if plugin_name not in _imported_plugins:
		raise ValueError("No such plugin %s" % plugin_name)
	_plugin_hooks.setdefault(plugin_name, []).append((callback, args))

def get_plugin_error(plugin_name):
	"""
	Return None if plugin is loaded without error, else
	return a tuple of exception information
	"""
	try:
		plugin = import_plugin(plugin_name)
		if getattr(plugin, "is_fake_plugin", None):
			return plugin.exc_info
	except ImportError:
		return sys.exc_info()


########NEW FILE########
__FILENAME__ = qfurl
import urlparse
from urlparse import urlparse as _urlparse
from urlparse import urlunparse as _urlunparse

from kupfer import pretty

QFURL_SCHEME = "qpfer"

# One would hope that there was a better way to do this
urlparse.uses_netloc.append(QFURL_SCHEME)
try:
	urlparse.uses_fragment.append(QFURL_SCHEME)
except AttributeError:
	# Python 2.7.3 drops `uses_fragment` global
	pass

class QfurlError (Exception):
	pass

class qfurl (object):
	"""A qfurl is a URI to locate unique objects in kupfer's catalog.

	The qfurl is built up as follows:
	``qpfer://mother/qfid#module_and_type_hint``

	The mother part is a mother source identifier and is optional.
	The module_and_type_hint is optional.

	A short url looks like the following:
	``qpfer:identifier``

	This class provides methods to get the qfurl for an object,
	and resolve the object in a catalog.

	>>> class Object (object):
	...     qf_id = "token"
	...
	>>> q = qfurl(Object())
	>>> qfurl.reduce_url(q.url)
	'qpfer:token'

	>>> class Source (object):
	...     def get_leaves(self):
	...         yield Object()
	...     def provides(self):
	...         yield Object
	...
	>>> q.resolve_in_catalog((Source(), ))  # doctest: +ELLIPSIS
	<__main__.Object object at 0x...>
	"""

	def __init__(self, obj=None, url=None):
		"""Create a new qfurl for object @obj"""
		if obj:
			typname = "%s.%s" % (type(obj).__module__, type(obj).__name__)
			try:
				qfid = obj.qf_id
			except AttributeError:
				raise QfurlError("%s has no qfurl" % obj)
			self.url = _urlunparse((QFURL_SCHEME, "", qfid, "", "", typname))
		else:
			self.url = url

	def __str__(self):
		return self.url

	def __hash__(self):
		return hash(self.url)

	def __eq__(self, other):
		return self.reduce_url(self.url) == self.reduce_url(other.url)

	@classmethod
	def reduce_url(cls, url):
		"""
		>>> url = "qpfer://mother/qfid#module_and_type_hint"
		>>> qfurl.reduce_url(url)
		'qpfer://mother/qfid'
		"""
		return urlparse.urldefrag(url)[0].replace("///", "", 1)

	@classmethod
	def _parts_mother_id_typename(cls, url):
		"""
		>>> murl = "qpfer://mother/qfid#module_and_type_hint"
		>>> qfurl._parts_mother_id_typename(murl)
		('mother', 'qfid', 'module_and_type_hint')
		"""
		scheme, mother, qfid, _ign, _ore, typname = _urlparse(url)
		if scheme != QFURL_SCHEME:
			raise QfurlError("Wrong scheme: %s" % scheme)
		qfid = qfid.lstrip("/")
		return mother, qfid, typname

	def resolve_in_catalog(self, catalog):
		"""Resolve self in a catalog of sources

		Return *immediately* on match found"""
		mother, qfid, typname = self._parts_mother_id_typename(self.url)
		module, name = typname.rsplit(".", 1) if typname else (None, None)
		for src in catalog:
			if name:
				if name not in (pt.__name__
						for pt in src.provides()) and \
					name not in (t.__name__
						for pt in src.provides()
						for t in pt.__subclasses__()):
					continue
			for obj in src.get_leaves():
				if not hasattr(obj, "qf_id"):
					continue
				try:
					if self == qfurl(obj):
						return obj
				except QfurlError:
					pass
		pretty.print_debug(__name__, "No match found for", self)
		return None

if __name__ == '__main__':
	import doctest
	doctest.testmod()

########NEW FILE########
__FILENAME__ = relevance
# Copyright (C) 2009  Ulrik Sverdrup <ulrik.sverdrup@gmail.com>
#               2008  Christian Hergert <chris@dronelabs.com>
#               2007  Chris Halse Rogers, DR Colkitt
#                     David Siegel, James Walker
#                     Jason Smith, Miguel de Icaza
#                     Rick Harding, Thomsen Anders
#                     Volker Braun, Jonathon Anderson 
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

"""
This module provides relevance matching and formatting of related strings
based on the relevance.  It originates in Gnome-Do.

 * Python port by Christian Hergert

 * Module updated by Ulrik Sverdrup to clean up and dramatically speed up
   the code, by using more pythonic constructs as well as doing less work.

Compatibility: Python 2.4 and later, including Python 3
"""

from __future__ import division

# This module is compatible with both Python 2 and Python 3;
# we need the iterator form of range for either version, stored in range()
try:
    range = xrange
except NameError:
    pass

def formatCommonSubstrings(s, query, format_clean=None, format_match=None):
    """
    Creates a new string highlighting matching substrings.

    Returns: a formatted string

    >>> formatCommonSubstrings('hi there dude', 'hidude',
    ...                        format_match=lambda m: "<b>%s</b>" % m)
    '<b>hi</b> there <b>dude</b>'

    >>> formatCommonSubstrings('parallelism', 'lsm', format_match=str.upper)
    'paralleLiSM'
    """
    format_clean = format_clean or (lambda x: x)
    format_match = format_match or (lambda x: x)
    format = lambda x: x and format_clean(x)

    if not query:
        return format(s)

    ls = s.lower()

    # find overall range of match
    first, last = _findBestMatch(ls, query)

    if first == -1:
        return format(s)

    # find longest perfect match, put in slc
    for slc in range(len(query), 0, -1):
        if query[:slc] == ls[first:first+slc]:
            break
    key, nextkey = query[:slc], query[slc:]

    head = s[:first]
    match = s[first: first+slc]
    matchtail = s[first+slc: last]
    tail = s[last:]

    # we use s[0:0], which is "" or u""
    return s[0:0].join((
            format(head),
            format_match(match),
            formatCommonSubstrings(matchtail, nextkey,
                                   format_clean, format_match),
            format(tail),
            ))

def score(s, query):
    """
    A relevancy score for the string ranging from 0 to 1

    @s: a string to be scored
    @query: a string query to score against

    `s' is treated case-insensitively while `query' is interpreted literally,
    including case and whitespace.

    Returns: a float between 0 and 1

    >>> print(score('terminal', 'trml'))
    0.735098684211
    >>> print(score('terminal', 'term'))
    0.992302631579
    >>> print(score('terminal', 'try'))
    0.0
    >>> print(score('terminal', ''))
    1.0
    """
    if not query:
        return 1.0

    ls = s.lower()

    # Find the shortest possible substring that matches the query
    # and get the ration of their lengths for a base score
    first, last = _findBestMatch(ls, query)
    if first == -1:
        return .0

    score = len(query) / (last - first)

    # Now we weight by string length so shorter strings are better
    score *= .7 + len(query) / len(s) * .3

    # Bonus points if the characters start words
    good = 0
    bad = 1
    firstCount = 0
    for i in range(first, last-1):
        if ls[i] in " -":
            if ls[i + 1] in query:
                firstCount += 1
            else:
                bad += 1
    
    # A first character match counts extra
    if query[0] == ls[0]:
        firstCount += 2
        
    # The longer the acronym, the better it scores
    good += firstCount * firstCount * 4
    
    # Better yet if the match itself started there
    if first == 0:
        good += 2

    # Super duper bonus if it is a perfect match
    if query == ls:
        good += last * 2 + 4

    score = (score + 3 * good / (good + bad)) / 4

    # This fix makes sure that perfect matches always rank higher
    # than split matches.  Perfect matches get the .9 - 1.0 range
    # everything else lower
    
    if last - first == len(query):
        score = .9 + .1 * score
    else:
        score = .9 * score
    
    return score

def _findBestMatch(s, query):
    """
    Finds the shortest substring of @s that contains all characters of query
    in order.

    @s: a string to search
    @query: a string query to search for

    Returns: a two-item tuple containing the start and end indicies of
             the match.  No match returns (-1,-1).

    >>> _findBestMatch('terminal', 'trml')
    (0, 8)
    >>> _findBestMatch('total told', 'tl')
    (2, 5)
    >>> _findBestMatch('terminal', 'yl')
    (-1, -1)
    """
    bestMatch = -1, -1
    
    # Find the last instance of the last character of the query
    # since we never need to search beyond that
    lastChar = s.rfind(query[-1])
    
    # No instance of the character?
    if lastChar == -1:
        return bestMatch

    # Loop through each instance of the first character in query
    index = s.find(query[0])

    queryLength = len(query)
    lastIndex = lastChar - len(query) + 1
    while 0 <= index <= lastIndex:
        # See if we can fit the whole query in the tail
        # We know the first char matches, so we dont check it.
        cur = index + 1
        qcur = 1
        while qcur < queryLength:
            # find where in the string the next query character is
            # if not found, we are done
            cur = s.find(query[qcur], cur, lastChar + 1)
            if cur == -1:
                return bestMatch
            cur += 1
            qcur += 1

        # take match if it is shorter
        # if perfect match, we are done
        if bestMatch[0] == -1 or (cur - index) < (bestMatch[1] - bestMatch[0]):
            bestMatch = (index, cur)
            if cur - index == queryLength:
                break

        index = s.find(query[0], index + 1)

    return bestMatch

if __name__ == '__main__':
    import doctest
    doctest.testmod()

########NEW FILE########
__FILENAME__ = search
# -*- coding: UTF-8 -*-

from kupfer.core import learn, relevance

def make_rankables(itr, rank=0):
	return (Rankable(unicode(obj), obj, rank) for obj in itr)

def wrap_rankable(obj, rank=0):
	return Rankable(unicode(obj), obj, rank)

class Rankable (object):
	"""
	Rankable has an object (represented item),
	value (determines rank) and an associated rank

	Rankable has __hash__ and __eq__ of the object so that a Rankable's
	rank doesn't matter, Rankables can still be equal
	"""
	# To save memory with (really) many Rankables
	__slots__ = ("rank", "value", "object", "aliases")
	def __init__(self, value, obj, rank=0):
		self.rank = rank
		self.value = value
		self.object = obj
		self.aliases = getattr(obj, "name_aliases", ())
	
	def __hash__(self):
		return hash(self.object)

	def __eq__(self, other):
		return (self.object == self.object)

	def __str__(self):
		return "%s: %s" % (self.rank, self.value)

	def __repr__(self):
		return "<Rankable %s repres %s at %x>" % (str(self), repr(self.object), id(self))

def bonus_objects(rankables, key):
	"""generator of @rankables that have mnemonics for @key

	rank is added to prev rank, all items are yielded"""
	key = key.lower()
	get_record_score = learn.get_record_score
	for obj in rankables:
		obj.rank += get_record_score(obj.object, key)
		obj.rank += obj.object.rank_adjust
		yield obj

def add_rank_objects(rankables, rank):
	for obj in rankables:
		obj.rank += rank
		yield obj

def score_objects(rankables, key):
	"""Return @rankables that pass with a >0 rank for @key,

	rank is added to previous rank,
	if not @key, then all items are returned"""
	_score = relevance.score
	key = key.lower()
	for rb in rankables:
		# Rank object
		rank = _score(rb.value, key)*100
		if rank < 90:
			for alias in rb.aliases:
				# consider aliases and change rb.value if alias is better
				# aliases rank lower so that value is chosen when close
				arank = _score(alias, key)*95
				if arank > rank:
					rank = arank
					rb.value = alias
		if rank:
			rb.rank = rank
			yield rb


def score_actions(rankables, for_leaf):
	"""Alternative (rigid) scoring mechanism for objects,
	putting much more weight in rank_adjust
	"""
	get_record_score = learn.get_record_score
	for obj in rankables:
		ra = obj.object.rank_adjust
		ra += learn.get_correlation_bonus(obj.object, for_leaf)
		if ra > 0:
			obj.rank = 50 + ra + get_record_score(obj.object)//2
		elif ra == 0:
			obj.rank = get_record_score(obj.object)
		else:
			obj.rank = -50 + ra + get_record_score(obj.object)
		yield obj


########NEW FILE########
__FILENAME__ = settings
from __future__ import with_statement

import ConfigParser
import copy
import os

import glib
import gobject

from kupfer import config, pretty, scheduler


def strbool(value, default=False):
	"""Coerce bool from string value or bool"""
	if value in (True, False):
		return value
	value = str(value).lower()
	if value in ("no", "false"):
		return False
	if value in ("yes", "true"):
		return True
	return default

class SettingsController (gobject.GObject, pretty.OutputMixin):
	__gtype_name__ = "SettingsController"
	config_filename = "kupfer.cfg"
	defaults_filename = "defaults.cfg"
	sep = ";"
	default_directories = ("~/", "~/Desktop", )
	# Minimal "defaults" to define all fields
	# Read defaults defined in a defaults.cfg file
	defaults = {
		"Kupfer": {
			"keybinding" : "" ,
			"magickeybinding": "",
			"showstatusicon" : True,
			"usecommandkeys" : True,
		},
		"Directories" : { "direct" : default_directories, "catalog" : (), },
		"DeepDirectories" : { "direct" : (), "catalog" : (), "depth" : 1, },
		'Keybindings': {},
		"Tools": {},
	}
	def __init__(self):
		gobject.GObject.__init__(self)
		self._defaults_path = None
		self._config = self._read_config()
		self._save_timer = scheduler.Timer(True)
		self._alternatives = {}
		self._alternative_validators = {}

	def _update_config_save_timer(self):
		self._save_timer.set(60, self._save_config)

	def _read_config(self, read_config=True):
		"""
		Read cascading config files
		default -> then config
		(in all XDG_CONFIG_DIRS)
		"""
		parser = ConfigParser.SafeConfigParser()

		def fill_parser(parser, defaults):
			for secname, section in defaults.iteritems():
				if not parser.has_section(secname):
					parser.add_section(secname)
				for key, default in section.iteritems():
					if isinstance(default, (tuple, list)):
						default = self.sep.join(default)
					elif isinstance(default, int):
						default = str(default)
					parser.set(secname, key, default)

		# Set up defaults
		confmap = copy.deepcopy(self.defaults)
		fill_parser(parser, confmap)

		# Read all config files
		config_files = []
		try:
			defaults_path = config.get_data_file(self.defaults_filename)
		except config.ResourceLookupError:
			print "Error: no default config file %s found!" % self.defaults_filename
		else:
			self._defaults_path = defaults_path
			config_files += (defaults_path, )

		if read_config:
			config_path = config.get_config_file(self.config_filename)
			if config_path:
				config_files += (config_path, )

		for config_file in config_files:
			try:
				with open(config_file, "r") as fil:
					parser.readfp(fil)
			except IOError, e:
				print "Error reading configuration file %s: %s", (config_file, e)

		# Read parsed file into the dictionary again
		for secname in parser.sections():
			if secname not in confmap: confmap[secname] = {}
			for key in parser.options(secname):
				value = parser.get(secname, key)
				retval = value
				if secname in self.defaults and key in self.defaults[secname]:
					defval = self.defaults[secname][key]
					if isinstance(defval, (tuple, list)):
						if not value:
							retval = ()
						else:
							retval = [p.strip() for p in value.split(self.sep) if p]
					elif isinstance(defval, bool):
						retval = strbool(value)
					elif isinstance(defval, int):
						retval = type(defval)(value)
					else:
						retval = str(value)
				confmap[secname][key] = retval

		return confmap

	def _save_config(self, scheduler=None):
		self.output_debug("Saving config")
		config_path = config.save_config_file(self.config_filename)
		if not config_path:
			self.output_info("Unable to save settings, can't find config dir")
			return
		# read in just the default values
		default_confmap = self._read_config(read_config=False)

		def confmap_difference(config, defaults):
			"""Extract the non-default keys to write out"""
			difference = dict()
			for secname, section in config.items():
				if secname not in defaults:
					difference[secname] = dict(section)
					continue
				difference[secname] = {}
				for key, config_val in section.items():
					if (secname in defaults and
							key in defaults[secname]):
						if defaults[secname][key] == config_val:
							continue
					difference[secname][key] = config_val
				if not difference[secname]:
					del difference[secname]
			return difference

		parser = ConfigParser.SafeConfigParser()
		def fill_parser(parser, defaults):
			for secname, section in defaults.iteritems():
				if not parser.has_section(secname):
					parser.add_section(secname)
				for key, default in section.iteritems():
					if isinstance(default, (tuple, list)):
						default = self.sep.join(default)
					elif isinstance(default, int):
						default = str(default)
					parser.set(secname, key, default)

		confmap = confmap_difference(self._config, default_confmap)
		fill_parser(parser, confmap)
		## Write to tmp then rename over for it to be atomic
		temp_config_path = "%s.%s" % (config_path, os.getpid())
		with open(temp_config_path, "w") as out:
			parser.write(out)
		os.rename(temp_config_path, config_path)

	def get_config(self, section, key):
		"""General interface, but section must exist"""
		key = key.lower()
		value = self._config[section].get(key)
		if section in self.defaults:
			return value
		raise KeyError("Invalid settings section: %s" % section)

	def _set_config(self, section, key, value):
		"""General interface, but section must exist"""
		self.output_debug("Set", section, key, "to", value)
		key = key.lower()
		oldvalue = self._config[section].get(key)
		if section in self.defaults:
			value_type = type(oldvalue) if oldvalue is not None else str
			self._config[section][key] = value_type(value)
			self._emit_value_changed(section, key, value)
			self._update_config_save_timer()
			return True
		raise KeyError("Invalid settings section: %s" % section)

	def _emit_value_changed(self, section, key, value):
		suffix = "%s.%s" % (section.lower(), key.lower())
		self.emit("value-changed::"+suffix, section, key, value)

	def _get_raw_config(self, section, key):
		"""General interface, but section must exist"""
		key = key.lower()
		value = self._config[section].get(key)
		return value

	def _set_raw_config(self, section, key, value):
		"""General interface, but will create section"""
		self.output_debug("Set", section, key, "to", value)
		key = key.lower()
		if section not in self._config:
			self._config[section] = {}
		self._config[section][key] = str(value)
		self._update_config_save_timer()
		return False

	def get_from_defaults(self, section, option=None):
		"""Load values from default configuration file.
		If @option is None, return all section items as (key, value) """
		if self._defaults_path is None:
			print 'Defaults not found'
			return
		parser = ConfigParser.SafeConfigParser()
		parser.read(self._defaults_path)
		if option is None:
			return parser.items(section)
		else:
			return parser.get(section, option.lower())

	def get_plugin_enabled(self, plugin_id):
		"""Convenience: if @plugin_id is enabled"""
		return self.get_plugin_config(plugin_id, "kupfer_enabled",
				value_type=strbool, default=False)

	def set_plugin_enabled(self, plugin_id, enabled):
		"""Convenience: set if @plugin_id is enabled"""
		ret = self.set_plugin_config(plugin_id, "kupfer_enabled", enabled,
				value_type=strbool)
		self.emit("plugin-enabled-changed", plugin_id, enabled)
		return ret

	def get_plugin_is_hidden(self, plugin_id):
		"""Convenience: if @plugin_id is hidden"""
		return self.get_plugin_config(plugin_id, "kupfer_hidden",
				value_type=strbool, default=False)

	@classmethod
	def _source_config_repr(self, obj):
		name = type(obj).__name__
		return "".join([(c if c.isalnum() else '_') for c in name])

	def get_source_is_toplevel(self, plugin_id, src):
		key = "kupfer_toplevel_" + self._source_config_repr(src)
		default = not getattr(src, "source_prefer_sublevel", False)
		return self.get_plugin_config(plugin_id, key,
		                              value_type=strbool, default=default)

	def set_source_is_toplevel(self, plugin_id, src, value):
		key = "kupfer_toplevel_" + self._source_config_repr(src)
		self.emit("plugin-toplevel-changed", plugin_id, value)
		return self.set_plugin_config(plugin_id, key,
		                              value, value_type=strbool)

	def get_keybinding(self):
		"""Convenience: Kupfer keybinding as string"""
		return self.get_config("Kupfer", "keybinding")

	def set_keybinding(self, keystr):
		"""Convenience: Set Kupfer keybinding as string"""
		return self._set_config("Kupfer", "keybinding", keystr)

	def get_magic_keybinding(self):
		"""Convenience: Kupfer alternate keybinding as string"""
		return self.get_config("Kupfer", "magickeybinding")

	def set_magic_keybinding(self, keystr):
		"""Convenience: Set alternate keybinding as string"""
		return self._set_config("Kupfer", "magickeybinding", keystr)

	def get_global_keybinding(self, key):
		M = {
			"keybinding": self.get_keybinding,
			"magickeybinding": self.get_magic_keybinding,
		}
		return M[key]()

	def set_global_keybinding(self, key, val):
		M = {
			"keybinding": self.set_keybinding,
			"magickeybinding": self.set_magic_keybinding,
		}
		return M[key](val)

	def get_use_command_keys(self):
		return self.get_config("Kupfer", "usecommandkeys")

	def set_use_command_keys(self, enabled):
		return self._set_config("Kupfer", "usecommandkeys", enabled)

	def get_show_status_icon(self):
		"""Convenience: Show icon in notification area as bool"""
		return strbool(self.get_config("Kupfer", "showstatusicon"))
	def set_show_status_icon(self, enabled):
		"""Set config value and return success"""
		return self._set_config("Kupfer", "showstatusicon", enabled)

	def get_directories(self, direct=True):
		"""Yield directories to use as directory sources"""

		specialdirs = dict((k, getattr(glib, k))
				for k in dir(glib) if k.startswith("USER_DIRECTORY_"))

		def get_special_dir(opt):
			if opt in specialdirs:
				return glib.get_user_special_dir(specialdirs[opt])

		level = "Direct" if direct else "Catalog"
		for direc in self.get_config("Directories", level):
			dpath = get_special_dir(direc)
			yield dpath or os.path.abspath(os.path.expanduser(direc))

	def set_directories(self, dirs):
		return self._set_config("Directories", "direct", dirs)

	def get_plugin_config(self, plugin, key, value_type=str, default=None):
		"""Return setting @key for plugin names @plugin, try
		to coerce to type @value_type.
		Else return @default if does not exist, or can't be coerced
		"""
		plug_section = "plugin_%s" % plugin
		if not plug_section in self._config:
			return default
		val = self._get_raw_config(plug_section, key)

		if val is None:
			return default

		if hasattr(value_type, "load"):
			val_obj = value_type()
			val_obj.load(plugin, key, val)
			return val_obj
		else:
			if value_type is bool:
				value_type = strbool

			try:
				val = value_type(val)
			except ValueError, err:
				self.output_info("Error for stored value %s.%s" %
						(plug_section, key), err)
				return default
			return val

	def set_plugin_config(self, plugin, key, value, value_type=str):
		"""Try set @key for plugin names @plugin, coerce to @value_type
		first.  """
		plug_section = "plugin_%s" % plugin
		self._emit_value_changed(plug_section, key, value)

		if hasattr(value_type, "save"):
			value_repr = value.save(plugin, key)
		else:
			value_repr = value_type(value)
		return self._set_raw_config(plug_section, key, value_repr)

	def get_accelerator(self, name):
		return self.get_config("Keybindings", name)

	def set_accelerator(self, name, key):
		return self._set_config("Keybindings", name, key)

	def get_accelerators(self):
		return self._config['Keybindings']

	def reset_keybindings(self):
		self.set_keybinding(self.get_from_defaults('Kupfer', 'keybinding'))
		self.set_magic_keybinding(
			self.get_from_defaults('Kupfer', 'magickeybinding'))

	def reset_accelerators(self):
		for key, value in self.get_from_defaults('Keybindings'):
			self._set_config('Keybindings', key, value)

	def get_preferred_tool(self, tool_id):
		"""
		Get preferred ID for a @tool_id

		Supported: 'terminal'
		"""
		return self.get_config("Tools", tool_id)

	def set_preferred_tool(self, tool_id, value):
		return self._set_config("Tools", tool_id, value)

	## Alternatives section
	## Provide alternatives for each category
	## for example the category "terminal"
	def get_valid_alternative_ids(self, category_key):
		"""
		Get a list of (id_, name) tuples for the given @category_key
		"""
		if not category_key in self._alternative_validators:
			return
		validator = self._alternative_validators[category_key]
		for (id_, alternative) in self._alternatives[category_key].iteritems():
			name = alternative["name"]
			if not validator or validator(alternative):
				yield (id_, name)

	def get_all_alternatives(self, category_key):
		return self._alternatives[category_key]

	def get_preferred_alternative(self, category_key):
		"""
		Get preferred alternative dict for @category_key
		"""
		tool_id = self.get_preferred_tool(category_key)
		alternatives = self._alternatives[category_key]
		alt = alternatives.get(tool_id)
		if not alt:
			self.output_debug("Warning, no configuration for", category_key)
		return alt or next(alternatives.itervalues(), None)

	def _update_alternatives(self, category_key, alternatives, validator):
		self._alternatives[category_key] = alternatives
		self._alternative_validators[category_key] = validator
		self.emit("alternatives-changed::"+category_key, category_key)


# Arguments: Section, Key, Value
# Detailed by 'section.key' in lowercase
gobject.signal_new("value-changed", SettingsController,
		gobject.SIGNAL_RUN_LAST | gobject.SIGNAL_DETAILED,
		gobject.TYPE_BOOLEAN, (gobject.TYPE_STRING, gobject.TYPE_STRING,
		gobject.TYPE_PYOBJECT))

# Arguments: Plugin ID, Value
gobject.signal_new("plugin-enabled-changed", SettingsController,
		gobject.SIGNAL_RUN_LAST, gobject.TYPE_BOOLEAN,
		(gobject.TYPE_STRING, gobject.TYPE_INT))

# Arguments: Plugin ID, Value
gobject.signal_new("plugin-toplevel-changed", SettingsController,
		gobject.SIGNAL_RUN_LAST, gobject.TYPE_BOOLEAN,
		(gobject.TYPE_STRING, gobject.TYPE_INT))

# Arguments: Alternative-category
# Detailed by: category key, in lowercase
gobject.signal_new("alternatives-changed", SettingsController,
		gobject.SIGNAL_RUN_LAST | gobject.SIGNAL_DETAILED,
		gobject.TYPE_BOOLEAN,
		(gobject.TYPE_STRING, ))

_settings_controller = None
def GetSettingsController():
	global _settings_controller
	if _settings_controller is None:
		_settings_controller = SettingsController()
	return _settings_controller



class ExtendedSetting(object):
	""" Abstract class for defining non-simple configuration option """
	def load(self, plugin_id, key, config_value):
		''' load value for @plugin_id and @key, @config_value is value
		stored in regular Kupfer config for plugin/key'''
		pass

	def save(self, plugin_id, key):
		''' Save value for @plugin_id and @key.
		@Return value that should be stored in Kupfer config for
		plugin/key (string)'''
		return None


########NEW FILE########
__FILENAME__ = sources
from __future__ import with_statement

import gzip
import hashlib
import itertools
import cPickle as pickle
import os
import threading
import time
import weakref

from kupfer import config, pretty, scheduler
from kupfer import conspickle
from kupfer.obj import base, sources
from kupfer.core import pluginload

class InternalError (Exception):
	pass

class PeriodicRescanner (pretty.OutputMixin):
	"""
	Periodically rescan a @catalog of sources

	Do first rescan after @startup seconds, then
	followup with rescans in @period.

	Each campaign of rescans is separarated by @campaign
	seconds
	"""
	def __init__(self, period=5, startup=10, campaign=3600):
		self.startup = startup
		self.period = period
		self.campaign=campaign
		self.timer = scheduler.Timer()
		# Source -> time mapping
		self.latest_rescan_time = weakref.WeakKeyDictionary()
		self._min_rescan_interval = campaign//4

	def set_catalog(self, catalog):
		self.catalog = catalog
		self.cur = iter(self.catalog)
		self.output_debug("Registering new campaign, in %d s" % self.startup)
		self.timer.set(self.startup, self._new_campaign)
	
	def _new_campaign(self):
		self.output_info("Starting new campaign, interval %d s" % self.period)
		self.cur = iter(self.catalog)
		self.timer.set(self.period, self._periodic_rescan_helper)

	def _periodic_rescan_helper(self):
		# Advance until we find a source that was not recently rescanned
		for next in self.cur:
			oldtime = self.latest_rescan_time.get(next, 0)
			if (time.time() - oldtime) > self._min_rescan_interval:
				self.timer.set(self.period, self._periodic_rescan_helper)
				self._start_source_rescan(next)
				return
		# No source to scan found
		self.output_info("Campaign finished, pausing %d s" % self.campaign)
		self.timer.set(self.campaign, self._new_campaign)

	def rescan_now(self, source, force_update=False):
		"Rescan @source immediately"
		if force_update:
			# if forced update, we know that it was brought up to date
			self.latest_rescan_time[source] = time.time()
		self.rescan_source(source, force_update=force_update)

	def _start_source_rescan(self, source):
		self.latest_rescan_time[source] = time.time()
		if not source.is_dynamic():
			thread = threading.Thread(target=self.rescan_source, args=(source,))
			thread.setDaemon(True)
			thread.start()

	def rescan_source(self, source, force_update=True):
		list(source.get_leaves(force_update=force_update))

class SourcePickler (pretty.OutputMixin):
	"""
	Takes care of pickling and unpickling Kupfer Sources.
	"""
	pickle_version = 4
	name_template = "k%s-v%d.pickle.gz"

	def __init__(self):
		self.open = lambda f,mode: gzip.open(f, mode, compresslevel=3)

	def should_use_cache(self):
		return config.has_capability("CACHE")

	def rm_old_cachefiles(self):
		"""Checks if there are old cachefiles from last version,
		and deletes those
		"""
		for dpath, dirs, files in os.walk(config.get_cache_home()):
			# Look for files matching beginning and end of
			# name_template, with the previous file version
			chead, ctail = self.name_template.split("%s")
			ctail = ctail % ((self.pickle_version -1),)
			obsolete_files = []
			for cfile in files:
				if cfile.startswith(chead) and cfile.endswith(ctail):
					cfullpath = os.path.join(dpath, cfile)
					obsolete_files.append(cfullpath)
		if obsolete_files:
			self.output_info("Removing obsolete cache files:", sep="\n",
					*obsolete_files)
			for fpath in obsolete_files:
				# be overly careful
				assert fpath.startswith(config.get_cache_home())
				assert "kupfer" in fpath
				os.unlink(fpath)

	def get_filename(self, source):
		"""Return cache filename for @source"""
		# make sure we take the source name into account
		# so that we get a "break" when locale changes
		source_id = "%s%s%s" % (repr(source), str(source), source.version)
		bytes = hashlib.md5(source_id).digest()
		hashstr = bytes.encode("base64").rstrip("\n=").replace("/", "-")
		filename = self.name_template % (hashstr, self.pickle_version)
		return os.path.join(config.get_cache_home(), filename)

	def unpickle_source(self, source):
		if not self.should_use_cache():
			return None

		cached = self._unpickle_source(self.get_filename(source))
		if not cached:
			return None

		# check consistency
		if source == cached:
			return cached
		else:
			self.output_debug("Cached version mismatches", source)
		return None
	def _unpickle_source(self, pickle_file):
		try:
			pfile = self.open(pickle_file, "rb")
		except IOError, e:
			return None
		try:
			source = pickle.loads(pfile.read())
			assert isinstance(source, base.Source), "Stored object not a Source"
			sname = os.path.basename
			self.output_debug("Loading", source, "from", sname(pickle_file))
		except (pickle.PickleError, Exception), e:
			source = None
			self.output_info("Error loading %s: %s" % (pickle_file, e))
		return source

	def pickle_source(self, source):
		if not self.should_use_cache():
			return None
		return self._pickle_source(self.get_filename(source), source)
	def _pickle_source(self, pickle_file, source):
		"""
		When writing to a file, use pickle.dumps()
		and then write the file in one go --
		if the file is a gzip file, pickler's thousands
		of small writes are very slow
		"""
		output = self.open(pickle_file, "wb")
		sname = os.path.basename
		self.output_debug("Storing", source, "as", sname(pickle_file))
		output.write(pickle.dumps(source, pickle.HIGHEST_PROTOCOL))
		output.close()
		return True

class SourceDataPickler (pretty.OutputMixin):
	""" Takes care of pickling and unpickling Kupfer Sources' configuration
	or data.

	The SourceDataPickler requires a protocol of three methods:

	config_save_name()
	  Return an ascii name to be used as a token/key for the configuration

	config_save()
	  Return an object to be saved as configuration

	config_restore(obj)
	  Receive the configuration object `obj' to load
	"""
	pickle_version = 1
	name_template = "config-%s-v%d.pickle"

	def __init__(self):
		self.open = open

	@classmethod
	def get_filename(cls, source):
		"""Return filename for @source"""
		name = source.config_save_name()
		filename = cls.name_template % (name, cls.pickle_version)
		return config.save_config_file(filename)

	@classmethod
	def source_has_config(self, source):
		return getattr(source, "config_save_name", None)

	def load_source(self, source):
		data = self._load_data(self.get_filename(source))
		if not data:
			return True
		source.config_restore(data)

	def _load_data(self, pickle_file):
		try:
			pfile = self.open(pickle_file, "rb")
		except IOError, e:
			return None
		try:
			data = conspickle.BasicUnpickler.loads(pfile.read())
			sname = os.path.basename(pickle_file)
			self.output_debug("Loaded configuration from", sname)
			# self.output_debug(data)
		except (pickle.PickleError, Exception), e:
			data = None
			self.output_error("Loading %s: %s" % (pickle_file, e))
		return data

	def save_source(self, source):
		return self._save_data(self.get_filename(source), source)
	def _save_data(self, pickle_file, source):
		sname = os.path.basename(pickle_file)
		obj = source.config_save()
		try:
			data = pickle.dumps(obj, pickle.HIGHEST_PROTOCOL)
		except pickle.PickleError:
			import traceback
			self.output_error("Unable to save configuration for", source)
			self.output_error("Saving configuration raised an exception:")
			traceback.print_exc()
			self.output_error("Please file a bug report")
			data = None
		if data:
			self.output_debug("Storing configuration for", source, "as", sname)
			## Write to temporary and rename into place
			tmp_pickle_file = "%s.%s" % (pickle_file, os.getpid())
			output = self.open(tmp_pickle_file, "wb")
			output.write(data)
			output.close()
			os.rename(tmp_pickle_file, pickle_file)
		return True

class SourceController (pretty.OutputMixin):
	"""Control sources; loading, pickling, rescanning

	Call .add() to add sources.
	Call .initialize() before use commences.
	"""
	def __init__(self):
		self.rescanner = PeriodicRescanner(period=3)
		self.sources = set()
		self.toplevel_sources = set()
		self.text_sources = set()
		self.content_decorators = {}
		self.action_decorators = {}
		self.action_generators = []
		self.plugin_object_map = weakref.WeakKeyDictionary()
		self.loaded_successfully = False
		self.did_finalize_sources = False
		self._pre_root = None

	def add(self, plugin_id, srcs, toplevel=False, initialize=False):
		self._invalidate_root()
		sources = set(self._try_restore(srcs))
		sources.update(srcs)

		self.sources.update(sources)
		if toplevel:
			self.toplevel_sources.update(sources)
		if initialize:
			self._initialize_sources(sources)
			self._cache_sources(sources)
			self.rescanner.set_catalog(self.sources)
		if plugin_id:
			self._register_plugin_objects(plugin_id, *sources)

	def set_toplevel(self, src, toplevel):
		assert src in self.sources, "Source is not tracked in SourceController"
		self._invalidate_root()
		if toplevel:
			self.toplevel_sources.add(src)
		else:
			self.toplevel_sources.discard(src)

	def _register_plugin_objects(self, plugin_id, *objects):
		"Register a plugin id mapping for @objects"
		for obj in objects:
			self.plugin_object_map[obj] = plugin_id
			pretty.print_debug(__name__, "Add", repr(obj))

	def _remove(self, src):
		self._invalidate_root()
		self.toplevel_sources.discard(src)
		self.sources.discard(src)
		self.rescanner.set_catalog(self.sources)
		self._finalize_source(src)
		pretty.print_debug(__name__, "Remove", repr(src))

	def get_plugin_id_for_object(self, obj):
		id_ = self.plugin_object_map.get(obj)
		#self.output_debug("Object", repr(obj), "has id", id_, id(obj))
		return id_

	def remove_objects_for_plugin_id(self, plugin_id):
		"""Remove all objects for @plugin_id

		Return True if the catalog configuration changed
		"""
		removed_source = False
		self.output_debug("Removing objects for plugin:", plugin_id)

		# sources
		for src in list(self.sources):
			if self.get_plugin_id_for_object(src) == plugin_id:
				self._remove(src)
				removed_source = True

		# all other objects
		def remove_matching_objects(collection, plugin_id):
			for obj in list(collection):
				if self.get_plugin_id_for_object(obj) == plugin_id:
					collection.remove(obj)
					pretty.print_debug(__name__, "Remove", repr(obj))

		remove_matching_objects(self.text_sources, plugin_id)

		for typ in self.content_decorators:
			remove_matching_objects(self.content_decorators[typ], plugin_id)

		for typ in self.action_decorators:
			remove_matching_objects(self.action_decorators[typ], plugin_id)

		remove_matching_objects(self.action_generators, plugin_id)

		return removed_source

	def get_sources(self):
		return self.sources

	def add_text_sources(self, plugin_id, srcs):
		self.text_sources.update(srcs)
		self._register_plugin_objects(plugin_id, *srcs)

	def get_text_sources(self):
		return self.text_sources

	def add_content_decorators(self, plugin_id, decos):
		for typ in decos:
			self.content_decorators.setdefault(typ, set()).update(decos[typ])
			self._register_plugin_objects(plugin_id, *decos[typ])

	def add_action_decorators(self, plugin_id, decos):
		for typ in decos:
			self.action_decorators.setdefault(typ, set()).update(decos[typ])
			self._register_plugin_objects(plugin_id, *decos[typ])
		for typ in self.action_decorators:
			self._disambiguate_actions(self.action_decorators[typ])

	def add_action_generator(self, plugin_id, agenerator):
		self.action_generators.append(agenerator)
		self._register_plugin_objects(plugin_id, agenerator)

	def _disambiguate_actions(self, actions):
		"""Rename actions by the same name (adding a suffix)"""
		# FIXME: Disambiguate by plugin name, not python module name
		names = {}
		renames = set()
		for action in actions:
			name = unicode(action)
			if name in names:
				renames.add(names[name])
				renames.add(action)
			else:
				names[name] = action
		for action in renames:
			self.output_debug("Disambiguate Action %s" % (action, ))
			action.name += " (%s)" % (type(action).__module__.split(".")[-1],)

	def __contains__(self, src):
		return src in self.sources
	def __getitem__(self, src):
		if not src in self:
			raise KeyError
		for s in self.sources:
			if s == src:
				return s
	@property
	def root(self):
		"""Get the root source of catalog"""
		if len(self.sources) == 1:
			root_catalog, = self.sources
		elif len(self.sources) > 1:
			firstlevel = self._firstlevel
			root_catalog = sources.MultiSource(firstlevel)
		else:
			root_catalog = None
		return root_catalog

	def _invalidate_root(self):
		"The source root needs to be recalculated"
		self._pre_root = None

	@property
	def _firstlevel(self):
		if self._pre_root:
			return self._pre_root
		sourceindex = set(self.sources)
		kupfer_sources = sources.SourcesSource(self.sources)
		sourceindex.add(kupfer_sources)
		# Make sure firstlevel is ordered
		# So that it keeps the ordering.. SourcesSource first
		firstlevel = []
		firstlevel.append(sources.SourcesSource(sourceindex))
		firstlevel.extend(set(self.toplevel_sources))
		self._pre_root = firstlevel
		return firstlevel

	@classmethod
	def good_source_for_types(cls, s, types):
		"""return whether @s provides good leaves for @types
		"""
		provides = list(s.provides())
		if not provides:
			return True
		for t in provides:
			if issubclass(t, types):
				return True

	def root_for_types(self, types):
		"""
		Get root for a flat catalog of all catalogs
		providing at least Leaves of @types

		Take all sources which:
			Provide a type T so that it is a subclass
			to one in the set of types we want
		"""
		types = tuple(types)
		firstlevel = set()
		# include the Catalog index since we want to include
		# the top of the catalogs (like $HOME)
		catalog_index = (sources.SourcesSource(self.sources), )
		for s in itertools.chain(self.sources, catalog_index):
			if self.good_source_for_types(s, types):
				firstlevel.add(s)
		return sources.MultiSource(firstlevel)

	def get_canonical_source(self, source):
		"Return the canonical instance for @source"
		# check if we already have source, then return that
		if source in self:
			return self[source]
		else:
			source.initialize()
			return source

	def get_contents_for_leaf(self, leaf, types=None):
		"""Iterator of content sources for @leaf,
		providing @types (or None for all)"""
		for typ in self.content_decorators:
			if not isinstance(leaf, typ):
				continue
			for content in self.content_decorators[typ]:
				dsrc = content.decorate_item(leaf)
				if dsrc:
					if types and not self.good_source_for_types(dsrc, types):
						continue
					yield self.get_canonical_source(dsrc)

	def get_actions_for_leaf(self, leaf):
		for typ in self.action_decorators:
			if isinstance(leaf, typ):
				for act in self.action_decorators[typ]:
					yield act
		for agenerator in self.action_generators:
			for action in agenerator.get_actions_for_leaf(leaf):
				yield action

	def decorate_object(self, obj, action=None):
		if hasattr(obj, "has_content"):
			types = tuple(action.object_types()) if action else ()
			contents = list(self.get_contents_for_leaf(obj, types))
			content = contents[0] if contents else None
			if len(contents) > 1:
				content = sources.SourcesSource(contents, name=unicode(obj),
						use_reprs=False)
			obj.add_content(content)

	def finalize(self):
		"Finalize all sources, equivalent to deactivating all sources"
		for src in self.sources:
			src.finalize()
		self.did_finalize_sources = True

	def save_cache(self):
		"Save all caches (non-important data)"
		if not self.did_finalize_sources:
			raise InternalError("Called save_cache without finalize!")
		if self.loaded_successfully:
			self._pickle_sources(self.sources)
		else:
			self.output_debug("Not writing cache on failed load")

	def save_data(self):
		"Save (important) user data/configuration"
		if not self.loaded_successfully:
			self.output_info("Not writing configuration on failed load")
			return
		configsaver = SourceDataPickler()
		for source in self.sources:
			if configsaver.source_has_config(source):
				self._save_source(source, pickler=configsaver)

	@classmethod
	def _save_source(self, source, pickler=None):
		configsaver = pickler or SourceDataPickler()
		configsaver.save_source(source)

	def _finalize_source(self, source):
		"Either save config, or save cache for @source"
		source.finalize()
		if SourceDataPickler.source_has_config(source):
			self._save_source(source)
		elif not source.is_dynamic():
			self._pickle_source(source)

	def _pickle_sources(self, sources):
		sourcepickler = SourcePickler()
		sourcepickler.rm_old_cachefiles()
		for source in sources:
			if (source.is_dynamic() or
				SourceDataPickler.source_has_config(source)):
				continue
			self._pickle_source(source, pickler=sourcepickler)

	@classmethod
	def _pickle_source(self, source, pickler=None):
		sourcepickler = pickler or SourcePickler()
		sourcepickler.pickle_source(source)

	def _try_restore(self, sources):
		"""
		Try to restore the source that is equivalent to the
		"dummy" instance @source, from cache, or from saved configuration.
		yield the instances that succeed.
		"""
		sourcepickler = SourcePickler()
		configsaver = SourceDataPickler()
		for source in set(sources):
			if configsaver.source_has_config(source):
				configsaver.load_source(source)
			else:
				source = sourcepickler.unpickle_source(source)
			if source:
				yield source

	def _remove_source(self, source):
		"Oust @source from catalog if any exception is raised"
		self.sources.discard(source)
		self.toplevel_sources.discard(source)
		source_type = type(source)
		for typ in self.content_decorators:
			self.content_decorators[typ].discard(source_type)

	def initialize(self):
		"Initialize all sources and cache toplevel sources"
		self._initialize_sources(self.sources)
		self.rescanner.set_catalog(self.sources)
		self._cache_sources(self.toplevel_sources)
		self.loaded_successfully = True

	def _initialize_sources(self, sources):
		for src in set(sources):
			with pluginload.exception_guard(src, self._remove_source, src):
				src.initialize()

	def _cache_sources(self, sources):
		# Make sure that the toplevel sources are chached
		# either newly rescanned or the cache is fully loaded
		for src in set(sources):
			with pluginload.exception_guard(src, self._remove_source, src):
				self.rescanner.rescan_now(src, force_update=False)


_source_controller = None
def GetSourceController():
	global _source_controller
	if _source_controller is None:
		_source_controller = SourceController()
	return _source_controller


########NEW FILE########
__FILENAME__ = datatools
import itertools

try:
	from collections import OrderedDict
except ImportError:
	from UserDict import DictMixin
	OrderedDict = None

class SavedIterable (object):
	"""Wrap an iterable and cache it.

	The SavedIterable can be accessed streamingly, while still being
	incrementally cached. Later attempts to iterate it will access the
	whole of the sequence.

	When it has been cached to its full extent once, it reduces to a
	thin wrapper of a sequence iterator. The SavedIterable will pickle
	into a list.

	>>> s = SavedIterable(xrange(5))
	>>> iter(s).next()
	0
	>>> list(s)
	[0, 1, 2, 3, 4]

	>>> iter(s)   # doctest: +ELLIPSIS
	<listiterator object at 0x...>

	>>> import pickle
	>>> pickle.loads(pickle.dumps(s))
	[0, 1, 2, 3, 4]

	>>> u = SavedIterable(xrange(5))
	>>> one, two = iter(u), iter(u)
	>>> one.next(), two.next()
	(0, 0)
	>>> list(two)
	[1, 2, 3, 4]
	>>> list(one)
	[1, 2, 3, 4]

	>>> SavedIterable(range(3))
	[0, 1, 2]
	"""
	def __new__(cls, iterable):
		if isinstance(iterable, list):
			return iterable
		return object.__new__(cls)
	def __init__(self, iterable):
		self.iterator = iter(iterable)
		self.data = []
	def __iter__(self):
		if self.iterator is None:
			return iter(self.data)
		return self._incremental_caching_iter()
	def _incremental_caching_iter(self):
		indices = itertools.count()
		while True:
			idx = indices.next()
			try:
				yield self.data[idx]
			except IndexError:
				pass
			else:
				continue
			if self.iterator is None:
				return
			try:
				x = self.iterator.next()
				self.data.append(x)
				yield x
			except StopIteration:
				self.iterator = None
	def __reduce__(self):
		# pickle into a list with __reduce__
		# (callable, args, state, listitems)
		return (list, (), None, iter(self))

def UniqueIterator(seq, key=None):
	"""
	yield items of @seq with set semantics; no duplicates

	>>> list(UniqueIterator([1, 2, 3, 3, 5, 1]))
	[1, 2, 3, 5]
	>>> list(UniqueIterator([1, -2, 3, -3, -5, 2], key=abs))
	[1, -2, 3, -5]
	"""
	coll = set()
	if key is None:
		for obj in seq:
			if obj not in coll:
				yield obj
				coll.add(obj)
		return
	else:
		for obj in seq:
			K = key(obj)
			if K not in coll:
				yield obj
				coll.add(K)


if not OrderedDict:
	"""
	The following is:
	http://code.activestate.com/recipes/576693/
	Created by Raymond Hettinger on Wed, 18 Mar 2009 (MIT) 
	Licensed under the MIT License
	"""

	class OrderedDict(dict, DictMixin):

		def __init__(self, *args, **kwds):
			if len(args) > 1:
				raise TypeError('expected at most 1 arguments, got %d' % len(args))
			try:
				self.__end
			except AttributeError:
				self.clear()
			self.update(*args, **kwds)

		def clear(self):
			self.__end = end = []
			end += [None, end, end]         # sentinel node for doubly linked list
			self.__map = {}                 # key --> [key, prev, next]
			dict.clear(self)

		def __setitem__(self, key, value):
			if key not in self:
				end = self.__end
				curr = end[1]
				curr[2] = end[1] = self.__map[key] = [key, curr, end]
			dict.__setitem__(self, key, value)

		def __delitem__(self, key):
			dict.__delitem__(self, key)
			key, prev, next = self.__map.pop(key)
			prev[2] = next
			next[1] = prev

		def __iter__(self):
			end = self.__end
			curr = end[2]
			while curr is not end:
				yield curr[0]
				curr = curr[2]

		def __reversed__(self):
			end = self.__end
			curr = end[1]
			while curr is not end:
				yield curr[0]
				curr = curr[1]

		def popitem(self, last=True):
			if not self:
				raise KeyError('dictionary is empty')
			if last:
				key = reversed(self).next()
			else:
				key = iter(self).next()
			value = self.pop(key)
			return key, value

		def __reduce__(self):
			items = [[k, self[k]] for k in self]
			tmp = self.__map, self.__end
			del self.__map, self.__end
			inst_dict = vars(self).copy()
			self.__map, self.__end = tmp
			if inst_dict:
				return (self.__class__, (items,), inst_dict)
			return self.__class__, (items,)

		def keys(self):
			return list(self)

		setdefault = DictMixin.setdefault
		update = DictMixin.update
		pop = DictMixin.pop
		values = DictMixin.values
		items = DictMixin.items
		iterkeys = DictMixin.iterkeys
		itervalues = DictMixin.itervalues
		iteritems = DictMixin.iteritems

		def __repr__(self):
			if not self:
				return '%s()' % (self.__class__.__name__,)
			return '%s(%r)' % (self.__class__.__name__, self.items())

		def copy(self):
			return self.__class__(self)

		@classmethod
		def fromkeys(cls, iterable, value=None):
			d = cls()
			for key in iterable:
				d[key] = value
			return d

		def __eq__(self, other):
			if isinstance(other, OrderedDict):
				return len(self)==len(other) and self.items() == other.items()
			return dict.__eq__(self, other)

		def __ne__(self, other):
			return not self == other

class LruCache (object):
	"""
	Least-recently-used cache mapping of
	size @maxsiz
	"""
	def __init__(self, maxsiz):
		self.d = OrderedDict()
		self.maxsiz = maxsiz

	def __contains__(self, key):
		return key in self.d

	def __setitem__(self, key, value):
		self.d.pop(key, None)
		self.d[key] = value
		if len(self.d) > self.maxsiz:
			# remove the first item (was inserted longest time ago)
			lastkey = next(iter(self.d))
			self.d.pop(lastkey)

	def __getitem__(self, key):
		try:
			value = self.d.pop(key)
		except KeyError:
			raise
		# reinsert the value, puts it "last" in the order
		self.d[key] = value
		return value

if __name__ == '__main__':
	import doctest
	doctest.testmod()

########NEW FILE########
__FILENAME__ = dbuscompat
"""Support code for implementing D-Bus services via GObjects."""

# Copyright (C) 2007 Collabora Ltd. <http://www.collabora.co.uk/>
#
# Permission is hereby granted, free of charge, to any person
# obtaining a copy of this software and associated documentation
# files (the "Software"), to deal in the Software without
# restriction, including without limitation the rights to use, copy,
# modify, merge, publish, distribute, sublicense, and/or sell copies
# of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be
# included in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
# HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
# WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
# DEALINGS IN THE SOFTWARE.

import gobject
import dbus.service

class ExportedGObjectType(gobject.GObjectMeta, dbus.service.InterfaceType):
    """A metaclass which inherits from both GObjectMeta and
    `dbus.service.InterfaceType`. Used as the metaclass for `ExportedGObject`.
    """
    def __init__(cls, name, bases, dct):
        gobject.GObjectMeta.__init__(cls, name, bases, dct)
        dbus.service.InterfaceType.__init__(cls, name, bases, dct)

class ExportedGObject(gobject.GObject, dbus.service.Object):
    """A GObject which is exported on the D-Bus.

    Because GObject and `dbus.service.Object` both have custom metaclasses,
    the naive approach using simple multiple inheritance won't work. This
    class has `ExportedGObjectType` as its metaclass, which is sufficient
    to make it work correctly.
    """
    __metaclass__ = ExportedGObjectType

    def __init__(self, conn=None, object_path=None, **kwargs):
        """Initialize an exported GObject.

        :Parameters:
            `conn` : dbus.connection.Connection
                The D-Bus connection or bus
            `object_path` : str
                The object path at which to register this object.
        :Keywords:
            `bus_name` : dbus.service.BusName
                A bus name to be held on behalf of this object, or None.
            `gobject_properties` : dict
                GObject properties to be set on the constructed object.

                Any unrecognised keyword arguments will also be interpreted
                as GObject properties.
            """
        bus_name = kwargs.pop('bus_name', None)
        gobject_properties = kwargs.pop('gobject_properties', None)

        if gobject_properties is not None:
            kwargs.update(gobject_properties)
        gobject.GObject.__init__(self, **kwargs)
        dbus.service.Object.__init__(self, conn=conn,
                                     object_path=object_path,
                                     bus_name=bus_name)

########NEW FILE########
__FILENAME__ = desktop_launch
import os

import pygtk
pygtk.require('2.0')
import glib
import gio
import gtk

import xdg.DesktopEntry
import xdg.Exceptions

from kupfer import desktop_parse
from kupfer import kupferstring
from kupfer import pretty
from kupfer import terminal

__all__ = ['launch_app_info', 'spawn_app', 'spawn_app_id']

STARTUP_ENV = "DESKTOP_STARTUP_ID"

# TODO: Broadcast Gio's launched message on dbus
# NOTE: GDK's startup notification things that we use
#       are really only sending xmessages. (roughly).

def debug_log(*args):
	pretty.print_debug(__name__, *args)
warning_log = debug_log

def error_log(*args):
	pretty.print_error(__name__, *args)
def exc_log():
	pretty.print_exc(__name__)

class SpawnError (Exception):
	"Error starting application"

class ResourceLookupError (Exception):
	"Unable to find resource"

class ResourceReadError (Exception):
	"Unable to open resource"

def gtk_to_unicode(gtkstring):
	"""Return unicode for a GTK/GLib string (bytestring or unicode)"""
	if isinstance(gtkstring, unicode):
		return gtkstring
	return gtkstring.decode("UTF-8", "ignore")

def find_desktop_file(desk_id):
	"""Find file for @desk_id or raise ResourceLookupError

	Desktop files are found by appending /applications/ to
	$XDG_DATA_DIRS, but if they are located in subdirs of that,
	then additional 'subdirectory-' prefixes are used.
	"""
	if not desk_id:
		raise ResourceLookupError("Empty id")
	try:
		return next(xdg.BaseDirectory.load_data_paths("applications", desk_id))
	except StopIteration:
		## it was not found as an immediate child of the data paths,
		## so we split by the hyphens and search deeper
		file_id = desk_id
		directories = ['applications']

		def lookup(path):
			"""Return location for @path if exists, else none"""
			return next(xdg.BaseDirectory.load_data_paths(*path), None)

		def get_dir_id_depth(desk_id, depth):
			"split 'hyph-example-id' at the nth hyphen"
			parts = desk_id.split('-', depth)
			return '-'.join(parts[:depth]), '-'.join(parts[depth:])

		while 1:
			## try the first parts of the id to see if it matches a directory
			for x in xrange(1,4):
				dirname, rest_id = get_dir_id_depth(file_id, x)
				if rest_id and lookup(directories + [dirname]):
					file_id = rest_id
					directories.append(dirname)
					break
			else:
				## we did not reach break
				break
			desktop_file_path = lookup(directories + [file_id])
			if desktop_file_path:
				return desktop_file_path
	raise ResourceLookupError("Cannot locate '%s'" % (desk_id,))

def read_desktop_info(desktop_file):
	"""
	Get the keys StartupNotify, Terminal, Exec, Path, Icon
	Return dict with bool and unicode values
	"""
	# Return values in unicode
	try:
		de = xdg.DesktopEntry.DesktopEntry(desktop_file)
	except xdg.Exceptions.Error:
		raise ResourceReadError
	if not de.getExec():
		raise ResourceReadError("Invalid data: empty Exec key")
	return {
		"Terminal": de.getTerminal(),
		"StartupNotify": de.getStartupNotify(),
		"Exec": gtk_to_unicode(de.getExec()),
		"Path": gtk_to_unicode(de.getPath()),
		"Icon": gtk_to_unicode(de.getIcon()),
		"Name": gtk_to_unicode(de.getName()),
	}

def create_desktop_info(commandline, name, icon, work_dir, in_terminal, startup_notify):
	return {
		"Terminal": in_terminal,
		"StartupNotify": startup_notify,
		"Exec": commandline,
		"Path": work_dir,
		"Icon": icon,
		"Name": name,
	}


def replace_format_specs(argv, location, desktop_info, gfilelist):
	"""
	http://standards.freedesktop.org/desktop-entry-spec/latest/ar01s06.html

	Replace format specifiers

	%% literal %
	%f file
	%F list of files
	%u URL
	%U list of URLs
	%i --icon <Icon key>
	%c Translated name
	%k location of .desktop file

	deprecated are removed:
	%d %D %n %N %v %m

	apart from those, all other.. stay and are ignored
	Like other implementations, we do actually insert
	a local path for %u and %U if it exists.

	Return (supports_single, added_at_end, argv)

	supports_single: Launcher only supports a single file
	                 caller has to re-call for each file
	added_at_end:    No format found for the file, it was added
	                 at the end
	"""
	supports_single_file = False
	files_added_at_end = False
	class Flags(object):
		did_see_small_f = False
		did_see_large_f = False

	fileiter = iter(gfilelist)

	def get_file_path(gfile):
		if not gfile:
			return ""
		return gfile.get_path() or gfile.get_uri()

	def get_next_file_path():
		try:
			f = next(fileiter)
		except StopIteration:
			return ""
		return get_file_path(f)

	def replace_single_code(key):
		"Handle all embedded format codes, including those to be removed"
		deprecated = set(['%d', '%D', '%n', '%N', '%v', '%m'])
		if key in deprecated:
			return ""
		if key == "%%":
			return "%"
		if key == "%f" or key == "%u":
			if Flags.did_see_large_f or Flags.did_see_small_f:
				warning_log("Warning, multiple file format specs!")
				return ""
			Flags.did_see_small_f = True
			return get_next_file_path()

		if key == "%c":
			return gtk_to_unicode(desktop_info["Name"] or location)
		if key == "%k":
			return location
		else:
			return None

	def replace_array_format(elem):
		"""
		Handle array format codes -- only recognized as single arguments
		
		Return  flag, arglist
		where flag is true if something was replaced
		"""
		if elem == "%U" or elem == "%F":
			if Flags.did_see_large_f or Flags.did_see_small_f:
				warning_log("Warning, multiple file format specs!")
				return True, []
			Flags.did_see_large_f = True
			return True, filter(bool,[get_file_path(f) for f in gfilelist])
		if elem == "%i":
			if desktop_info["Icon"]:
				return True, ["--icon", desktop_info["Icon"]]
			return True, []
		else:
			return False, elem

	def two_part_unescaper(s, repfunc):
		"""
		Handle embedded format codes

		Scan @s two characters at a time and replace using @repfunc
		"""
		if not s:
			return s
		def _inner():
			it = iter(zip(s, s[1:]))
			for cur, nex in it:
				key = cur+nex
				rep = repfunc(key)
				if rep is not None:
					yield rep
					# skip a step in the iter
					try:
						it.next()
					except StopIteration:
						return
				else:
					yield cur
			yield s[-1]
		return ''.join(_inner())

	new_argv = []
	for x in argv:
		if not x:
			# the arg is an empty string, we don't need extra processing
			new_argv.append(x)
			continue
		succ, newargs = replace_array_format(x)
		if succ:
			new_argv.extend(newargs)
		else:
			arg = two_part_unescaper(x, replace_single_code)
			if arg:
				new_argv.append(arg)
	
	if len(gfilelist) > 1 and not Flags.did_see_large_f:
		supports_single_file = True
	if not Flags.did_see_small_f and not Flags.did_see_large_f and len(gfilelist):
		files_added_at_end = True
		new_argv.append(get_next_file_path())

	return supports_single_file, files_added_at_end, new_argv

def _file_for_app_info(app_info):
	try:
		desktop_file = find_desktop_file(app_info.get_id())
	except ResourceLookupError:
		exc_log()
		desktop_file = None
	return desktop_file

def _info_for_desktop_file(desktop_file):
	if not desktop_file:
		return None
	try:
		desktop_info = read_desktop_info(desktop_file)
	except ResourceReadError:
		desktop_info = None
		exc_log()
	return desktop_info

def launch_app_info(app_info, gfiles=[], in_terminal=None, timestamp=None,
	                desktop_file=None, launch_cb=None, screen=None):
	"""
	Launch @app_info, opening @gfiles

	@in_terminal: override Terminal flag
	@timestamp: override timestamp
	@desktop_file: specify location of desktop file
	@launch_cb: Called once per launched process,
	            like ``spawn_app``

	Will pass on exceptions from spawn_app
	"""
	desktop_file = desktop_file or _file_for_app_info(app_info)
	desktop_info = _info_for_desktop_file(desktop_file)
	if not desktop_file or not desktop_info:
		# Allow in-memory app_info creations (without id or desktop file)
		desktop_file = ""
		desktop_info = create_desktop_info(app_info.get_commandline() or "",
		                                   app_info.get_name(),
		                                   "",
		                                   "",
		                                   False,
		                                   False)
		# in this case, the command line is already primarily escaped
		argv = desktop_parse.parse_argv(desktop_info["Exec"])
	else:
		# In the normal case, we must first escape one round
		argv = desktop_parse.parse_unesc_argv(desktop_info["Exec"])
	assert argv and argv[0]

	# Now Resolve the %f etc format codes
	multiple_needed, missing_format, launch_argv = \
			replace_format_specs(argv, desktop_file, desktop_info, gfiles)

	if not multiple_needed:
		# Launch 1 process
		launch_records = [(launch_argv, gfiles)]

	else:
		# Launch one process per file
		launch_records = [(launch_argv, [gfiles[0]])]
		for f in gfiles[1:]:
			_ignore1, _ignore2, launch_argv = \
				replace_format_specs(argv, desktop_file, desktop_info, [f])
			launch_records.append((launch_argv, [f]))

	notify = desktop_info["StartupNotify"]
	workdir = desktop_info["Path"] or None

	if in_terminal is None:
		in_terminal = desktop_info["Terminal"]
	if in_terminal:
		term = terminal.get_configured_terminal()
		notify = notify or term["startup_notify"]

	for argv, gfiles in launch_records:
		if in_terminal:
			term = terminal.get_configured_terminal()
			targv = list(term["argv"])
			if term["exearg"]:
				targv.append(term["exearg"])
			argv = targv + argv
		ret = spawn_app(app_info, argv, gfiles, workdir, notify,
		                timestamp=timestamp, launch_cb=launch_cb,
		                screen=screen)
		if not ret:
			return False
	return True

def spawn_app_id(app_id, argv, workdir=None, startup_notify=True, screen=None):
	"""
	Spawn @argv trying to notify it as if it is app_id
	"""
	try:
		app_info = get_info_for_id(app_id)
	except RuntimeError:
		app_info = None
		startup_notify = False
	return spawn_app(app_info, argv, [], workdir, startup_notify, screen=screen)

def spawn_app(app_info, argv, filelist, workdir=None, startup_notify=True,
	          timestamp=None, launch_cb=None, screen=None):
	"""
	Spawn app.

	@argv: argument list including files
	@workdir: where to set workdir if not cwd
	@app_info: Used for startup notification, if @startup_notify is True
	@filelist: Used for startup notification
	@startup_notify: Use startup notification
	@timestamp: Event timestamp
	@launch_cb: Called if successful with
	            (argv, pid, notify_id, filelist, timestamp)
	@screen: GdkScreen on which to put the application

	return pid if successful
	raise SpawnError on error
	"""
	notify_id = None
	if startup_notify:
		ctx = gtk.gdk.AppLaunchContext()
		ctx.set_timestamp(timestamp or gtk.get_current_event_time())
		if screen:
			ctx.set_screen(screen)
		# This not only returns the string ID but
		# it actually starts the startup notification!
		notify_id = ctx.get_startup_notify_id(app_info, filelist)
		child_env_add = {STARTUP_ENV: notify_id}
	else:
		child_env_add = {}
	if screen:
		child_env_add["DISPLAY"]=screen.make_display_name()

	if not workdir or not os.path.exists(workdir):
		workdir = "."

	argv = list(locale_encode_argv(argv))

	try:
		(pid, _ig1, _ig2, _ig3) = glib.spawn_async(argv,
		                       working_directory=workdir,
		                       flags=glib.SPAWN_SEARCH_PATH,
		                       child_setup=child_setup,
		                       user_data=child_env_add)
		debug_log("Launched", argv,  notify_id, "pid:", pid)
	except glib.GError as exc:
		error_log("Error Launching ", argv, unicode(exc))
		if notify_id:
			gtk.gdk.notify_startup_complete_with_id(notify_id)
		raise SpawnError(unicode(exc))
	if launch_cb:
		launch_cb(argv, pid, notify_id, filelist, timestamp)
	return pid

def child_setup(add_environ):
	"""Called to setup the child process before exec()
	@add_environ is a dict for extra env variables
	"""
	for key in add_environ:
		os.putenv(key, add_environ[key])

def locale_encode_argv(argv):
	for x in argv:
		if isinstance(x, unicode):
			yield kupferstring.tolocale(x)
		else:
			yield x

def get_info_for_id(id_):
	return gio.unix.DesktopAppInfo(id_)

if __name__ == '__main__':

	while True:
		id_ = raw_input("Give me an App ID > ")
		launch_app_info(get_info_for_id(id_ + ".desktop"), [])
		#launch_app_info(gio.AppInfo("gvim"), [gio.File(".")])


########NEW FILE########
__FILENAME__ = desktop_parse

"""
Implementation of unescaping and unquoting of the Exec= key in
the Desktop Entry Specification (As of March 2011, version 1.1-draft)
http://standards.freedesktop.org/desktop-entry-spec/latest/ar01s06.html
http://standards.freedesktop.org/desktop-entry-spec/desktop-entry-spec-1.1.html#exec-variables

The unescaping we are doing is only one way.. so we unescape according to the
rules, but we accept everything, if validly quoted or not.
"""

import shlex

# This is the "string" type encoding escapes
# this is unescaped before we process anything..
escape_table = {
	r'\s': ' ',
	r'\n': '\n',
	r'\t': '\t',
	r'\r': '\r',
	'\\\\': '\\',
}

# quoted are those chars that need a backslash in front
# (inside a double-quoted section, that is)
quoted = r""" " ` $ \ """.split()
quoted_table = {
	r'\"': '"',
	r'\`': '`',
	r'\$': '$',
	'\\\\': '\\',
}

'''
# reserved are those that need to be inside quotes
# note that all the quoted are also reserved, of course

We don't use these at all
reserved = r""" " ' \ > < ~ | & ; $ * ? # ( ) ` """.split()
reserved.extend([' ', '\t', '\n'])
'''

def two_part_unescaper(s, reptable):
	"Scan @s two characters at a time and replace using @reptable"
	if not s:
		return s
	def _inner():
		it = iter(zip(s, s[1:]))
		for cur, nex in it:
			key = cur+nex
			if key in reptable:
				yield reptable[key]
				try:
					it.next()
				except StopIteration:
					return
			else:
				yield cur
		yield s[-1]
	return ''.join(_inner())

def custom_shlex_split(s, comments=False, posix=True):
	"""
	Wrapping shlex.split
	"""
	if isinstance(s, unicode):
		is_unicode = True
		s = s.encode("UTF-8")
	else:
		is_unicode = False
	lex = shlex.shlex(s, posix=posix)
	lex.whitespace_split = True
	if not comments:
		lex.commenters = ''
	try:
		lex_output = list(lex)
	except ValueError:
		lex_output = [s]

	## extra-unescape  ` and $ that are not handled by shlex
	quoted_shlex = {r'\`': '`', r'\$':'$'}
	lex_output[:] = [two_part_unescaper(x, quoted_shlex) for x in lex_output]
	if is_unicode:
		return [x.decode("UTF-8") for x in lex_output]
	else:
		return lex_output

def unescape(s):
	"Primary unescape of control sequences"
	return two_part_unescaper(s, escape_table)

def test_unescape():
	r"""
	>>> t = r'"This \\$ \\\\ \s\\\\"'
	>>> unescape(t)
	'"This \\$ \\\\  \\\\"'
	>>> unescape(r'\t\s\\\\')
	'\t \\\\'
	"""
	pass

def parse_argv(instr):
	r"""
	Parse quoted @instr into an argv

	This is according to the spec
	>>> parse_argv('env "VAR=is good" ./program')
	['env', 'VAR=is good', './program']
	>>> parse_argv('env "VAR=\\\\ \\$ @ x" ./program')
	['env', 'VAR=\\ $ @ x', './program']
	>>> parse_argv('"\\$" "\\`"  "\\""')
	['$', '`', '"']
	>>> parse_argv('/usr/bin/x-prog -q %F')
	['/usr/bin/x-prog', '-q', '%F']
	>>> parse_argv('env LANG=en_US.UTF-8 freeciv-gtk2')
	['env', 'LANG=en_US.UTF-8', 'freeciv-gtk2']
	>>> parse_argv('emacsclient -a "" -c %f')
	['emacsclient', '-a', '', '-c', '%f']

	== Below this we need quirks mode ==

	The following style is common but not supported in spec
	>>> parse_argv('env VAR="is broken" ./program')
	['env', 'VAR=is broken', './program']

	The following is just completely broken
	>>> parse_argv('./program unquoted\\\\argument')
	['./program', 'unquoted\\argument']

	The following is just completely broken
	>>> parse_argv('./program No\\ Space')
	['./program', 'No Space']

	The following is just insanely broken
	>>> parse_argv("'/opt'/now/'This is broken/'")
	['/opt/now/This is broken/']

	This is broken
	#>>> parse_argv('\\$')
	#['$']
	#>>> parse_argv('\\$ \\`  \\"')
	#['$', '`', '"']

	Unmatched quote, normal mode (just testing that it does not raise)
	>>> parse_argv('"hi there')
	['"hi there']

	Unmatched quote, quirks mode (just testing that it does not raise)
	>>> parse_argv('A\\\\BC "hi there')
	['A\\\\BC "hi there']

	"""
	return custom_shlex_split(instr)

def parse_unesc_argv(instr):
	r"""
	Parse quoted @instr into an argv after unescaping it

	>>> parse_unesc_argv(r'stuff "C:\\\\suck\\\\start.exe"')
	['stuff', 'C:\\suck\\start.exe']

	== Below this we need quirks mode ==

	>>> parse_unesc_argv(r'stuff C:\\\\suck\\\\start.exe')
	['stuff', 'C:\\suck\\start.exe']

	>>> parse_unesc_argv("'/usr'/bin/gnome-terminal -x gvim 'Insanely Broken'Yes")
	['/usr/bin/gnome-terminal', '-x', 'gvim', 'Insanely BrokenYes']
	"""
	return custom_shlex_split(unescape(instr))


if __name__ == "__main__":
	import doctest
	doctest.testmod()

########NEW FILE########
__FILENAME__ = icons
import os

import gtk
from gtk import ICON_LOOKUP_USE_BUILTIN, ICON_LOOKUP_FORCE_SIZE
from gtk.gdk import pixbuf_new_from_file_at_size
from gio import Icon, ThemedIcon, FileIcon, File
from gio import FILE_ATTRIBUTE_STANDARD_ICON, FILE_ATTRIBUTE_THUMBNAIL_PATH
from gobject import GError

from kupfer import config
from kupfer import datatools
from kupfer import pretty
from kupfer import scheduler

icon_cache = {}

# number of elements in icon lru cache (per icon size)
ICON_CACHE_SIZE = 15

LARGE_SZ = 128
SMALL_SZ = 24

gtk.icon_size_register("kupfer-large", LARGE_SZ, LARGE_SZ)
gtk.icon_size_register("kupfer-small", SMALL_SZ, SMALL_SZ)

## default fallbacks for our themable icons
kupfer_icon_fallbacks = {
	'kupfer-execute': 'gtk-execute',
	'kupfer-object': 'gtk-file',
	'kupfer-object-multiple': 'gtk-file',
	'kupfer-catalog': 'folder-saved-search',
}

kupfer_locally_installed_names = set()

def _icon_theme_changed(theme):
	pretty.print_info(__name__, "Icon theme changed, clearing cache")
	global icon_cache
	icon_cache = {}

_default_theme = gtk.icon_theme_get_default()
_default_theme.connect("changed", _icon_theme_changed)
_local_theme = gtk.IconTheme()
_local_theme.set_search_path([])

def parse_load_icon_list(icon_list_data, get_data_func, plugin_name=None):
	"""
	@icon_list_data: A bytestring whose lines identify icons
	@get_data_func: A function to return the data for a relative filename
	@plugin_name: plugin id, if applicable
	"""
	for line in icon_list_data.splitlines():
		# ignore '#'-comments
		if line.startswith("#") or not line.strip():
			continue
		fields = map(str.strip, line.split('\t'))
		if len(fields) < 2:
			pretty.print_error(__name__, "Malformed icon-list line %r from %r" %
			                   (line, plugin_name))
			continue
		icon_name, basename = fields[:2]
		override = ('!override' in fields)
		def wrap_get_data():
			return get_data_func(basename)
		load_icon_from_func(plugin_name, icon_name, wrap_get_data, override)

def load_icon_from_func(plugin_name, icon_name, get_data_func, override=False):
	"""
	Load icon from @icon_data into the name @icon_name

	@get_data_func: function to retrieve the data if needed
	@override: override the icon theme
	"""
	if not override and icon_name in kupfer_locally_installed_names:
		pretty.print_debug(__name__, "Skipping existing", icon_name)
		return
	if not override and _default_theme.has_icon(icon_name):
		pretty.print_debug(__name__, "Skipping themed icon", icon_name)
		return
	try:
		icon_data = get_data_func()
	except:
		pretty.print_error(__name__, "Error loading icon %r for %r" %
		                   (icon_name, plugin_name))
		pretty.print_exc(__name__)
		return
	for size in (SMALL_SZ, LARGE_SZ):
		pixbuf = get_pixbuf_from_data(icon_data, size, size)
		gtk.icon_theme_add_builtin_icon(icon_name, size, pixbuf)
		pretty.print_debug(__name__, "Loading icon", icon_name, "at", size,
				"for", plugin_name)
	kupfer_locally_installed_names.add(icon_name)

def get_icon(key, icon_size):
	"""
	try retrieve icon in cache
	is a generator so it can be concisely called with a for loop
	"""
	try:
		rec = icon_cache[icon_size][key]
	except KeyError:
		return
	yield rec

def store_icon(key, icon_size, icon):
	"""
	Store an icon in cache. It must not have been stored before
	"""
	assert icon, "icon %s may not be %s" % (key, icon)
	icon_rec = icon
	if icon_size not in icon_cache:
		icon_cache[icon_size] = datatools.LruCache(ICON_CACHE_SIZE)
	icon_cache[icon_size][key] = icon_rec

def _get_icon_dwim(icon, icon_size):
	"""Make an icon at @icon_size where
	@icon can be either an icon name, or a gicon
	"""
	if isinstance(icon, Icon):
		return get_icon_for_gicon(icon, icon_size)
	elif icon:
		return get_icon_for_name(icon, icon_size)
	return None

class ComposedIcon (Icon):
	"""
	A composed icon, which kupfer will render to pixbuf as
	background icon with the decorating icon as emblem
	"""

	class Implementation (object):
		"""Base class for the internal implementation

		@minimum_icon_size is the minimum size for
		the composition to be drawn"""
		minimum_icon_size = 48

		def __init__(self, baseicon, emblem):
			self.baseicon = baseicon
			self.emblemicon = emblem

	class _ThemedIcon (Implementation, ThemedIcon):
		def __init__(self, fallback, baseicon, emblem):
			ComposedIcon.Implementation.__init__(self, baseicon, emblem)
			if isinstance(fallback, basestring):
				names = (fallback, )
			else:
				names = fallback.get_names()
			ThemedIcon.__init__(self, names)

	class _FileIcon (Implementation, FileIcon):
		def __init__(self, fallback, baseicon, emblem):
			ComposedIcon.Implementation.__init__(self, baseicon, emblem)
			FileIcon.__init__(self, fallback.get_file())

	def __new__(cls, baseicon, emblem, emblem_is_fallback=False):
		"""Contstuct a composed icon from @baseicon and @emblem,
		which may be GIcons or icon names (strings)
		"""
		fallback = emblem if emblem_is_fallback else baseicon
		if isinstance(fallback, (basestring, ThemedIcon)):
			return cls._ThemedIcon(fallback, baseicon, emblem)
		if isinstance(fallback, FileIcon):
			return cls._FileIcon(fallback, baseicon, emblem)
		return None


def ComposedIconSmall(baseicon, emblem, **kwargs):
	"""Create composed icon for leaves with emblem visible on browser list"""
	ci = ComposedIcon(baseicon, emblem, **kwargs)
	ci.minimum_icon_size = SMALL_SZ
	return ci


def _render_composed_icon(composed_icon, icon_size):
	# If it's too small, render as fallback icon
	if icon_size < composed_icon.minimum_icon_size:
		return _get_icon_for_standard_gicon(composed_icon, icon_size)
	emblemicon = composed_icon.emblemicon
	baseicon = composed_icon.baseicon
	toppbuf = _get_icon_dwim(emblemicon, icon_size)
	bottompbuf = _get_icon_dwim(baseicon, icon_size)
	if not toppbuf or not bottompbuf:
		return _get_icon_for_standard_gicon(composed_icon, icon_size)

	dest = bottompbuf.copy()
	# @fr is the scale
	fr = 0.6
	dcoord = int((1-fr)*icon_size)
	dsize = int(fr*icon_size)
	# http://library.gnome.org/devel/gdk-pixbuf/unstable//gdk-pixbuf-scaling.html
	toppbuf.composite(dest, dcoord, dcoord, dsize, dsize,
			dcoord, dcoord, fr, fr, gtk.gdk.INTERP_BILINEAR, 255)
	return dest

def get_thumbnail_for_file(uri, width=-1, height=-1):
	"""
	Return a Pixbuf thumbnail for the file at
	the @uri, which can be *either* and uri or a path
	size is @width x @height

	return None if not found
	"""

	gfile = File(uri)
	if not gfile.query_exists():
		return None
	finfo = gfile.query_info(FILE_ATTRIBUTE_THUMBNAIL_PATH)
	thumb_path = finfo.get_attribute_byte_string(FILE_ATTRIBUTE_THUMBNAIL_PATH)

	return get_pixbuf_from_file(thumb_path, width, height)

def get_pixbuf_from_file(thumb_path, width=-1, height=-1):
	"""
	Return a Pixbuf thumbnail for the file at @thumb_path
	sized @width x @height
	For non-icon pixbufs:
	We might cache these, but on different terms than the icon cache
	if @thumb_path is None, return None
	"""
	if not thumb_path:
		return None
	try:
		icon = pixbuf_new_from_file_at_size(thumb_path, width, height)
		return icon
	except GError, e:
		# this error is not important, the program continues on fine,
		# so we put it in debug output.
		pretty.print_debug(__name__, "get_pixbuf_from_file file:", thumb_path,
			"error:", e)

def get_gicon_for_file(uri):
	"""
	Return a GIcon representing the file at
	the @uri, which can be *either* and uri or a path

	return None if not found
	"""

	gfile = File(uri)
	if not gfile.query_exists():
		return None

	finfo = gfile.query_info(FILE_ATTRIBUTE_STANDARD_ICON)
	gicon = finfo.get_attribute_object(FILE_ATTRIBUTE_STANDARD_ICON)
	# very manually override generic folder icon name
	if isinstance(gicon, ThemedIcon):
		if gicon.get_names()[0] == "inode-directory":
			return ThemedIcon("folder")
	return gicon

def get_icon_for_gicon(gicon, icon_size):
	"""
	Return a pixbuf of @icon_size for the @gicon

	NOTE: Currently only the following can be rendered:
		gio.ThemedIcon
		gio.FileIcon
		kupfer.icons.ComposedIcon
	"""
	# FIXME: We can't load any general GIcon
	if not gicon:
		return None
	if isinstance(gicon, ComposedIcon.Implementation):
		return _render_composed_icon(gicon, icon_size)
	return _get_icon_for_standard_gicon(gicon, icon_size)

def _get_icon_for_standard_gicon(gicon, icon_size):
	"""Render ThemedIcon and FileIcon"""
	if isinstance(gicon, FileIcon):
		ifile = gicon.get_file()
		return get_icon_from_file(ifile.get_path(), icon_size)
	if isinstance(gicon, ThemedIcon):
		names = gicon.get_names()
		return get_icon_for_name(names[0], icon_size, names)
	print "get_icon_for_gicon, could not load", gicon
	return None


def _setup_icon_renderer(sched):
	from kupfer.core import settings
	setctl = settings.GetSettingsController()
	setctl.connect("alternatives-changed::icon_renderer", _icon_render_change)
	setctl.connect("value-changed::tools.icon_renderer", _icon_render_change)
	_icon_render_change(setctl)

def _icon_render_change(setctl, *arguments):
	global _IconRenderer
	renderer_dict = setctl.get_preferred_alternative('icon_renderer')
	renderer = renderer_dict.get("renderer")
	if not renderer or renderer is _IconRenderer:
		return
	pretty.print_debug(__name__, "Using", renderer)
	_icon_theme_changed(None)
	_IconRenderer = renderer

scheduler.GetScheduler().connect("loaded", _setup_icon_renderer)


class IconRenderer (object):
	"""
	Default GTK+ implementation
	"""
	@classmethod
	def pixbuf_for_name(cls, icon_name, icon_size):
		if icon_name in kupfer_locally_installed_names:
			try:
				return _local_theme.load_icon(icon_name, icon_size,
				                              ICON_LOOKUP_USE_BUILTIN |
				                              ICON_LOOKUP_FORCE_SIZE)
			except GError:
				pass
		try:
			return _default_theme.load_icon(icon_name, icon_size,
			                                ICON_LOOKUP_USE_BUILTIN |
			                                ICON_LOOKUP_FORCE_SIZE)
		except GError:
			pass

	@classmethod
	def pixbuf_for_file(cls, file_path, icon_size):
		try:
			icon = gtk.gdk.pixbuf_new_from_file_at_size(file_path, icon_size,
			                                            icon_size)
			return icon
		except GError:
			pretty.print_exc(__name__)

_IconRenderer = IconRenderer


def get_icon_for_name(icon_name, icon_size, icon_names=[]):
	for i in get_icon(icon_name, icon_size):
		return i
	if not icon_names: icon_names = (icon_name,)

	# Try the whole list of given names
	for load_name in icon_names:
		try:
			icon = _IconRenderer.pixbuf_for_name(load_name, icon_size)
			if icon:
				break
			elif icon_name in kupfer_icon_fallbacks:
				fallback_name = kupfer_icon_fallbacks[icon_name]
				icon = _IconRenderer.pixbuf_for_name(fallback_name, icon_size)
				if icon:
					break
		except Exception:
			pretty.print_exc(__name__)
			icon = None
	else:
		# if we did not reach 'break' in the loop
		return None
	# We store the first icon in the list, even if the match
	# found was later in the chain
	store_icon(icon_name, icon_size, icon)
	return icon

def get_icon_from_file(icon_file, icon_size):
	# try to load from cache
	for icon in get_icon(icon_file, icon_size):
		return icon
	icon = _IconRenderer.pixbuf_for_file(icon_file, icon_size)
	if icon is not None:
		store_icon(icon_file, icon_size, icon)
		return icon

def is_good(gicon):
	"""Return True if it is likely that @gicon will load a visible icon
	(icon name exists in theme, or icon references existing file)
	"""
	if not gicon:
		return False
	if isinstance(gicon, ThemedIcon):
		return bool(get_good_name_for_icon_names(gicon.get_names()))
	if isinstance(gicon, FileIcon):
		ifile = gicon.get_file()
		return ifile.query_exists()
	# Since we can't load it otherwise (right now, see above)
	return False

def get_gicon_with_fallbacks(gicon, names):
	if not is_good(gicon):
		for name in names:
			gicon = ThemedIcon(name)
			if is_good(gicon):
				return gicon
		return ThemedIcon(name)
	return gicon

def get_good_name_for_icon_names(names):
	"""Return first name in @names that exists
	in current icon theme, or None
	"""
	for name in names:
		if _default_theme.has_icon(name):
			return name
	return None

def get_gicon_for_names(*names):
	return ThemedIcon(names)


def get_pixbuf_from_data(data, width=None, height=None):
	"""Create pixbuf object from data with optional scaling

	@data: picture as raw data
	@width, @heigh: optional destination size
	"""
	def set_size(img, img_width, img_height):
		scale = min(width/float(img_width), height/float(img_height))
		new_width, new_height = int(img_width*scale), int(img_height*scale)
		img.set_size(new_width, new_height)

	ploader = gtk.gdk.PixbufLoader()
	if width and height:
		ploader.connect("size-prepared", set_size)
	ploader.write(data)
	ploader.close()
	return ploader.get_pixbuf()


########NEW FILE########
__FILENAME__ = interface
import gtk

class TextRepresentation (object):
	"""
	Kupfer Objects that implement this interface have a plain text
	representation that can be used for Copy & Paste etc
	"""
	def get_text_representation(self):
		"""The default implementation returns the represented object"""
		return self.object

class UriListRepresentation (object):
	"""
	Kupfer Objects that implement this interface have a uri-list
	representation that can be used for Copy & Paste etc

	get_urilist_representation should return a sequence of bytestring
	URIs.
	"""
	def get_urilist_representation(self):
		"""The default implementation raises notimplementederror """
		raise NotImplementedError

def get_text_representation(obj):
	try:
		return obj.get_text_representation()
	except AttributeError:
		return None

def copy_to_clipboard(obj, clipboard):
	"""
	Copy @obj to @clipboard, a gtk.Clipboard

	Return True if successful
	"""
	## support copying text to clipboard
	## as well as files in both the general uri-list representation
	## and in nautilus' file copy clipboard type
	target_ids = (uri_id, text_id, nautilus_id) = (80, 81, 82)
	nautilus_target = 'x-special/gnome-copied-files'

	# udata is the data dict
	def store(clipboard, sdata, info, udata):
		if info == uri_id:
			sdata.set_uris(udata[uri_id])
		if info == text_id:
			sdata.set_text(udata[text_id])
		if info == nautilus_id:
			str_data_format = 8
			sdata.set(nautilus_target, str_data_format, udata[nautilus_id])
	def clear(clipboard, udata):
		pass

	targets = []
	data = {}
	try:
		urilist = obj.get_urilist_representation()
	except AttributeError:
		pass
	else:
		if urilist:
			targets = gtk.target_list_add_uri_targets(targets, uri_id)
			targets.append((nautilus_target, 0, nautilus_id))
			data[uri_id] = urilist
			data[nautilus_id] = 'copy\n' + '\n'.join(urilist)

	try:
		text = obj.get_text_representation()
	except AttributeError:
		pass
	else:
		targets = gtk.target_list_add_text_targets(targets, text_id)
		data[text_id] = text
	if data:
		clipboard.set_with_data(targets, store, clear, data)
		# store all targets
		clipboard.set_can_store(targets)
		return True
	return False

def get_fileleaf_for_path(pth):
	import kupfer.objects
	return kupfer.objects.FileLeaf(pth)

########NEW FILE########
__FILENAME__ = keyrelay
"""
This is a program of its own, that does not integrate with the
Kupfer process.
"""
import __builtin__
import os

import gtk
import keybinder
import dbus

from dbus.mainloop.glib import DBusGMainLoop

SERV = "se.kaizer.kupfer"
OBJ = "/interface"
IFACE = "se.kaizer.kupfer.Listener"

if not hasattr(__builtin__, '_'):
	def _(x):
		return x

def get_all_keys():
	try:
		bus = dbus.Bus()
		obj = bus.get_object(SERV, OBJ)
		iface = dbus.Interface(obj, IFACE)
		return iface.GetBoundKeys(byte_arrays=True)
	except dbus.DBusException as exc:
		print exc
		print "Waiting for Kupfer to start.."
		return []

def rebind_key(keystring, is_bound):
	if is_bound:
		print "binding", keystring
		keybinder.bind(keystring, relay_key, keystring)
	else:
		print "unbinding", keystring
		keybinder.unbind(keystring)

def relay_key(key):
	print "Relaying", key
	time = keybinder.get_current_event_time()
	s_id = "kupfer-%d_TIME%s" % (os.getpid(), time)
	bus = dbus.Bus()
	obj = bus.get_object(SERV, OBJ, introspect=False)
	iface = dbus.Interface(obj, IFACE)
	iface.RelayKeysFromDisplay(key, os.getenv("DISPLAY", ":0"), s_id)

def main():
	DBusGMainLoop(set_as_default=True)

	relayed_keys = list(get_all_keys())

	for key in relayed_keys:
		rebind_key(key, True)
	bus = dbus.Bus()
	bus.add_signal_receiver(rebind_key, 'BoundKeyChanged',
			dbus_interface=IFACE)
	sicon = gtk.status_icon_new_from_icon_name("kupfer")
	display = os.getenv("DISPLAY", ":0")
	sicon.set_tooltip(_("Keyboard relay is active for display %s") % display)
	sicon.set_visible(True)
	try:
		gtk.main()
	except KeyboardInterrupt:
		raise SystemExit(0)

if __name__ == '__main__':
	main()

########NEW FILE########
__FILENAME__ = kupferstring
# -*- encoding: UTF-8 -*-

import locale
from unicodedata import normalize, category

def _folditems():
	_folding_table = {
		# general non-decomposing characters
		# FIXME: This is not complete
		u"Å‚" : u"l",
		u"Å“" : u"oe",
		u"Ã°" : u"d",
		u"Ã¾" : u"th",
		u"ÃŸ" : u"ss",
		# germano-scandinavic canonical transliterations
		u"Ã¼" : u"ue",
		u"Ã¥" : u"aa",
		u"Ã¤" : u"ae",
		u"Ã¦" : u"ae",
		u"Ã¶" : u"oe",
		u"Ã¸" : u"oe",
	}

	for c, rep in _folding_table.iteritems():
		yield (ord(c.upper()), rep.title())
		yield (ord(c), rep)

folding_table = dict(_folditems())

def tounicode(utf8str):
	"""Return `unicode` from UTF-8 encoded @utf8str
	This is to use the same error handling etc everywhere
	"""
	if isinstance(utf8str, unicode):
		return utf8str
	return utf8str.decode("UTF-8", "replace") if utf8str is not None else u""

def toutf8(ustr):
	"""Return UTF-8 `str` from unicode @ustr
	This is to use the same error handling etc everywhere
	if ustr is `str`, just return it
	"""
	if isinstance(ustr, str):
		return ustr
	return ustr.encode("UTF-8")

def fromlocale(lstr):
	"""Return a unicode string from locale bytestring @lstr"""
	assert isinstance(lstr, str)
	enc = locale.getpreferredencoding(do_setlocale=False)
	return lstr.decode(enc, "replace")

def tolocale(ustr):
	"""Return a locale-encoded bytestring from unicode @ustr"""
	assert isinstance(ustr, unicode)
	enc = locale.getpreferredencoding(do_setlocale=False)
	return ustr.encode(enc)


def tofolded(ustr):
	u"""Fold @ustr

	Return a unicode string where composed characters are replaced by
	their base, and extended latin characters are replaced by
	similar basic latin characters.

	>>> tofolded(u"WyÅ‚Ä…cz")
	u'Wylacz'
	>>> tofolded(u"naÃ¯vetÃ©")
	u'naivete'

	Characters from other scripts are not transliterated.

	>>> print tofolded(u"á¼™Î»Î»Î¬Ï‚")
	Î•Î»Î»Î±Ï‚
	"""
	srcstr = normalize("NFKD", ustr.translate(folding_table))
	return u"".join([c for c in srcstr if category(c) != 'Mn'])

if __name__ == '__main__':
	import sys
	reload(sys)
	sys.setdefaultencoding("UTF-8")

	import doctest
	doctest.testmod()

########NEW FILE########
__FILENAME__ = kupferui
"""
Access functions of Kupfer's Interface
"""
import gtk

from kupfer import utils, version

def _get_time(ctxenv):
	return ctxenv.get_timestamp() if ctxenv else \
			gtk.get_current_event_time()

def show_help(ctxenv=None):
	"""
	Show Kupfer help pages, if possible
	"""
	if not utils.show_help_url("ghelp:%s" % version.PACKAGE_NAME):
		utils.show_url(version.HELP_WEBSITE)

_about_dialog = None

def show_about_dialog(ctxenv=None):
	"""
	create an about dialog and show it
	"""
	# Use only one instance, stored in _about_dialog
	global _about_dialog
	if _about_dialog:
		ab = _about_dialog
	else:
		ab = gtk.AboutDialog()
		ab.set_program_name(version.PROGRAM_NAME)
		ab.set_icon_name(version.ICON_NAME)
		ab.set_logo_icon_name(version.ICON_NAME)
		ab.set_version(version.VERSION)
		ab.set_comments(version.SHORT_DESCRIPTION)
		ab.set_copyright(version.COPYRIGHT)
		ab.set_website(version.WEBSITE)
		ab.set_license(version.LICENSE)
		ab.set_authors(version.AUTHORS)
		if version.DOCUMENTERS:
			ab.set_documenters(version.DOCUMENTERS)
		if version.TRANSLATOR_CREDITS:
			ab.set_translator_credits(version.TRANSLATOR_CREDITS)
		if version.ARTISTS:
			ab.set_artists(version.ARTISTS)

		ab.connect("response", _response_callback)
		# do not delete window on close
		ab.connect("delete-event", lambda *ign: True)
		_about_dialog = ab
	if ctxenv:
		ctxenv.present_window(ab)
	else:
		ab.present()

def _response_callback(dialog, response_id):
	dialog.hide()


def show_preferences(ctxenv):
	from kupfer.ui import preferences
	win = preferences.GetPreferencesWindowController()
	if ctxenv:
		win.show_on_screen(ctxenv.get_timestamp(),
		                   ctxenv.get_screen())
	else:
		win.show(_get_time(ctxenv))

def show_plugin_info(plugin_id, ctxenv=None):
	from kupfer.ui import preferences
	prefs = preferences.GetPreferencesWindowController()
	prefs.show_focus_plugin(plugin_id, _get_time(ctxenv))

########NEW FILE########
__FILENAME__ = launch
from time import time
import os
import cPickle as pickle

import gio
import gobject

from kupfer import pretty, config
from kupfer import scheduler
from kupfer import desktop_launch
from kupfer.ui import uievents
from kupfer import terminal

from kupfer.desktop_launch import SpawnError

## NOTE: SpawnError  *should* be imported from this module

try:
	import wnck
	wnck.set_client_type(wnck.CLIENT_TYPE_PAGER)
except ImportError, e:
	pretty.print_info(__name__, "Disabling window tracking:", e)
	wnck = None


default_associations = {
	"evince" : "Document Viewer",
	"file-roller" : "File Roller",
	#"gedit" : "Text Editor",
	"gnome-keyring-manager" : "Keyring Manager",
	"nautilus-browser" : "File Manager",
	"rhythmbox" : "Rhythmbox Music Player",
}


def application_id(app_info, desktop_file=None):
	"""Return an application id (string) for GAppInfo @app_info"""
	app_id = app_info.get_id()
	if not app_id:
		app_id = desktop_file or ""
	if app_id.endswith(".desktop"):
		app_id = app_id[:-len(".desktop")]
	return app_id

def launch_application(app_info, files=(), uris=(), paths=(), track=True,
	                   activate=True, desktop_file=None, screen=None):
	"""
	Launch @app_rec correctly, using a startup notification

	you may pass in either a list of gio.Files in @files, or 
	a list of @uris or @paths

	if @track, it is a user-level application
	if @activate, activate rather than start a new version

	@app_rec is either an GAppInfo or (GAppInfo, desktop_file_path) tuple

	Raises SpawnError on failed program start.
	"""
	assert app_info

	if paths:
		files = [gio.File(p) for p in paths]
	if uris:
		files = [gio.File(p) for p in uris]

	svc = GetApplicationsMatcherService()
	app_id = application_id(app_info, desktop_file)

	if activate and svc.application_is_running(app_id):
		svc.application_to_front(app_id)
		return True

	# An launch callback closure for the @app_id
	def application_launch_callback(argv, pid, notify_id, files, timestamp):
		is_terminal = terminal.is_known_terminal_executable(argv[0])
		if not is_terminal:
			svc.launched_application(app_id, pid)

	if track:
		launch_callback = application_launch_callback
	else:
		launch_callback = None

	try:
		desktop_launch.launch_app_info(app_info, files,
			   timestamp=uievents.current_event_time(),
			   desktop_file=desktop_file,
			   launch_cb=launch_callback,
			   screen=screen)
	except SpawnError:
		raise
	return True

def application_is_running(app_id):
	svc = GetApplicationsMatcherService()
	return svc.application_is_running(app_id)

def application_close_all(app_id):
	svc = GetApplicationsMatcherService()
	return svc.application_close_all(app_id)

class ApplicationsMatcherService (pretty.OutputMixin):
	"""Handle launching applications and see if they still run.
	This is a learning service, since we have no first-class application
	object on the Linux desktop
	"""
	def __init__(self):
		self.register = {}
		self._get_wnck_screen_windows_stacked()
		scheduler.GetScheduler().connect("finish", self._finish)
		self._load()

	@classmethod
	def _get_wnck_screen_windows_stacked(cls):
		if not wnck:
			return ()
		screen = wnck.screen_get_default()
		return screen.get_windows_stacked()

	def _get_filename(self):
		# Version 1: Up to incl v203
		# Version 2: Do not track terminals
		version = 2
		return os.path.join(config.get_cache_home(),
				"application_identification_v%d.pickle" % version)
	def _load(self):
		reg = self._unpickle_register(self._get_filename())
		self.register = reg if reg else default_associations
		# pretty-print register to debug
		if self.register:
			self.output_debug("Learned the following applications")
			self.output_debug("\n{\n%s\n}" % "\n".join(
				("  %-30s : %s" % (k,v)
					for k,v in self.register.iteritems())
				))
	def _finish(self, sched):
		self._pickle_register(self.register, self._get_filename())
	def _unpickle_register(self, pickle_file):
		try:
			pfile = open(pickle_file, "rb")
		except IOError, e:
			return None
		try:
			source = pickle.loads(pfile.read())
			assert isinstance(source, dict), "Stored object not a dict"
			self.output_debug("Reading from %s" % (pickle_file, ))
		except (pickle.PickleError, Exception), e:
			source = None
			self.output_info("Error loading %s: %s" % (pickle_file, e))
		return source

	def _pickle_register(self, reg, pickle_file):
		output = open(pickle_file, "wb")
		self.output_debug("Saving to %s" % (pickle_file, ))
		output.write(pickle.dumps(reg, pickle.HIGHEST_PROTOCOL))
		output.close()
		return True

	def _store(self, app_id, window):
		# FIXME: Store the 'res_class' name?
		application = window.get_application()
		store_name = application.get_name()
		self.register[app_id] = store_name
		self.output_debug("storing application", app_id, "as", store_name)

	def _has_match(self, app_id):
		return app_id in self.register

	def _is_match(self, app_id, window):
		application = window.get_application()
		res_class = window.get_class_group().get_res_class()
		reg_name = self.register.get(app_id)
		if reg_name and reg_name in (application.get_name(), res_class):
			return True
		if app_id in (application.get_name().lower(), res_class.lower()):
			return True
		return False

	def launched_application(self, app_id, pid):
		if self._has_match(app_id):
			return
		timeout = time() + 15
		gobject.timeout_add_seconds(2, self._find_application, app_id, pid, timeout)
		# and once later
		gobject.timeout_add_seconds(30, self._find_application, app_id, pid, timeout)

	def _find_application(self, app_id, pid, timeout):
		if self._has_match(app_id):
			return False
		#self.output_debug("Looking for window for application", app_id)
		for w in self._get_wnck_screen_windows_stacked():
			app = w.get_application()
			app_pid = app.get_pid()
			if not app_pid:
				app_pid = w.get_pid()
			if app_pid == pid:
				self._store(app_id, w)
				return False
		if time() > timeout:
			return False
		return True

	def application_name(self, app_id):
		if not self._has_match(app_id):
			return None
		return self.register[app_id]

	def application_is_running(self, app_id):
		for w in self._get_wnck_screen_windows_stacked():
			if (w.get_application() and self._is_match(app_id, w) and 
			    w.get_window_type() == wnck.WINDOW_NORMAL):
				return True
		return False

	def get_application_windows(self, app_id):
		application_windows = []
		for w in self._get_wnck_screen_windows_stacked():
			if (w.get_application() and self._is_match(app_id, w) and 
			    w.get_window_type() == wnck.WINDOW_NORMAL):
				application_windows.append(w)
		return application_windows

	def application_to_front(self, app_id):
		application_windows = self.get_application_windows(app_id)
		if not application_windows:
			return False
		etime = uievents.current_event_time()
		# if True, focus app's all windows on the same workspace
		# if False, focus only one window (in cyclical manner)
		focus_all = True
		if focus_all:
			return self._to_front_application_style(application_windows, etime)
		else:
			return self._to_front_single(application_windows, etime)

	def _to_front_application_style(self, application_windows, evttime):
		workspaces = {}
		cur_screen = application_windows[0].get_screen()
		cur_workspace = cur_screen.get_active_workspace()

		def visible_window(window):
			return (window.get_window_type() == wnck.WINDOW_NORMAL and
			        window.is_visible_on_workspace(cur_workspace))

		def normal_window(window):
			return window.get_window_type() == wnck.WINDOW_NORMAL

		## get all visible windows in stacking order
		vis_windows = filter(visible_window,
		                     self._get_wnck_screen_windows_stacked())

		## sort windows into "bins" by workspace
		for w in filter(normal_window, application_windows):
			wspc = w.get_workspace() or cur_workspace
			workspaces.setdefault(wspc, []).append(w)

		cur_wspc_windows = workspaces.get(cur_workspace, [])
		# make a rotated workspace list, with current workspace first
		idx = cur_workspace.get_number()
		all_workspaces = cur_screen.get_workspaces()
		all_workspaces[:] = all_workspaces[idx:] + all_workspaces[:idx]
		# check if the application's window on current workspace
		# are the topmost
		focus_windows = []
		if (cur_wspc_windows and 
		    set(vis_windows[-len(cur_wspc_windows):]) != set(cur_wspc_windows)):
			focus_windows = cur_wspc_windows
			## if the topmost window is already active, take another
			if focus_windows[-1:] == vis_windows[-1:]:
				focus_windows[:] = focus_windows[:-1]
		else:
			# all windows are focused, find on next workspace
			for wspc in all_workspaces[1:]:
				focus_windows = workspaces.get(wspc, [])
				if focus_windows:
					break
			else:
				# no windows on other workspaces, so we rotate among
				# the local ones
				focus_windows = cur_wspc_windows[:1]
		self._focus_windows(focus_windows, evttime)

	def _to_front_single(self, application_windows, evttime):
		# bring the first window to front
		for window in application_windows:
			self._focus_windows([window], evttime)
			return

	def _focus_windows(self, windows, evttime):
		for window in windows:
			# we special-case the desktop
			# only show desktop if it's the only window
			if window.get_name() == "x-nautilus-desktop":
				if len(windows) == 1:
					screen = wnck.screen_get_default()
					screen.toggle_showing_desktop(True)
				else:
					continue
			wspc = window.get_workspace()
			if wspc:
				wspc.activate(evttime)
			window.activate_transient(evttime)

	def application_close_all(self, app_id):
		application_windows = self.get_application_windows(app_id)
		evttime = uievents.current_event_time()
		for w in application_windows:
			if not w.is_skip_tasklist():
				w.close(evttime)


_appl_match_service = None
def GetApplicationsMatcherService():
	"""Get the (singleton) ApplicationsMatcherService"""
	global _appl_match_service
	if not _appl_match_service:
		_appl_match_service = ApplicationsMatcherService()
	return _appl_match_service


########NEW FILE########
__FILENAME__ = main
import gettext
import locale
import sys

_debug = False

def setup_locale_and_gettext():
	"""Set up localization with gettext"""
	package_name = "kupfer"
	localedir = "./locale"
	try:
		from kupfer import version_subst
	except ImportError:
		pass
	else:
		package_name = version_subst.PACKAGE_NAME
		localedir = version_subst.LOCALEDIR
	# Install _() builtin for gettext; always returning unicode objects
	# also install ngettext()
	gettext.install(package_name, localedir=localedir, unicode=True,
			names=("ngettext",))
	# For gtk.Builder, we need to call the C library gettext functions
	# As well as set the codeset to avoid locale-dependent translation
	# of the message catalog
	locale.bindtextdomain(package_name, localedir)
	locale.bind_textdomain_codeset(package_name, "UTF-8")
	# to load in current locale properly for sorting etc
	try:
		locale.setlocale(locale.LC_ALL, "")
	except locale.Error:
		pass

setup_locale_and_gettext()

def prt(*args):
	enc = locale.getpreferredencoding(do_setlocale=False)
	print (u" ".join(args)).encode(enc, "replace")

def get_options():
	"""Return a list of other application flags with --* prefix included."""

	program_options = [
		("no-splash", _("do not present main interface on launch")),
		("list-plugins", _("list available plugins")),
		("debug", _("enable debug info")),
		("relay", ""),
		# TRANS: --exec-helper=HELPER is an internal command
		# TRANS: that executes a helper program that is part of kupfer
		("exec-helper=", _("run plugin helper")),
	]
	misc_options = [
		("help", _("show usage help")),
		("version", _("show version information")),
	]

	import getopt

	def make_help_text():
		usage_string = _("Usage: kupfer [ OPTIONS | FILE ... ]")
		def format_options(opts):
			return "\n".join("  --%-15s  %s" % (o,h) for o,h in opts)

		options_string = u"%s\n\n%s\n\n%s\n" % (usage_string,
				format_options(program_options), format_options(misc_options))

		return options_string

	def make_plugin_list():
		from kupfer.core import plugins
		plugin_header = _("Available plugins:")
		plugin_list = plugins.get_plugin_desc()
		return "\n".join((plugin_header, plugin_list))

	# Fix sys.argv that can be None in exceptional cases
	if sys.argv[0] is None:
		sys.argv[0] = "kupfer"

	try:
		opts, args = getopt.getopt(sys.argv[1:], "",
				[o for o,h in program_options] +
				[o for o,h in misc_options])
	except getopt.GetoptError as exc:
		prt(unicode(exc))
		prt(make_help_text())
		raise SystemExit

	for k, v in opts:
		if k == "--list-plugins":
			prt(make_plugin_list())
			raise SystemExit
		if k == "--help":
			prt(make_help_text())
			raise SystemExit
		if k == "--version":
			print_version()
			prt()
			print_banner()
			raise SystemExit
		if k == "--debug":
			global _debug
			_debug = True
		if k == "--relay":
			prt("WARNING: --relay is deprecated!")
			exec_helper('kupfer.keyrelay')
			raise SystemExit
		if k == "--exec-helper":
			exec_helper(v)
			raise SystemExit(1)

	# return list first of tuple pair
	return [tupl[0] for tupl in opts]

def print_version():
	from kupfer import version
	prt(version.PACKAGE_NAME, version.VERSION)

def print_banner():
	from kupfer import version

	banner = _(
		"%(PROGRAM_NAME)s: %(SHORT_DESCRIPTION)s\n"
		"	%(COPYRIGHT)s\n"
		"	%(WEBSITE)s\n") % vars(version)
	prt(banner)

def _set_process_title_linux():
	try:
		import ctypes
	except ImportError:
		return
	try:
		libc = ctypes.CDLL("libc.so.6")
		libc.prctl(15, "kupfer")
	except (AttributeError, OSError):
		pass

def _set_process_title():
	try:
		import setproctitle
	except ImportError:
		if sys.platform == "linux2":
			_set_process_title_linux()
	else:
		setproctitle.setproctitle("kupfer")

def exec_helper(helpername):
	import runpy
	runpy.run_module(helpername, run_name='__main__', alter_sys=True)
	raise SystemExit

def gtkmain(quiet):
	import pygtk
	pygtk.require('2.0')
	import gtk

	if not gtk.gdk.screen_get_default():
		print >>sys.stderr, "No Screen Found, Exiting..."
		sys.exit(1)

	from kupfer.ui import browser
	w = browser.WindowController()
	w.main(quiet=quiet)

def main():
	# parse commandline before importing UI
	cli_opts = get_options()
	print_banner()

	from kupfer import pretty

	if _debug:
		pretty.debug = _debug
		try:
			import debug
			debug.install()
		except ImportError:
			pass
	sys.excepthook = sys.__excepthook__
	_set_process_title()

	quiet = ("--no-splash" in cli_opts)
	gtkmain(quiet)


########NEW FILE########
__FILENAME__ = apps
from kupfer.obj.base import InvalidDataError, Source
from kupfer.obj.helplib import PicklingHelperMixin, FilesystemWatchMixin
from kupfer.obj.objects import AppLeaf

class AppLeafContentMixin (object):
	"""
	Mixin for Source that correspond one-to-one with a AppLeaf

	This Mixin sees to that the Source is set as content for the application
	with id 'cls.appleaf_content_id', which may also be a sequence of ids.

	Source has to define the attribute appleaf_content_id and must
	inherit this mixin BEFORE the Source

	This Mixin defines:
	get_leaf_repr
	decorates_type,
	decorates_item
	"""
	@classmethod
	def get_leaf_repr(cls):
		if not hasattr(cls, "_cached_leaf_repr"):
			cls._cached_leaf_repr = cls.__get_leaf_repr()
		return cls._cached_leaf_repr
	@classmethod
	def __get_appleaf_id_iter(cls):
		if hasattr(cls.appleaf_content_id, "__iter__"):
			ids = iter(cls.appleaf_content_id)
		else:
			ids = (cls.appleaf_content_id, )
		return ids
	@classmethod
	def __get_leaf_repr(cls):
		for appleaf_id in cls.__get_appleaf_id_iter():
			try:
				return AppLeaf(app_id=appleaf_id)
			except InvalidDataError:
				pass
	@classmethod
	def decorates_type(cls):
		return AppLeaf
	@classmethod
	def decorate_item(cls, leaf):
		if leaf == cls.get_leaf_repr():
			return cls()

class ApplicationSource(AppLeafContentMixin, Source, PicklingHelperMixin,
		FilesystemWatchMixin):
	pass


########NEW FILE########
__FILENAME__ = base
from kupfer import datatools
from kupfer import icons
from kupfer import pretty
from kupfer.utils import locale_sort
from kupfer.kupferstring import tounicode, toutf8, tofolded

__all__ = [
	"Error", "InvalidDataError", "OperationError", "InvalidLeafError",
	"KupferObject", "Leaf", "Action", "Source", "TextSource",
]

# If no gettext function is loaded at this point, we load a substitute,
# so that testing code can still work
import __builtin__
if not hasattr(__builtin__, "_"):
	def identity(x): return x
	__builtin__._ = identity

class Error (Exception):
	pass

class InvalidDataError (Error):
	"The data is wrong for the given Leaf"

class OperationError (Error):
	"Command execution experienced an error"

class InvalidLeafError (OperationError):
	"The Leaf passed to an Action is invalid"

_builtin_modules = frozenset([
	"kupfer.obj.objects",
	"kupfer.obj.base",
	"kupfer.obj.sources",
	"kupfer.obj.fileactions",
])

class _BuiltinObject (type):
	def __new__(mcls, name, bases, dict):
		dict["_is_builtin"] = dict["__module__"] in _builtin_modules
		return type.__new__(mcls, name, bases, dict)


class KupferObject (object):
	"""
	Base class for kupfer data model

	This class provides a way to get at an object's:

	* icon with get_thumbnail, get_pixbuf and get_icon
	* name with unicode() or str()
	* description with get_description

	@rank_adjust should be used _very_ sparingly:
		Default actions should have +5 or +1
		Destructive (dangerous) actions should have -5 or -10

	@fallback_icon_name is a class attribute for the last fallback
	icon; it must always be accessible.
	"""
	__metaclass__ = _BuiltinObject
	rank_adjust = 0
	fallback_icon_name = "kupfer-object"
	def __init__(self, name=None):
		""" Init kupfer object with, where
		@name *should* be a unicode object but *may* be
		a UTF-8 encoded `str`
		"""
		if not name:
			name = self.__class__.__name__
		self.name = tounicode(name)
		folded_name = tofolded(self.name)
		self.kupfer_add_alias(folded_name)

	def kupfer_add_alias(self, alias):
		if alias != unicode(self):
			if not hasattr(self, "name_aliases"):
				self.name_aliases = set()
			self.name_aliases.add(alias)

	def __str__(self):
		return toutf8(self.name)

	def __unicode__(self):
		"""Return a `unicode` representation of @self """
		return self.name

	def __repr__(self):
		key = self.repr_key()
		keys = " %s" % (key, ) if key else ""
		if self._is_builtin:
			return "<builtin.%s%s>" % (self.__class__.__name__, keys)
		return "<%s.%s%s>" % (self.__module__, self.__class__.__name__, keys)

	def repr_key(self):
		"""
		Return an object whose str() will be used in the __repr__,
		self is returned by default.
		This value is used to recognize objects, for example learning commonly
		used objects.
		"""
		return self

	def get_description(self):
		"""Return a description of the specific item
		which *should* be a unicode object
		"""
		return None

	def get_thumbnail(self, width, height):
		"""Return pixbuf of size @width x @height if available
		Most objects will not implement this
		"""
		return None

	def get_pixbuf(self, icon_size):
		"""
		Returns an icon in pixbuf format with dimension @icon_size

		Subclasses should implement: get_gicon and get_icon_name,
		if they make sense.
		The methods are tried in that order.
		"""
		gicon = self.get_gicon()
		pbuf = gicon and icons.get_icon_for_gicon(gicon, icon_size)
		if pbuf:
			return pbuf
		icon_name = self.get_icon_name()
		icon = icon_name and icons.get_icon_for_name(icon_name, icon_size)
		if icon:
			return icon
		return icons.get_icon_for_name(self.fallback_icon_name, icon_size)

	def get_icon(self):
		"""
		Returns an icon in GIcon format

		Subclasses should implement: get_gicon and get_icon_name,
		if they make sense.
		The methods are tried in that order.
		"""
		gicon = self.get_gicon()
		if gicon and icons.is_good(gicon):
			return gicon
		icon_name = self.get_icon_name()
		if icon_name and icons.get_good_name_for_icon_names((icon_name, )):
			return icons.get_gicon_for_names(icon_name)
		return icons.get_gicon_for_names(self.fallback_icon_name)

	def get_gicon(self):
		"""Return GIcon, if there is one"""
		return None

	def get_icon_name(self):
		"""Return icon name. All items should have at least
		a generic icon name to return.
		"""
		return self.fallback_icon_name

def aslist(seq):
	"""Return a list out of @seq, or seq if it is a list"""
	if not isinstance(seq, type([])) and not isinstance(seq, type(())):
		seq = list(seq)
	return seq

class _NonpersistentToken (object):
	"Goes None when pickled"
	__slots__ = "object"
	def __init__(self, object_):
		self.object = object_
	def __nonzero__(self):
		return bool(self.object)
	def __reduce__(self):
		return (sum, ((), None))

class Leaf (KupferObject):
	"""
	Base class for objects

	Leaf.object is the represented object (data)
	All Leaves should be hashable (__hash__ and __eq__)
	"""
	def __init__(self, obj, name):
		"""Represented object @obj and its @name"""
		super(Leaf, self).__init__(name)
		self.object = obj
		self._content_source = None

	def __hash__(self):
		return hash(unicode(self))

	def __eq__(self, other):
		return (type(self) == type(other) and self.object == other.object)

	def add_content(self, content):
		"""Register content source @content with Leaf"""
		self._content_source = content and _NonpersistentToken(content)

	def has_content(self):
		return self._content_source

	def content_source(self, alternate=False):
		"""Content of leaf. it MAY alter behavior with @alternate,
		as easter egg/extra mode"""
		return self._content_source and self._content_source.object

	def get_actions(self):
		"""Default (builtin) actions for this Leaf"""
		return ()

class Action (KupferObject):
	'''
	Base class for all actions

	Implicit interface:
	  valid_object will be called once for each (secondary) object
	  to see if it applies. If it is not defined, all objects are
	  assumed ok (within the other type/source constraints)

	def valid_object(self, obj, for_item):
		"""Whether @obj is good for secondary obj,
		where @for_item is passed in as a hint for
		which it should be applied to
		"""
		return True
	'''
	fallback_icon_name = "kupfer-execute"

	def __hash__(self):
		return hash(repr(self))

	def __eq__(self, other):
		return (type(self) == type(other) and repr(self) == repr(other) and
				unicode(self) == unicode(other))

	def repr_key(self):
		"""by default, actions of one type are all the same"""
		return ""

	def activate(self, obj, iobj=None, ctx=None):
		"""Use this action with @obj and @iobj

		@obj:  the direct object (Leaf)
		@iobj: the indirect object (Leaf), if ``self.requires_object``
			   returns ``False``

		if ``self.wants_context`` returns ``True``, then the action
		also receives an execution context object as ``ctx``.

		Also, ``activate_multiple(self, objects, iobjects=None, ctx=None)``
		is called if it is defined and the action gets either
		multiple objects or iobjects.
		"""
		pass

	def wants_context(self):
		"""Return ``True`` if ``activate`` should receive the
		ActionExecutionContext as the keyword argument context

		Defaults to ``False`` in accordance with the old protocol
		"""
		return False

	def is_factory(self):
		"""Return whether action may return a result collection as a Source"""
		return False

	def has_result(self):
		"""Return whether action may return a result item as a Leaf"""
		return False

	def is_async(self):
		"""If this action runs asynchronously, return True.

		Then activate(..) must return an object from the kupfer.task module,
		which will be queued to run by Kupfer's task scheduler.
		"""
		return False

	def item_types(self):
		"""Yield types this action may apply to. This is used only
		when this action is specified in __kupfer_actions__ to "decorate"
		"""
		return ()

	def valid_for_item(self, item):
		"""Whether action can be used with exactly @item"""
		return True

	def requires_object(self):
		"""If this action requires a secondary object
		to complete is action, return True
		"""
		return False

	def object_source(self, for_item=None):
		"""Source to use for object or None,
		to use the catalog (flat and filtered for @object_types)
		"""
		return None

	def object_types(self):
		"""Yield types this action may use as indirect objects, if the action
		requrires it.
		"""
		return ()

class Source (KupferObject, pretty.OutputMixin):
	"""
	Source: Data provider for a kupfer browser

	All Sources should be hashable and treated as equal if
	their @repr are equal!

	@source_user_reloadable if True source get "Reload" action without
		debug mode.
	@source_prefer_sublevel if True, the source by default exports
		its contents in a subcatalog, not to the toplevel.
		NOTE: *Almost never* use this: let the user decide, default to toplevel.
	"""
	fallback_icon_name = "kupfer-object-multiple"
	source_user_reloadable = False
	source_prefer_sublevel = False

	def __init__(self, name):
		KupferObject.__init__(self, name)
		self.cached_items = None
		self._version = 1

	@property
	def version(self):
		"""version is for pickling (save and restore from cache),
		subclasses should increase self._version when changing"""
		return self._version

	def __eq__(self, other):
		return (type(self) == type(other) and repr(self) == repr(other) and
		        self.version == other.version)

	def __hash__(self ):
		return hash(repr(self))

	def toplevel_source(self):
		return self

	def initialize(self):
		"""
		Called when a Source enters Kupfer's system for real

		This method is called at least once for any "real" Source. A Source
		must be able to return an icon name for get_icon_name as well as a
		description for get_description, even if this method was never called.
		"""
		pass

	def finalize(self):
		"""
		Called before a source is deactivated.
		"""
		pass

	def repr_key(self):
		return ""

	def get_items(self):
		"""
		Internal method to compute and return the needed items

		Subclasses should use this method to return a sequence or
		iterator to the leaves it contains
		"""
		return []

	def get_items_forced(self):
		"""
		Force compute and return items for source.
		Default - call get_items method.
		"""
		return self.get_items()

	def is_dynamic(self):
		"""
		Whether to recompute contents each time it is accessed
		"""
		return False

	def mark_for_update(self):
		"""
		Mark source as changed

		it should be reloaded on next used (if normally cached)
		"""
		self.cached_items = None

	def should_sort_lexically(self):
		"""
		Sources should return items by most relevant order (most
		relevant first). If this is True, Source will sort items
		from get_item() in locale lexical order
		"""
		return False

	def get_leaves(self, force_update=False):
		"""
		Return a list of all leaves.

		Subclasses should implement get_items, so that Source
		can handle sorting and caching.
		if @force_update, ignore cache, print number of items loaded
		"""
		if self.should_sort_lexically():
			# sort in locale order
			sort_func = locale_sort
		else:
			sort_func = lambda x: x

		if self.is_dynamic():
			if force_update:
				return sort_func(self.get_items_forced())
			else:
				return sort_func(self.get_items())

		if self.cached_items is None or force_update:
			if force_update:
				self.cached_items = aslist(sort_func(self.get_items_forced()))
				self.output_debug("Loaded %d items" % len(self.cached_items))
			else:
				self.cached_items = \
						datatools.SavedIterable(sort_func(self.get_items()))
				self.output_debug("Loaded items")
		return self.cached_items

	def has_parent(self):
		return False

	def get_parent(self):
		return None

	def get_leaf_repr(self):
		"""Return, if appicable, another object
		to take the source's place as Leaf"""
		return None

	def provides(self):
		"""A seq of the types of items it provides;
		empty is taken as anything -- however most sources
		should set this to exactly the type they yield
		"""
		return ()

class TextSource (KupferObject):
	"""TextSource base class implementation,

	this is a psedo Source"""
	def __init__(self, name=None):
		if not name:
			name = _("Text")
		KupferObject.__init__(self, name)

	def __eq__(self, other):
		return (type(self) == type(other) and repr(self).__eq__(repr(other)))

	def __hash__(self ):
		return hash(repr(self))

	def initialize(self):
		pass

	def get_rank(self):
		"""All items are given this rank"""
		return 20

	def get_items(self, text):
		return ()

	def get_text_items(self, text):
		"""Get leaves for unicode string @text"""
		return self.get_items(text)

	def has_parent(self):
		return False

	def provides(self):
		"""A seq of the types of items it provides"""
		yield Leaf

	def get_icon_name(self):
		return "edit-select-all"


class ActionGenerator (object):
	"""A "source" for actions

	NOTE: The ActionGenerator should not perform any expensive
	computation, and not access any slow media (files, network) when
	returning actions.  Such expensive checks must be performed in
	each Action's valid_for_item method.
	"""

	def get_actions_for_leaf(self, leaf):
		'''Return actions appropriate for given leaf. '''
		return []

########NEW FILE########
__FILENAME__ = compose
# encoding: utf-8

from kupfer import icons
from kupfer import pretty
from kupfer import utils
from kupfer import datatools
from kupfer import puid

from kupfer.obj.base import Leaf, Action, Source, InvalidDataError
from kupfer.obj.objects import Perform, RunnableLeaf, TextLeaf

class TimedPerform (Perform):
	"""A timed (delayed) version of Run (Perform) """
	def __init__(self):
		Action.__init__(self, _("Run after Delay..."))

	def activate(self, leaf, iobj, ctx):
		from kupfer import scheduler
		# make a timer that will fire when Kupfer exits
		interval = utils.parse_time_interval(iobj.object)
		pretty.print_debug(__name__, "Run %s in %s seconds" % (leaf, interval))
		timer = scheduler.Timer(True)
		args = (ctx,) if leaf.wants_context() else ()
		timer.set(interval, leaf.run, *args)

	def requires_object(self):
		return True
	def object_types(self):
		yield TextLeaf

	def valid_object(self, iobj, for_item=None):
		interval = utils.parse_time_interval(iobj.object)
		return interval > 0

	def get_description(self):
		return _("Perform command after a specified time interval")

class ComposedLeaf (RunnableLeaf):
	serializable = 1
	def __init__(self, obj, action, iobj=None):
		object_ = (obj, action, iobj)
		# A slight hack: We remove trailing ellipsis and whitespace
		format = lambda o: unicode(o).strip(".â€¦ ")
		name = u" â†’ ".join([format(o) for o in object_ if o is not None])
		RunnableLeaf.__init__(self, object_, name)

	def __getstate__(self):
		state = dict(vars(self))
		state["object"] = [puid.get_unique_id(o) for o in self.object]
		return state

	def __setstate__(self, state):
		vars(self).update(state)
		objid, actid, iobjid = state["object"]
		obj = puid.resolve_unique_id(objid)
		act = puid.resolve_action_id(actid, obj)
		iobj = puid.resolve_unique_id(iobjid)
		if (not obj or not act) or (iobj is None) != (iobjid is None):
			raise InvalidDataError("Parts of %s not restored" % unicode(self))
		self.object[:] = [obj, act, iobj]

	def get_actions(self):
		yield Perform()
		yield TimedPerform()

	def repr_key(self):
		return self

	def wants_context(self):
		return True

	def run(self, ctx):
		obj, action, iobj = self.object
		return ctx.delegated_run(obj, action, iobj)

	def get_gicon(self):
		obj, action, iobj = self.object
		return icons.ComposedIcon(obj.get_icon(), action.get_icon())

class _MultipleLeafContentSource (Source):
	def __init__(self, leaf):
		Source.__init__(self, unicode(leaf))
		self.leaf = leaf
	def get_items(self):
		return self.leaf.object

class MultipleLeaf (Leaf):
	"""
	A Leaf for the direct representation of many leaves. It is not
	a container or "source", it *is* the many leaves itself.

	The represented object is a sequence of Leaves
	"""
	serializable = 1
	def __init__(self, obj, name=_("Multiple Objects")):
		# modifying the list of objects is strictly forbidden
		robj = list(datatools.UniqueIterator(obj))
		Leaf.__init__(self, robj, name)

	def get_multiple_leaf_representation(self):
		return self.object

	def __getstate__(self):
		state = dict(vars(self))
		state["object"] = [puid.get_unique_id(o) for o in self.object]
		return state

	def __setstate__(self, state):
		vars(self).update(state)
		objects = []
		for id_ in state["object"]:
			obj = puid.resolve_unique_id(id_)
			if obj is None:
				raise InvalidDataError("%s could not be restored!" % (id_, ))
			objects.append(obj)
		self.object[:] = objects

	def has_content(self):
		return True

	def content_source(self, alternate=False):
		return _MultipleLeafContentSource(self)

	def get_description(self):
		n = len(self.object)
		return ngettext("%s object", "%s objects", n) % (n, )
	def get_icon_name(self):
		return "kupfer-object-multiple"

########NEW FILE########
__FILENAME__ = contacts
# -*- encoding: utf-8 -*-
"""
Kupfer's Contacts API

Main definition and *constructor* classes.

Constructor classes such as EmailContact are used to conveniently construct
contacts with common traits. To *use* contacts, always use ContactLeaf, asking
for specific slots to be filled.
"""
import re

from kupfer import icons
from kupfer.obj.grouping import GroupingLeaf

__author__ = ("Ulrik Sverdrup <ulrik.sverdrup@gmail.com>, "
              "Karol BÄ™dkowski <karol.bedkowsk+gh@gmail.com>",
              "Adi Sieker <adi@sieker.info>",
)

EMAIL_KEY = "EMAIL"
NAME_KEY = "NAME"
PHONE_KEY = "PHONE"
ADDRESS_KEY = "ADDRESS"
LABEL_KEY = "LABEL"
JABBER_JID_KEY = "JID"
JABBER_STATUS_KEY = "JABBER_STATUS"
JABBER_RESOURCE_KEY = "JABBER_RESOURCE"
AIM_KEY = "AIM"
GOOGLE_TALK_KEY = "GOOGLE_TALK"
ICQ_KEY = "ICQ"
MSN_KEY = "MSN"
QQ_KEY = "QQ"
SKYPE_KEY = "SKYPE"
YAHOO_KEY = "YAHOO"


class ContactLeaf(GroupingLeaf):
	grouping_slots = (NAME_KEY, )

	def __init__(self, obj, name, image=None):
		self.image = image
		GroupingLeaf.__init__(self, obj, name)

	def get_icon_name(self):
		return "stock_person"

	def get_text_representation(self):
		return self.get_description()

	def get_thumbnail(self, width, height):
		if self.image:
			return icons.get_pixbuf_from_data(self.image, width, height)
		return GroupingLeaf.get_thumbnail(self, width, height)

## E-mail convenience and constructors

def _get_email_from_url(url):
	''' convert http://foo@bar.pl -> foo@bar.pl '''
	sep = url.find('://')
	return url[sep + 3:] if sep > -1 else url

# FIXME: Find a more robust (less strict?) approach than regex
_CHECK_EMAIL_RE = re.compile(r"^[a-z0-9\._%-+]+\@[a-z0-9._%-]+\.[a-z]{2,}$")


def is_valid_email(email):
	''' simple email check '''
	return len(email) > 7 and _CHECK_EMAIL_RE.match(email.lower()) is not None


def email_from_leaf(leaf):
	"""
	Return an email address string if @leaf has a valid email address.

	@leaf may also be a TextLeaf or UrlLeaf.
	Return a false value if no valid email is found.
	"""
	if isinstance(leaf, ContactLeaf):
		return EMAIL_KEY in leaf and leaf[EMAIL_KEY]
	email = _get_email_from_url(leaf.object)
	return is_valid_email(email) and email


class EmailContact (ContactLeaf):
	grouping_slots = ContactLeaf.grouping_slots + (EMAIL_KEY, )

	def __init__(self, email, name, image=None):
		slots = {EMAIL_KEY: email, NAME_KEY: name}
		ContactLeaf.__init__(self, slots, name, image)

	def repr_key(self):
		return self.object[EMAIL_KEY]

	def get_description(self):
		return self.object[EMAIL_KEY]

	def get_gicon(self):
		return icons.ComposedIconSmall(self.get_icon_name(), "stock_mail")


class IMContact (ContactLeaf):
	grouping_slots = ContactLeaf.grouping_slots + (EMAIL_KEY, )

	def __init__(self, im_id_kind, im_id, name, label=None, other_slots=None,
			image=None):
		self.im_id_kind = im_id_kind
		slots = {im_id_kind: im_id, NAME_KEY: name, LABEL_KEY: label}
		if other_slots:
			slots.update(other_slots)
		ContactLeaf.__init__(self, slots, name, image)
		self.kupfer_add_alias(im_id)

	def repr_key(self):
		return self.object[self.im_id_kind]

	def get_description(self):
		return self.object[LABEL_KEY] or self.object[self.im_id_kind]


class JabberContact (IMContact):
	''' Minimal class for all Jabber contacts. '''
	grouping_slots = IMContact.grouping_slots + (JABBER_JID_KEY, )

	def __init__(self, jid, name, status=None, resource=None, slots=None,
			image=None):
		IMContact.__init__(self, JABBER_JID_KEY, jid, name or jid,
				other_slots=slots, image=image)
		self._description = _("[%(status)s] %(userid)s/%(service)s") % \
				{
					"status": status or _("unknown"),
					"userid": jid,
					"service": resource or u"",
				}

	def get_description(self):
		return self._description


class AIMContact(IMContact):
	grouping_slots = IMContact.grouping_slots + (AIM_KEY, )

	def __init__(self, id_, name, slots=None, image=None):
		IMContact.__init__(self, AIM_KEY, id_, name, _("Aim"), slots, image)


class GoogleTalkContact(IMContact):
	grouping_slots = IMContact.grouping_slots + (GOOGLE_TALK_KEY, )

	def __init__(self, id_, name, slots=None, image=None):
		IMContact.__init__(self, GOOGLE_TALK_KEY, id_, name, _("Google Talk"),
				slots, image)


class ICQContact(IMContact):
	grouping_slots = IMContact.grouping_slots + (ICQ_KEY, )

	def __init__(self, id_, name, slots=None, image=None):
		IMContact.__init__(self, ICQ_KEY, id_, name, _("ICQ"), slots, image)


class MSNContact(IMContact):
	grouping_slots = IMContact.grouping_slots + (MSN_KEY, )

	def __init__(self, id_, name, slots=None, image=None):
		IMContact.__init__(self, MSN_KEY, id_, name, _("MSN"), slots, image)


class QQContact(IMContact):
	grouping_slots = IMContact.grouping_slots + (QQ_KEY, )

	def __init__(self, id_, name, slots=None, image=None):
		IMContact.__init__(self, QQ_KEY, id_, name, _("QQ"), slots, image)


class YahooContact(IMContact):
	grouping_slots = IMContact.grouping_slots + (YAHOO_KEY, )

	def __init__(self, id_, name, slots=None, image=None):
		IMContact.__init__(self, YAHOO_KEY, id_, name, _("Yahoo"), slots, image)


class SkypeContact(IMContact):
	grouping_slots = IMContact.grouping_slots + (SKYPE_KEY, )

	def __init__(self, id_, name, slots=None, image=None):
		IMContact.__init__(self, SKYPE_KEY, id_, name, _("Skype"), slots, image)


class PhoneContact(ContactLeaf):
	grouping_slots = ContactLeaf.grouping_slots + (EMAIL_KEY, )

	def __init__(self, number, name, label, slots=None, image=None):
		pslots = {PHONE_KEY: number, NAME_KEY: name, LABEL_KEY: label}
		if slots:
			pslots.update(slots)
		ContactLeaf.__init__(self, pslots, name, image)

	def repr_key(self):
		return self.object[PHONE_KEY]

	def get_description(self):
		return '%s: %s' % (self.object[LABEL_KEY], self.object[PHONE_KEY])


class AddressContact(ContactLeaf):
	grouping_slots = ContactLeaf.grouping_slots + (EMAIL_KEY, )

	def __init__(self, address, name, label, slots=None, image=None):
		aslots = {ADDRESS_KEY: address, NAME_KEY: name, LABEL_KEY: label}
		if slots:
			aslots.update(slots)
		ContactLeaf.__init__(self, aslots, name, image)

	def repr_key(self):
		return self.object[ADDRESS_KEY]

########NEW FILE########
__FILENAME__ = exceptions
from kupfer import kupferstring
from kupfer.obj.base import OperationError

class LocaleOperationError (OperationError):
	"""
	User-visible error created from locale-encoded
	error message (for example OSError)
	"""
	def __init__(self, s):
		OperationError.__init__(self, kupferstring.fromlocale(s))

class NotAvailableError (OperationError):
	"""
	User-visible error message when an external
	tool is the wrong version
	"""
	def __init__(self, toolname):
		OperationError.__init__(self,
		               _("%s does not support this operation") % toolname)

class NoMultiError (OperationError):
	def __init__(self):
		OperationError.__init__(self,
		               _("Can not be used with multiple objects"))

########NEW FILE########
__FILENAME__ = fileactions
import os
import gio

from kupfer import utils
from kupfer import launch

from kupfer.obj.base import Action, OperationError

class NoDefaultApplicationError (OperationError):
	pass

def is_good_executable(fileleaf):
	if not fileleaf._is_executable():
		return False
	ctype, uncertain = gio.content_type_guess(fileleaf.object, None, True)
	return uncertain or gio.content_type_can_be_executable(ctype)

def get_actions_for_file(fileleaf):
	acts = [RevealFile(), ]
	if fileleaf.is_dir():
		acts.append(OpenTerminal())
	elif fileleaf.is_valid():
		if is_good_executable(fileleaf):
			acts.extend((Execute(), Execute(in_terminal=True)))
	return [Open()] + acts

class Open (Action):
	""" Open with default application """
	rank_adjust = 5
	def __init__(self, name=_("Open")):
		Action.__init__(self, name)

	@classmethod
	def default_application_for_leaf(cls, leaf):
		content_attr = gio.FILE_ATTRIBUTE_STANDARD_CONTENT_TYPE
		gfile = gio.File(leaf.object)
		info = gfile.query_info(content_attr)
		content_type = info.get_attribute_string(content_attr)
		def_app = gio.app_info_get_default_for_type(content_type, False)
		if not def_app:
			apps_for_type = gio.app_info_get_all_for_type(content_type)
			raise NoDefaultApplicationError(
					(_("No default application for %(file)s (%(type)s)") % 
					 {"file": unicode(leaf), "type": content_type}) + "\n" +
					_('Please use "%s"') % _("Set Default Application...")
				)
		return def_app

	def wants_context(self):
		return True

	def activate(self, leaf, ctx):
		self.activate_multiple((leaf, ), ctx)

	def activate_multiple(self, objects, ctx):
		appmap = {}
		leafmap = {}
		for obj in objects:
			app = self.default_application_for_leaf(obj)
			id_ = app.get_id()
			appmap[id_] = app
			leafmap.setdefault(id_, []).append(obj)

		for id_, leaves in leafmap.iteritems():
			app = appmap[id_]
			launch.launch_application(app, paths=[L.object for L in leaves],
			                          activate=False,
			                          screen=ctx and ctx.environment.get_screen())

	def get_description(self):
		return _("Open with default application")

class RevealFile (Action):
	def __init__(self, name=_("Reveal")):
		super(RevealFile, self).__init__(name)
	
	def activate(self, leaf):
		fileloc = leaf.object
		parent = os.path.normpath(os.path.join(fileloc, os.path.pardir))
		utils.show_path(parent)

	def get_description(self):
		return _("Open parent folder")

	def get_icon_name(self):
		return "folder-open"

class OpenTerminal (Action):
	def __init__(self, name=_("Open Terminal Here")):
		super(OpenTerminal, self).__init__(name)

	def wants_context(self):
		return True

	def activate(self, leaf, ctx):
		try:
			utils.spawn_terminal(leaf.object, ctx.environment.get_screen())
		except utils.SpawnError as exc:
			raise OperationError(exc)

	def get_description(self):
		return _("Open this location in a terminal")
	def get_icon_name(self):
		return "terminal"

class Execute (Action):
	""" Execute executable file (FileLeaf) """
	rank_adjust = 10
	def __init__(self, in_terminal=False, quoted=True):
		name = _("Run in Terminal") if in_terminal else _("Run (Execute)")
		super(Execute, self).__init__(name)
		self.in_terminal = in_terminal
		self.quoted = quoted

	def repr_key(self):
		return (self.in_terminal, self.quoted)
	
	def activate(self, leaf):
		if self.quoted:
			argv = [leaf.object]
		else:
			argv = utils.argv_for_commandline(leaf.object)
		if self.in_terminal:
			utils.spawn_in_terminal(argv)
		else:
			utils.spawn_async(argv)

	def get_description(self):
		if self.in_terminal:
			return _("Run this program in a Terminal")
		else:
			return _("Run this program")


########NEW FILE########
__FILENAME__ = grouping
# -*- encoding: UTF-8 -*-
"""
Classes used to provide grouping leaves mechanism.
"""
import copy
import itertools
import time
import weakref

from kupfer.objects import Leaf, Source
from kupfer import utils

__author__ = ("Karol BÄ™dkowski <karol.bedkowsk+gh@gmail.com>, "
              "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>" )

class GroupingLeaf (Leaf):
	"""
	A Leaf that groups with other leaves inside Grouping Sources

	The represented object of a GroupedLeaf is a dictionary of (slot, value)
	pairs, where slot identifies the slot, and the value is something that must
	be equal to be grouped.

	The GroupingLeaf must have a value for all @grouping_slots, but values of
	None will not be grouped with others.
	"""
	grouping_slots = ()

	def __init__(self, obj, name):
		Leaf.__init__(self, obj, name)
		self.links = [self]

	def slots(self):
		return self.object

	def has_content(self):
		return len(self.links) > 1

	def content_source(self, alternate=False):
		return _GroupedItemsSource(self)

	def __len__(self):
		return len(self.links)

	def __contains__(self, key):
		"Return True if GroupedLeaf has value for @key"
		return any(key in leaf.object for leaf in self.links)

	def __getitem__(self, key):
		"Get first (canonical) value for key"
		try:
			return iter(self.all(key)).next()
		except StopIteration:
			raise KeyError("%s has no slot %s" % (self, key))

	def all(self, key):
		"Return iterator of all values for @key"
		return (leaf.object[key] for leaf in self.links if key in leaf.object)

	def check_key(self, key):
		''' check if GroupedLeaf has non empty value for @key '''
		return any(bool(leaf.object.get(key)) for leaf in self.links)

class GroupingSource (Source):

	def __init__(self, name, sources):
		Source.__init__(self, name)
		self.sources = sources

	def get_leaves(self, force_update=False):
		starttime = time.time()
		# map (slot, value) -> group
		groups = {}
		non_group_leaves = []
		for src in self.sources:
			leaves = Source.get_leaves(src, force_update)
			for leaf in leaves:
				try:
					slots = leaf.slots()
				except AttributeError:
					# Let through Non-grouping leaves
					non_group_leaves.append(leaf)
					continue
				slots = leaf.slots()
				for slot in leaf.grouping_slots:
					value = slots.get(slot)
					if value:
						groups.setdefault((slot, value), set()).add(leaf)
				if not leaf.grouping_slots:
					self.output_error("GroupingLeaf has no grouping slots",
							repr(leaf))

		# Keep track of keys that are only duplicate references
		redundant_keys = set()

		def merge_groups(key1, key2):
			if groups[key1] is groups[key2]:
				return
			groups[key1].update(groups[key2])
			groups[key2] = groups[key1]
			redundant_keys.add(key2)

		# Find all (slot, value) combinations that have more than one leaf
		# and merge those groups
		for (slot, value), leaves in groups.iteritems():
			if len(leaves) <= 1:
				continue
			for leaf in list(leaves):
				for slot2 in leaf.grouping_slots:
					for value2 in leaf.all(slot2):
						if not value2:
							continue
						merge_groups((slot, value), (slot2, value2))
		if self.should_sort_lexically():
			sort_func = utils.locale_sort
		else:
			sort_func = lambda x: x

		keys = set(groups)
		keys.difference_update(redundant_keys)
		leaves = sort_func(self._make_group_leader(groups[K]) for K in keys)
		mergetime = time.time() - starttime
		if mergetime > 0.05:
			self.output_debug("Warning(?): merged in %s seconds" % mergetime)
		return itertools.chain(non_group_leaves, leaves)

	def repr_key(self):
		# Distinguish when used as GroupingSource
		if type(self) is GroupingSource:
			return unicode(self)
		return Source.repr_key(self)

	@classmethod
	def _make_group_leader(cls, leaves):
		if len(leaves) == 1:
			(leaf, ) = leaves
			return leaf
		obj = copy.copy(iter(leaves).next())
		obj.links = list(leaves)
		for other in leaves:
			obj.kupfer_add_alias(unicode(other))
			# adding the other's aliases can be misleading
			# since the matched email address might not be
			# what we are e-mailing
			# obj.name_aliases.update(other.name_aliases)
		return obj

class ToplevelGroupingSource (GroupingSource):
	"""
	Sources of this type group their leaves with others in the toplevel
	of the catalog.
	"""
	_sources = {}

	def __init__(self, name, category):
		GroupingSource.__init__(self, name, [self])
		self.category = category

	def toplevel_source(self):
		if self.category not in self._sources:
			return self
		sources = self._sources[self.category].keys()
		return GroupingSource(self.category, sources)

	def initialize(self):
		if not self.category in self._sources:
			self._sources[self.category] = weakref.WeakKeyDictionary()
		self._sources[self.category][self] = 1
		self.output_debug("Register %s source %s" % (self.category, self))

	def finalize(self):
		del self._sources[self.category][self]
		self.output_debug("Unregister %s source %s" % (self.category, self))

class _GroupedItemsSource(Source):
	def __init__(self, leaf):
		Source.__init__(self, unicode(leaf))
		self._leaf = leaf

	def get_items(self):
		for leaf in self._leaf.links:
			yield leaf

	def repr_key(self):
		return repr(self._leaf)




########NEW FILE########
__FILENAME__ = helplib
"""
This module contains Helper constructs

This module is a part of the program Kupfer, see the main program file for
more information.
"""

import gio

class PicklingHelperMixin (object):
	""" This pickling helper will define __getstate__/__setstate__
	acting simply on the class dictionary; it is up to the inheriting
	class to set up:
	pickle_prepare:
		Modify the instance dict to remove any unpickleable attributes,
		the resulting dict will be pickled
	unpickle_finish:
		Finish unpickling by restoring nonpickled attributes from the
		saved class dict, or setting up change callbacks or similar
	"""
	def pickle_prepare(self):
		pass
	def unpickle_finish(self):
		pass
	def __getstate__(self):
		"""On pickle, getstate will call self.pickle_prepare(),
		then it will return the class' current __dict__
		"""
		self.pickle_prepare()
		return self.__dict__

	def __setstate__(self, state):
		"""On unpickle, setstate will restore the class' __dict__,
		then call self.unpickle_finish()
		"""
		self.__dict__.update(state)
		self.unpickle_finish()

class NonpersistentToken (PicklingHelperMixin):
	"""A token will keep a reference until pickling, when it is deleted"""
	def __init__(self, data):
		self.data = data
	def __nonzero__(self):
		return self.data
	def pickle_prepare(self):
		self.data = None

class FilesystemWatchMixin (object):
	"""A mixin for Sources watching directories"""

	def monitor_directories(self, *directories, **kwargs):
		"""Register @directories for monitoring;

		On changes, the Source will be marked for update.
		This method returns a monitor token that has to be
		stored for the monitor to be active.

		The token will be a false value if nothing could be monitored.

		Nonexisting directories are skipped, if not passing
		the kwarg @force
		"""
		tokens = []
		force = kwargs.get('force', False)
		for directory in directories:
			gfile = gio.File(directory)
			if not force and not gfile.query_exists():
				continue
			monitor = gfile.monitor_directory(gio.FILE_MONITOR_NONE, None)
			if monitor:
				monitor.connect("changed", self.__directory_changed)
				tokens.append(monitor)
		return NonpersistentToken(tokens)

	def monitor_include_file(self, gfile):
		"""Return whether @gfile should trigger an update event
		by default, files beginning with "." are ignored
		"""
		return not (gfile and gfile.get_basename().startswith("."))

	def __directory_changed(self, monitor, file1, file2, evt_type):
		if (evt_type in (gio.FILE_MONITOR_EVENT_CREATED,
				gio.FILE_MONITOR_EVENT_DELETED) and
				self.monitor_include_file(file1)):
			self.mark_for_update()

def reverse_action(action, rank=0):
	"""Return a reversed version a three-part action

	@action: the action class
	@rank: the rank_adjust to give the reversed action

	A three-part action requires a direct object (item) and an indirect
	object (iobj).

	In general, the item must be from the Catalog, while the iobj can be
	from one, specified special Source. If this is used, and the action
	will be reversed, the base action must be the one specifying a
	source for the iobj. The reversed action will always take both item
	and iobj from the Catalog, filtered by type.

	If valid_object(iobj, for_leaf=None) is used, it will always be
	called with only the new item as the first parameter when reversed.
	"""
	class ReverseAction (action):
		rank_adjust = rank
		def activate(self, leaf, iobj):
			return action.activate(self, iobj, leaf)
		def item_types(self):
			return action.object_types(self)
		def valid_for_item(self, leaf):
			try:
				return action.valid_object(self, leaf)
			except AttributeError:
				return True
		def object_types(self):
			return action.item_types(self)
		def valid_object(self, obj, for_item=None):
			return action.valid_for_item(self, obj)
		def object_source(self, for_item=None):
			return None
	ReverseAction.__name__ = "Reverse" + action.__name__
	return ReverseAction


########NEW FILE########
__FILENAME__ = hosts
# -*- encoding: utf-8 -*-
"""
Kupfer's Hosts API

Main definition and *constructor* classes.
"""

from kupfer.obj.grouping import GroupingLeaf

__author__ = ("Ulrik Sverdrup <ulrik.sverdrup@gmail.com>, "
              "Karol BÄ™dkowski <karol.bedkowsk+gh@gmail.com>" )

HOST_NAME_KEY = "HOST_NAME"
HOST_ADDRESS_KEY = "HOST_ADDRESS"
HOST_SERVICE_NAME_KEY = "HOST_SERVICE_NAME"
HOST_SERVICE_PORT_KEY = "HOST_SERVICE_PORT"
HOST_SERVICE_USER_KEY = "HOST_SERVICE_USER"
HOST_SERVICE_PASS_KEY = "HOST_SERVICE_PASS"
HOST_SERVICE_REMOTE_PATH_KEY = "HOST_SERVICE_REMOTE_PATH"


class HostLeaf(GroupingLeaf):
	grouping_slots = (HOST_NAME_KEY, HOST_ADDRESS_KEY)

	def get_icon_name(self):
		return "computer"


class HostServiceLeaf(HostLeaf):
	''' Leaf dedicated for well known services like ftp, ssh, vnc '''
	def __init__(self, name, address, service, description, port=None,
			user=None, password=None, slots=None):
		_slots = {
			HOST_NAME_KEY: name,
			HOST_ADDRESS_KEY: address,
			HOST_SERVICE_NAME_KEY: service,
			HOST_SERVICE_PORT_KEY: port,
			HOST_SERVICE_USER_KEY: user,
			HOST_SERVICE_PASS_KEY: password,
		}
		if slots:
			_slots.update(slots)
		HostLeaf.__init__(self, _slots, name or address)
		self._description = description

	def get_description(self):
		return self._description


########NEW FILE########
__FILENAME__ = objects
# -*- coding: UTF-8 -*-

"""
Copyright 2007--2009 Ulrik Sverdrup <ulrik.sverdrup@gmail.com>

This file is a part of the program kupfer, which is
released under GNU General Public License v3 (or any later version),
see the main program file, and COPYING for details.
"""

import os
from os import path

import gio
import gobject

from kupfer import icons, launch, utils
from kupfer import pretty
from kupfer.obj.base import Leaf, Action
from kupfer.obj.base import InvalidDataError, OperationError
from kupfer.obj import fileactions
from kupfer.interface import TextRepresentation
from kupfer.kupferstring import tounicode

def ConstructFileLeafTypes():
	""" Return a seq of the Leaf types returned by ConstructFileLeaf"""
	yield FileLeaf
	yield AppLeaf

def ConstructFileLeaf(obj):
	"""
	If the path in @obj points to a Desktop Item file,
	return an AppLeaf, otherwise return a FileLeaf
	"""
	root, ext = path.splitext(obj)
	if ext == ".desktop":
		try:
			return AppLeaf(init_path=obj)
		except InvalidDataError:
			pass
	return FileLeaf(obj)

def _directory_content(dirpath, show_hidden):
	from kupfer.obj.sources import DirectorySource
	return DirectorySource(dirpath, show_hidden)

class FileLeaf (Leaf, TextRepresentation):
	"""
	Represents one file: the represented object is a bytestring (important!)
	"""
	serializable = 1

	def __init__(self, obj, name=None, alias=None):
		"""Construct a FileLeaf

		The display name of the file is normally derived from the full path,
		and @name should normally be left unspecified.

		@obj: byte string (file system encoding)
		@name: unicode name or None for using basename
		"""
		if obj is None:
			raise InvalidDataError("File path for %s may not be None" % name)
		# Use glib filename reading to make display name out of filenames
		# this function returns a `unicode` object
		if not name:
			name = gobject.filename_display_basename(obj)
		super(FileLeaf, self).__init__(obj, name)
		if alias:
			self.kupfer_add_alias(alias)

	def __eq__(self, other):
		try:
			return (type(self) == type(other) and
					unicode(self) == unicode(other) and
					path.samefile(self.object, other.object))
		except OSError, exc:
			pretty.print_debug(__name__, exc)
			return False

	def repr_key(self):
		return self.object

	def canonical_path(self):
		"""Return the true path of the File (without symlinks)"""
		return path.realpath(self.object)

	def is_valid(self):
		return os.access(self.object, os.R_OK)

	def _is_executable(self):
		return os.access(self.object, os.R_OK | os.X_OK)

	def is_dir(self):
		return path.isdir(self.object)

	def get_text_representation(self):
		return gobject.filename_display_name(self.object)

	def get_urilist_representation(self):
		return [gio.File(path=self.object).get_uri()]

	def get_description(self):
		return utils.get_display_path_for_bytestring(self.canonical_path())

	def get_actions(self):
		return fileactions.get_actions_for_file(self)

	def has_content(self):
		return self.is_dir() or Leaf.has_content(self)
	def content_source(self, alternate=False):
		if self.is_dir():
			return _directory_content(self.object, alternate)
		else:
			return Leaf.content_source(self)

	def get_thumbnail(self, width, height):
		if self.is_dir(): return None
		return icons.get_thumbnail_for_file(self.object, width, height)
	def get_gicon(self):
		return icons.get_gicon_for_file(self.object)
	def get_icon_name(self):
		if self.is_dir():
			return "folder"
		else:
			return "text-x-generic"

class SourceLeaf (Leaf):
	def __init__(self, obj, name=None):
		"""Create SourceLeaf for source @obj"""
		if not name:
			name = unicode(obj)
		Leaf.__init__(self, obj, name)
	def has_content(self):
		return True

	def repr_key(self):
		return repr(self.object)

	def content_source(self, alternate=False):
		return self.object

	def get_description(self):
		return self.object.get_description()

	@property
	def fallback_icon_name(self):
		return self.object.fallback_icon_name

	def get_gicon(self):
		return self.object.get_gicon()

	def get_icon_name(self):
		return self.object.get_icon_name()

class AppLeaf (Leaf):
	def __init__(self, item=None, init_path=None, app_id=None, require_x=True):
		"""Try constructing an Application for GAppInfo @item,
		for file @path or for package name @app_id.

		@require_x: require executable file
		"""
		self.init_item = item
		self.init_path = init_path
		self.init_item_id = app_id and app_id + ".desktop"
		# finish will raise InvalidDataError on invalid item
		self.finish(require_x)
		Leaf.__init__(self, self.object, self.object.get_name())
		self._add_aliases()

	def _add_aliases(self):
		# find suitable alias
		# use package name: non-extension part of ID
		lowername = unicode(self).lower()
		package_name = self._get_package_name()
		if package_name and package_name not in lowername:
			self.kupfer_add_alias(package_name)

	def __hash__(self):
		return hash(unicode(self))

	def __eq__(self, other):
		return (isinstance(other, type(self)) and
				self.get_id() == other.get_id())

	def __getstate__(self):
		self.init_item_id = self.object and self.object.get_id()
		state = dict(vars(self))
		state["object"] = None
		state["init_item"] = None
		return state

	def __setstate__(self, state):
		vars(self).update(state)
		self.finish()

	def finish(self, require_x=False):
		"""Try to set self.object from init's parameters"""
		item = None
		if self.init_item:
			item = self.init_item
		else:
			# Construct an AppInfo item from either path or item_id
			from gio.unix import DesktopAppInfo, desktop_app_info_new_from_filename
			if self.init_path and (
			   not require_x or os.access(self.init_path, os.X_OK)):
				# serilizable if created from a "loose file"
				self.serializable = 1
				item = desktop_app_info_new_from_filename(self.init_path)
			elif self.init_item_id:
				try:
					item = DesktopAppInfo(self.init_item_id)
				except RuntimeError:
					pretty.print_debug(__name__, "Application not found:",
							self.init_item_id)
		self.object = item
		if not self.object:
			raise InvalidDataError

	def repr_key(self):
		return self.get_id()

	def _get_package_name(self):
		return gobject.filename_display_basename(self.get_id())

	def launch(self, files=(), paths=(), activate=False, ctx=None):
		"""
		Launch the represented applications

		@files: a seq of GFiles (gio.File)
		@paths: a seq of bytestring paths
		@activate: activate instead of start new
		"""
		try:
			return launch.launch_application(self.object, files=files,
			                                 paths=paths, activate=activate,
			                                 desktop_file=self.init_path,
			                                 screen=ctx and ctx.environment.get_screen())
		except launch.SpawnError as exc:
			raise OperationError(exc)

	def get_id(self):
		"""Return the unique ID for this app.

		This is the GIO id "gedit.desktop" minus the .desktop part for
		system-installed applications.
		"""
		return launch.application_id(self.object, self.init_path)

	def get_actions(self):
		if launch.application_is_running(self.get_id()):
			yield Launch(_("Go To"), is_running=True)
			yield CloseAll()
		else:
			yield Launch()
		yield LaunchAgain()

	def get_description(self):
		# Use Application's description, else use executable
		# for "file-based" applications we show the path
		app_desc = tounicode(self.object.get_description())
		ret = tounicode(app_desc if app_desc else self.object.get_executable())
		if self.init_path:
			app_path = utils.get_display_path_for_bytestring(self.init_path)
			return u"(%s) %s" % (app_path, ret)
		return ret

	def get_gicon(self):
		return self.object.get_icon()

	def get_icon_name(self):
		return "exec"

class OpenUrl (Action):
	rank_adjust = 5
	def __init__(self, name=None):
		if not name:
			name = _("Open URL")
		super(OpenUrl, self).__init__(name)

	def activate(self, leaf):
		url = leaf.object
		self.open_url(url)

	def open_url(self, url):
		utils.show_url(url)

	def get_description(self):
		return _("Open URL with default viewer")

	def get_icon_name(self):
	  	return "forward"

class Launch (Action):
	""" Launches an application (AppLeaf) """
	rank_adjust = 5
	def __init__(self, name=None, is_running=False, open_new=False):
		"""
		If @is_running, style as if the app is running (Show application)
		If @open_new, always start a new instance.
		"""
		if not name:
			name = _("Launch")
		Action.__init__(self, name)
		self.is_running = is_running
		self.open_new = open_new

	def wants_context(self):
		return True

	def activate(self, leaf, ctx):
		leaf.launch(activate=not self.open_new, ctx=ctx)

	def get_description(self):
		if self.is_running:
			return _("Show application window")
		return _("Launch application")

	def get_icon_name(self):
		if self.is_running:
			return "go-jump"
		return "kupfer-launch"

class LaunchAgain (Launch):
	rank_adjust = 0
	def __init__(self, name=None):
		if not name:
			name = _("Launch Again")
		Launch.__init__(self, name, open_new=True)
	def item_types(self):
		yield AppLeaf
	def valid_for_item(self, leaf):
		return launch.application_is_running(leaf.get_id())
	def get_description(self):
		return _("Launch another instance of this application")

class CloseAll (Action):
	"""Attempt to close all application windows"""
	rank_adjust = -10
	def __init__(self):
		Action.__init__(self, _("Close"))
	def activate(self, leaf):
		return launch.application_close_all(leaf.get_id())
	def item_types(self):
		yield AppLeaf
	def valid_for_item(self, leaf):
		return launch.application_is_running(leaf.get_id())
	def get_description(self):
		return _("Attempt to close all application windows")
	def get_icon_name(self):
		return "window-close"

class UrlLeaf (Leaf, TextRepresentation):
	def __init__(self, obj, name):
		super(UrlLeaf, self).__init__(obj, name or obj)
		if obj != name:
			self.kupfer_add_alias(obj)

	def get_actions(self):
		return (OpenUrl(), )

	def get_description(self):
		return self.object

	def get_icon_name(self):
		return "text-html"

class RunnableLeaf (Leaf):
	"""Leaf where the Leaf is basically the action itself,
	for items such as Quit, Log out etc.
	"""
	def __init__(self, obj=None, name=None):
		Leaf.__init__(self, obj, name)
	def get_actions(self):
		yield Perform()
	def run(self, ctx=None):
		raise NotImplementedError
	def wants_context(self):
		""" Return ``True`` if you want the actions' execution
		context passed as ctx= in RunnableLeaf.run
		"""
		return False
	def repr_key(self):
		return ""
	def get_gicon(self):
		iname = self.get_icon_name()
		if iname:
			return icons.get_gicon_with_fallbacks(None, (iname, ))
		return icons.ComposedIcon("kupfer-object", "kupfer-execute")
	def get_icon_name(self):
		return ""

class Perform (Action):
	"""Perform the action in a RunnableLeaf"""
	rank_adjust = 5
	def __init__(self, name=None):
		# TRANS: 'Run' as in Perform a (saved) command
		if not name: name = _("Run")
		super(Perform, self).__init__(name=name)
	def wants_context(self):
		return True
	def activate(self, leaf, ctx):
		if leaf.wants_context():
			return leaf.run(ctx)
		else:
			return leaf.run()
	def get_description(self):
		return _("Perform command")

class TextLeaf (Leaf, TextRepresentation):
	"""Represent a text query
	The represented object is a unicode string
	"""
	serializable = 1
	def __init__(self, text, name=None):
		"""@text *must* be unicode or UTF-8 str"""
		text = tounicode(text)
		if not name:
			name = self.get_first_text_line(text)
		if len(text) == 0 or not name:
			name = _("(Empty Text)")
		Leaf.__init__(self, text, name)

	def get_actions(self):
		return ()

	def repr_key(self):
		return hash(self.object)

	@classmethod
	def get_first_text_line(cls, text):
		firstline = None
		firstnl = text.find("\n")
		if firstnl != -1:
			firstline = text[:firstnl].strip()
			if not firstline:
				splut = text.split(None, 1)
				firstline = splut[0] if splut else text
		else:
			firstline = text
		if not firstline:
			firstline = text.strip("\n")
		return firstline

	def get_description(self):
		numlines = self.object.count("\n") + 1
		desc = self.get_first_text_line(self.object)

		# TRANS: This is description for a TextLeaf, a free-text search
		# TRANS: The plural parameter is the number of lines %(num)d
		return ngettext('"%(text)s"', '(%(num)d lines) "%(text)s"',
			numlines) % {"num": numlines, "text": desc }

	def get_icon_name(self):
		return "edit-select-all"


########NEW FILE########
__FILENAME__ = sources
import itertools
import os
from os import path

import gobject

from kupfer import datatools
from kupfer import icons
from kupfer import utils

from kupfer.obj.base import Source
from kupfer.obj.helplib import PicklingHelperMixin, FilesystemWatchMixin
from kupfer.obj.objects import FileLeaf, SourceLeaf
from kupfer.obj.objects import ConstructFileLeaf, ConstructFileLeafTypes


class FileSource (Source):
	def __init__(self, dirlist, depth=0):
		"""
		@dirlist: Directories as byte strings
		"""
		name = gobject.filename_display_basename(dirlist[0])
		if len(dirlist) > 1:
			name = _("%s et. al.") % name
		super(FileSource, self).__init__(name)
		self.dirlist = dirlist
		self.depth = depth

	def __repr__(self):
		return "%s.%s((%s, ), depth=%d)" % (self.__class__.__module__,
			self.__class__.__name__,
			', '.join('"%s"' % d for d in sorted(self.dirlist)), self.depth)

	def get_items(self):
		iters = []
		
		def mkleaves(directory):
			files = utils.get_dirlist(directory, depth=self.depth,
					exclude=self._exclude_file)
			return (ConstructFileLeaf(f) for f in files)

		for d in self.dirlist:
			iters.append(mkleaves(d))

		return itertools.chain(*iters)

	def should_sort_lexically(self):
		return True

	def _exclude_file(self, filename):
		return filename.startswith(".") 

	def get_description(self):
		return (_("Recursive source of %(dir)s, (%(levels)d levels)") %
				{"dir": self.name, "levels": self.depth})

	def get_icon_name(self):
		return "folder-saved-search"

	def provides(self):
		return ConstructFileLeafTypes()

class DirectorySource (Source, PicklingHelperMixin, FilesystemWatchMixin):
	def __init__(self, dir, show_hidden=False):
		# Use glib filename reading to make display name out of filenames
		# this function returns a `unicode` object
		name = gobject.filename_display_basename(dir)
		super(DirectorySource, self).__init__(name)
		self.directory = dir
		self.show_hidden = show_hidden

	def __repr__(self):
		return "%s.%s(\"%s\", show_hidden=%s)" % (self.__class__.__module__,
				self.__class__.__name__, str(self.directory), self.show_hidden)

	def initialize(self):
		self.monitor = self.monitor_directories(self.directory)

	def finalize(self):
		self.monitor = None

	def monitor_include_file(self, gfile):
		return self.show_hidden or not gfile.get_basename().startswith('.')

	def get_items(self):
		try:
			for fname in os.listdir(self.directory):
				if self.show_hidden or not fname.startswith("."):
					yield ConstructFileLeaf(path.join(self.directory, fname))
		except OSError, exc:
			self.output_error(exc)

	def should_sort_lexically(self):
		return True

	def _parent_path(self):
		return path.normpath(path.join(self.directory, path.pardir))

	def has_parent(self):
		return not path.samefile(self.directory , self._parent_path())

	def get_parent(self):
		if not self.has_parent():
			return super(DirectorySource, self).has_parent(self)
		return DirectorySource(self._parent_path())

	def get_description(self):
		return _("Directory source %s") % self.directory

	def get_gicon(self):
		return icons.get_gicon_for_file(self.directory)

	def get_icon_name(self):
		return "folder"

	def get_leaf_repr(self):
		if os.path.isdir(self.directory) and \
			 os.path.samefile(self.directory, os.path.expanduser("~")):
			alias = _("Home Folder")
		else:
			alias = None
		return FileLeaf(self.directory, alias=alias)

	def provides(self):
		return ConstructFileLeafTypes()

class SourcesSource (Source):
	""" A source whose items are SourceLeaves for @source """
	def __init__(self, sources, name=None, use_reprs=True):
		if not name: name = _("Catalog Index")
		super(SourcesSource, self).__init__(name)
		self.sources = sources
		self.use_reprs = use_reprs

	def get_items(self):
		"""Ask each Source for a Leaf substitute, else
		yield a SourceLeaf """
		for s in self.sources:
			yield (self.use_reprs and s.get_leaf_repr()) or SourceLeaf(s)

	def should_sort_lexically(self):
		return True

	def get_description(self):
		return _("An index of all available sources")

	def get_icon_name(self):
		return "folder-saved-search"

class MultiSource (Source):
	"""
	A source whose items are the combined items
	of all @sources
	"""
	fallback_icon_name = "kupfer-catalog"
	def __init__(self, sources):
		super(MultiSource, self).__init__(_("Catalog"))
		self.sources = sources
	
	def is_dynamic(self):
		"""
		MultiSource should be dynamic so some of its content
		also can be
		"""
		return True

	def get_items(self):
		iterators = []
		ui = datatools.UniqueIterator(S.toplevel_source() for S in self.sources)
		for S in ui:
			it = S.get_leaves()
			iterators.append(it)

		return itertools.chain(*iterators)

	def get_description(self):
		return _("Root catalog")


########NEW FILE########
__FILENAME__ = special
__version__ = '2010-01-21'


from kupfer.obj.objects import RunnableLeaf
from kupfer import kupferui


class PleaseConfigureLeaf(RunnableLeaf):
	""" Show information and allow to open preferences for given plugin """
	message = _("Please Configure Plugin")
	description = _("Plugin %s is not configured")

	def __init__(self, plugin_id, plugin_name):
		plugin_id = plugin_id.split('.')[-1]
		RunnableLeaf.__init__(self, plugin_id, self.message)
		self.plugin_name = plugin_name

	def wants_context(self):
		return True

	def run(self, ctx):
		kupferui.show_plugin_info(self.object, ctx.environment)

	def get_icon_name(self):
		return "preferences-desktop"

	def get_description(self):
		return self.description % self.plugin_name


class InvalidCredentialsLeaf(PleaseConfigureLeaf):
	description = _("Invalid user credentials for %s")



########NEW FILE########
__FILENAME__ = objects
from kupfer.obj.base import *
from kupfer.obj.exceptions import *
from kupfer.obj.objects import FileLeaf, AppLeaf, UrlLeaf, TextLeaf
from kupfer.obj.objects import RunnableLeaf, SourceLeaf

# Show everything here in help(..)
__all__ = dir()

########NEW FILE########
__FILENAME__ = abiword
__kupfer_name__ = _("Abiword")
__kupfer_sources__ = ("RecentsSource", )
__description__ = _("Recently used documents in Abiword")
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import os
import xml.etree.cElementTree as ElementTree

import gio

from kupfer.objects import Source, FileLeaf, UrlLeaf
from kupfer.obj.helplib import PicklingHelperMixin
from kupfer.obj.apps import AppLeafContentMixin

def get_abiword_files(xmlpth, application="abiword"):
	"""
	Yield URLs to abiword's recent files from XML file @xmlpth
	"""
	inside = False
	for event, entry in ElementTree.iterparse(xmlpth, events=("start", "end")):
		if entry.tag == "AbiPreferences" and entry.get("app") == application:
			if event == "start":
				inside = True
		elif not inside and event != "end":
			continue
		if entry.tag == "Recent":
			return (entry.get(a) for a in entry.attrib if a.startswith("name"))

class RecentsSource (AppLeafContentMixin, Source, PicklingHelperMixin):
	appleaf_content_id = "abiword"
	def __init__(self, name=None):
		if not name:
			name = _("Abiword Recent Items")
		super(RecentsSource, self).__init__(name)
		self.unpickle_finish()

	def pickle_prepare(self):
		# monitor is not pickleable
		self.monitor = None

	def unpickle_finish(self):
		"""Set up change monitor"""
		abifile = self._get_abiword_file()
		if not abifile: return
		gfile = gio.File(abifile)
		self.monitor = gfile.monitor_file(gio.FILE_MONITOR_NONE, None)
		if self.monitor:
			self.monitor.connect("changed", self._changed)

	def _changed(self, monitor, file1, file2, evt_type):
		"""Change callback; something changed"""
		if evt_type in (gio.FILE_MONITOR_EVENT_CREATED,
				gio.FILE_MONITOR_EVENT_DELETED,
				gio.FILE_MONITOR_EVENT_CHANGED):
			self.mark_for_update()

	def _get_abiword_file(self):
		abifile = os.path.expanduser("~/.AbiSuite/AbiWord.Profile")
		if not os.path.exists(abifile):
			return None
		return abifile

	def get_items(self):
		abifile = self._get_abiword_file()
		if not abifile:
			self.output_debug("Abiword profile not found at", abifile)
			return

		try:
			uris = list(get_abiword_files(abifile))
		except EnvironmentError, exc:
			self.output_error(exc)
			return

		for uri in uris:
			gfile = gio.File(uri)
			if not gfile.query_exists():
				continue

			if gfile.get_path():
				leaf = FileLeaf(gfile.get_path())
			else:
				leaf = UrlLeaf(gfile.get_uri(), gfile.get_basename())
			yield leaf

	def get_description(self):
		return _("Recently used documents in Abiword")

	def get_icon_name(self):
		return "document-open-recent"
	def provides(self):
		yield FileLeaf
		yield UrlLeaf


########NEW FILE########
__FILENAME__ = applications

__kupfer_name__ = _("Applications")
__kupfer_sources__ = ("AppSource", )
__kupfer_actions__ = (
		"OpenWith",
		"SetDefaultApplication",
	)
__description__ = _("All applications and preferences")
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import gio
from gio import app_info_get_all
from gio.unix import desktop_app_info_set_desktop_env

from kupfer.objects import Action, Source, AppLeaf, FileLeaf
from kupfer.obj.helplib import FilesystemWatchMixin
from kupfer import config, plugin_support

__kupfer_settings__ = plugin_support.PluginSettings(
	{
		"key" : "desktop_type",
		"label": _("Applications for Desktop Environment"),
		"type": str,
		"value": "GNOME",
		"alternatives": ("GNOME", "KDE", "LXDE", "ROX", "XFCE")
	},
)

class AppSource (Source, FilesystemWatchMixin):
	"""
	Applications source

	This Source contains all user-visible applications (as given by
	the desktop files)
	"""
	def __init__(self):
		super(AppSource, self).__init__(_("Applications"))

	def initialize(self):
		application_dirs = config.get_data_dirs("", "applications")
		self.monitor_token = self.monitor_directories(*application_dirs)

	def get_items(self):
		# If we set proper desktop environment
		# We get exactly the apps shown in the menu,
		# as well as the preference panes
		desktop_type = __kupfer_settings__["desktop_type"]
		desktop_app_info_set_desktop_env(desktop_type)
		# Add this to the default
		whitelist = set([
			# if you set/reset default handler for folders it is useful
			"nautilus-folder-handler.desktop",
			# we think that these are useful to show
			"eog.desktop",
			"evince.desktop",
			"gnome-about.desktop",
			"gstreamer-properties.desktop",
			"notification-properties.desktop",
			])
		blacklist = set([
			"nautilus-home.desktop",
		])

		for item in app_info_get_all():
			id_ = item.get_id()
			if id_ in whitelist or (item.should_show() and not id_ in blacklist):
				yield AppLeaf(item)

	def should_sort_lexically(self):
		return True

	def get_description(self):
		return _("All applications and preferences")

	def get_icon_name(self):
		return "applications-office"
	def provides(self):
		yield AppLeaf

class OpenWith (Action):
	def __init__(self):
		Action.__init__(self, _("Open With..."))

	def _activate(self, app_leaf, paths, ctx):
		app_leaf.launch(paths=paths, ctx=ctx)

	def wants_context(self):
		return True

	def activate(self, leaf, iobj, ctx):
		self._activate(iobj, (leaf.object, ), ctx)
	def activate_multiple(self, objects, iobjects, ctx):
		# for each application, launch all the files
		for iobj_app in iobjects:
			self._activate(iobj_app, [L.object for L in objects], ctx)

	def item_types(self):
		yield FileLeaf
	def requires_object(self):
		return True
	def object_types(self):
		yield AppLeaf
	def get_description(self):
		return _("Open with any application")

class SetDefaultApplication (Action):
	def __init__(self):
		Action.__init__(self, _("Set Default Application..."))
	def activate(self, leaf, obj):
		gfile = gio.File(leaf.object)
		info = gfile.query_info(gio.FILE_ATTRIBUTE_STANDARD_CONTENT_TYPE)
		content_type = info.get_attribute_string(gio.FILE_ATTRIBUTE_STANDARD_CONTENT_TYPE)
		print content_type, gfile
		desktop_item = obj.object
		desktop_item.set_as_default_for_type(content_type)
	def item_types(self):
		yield FileLeaf
	def requires_object(self):
		return True
	def object_types(self):
		yield AppLeaf
	def get_description(self):
		return _("Set default application to open this file type")

########NEW FILE########
__FILENAME__ = apt_tools
__kupfer_name__ = _("APT")
__kupfer_sources__ = ()
__kupfer_text_sources__ = ()
__kupfer_actions__ = (
		"ShowPackageInfo",
		"SearchPackageName",
		"InstallPackage",
	)
__description__ = _("Interface with the package manager APT")
__version__ = ""
__author__ = ("Martin Koelewijn <martinkoelewijn@gmail.com>, "
              "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>")

import os

from kupfer.objects import Action, Source, Leaf
from kupfer.objects import TextLeaf
from kupfer import icons, kupferstring, task, uiutils, utils
from kupfer import plugin_support


__kupfer_settings__ = plugin_support.PluginSettings(
	{
		"key" : "installation_method",
		"label": _("Installation method"),
		"type": str,
		"value": "gksu -- apt-get install --yes",
	},
)

class InfoTask(task.Task):
	def __init__(self, text):
		super(InfoTask, self).__init__()
		self.text = text
		self.aptitude = None
		self.apt_cache = None

	def start(self, finish_callback):
		self._finish_callback = finish_callback
		timeout = 60
		AC = utils.AsyncCommand
		AC(["aptitude", "show", self.text], self.aptitude_finished, timeout)
		AC(["apt-cache", "policy", self.text], self.aptcache_finished, timeout)

	def aptitude_finished(self, acommand, stdout, stderr):
		self.aptitude = stderr
		self.aptitude += stdout
		self._check_end()

	def aptcache_finished(self, acommand, stdout, stderr):
		self.apt_cache = stderr
		self.apt_cache += stdout
		self._check_end()

	def _check_end(self):
		if self.aptitude is not None and self.apt_cache is not None:
			self.finish(u"".join(kupferstring.fromlocale(s)
			            for s in (self.aptitude, self.apt_cache)))

	def finish(self, text):
		uiutils.show_text_result(text, title=_("Show Package Information"))
		self._finish_callback(self)

class ShowPackageInfo (Action):
	def __init__(self):
		Action.__init__(self, _("Show Package Information"))

	def is_async(self):
		return True
	def activate(self, leaf):
		return InfoTask(leaf.object.strip())

	def item_types(self):
		yield TextLeaf
		yield Package

	def valid_for_item(self, item):
		# check if it is a single word
		text = item.object
		return len(text.split(None, 1)) == 1

	def get_gicon(self):
		return icons.ComposedIcon("dialog-information", "package-x-generic")

class InstallPackage (Action):
	def __init__(self):
		Action.__init__(self, _("Install"))

	def activate(self, leaf):
		self.activate_multiple((leaf, ))

	def activate_multiple(self, objs):
		program = (__kupfer_settings__["installation_method"])
		pkgs = [o.object.strip() for o in objs]
		prog_argv = utils.argv_for_commandline(program)
		utils.spawn_in_terminal(prog_argv + pkgs)

	def item_types(self):
		yield Package
		yield TextLeaf

	def get_description(self):
		return _("Install package using the configured method")
	def get_icon_name(self):
		return "document-save"

class Package (Leaf):
	def __init__(self, package, desc):
		Leaf.__init__(self, package, package)
		self.desc = desc

	def get_text_representation(self):
		return self.object
	def get_description(self):
		return self.desc
	def get_icon_name(self):
		return "package-x-generic"

class PackageSearchSource (Source):
	def __init__(self, query):
		self.query = query
		Source.__init__(self, _('Packages matching "%s"') % query)

	def repr_key(self):
		return self.query

	def get_items(self):
		package = kupferstring.tolocale(self.query)
		c_in, c_out_err = os.popen4(['apt-cache', 'search', '--names-only', package])
		try:
			c_in.close()
			acp_out = c_out_err.read()
			for line in kupferstring.fromlocale(acp_out).splitlines():
				if not line.strip():
					continue
				if not " - " in line:
					self.output_error("apt-cache: ", line)
					continue
				package, desc = line.split(" - ", 1)
				yield Package(package, desc)
		finally:
			c_out_err.close()

	def should_sort_lexically(self):
		return True

	def provides(self):
		yield TextLeaf
	def get_icon_name(self):
		return "system-software-install"

class SearchPackageName (Action):
	def __init__(self):
		Action.__init__(self, _("Search Package Name..."))

	def is_factory(self):
		return True

	def activate(self, leaf):
		package = leaf.object.strip()
		return PackageSearchSource(package)

	def item_types(self):
		yield TextLeaf
	def valid_for_item(self, item):
		# check if it is a single word
		text = item.object
		return len(text.split(None, 1)) == 1

	def get_icon_name(self):
		return "system-software-install"


########NEW FILE########
__FILENAME__ = archiveinside
"""
A test project to see if we can make a plugin that allows us to
drill down into compressed archives.

So far we only support .zip and .tar, .tar.gz, .tar.bz2, using Python's
standard library.
"""
__kupfer_name__ = _("Deep Archives")
__kupfer_contents__ = ("ArchiveContent", )
__description__ = _("Allow browsing inside compressed archive files")
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import hashlib
import os
import shutil
import tarfile
import zipfile

from kupfer.objects import Source, FileLeaf
from kupfer.obj.sources import DirectorySource
from kupfer import pretty
from kupfer import scheduler

# Limit this to archives of a couple of megabytes
MAX_ARCHIVE_BYTE_SIZE = 15 * 1024**2

# Wait a year, or until program shutdown for cleaning up
# archive files
VERY_LONG_TIME_S = 3600*24*365


class UnsafeArchiveError (Exception):
	def __init__(self, path):
		Exception.__init__(self, "Refusing to extract unsafe path: %s" % path)

def is_safe_to_unarchive(path):
	"return whether @path is likely a safe path to unarchive"
	npth = os.path.normpath(path)
	return not os.path.isabs(npth) and not npth.startswith(os.path.pardir)


class ArchiveContent (Source):
	extractors = []
	unarchived_files = []
	end_timer = scheduler.Timer(True)

	def __init__(self, fileleaf, unarchive_func):
		Source.__init__(self, _("Content of %s") % fileleaf)
		self.path = fileleaf.object
		self.unarchiver = unarchive_func

	def repr_key(self):
		return self.path

	def get_items(self):
		# always use the same destination for the same file and mtime
		basename = os.path.basename(os.path.normpath(self.path))
		root, ext = os.path.splitext(basename)
		mtime = os.stat(self.path).st_mtime
		fileid = hashlib.sha1("%s%s" % (self.path, mtime)).hexdigest()
		pth = os.path.join("/tmp", "kupfer-%s-%s" % (root, fileid, ))
		if not os.path.exists(pth):
			self.output_debug("Extracting with %s" % (self.unarchiver, ))
			self.unarchiver(self.path, pth)
			self.unarchived_files.append(pth)
			self.end_timer.set(VERY_LONG_TIME_S, self.clean_up_unarchived_files)
		files = list(DirectorySource(pth, show_hidden=True).get_leaves())
		if len(files) == 1 and files[0].has_content():
			return files[0].content_source().get_leaves()
		return files

	def get_description(self):
		return None

	@classmethod
	def decorates_type(cls):
		return FileLeaf

	@classmethod
	def decorate_item(cls, leaf):
		basename = os.path.basename(leaf.object).lower()
		for extractor in cls.extractors:
			if any(basename.endswith(ext) for ext in extractor.extensions):
				if extractor.predicate(leaf.object):
					return cls._source_for_path(leaf, extractor)


	@classmethod
	def _source_for_path(cls, leaf, extractor):
		byte_size = os.stat(leaf.object).st_size
		if byte_size < MAX_ARCHIVE_BYTE_SIZE:
			return cls(leaf, extractor)
		return None

	@classmethod
	def clean_up_unarchived_files(cls):
		if not cls.unarchived_files:
			return
		pretty.print_info(__name__, "Removing extracted archives..")
		for filetree in set(cls.unarchived_files):
			pretty.print_debug(__name__, "Removing", os.path.basename(filetree))
			shutil.rmtree(filetree, onerror=cls._clean_up_error_handler)
		cls.unarchived_files = []


	@classmethod
	def _clean_up_error_handler(cls, func, path, exc_info):
		pretty.print_error(__name__, "Error in %s deleting %s:" % (func, path))
		pretty.print_error(__name__, exc_info)

	@classmethod
	def extractor(cls, extensions, predicate):
		def decorator(func):
			func.extensions = extensions
			func.predicate = predicate
			cls.extractors.append(func)
			return func
		return decorator


@ArchiveContent.extractor((".tar", ".tar.gz", ".tgz", ".tar.bz2"),
		tarfile.is_tarfile)
def extract_tarfile(filepath, destpath):
	zf = tarfile.TarFile.open(filepath, 'r')
	try:
		for member in zf.getnames():
			if not is_safe_to_unarchive(member):
				raise UnsafeArchiveError(member)
		zf.extractall(path=destpath)
	finally:
		zf.close()


# ZipFile only supports extractall since Python 2.6
@ArchiveContent.extractor((".zip", ), zipfile.is_zipfile)
def extract_zipfile(filepath, destpath):
	zf = zipfile.ZipFile(filepath, 'r')
	try:
		for member in zf.namelist():
			if not is_safe_to_unarchive(member):
				raise UnsafeArchiveError(member)
		zf.extractall(path=destpath)
	finally:
		zf.close()

########NEW FILE########
__FILENAME__ = archivemanager
__kupfer_name__ = _("Archive Manager")
__kupfer_sources__ = ()
__kupfer_text_sources__ = ()
__kupfer_actions__ = (
		"UnpackHere",
		"CreateArchive",
		"CreateArchiveIn",
	)
__description__ = _("Use Archive Manager actions")
__version__ = ""
__author__ = "Ulrik"

import os
import re
# since "path" is a very generic name, you often forget..
from os import path as os_path

from kupfer.objects import Action, FileLeaf
from kupfer import utils 
from kupfer import plugin_support
from kupfer import runtimehelper


__kupfer_settings__ = plugin_support.PluginSettings(
	{
		"key" : "archive_type",
		"label": _("Compressed archive type for 'Create Archive In'"),
		"type": str,
		"value": ".tar.gz",
		"alternatives": (
			".7z",
			".rar",
			".tar",
			".tar.gz",
			".tar.bz2",
			".tar.xz",
			".zip",
			)
	},
)

class UnpackHere (Action):
	def __init__(self):
		Action.__init__(self, _("Extract Here"))
		self.extensions_set = set((
			".rar", ".7z", ".zip", ".gz", ".tgz", ".tar", ".lzma", ".bz2",
			".tbz2", ".tzo", ".lzo", ".xz", ".ar", ".cbz", ".Z", ".taz",
			".lz", ".bz", ".tbz", ".lzh",
			))
	def activate(self, leaf):
		utils.spawn_async_notify_as("file-roller.desktop",
				["file-roller", "--extract-here", leaf.object])

	def valid_for_item(self, item):
		tail, ext = os.path.splitext(item.object)
		# FIXME: Make this detection smarter
		# check for standard extension or a multi-part rar extension
		return (ext.lower() in self.extensions_set or
			re.search(r".r\d+$", ext.lower()) is not None)

	def item_types(self):
		yield FileLeaf
	def get_description(self):
		return _("Extract compressed archive")
	def get_icon_name(self):
		return "extract-archive"

class CreateArchive (Action):
	def __init__(self):
		Action.__init__(self, _("Create Archive"))

	@classmethod
	def _make_archive(cls, filepaths):
		cmd = ["file-roller", "--add"]
		cmd.extend(filepaths)
		utils.spawn_async_notify_as("file-roller.desktop", cmd)

	def activate(self, leaf):
		self._make_archive((leaf.object, ))
	def activate_multiple(self, objs):
		self._make_archive([L.object for L in objs])

	def item_types(self):
		yield FileLeaf
	def get_description(self):
		return _("Create a compressed archive from folder")
	def get_icon_name(self):
		return "add-files-to-archive"

class CreateArchiveIn (Action):
	def __init__(self):
		Action.__init__(self, _("Create Archive In..."))

	@classmethod
	def _make_archive(cls, ctx, basename, dirpath, filepaths):
		archive_type = __kupfer_settings__["archive_type"]
		archive_path = \
			utils.get_destpath_in_directory(dirpath, basename, archive_type)
		cmd = ["file-roller", "--add-to=%s" % (archive_path, )]
		cmd.extend(filepaths)
		runtimehelper.register_async_file_result(ctx, archive_path)
		utils.spawn_async_notify_as("file-roller.desktop", cmd)
		return archive_path

	def wants_context(self):
		return True

	def activate(self, leaf, iobj, ctx):
		dirpath = iobj.object
		basename = os_path.basename(leaf.object)
		self._make_archive(ctx, basename, dirpath, (leaf.object, ))

	def activate_multiple(self, objs, iobjs, ctx):
		# TRANS: Default filename (no extension) for 'Create Archive In...'
		basename = _("Archive")
		for iobj in iobjs:
			self._make_archive(ctx, basename, iobj.object,
			                   [L.object for L in objs])

	def item_types(self):
		yield FileLeaf
	def requires_object(self):
		return True
	def object_types(self):
		yield FileLeaf
	def valid_object(self, obj, for_item=None):
		return utils.is_directory_writable(obj.object)
	def get_description(self):
		return _("Create a compressed archive from folder")
	def get_icon_name(self):
		return "add-files-to-archive"


########NEW FILE########
__FILENAME__ = asciiunicodeiconset
# encoding: utf-8
# don't panic! This is just because it's crazy and fun! ãƒ„
__kupfer_name__ = _("Ascii & Unicode Icon Set")
__kupfer_sources__ = ()
__description__ = _("Provides the Ascii and Unicode icon sets that"
                    " use letters and symbols to produce icons for"
                    " the objects found in Kupfer.")
__version__ = ""
__author__ = "Ulrik Sverdrup"

import io
import weakref

import cairo
import gtk

from kupfer import plugin_support

def initialize_plugin(name):
	plugin_support.register_alternative(__name__, 'icon_renderer', 'ascii',
			name=_("Ascii"), renderer=AsciiIconRenderer())
	plugin_support.register_alternative(__name__, 'icon_renderer', 'unicode',
			name=_("Unicode"), renderer=UnicodeIconRenderer())

def text_color():
	"color as triple or None"
	settings = gtk.settings_get_default()
	s = gtk.rc_get_style_by_paths(settings, "kupfer.*", None, None)
	if not s:
		e = gtk.Invisible()
		e.realize()
		s = e.style
	c = s.fg[gtk.STATE_NORMAL]
	return (1.0*c.red/0xffff, 1.0*c.green/0xffff, 1.0*c.blue/0xffff)

class AsciiIconRenderer (object):
	glyph_pixbuf_cache = weakref.WeakValueDictionary()
	def __init__(self):
		settings = gtk.settings_get_default()
		settings.connect("notify::gtk-color-scheme", self._theme_change)

	@classmethod
	def _theme_change(cls, *ignored):
		cls.glyph_pixbuf_cache.clear()

	@classmethod
	def pixbuf_for_name(cls, icon_name, size):
		"""Return pixbuf at @size or None"""
		icon_glyph = ascii_icon_map.get(icon_name)
		if not icon_glyph:
			return None


		pixbuf = cls.glyph_pixbuf_cache.get((icon_glyph, size))
		if not pixbuf:
			pixbuf = get_glyph_pixbuf(icon_glyph, size, False, text_color())

			cls.glyph_pixbuf_cache[(icon_glyph, size)] = pixbuf
		return pixbuf

	@classmethod
	def pixbuf_for_file(cls, file_path, icon_size):
		return None

class UnicodeIconRenderer (object):
	glyph_pixbuf_cache = weakref.WeakValueDictionary()
	def __init__(self):
		settings = gtk.settings_get_default()
		settings.connect("notify::gtk-color-scheme", self._theme_change)

	@classmethod
	def _theme_change(cls, *ignored):
		cls.glyph_pixbuf_cache.clear()

	@classmethod
	def pixbuf_for_name(cls, icon_name, size):
		"""Return pixbuf at @size or None"""
		icon_glyph = unicode_icon_map.get(icon_name)
		if not icon_glyph:
			return None

		pixbuf = cls.glyph_pixbuf_cache.get((icon_glyph, size))
		if not pixbuf:
			pixbuf = get_glyph_pixbuf(icon_glyph, size, False, text_color())
			cls.glyph_pixbuf_cache[(icon_glyph, size)] = pixbuf
		return pixbuf

	@classmethod
	def pixbuf_for_file(cls, file_path, icon_size):
		return None

ascii_icon_map = {
	"kupfer": "k",
	"kupfer-object-multiple": "O",
	"kupfer-object": "O",
	"gtk-execute": "o",
	## filetypes
	"folder-saved-search": u"/",
	"folder": "/",
	"exec": "$",
	"text-x-script": "$",
	"audio-x-generic": u"s",
	"text-x-generic": "a",
	"text-html": "@",
	"image-x-generic": "c",
	"video-x-generic": "v",
	"application-x-executable": "$",
	"application-x-generic": "f",
	#"gnome-mime-application-pdf": "f",
	#"x-office-document": "f",
	## actions
	"document-open-recent": "1",
	"applications-office": "$",
	"applications-internet": "S",
	"edit-select-all": u"\"",
	"forward": u">",
	"go-jump": u">",
	"format-text-bold": u"A",
	"help-contents": u"?",
	"list-add": u"+",
	"list-remove": u"--",
	"preferences-desktop-locale": u"L",
	"help-about": u"?",
	"dialog-information": u"?",
	"application-exit": u"X",
	"window-close": u"X",
	"gnome-window-manager": "]",
	"system-shutdown": u"X",
	"system-lock-screen": u"#",
	"system-log-out": u"[",
	"preferences-desktop": u"&",
	"user-trash-full": u"X",
	"user-home": u"~",
	"emblem-favorite": "*",
	#"document-open-recent": u"\N{WATCH}",
	"key_bindings": u"3",
	"mail-message-new": u"@",
	"edit-copy": "C",
	"edit-paste": "P",
	"edit-clear": "x",
	"edit-undo": "<",
	"view-refresh": "r",
	"drive-removable-media": u"=",
	"media-skip-backward": u"<",
	"media-skip-forward": u">",
	"media-playback-pause": '"',
	"media-playback-start": u">",
	"package-x-generic": u"=",
	"user-info": "p",
	"stock_person": "p",
	## Applications
	"rhythmbox": "R",
	"terminal": "$",
	"banshee": "B",
	"audacious": u"a",
	"totem": "t",
	"vlc": u"V",
	"stellarium": u"*",
	"preferences-desktop-keyboard": "&",
	"preferences-desktop-keyboard-shortcuts": "&",
	"session-properties": "&",
	"utilities-system-monitor": "#",
	"synaptic": "#",
	"gnome-power-manager": u"=",
	"xine": u"x",
	"docky": "d",
	"empathy": u"@",
	"pidgin": u"@",
	"skype": u"@",
	"accessories-calculator": "=",
	"dia": "D",
	"mypaint": "y",
	"liferea": "L",
	"freeciv-client": "C",
	"qbittorrent": "q",
	"gnome-display-properties" : "]",
	"preferences-desktop-screensaver": "]",
	#"Thunar": u"\N{MALE SIGN}",
	"claws-mail": "@",
	"icedove": "@",
	"gajim": "@",
	"iceweasel": "@",
	"firefox": "@",
	"tomboy": "T",
	"gnome-specimen" : "Q",
	"accessories-text-editor": "g",
	"openofficeorg3-writer": "W",
	"openofficeorg3-draw": u"D",
	"openofficeorg3-impress": u"M",
	"openofficeorg3-calc": u"$",
	"libreoffice-writer": "W",
	"libreoffice-draw": u"D",
	"libreoffice-impress": u"M",
	"libreoffice-calc": u"$",
	"abiword_48": "W",
	"abiword": "W",
	"gnumeric": u"$",
	"geany": "g",
	"vim": "v",
	"zim": u"Z",
	"gimp": "G",
	"inkscape": "N",
	"accessories-dictionary": u"A",
	"accessories-character-map": u"z",
	"preferences-desktop-theme": u"&",
	"help-browser": u"?",
	"preferences-desktop-accessibility": u"&",
	"gconf-editor": "&",
	# "ALEMBIC"
	"gwibber": u"@",
}

unicode_icon_map = {
	"kupfer": u"\N{FEMALE SIGN}",
	"gtk-execute": u"\N{GEAR}",
	"folder-saved-search": u"/",
	"exec": u"\N{HAMMER AND PICK}",
	"text-x-script": u"\N{HAMMER AND PICK}",
	"audio-x-generic": u"s",
	"text-x-generic": "a",
	"text-html": "@",
	"image-x-generic": "c",
	"video-x-generic": "v",
	"application-x-executable": u"\N{HAMMER AND PICK}",
	"application-x-generic": "f",

	"applications-office": u"\N{HAMMER AND PICK}",
	"applications-science": u"\N{STAFF OF AESCULAPIUS}",
	"edit-select-all": u"\N{HEAVY DOUBLE TURNED COMMA QUOTATION MARK ORNAMENT}",
	"forward": u"\N{RIGHTWARDS ARROW}",
	"go-jump": u"\N{CLOCKWISE TOP SEMICIRCLE ARROW}",
	"format-text-bold": u"\N{MATHEMATICAL DOUBLE-STRUCK CAPITAL A}",
	"help-contents": u"\N{DOUBLE QUESTION MARK}",
	"list-add": u"+",
	"list-remove": u"\N{MINUS SIGN}",
	"preferences-desktop-locale": u"\N{WHITE FLAG}",
	"test" : u"\N{RADIOACTIVE SIGN}",
	"audio-x-generic": u"\N{EIGHTH NOTE}",
	"help-about": u"\N{INFORMATION SOURCE}",
	"dialog-information": u"\N{INFORMATION SOURCE}",
	"dialog-error": u"\N{WARNING SIGN}",
	"application-exit": u"\N{SKULL AND CROSSBONES}",
	"window-close": u"\N{SKULL AND CROSSBONES}",
	"system-shutdown": u"\N{SKULL AND CROSSBONES}",
	"system-log-out": u"\N{LEFTWARDS ARROW}",
	"system-lock-screen": u"\N{CHIRON}",
	#"system-log-out": u"\N{APL FUNCTIONAL SYMBOL QUAD LEFTWARDS ARROW}",
	"preferences-desktop": u"\N{BALLOT BOX WITH CHECK}",
	"user-trash-full": u"\N{BLACK UNIVERSAL RECYCLING SYMBOL}",
	"user-trash": u"\N{UNIVERSAL RECYCLING SYMBOL}",
	"user-home": u"\N{TILDE OPERATOR}",
	#"emblem-favorite": u"\N{BLACK STAR}",
	"emblem-favorite": u"\N{HEAVY BLACK HEART}",
	"kupfer-object-multiple": u"\N{DOTTED SQUARE}",
	"kupfer-object": u"\N{DOTTED SQUARE}",
	"document-open-recent": u"\N{WATCH}",
	"key_bindings": u"\N{KEYBOARD}",
	"mail-message-new": u"\N{ENVELOPE}",
	"edit-copy": u"\N{BLACK SCISSORS}",
	"edit-undo": u"\N{UNDO SYMBOL}",
	"view-refresh": u"\N{CLOCKWISE OPEN CIRCLE ARROW}",
	"folder": u"\N{STRICTLY EQUIVALENT TO}",
	"drive-removable-media": u"\N{TAPE DRIVE}",
	"media-optical": u"\N{TAPE DRIVE}",
	# ok these are stretching it..
	"media-skip-backward": u"\N{LEFT-POINTING DOUBLE ANGLE QUOTATION MARK}",
	"media-skip-forward": u"\N{RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK}",
	"media-playback-pause": u"\N{MIDDLE DOT}",
	"media-playback-start": u"\N{TRIANGULAR BULLET}",
	"package-x-generic": u"\N{WHITE DRAUGHTS KING}",
	## Applications
	"user-info": u"\N{BLACK CHESS PAWN}",
	"stock_person": u"\N{BLACK CHESS PAWN}",
	"rhythmbox": u"\N{BEAMED EIGHTH NOTES}",
	"banshee": u"\N{BEAMED EIGHTH NOTES}",
	"audacious": u"\N{BEAMED EIGHTH NOTES}",
	"totem": u"\N{BEAMED EIGHTH NOTES}",
	"vlc": u"\N{BEAMED EIGHTH NOTES}",
	"stellarium": u"\N{ASTERISM}",
	"preferences-desktop-keyboard": u"\N{KEYBOARD}",
	"preferences-desktop-keyboard-shortcuts": u"\N{KEYBOARD}",
	"utilities-system-monitor": u"\N{ATOM SYMBOL}",
	"gnome-power-manager": u"\N{HIGH VOLTAGE SIGN}",
	"freeciv-client": u"\N{CROSSED SWORDS}",
	"xboard": u"\N{BLACK CHESS ROOK}",
	"application-games": u"\N{BLACK CHESS ROOK}",
	"empathy": u"\N{WHITE SMILING FACE}",
	"pidgin": u"\N{WHITE SMILING FACE}",
	"skype": u"\N{BLACK TELEPHONE}",
	"Thunar": u"\N{MALE SIGN}",
	"claws-mail": u"\N{ENVELOPE}",
	"icedove": u"\N{ENVELOPE}",
	"accessories-text-editor": u"\N{WRITING HAND}",
	"openofficeorg3-writer": u"\N{WRITING HAND}",
	"libreoffice-writer": u"\N{WRITING HAND}",
	"geany": u"\N{WRITING HAND}",
	"zim": u"\N{WRITING HAND}",
	"gimp": u"\N{PENCIL}",
	"openofficeorg3-draw": u"\N{PENCIL}",
	"libreoffice-draw": u"\N{PENCIL}",
	"openofficeorg3-calc": u"\N{GREEK CAPITAL LETTER SIGMA}",
	"libreoffice-calc": u"\N{GREEK CAPITAL LETTER SIGMA}",
	"accessories-calculator": u"\N{GREEK CAPITAL LETTER SIGMA}",
	"abiword_48": u"\N{WRITING HAND}",
	"abiword": u"\N{WRITING HAND}",
	"accessories-dictionary": u"\N{MATHEMATICAL DOUBLE-STRUCK CAPITAL A}",
	"accessories-character-map": u"Ã¡",
	"preferences-desktop-theme": u"\N{EIGHT PETALLED OUTLINED BLACK FLORETTE}",
	"help-browser": u"?",
	"preferences-desktop-accessibility": u"\N{WHEELCHAIR SYMBOL}",
	#"ALEMBIC"
	"vim": u"\N{MATHEMATICAL DOUBLE-STRUCK CAPITAL V}",
	"gvim": u"\N{MATHEMATICAL DOUBLE-STRUCK CAPITAL V}",
	"gnome-volume-control": u"\N{EIGHTH NOTE}",
	"gnumeric": u"\N{GREEK CAPITAL LETTER SIGMA}",
	#"gwibber": u"\N{FACSIMILE SIGN}",
	"gwibber": u"\N{ENVELOPE}",

	### marker
	"default": u"O",
}

def get_glyph_pixbuf(text, sz, center_vert=True, color=None):
	"""Return pixbuf for @text

	if @center_vert, then center completely vertically
	"""
	margin = sz * 0.1
	ims = cairo.ImageSurface(cairo.FORMAT_ARGB32, sz, sz)
	cc = cairo.Context(ims)

	cc.move_to(margin, sz-margin)
	cc.set_font_size(sz)
	if color is None:
		cc.set_source_rgba(0,0,0,1)
	else:
		cc.set_source_rgb(*color)

	cc.text_path(text)
	x1, y1, x2, y2 =cc.path_extents()
	skew_horiz = ((sz-x2) - (x1))/2.0
	skew_vert = ((sz-y2) - (y1))/2.0
	if not center_vert:
		skew_vert = skew_vert*0.2 - margin*0.5
	cc.new_path()
	cc.move_to(margin+skew_horiz, sz-margin+skew_vert)
	cc.text_path(text)
	cc.fill()

	ims.flush()
	f = io.BytesIO()
	ims.write_to_png(f)

	loader = gtk.gdk.PixbufLoader()
	loader.write(f.getvalue())
	loader.close()

	return loader.get_pixbuf()

########NEW FILE########
__FILENAME__ = audacious
__kupfer_name__ = _("Audacious")
__kupfer_sources__ = ("AudaciousSource", )
__description__ = _("Control Audacious playback and playlist")
__version__ = "2009-12-15"
__author__ = "Horia V. Corcalciuc <h.v.corcalciuc@gmail.com>"

import subprocess

from kupfer.objects import Leaf, Source, Action
from kupfer.objects import RunnableLeaf, SourceLeaf
from kupfer.obj.apps import AppLeafContentMixin
from kupfer import icons, utils
from kupfer import plugin_support
from kupfer import kupferstring


__kupfer_settings__ = plugin_support.PluginSettings(
	{
		"key": "playlist_toplevel",
		"label": _("Include songs in top level"),
		"type": bool,
		"value": True,
	},
)

AUDTOOL = "audtool"
AUDACIOUS = "audacious"

def enqueue_song(info):
	utils.spawn_async((AUDTOOL, "playqueue-add", "%d" % info))

def dequeue_song(info):
	utils.spawn_async((AUDTOOL, "playqueue-remove", "%d" % info))

def play_song(info):
	utils.spawn_async((AUDTOOL, "playlist-jump", "%d" % info))
	utils.spawn_async((AUDTOOL, "playback-play"))

def get_playlist_songs():
	"""Yield tuples of (position, name) for playlist songs"""
	toolProc = subprocess.Popen([AUDTOOL, "playlist-display"],
			stdout=subprocess.PIPE)
	stdout, stderr = toolProc.communicate()
	for line in stdout.splitlines():
		if not line.count('|') >= 2:
			continue
		position, rest = line.split('|', 1)
		songname, rest = rest.rsplit('|', 1)
		pos = int(position.strip())
		nam = kupferstring.fromlocale(songname.strip())
		yield (pos, nam)

def clear_queue():
	utils.spawn_async((AUDTOOL, "playqueue-clear"))

class Enqueue (Action):
	def __init__(self):
		Action.__init__(self, _("Enqueue"))
	def activate(self, leaf):
		enqueue_song(leaf.object)
	def get_description(self):
		return _("Add track to the Audacious play queue")
	def get_gicon(self):
		return icons.ComposedIcon("gtk-execute", "media-playback-start")
	def get_icon_name(self):
		return "media-playback-start"

class Dequeue (Action):
	def __init__(self):
		Action.__init__(self, _("Dequeue"))
	def activate(self, leaf):
		dequeue_song(leaf.object)
	def get_description(self):
		return _("Remove track from the Audacious play queue")
	def get_gicon(self):
		return icons.ComposedIcon("gtk-execute", "media-playback-stop")
	def get_icon_name(self):
		return "media-playback-stop"

class JumpToSong(Action):
	def __init__(self):
		Action.__init__(self, _("Play"))
	def activate(self, leaf):
		play_song(leaf.object)
	def get_description(self):
		return _("Jump to track in Audacious")
	def get_icon_name(self):
		return "media-playback-start"

class Play (RunnableLeaf):
	def __init__(self):
		RunnableLeaf.__init__(self, name=_("Play"))
	def run(self):
		utils.spawn_async((AUDTOOL, "playback-play"))
	def get_description(self):
		return _("Resume playback in Audacious")
	def get_icon_name(self):
		return "media-playback-start"

class Pause (RunnableLeaf):
	def __init__(self):
		RunnableLeaf.__init__(self, name=_("Pause"))
	def run(self):
		utils.spawn_async((AUDTOOL, "playback-pause"))
	def get_description(self):
		return _("Pause playback in Audacious")
	def get_icon_name(self):
		return "media-playback-pause"

class Next (RunnableLeaf):
	def __init__(self):
		RunnableLeaf.__init__(self, name=_("Next"))
	def run(self):
		utils.spawn_async((AUDTOOL, "playlist-advance"))
	def get_description(self):
		return _("Jump to next track in Audacious")
	def get_icon_name(self):
		return "media-skip-forward"

class Previous (RunnableLeaf):
	def __init__(self):
		RunnableLeaf.__init__(self, name=_("Previous"))
	def run(self):
		utils.spawn_async((AUDTOOL, "playlist-reverse"))
	def get_description(self):
		return _("Jump to previous track in Audacious")
	def get_icon_name(self):
		return "media-skip-backward"

class ClearQueue (RunnableLeaf):
	def __init__(self):
		RunnableLeaf.__init__(self, name=_("Clear Queue"))
	def run(self):
		clear_queue()
	def get_description(self):
		return _("Clear the Audacious play queue")
	def get_icon_name(self):
		return "edit-clear"
		
class Shuffle (RunnableLeaf):
	def __init__(self):
		RunnableLeaf.__init__(self, name=_("Shuffle"))
	def run(self):
		utils.spawn_async((AUDTOOL, "playlist-shuffle-toggle"))
	def get_description(self):
		return _("Toggle shuffle in Audacious")
	def get_icon_name(self):
		return "media-playlist-shuffle"

class Repeat (RunnableLeaf):
	def __init__(self):
		RunnableLeaf.__init__(self, name=_("Repeat"))
	def run(self):
		utils.spawn_async((AUDTOOL, "playlist-repeat-toggle"))
	def get_description(self):
		return _("Toggle repeat in Audacious")
	def get_icon_name(self):
		return "media-playlist-repeat"

class SongLeaf (Leaf):
	"""The SongLeaf's represented object is the Playlist index"""
	def get_actions(self):
		yield JumpToSong()
		yield Enqueue()
		yield Dequeue()
	def get_icon_name(self):
		return "audio-x-generic"

class AudaciousSongsSource (Source):
	def __init__(self, library):
		Source.__init__(self, _("Playlist"))
		self.library = library
	def get_items(self):
		for song in self.library:
			yield SongLeaf(*song)
	def get_gicon(self):
		return icons.ComposedIcon(AUDACIOUS, "audio-x-generic",
			emblem_is_fallback=True)
	def provides(self):
		yield SongLeaf

class AudaciousSource (AppLeafContentMixin, Source):
	appleaf_content_id = AUDACIOUS
	source_user_reloadable = True

	def __init__(self):
		Source.__init__(self, _("Audacious"))
	def get_items(self):
		yield Play()
		yield Pause()
		yield Next()
		yield Previous() 
		yield ClearQueue()
		# Commented as these seem to have no effect
		#yield Shuffle()
		#yield Repeat()
		songs = list(get_playlist_songs())
		songs_source = AudaciousSongsSource(songs)
		yield SourceLeaf(songs_source)
		if __kupfer_settings__["playlist_toplevel"]:
			for leaf in songs_source.get_leaves():
				yield leaf
	def get_description(self):
		return __description__
	def get_icon_name(self):
		return AUDACIOUS
	def provides(self):
		yield RunnableLeaf

########NEW FILE########
__FILENAME__ = calculator
from __future__ import division
__kupfer_name__ = _("Calculator")
__kupfer_actions__ = ("Calculate", "CalculateOtherExpressions")
__description__ = _("Calculate mathematical expressions")
__version__ = "2012-06-10"
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

"""
Changes:
	2012-06-09:
		+ calculate action for expression w/o =
	2012-06-10:
		+ separate Calculate action
		+ change localized decimal point symbol to .
"""

import locale
import cmath
import math

from kupfer.objects import Action, TextLeaf
from kupfer import pretty


class IgnoreResultException (Exception):
	pass


class KupferSurprise (float):
	"""kupfer

	cleverness to the inf**inf
	"""
	def __call__(self, *args):
		from kupfer import utils, version
		utils.show_url(version.WEBSITE)
		raise IgnoreResultException


class DummyResult (object):
	def __unicode__(self):
		return u"<Result of last expression>"


class Help (object):
	"""help()

	Show help about the calculator
	"""
	def __call__(self):
		import textwrap

		from kupfer import uiutils

		environment = make_environment(last_result=DummyResult())
		docstrings = []
		for attr in sorted(environment):
			if attr != "_" and attr.startswith("_"):
				continue
			val = environment[attr]
			if not callable(val):
				docstrings.append(u"%s = %s" % (attr, val))
				continue
			try:
				docstrings.append(val.__doc__)
			except AttributeError:
				pass
		formatted = []
		maxlen = 72
		left_margin = 4
		for docstr in docstrings:
			# Wrap the description and align continued lines
			docsplit = docstr.split("\n", 1)
			if len(docsplit) < 2:
				formatted.append(docstr)
				continue
			wrapped_lines = textwrap.wrap(docsplit[1].strip(),
					maxlen - left_margin)
			wrapped = (u"\n" + u" " * left_margin).join(wrapped_lines)
			formatted.append("%s\n    %s" % (docsplit[0], wrapped))
		uiutils.show_text_result("\n\n".join(formatted), _("Calculator"))
		raise IgnoreResultException

	def __complex__(self):
		return self()


def make_environment(last_result=None):
	"Return a namespace for the calculator's expressions to be executed in."
	environment = dict(vars(math))
	environment.update(vars(cmath))
	# define some constants missing
	if last_result is not None:
		environment["_"] = last_result
	environment["help"] = Help()
	environment["kupfer"] = KupferSurprise("inf")
	# make the builtins inaccessible
	environment["__builtins__"] = {}
	return environment


def format_result(res):
	cres = complex(res)
	parts = []
	if cres.real:
		parts.append(u"%s" % cres.real)
	if cres.imag:
		parts.append(u"%s" % complex(0, cres.imag))
	return u"+".join(parts) or u"%s" % res


class Calculate (Action):
	# since it applies only to special queries, we can up the rank
	rank_adjust = 10
	# global last_result
	last_result = {'last': None}

	def __init__(self):
		Action.__init__(self, _("Calculate"))

	def has_result(self):
		return True

	def activate(self, leaf):
		expr = leaf.object.lstrip("= ")

		# try to add missing parantheses
		brackets_missing = expr.count("(") - expr.count(")")
		if brackets_missing > 0:
			expr += ")" * brackets_missing
		# hack: change all decimal points (according to current locale) to '.'
		expr = expr.replace(locale.localeconv()['decimal_point'], '.')
		environment = make_environment(self.last_result['last'])
		pretty.print_debug(__name__, "Evaluating", repr(expr))
		try:
			result = eval(expr, environment)
			resultstr = format_result(result)
			self.last_result['last'] = result
		except IgnoreResultException:
			return
		except Exception, exc:
			pretty.print_error(__name__, type(exc).__name__, exc)
			resultstr = unicode(exc)
		return TextLeaf(resultstr)

	def item_types(self):
		yield TextLeaf

	def valid_for_item(self, leaf):
		text = leaf.object
		return text and text.startswith("=")

	def get_description(self):
		return None


class CalculateOtherExpressions(Calculate):
	""" Calcualte expressions that not starts with "=" """
	rank_adjust = 0

	def valid_for_item(self, leaf):
		text = leaf.object
		return text and not text.startswith("=") and (
				"+" in text or
				"-" in text or
				"*" in text or
				"/" in text or
				"^" in text or
				"&" in text or
				"|" in text or
				"~" in text)

########NEW FILE########
__FILENAME__ = chromium
__kupfer_name__ = _("Chromium Bookmarks")
__kupfer_sources__ = ("BookmarksSource", )
__description__ = _("Index of Chromium bookmarks")
__version__ = ""
__author__ = "Francesco Marella <francesco.marella@gmail.com>"

from kupfer.objects import Source
from kupfer.objects import UrlLeaf
from kupfer import config
from kupfer.obj.apps import AppLeafContentMixin


class BookmarksSource (AppLeafContentMixin, Source):
	appleaf_content_id = ("chromium-browser")
	def __init__(self):
		super(BookmarksSource, self).__init__(_("Chromium Bookmarks"))

	def _get_chromium_items(self, fpath):
		"""Parse Chromium' bookmarks backups"""
		from kupfer.plugin import chromium_support
		self.output_debug("Parsing", fpath)
		bookmarks = chromium_support.get_bookmarks(fpath)
		for book in bookmarks:
			yield UrlLeaf(book["url"], book["name"])

	def get_items(self):
		fpath = config.get_config_file("Bookmarks", package="chromium/Default")

		# If there is no chromium bookmarks file, look for a google-chrome one
		if not fpath:
			fpath = config.get_config_file("Bookmarks",package="google-chrome/Default")

		if fpath:
			try:
				return self._get_chromium_items(fpath)
			except Exception, exc:
				self.output_error(exc)

		self.output_error("No Chromium bookmarks file found")
		return []

	def get_description(self):
		return _("Index of Chromium bookmarks")
	def get_icon_name(self):
		return "chromium-browser"
	def provides(self):
		yield UrlLeaf

########NEW FILE########
__FILENAME__ = chromium_support
# -*- coding: UTF-8 -*-

from __future__ import with_statement

import os

try:
	import cjson
	json_decoder = cjson.decode
except ImportError:
	import json
	json_decoder = json.loads

def get_bookmarks(bookmarks_file):
	# construct and configure the parser
	if not bookmarks_file:
		return []

	with open(bookmarks_file) as f:
		content = f.read().decode("UTF-8")
		root = json_decoder(content)

	# make a dictionary of unique bookmarks
	bmap = {}

	def bmap_add(bmark, bmap):
		if bmark["id"] not in bmap:
			bmap[bmark["id"]] = bmark

	CONTAINER = "folder"
	UNWANTED_SCHEME = ("data", "place", "javascript")

	def is_container(ch):
		return ch["type"] == CONTAINER
	def is_bookmark(ch):
		return ch.get("url")
	def is_good(ch):
		return not ch["url"].split(":", 1)[0] in UNWANTED_SCHEME

	folders = []

	# add some folders
	folders.extend(root['roots']['bookmark_bar']['children'])
	folders.extend(root['roots']['other']['children'])

	for item in folders:
		if is_bookmark(item) and is_good(item):
			bmap_add(item, bmap)
		if is_container(item):
			folders.extend(item["children"])

	return bmap.values()

if __name__ == "__main__":
	fpath = os.path.expanduser("~/.config/chromium/Default/")
	print "Parsed # bookmarks:", len(list(get_bookmarks(fpath)))

########NEW FILE########
__FILENAME__ = clawsmail
# -*- coding: UTF-8 -*-
__kupfer_name__ = _("Claws Mail")
__kupfer_sources__ = ("ClawsContactsSource", )
__kupfer_actions__ = ("NewMailAction", "SendFileByMail")
__description__ = _("Claws Mail Contacts and Actions")
__version__ = "2010-05-19"
__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"

import os
from xml.dom import minidom
import xml

from kupfer.objects import Action
from kupfer.objects import TextLeaf, UrlLeaf, RunnableLeaf, FileLeaf
from kupfer import utils
from kupfer.obj.apps import AppLeafContentMixin
from kupfer.obj.helplib import FilesystemWatchMixin
from kupfer.obj.grouping import ToplevelGroupingSource
from kupfer.obj.contacts import ContactLeaf, EmailContact, email_from_leaf



class ComposeMail(RunnableLeaf):
	''' Create new mail without recipient '''
	def __init__(self):
		RunnableLeaf.__init__(self, name=_("Compose New Email"))

	def run(self):
		utils.spawn_async(['claws-mail','--compose'])

	def get_description(self):
		return _("Compose a new message in Claws Mail")

	def get_icon_name(self):
		return "mail-message-new"


class ReceiveMail(RunnableLeaf):
	''' Receive all new mail from all accounts '''
	def __init__(self):
		RunnableLeaf.__init__(self, name=_("Receive All Email"))

	def run(self):
		utils.spawn_async(['claws-mail', '--receive-all'])

	def get_description(self):
		return _("Receive new messages from all accounts in ClawsMail")

	def get_icon_name(self):
		return "mail-send-receive"


class NewMailAction(Action):
	''' Create new mail to selected leaf'''
	def __init__(self):
		Action.__init__(self, _('Compose Email'))

	def activate(self, leaf):
		self.activate_multiple((leaf, ))

	def activate_multiple(self, objects):
		recipients = ",".join(email_from_leaf(L) for L in objects)
		utils.spawn_async(["claws-mail", "--compose", recipients])

	def get_icon_name(self):
		return "mail-message-new"

	def item_types(self):
		yield ContactLeaf
		# we can enter email
		yield TextLeaf
		yield UrlLeaf

	def valid_for_item(self, item):
		return bool(email_from_leaf(item))


class SendFileByMail (Action):
	'''Create new e-mail and attach selected file'''
	def __init__(self):
		Action.__init__(self, _('Send in Email To...'))

	def activate(self, obj, iobj):
		self.activate_multiple((obj, ), (iobj, ))

	def activate_multiple(self, objects, iobjects):
		recipients = ",".join(email_from_leaf(I) for I in iobjects)
		attachlist = ["--attach"] + [L.object for L in objects]
		utils.spawn_async(["claws-mail", "--compose", recipients] + attachlist)

	def item_types(self):
		yield FileLeaf
	def valid_for_item(self, item):
		return not item.is_dir()

	def requires_object(self):
		return True
	def object_types(self):
		yield ContactLeaf
		# we can enter email
		yield TextLeaf
		yield UrlLeaf
	def valid_object(self, iobj, for_item=None):
		return bool(email_from_leaf(iobj))

	def get_description(self):
		return _("Compose new message in Claws Mail and attach file")
	def get_icon_name(self):
		return "document-send"


class ClawsContactsSource(AppLeafContentMixin, ToplevelGroupingSource,
		FilesystemWatchMixin):
	appleaf_content_id = 'claws-mail'

	def __init__(self, name=_("Claws Mail Address Book")):
		super(ClawsContactsSource, self).__init__(name, "Contacts")
		#Source.__init__(self, name)
		self._claws_addrbook_dir = os.path.expanduser('~/.claws-mail/addrbook')
		self._claws_addrbook_index = os.path.join(self._claws_addrbook_dir, \
				"addrbook--index.xml")
		self._version = 4

	def initialize(self):
		ToplevelGroupingSource.initialize(self)
		if not os.path.isdir(self._claws_addrbook_dir):
			return

		self.monitor_token = self.monitor_directories(self._claws_addrbook_dir)

	def monitor_include_file(self, gfile):
		# monitor only addrbook-*.xml files
		return gfile and gfile.get_basename().endswith('.xml') and \
				gfile.get_basename().startswith("addrbook-")

	def get_items(self):
		if os.path.isfile(self._claws_addrbook_index):
			for addrbook_file in self._load_address_books():
				addrbook_filepath = os.path.join(self._claws_addrbook_dir, addrbook_file)
				if not os.path.exists(addrbook_filepath):
					continue

				try:
					dtree = minidom.parse(addrbook_filepath)
					persons = dtree.getElementsByTagName('person')
					for person in persons:
						cn = person.getAttribute('cn')
						addresses = person.getElementsByTagName('address')
						for address in addresses:
							email = address.getAttribute('email')
							yield EmailContact(email, cn)
				except (StandardError, xml.parsers.expat.ExpatError), err:
					self.output_error(err)

		yield ComposeMail()
		yield ReceiveMail()

	def should_sort_lexically(self):
		# since it is a grouping source, grouping and non-grouping will be
		# separate and only grouping leaves will be sorted
		return True

	def get_description(self):
		return _("Contacts from Claws Mail Address Book")

	def get_icon_name(self):
		return "claws-mail"

	def provides(self):
		yield RunnableLeaf
		yield ContactLeaf

	def _load_address_books(self):
		''' load list of address-book files '''
		try:
			dtree = minidom.parse(self._claws_addrbook_index)
			for book in dtree.getElementsByTagName('book'):
				yield book.getAttribute('file')
		except (StandardError, xml.parsers.expat.ExpatError), err:
			self.output_error(err)




########NEW FILE########
__FILENAME__ = clipboard
__kupfer_name__ = _("Clipboards")
__kupfer_sources__ = ("ClipboardSource", )
__kupfer_actions__ = ("ClearClipboards", )
__description__ = _("Recent clipboards and clipboard proxy objects")
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

from collections import deque

import gio
import gtk

from kupfer.objects import Source, TextLeaf, Action, SourceLeaf
from kupfer.objects import FileLeaf
from kupfer.obj.compose import MultipleLeaf
from kupfer import plugin_support
from kupfer.weaklib import gobject_connect_weakly
from kupfer import kupferstring


__kupfer_settings__ = plugin_support.PluginSettings(
	{
		"key" : "max",
		"label": _("Number of recent clipboards to remember"),
		"type": int,
		"value": 10,
	},
	{
		"key" : "use_selection",
		"label": _("Include selected text in clipboard history"),
		"type": bool,
		"value": False,
	},
	{
		"key" : "sync_selection",
		"label": _("Copy selected text to primary clipboard"),
		"type": bool,
		"value": False,
	},
)

URI_TARGET="text/uri-list"

class SelectedText (TextLeaf):
	qf_id = "selectedtext"
	def __init__(self, text):
		TextLeaf.__init__(self, text, _('Selected Text'))

	def __repr__(self):
		return "<%s %s>" % (__name__, self.qf_id)

class ClipboardText (TextLeaf):
	def get_description(self):
		numlines = self.object.count("\n") + 1
		desc = self.get_first_text_line(self.object)

		return ngettext('Clipboard "%(desc)s"',
			'Clipboard with %(num)d lines "%(desc)s"',
			numlines) % {"num": numlines, "desc": desc }

class CurrentClipboardText (ClipboardText):
	qf_id = "clipboardtext"
	def __init__(self, text):
		ClipboardText.__init__(self, text, _('Clipboard Text'))

	def __repr__(self):
		return "<%s %s>" % (__name__, self.qf_id)

class CurrentClipboardFile (FileLeaf):
	"represents the *unique* current clipboard file"
	qf_id = "clipboardfile"
	def __init__(self, filepath):
		"""@filepath is a filesystem byte string `str`"""
		FileLeaf.__init__(self, filepath, _('Clipboard File'))

	def __repr__(self):
		return "<%s %s>" % (__name__, self.qf_id)

class CurrentClipboardFiles (MultipleLeaf):
	"represents the *unique* current clipboard if there are many files"
	qf_id = "clipboardfile"
	def __init__(self, paths):
		files = [FileLeaf(path) for path in paths]
		MultipleLeaf.__init__(self, files, _("Clipboard Files"))

	def __repr__(self):
		return "<%s %s>" % (__name__, self.qf_id)


class ClearClipboards(Action):
	def __init__(self):
		Action.__init__(self, _("Clear"))

	def activate(self, leaf):
		leaf.object.clear()

	def item_types(self):
		yield SourceLeaf

	def valid_for_item(self, leaf):
		return isinstance(leaf.object, ClipboardSource)

	def get_description(self):
		return _("Remove all recent clipboards")

	def get_icon_name(self):
		return "edit-clear"


class ClipboardSource (Source):
	def __init__(self):
		Source.__init__(self, _("Clipboards"))
		self.clipboards = deque()

	def initialize(self):
		clip = gtk.clipboard_get(gtk.gdk.SELECTION_CLIPBOARD)
		gobject_connect_weakly(clip, "owner-change", self._clipboard_changed)
		clip = gtk.clipboard_get(gtk.gdk.SELECTION_PRIMARY)
		gobject_connect_weakly(clip, "owner-change", self._clipboard_changed)
		self.clipboard_uris = []
		self.clipboard_text = None
		self.selected_text = None

	def finalize(self):
		self.clipboard_uris = []
		self.clipboard_text = None
		self.selected_text = None
		self.mark_for_update()

	def _clipboard_changed(self, clip, event, *args):
		is_selection = (event.selection == gtk.gdk.SELECTION_PRIMARY)

		max_len = __kupfer_settings__["max"]
		# receive clipboard as gtk text
		newtext = kupferstring.tounicode(clip.wait_for_text())

		is_valid = bool(newtext and newtext.strip())
		is_sync_selection = (is_selection and
		                     __kupfer_settings__["sync_selection"])

		if not is_selection or __kupfer_settings__["use_selection"]:
			if is_valid:
				self._add_to_history(newtext, is_selection)

		if is_sync_selection and is_valid:
			gtk.clipboard_get(gtk.gdk.SELECTION_CLIPBOARD).set_text(newtext)

		if is_selection:
			self.selected_text = newtext
		if not is_selection or is_sync_selection:
			self.clipboard_text = newtext
			if clip.wait_is_target_available(URI_TARGET):
				sdata = clip.wait_for_contents(URI_TARGET)
				self.clipboard_uris = list(sdata.get_uris())
			else:
				self.clipboard_uris = []
		self._prune_to_length(max_len)
		self.mark_for_update()

	def _add_to_history(self, cliptext, is_selection):
		if cliptext in self.clipboards:
			self.clipboards.remove(cliptext)
		# if the previous text is a prefix of the new selection, supercede it
		if (is_selection and self.clipboards
				and (cliptext.startswith(self.clipboards[-1])
				or cliptext.endswith(self.clipboards[-1]))):
			self.clipboards.pop()
		self.clipboards.append(cliptext)

	def _prune_to_length(self, max_len):
		while len(self.clipboards) > max_len:
			self.clipboards.popleft()

	def get_items(self):
		# selected text
		if self.selected_text:
			yield SelectedText(self.selected_text)

		# produce the current clipboard files if any
		paths = filter(None, 
		        [gio.File(uri=uri).get_path() for uri in self.clipboard_uris])
		if len(paths) == 1:
			yield CurrentClipboardFile(paths[0])
		if len(paths) > 1:
			yield CurrentClipboardFiles(paths)

		# put out the current clipboard text
		if self.clipboard_text:
			yield CurrentClipboardText(self.clipboard_text)
		# put out the clipboard history
		for t in reversed(self.clipboards):
			yield ClipboardText(t)

	def get_description(self):
		return __description__

	def get_icon_name(self):
		return "edit-paste"

	def provides(self):
		yield TextLeaf
		yield FileLeaf
		yield MultipleLeaf

	def clear(self):
		self.clipboards.clear()
		self.mark_for_update()

########NEW FILE########
__FILENAME__ = commands
__kupfer_name__ = _("Shell Commands")
__kupfer_sources__ = ()
__kupfer_actions__ = (
		"PassToCommand",
		"FilterThroughCommand",
		"WriteToCommand",
	)
__kupfer_text_sources__ = ("CommandTextSource",)
__description__ = _(u"Run command-line programs. Actions marked with"
                    u" the symbol %s run in a subshell.") % u"\N{GEAR}"
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import os

import gobject

from kupfer.objects import TextSource, TextLeaf, Action, FileLeaf
from kupfer.objects import OperationError
from kupfer.obj.fileactions import Execute
from kupfer import utils, icons
from kupfer import kupferstring
from kupfer import pretty

def finish_command(ctx, acommand, stdout, stderr, post_result=True):
	"""Show async error if @acommand returns error output & error status.
	Else post async result if @post_result.
	"""
	max_error_msg=512
	pretty.print_debug(__name__, "Exited:", acommand)
	if acommand.exit_status != 0 and not stdout and stderr:
		errstr = kupferstring.fromlocale(stderr)[:max_error_msg]
		ctx.register_late_error(OperationError(errstr))
	elif post_result:
		leaf = TextLeaf(kupferstring.fromlocale(stdout))
		ctx.register_late_result(leaf)


class GetOutput (Action):
	def __init__(self):
		Action.__init__(self, _("Run (Get Output)"))

	def wants_context(self):
		return True

	def activate(self, leaf, ctx):
		if isinstance(leaf, Command):
			argv = ['sh', '-c', leaf.object, '--']
		else:
			argv = [leaf.object]

		def finish_callback(acommand, stdout, stderr):
			finish_command(ctx, acommand, stdout, stderr)

		pretty.print_debug(__name__, "Spawning with timeout 15 seconds")
		utils.AsyncCommand(argv, finish_callback, 15)

	def get_description(self):
		return _("Run program and return its output") + u" \N{GEAR}"

class PassToCommand (Action):
	def __init__(self):
		# TRANS: The user starts a program (command) and the text
		# TRANS: is an argument to the command
		Action.__init__(self, _("Pass to Command..."))

	def wants_context(self):
		return True

	def activate(self, leaf, iobj, ctx):
		self.activate_multiple((leaf,),(iobj, ), ctx)

	def _run_command(self, objs, iobj, ctx):
		if isinstance(iobj, Command):
			argv = ['sh', '-c', iobj.object + ' "$@"', '--']
		else:
			argv = [iobj.object]

		def finish_callback(acommand, stdout, stderr):
			finish_command(ctx, acommand, stdout, stderr, False)

		argv.extend([o.object for o in objs])
		pretty.print_debug(__name__, "Spawning without timeout")
		utils.AsyncCommand(argv, finish_callback, None)

	def activate_multiple(self, objs, iobjs, ctx):
		for iobj in iobjs:
			self._run_command(objs, iobj, ctx)

	def item_types(self):
		yield TextLeaf
		yield FileLeaf

	def requires_object(self):
		return True

	def object_types(self):
		yield FileLeaf
		yield Command

	def valid_object(self, iobj, for_item=None):
		if isinstance(iobj, Command):
			return True
		return not iobj.is_dir() and os.access(iobj.object, os.X_OK | os.R_OK)

	def get_description(self):
		return _("Run program with object as an additional parameter") + \
		        u" \N{GEAR}"


class WriteToCommand (Action):
	def __init__(self):
		# TRANS: The user starts a program (command) and
		# TRANS: the text is written on stdin
		Action.__init__(self, _("Write to Command..."))
		self.post_result = False

	def wants_context(self):
		return True

	def activate(self, leaf, iobj, ctx):
		if isinstance(iobj, Command):
			argv = ['sh', '-c', iobj.object]
		else:
			argv = [iobj.object]

		def finish_callback(acommand, stdout, stderr):
			finish_command(ctx, acommand, stdout, stderr, self.post_result)

		pretty.print_debug(__name__, "Spawning without timeout")
		utils.AsyncCommand(argv, finish_callback, None, stdin=leaf.object)

	def item_types(self):
		yield TextLeaf

	def requires_object(self):
		return True

	def object_types(self):
		yield FileLeaf
		yield Command

	def valid_object(self, iobj, for_item=None):
		if isinstance(iobj, Command):
			return True
		return not iobj.is_dir() and os.access(iobj.object, os.X_OK | os.R_OK)

	def get_description(self):
		return _("Run program and supply text on the standard input") + \
		        u" \N{GEAR}"

class FilterThroughCommand (WriteToCommand):
	def __init__(self):
		# TRANS: The user starts a program (command) and
		# TRANS: the text is written on stdin, and we
		# TRANS: present the output (stdout) to the user.
		Action.__init__(self, _("Filter through Command..."))
		self.post_result = True

	def get_description(self):
		return _("Run program and supply text on the standard input") + \
		        u" \N{GEAR}"

class Command (TextLeaf):
	def __init__(self, exepath, name):
		TextLeaf.__init__(self, name, name)
		self.exepath = exepath

	def get_actions(self):
		yield Execute(quoted=False)
		yield Execute(in_terminal=True, quoted=False)
		yield GetOutput()

	def get_description(self):
		args = u" ".join(unicode(self).split(None, 1)[1:])
		return u"%s %s" % (self.exepath, args)

	def get_gicon(self):
		return icons.get_gicon_for_file(self.exepath)

	def get_icon_name(self):
		return "exec"

class CommandTextSource (TextSource):
	"""Yield path and command text items """
	def __init__(self):
		TextSource.__init__(self, name=_("Shell Commands"))

	def get_rank(self):
		return 80

	def get_text_items(self, text):
		if not text.strip():
			return
		if '\n' in text:
			return
		## check for absolute path with arguments
		firstwords = text.split()
		## files are handled elsewhere
		if firstwords[0].startswith("/") and len(firstwords) == 1:
			return
		## absolute paths come out here since
		## os.path.join with two abspaths returns the latter
		firstword = firstwords[0]
		# iterate over $PATH directories
		PATH = os.environ.get("PATH", os.defpath)
		for execdir in PATH.split(os.pathsep):
			exepath = os.path.join(execdir, firstword)
			# use filesystem encoding here
			exepath = gobject.filename_from_utf8(exepath)
			if os.access(exepath, os.R_OK|os.X_OK) and os.path.isfile(exepath):
				yield Command(exepath, text)
				break
	def get_description(self):
		return _("Run command-line programs")

########NEW FILE########
__FILENAME__ = alternatives
from kupfer import plugin_support
from kupfer import icons

def initialize_alternatives(__name__):
	plugin_support.register_alternative(__name__, 'icon_renderer', 'gtk',
		**{
			'name': _("GTK+"),
			'renderer': icons.IconRenderer,
		})

	plugin_support.register_alternative(__name__, 'terminal', 'gnome-terminal',
		**{
			'name': _("GNOME Terminal"),
			'argv': ['gnome-terminal'],
			'exearg': '-x',
			'desktopid': "gnome-terminal.desktop",
			'startup_notify': True,
		})

	plugin_support.register_alternative(__name__, 'terminal', 'xfce4-terminal',
		**{
			'name': _("XFCE Terminal"),
			'argv': ['xfce4-terminal'],
			'exearg': '-x',
			'desktopid': "xfce4-terminal.desktop",
			'startup_notify': True,
		})

	plugin_support.register_alternative(__name__, 'terminal', 'lxterminal',
		**{
			'name': _("LXTerminal"),
			'argv': ['lxterminal'],
			'exearg': '-e',
			'desktopid': "lxterminal.desktop",
			'startup_notify': False,
		})

	plugin_support.register_alternative(__name__, 'terminal', 'xterm',
		**{
			'name': _("X Terminal"),
			'argv': ['xterm'],
			'exearg': '-e',
			'desktopid': "xterm.desktop",
			'startup_notify': False,
		})

	plugin_support.register_alternative(__name__, 'terminal', 'urxvt',
		**{
			'name': _("Urxvt"),
			'argv': ['urxvt'],
			'exearg': '-e',
			'desktopid': "urxvt.desktop",
			'startup_notify': False,
		})

	plugin_support.register_alternative(__name__, 'terminal', 'konsole',
		**{
			'name': _("Konsole"),
			'argv': ['konsole'],
			'exearg': '-e',
			'desktopid': "konsole.desktop",
			# Not sure here, so setting to false
			'startup_notify': False,
		})

########NEW FILE########
__FILENAME__ = commands
__kupfer_actions__ = ("SaveToFile", )

import os

from kupfer.objects import Action, FileLeaf, TextLeaf, TextSource
from kupfer.obj.compose import ComposedLeaf
from kupfer import kupferstring
from kupfer.core import execfile


class SaveToFile (Action):
	def __init__(self):
		Action.__init__(self, _("Save As..."))

	def has_result(self):
		return True

	def activate(self, obj, iobj):
		filepath = kupferstring.tolocale(iobj.object)
		execfile.save_to_file(obj, filepath)
		execfile.update_icon(obj, iobj.object)
		return FileLeaf(os.path.abspath(filepath))

	def item_types(self):
		yield ComposedLeaf

	def requires_object(self):
		return True
	def object_types(self):
		yield TextLeaf
	def object_source(self, for_item=None):
		return NameSource(_("Save As..."), ".kfcom")

class NameSource (TextSource):
	"""A source for new names for a file;
	here we "autopropose" the source file's extension,
	but allow overriding it as well as renaming to without
	extension (selecting the normal TextSource-returned string).
	"""
	def __init__(self, name, extension, sourcefile=None):
		TextSource.__init__(self, name)
		self.sourcefile = sourcefile
		self.extension = extension

	def get_rank(self):
		return 100

	def get_items(self, text):
		if not text:
			return
		t_root, t_ext = os.path.splitext(text)
		yield TextLeaf(text) if t_ext else TextLeaf(t_root + self.extension)

	def get_gicon(self):
		return self.sourcefile and self.sourcefile.get_gicon()

	def get_icon_name(self):
		return "text-x-generic"


########NEW FILE########
__FILENAME__ = contents
import gtk

from kupfer.objects import Source, RunnableLeaf
from kupfer.obj.apps import AppLeafContentMixin
from kupfer import pretty
from kupfer import kupferui

__kupfer_sources__ = ("KupferSource", )
__kupfer_actions__ = ()
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

__all__ = __kupfer_sources__ + __kupfer_actions__

def _is_debug():
	# Return True if Kupfer is in debug mode
	return pretty.debug

class DebugRestart (RunnableLeaf):
	def __init__(self):
		RunnableLeaf.__init__(self, None, u"Restart Kupfer")

	@classmethod
	def _exec_new_kupfer(cls, executable, argv):
		import os
		os.execvp(executable, [executable] + argv)

	def run(self):
		import atexit
		import sys
		gtk.main_quit()
		atexit.register(self._exec_new_kupfer, sys.executable, sys.argv)

	def get_description(self):
		return u"Restart Kupfer quickly (for internal kupfer use)"
	def get_icon_name(self):
		return "view-refresh"

class Quit (RunnableLeaf):
	qf_id = "quit"
	def __init__(self, name=None):
		if not name: name = _("Quit")
		super(Quit, self).__init__(name=name)
	def run(self):
		gtk.main_quit()
	def get_description(self):
		return _("Quit Kupfer")
	def get_icon_name(self):
		return "application-exit"

class About (RunnableLeaf):
	def __init__(self, name=None):
		if not name: name = _("About Kupfer")
		super(About, self).__init__(name=name)
	def wants_context(self):
		return True
	def run(self, ctx):
		kupferui.show_about_dialog(ctx.environment)
	def get_description(self):
		return _("Show information about Kupfer authors and license")
	def get_icon_name(self):
		return "help-about"

class Help (RunnableLeaf):
	def __init__(self, name=None):
		if not name: name = _("Kupfer Help")
		super(Help, self).__init__(name=name)
	def wants_context(self):
		return True
	def run(self, ctx):
		kupferui.show_help(ctx.environment)
	def get_description(self):
		return _("Get help with Kupfer")
	def get_icon_name(self):
		return "help-contents"

class Preferences (RunnableLeaf):
	def __init__(self, name=None):
		if not name: name = _("Kupfer Preferences")
		super(Preferences, self).__init__(name=name)
	def wants_context(self):
		return True
	def run(self, ctx):
		kupferui.show_preferences(ctx.environment)
	def get_description(self):
		return _("Show preferences window for Kupfer")
	def get_icon_name(self):
		return "preferences-desktop"

class KupferSource (AppLeafContentMixin, Source):
	appleaf_content_id = "kupfer"
	def __init__(self, name=_("Kupfer")):
		Source.__init__(self, name)
	def is_dynamic(self):
		return True
	def get_items(self):
		yield Preferences()
		yield Help()
		yield About()
		yield Quit()
		if _is_debug():
			yield DebugRestart()

	def get_description(self):
		return None
	def get_icon_name(self):
		return "search"
	def provides(self):
		yield RunnableLeaf

########NEW FILE########
__FILENAME__ = debug
"""
This module contains internal and / or experimental Kupfer features.

These are not meant to be useful to "normal" users of Kupfer -- if they are,
they can be tested here before they migrate to a fitting plugin.
"""

from kupfer.obj.base import Action, Leaf, Source
from kupfer.obj.compose import ComposedLeaf
from kupfer import pretty

__kupfer_sources__ = ()
__kupfer_contents__ = (
		"ComposedSource",
	)
__kupfer_actions__ = (
		"DebugInfo",
		"Forget",
	)
__description__ = __doc__
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"


class DebugInfo (Action):
	""" Print debug info to terminal """
	rank_adjust = -50
	def __init__(self):
		Action.__init__(self, u"Debug Info")

	def activate(self, leaf):
		import StringIO
		# NOTE: Core imports
		from kupfer.core import qfurl
		from kupfer import uiutils
		from kupfer import puid

		output = StringIO.StringIO()
		def print_func(*args):
			print >>output, " ".join(unicode(a) for a in args)
			pretty.print_debug("debug", *args)

		print_func("Debug info about", leaf)
		print_func(leaf, repr(leaf))
		def get_qfurl(leaf):
			try:
				return qfurl.qfurl(leaf)
			except qfurl.QfurlError:
				pass
		def get_object_fields(leaf):
			return {
				"repr" : leaf,
				"description": leaf.get_description(),
				"thumb" : leaf.get_thumbnail(32, 32),
				"gicon" : leaf.get_gicon(),
				"icon" : leaf.get_icon(),
				"icon-name": leaf.get_icon_name(),
				"type" : type(leaf),
				"module" : leaf.__module__,
				"aliases" : getattr(leaf, "name_aliases", None),
				"qfurl" : get_qfurl(leaf),
				"puid" : puid.get_unique_id(leaf),
				}
		def get_leaf_fields(leaf):
			base = get_object_fields(leaf)
			base.update( {
				"object" : leaf.object,
				"object-type" : type(leaf.object),
				"content" : leaf.content_source(),
				"content-alt" : leaf.content_source(alternate=True),
				"builtin-actions": list(leaf.get_actions()),
				} )
			return base
		def get_source_fields(src):
			base = get_object_fields(src)
			base.update({
				"dynamic" : src.is_dynamic(),
				"sort" : src.should_sort_lexically(),
				"parent" : src.get_parent(),
				"leaf" : src.get_leaf_repr(),
				"provides" : list(src.provides()),
				"cached_items": type(src.cached_items),
				"len": isinstance(src.cached_items, list) and len(src.cached_items),
				} )
			return base

		def print_fields(fields):
			for field in sorted(fields):
				val = fields[field]
				rep = repr(val)
				print_func("%-15s:" % field, rep)
				if str(val) not in rep:
					print_func("%-15s:" % field, val)
		leafinfo = get_leaf_fields(leaf)
		print_fields(leafinfo)
		if leafinfo["content"]:
			print_func("Content ============")
			print_fields(get_source_fields(leafinfo["content"]))
		if leafinfo["content"] != leafinfo["content-alt"]:
			print_func("Content-Alt ========")
			print_fields(get_source_fields(leafinfo["content-alt"]))
		uiutils.show_text_result(output.getvalue())

	def get_description(self):
		return u"Print debug output (for interal kupfer use)"
	def get_icon_name(self):
		return "emblem-system"
	def item_types(self):
		yield Leaf

class Forget (Action):
	rank_adjust = -10
	def __init__(self):
		Action.__init__(self, u"Forget")

	def activate(self, leaf):
		# NOTE: Core imports
		from kupfer.core import learn

		# FIXME: This is a large, total, utter HACK
		if isinstance(leaf, ComposedLeaf):
			for o in leaf.object:
				learn._register.pop(repr(o), None)
		if isinstance(leaf, ActionLeaf):
			learn._register.pop(repr(leaf.object), None)
		else:
			learn._register.pop(repr(leaf), None)

	def item_types(self):
		yield Leaf

	def get_description(self):
		return u"Let Kupfer forget about this object"

class ActionLeaf (Leaf):
	def __init__(self, action):
		Leaf.__init__(self, action, unicode(action))

	def get_actions(self):
		act = self.object
		if not (hasattr(act, "requires_object") and act.requires_object()):
			yield Apply(act)

	def get_description(self):
		return self.object.get_description()
	def get_icon_name(self):
		return self.object.get_icon_name()

class Apply (Action):
	rank_adjust = 5
	def __init__(self, action):
		Action.__init__(self, u"Apply To...")
		self.action = action

	def is_factory(self):
		return self.action.is_factory()
	def has_result(self):
		return self.action.has_result()
	def is_async(self):
		return self.action.is_async()
	def requires_object(self):
		return True
	def object_types(self):
		return self.action.item_types()
	def valid_object(self, obj, for_item=None):
		return self.action.valid_for_item(obj)
	def activate(self, leaf, iobj):
		return self.action.activate(iobj)

class ComposedSource (Source):
	"""
	Decorated ComposedLeaf with a Source that shows the contents of
	Composed Commands
	"""
	def __init__(self, leaf):
		Source.__init__(self, u"Composed Command")
		self.leaf = leaf

	def get_items(self):
		obj = self.leaf.object
		yield self.leaf.object[0]
		yield ActionLeaf(obj[1])
		if self.leaf.object[2] is not None:
			yield self.leaf.object[2]

	def repr_key(self):
		return self.leaf.repr_key()

	@classmethod
	def decorates_type(cls):
		return ComposedLeaf

	@classmethod
	def decorate_item(cls, leaf):
		return cls(leaf)

########NEW FILE########
__FILENAME__ = internal

from kupfer.objects import Source, Leaf
from kupfer.objects import RunnableLeaf
from kupfer.core import commandexec

__kupfer_sources__ = ("KupferInterals", "CommandResults", )
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

class LastCommand (RunnableLeaf):
	"Represented object is the command tuple to run"
	qf_id = "lastcommand"
	def __init__(self, obj):
		RunnableLeaf.__init__(self, obj, _("Last Command"))

	def wants_context(self):
		return True

	def run(self, ctx):
		obj, action, iobj = self.object
		return ctx.delegated_run(obj, action, iobj)

class KupferInterals (Source):
	def __init__(self):
		Source.__init__(self, _("Internal Kupfer Objects"))

	def is_dynamic(self):
		return True

	def get_items(self):
		ctx = commandexec.DefaultActionExecutionContext()
		if ctx.last_command is None:
			return
		yield LastCommand(ctx.last_command)

	def provides(self):
		yield LastCommand

class LastResultObject (Leaf):
	"dummy superclass"

def _make_first_result_object(leaf):
	global LastResultObject
	class LastResultObject (LastResultObject):
		qf_id = "lastresult"
		def __init__(self, leaf):
			Leaf.__init__(self, leaf.object, _("Last Result"))
			vars(self).update(vars(leaf))
			self.name = _("Last Result")
			self.__orignal_leaf = leaf
			self.__class__.__bases__ = (leaf.__class__, Leaf)

		def get_gicon(self):
			return None
		def get_icon_name(self):
			return Leaf.get_icon_name(self)
		def get_thumbnail(self, w, h):
			return None
		def get_description(self):
			return unicode(self.__orignal_leaf)

	return LastResultObject(leaf)


class CommandResults (Source):
	def __init__(self):
		Source.__init__(self, _("Command Results"))

	def is_dynamic(self):
		return True

	def get_items(self):
		ctx = commandexec.DefaultActionExecutionContext()
		for x in reversed(ctx.last_results):
			yield x
		try:
			leaf = ctx.last_results[-1]
		except IndexError:
			return
		yield _make_first_result_object(leaf)

	def provides(self):
		yield Leaf
		yield LastResultObject

########NEW FILE########
__FILENAME__ = text
import os
import urlparse
import urllib

import gobject

from kupfer.objects import TextSource, TextLeaf, FileLeaf, UrlLeaf
from kupfer.obj.objects import OpenUrl
from kupfer import utils

__kupfer_name__ = u"Free-text Queries"
__kupfer_sources__ = ()
__kupfer_text_sources__ = ("BasicTextSource", "PathTextSource", "URLTextSource",)
__kupfer_actions__ = ("OpenTextUrl", )
__description__ = u"Basic support for free-text queries"
__version__ = "2009-12-16"
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

class BasicTextSource (TextSource):
	"""The most basic TextSource yields one TextLeaf"""
	def __init__(self):
		TextSource.__init__(self, name=_("Text"))

	def get_text_items(self, text):
		if not text:
			return
		yield TextLeaf(text)
	def provides(self):
		yield TextLeaf


class PathTextSource (TextSource):
	"""Return existing full paths if typed"""
	def __init__(self):
		TextSource.__init__(self, name=u"Filesystem Text Matches")

	def get_rank(self):
		return 80
	def get_text_items(self, text):
		# Find directories or files
		prefix = os.path.expanduser(u"~/")
		ufilepath = text if os.path.isabs(text) else os.path.join(prefix, text)
		# use filesystem encoding here
		filepath = gobject.filename_from_utf8(os.path.normpath(ufilepath))
		if os.access(filepath, os.R_OK):
			yield FileLeaf(filepath)
	def provides(self):
		yield FileLeaf

def is_url(text):
	"""If @text is an URL, return a cleaned-up URL, else return None"""
	text = text.strip()
	components = list(urlparse.urlparse(text))
	domain = "".join(components[1:])
	dotparts = domain.rsplit(".")

	# 1. Domain name part is one word (without spaces)
	# 2. Urlparse parses a scheme (http://), else we apply heuristics
	if len(domain.split()) == 1 and (components[0] or ("." in domain and
		len(dotparts) >= 2 and len(dotparts[-1]) >= 2 and
		any(char.isalpha() for char in domain) and
		all(part[:1].isalnum() for part in dotparts))):
		if not components[0]:
			url = "http://" + "".join(components[1:])
		else:
			url = text
		name = ("".join(components[1:3])).strip("/")
		if name:
			return url

def try_unquote_url(url):
	"""Try to turn an URL-escaped string into a Unicode string

	Where we assume UTF-8 encoding; and return the original url if
	any step fails.
	"""
	# check that it is ascii only
	try:
		burl = url.encode("ascii")
	except UnicodeEncodeError:
		return url
	try:
		return urllib.unquote(burl).decode("UTF-8")
	except UnicodeDecodeError:
		return url

class OpenTextUrl (OpenUrl):
	rank_adjust = 1

	def activate(self, leaf):
		url = is_url(leaf.object)
		utils.show_url(url)

	def item_types(self):
		yield TextLeaf
	def valid_for_item(self, leaf):
		return is_url(leaf.object)

class URLTextSource (TextSource):
	"""detect URLs and webpages"""
	def __init__(self):
		TextSource.__init__(self, name=u"URL Text Matches")

	def get_rank(self):
		return 75
	def get_text_items(self, text):
		# Only detect "perfect" URLs
		text = text.strip()
		components = list(urlparse.urlparse(text))
		domain = "".join(components[1:])

		# If urlparse parses a scheme (http://), it's an URL
		if len(domain.split()) <= 1 and components[0]:
			url = text
			name = ("".join(components[1:3])).strip("/")
			name = try_unquote_url(name) or url
			yield UrlLeaf(url, name=name)

	def provides(self):
		yield UrlLeaf

########NEW FILE########
__FILENAME__ = customtheme
__kupfer_name__ = _("Custom Theme")
__kupfer_sources__ = ()
__description__ = _("Use a custom color theme")
__version__ = ""
__author__ = ""

import os
import gtk

from kupfer import config
from kupfer import plugin_support

"""
Kupfer's UI can be themed by using the normal GtkRc style language
Theming can change colors and some pre-defined parameters, but
not the layout.

See also Documentation/GTKTheming.rst
      or http://kaizer.se/wiki/kupfer/GTKTheming.html

For general information about GTK+ styles,
please see http://live.gnome.org/GnomeArt/Tutorials/GtkThemes

"""

SQUARE_STYLE = """
style "square"
{
	MatchView :: corner-radius = 0
	MatchView :: opacity = 100
	Search :: list-opacity = 100
	KupferWindow :: corner-radius = 0
	KupferWindow :: opacity = 100
	KupferWindow :: decorated = 0
	KupferWindow :: border-width = 4

}

## The main window is kupfer
widget "kupfer" style "square"
widget "kupfer.*" style "square"

## The result list is kupfer-list
widget "kupfer-list.*" style "square"
"""

DARK_STYLE = """
style "dark"
{
	## bg: background color
	bg[NORMAL] = "#333"
	bg[SELECTED] = "#000"
	bg[ACTIVE] = "#222"
	bg[PRELIGHT] = "#222"
	bg[INSENSITIVE] = "#333"

	## fg: foreground text color
	fg[NORMAL] = "#DDD"
	fg[SELECTED] = "#EEE"
	fg[ACTIVE] = "#EEE"
	fg[PRELIGHT] = "#EEE"
	fg[INSENSITIVE] = "#DDD"

	## text: text color in input widget and treeview
	text[NORMAL] = "#EEE"
	text[SELECTED] = "#EEE"
	text[ACTIVE] = "#EEE"

	## base: background color in input widget and treeview
	base[NORMAL] = "#777"
	base[SELECTED] = "#100"
	base[ACTIVE] = "#112"

	## These are UI Widget style properties with their approximate
	## default values. These can all be overidden in the theme.
	## MatchView :: corner-radius = 15
	MatchView :: opacity = 90
	## Search :: list-opacity = 93
	## KupferWindow :: corner-radius = 15
	KupferWindow :: opacity = 90
	## KupferWindow :: decorated = 0
	## KupferWindow :: border-width = 8
}

## The main window is kupfer
widget "kupfer" style "dark"
widget "kupfer.*" style "dark"

## The result list is kupfer-list
widget "kupfer-list.*" style "dark"

## The menu button is *.kupfer-menu-button
## widget "*.kupfer-menu-button" style "dark"
## The description text is *.kupfer-description
## widget "*.kupfer-description" style "dark"
## The context menu is GtkWindow.kupfer-menu
## widget "*.kupfer-menu" style "dark"
"""


all_styles = {
	'default': None,
	'square': SQUARE_STYLE,
	'dark': DARK_STYLE,
}

__kupfer_settings__ = plugin_support.PluginSettings(
		{
			"key": "theme",
			"label": _("Theme:"),
			"type": str,
			"value": 'default',
			"alternatives": all_styles.keys(),
		},
	)

def cache_filename():
	return os.path.join(config.get_cache_home(), __name__)

def re_read_theme():
	## force re-read theme
	## FIXME: re-read on all screens
	settings = gtk.settings_get_default()
	gtk.rc_reparse_all_for_settings(settings, True)

def initialize_plugin(name):
	"""
	Theme changes are only reversible if we add
	and remove gtkrc files.
	"""
	use_theme(all_styles.get(__kupfer_settings__['theme']))
	__kupfer_settings__.connect_settings_changed_cb(on_change_theme)

def on_change_theme(sender, key, value):
	if key == 'theme':
		use_theme(all_styles.get(__kupfer_settings__[key]))

def use_theme(style_str):
	"""
	Use the GTK+ style in @style_str,
	or unset if it is None
	"""
	filename = cache_filename()
	if style_str is None:
		filename = cache_filename()
		gtk.rc_set_default_files([f for f in gtk.rc_get_default_files()
		                          if f != filename])
	else:
		with open(filename, "wb") as rcfile:
			rcfile.write(style_str)
		gtk.rc_add_default_file(filename)
	re_read_theme()

def finalize_plugin(name):
	use_theme(None)
	re_read_theme()
	## remove cache file
	filename = cache_filename()
	assert ("kupfer" in filename)
	try:
		os.unlink(filename)
	except OSError:
		pass

########NEW FILE########
__FILENAME__ = custom_terminal
__kupfer_name__ = _("Custom Terminal")
__description__ = _("Configure a custom terminal emulator")
__version__ = ""
__author__ = "Ulrik Sverdrup"

from kupfer import plugin_support
from kupfer import utils

__kupfer_settings__ = plugin_support.PluginSettings(
		{
			"key": "command",
			"label": _("Command"),
			"type": str,
			"value": "",
		},
		{
			"key": "exearg",
			"label": _("Execute flag"),
			"type": str,
			"value": "-e",
			"tooltip": ("The flag which makes the terminal execute"
			            " everything following it in the argument string. ")
		},
	)



def initialize_plugin(name):
	__kupfer_settings__.connect_settings_changed_cb(_update_alternative)
	_update_alternative()

def _update_alternative(*args):
	command = __kupfer_settings__["command"]
	exearg = __kupfer_settings__["exearg"]
	argv = utils.argv_for_commandline(command)
	if not argv or not utils.lookup_exec_path(argv[0]):
		return
	plugin_support.register_alternative(__name__, 'terminal', 'custom1',
			name=_("Custom Terminal"),
			argv=argv,
			exearg=exearg,
			desktopid="",
			startup_notify=True)


########NEW FILE########
__FILENAME__ = defaultmail
__kupfer_name__ = _("Default Email Client")
__kupfer_actions__ = (
	"NewMailAction",
	"SendFileByMail",
)
__description__ = _("Compose email using the system's default mailto: handler")
__version__ = "2010-01-12"
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

from kupfer.objects import Action
from kupfer.objects import TextLeaf, UrlLeaf, FileLeaf
from kupfer.obj.contacts import ContactLeaf, email_from_leaf
from kupfer import utils


class NewMailAction(Action):
	def __init__(self):
		Action.__init__(self, _('Compose Email'))

	def activate(self, leaf):
		email = email_from_leaf(leaf)
		utils.show_url("mailto:%s" % email)

	def activate_multiple(self, objects):
		recipients = ",".join(email_from_leaf(L) for L in objects)
		url = "mailto:" + recipients
		utils.show_url(url)

	def item_types(self):
		yield ContactLeaf
		yield TextLeaf
		yield UrlLeaf
	def valid_for_item(self, item):
		return bool(email_from_leaf(item))

	def get_description(self):
		return __description__
	def get_icon_name(self):
		return "mail-message-new"

class SendFileByMail (Action):
	def __init__(self):
		Action.__init__(self, _('Send in Email To...'))

	def activate(self, obj, iobj):
		self.activate_multiple((obj, ), (iobj, ))

	def activate_multiple(self, objects, iobjects):
		# FIXME: revisit for unicode email addresses
		recipients = ",".join(email_from_leaf(I) for I in iobjects)
		attachlist = "?attach=" + "&attach=".join(L.object for L in objects)
		url = "mailto:" + recipients + attachlist
		utils.show_url(url)

	def item_types(self):
		yield FileLeaf
	def valid_for_item(self, item):
		return not item.is_dir()

	def requires_object(self):
		return True
	def object_types(self):
		yield ContactLeaf
		yield TextLeaf
		yield UrlLeaf
	def valid_object(self, iobj, for_item=None):
		return bool(email_from_leaf(iobj))

	def get_icon_name(self):
		return "document-send"

########NEW FILE########
__FILENAME__ = devhelp
__kupfer_name__ = _("Devhelp")
__kupfer_actions__ = ("LookUp", )
__description__ = _("Search in Devhelp")
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

from kupfer.objects import Action, TextLeaf
from kupfer import utils


class LookUp (Action):
	def __init__(self):
		Action.__init__(self, _("Search in Devhelp"))
	def activate(self, leaf):
		text = leaf.object
		utils.spawn_async(['devhelp', '--search=%s' % text])
	def item_types(self):
		yield TextLeaf
	def valid_for_item(self, leaf):
		text = leaf.object
		return '\n' not in text
	def get_description(self):
		return None
	def get_icon_name(self):
		return "devhelp"

########NEW FILE########
__FILENAME__ = dictionary
__kupfer_name__ = _("Dictionary")
__kupfer_actions__ = ("LookUp", )
__description__ = _("Look up word in dictionary")
__version__ = ""
__author__ = "Ulrik"

from kupfer.objects import Action, TextLeaf, OperationError
from kupfer import utils
from kupfer import plugin_support
from kupfer import kupferstring

dictionaries = {
	'gnome-dictionary': ['gnome-dictionary', '--look-up='],
	'purple': ['purple', '--define='],
	'xfce4-dict': ['xfce4-dict', '--dict', ''],
}

__kupfer_settings__ = plugin_support.PluginSettings(
	{
		"key" : "dictionary",
		"label": _("Dictionary"),
		"type": str,
		"alternatives": dictionaries.keys(),
		"value": 'gnome-dictionary',
	}
)

class LookUp (Action):
	def __init__(self):
		Action.__init__(self, _("Look Up"))
	def activate(self, leaf):
		text = leaf.object
		dict_id = __kupfer_settings__["dictionary"]
		dict_argv = list(dictionaries[dict_id])
		dict_argv[-1] = dict_argv[-1] + kupferstring.tolocale(text)
		try:
			utils.spawn_async_notify_as(dict_id + ".desktop", dict_argv)
		except utils.SpawnError as exc:
			raise OperationError(exc)

	def item_types(self):
		yield TextLeaf
	def valid_for_item(self, leaf):
		text = leaf.object
		return len(text.split("\n", 1)) <= 1
	def get_description(self):
		return _("Look up word in dictionary")
	def get_icon_name(self):
		return "accessories-dictionary"

########NEW FILE########
__FILENAME__ = documents
__kupfer_name__ = _("Documents")
__kupfer_sources__ = ("RecentsSource", "PlacesSource", )
__kupfer_contents__ = ("ApplicationRecentsSource", )
__description__ = _("Recently used documents and bookmarked folders")
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

from os import path

import gio
from gtk import recent_manager_get_default

from kupfer.objects import Source, AppLeaf, FileLeaf, UrlLeaf
from kupfer import icons
from kupfer import launch
from kupfer import plugin_support
from kupfer.weaklib import gobject_connect_weakly

__kupfer_settings__ = plugin_support.PluginSettings(
	{
		"key" : "max_days",
		"label": _("Max recent document days"),
		"type": int,
		"value": 28,
	},
)


class RecentsSource (Source):
	def __init__(self, name=None):
		if not name:
			name = _("Recent Items")
		super(RecentsSource, self).__init__(name)

	def initialize(self):
		"""Set up change callback"""
		manager = recent_manager_get_default()
		gobject_connect_weakly(manager, "changed", self._recent_changed)

	def _recent_changed(self, *args):
		# FIXME: We don't get single item updates, might this be
		# too many updates?
		self.mark_for_update()
	
	def get_items(self):
		max_days = __kupfer_settings__["max_days"]
		#self.output_info("Items younger than", max_days, "days")
		items = self._get_items(max_days)
		return items

	@classmethod
	def _get_items(cls, max_days, for_application_named=None):
		manager = recent_manager_get_default()
		items = manager.get_items()
		item_leaves = []
		for item in items:
			if for_application_named:
				low_apps = [A.lower() for A in item.get_applications()]
				if for_application_named.lower() not in low_apps:
					continue
			day_age = item.get_age()
			if max_days >= 0 and day_age > max_days:
				continue
			if not item.exists():
				continue

			uri = item.get_uri()
			name = item.get_short_name()
			if item.is_local():
				leaf = FileLeaf(gio.File(uri).get_path())
			else:
				leaf = UrlLeaf(uri, name)
			item_leaves.append((leaf, item.get_modified()))
		for lf, date in sorted(item_leaves, key=lambda t: t[1], reverse=True):
			yield lf

	def get_description(self):
		return _("Recently used documents")

	def get_icon_name(self):
		return "document-open-recent"
	def provides(self):
		yield FileLeaf
		yield UrlLeaf

class ApplicationRecentsSource (RecentsSource):
	def __init__(self, application):
		name = _("%s Documents") % unicode(application)
		super(ApplicationRecentsSource, self).__init__(name)
		self.application = application

	def repr_key(self):
		return self.application.repr_key()

	def get_items(self):
		svc = launch.GetApplicationsMatcherService()
		app_name = svc.application_name(self.application.get_id())
		max_days = -1
		self.output_info("Items for", app_name)
		items = self._get_items(max_days, app_name)
		return items

	@classmethod
	def has_items_for_application(cls, name):
		for item in cls._get_items(-1, name):
			return True
		return False

	def get_gicon(self):
		return icons.ComposedIcon(self.get_icon_name(),
				self.application.get_icon())
	def get_description(self):
		return _("Recently used documents for %s") % unicode(self.application)

	@classmethod
	def decorates_type(cls):
		return AppLeaf

	@classmethod
	def decorate_item(cls, leaf):
		svc = launch.GetApplicationsMatcherService()
		app_name = svc.application_name(leaf.get_id())
		if app_name and cls.has_items_for_application(app_name):
			return cls(leaf)
		return None

class PlacesSource (Source):
	"""
	Source for items from nautilus bookmarks 
	"""
	def __init__(self):
		super(PlacesSource, self).__init__(_("Places"))
		self.places_file = "~/.gtk-bookmarks"
	
	def get_items(self):
		"""
		gtk-bookmarks: each line has url and optional title
		file:///path/to/that.end [title]
		"""
		fileloc = path.expanduser(self.places_file)
		if not path.exists(fileloc):
			return ()
		return self._get_places(fileloc)

	def _get_places(self, fileloc):
		for line in open(fileloc):
			if not line.strip():
				continue
			items = line.split()
			uri = items[0]
			gfile = gio.File(uri)
			if len(items) > 1:
				title = items[1]
			else:
				disp = gfile.get_parse_name()
				title =	path.basename(disp)
			locpath = gfile.get_path()
			if locpath:
				yield FileLeaf(locpath, title)
			else:
				yield UrlLeaf(gfile.get_uri(), title)

	def get_description(self):
		return _("Bookmarked folders")
	def get_icon_name(self):
		return "file-manager"
	def provides(self):
		yield FileLeaf
		yield UrlLeaf

########NEW FILE########
__FILENAME__ = duckduckgo
"""
This is a DuckDuckGo search plugin based on the Wikipedia search plugin
"""

__kupfer_name__ = _("DuckDuckGo Search")
__kupfer_sources__ = ()
__kupfer_actions__ = ("DuckDuckGoSearch",)
__description__ = _("Search the web securely with DuckDuckGo")
__version__ = "1.0"
__author__ = "Isaac Aggrey <isaac.aggrey@gmail.com>"

import urllib

from kupfer.objects import Action, TextLeaf
from kupfer import utils

class DuckDuckGoSearch (Action):
	def __init__(self):
		Action.__init__(self, _("DuckDuckGo Search"))

	def activate(self, leaf):
		search_url = "https://duckduckgo.com/"
		query_url = search_url + "?" + urllib.urlencode({"q" : leaf.object})
		utils.show_url(query_url)

	def item_types(self):
		yield TextLeaf

	def get_description(self):
		return _("Search the web securely with DuckDuckGo")

	def get_icon_name(self):
		return "edit-find"

########NEW FILE########
__FILENAME__ = empathy
# -*- coding: UTF-8 -*-
# vim: set noexpandtab ts=8 sw=8:
__kupfer_name__ = _("Empathy")
__kupfer_sources__ = ("ContactsSource", )
__kupfer_actions__ = ("ChangeStatus", 'OpenChat')
__description__ = _("Access to Empathy Contacts")
__version__ = "2010-10-17"
__author__ = "Jakh Daven <tuxcanfly@gmail.com>"

import dbus
import time

from kupfer import icons
from kupfer import plugin_support
from kupfer import pretty
from kupfer.objects import Leaf, Action, Source, AppLeaf
from kupfer.weaklib import dbus_signal_connect_weakly
from kupfer.obj.helplib import PicklingHelperMixin
from kupfer.obj.apps import AppLeafContentMixin
from kupfer.obj.grouping import ToplevelGroupingSource
from kupfer.obj.contacts import ContactLeaf, JabberContact, JABBER_JID_KEY

__kupfer_settings__ = plugin_support.PluginSettings(
	{
		"key" : "show_offline",
		"label": _("Show offline contacts"),
		"type": bool,
		"value": False,
	},
)

plugin_support.check_dbus_connection()

_STATUSES = {
	'available':	_('Available'),
	'away':		_('Away'),
	'dnd':		_('Busy'),
	'xa':		_('Not Available'),
	'hidden':	_('Invisible'),
	'offline':	_('Offline')
}

_ATTRIBUTES = {
	'alias':          'org.freedesktop.Telepathy.Connection.Interface.Aliasing/alias',
	'presence':       'org.freedesktop.Telepathy.Connection.Interface.SimplePresence/presence',
	'contact_caps':   'org.freedesktop.Telepathy.Connection.Interface.ContactCapabilities.DRAFT/caps',
	'jid':            'org.freedesktop.Telepathy.Connection/contact-id',
	'caps':           'org.freedesktop.Telepathy.Connection.Interface.Capabilities/caps',
}


ACCOUNTMANAGER_PATH = "/org/freedesktop/Telepathy/AccountManager"
ACCOUNTMANAGER_IFACE = "org.freedesktop.Telepathy.AccountManager"
ACCOUNT_IFACE = "org.freedesktop.Telepathy.Account"
CHANNEL_GROUP_IFACE = "org.freedesktop.Telepathy.Channel.Interface.Group"
CONTACT_IFACE = "org.freedesktop.Telepathy.Connection.Interface.Contacts"
SIMPLE_PRESENCE_IFACE = "org.freedesktop.Telepathy.Connection.Interface.SimplePresence"
DBUS_PROPS_IFACE = "org.freedesktop.DBus.Properties"
CHANNELDISPATCHER_IFACE = "org.freedesktop.Telepathy.ChannelDispatcher"
CHANNELDISPATCHER_PATH = "/org/freedesktop/Telepathy/ChannelDispatcher"
CHANNEL_TYPE = "org.freedesktop.Telepathy.Channel.ChannelType"
CHANNEL_TYPE_TEXT = "org.freedesktop.Telepathy.Channel.Type.Text"
CHANNEL_TARGETHANDLE = "org.freedesktop.Telepathy.Channel.TargetHandle"
CHANNEL_TARGETHANDLETYPE = "org.freedesktop.Telepathy.Channel.TargetHandleType"
EMPATHY_CLIENT_IFACE = "org.freedesktop.Telepathy.Client.Empathy"

EMPATHY_ACCOUNT_KEY = "EMPATHY_ACCOUNT"
EMPATHY_CONTACT_ID = "EMPATHY_CONTACT_ID"

def _create_dbus_connection():
	try:
		sbus = dbus.SessionBus()
		proxy_obj = sbus.get_object(ACCOUNTMANAGER_IFACE, ACCOUNTMANAGER_PATH)
		dbus_iface = dbus.Interface(proxy_obj, DBUS_PROPS_IFACE)
		return dbus_iface
	except dbus.DBusException as exc:
		pretty.print_exc(__name__)


class EmpathyContact(JabberContact):

	def __init__(self, jid, name, status, resources, account, contact_id):
		empathy_slots= { EMPATHY_ACCOUNT_KEY: account, EMPATHY_CONTACT_ID: contact_id }
		JabberContact.__init__(self, jid, name, status, resources, empathy_slots)

	def repr_key(self):
		return "".join((self.object[JABBER_JID_KEY], self.object[EMPATHY_ACCOUNT_KEY]))

	def get_gicon(self):
		return icons.ComposedIconSmall(self.get_icon_name(), "empathy")


class AccountStatus(Leaf):
	pass


class OpenChat(Action):

	def __init__(self):
		Action.__init__(self, _('Open Chat'))

	def activate(self, leaf):
		bus = dbus.SessionBus()
		jid = JABBER_JID_KEY in leaf and leaf[JABBER_JID_KEY]
		account = bus.get_object(ACCOUNTMANAGER_IFACE, leaf[EMPATHY_ACCOUNT_KEY])
		contact_id = leaf[EMPATHY_CONTACT_ID]

		channel_dispatcher_iface = bus.get_object(CHANNELDISPATCHER_IFACE, CHANNELDISPATCHER_PATH)
		ticks = dbus.Int64(time.time())
		channel_request_params = dbus.Dictionary()
		channel_request_params[CHANNEL_TYPE] = dbus.String(CHANNEL_TYPE_TEXT, variant_level=1)
		channel_request_params[CHANNEL_TARGETHANDLETYPE] = dbus.UInt32(1, variant_level=1)
		channel_request_params[CHANNEL_TARGETHANDLE] = contact_id
		message_channel_path = channel_dispatcher_iface.EnsureChannel(account, channel_request_params, ticks, EMPATHY_CLIENT_IFACE)
		channel_request = bus.get_object(ACCOUNTMANAGER_IFACE, message_channel_path)
		channel_request.Proceed()


	def get_icon_name(self):
		return 'empathy'

	def item_types(self):
		yield ContactLeaf

	def valid_for_item(self, item):
		return EMPATHY_ACCOUNT_KEY in item and item[EMPATHY_ACCOUNT_KEY]


class ChangeStatus(Action):
	''' Change global status '''

	def __init__(self):
		Action.__init__(self, _('Change Global Status To...'))

	def activate(self, leaf, iobj):
		bus = dbus.SessionBus()
		interface = _create_dbus_connection()
		for valid_account in interface.Get(ACCOUNTMANAGER_IFACE, "ValidAccounts"):
			account = bus.get_object(ACCOUNTMANAGER_IFACE, valid_account)
			connection_status = account.Get(ACCOUNT_IFACE, "ConnectionStatus")
			if connection_status != 0:
				continue

			if iobj.object == "offline":
				false = dbus.Boolean(0, variant_level=1)
				account.Set(ACCOUNT_IFACE, "Enabled", false)
			else:
				connection_path = account.Get(ACCOUNT_IFACE, "Connection")
				connection_iface = connection_path.replace("/", ".")[1:]
				connection = bus.get_object(connection_iface, connection_path)
				simple_presence = dbus.Interface(connection, SIMPLE_PRESENCE_IFACE)
				simple_presence.SetPresence(iobj.object, _STATUSES.get(iobj.object))

	def item_types(self):
		yield AppLeaf

	def valid_for_item(self, leaf):
		return leaf.get_id() == 'empathy'

	def requires_object(self):
		return True

	def object_types(self):
		yield AccountStatus

	def object_source(self, for_item=None):
		return StatusSource()


class ContactsSource(AppLeafContentMixin, ToplevelGroupingSource,
		PicklingHelperMixin):
	''' Get contacts from all on-line accounts in Empathy via DBus '''
	appleaf_content_id = 'empathy'

	def __init__(self, name=_('Empathy Contacts')):
		super(ContactsSource, self).__init__(name, "Contacts")
		self._version = 2
		self.unpickle_finish()

	def pickle_prepare(self):
		self._contacts = []

	def unpickle_finish(self):
		self.mark_for_update()
		self._contacts = []

	def initialize(self):
		ToplevelGroupingSource.initialize(self)

	def get_items(self):
		interface = _create_dbus_connection()
		if interface is not None:
			self._contacts = list(self._find_all_contacts(interface))
		else:
			self._contacts = []
		return self._contacts

	def _find_all_contacts(self, interface):
		show_offline = __kupfer_settings__["show_offline"]
		bus = dbus.SessionBus()
		for valid_account in interface.Get(ACCOUNTMANAGER_IFACE, "ValidAccounts"):
			account = bus.get_object(ACCOUNTMANAGER_IFACE, valid_account)
			connection_status = account.Get(ACCOUNT_IFACE, "ConnectionStatus")
			if connection_status != 0:
				continue

			connection_path = account.Get(ACCOUNT_IFACE, "Connection")
			connection_iface = connection_path.replace("/", ".")[1:]
			connection = bus.get_object(connection_iface, connection_path)
			channels = connection.ListChannels()
			for channel in channels:
				contact_group = bus.get_object(connection_iface, channel[0])
				try:
					contacts = contact_group.Get(CHANNEL_GROUP_IFACE, "Members")
				except dbus.exceptions.DBusException, ex:
					self.output_info(ex)
					contacts = None
				if contacts:
						contacts = [c for c in contacts]
						contact_attributes = connection.Get(CONTACT_IFACE, "ContactAttributeInterfaces")
						contact_attributes = [str(a) for a in contact_attributes]
						contact_details = connection.GetContactAttributes(contacts, contact_attributes, False)
						for contact, details in contact_details.iteritems():
								try:
									status_code = details[_ATTRIBUTES.get("presence")][1]
								except KeyError, ex:
									self.output_info('Presence could not be established with %s. Leaving unknown.' % ex)
									status_code = u'unknown'
								if not show_offline and status_code == 'offline':
									continue
								yield EmpathyContact(
										details[_ATTRIBUTES.get("jid")],
										details[_ATTRIBUTES.get("alias")],
										_STATUSES.get(status_code),
										'', # empathy does not provide resource here AFAIK
										valid_account,
										contact)

	def get_icon_name(self):
		return 'empathy'

	def provides(self):
		yield ContactLeaf


class StatusSource(Source):

	def __init__(self):
		Source.__init__(self, _("Empathy Account Status"))

	def get_items(self):
		for status, name in _STATUSES.iteritems():
			yield AccountStatus(status, name)

	def provides(self):
		yield AccountStatus


########NEW FILE########
__FILENAME__ = epiphany
__kupfer_name__ = _("Epiphany Bookmarks")
__kupfer_sources__ = ("EpiphanySource", )
__description__ = _("Index of Epiphany bookmarks")
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import os

from kupfer.objects import Source
from kupfer.objects import UrlLeaf
from kupfer.obj.apps import AppLeafContentMixin

from kupfer.plugin import epiphany_support

class EpiphanySource (AppLeafContentMixin, Source):
	appleaf_content_id = "epiphany"
	def __init__(self):
		super(EpiphanySource, self).__init__(_("Epiphany Bookmarks"))
	
	def get_items(self):
		fpath = os.path.expanduser(epiphany_support.EPHY_BOOKMARKS_FILE)
		if not os.path.exists(fpath):
			self.output_debug("Epiphany bookmarks file not found:", fpath)
			return ()

		try:
			bookmarks = list(epiphany_support.parse_epiphany_bookmarks(fpath))
		except EnvironmentError, exc:
			self.output_error(exc)
			return ()

		return (UrlLeaf(href, title) for title, href in bookmarks)

	def get_description(self):
		return _("Index of Epiphany bookmarks")

	def get_icon_name(self):
		return "web-browser"
	def provides(self):
		yield UrlLeaf


########NEW FILE########
__FILENAME__ = epiphany_support
"""
Parse Epiphany's bookmarks file
Inspired by the Epiphany handler from the deskbar project
"""

__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"


import xml.etree.cElementTree as ElementTree

EPHY_BOOKMARKS_FILE = "~/.gnome2/epiphany/bookmarks.rdf"

def parse_epiphany_bookmarks(filename):
	"""
	Yield a sequence of bookmarks
	"""
	UNWANTED_SCHEME = set(("data", "javascript"))

	ns = u"{http://purl.org/rss/1.0/}"
	ITEM_NAME = ns + "item"
	HREF_NAME = ns + "link"
	TITLE_NAME = ns + "title"

	def get_item(entry):
		"""Return a bookmarks item or None if not good"""
		title, href = None, None
		for child in entry.getchildren():
			if child.tag == HREF_NAME:
				href = child.text
				if not href or href.split(":", 1)[0].lower() in UNWANTED_SCHEME:
					return None
			if child.tag == TITLE_NAME:
				title = child.text
		return title and href and (title, href)

	for event, entry in ElementTree.iterparse(filename):
		if entry.tag != ITEM_NAME:
			continue
		item = get_item(entry)
		if item:
			yield item

if __name__ == '__main__':
	import os
	f = os.path.expanduser(EPHY_BOOKMARKS_FILE)
	print "Got ET # bookmarks:", len(list(parse_epiphany_bookmarks(f)))

########NEW FILE########
__FILENAME__ = evolution
# -*- coding: UTF-8 -*-
from __future__ import absolute_import

__kupfer_name__ = _("Evolution")
__kupfer_sources__ = ("ContactsSource", )
__kupfer_actions__ = ("NewMailAction", "SendFileByMail")
__description__ = _("Evolution contacts")
__version__ = "2010-02-14"
__author__ = "Francesco Marella, Karol BÄ™dkowski"

import evolution

from kupfer.objects import Action
from kupfer.objects import TextLeaf, UrlLeaf, RunnableLeaf, FileLeaf
from kupfer import utils
from kupfer.obj.apps import AppLeafContentMixin
from kupfer.obj.grouping import ToplevelGroupingSource
from kupfer.obj.contacts import ContactLeaf, EmailContact, email_from_leaf


class ComposeMail(RunnableLeaf):
	''' Create new mail without recipient '''
	def __init__(self):
		RunnableLeaf.__init__(self, name=_("Compose New Email"))

	def run(self):
		utils.spawn_async_notify_as("evolution.desktop",
		                           ['evolution', 'mailto:'])

	def get_description(self):
		return _("Compose a new message in Evolution")

	def get_icon_name(self):
		return "mail-message-new"


class NewMailAction(Action):
	''' Create new mail to selected leaf'''
	def __init__(self):
		Action.__init__(self, _('Compose Email'))

	def activate(self, leaf):
		self.activate_multiple((leaf, ))

	def activate_multiple(self, objects):
		recipients = ",".join(email_from_leaf(L) for L in objects)
		utils.spawn_async(["evolution", "mailto:%s" % recipients])

	def get_icon_name(self):
		return "mail-message-new"

	def item_types(self):
		yield ContactLeaf
		# we can enter email
		yield TextLeaf
		yield UrlLeaf

	def valid_for_item(self, item):
		return bool(email_from_leaf(item))


class SendFileByMail (Action):
	'''Create new e-mail and attach selected file'''
	def __init__(self):
		Action.__init__(self, _('Send in Email To...'))

	def activate(self, obj, iobj):
		self.activate_multiple((obj, ), (iobj, ))

	def activate_multiple(self, objects, iobjects):
		recipients = ",".join(email_from_leaf(I) for I in iobjects)
		attachlist = ["attach=%s" % L.object for L in objects]
		utils.spawn_async(["evolution",
			"mailto:%s?%s" % (recipients, "&".join(attachlist))])

	def item_types(self):
		yield FileLeaf
	def valid_for_item(self, item):
		return not item.is_dir()

	def requires_object(self):
		return True
	def object_types(self):
		yield ContactLeaf
		# we can enter email
		yield TextLeaf
		yield UrlLeaf
	def valid_object(self, iobj, for_item=None):
		return bool(email_from_leaf(iobj))

	def get_description(self):
		return _("Compose new message in Evolution and attach file")
	def get_icon_name(self):
		return "document-send"


class ContactsSource(AppLeafContentMixin, ToplevelGroupingSource):
	appleaf_content_id = 'evolution'

	def __init__(self, name=_("Evolution Address Book")):
		super(ContactsSource, self).__init__(name, "Contacts")

	def get_items(self):
		ebook_ = evolution.ebook.open_addressbook("default")
		if not ebook_:
			return
		for contact in ebook_.get_all_contacts():
			name = contact.get_property("full-name")
			email = contact.get_property("email-1")
			if email:
				yield EmailContact(email, name)

		yield ComposeMail()

	def should_sort_lexically(self):
		return True

	def get_description(self):
		return _("Evolution contacts")

	def get_icon_name(self):
		return "evolution"

	def provides(self):
		yield RunnableLeaf
		yield ContactLeaf


########NEW FILE########
__FILENAME__ = favorites
__kupfer_name__ = _("Favorites")
__kupfer_sources__ = ("FavoritesSource", )
__kupfer_actions__ = ("AddFavorite", "RemoveFavorite", )
__description__ = _("Mark commonly used items and store objects for later use")
__version__ = "2009-12-30"
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import weakref

from kupfer.objects import Leaf, Source, Action
from kupfer import puid

# NOTE: core import
from kupfer.core import learn


class FavoritesSource (Source):
	"""Keep a list of Leaves that the User may add and remove from"""
	instance = None
	def __init__(self):
		Source.__init__(self, _("Favorites"))
		## these are default favorites for new users
		self.references = [
				'<kupfer.plugin.core.contents.Help>',
				'<kupfer.plugin.core.contents.Preferences>',
			]

	def config_save(self):
		references = [puid.get_unique_id(F) for F in self.favorites]
		return {"favorites": references, "version": self.version}

	def config_save_name(self):
		return __name__

	def config_restore(self, state):
		self.references = state["favorites"]

	def _lookup_item(self, id_):
		itm = puid.resolve_unique_id(id_, excluding=self)
		if itm is None:
			return None
		return itm

	def _valid_item(self,  itm):
		if hasattr(itm, "is_valid") and not itm.is_valid():
			return False
		return True

	def _find_item(self, id_):
		itm = self._lookup_item(id_)
		if itm is None or not self._valid_item(itm):
			return None
		if puid.is_reference(id_):
			self.reference_table[id_] = itm
		else:
			self.persist_table[id_] = itm
		return itm

	def initialize(self):
		FavoritesSource.instance = self
		self.favorites = []
		self.persist_table = {}
		self.reference_table = weakref.WeakValueDictionary()
		self.mark_for_update()

	def _update_items(self):
		self.favorites = []
		self.mark_for_update()
		for id_ in self.references:
			if id_ in self.persist_table:
				self.favorites.append(self.persist_table[id_])
				continue
			if id_ in self.reference_table:
				self.favorites.append(self.reference_table[id_])
				continue
			itm = self._find_item(id_)
			if itm is None:
				self.output_debug("MISSING:", id_)
			else:
				self.favorites.append(itm)

	@classmethod
	def add(cls, itm):
		cls.instance._add(itm)

	def _add(self, itm):
		if self._has_item(itm):
			self._remove(itm)
		learn.add_favorite(itm)
		self.favorites.append(itm)
		self.references.append(puid.get_unique_id(itm))
		self.mark_for_update()

	@classmethod
	def has_item(cls, itm):
		return cls.instance._has_item(itm)

	def _has_item(self, itm):
		return itm in set(self.favorites)

	@classmethod
	def remove(cls, itm):
		if cls.has_item(itm):
			cls.instance._remove(itm)

	def _remove(self, itm):
		learn.remove_favorite(itm)
		self.favorites.remove(itm)
		id_ = puid.get_unique_id(itm)
		if id_ in self.references:
			self.references.remove(id_)
		else:
			for key, val in self.persist_table.iteritems():
				if val == itm:
					self.references.remove(key)
					self.persist_table.pop(key)
					break
		self.mark_for_update()

	def get_items(self):
		self._update_items()
		for fav in self.favorites:
			learn.add_favorite(fav)
		return reversed(self.favorites)

	def get_description(self):
		return _('Shelf of "Favorite" items')

	def get_icon_name(self):
		return "emblem-favorite"

	def provides(self):
		# returning nothing means it provides anything
		return ()

class AddFavorite (Action):
	# Rank down, since it applies everywhere
	rank_adjust = -15
	def __init__(self):
		Action.__init__(self, _("Add to Favorites"))
	def activate(self, leaf):
		FavoritesSource.add(leaf)
	def item_types(self):
		return (Leaf, )
	def valid_for_item(self, item):
		return not FavoritesSource.has_item(item)
	def get_description(self):
		return _("Add item to favorites shelf")
	def get_icon_name(self):
		return "list-add"

class RemoveFavorite (Action):
	rank_adjust = -15
	def __init__(self):
		Action.__init__(self, _("Remove from Favorites"))
	def activate(self, leaf):
		FavoritesSource.remove(leaf)
	def item_types(self):
		return (Leaf, )
	def valid_for_item(self, item):
		return FavoritesSource.has_item(item)
	def get_description(self):
		return _("Remove item from favorites shelf")
	def get_icon_name(self):
		return "list-remove"

########NEW FILE########
__FILENAME__ = fileactions
__kupfer_name__ = _("File Actions")
__kupfer_sources__ = ()
__kupfer_text_sources__ = ()
__kupfer_actions__ = (
		"MoveTo",
		"Rename",
		"CopyTo",
	)
__description__ = _("More file actions")
__version__ = ""
__author__ = "Ulrik"

import gio
import os
# since "path" is a very generic name, you often forget..
from os import path as os_path

from kupfer.objects import Action, FileLeaf, TextLeaf, TextSource
from kupfer.objects import OperationError
from kupfer import pretty


def _good_destination(dpath, spath):
	"""If directory path @dpath is a valid destination for file @spath
	to be copied or moved to.
	"""
	if not os_path.isdir(dpath):
		return False
	spath = os_path.normpath(spath)
	dpath = os_path.normpath(dpath)
	if not os.access(dpath, os.R_OK | os.W_OK | os.X_OK):
		return False
	cpfx = os_path.commonprefix((spath, dpath))
	if os_path.samefile(dpath, spath) or cpfx == spath:
		return False
	return True

class MoveTo (Action, pretty.OutputMixin):
	def __init__(self):
		Action.__init__(self, _("Move To..."))
	def has_result(self):
		return True
	def activate(self, leaf, obj):
		sfile = gio.File(leaf.object)
		bname = sfile.get_basename()
		dfile = gio.File(os_path.join(obj.object, bname))
		try:
			ret = sfile.move(dfile, flags=gio.FILE_COPY_ALL_METADATA)
			self.output_debug("Move %s to %s (ret: %s)" % (sfile, dfile, ret))
		except gio.Error, exc:
			raise OperationError(unicode(exc))
		else:
			return FileLeaf(dfile.get_path())

	def valid_for_item(self, item):
		return os.access(item.object, os.R_OK | os.W_OK)
	def requires_object(self):
		return True

	def item_types(self):
		yield FileLeaf
	def object_types(self):
		yield FileLeaf
	def valid_object(self, obj, for_item):
		return _good_destination(obj.object, for_item.object)
	def get_description(self):
		return _("Move file to new location")
	def get_icon_name(self):
		return "go-next"

class RenameSource (TextSource):
	"""A source for new names for a file;
	here we "autopropose" the source file's extension,
	but allow overriding it as well as renaming to without
	extension (either using a terminating space, or selecting the
	normal TextSource-returned string).
	"""
	def __init__(self, sourcefile):
		self.sourcefile = sourcefile
		name = _("Rename To...").rstrip(".")
		TextSource.__init__(self, name)

	def get_rank(self):
		# this should rank high
		return 100

	def get_items(self, text):
		if not text:
			return
		basename = os_path.basename(self.sourcefile.object)
		root, ext = os_path.splitext(basename)
		t_root, t_ext = os_path.splitext(text)
		if text.endswith(u" "):
			yield TextLeaf(text.rstrip())
		else:
			yield TextLeaf(text) if t_ext else TextLeaf(t_root + ext)

	def get_gicon(self):
		return self.sourcefile.get_gicon()

class Rename (Action, pretty.OutputMixin):
	def __init__(self):
		Action.__init__(self, _("Rename To..."))

	def has_result(self):
		return True
	def activate(self, leaf, obj):
		sfile = gio.File(leaf.object)
		dest = os_path.join(os_path.dirname(leaf.object), obj.object)
		dfile = gio.File(dest)
		try:
			ret = sfile.move(dfile)
			self.output_debug("Move %s to %s (ret: %s)" % (sfile, dfile, ret))
		except gio.Error, exc:
			raise OperationError(unicode(exc))
		else:
			return FileLeaf(dfile.get_path())

	def activate_multiple(self, objs, iobjs):
		raise NotImplementedError

	def item_types(self):
		yield FileLeaf
	def valid_for_item(self, item):
		return os.access(item.object, os.R_OK | os.W_OK)

	def requires_object(self):
		return True
	def object_types(self):
		yield TextLeaf

	def valid_object(self, obj, for_item):
		dest = os_path.join(os_path.dirname(for_item.object), obj.object)
		return os_path.exists(os_path.dirname(dest)) and \
				not os_path.exists(dest)

	def object_source(self, for_item):
		return RenameSource(for_item)

	def get_description(self):
		return None

class CopyTo (Action, pretty.OutputMixin):
	def __init__(self):
		Action.__init__(self, _("Copy To..."))

	def has_result(self):
		return True

	def _finish_callback(self, gfile, result, data):
		self.output_debug("Finished copying", gfile)
		dfile, ctx = data
		try:
			gfile.copy_finish(result)
		except gio.Error:
			ctx.register_late_error()
		else:
			ctx.register_late_result(FileLeaf(dfile.get_path()))

	def wants_context(self):
		return True

	def activate(self, leaf, iobj, ctx):
		sfile = gio.File(leaf.object)
		dpath = os_path.join(iobj.object, os_path.basename(leaf.object))
		dfile = gio.File(dpath)
		try:
			ret = sfile.copy_async(dfile, self._finish_callback,
					user_data=(dfile, ctx),
					flags=gio.FILE_COPY_ALL_METADATA)
			self.output_debug("Copy %s to %s (ret: %s)" % (sfile, dfile, ret))
		except gio.Error, exc:
			raise OperationError(unicode(exc))

	def item_types(self):
		yield FileLeaf
	def valid_for_item(self, item):
		return (not item.is_dir()) and os.access(item.object, os.R_OK)
	def requires_object(self):
		return True
	def object_types(self):
		yield FileLeaf
	def valid_object(self, obj, for_item):
		return _good_destination(obj.object, for_item.object)
	def get_description(self):
		return _("Copy file to a chosen location")

########NEW FILE########
__FILENAME__ = filezilla
# -*- coding: UTF-8 -*-

__kupfer_name__ = _("Filezilla")
__kupfer_sources__ = ("SitesSource", )
__kupfer_actions__ = ('OpeninFilezilla', )
__description__ = _("Show sites and handle ftp addresses by Filezilla")
__version__ = "2010-04-13"
__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"

import os
from xml.etree import cElementTree as ElementTree

from kupfer.obj.apps import AppLeafContentMixin
from kupfer.obj.base import Action
from kupfer.obj.grouping import ToplevelGroupingSource
from kupfer.obj.helplib import FilesystemWatchMixin
from kupfer.obj.objects import UrlLeaf, TextLeaf
from kupfer.obj import hosts
from kupfer import utils, icons


_SITEMANAGER_DIR = os.path.expanduser("~/.filezilla/")
_SITEMANAGER_FILE = "sitemanager.xml"
FILEZILLA_SITE_KEY = "FILEZILLA_SITE"


class Site(hosts.HostServiceLeaf):
	def __init__(self, name, host, descr, port, user, passwd, remotedir,
			entry_type):
		slots = {FILEZILLA_SITE_KEY: name,
				hosts.HOST_SERVICE_REMOTE_PATH_KEY: remotedir}
		hosts.HostServiceLeaf.__init__(self, name, host, 'ftp', descr, port,
				user, passwd, slots)
		self.entry_type = entry_type

	def get_gicon(self):
		return icons.ComposedIconSmall(self.get_icon_name(), "filezilla")


class OpeninFilezilla(Action):
	def __init__(self):
		Action.__init__(self, _("Open Site with Filezilla"))

	def activate(self, leaf, iobj=None):
		if isinstance(leaf, (UrlLeaf, TextLeaf)):
			utils.spawn_async(['filezilla', leaf.object])
		elif leaf.check_key(FILEZILLA_SITE_KEY):
			sessname = leaf.entry_type + '/' + leaf[hosts.HOST_NAME_KEY]
			utils.spawn_async(['filezilla', '-c', sessname])
		else:
			url = ['ftp://']
			if leaf.check_key(hosts.HOST_SERVICE_USER_KEY):
				url.append(leaf[hosts.HOST_SERVICE_USER_KEY])
				if leaf.check_key(hosts.HOST_SERVICE_PASS_KEY):
					url.append(':')
					url.append(leaf[hosts.HOST_SERVICE_PASS_KEY])
				url.append('@')
			url.append(leaf[hosts.HOST_ADDRESS_KEY])
			if leaf.check_key(hosts.HOST_SERVICE_PORT_KEY):
				url.append(':')
				url.append(leaf[hosts.HOST_SERVICE_PORT_KEY])
			if leaf.check_key(hosts.HOST_SERVICE_REMOTE_PATH_KEY):
				url.append(leaf[hosts.HOST_SERVICE_REMOTE_PATH_KEY])
			utils.spawn_async(['filezilla', ''.join(url)])

	def get_icon_name(self):
		return "filezilla"

	def item_types(self):
		yield hosts.HostLeaf
		yield UrlLeaf
		yield TextLeaf

	def valid_for_item(self, item):
		if isinstance(item, (UrlLeaf, TextLeaf)):
			return item.object.startswith('ftp')
		if item.check_key(hosts.HOST_SERVICE_NAME_KEY):
			if item[hosts.HOST_SERVICE_NAME_KEY] == 'ftp':
				return True
		return item.check_key(FILEZILLA_SITE_KEY)


class SitesSource (AppLeafContentMixin, ToplevelGroupingSource,
		FilesystemWatchMixin):
	appleaf_content_id = "filezilla"

	def __init__(self, name=_("Filezilla Sites")):
		ToplevelGroupingSource.__init__(self, name, "hosts")

	def initialize(self):
		ToplevelGroupingSource.initialize(self)
		self.monitor_token = self.monitor_directories(_SITEMANAGER_DIR)

	def monitor_include_file(self, gfile):
		return gfile and gfile.get_basename() == _SITEMANAGER_FILE

	def get_items(self):
		sm_file_path = os.path.join(_SITEMANAGER_DIR, _SITEMANAGER_FILE)
		if not os.path.isfile(sm_file_path):
			return
		try:
			tree = ElementTree.parse(sm_file_path)
			for server in tree.find('Servers').findall('Server'):
				host = get_xml_element_text(server, 'Host')
				if not host:
					continue
				port = get_xml_element_text(server, 'Port')
				etype = get_xml_element_text(server, 'Type')
				user = get_xml_element_text(server, 'User')
				passwd = get_xml_element_text(server, 'Pass')
				name = get_xml_element_text(server, 'Name')
				descr = get_xml_element_text(server, 'Comments')
				remote = get_xml_element_text(server, 'RemoteDir')
				if not descr:
					descr = '%s@%s' % (user, host) if user else host

				yield Site(name, host, descr, port, user, passwd, remote, etype)
		except StandardError, err:
			self.output_error(err)

	def get_description(self):
		return _("Sites from Filezilla")

	def get_icon_name(self):
		return "filezilla"

	def provides(self):
		yield Site


def get_xml_element_text(node, tag):
	'''Find @tag in childs of @node and return text from it.
	If @tag is not found - return None'''
	child = node.find(tag)
	if child is None:
		return None
	return child.text

########NEW FILE########
__FILENAME__ = firefox
# encoding: utf-8
from __future__ import with_statement

__kupfer_name__ = _("Firefox Bookmarks")
__kupfer_sources__ = ("BookmarksSource", )
__description__ = _("Index of Firefox bookmarks")
__version__ = "2010-05-14"
__author__ = "Ulrik, William Friesen, Karol BÄ™dkowski"

from contextlib import closing
import os
import itertools
import sqlite3

from kupfer import plugin_support
from kupfer.objects import Source
from kupfer.objects import UrlLeaf, Leaf
from kupfer.obj.apps import AppLeafContentMixin
from kupfer.obj.helplib import FilesystemWatchMixin
from kupfer.plugin import firefox_support


__kupfer_settings__ = plugin_support.PluginSettings(
	{
		"key": "load_history",
		"label": _("Include visited sites"),
		"type": bool,
		"value": True,
	},
)


class Tag(Leaf):
	def __init__(self, name, bookmarks):
		Leaf.__init__(self, bookmarks, name)

	def has_content(self):
		return bool(self.object)

	def content_source(self, alternate=False):
		return TaggedBookmarksSource(self)

	def get_description(self):
		return _("Firefox tag")


class TaggedBookmarksSource(Source):
	"""docstring for TaggedBookmarksSource"""
	def __init__(self, tag):
		Source.__init__(self, tag.name)
		self.tag = tag

	def get_items(self):
		for book in self.tag.object:
			yield UrlLeaf(book["uri"], book["title"] or book["uri"])


class BookmarksSource (AppLeafContentMixin, Source, FilesystemWatchMixin):
	appleaf_content_id = ("firefox", "iceweasel")
	def __init__(self):
		super(BookmarksSource, self).__init__(_("Firefox Bookmarks"))
		self._history = []
		self._version = 2

	def initialize(self):
		ff_home = firefox_support.get_firefox_home_file('')
		self.monitor_token = self.monitor_directories(ff_home)

	def monitor_include_file(self, gfile):
		return gfile and gfile.get_basename() == 'lock'

	def _get_ffx3_history(self):
		"""Query the firefox places database"""
		max_history_items = 25
		fpath = firefox_support.get_firefox_home_file("places.sqlite")
		if not (fpath and os.path.isfile(fpath)):
			return
		try:
			self.output_debug("Reading history from", fpath)
			with closing(sqlite3.connect(fpath, timeout=1)) as conn:
				c = conn.cursor()
				c.execute("""SELECT DISTINCT(url), title
				             FROM moz_places
				             ORDER BY visit_count DESC
				             LIMIT ?""",
				             (max_history_items,))
				return [UrlLeaf(url, title) for url, title in c]
		except sqlite3.Error:
			# Something is wrong with the database
			self.output_exc()

	def _get_ffx3_bookmarks(self, fpath):
		"""Parse Firefox' .json bookmarks backups"""
		from kupfer.plugin import firefox3_support
		self.output_debug("Parsing", fpath)
		bookmarks, tags = firefox3_support.get_bookmarks(fpath)
		for book in bookmarks:
			yield UrlLeaf(book["uri"], book["title"] or book["uri"])
		for tag, items in tags.iteritems():
			yield Tag(tag, items)

	def _get_ffx2_bookmarks(self, fpath):
		"""Parse Firefox' bookmarks.html"""
		self.output_debug("Parsing", fpath)
		bookmarks = firefox_support.get_bookmarks(fpath)
		for book in bookmarks:
			yield UrlLeaf(book["href"], book["title"])

	def get_items(self):
		# try to update the history file
		if __kupfer_settings__['load_history']:
			history_items = self._get_ffx3_history()
			if history_items is not None:
				self._history = history_items
		else:
			self._history = []

		# now try reading JSON bookmark backups,
		# with html bookmarks as backup
		dirloc = firefox_support.get_firefox_home_file("bookmarkbackups")
		fpath = None
		if dirloc:
			files = os.listdir(dirloc)
			if files:
				latest_file = (files.sort() or files)[-1]
				fpath = os.path.join(dirloc, latest_file)

		if fpath and os.path.splitext(fpath)[-1].lower() == ".json":
			try:
				json_bookmarks = list(self._get_ffx3_bookmarks(fpath))
			except Exception:
				# Catch JSON parse errors
				# different exception for cjson and json
				self.output_exc()
			else:
				return itertools.chain(self._history, json_bookmarks)

		fpath = firefox_support.get_firefox_home_file("bookmarks.html")
		if fpath:
			html_bookmarks = self._get_ffx2_bookmarks(fpath)
		else:
			self.output_error("No firefox bookmarks file found")
			html_bookmarks = []
		return itertools.chain(self._history, html_bookmarks)

	def get_description(self):
		return _("Index of Firefox bookmarks")
	def get_gicon(self):
		return self.get_leaf_repr() and self.get_leaf_repr().get_gicon()
	def get_icon_name(self):
		return "web-browser"
	def provides(self):
		yield UrlLeaf

########NEW FILE########
__FILENAME__ = firefox3_support
from __future__ import with_statement

try:
	import cjson
	json_decoder = cjson.decode
except ImportError:
	import json
	json_decoder = json.loads

def get_bookmarks(bookmarks_file):
	# construct and configure the parser
	if not bookmarks_file:
		return []

	with open(bookmarks_file) as f:
		content = f.read().decode("UTF-8")
		# HACK: Firefox' JSON writer leaves a trailing comma
		# HACK: at the end of the array, which no parser accepts
		if content.endswith(u"}]},]}"):
			content = content[:-6] + u"}]}]}"
		root = json_decoder(content)

	# make a dictionary of unique bookmarks
	bmap = {}

	def bmap_add(bmark, bmap):
		if bmark["id"] not in bmap:
			bmap[bmark["id"]] = bmark

	def bmap_add_tag(id_, tag, bmap):
		if not "tags" in bmap[id_]:
			bmap[id_]["tags"] = []
		else:
			print "Already in, gets tag:", tag
		bmap[id_]["tags"].append(tag)

	MOZ_CONTAINER = "text/x-moz-place-container"
	MOZ_PLACE = "text/x-moz-place"
	UNWANTED_SCHEME = ("data", "place", "javascript")

	def is_container(ch):
		return ch["type"] == MOZ_CONTAINER
	def is_bookmark(ch):
		return ch["type"] == MOZ_PLACE and ch.get("uri")
	def is_good(ch):
		return not ch["uri"].split(":", 1)[0] in UNWANTED_SCHEME

	# find toplevel subfolders and tag folders
	catalogs = []
	tagcatalogs = []
	for child in root["children"]:
		if child.get("root") == "tagsFolder":
			tagcatalogs.extend(child["children"])
		elif child.get("root"):
			catalogs.append(child)

	# visit all subfolders recursively
	visited = set()
	while catalogs:
		next = catalogs.pop()
		if next["id"] in visited:
			continue
		for child in next["children"]:
			if is_container(child):
				catalogs.append(child)
				tagcatalogs.append(child)
			elif is_bookmark(child) and is_good(child):
				bmap_add(child, bmap)
		visited.add(next["id"])

	# visit all tag folders
	tags_catalogs = {}
	for tag in tagcatalogs:
		items = []
		for bmark in tag["children"]:
			if is_bookmark(bmark) and is_good(bmark):
				bmap_add(bmark, bmap)
				bmap_add_tag(bmark["id"], tag["title"], bmap)
				items.append(bmark)
		if items:
			tags_catalogs[tag['title']] = items

	return bmap.values(), tags_catalogs

if __name__ == '__main__':
	import os
	import firefox_support

	dirloc = firefox_support.get_firefox_home_file("bookmarkbackups")
	fpath = None
	if dirloc:
		files = os.listdir(dirloc)
		if files:
			latest_file = (files.sort() or files)[-1]
			fpath = os.path.join(dirloc, latest_file)

	if fpath and os.path.splitext(fpath)[-1].lower() == ".json":
		bookmarks, tags = get_bookmarks(fpath)
		print "Parsed # bookmarks:", len(bookmarks)
		print "Parsed # tags:", len(tags)

########NEW FILE########
__FILENAME__ = firefox_support
# -*- coding: UTF-8 -*-

"""
Original file much thanks to
http://www.kylo.net/deli.py.txt

Modifications released under GPL v2 (or any later)
Ulrik Sverdrup <ulrik.sverdrup@gmail.com>
"""
import os

from ConfigParser import RawConfigParser
from HTMLParser import HTMLParser
 
def get_firefox_home_file(needed_file):
    for firefox_dir in (os.path.expanduser(p) for p in
			("~/.mozilla/firefox-3.5/", "~/.mozilla/firefox/")):
        if os.path.exists(firefox_dir):
            break
    else:
        # no break
        return None
    # here we leak firefox_dir
    config = RawConfigParser({"Default" : 0})
    config.read(os.path.join(firefox_dir, "profiles.ini"))
    path = None

    for section in config.sections():
        if config.has_option(section, "Default") and config.get(section, "Default") == "1":
            path = config.get (section, "Path")
            break
        elif path == None and config.has_option(section, "Path"):
            path = config.get (section, "Path")
        
    if path == None:
        return ""

    if path.startswith("/"):
        return os.path.join(path, needed_file)

    return os.path.join(firefox_dir, path, needed_file)


class BookmarksParser(HTMLParser):

	def __init__(self):
		# this is python: explicitly invoke base class constructor
		HTMLParser.__init__(self)
		self.inH3		= False
		self.inA		 = False
		self.tagCount	= 0
		self.tags		= []
		self.currentTag  = ""
		self.href		= ""
		self.description = ""
		self.ignore	  = ""
		
		self.debug = False
		self.all_items = []

	def setBaseTag(self, baseTag):
		self.tags.append(baseTag)

	def setIgnoreUrls(self, ignore):
		self.ignore = ignore
		
	# remove white space
	# remove apostrophes, quote, double-quotes, colons, commas
	def normalizeText(self, text):
		text = text.replace('\'', '')
		text = text.replace('"', '')
		text = text.replace('`', '')
		text = text.replace(':', '')
		text = text.replace(',', '')
		text = text.replace(' ', '')
		text = text.replace('	', '')
		return text

	def handle_starttag(self, tag, attrs):
		if tag == "a":
			self.inA = True
			for attr in attrs:
				if attr[0] == "href":
					self.href = attr[1]
					

		if tag == "h3":
			self.inH3 = True
			self.tagCount += 1

		if tag == "dl":
			pass
			#print "Entering folder list; tags are", self.tags

	def handle_endtag(self, tag):
		if tag == "h3":
			self.tags.append(self.currentTag)
			self.currentTag = ""
			self.inH3 = False

		if tag == "a":
			if self.debug == True:
				print
				print "href =", self.href
				print "description =", self.description
				print "tags =", self.tags
				
			# validate href
			validHref = True
			if len(self.href) == 0:
				validHref = False
			if not self.href.split(":")[0] in ["http", "https", "news", "ftp"]:
				validHref = False
			if self.href in self.ignore:
				validHref = False

			# actually post here, make sure there's a url to post
			if validHref:
				bookmark = {
					"href" : self.href,
					"title": self.description,
					"tags" : self.tags
				}
				self.all_items.append(bookmark)
			
			self.href = ""
			self.description = ""
			self.inA = False

		# exiting a dl means end of a bookmarks folder, pop the last tag off
		if tag == "dl":
			self.tags = self.tags[:-1]

	# handle any data: note that this will miss the "escaped" stuff
	# fix this by adding handle_charref, etc methods
	def handle_data(self, data):
		if self.inH3:
			self.currentTag += self.normalizeText(data)

		if self.inA:
			self.description += data

def get_bookmarks(bookmarks_file):
	"""
	Return a list of bookmarks (dictionaries)
	
	each bookmark has the keys:
	href: URL
	title: description
	tags: list of tags/the folder
	"""
	# construct and configure the parser
	if not bookmarks_file:
		return []
	if not os.path.isfile(bookmarks_file):
		return []
	parser = BookmarksParser()

	# initiate the parse; this will submit requests to delicious
	parser.feed(open(bookmarks_file).read())

	# cleanup
	parser.close()
	
	return parser.all_items

def main():
	# go forth
	fileloc = get_firefox_home_file("bookmarks.html")
	print fileloc
	print get_bookmarks(fileloc)

if __name__ == "__main__":
	main()

########NEW FILE########
__FILENAME__ = gajim
# -*- coding: UTF-8 -*-
__kupfer_name__ = _("Gajim")
__kupfer_sources__ = ("ContactsSource", )
__kupfer_actions__ = ("ChangeStatus", 'OpenChat')
__description__ = _("Access to Gajim Contacts")
__version__ = "2011-05-12"
__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"

import dbus

from kupfer import icons
from kupfer import plugin_support
from kupfer import pretty
from kupfer.objects import Leaf, Action, Source, AppLeaf
from kupfer.weaklib import dbus_signal_connect_weakly
from kupfer.obj.helplib import PicklingHelperMixin
from kupfer.obj.apps import AppLeafContentMixin
from kupfer.obj.grouping import ToplevelGroupingSource
from kupfer.obj.contacts import ContactLeaf, JabberContact, JABBER_JID_KEY 
		


plugin_support.check_dbus_connection()

_STATUSES = {
		'online':	_('Available'),
		'chat':		_('Free for Chat'),
		'away':		_('Away'),
		'xa':		_('Not Available'),
		'dnd':		_('Busy'),
		'invisible':_('Invisible'),
		'offline':	_('Offline')
}

_SERVICE_NAME = 'org.gajim.dbus'
_OBJECT_NAME = '/org/gajim/dbus/RemoteObject'
_IFACE_NAME = 'org.gajim.dbus.RemoteInterface'

GAJIM_ACCOUNT_KEY = "GAJIM_ACCOUNT"

def _create_dbus_connection(activate=False):
	''' Create dbus connection to Gajim 
		@activate: true=starts gajim if not running
	'''
	interface = None
	sbus = dbus.SessionBus()
	try:
		#check for running gajim (code from note.py)
		proxy_obj = sbus.get_object('org.freedesktop.DBus', '/org/freedesktop/DBus')
		dbus_iface = dbus.Interface(proxy_obj, 'org.freedesktop.DBus')
		if activate or dbus_iface.NameHasOwner('org.gajim.dbus'):
			obj = sbus.get_object('org.gajim.dbus', '/org/gajim/dbus/RemoteObject')
			if obj:
				interface = dbus.Interface(obj, 'org.gajim.dbus.RemoteInterface')

	except dbus.exceptions.DBusException, err:
		pretty.print_debug(err)

	return interface


def _check_gajim_version(conn):
	''' get gajim version. return list lika [0.12.5] '''
	prefs = conn.prefs_list()
	version = prefs['version']
	tversion = map(int, version.split('.'))
	if len(tversion) == 2:
		tversion += [0]
	elif len(tversion) > 3:
		# i.e. daily builds
		tversion = tversion[:3]
	return tversion


class GajimContact(JabberContact):
	def __init__(self, jid, name, status, resources, account):
		gajim_slots = { GAJIM_ACCOUNT_KEY: account }
		JabberContact.__init__(self, jid, name, status, resources, gajim_slots)

	def repr_key(self):
		return "".join((self.object[JABBER_JID_KEY], self.object[GAJIM_ACCOUNT_KEY]))

	def get_gicon(self):
		return icons.ComposedIconSmall(self.get_icon_name(), "gajim")


class AccountStatus(Leaf):
	pass


class OpenChat(Action):
	def __init__(self):
		Action.__init__(self, _('Open Chat'))

	def activate(self, leaf):
		interface = _create_dbus_connection()
		jid = JABBER_JID_KEY in leaf and leaf[JABBER_JID_KEY]
		account = leaf[GAJIM_ACCOUNT_KEY]
		if interface is not None:
			vmaj,vmin,vbuild = _check_gajim_version(interface)
			if vmaj == 0 and vmin < 13:
				interface.open_chat(jid, account)
			else:
				interface.open_chat(jid, account, '')

	def get_icon_name(self):
		return 'gajim'

	def item_types(self):
		yield ContactLeaf

	def valid_for_item(self, item):
		return GAJIM_ACCOUNT_KEY in item and item[GAJIM_ACCOUNT_KEY]


class ChangeStatus(Action):
	''' Change global status '''
	rank_adjust = 5

	def __init__(self):
		Action.__init__(self, _('Change Global Status To...'))

	def activate(self, leaf, iobj):
		interface = _create_dbus_connection((iobj.object != 'offline'))
		if interface:
			interface.change_status(iobj.object, '', '')

	def item_types(self):
		yield AppLeaf

	def valid_for_item(self, leaf):
		return leaf.get_id() == 'gajim'

	def requires_object(self):
		return True

	def object_types(self):
		yield AccountStatus

	def object_source(self, for_item=None):
		return StatusSource()


class ContactsSource(AppLeafContentMixin, ToplevelGroupingSource,
		PicklingHelperMixin):
	''' Get contacts from all on-line accounts in Gajim via DBus '''
	appleaf_content_id = 'gajim'

	def __init__(self, name=_('Gajim Contacts')):
		super(ContactsSource, self).__init__(name, "Contacts")
		self._version = 2
		self.unpickle_finish()

	def pickle_prepare(self):
		self._contacts = []

	def unpickle_finish(self):
		self.mark_for_update()
		self._contacts = []

	def initialize(self):
		ToplevelGroupingSource.initialize(self)
		# listen to d-bus signals for updates
		signals = [
			"ContactAbsence",
			"ContactPresence",
			"ContactStatus",
			"AccountPresence",
			"Roster",
			"RosterInfo",
		]

		session_bus = dbus.Bus()

		for signal in signals:
			dbus_signal_connect_weakly(session_bus, signal,
					self._signal_update, dbus_interface=_IFACE_NAME)

	def _signal_update(self, *args):
		"""catch all notifications to mark for update"""
		self.mark_for_update()

	def get_items(self):
		interface = _create_dbus_connection()
		if interface is not None:
			self._contacts = list(self._find_all_contacts(interface))
		else:
			self._contacts = []
		return self._contacts

	def _find_all_contacts(self, interface):
		for account in interface.list_accounts():
			if interface.get_status(account) == 'offline':
				continue

			for contact in interface.list_contacts(account):
				name = contact['name'] or contact['jid']
				resources = contact['resources'][0][0] if contact['resources'] else u''
				jc = GajimContact(contact['jid'], name, \
						_STATUSES.get(contact['show'], contact['show']), \
						resources, account)
				yield jc

	def get_icon_name(self):
		return 'gajim'

	def provides(self):
		yield ContactLeaf


class StatusSource(Source):
	def __init__(self):
		Source.__init__(self, _("Gajim Account Status"))

	def get_items(self):
		for status, name in _STATUSES.iteritems():
			yield AccountStatus(status, name)

	def provides(self):
		yield AccountStatus


########NEW FILE########
__FILENAME__ = glob
from __future__ import absolute_import
# TRANS: "Glob" is the matching files like a shell with "*.py" etc.
__kupfer_name__ = _("Glob")
__kupfer_actions__ = ("Glob",)
__description__ = ""
__version__ = ""
__author__ = "Ulrik"

import fnmatch
import re

from kupfer.objects import Action, TextLeaf, TextSource, Leaf, OperationError
from kupfer.obj.compose import MultipleLeaf

class Glob (Action):
	def __init__(self):
		Action.__init__(self, _("Glob"))

	def activate(self, obj, iobj):
		return self.activate_multiple((obj,), (iobj, ))

	def activate_multiple(self, objects, iobjects):
		## Do case-insentive matching
		## As a special case, understand '**/' prefix as recurive

		def get_subcatalog_matches(subcatalog, pat, recursive, paths):
			if len(paths) > 1000:
				raise OperationError("Globbing wayy too many objects")
			for content in subcatalog.content_source().get_leaves():
				if recursive and content.has_content():
					get_subcatalog_matches(content, pat, recursive, paths)
				else:
					if re.match(pat, unicode(content), flags=re.I):
						paths.append(content)
		paths = []
		for iobj in iobjects:
			glob = iobj.object
			if glob.startswith('**/'):
				glob = glob[3:]
				recursive = True
			else:
				recursive = False
			pat = fnmatch.translate(glob)
			for obj in objects:
				get_subcatalog_matches(obj, pat, recursive, paths)
		if paths:
			return MultipleLeaf(paths)

	def has_result(self):
		return True
	def item_types(self):
		yield Leaf
	def valid_for_item(self, item):
		return item.has_content()
	def requires_object(self):
		return True
	def object_types(self):
		yield TextLeaf
	def object_source(self, for_item=None):
		return TextSource()
	def valid_object(self, iobj, for_item):
		return (u'*' in iobj.object) or (u'?' in iobj.object)


########NEW FILE########
__FILENAME__ = gnome_terminal
__kupfer_name__ = _("GNOME Terminal Profiles")
__kupfer_sources__ = ("SessionsSource", )
__description__ = _("Launch GNOME Terminal profiles")
__version__ = ""
__author__ = "Chmouel Boudjnah <chmouel@chmouel.com>"

import os

import gconf
import glib

from kupfer.objects import Leaf, Action
from kupfer.obj.apps import ApplicationSource
from kupfer import utils, icons


GCONF_KEY = "/apps/gnome-terminal/profiles"


class Terminal(Leaf):
	""" Leaf represent profile saved in GNOME Terminal"""

	def __init__(self, name):
		Leaf.__init__(self, name, name)

	def get_actions(self):
		yield OpenSession()

	def get_icon_name(self):
		return "terminal"


class OpenSession(Action):
	""" Opens GNOME Terminal profile """
	def __init__(self):
		Action.__init__(self, _("Open"))

	def wants_context(self):
		return True

	def activate(self, leaf, ctx):
		utils.spawn_async(["gnome-terminal",
				   "--profile=%s" % leaf.object,
				   "--display=%s" % ctx.environment.get_display()],
				  in_dir=os.path.expanduser("~"))

	def get_gicon(self):
		return icons.ComposedIcon("gtk-execute", "terminal")


class SessionsSource(ApplicationSource):
	""" Yield GNOME Terminal profiles """
	appleaf_content_id = 'gnome-terminal'

	def __init__(self):
		ApplicationSource.__init__(self, name=_("GNOME Terminal Profiles"))

	def get_items(self):
		gc = gconf.client_get_default()
		try:
			if not gc.dir_exists(GCONF_KEY):
				return

			for entry in gc.all_dirs(GCONF_KEY):
				yield Terminal(gc.get_string("%s/visible_name" % entry))
		except glib.GError, err:
			self.output_error(err)

	def should_sort_lexically(self):
		return True

	def get_icon_name(self):
		return "terminal"

	def provides(self):
		yield Terminal


########NEW FILE########
__FILENAME__ = google_search
__kupfer_name__ = _("Google Search")
__kupfer_actions__ = ("Search", )
__description__ = _("Search Google with results shown directly")
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import httplib
import urllib

from kupfer.objects import Action, Source, OperationError
from kupfer.objects import TextLeaf, UrlLeaf
from kupfer.plugin import ssl_support

try:
	import cjson
	json_decoder = cjson.decode
except ImportError:
	import json
	json_decoder = json.loads


# Path uses API Key for Kupfer
SEARCH_HOST =  "ajax.googleapis.com"
SEARCH_PATH = ("/ajax/services/search/web?v=1.0&"
               "key=ABQIAAAAV3_egytv7qJVulO0KzPiVRQg95CfKdfDbUDlTS80sgrv"
               "_Zs39hRNkb5m7HV_qLx_d40GexmdjYGvcg&")

class Search (Action):
	def __init__(self):
		Action.__init__(self, _("Google Search"))

	def is_factory(self):
		return True
	def activate(self, leaf):
		return SearchResults(leaf.object)

	def item_types(self):
		yield TextLeaf

	def get_description(self):
		return __description__


class CustomDescriptionUrl (UrlLeaf):
	def __init__(self, obj, title, desc):
		UrlLeaf.__init__(self, obj, title)
		self.description = desc
	def get_description(self):
		return self.description

def _xml_unescape(ustr):
	"""Unescape &amp; to &, &lt; to <,  &gt; to >"""
	# important to replace &amp; last here
	return ustr.replace("&lt;", "<").replace("&gt;", ">").replace("&amp;", "&")

class SearchResults (Source):
	def __init__(self, query):
		Source.__init__(self, _('Results for "%s"') % query)
		self.query = query

	def repr_key(self):
		return self.query

	def get_items(self):
		try:
			query = urllib.urlencode({'q': self.query})
			if ssl_support.is_supported():
				conn = ssl_support.VerifiedHTTPSConnection(SEARCH_HOST,
				                                           timeout=5)
				self.output_debug("Connected to", SEARCH_HOST, "using SSL")
			else:
				conn = httplib.HTTPConnection(SEARCH_HOST, timeout=5)
			conn.request("GET", SEARCH_PATH + query)
			response = conn.getresponse()
			ctype = response.getheader("content-type", default="")
			parts = ctype.split("charset=", 1)
			encoding = parts[-1] if len(parts) > 1 else "UTF-8"
			search_results = response.read().decode(encoding)
			response.close()
		except (IOError, httplib.HTTPException) as exc:
			raise OperationError(unicode(exc))
		results = json_decoder(search_results)
		data = results['responseData']
		more_results_url = data['cursor']['moreResultsUrl']
		total_results = data['cursor'].get('estimatedResultCount', 0)
		for h in data['results']:
			uq_url = urllib.unquote(h['url'])
			uq_title = _xml_unescape(h['titleNoFormatting'])
			yield UrlLeaf(uq_url, uq_title)
		yield CustomDescriptionUrl(more_results_url,
				_('Show More Results For "%s"') % self.query,
				_("%s total found") % total_results)

	def provides(self):
		yield UrlLeaf


########NEW FILE########
__FILENAME__ = gtg
# -*- coding: UTF-8 -*-
__kupfer_name__ = _("Getting Things GNOME")
__kupfer_sources__ = ("TasksSource", )
__kupfer_actions__ = ("CreateNewTask",)
__description__ = _("Browse and create new tasks in GTG")
__version__ = "2010-05-27"
__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"


'''
Changes:
	2012-06-21 Karol BÄ™dkowski:
		* support new dbus api introduced in GTG 0.2.9
'''

import os

import dbus

from kupfer import plugin_support
from kupfer import pretty
from kupfer import textutils
from kupfer.obj.base import Leaf, Action, Source
from kupfer.obj.objects import TextLeaf
from kupfer.obj.apps import AppLeafContentMixin
from kupfer.obj.helplib import FilesystemWatchMixin

plugin_support.check_dbus_connection()

_SERVICE_NAME = 'org.GTG'
_OBJECT_NAME = '/org/GTG'
_IFACE_NAME = 'org.GTG'
_GTG_HOME = "~/.local/share/gtg/"
_SERVICE_NAME2 = 'org.gnome.GTG'
_OBJECT_NAME2 = '/org/gnome/GTG'
_IFACE_NAME2 = 'org.gnome.GTG'


def _create_dbus_connection_gtg(iface, obj, service, activate=False):
	''' Create dbus connection to GTG
		@activate: if True, start program if not running
	'''
	interface = None
	sbus = dbus.SessionBus()
	try:
		proxy_obj = sbus.get_object('org.freedesktop.DBus',
				'/org/freedesktop/DBus')
		dbus_iface = dbus.Interface(proxy_obj, 'org.freedesktop.DBus')
		if activate or dbus_iface.NameHasOwner(iface):
			obj = sbus.get_object(service, obj)
			if obj:
				interface = dbus.Interface(obj, iface)
	except dbus.exceptions.DBusException, err:
		pretty.print_debug(err)
	return interface


def _create_dbus_connection(activate=False):
	interface, apiver = _create_dbus_connection_gtg(_IFACE_NAME, _OBJECT_NAME,
			_SERVICE_NAME, activate), 1
	if interface is None:
		interface, apiver = _create_dbus_connection_gtg(_IFACE_NAME2,
				_OBJECT_NAME2, _SERVICE_NAME2, activate), 2
	if interface is None:
		pretty.print_error('Cannot connect to GTG via DBus')
	return interface, apiver


def _truncate_long_text(text, maxlen=80):
	if len(text) > maxlen:
		return text[:maxlen - 1] + u'â€¦'
	return text


def _load_tasks(interface, apiver):
	''' Load task by dbus interface '''
	if apiver == 1:
		tasks = interface.get_tasks()
	else:
		tasks = interface.GetTasks()
		if not tasks:
			tasks = interface.GetTasksFiltered("")
	for task in tasks:
		title = task['title'].strip()
		if not title:
			title = task['text'].strip()
		title = _truncate_long_text(title)
		otask = Task(task['id'], title, task['status'])
		otask.duedate = task['duedate']
		otask.startdate = task['startdate']
		otask.tags = task['tags']
		yield otask


def _change_task_status(task_id, status):
	interface, apiver = _create_dbus_connection(True)
	task = interface.get_task(task_id)
	task['status'] = status
	if apiver == 1:
		interface.modify_task(task_id, task)
	else:
		interface.ModifyTask(task_id, task)


class Task (Leaf):
	def __init__(self, task_id, title, status):
		Leaf.__init__(self, task_id, title)
		self.status = status
		self.tags = None
		self.duedate = None
		self.startdate = None

	def get_description(self):
		descr = [self.status]
		if self.duedate:
			descr.append(_("due: %s") % self.duedate)
		if self.startdate:
			descr.append(_("start: %s") % self.startdate)
		if self.tags:
			descr.append(_("tags: %s") % " ".join(self.tags))
		return "  ".join(descr)

	def get_icon_name(self):
		return 'gtg'

	def get_actions(self):
		yield OpenEditor()
		yield Delete()
		yield MarkDone()
		yield Dismiss()


class OpenEditor (Action):
	rank_adjust = 1

	def __init__(self):
		Action.__init__(self, _("Open"))

	def activate(self, leaf):
		interface, apiver = _create_dbus_connection(True)
		if apiver == 1:
			interface.open_task_editor(leaf.object)
		else:
			interface.OpenTaskEditor(leaf.object)

	def get_icon_name(self):
		return 'document-open'

	def get_description(self):
		return _("Open task in Getting Things GNOME!")


class Delete (Action):
	rank_adjust = -10

	def __init__(self):
		Action.__init__(self, _("Delete"))

	def activate(self, leaf):
		interface, apiver = _create_dbus_connection(True)
		if apiver:
			interface.delete_task(leaf.object)
		else:
			interface.DeleteTask(leaf.object)

	def get_icon_name(self):
		return 'edit-delete'

	def get_description(self):
		return _("Permanently remove this task")


class MarkDone (Action):
	def __init__(self):
		Action.__init__(self, _("Mark Done"))

	def activate(self, leaf):
		_change_task_status(leaf.object, 'Done')

	def get_icon_name(self):
		return 'gtk-yes'

	def get_description(self):
		return _("Mark this task as done")


class Dismiss (Action):
	def __init__(self):
		Action.__init__(self, _("Dismiss"))

	def activate(self, leaf):
		_change_task_status(leaf.object, 'Dismiss')

	def get_icon_name(self):
		return 'gtk-cancel'

	def get_description(self):
		return _("Mark this task as not to be done anymore")


class CreateNewTask (Action):
	def __init__(self):
		Action.__init__(self, _("Create Task"))

	def activate(self, leaf):
		interface, apiver = _create_dbus_connection(True)
		title, body = textutils.extract_title_body(leaf.object)
		if apiver == 1:
			interface.open_new_task(title, body)
		else:
			interface.OpenNewTask(title, body)

	def item_types(self):
		yield TextLeaf

	def get_icon_name(self):
		return 'document-new'

	def get_description(self):
		return _("Create new task in Getting Things GNOME")


class TasksSource (AppLeafContentMixin, Source, FilesystemWatchMixin):
	appleaf_content_id = 'gtg'

	def __init__(self, name=None):
		Source.__init__(self, name or __kupfer_name__)
		self._tasks = []
		self._version = 2

	def initialize(self):
		self.monitor_token = \
			self.monitor_directories(os.path.expanduser(_GTG_HOME))
		bus = dbus.Bus()
		self._signal_new_task = bus.add_signal_receiver(self._on_tasks_updated,
				signal_name="TaskAdded", dbus_interface=_IFACE_NAME2)
		self._signal_task_deleted = bus.add_signal_receiver(self._on_tasks_updated,
				signal_name="TaskDeleted", dbus_interface=_IFACE_NAME2)
		self._signal_task_modified = bus.add_signal_receiver(self._on_tasks_updated,
				signal_name="TaskModified", dbus_interface=_IFACE_NAME2)

	def finalize(self):
		bus = dbus.Bus()
		if self._signal_new_task is not None:
			bus.remove_signal_receiver(self._on_tasks_updated,
					signal_name="TaskAdded", dbus_interface=_IFACE_NAME2)
			bus.remove_signal_receiver(self._on_tasks_updated,
					signal_name="TaskDeleted", dbus_interface=_IFACE_NAME2)
			bus.remove_signal_receiver(self._on_tasks_updated,
					signal_name="TaskModified", dbus_interface=_IFACE_NAME2)

	def get_items(self):
		interface, apiver = _create_dbus_connection()
		if interface is not None:
			self._tasks = list(_load_tasks(interface, apiver))
		return self._tasks

	def get_icon_name(self):
		return 'gtg'

	def provides(self):
		yield Task

	def _on_tasks_updated(self, *argv, **kwarg):
		self.mark_for_update()

########NEW FILE########
__FILENAME__ = gwibber
# -*- coding: UTF-8 -*-
from __future__ import absolute_import
__kupfer_name__ = _("Gwibber")
__kupfer_sources__ = ("HomeMessagesSource", "AccountsSource", "StreamsSource")
__kupfer_actions__ = ("SendMessage", "SendMessageBy", "SendMessageTo")
__description__ = _("Microblogging with Gwibber. Allows sending and receiving "
                    "messages from social networks like Twitter, Identi.ca etc. "
                    "Requires the package 'gwibber-service'.")
__version__ = "2011-03-04"
__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"

import time
import locale
try:
	import cjson
	json_decoder = cjson.decode
	json_encoder = cjson.encode
except ImportError:
	import json
	json_decoder = json.loads
	json_encoder = json.dumps

import dbus
# quick test is gwibber-service installed
import gwibber.microblog

from kupfer import icons
from kupfer import pretty
from kupfer import plugin_support
from kupfer.objects import Action, TextLeaf, Source, Leaf, TextSource
from kupfer.obj.objects import OpenUrl
from kupfer.weaklib import dbus_signal_connect_weakly

plugin_support.check_dbus_connection()

DBUS_GWIBBER_SERVICE = ('com.Gwibber.Service', '/com/gwibber/Service')
DBUS_GWIBBER_ACCOUNTS = ('com.Gwibber.Accounts', '/com/gwibber/Accounts')
DBUS_GWIBBER_STREAMS = ('com.Gwibber.Streams', '/com/gwibber/Streams')
DBUS_GWIBBER_MESSAGES = ('com.Gwibber.Messages', '/com/gwibber/Messages')
DBUS_GWIBBER_SEARCH = ('com.Gwibber.Search', '/com/gwibber/Search')

__kupfer_settings__ = plugin_support.PluginSettings(
	{
		'key': 'load_limit',
		'label': _("Maximum number of messages to show"),
		'type': int,
		'value': 25,
	}
)


def _get_dbus_iface(service_objname, activate=False):
	interface = None
	sbus = dbus.SessionBus()
	service, objname = service_objname
	try:
		proxy_obj = sbus.get_object('org.freedesktop.DBus',
				'/org/freedesktop/DBus')
		dbus_iface = dbus.Interface(proxy_obj, 'org.freedesktop.DBus')
		if activate or dbus_iface.NameHasOwner(service):
			obj = sbus.get_object(service, objname)
			if obj:
				interface = dbus.Interface(obj, service)
	except dbus.exceptions.DBusException, err:
		pretty.print_debug(err)
	return interface


def _get_messages_for_account(stream, account, transient='0'):
	conn = _get_dbus_iface(DBUS_GWIBBER_SERVICE, True)
	if not conn:
		return
	services = json_decoder(conn.GetServices())
	conn = _get_dbus_iface(DBUS_GWIBBER_STREAMS)
	if not conn:
		return
	result = conn.Messages(stream, account, 0, '0', transient, 'time', 'desc',
			__kupfer_settings__['load_limit'])
	for msg in json_decoder(result):
		yield Message(msg['text'], msg, services[msg['service']])


def _gwibber_refresh(conn=None):
	conn = conn or _get_dbus_iface(DBUS_GWIBBER_SERVICE, True)
	if conn:
		conn.Refresh()


def _trunc_message(message):
	return message[:139] + 'â€¦' if len(message) > 140 else message


class Account(Leaf):
	def __init__(self, account, service_name, show_content=True):
		Leaf.__init__(self, account['id'], service_name)
		self._show_content = show_content
		# TRANS: Account description, similar to "John on Identi.ca"
		self._description = _("%(user)s on %(service)s") % {
				'user': account.get('site_display_name') or account['username'],
				'service': account['service']}

	def repr_key(self):
		return self.object

	def get_icon_name(self):
		return 'gwibber'

	def has_content(self):
		return self._show_content

	def content_source(self, alternate=False):
		return MessagesSource(self.object, self.name)

	def get_description(self):
		return self._description


class Stream(Leaf):
	def __init__(self, name, id_, account):
		Leaf.__init__(self, id_, name)
		self.account = account

	def repr_key(self):
		return self.object

	def get_icon_name(self):
		return 'gwibber'

	def has_content(self):
		return True

	def content_source(self, alternate=False):
		return StreamMessagesSource(self)

def unicode_strftime(fmt, time_tuple=None):
	enc = locale.getpreferredencoding(False)
	return unicode(time.strftime(fmt, time_tuple), enc, "replace")

class Message (Leaf):
	def __init__(self, text, msg, service):
		Leaf.__init__(self, text, text)
		self.id = msg['id']
		self.msg_url = msg.get('url')
		self.msg_sender = msg['sender']['nick'] if 'nick' in msg['sender'] \
				else msg['sender']['name']
		self._service_features = list(service['features'])
		self._is_my_msg = bool(msg['sender']['is_me'])
		sender = unicode(msg['sender'].get('name') or msg['sender']['nick'])
		date = unicode_strftime('%c', time.localtime(msg['time']))
		# TRANS: Gwibber Message description
		# TRANS: Similar to "John  May 5 2011 11:40 on Identi.ca"
		# TRANS: the %(user)s and similar tokens must be unchanged
		self._description = _("%(user)s %(when)s on %(where)s") % {
				'user': sender, 'when': date, 'where': service['name']}

	def repr_key(self):
		return self.id

	def get_actions(self):
		service_features = self._service_features
		if self._is_my_msg:
			if 'delete' in service_features:
				yield DeleteMessage()
		else:
			if 'reply' in service_features:
				yield Reply()
			if 'send_private' in service_features:
				yield SendPrivate()
			if 'retweet' in service_features:
				yield Retweet()
				yield Retweet(True)
		if self.msg_url:
			yield OpenMessageUrl()

	def get_description(self):
		return self._description

	def get_text_representation(self):
		return self.object

	def get_gicon(self):
		return icons.ComposedIcon("gwibber", "stock_mail")


class SendMessage(Action):
	def __init__(self):
		Action.__init__(self, _('Send Message'))

	def activate(self, leaf):
		conn = _get_dbus_iface(DBUS_GWIBBER_SERVICE, True)
		if conn:
			conn.SendMessage(_trunc_message(leaf.object))
			_gwibber_refresh()

	def item_types(self):
		yield TextLeaf

	def valid_for_item(self, item):
		return bool(item.object)

	def get_gicon(self):
		return icons.ComposedIcon("gwibber", "mail-message-new")

	def get_description(self):
		return _("Send message to all Gwibber accounts")


class SendMessageBy(Action):
	def __init__(self):
		Action.__init__(self, _("Send Message To..."))

	def activate(self, leaf, iobj):
		conn = _get_dbus_iface(DBUS_GWIBBER_SERVICE, True)
		if conn:
			msg = {'message': _trunc_message(leaf.object), 'accounts': [iobj.object]}
			conn.Send(json_encoder(msg))
			_gwibber_refresh()

	def item_types(self):
		yield TextLeaf

	def valid_for_item(self, item):
		return bool(item.object)

	def requires_object(self):
		return True

	def object_types(self):
		yield Account

	def object_source(self, for_item=None):
		return SendToAccountSource('send')

	def get_gicon(self):
		return icons.ComposedIcon("gwibber", "mail-message-new")

	def get_description(self):
		return _("Send message to a Gwibber account")


class SendMessageTo(Action):
	def __init__(self):
		Action.__init__(self, _("Send Message..."))

	def activate(self, leaf, iobj):
		conn = _get_dbus_iface(DBUS_GWIBBER_SERVICE, True)
		if conn:
			msg = {'message': _trunc_message(iobj.object),
					'accounts': [leaf.object]}
			conn.Send(json_encoder(msg))
			_gwibber_refresh()

	def item_types(self):
		yield Account

	def requires_object(self):
		return True

	def object_source(self, for_item=None):
		return TextSource()

	def object_types(self):
		yield TextLeaf

	def valid_object(self, iobj, for_item=None):
		# ugly, but we don't want derived text
		return type(iobj) is TextLeaf

	def get_gicon(self):
		return icons.ComposedIcon("gwibber", "mail-message-new")

	def get_description(self):
		return _("Send message to selected Gwibber account")


class Reply(Action):
	def __init__(self):
		Action.__init__(self, _("Reply..."))

	def activate(self, leaf, iobj):
		conn = _get_dbus_iface(DBUS_GWIBBER_MESSAGES, True)
		if not conn:
			return
		rmsg = json_decoder(conn.Get(leaf.id))
		text = '@%s: %s' % (rmsg['sender']['nick'], iobj.object)
		msg = {'message': _trunc_message(text), 'target': rmsg}
		conn = _get_dbus_iface(DBUS_GWIBBER_SERVICE)
		if conn:
			conn.Send(json_encoder(msg))
			_gwibber_refresh()

	def item_types(self):
		yield Message

	def requires_object(self):
		return True

	def object_source(self, for_item=None):
		return TextSource()

	def object_types(self):
		yield TextLeaf

	def valid_object(self, iobj, for_item=None):
		# ugly, but we don't want derived text
		return type(iobj) is TextLeaf

	def get_gicon(self):
		return icons.ComposedIcon("gwibber", "mail-reply-all")


class DeleteMessage(Action):
	def __init__(self):
		Action.__init__(self, _("Delete Message"))

	def activate(self, leaf):
		conn = _get_dbus_iface(DBUS_GWIBBER_MESSAGES, True)
		if not conn:
			return
		rmsg = json_decoder(conn.Get(leaf.id))
		cmd = {'transient': False, 'account': rmsg['account'],
				'operation': 'delete', 'args': {'message': rmsg}}
		conn = _get_dbus_iface(DBUS_GWIBBER_SERVICE)
		if conn:
			conn.PerformOp(json_encoder(cmd))
			_gwibber_refresh(conn)

	def item_types(self):
		yield Message

	def get_gicon(self):
		return icons.ComposedIcon("gwibber", "stock_delete")


class SendPrivate(Action):
	def __init__(self):
		Action.__init__(self, _("Send Private Message..."))

	def activate(self, leaf, iobj):
		conn = _get_dbus_iface(DBUS_GWIBBER_MESSAGES, True)
		if not conn:
			return
		rmsg = json_decoder(conn.Get(leaf.id))
		msg = {'message': _trunc_message(iobj.object), 'private': rmsg}
		conn = _get_dbus_iface(DBUS_GWIBBER_SERVICE)
		if conn:
			conn.Send(json_encoder(msg))
			_gwibber_refresh()

	def item_types(self):
		yield Message

	def requires_object(self):
		return True

	def object_source(self, for_item=None):
		return TextSource()

	def object_types(self):
		yield TextLeaf

	def valid_object(self, iobj, for_item=None):
		# ugly, but we don't want derived text
		return type(iobj) is TextLeaf

	def get_gicon(self):
		return icons.ComposedIcon("gwibber", "mail-reply-sender")

	def get_description(self):
		return _("Send direct message to user")


class Retweet(Action):
	def __init__(self, retweet_to_all=False):
		self._retweet_to_all = retweet_to_all
		name = _("Retweet") if retweet_to_all else _("Retweet To...")
		Action.__init__(self, name)

	def activate(self, leaf, iobj=None):
		conn = _get_dbus_iface(DBUS_GWIBBER_SERVICE, True)
		if conn:
			text = 'â™º @%s: %s' % (leaf.msg_sender, leaf.object)
			if iobj:
				msg = {'message': _trunc_message(text), 'accounts': [iobj.object]}
				conn.Send(json_encoder(msg))
			else:
				conn.SendMessage(_trunc_message(text))
			_gwibber_refresh()

	def item_types(self):
		yield Message

	def requires_object(self):
		return not self._retweet_to_all

	def object_types(self):
		yield Account

	def object_source(self, for_item=None):
		return SendToAccountSource('retweet')

	def get_gicon(self):
		return icons.ComposedIcon("gwibber", "mail-message-forward")

	def get_description(self):
		if self._retweet_to_all:
			return _("Retweet message to all Gwibber accounts")
		return _("Retweet message to a Gwibber account")


class OpenMessageUrl(OpenUrl):
	def __init__(self):
		OpenUrl.__init__(self, _("Open in Browser"))

	def activate(self, leaf):
		self.open_url(leaf.msg_url)

	def get_description(self):
		return _("Open message in default web browser")


class AccountsSource(Source):
	source_user_reloadable = True

	def __init__(self, name=_("Gwibber Accounts")):
		Source.__init__(self, name)

	def initialize(self):
		session_bus = dbus.Bus()
		for signal in ('Created', 'Updated', 'Deleted'):
			dbus_signal_connect_weakly(session_bus, signal,
					self._signal_update, dbus_interface=DBUS_GWIBBER_ACCOUNTS[0])

	def _signal_update(self, *args):
		self.mark_for_update()

	def get_items(self):
		conn = _get_dbus_iface(DBUS_GWIBBER_SERVICE, True)
		if not conn:
			return
		services = json_decoder(conn.GetServices())
		del conn
		if not services:
			return
		conn = _get_dbus_iface(DBUS_GWIBBER_ACCOUNTS, True)
		if conn:
			accounts = json_decoder(conn.List())
			for account in accounts:
				service = services[account['service']]
				yield Account(account, service['name'])

	def get_icon_name(self):
		return 'gwibber'

	def get_description(self):
		return _("Accounts configured in Gwibber")

	def provides(self):
		yield Account


class SendToAccountSource(Source):
	def __init__(self, required_feature=None, name=_("Gwibber Accounts")):
		Source.__init__(self, name)
		self._required_feature = required_feature

	def get_items(self):
		conn = _get_dbus_iface(DBUS_GWIBBER_SERVICE, True)
		if not conn:
			return
		services = json_decoder(conn.GetServices())
		conn = _get_dbus_iface(DBUS_GWIBBER_ACCOUNTS, True)
		if conn:
			for account in json_decoder(conn.List()):
				aservice = account['service']
				if aservice not in services:
					continue
				service = services[aservice]
				if not self._required_feature or \
						self._required_feature in service['features']:
					yield Account(account, service['name'], False)

	def get_icon_name(self):
		return 'gwibber'

	def provides(self):
		yield Account


class HomeMessagesSource(Source):
	# we don't connect to "gwibber" app as long we only need "gwibber-service".
	source_user_reloadable = True
	source_prefer_sublevel = True

	def __init__(self, name=_("Gwibber Messages")):
		Source.__init__(self, name)

	def initialize(self):
		session_bus = dbus.Bus()
		dbus_signal_connect_weakly(session_bus, 'Message',
				self._signal_update, dbus_interface=DBUS_GWIBBER_MESSAGES[0])
		dbus_signal_connect_weakly(session_bus, 'LoadingComplete',
				self._signal_update, dbus_interface=DBUS_GWIBBER_SERVICE[0])
		for signal in ('Created', 'Updated', 'Deleted'):
			dbus_signal_connect_weakly(session_bus, signal,
					self._signal_update, dbus_interface=DBUS_GWIBBER_STREAMS[0])

	def _signal_update(self, *args):
		self.mark_for_update()

	def get_items(self):
		return _get_messages_for_account('messages', 'all')

	def get_icon_name(self):
		return 'gwibber'

	def get_description(self):
		return _("Recent messages received by Gwibber")

	def provides(self):
		yield Message


class MessagesSource(Source):
	def __init__(self, account, service):
		# TRANS:  %s is a service name
		Source.__init__(self, _("Gwibber Messages for %s") % service)
		self.account = account

	def get_items(self):
		return _get_messages_for_account('messages', self.account)

	def get_icon_name(self):
		return 'gwibber'

	def provides(self):
		yield Message


class StreamsSource(Source):
	source_user_reloadable = True

	def __init__(self, name=_("Gwibber Streams")):
		Source.__init__(self, name)

	def initialize(self):
		session_bus = dbus.Bus()
		for signal in ('Created', 'Updated', 'Deleted'):
			dbus_signal_connect_weakly(session_bus, signal,
					self._signal_update, dbus_interface=DBUS_GWIBBER_STREAMS[0])
		_gwibber_refresh()

	def _signal_update(self, *args):
		self.mark_for_update()

	def get_items(self):
		conn = _get_dbus_iface(DBUS_GWIBBER_STREAMS, True)
		if conn:
			for stream in json_decoder(conn.List()):
				yield Stream(stream['name'], stream['id'], stream['account'])

	def get_icon_name(self):
		return 'gwibber'

	def get_description(self):
		return _("Streams configured in Gwibber")

	def provides(self):
		yield Stream

class StreamMessagesSource(Source):
	def __init__(self, stream):
		# TRANS: Gwibber messages in %s :: %s is a Stream name
		Source.__init__(self, _("Gwibber Messages in %s") % stream.name)
		self._account = stream.account
		self._stream_id = stream.object

	def get_items(self):
		conn = _get_dbus_iface(DBUS_GWIBBER_STREAMS, True)
		if conn:
			return _get_messages_for_account('all', self._account, self._stream_id)

	def get_icon_name(self):
		return 'gwibber'

	def provides(self):
		yield Message



########NEW FILE########
__FILENAME__ = gwibber_simple
from __future__ import absolute_import

__kupfer_name__ = _("Gwibber (Simple)")
__kupfer_actions__ = (
		"SendUpdate",
	)
__description__ = _("Send updates via the microblogging client Gwibber")
__version__ = ""
__author__ = ""

import dbus

from kupfer.objects import Action, TextLeaf, OperationError
from kupfer import plugin_support
from kupfer import pretty

plugin_support.check_dbus_connection()

SERVICE_NAME = "com.Gwibber.Service"
OBJ_NAME = "/com/gwibber/Service"
IFACE_NAME = "com.Gwibber.Service"


def _get_interface(activate=False):
	"""Return the dbus proxy object for our Note Application.

	if @activate, we will activate it over d-bus (start if not running)
	"""
	bus = dbus.SessionBus()
	proxy_obj = bus.get_object('org.freedesktop.DBus', '/org/freedesktop/DBus')
	dbus_iface = dbus.Interface(proxy_obj, 'org.freedesktop.DBus')

	if not activate and not dbus_iface.NameHasOwner(SERVICE_NAME):
		return

	try:
		proxyobj = bus.get_object(SERVICE_NAME, OBJ_NAME)
	except dbus.DBusException, e:
		pretty.print_error(__name__, e)
		return
	return dbus.Interface(proxyobj, IFACE_NAME)

class SendUpdate (Action):
	def __init__(self):
		Action.__init__(self, _("Send Update"))

	def wants_context(self):
		return True

	def activate(self, leaf, ctx):
		def success_cb():
			pretty.print_debug(__name__, "Successful D-Bus method call")

		def err_cb(exc):
			exc_info = (type(exc), exc, None)
			ctx.register_late_error(exc_info)

		gwibber = _get_interface(True)
		if gwibber:
			gwibber.SendMessage(leaf.object,
			                    reply_handler=success_cb, error_handler=err_cb)
		else:
			pretty.print_error(__name__, "Gwibber Service not found as:",
			                   (SERVICE_NAME, OBJ_NAME, IFACE_NAME))
			raise OperationError(_("Unable to activate Gwibber service"))

	def item_types(self):
		yield TextLeaf

	def get_description(self):
		return __description__


########NEW FILE########
__FILENAME__ = higherorder
__kupfer_name__ = _("Higher-order Actions")
__kupfer_actions__ = (
	"Select",
	"TakeResult",
	"DiscardResult",
)
__description__ = _("Tools to work with commands as objects")
__version__ = "2010-01-11"
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

from kupfer.objects import Action, Leaf
from kupfer.obj.compose import ComposedLeaf, MultipleLeaf
from kupfer.core import commandexec
from kupfer import pretty


class Select (Action):
	rank_adjust = -15
	def __init__(self):
		Action.__init__(self, _("Select in Kupfer"))

	def has_result(self):
		return True
	def activate(self, leaf):
		return leaf
	def item_types(self):
		yield Leaf

def _exec_no_show_result(composedleaf):
	pretty.print_debug(__name__, "Evaluating command", composedleaf)
	obj, action, iobj = composedleaf.object
	ret = commandexec.activate_action(None, *composedleaf.object)
	result_type = commandexec.parse_action_result(action, ret)
	if result_type == commandexec.RESULT_OBJECT:
		return ret
	if result_type == commandexec.RESULT_SOURCE:
		leaves = list(ret.get_leaves())
		if not leaves:
			return
		if len(leaves) == 1:
			return leaves[0]
		else:
			return MultipleLeaf(leaves)


def _save_result(cleaf):
	# Save the result of @cleaf into a ResultObject
	# When the ResultObject is to be restored from serialized state,
	# @cleaf is executed again.
	# NOTE: This will have unintended consequences outside Trigger use.
	leaf = _exec_no_show_result(cleaf)
	if leaf is None:
		return None
	class ResultObject (Leaf):
		serializable = 1
		def __init__(self, leaf, cleaf):
			Leaf.__init__(self, leaf.object, unicode(leaf))
			vars(self).update(vars(leaf))
			self.name = _("Result of %s (%s)") % (cleaf, self)
			self.__composed_leaf = cleaf
			self.__class__.__bases__ = (leaf.__class__, Leaf)

		def get_gicon(self):
			return None
		def get_icon_name(self):
			return Leaf.get_icon_name(self)

		def __reduce__(self):
			return (_save_result, (self.__composed_leaf, ))
	return ResultObject(leaf, cleaf)


class TakeResult (Action):
	def __init__(self):
		Action.__init__(self, _("Run (Take Result)"))

	def has_result(self):
		return True
	def activate(self, leaf):
		return _save_result(leaf)

	def item_types(self):
		yield ComposedLeaf
	def valid_for_item(self, leaf):
		action = leaf.object[1]
		return ((action.has_result() or
		         action.is_factory()) and
		         not action.wants_context())
	def get_description(self):
		return _("Take the command result as a proxy object")

class DiscardResult (Action):
	"""Run ComposedLeaf without showing the result"""
	def __init__(self):
		Action.__init__(self, _("Run (Discard Result)"))

	def wants_context(self):
		return True

	def activate(self, leaf, ctx):
		commandexec.activate_action(ctx, *leaf.object)
	def item_types(self):
		yield ComposedLeaf
	def valid_for_item(self, leaf):
		action = leaf.object[1]
		return action.has_result() or action.is_factory()
	def get_description(self):
		return None


########NEW FILE########
__FILENAME__ = image
__kupfer_name__ = _("Image Tools")
__kupfer_sources__ = ()
__kupfer_text_sources__ = ()
__kupfer_actions__ = (
		"Scale",
		"Rotate90",
		"Rotate270",
		"Autorotate",
	)
__description__ = _("Image transformation tools")
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

# since "path" is a very generic name, you often forget..
from os import path as os_path
import subprocess

from kupfer.objects import Action, FileLeaf, TextLeaf
from kupfer import utils, pretty
from kupfer import runtimehelper


class Scale (Action):
	def __init__(self):
		Action.__init__(self, _("Scale..."))

	def has_result(self):
		return True

	def wants_context(self):
		return True

	def activate(self, leaf, obj, ctx):
		size = self._make_size(obj.object)
		fpath = leaf.object
		dirname = os_path.dirname(fpath)
		head, ext = os_path.splitext(os_path.basename(fpath))
		filename = "%s_%s%s" % (head, size, ext)
		dpath = utils.get_destpath_in_directory(dirname, filename)
		argv = ["convert", "-scale", ('%s' % size),  fpath, dpath]
		runtimehelper.register_async_file_result(ctx, dpath)
		utils.spawn_async(argv)
		return FileLeaf(dpath)

	def item_types(self):
		yield FileLeaf

	def valid_for_item(self, item):
		# FIXME: Make this detection smarter
		root, ext = os_path.splitext(item.object)
		return ext.lower() in (".jpeg", ".jpg", ".png", ".gif")

	def requires_object(self):
		return True

	def object_types(self):
		yield TextLeaf

	@classmethod
	def _make_size(self, text):
		size = None
		try:
			size = "%g" % float(text.strip())
		except ValueError:
			try:
				twoparts = text.split("x", 1)
				size = "%gx%g" % (float(twoparts[0].strip()),
						float(twoparts[1].strip()))
			except ValueError:
				pass
		return size

	def valid_object(self, obj, for_item=None):
		return self._make_size(obj.object)

	def get_description(self):
		return _("Scale image to fit inside given pixel measure(s)")

class RotateBase (Action):
	def __init__(self, name, rotation):
		Action.__init__(self, name)
		self.rotation = rotation

	def has_result(self):
		return True

	def wants_context(self):
		return True

	def activate(self, leaf, ctx):
		fpath = leaf.object
		dirname = os_path.dirname(fpath)
		head, ext = os_path.splitext(os_path.basename(fpath))
		filename = "%s_%s%s" % (head, self.rotation, ext)
		dpath = utils.get_destpath_in_directory(dirname, filename)
		argv = ["jpegtran", "-copy", "all", "-rotate", self.rotation, "-outfile",
		        dpath, fpath]
		runtimehelper.register_async_file_result(ctx, dpath)
		utils.spawn_async(argv)
		return FileLeaf(dpath)

	def item_types(self):
		yield FileLeaf

	def valid_for_item(self, item):
		# FIXME: Make this detection smarter
		root, ext = os_path.splitext(item.object)
		return ext.lower() in (".jpeg", ".jpg")

class Rotate90 (RotateBase):
	def __init__(self):
		RotateBase.__init__(self, _("Rotate Clockwise"), "90")

	def get_icon_name(self):
		return "object-rotate-right"

class Rotate270 (RotateBase):
	def __init__(self):
		RotateBase.__init__(self, _("Rotate Counter-Clockwise"), "270")

	def get_icon_name(self):
		return "object-rotate-left"

class Autorotate (Action):
	def __init__(self):
		Action.__init__(self, _("Autorotate"))

	def has_result(self):
		return True

	def activate(self, leaf, obj=None):
		fpath = leaf.object
		argv = ['jhead', '-autorot', fpath]
		utils.spawn_async(argv)

	def item_types(self):
		yield FileLeaf

	def valid_for_item(self, item):
		root, ext = os_path.splitext(item.object)
		if not ext.lower() in (".jpeg", ".jpg"):
			return False
		# Launch jhead to see if 1) it is installed, 2) Orientation nondefault
		try:
			cmdargs = ("jhead", item.object)
			proc = subprocess.Popen(cmdargs, stdout=subprocess.PIPE)
		except OSError:
			pretty.print_debug(__name__ , "Action %s needs 'jhead'" % self)
		else:
			out, err = proc.communicate()
			pretty.print_debug(__name__, "Running", cmdargs)
			return any(li.startswith("Orientation") for li in out.splitlines())

	def get_description(self):
		return _("Rotate JPEG (in-place) according to its EXIF metadata")


########NEW FILE########
__FILENAME__ = kupfer_plugins
__kupfer_name__ = _("Kupfer Plugins")
__kupfer_sources__ = ("KupferPlugins", )
__description__ = _("Access Kupfer's plugin list in Kupfer")
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import os

from kupfer.objects import Action, Source, Leaf, FileLeaf, TextLeaf
from kupfer import kupferui

# Since this is a core plugin we break some rules
# These modules are normally out of bounds for plugins
from kupfer.core import plugins, settings


class ShowInfo (Action):
	def __init__(self):
		Action.__init__(self, _("Show Information"))

	def wants_context(self):
		return True

	def activate(self, leaf, ctx):
		plugin_id = leaf.object["name"]
		kupferui.show_plugin_info(plugin_id, ctx.environment)

	def get_description(self):
		pass
	def get_icon_name(self):
		return "dialog-information"

class ShowSource (Action):
	def __init__(self):
		Action.__init__(self, _("Show Source Code"))

	def has_result(self):
		return True
	def activate(self, leaf):
		# Try to find the __file__ attribute for the plugin
		# It will fail for files inside zip packages, but that is
		# uncommon for now.
		# Additionally, it will fail for fake plugins
		plugin_id = leaf.object["name"]
		filename = plugins.get_plugin_attribute(plugin_id, "__file__")
		if not filename:
			return leaf
		root, ext = os.path.splitext(filename)
		if ext.lower() == ".pyc" and os.path.exists(root + ".py"):
			return FileLeaf(root + ".py")

		if not os.path.exists(filename):
			# handle modules in zip or eggs
			import pkgutil
			pfull = "kupfer.plugin." + plugin_id
			loader = pkgutil.get_loader(pfull)
			if loader:
				return TextLeaf(loader.get_source(pfull))
		return FileLeaf(filename)

	def get_description(self):
		pass
	def get_icon_name(self):
		return "dialog-information"

class Plugin (Leaf):
	# NOTE: Just to be sure that a plugin ranks lower than a
	# like-named other object by default.
	rank_adjust = -1
	def __init__(self, obj, name):
		Leaf.__init__(self, obj, name)
	def get_actions(self):
		yield ShowInfo()
		yield ShowSource()

	def get_description(self):
		setctl = settings.GetSettingsController()
		enabled = setctl.get_plugin_enabled(self.object["name"])
		return u"%s (%s)" % (self.object["description"],
				_("enabled") if enabled else _("disabled"))
	def get_icon_name(self):
		return "package-x-generic"

class KupferPlugins (Source):
	def __init__(self):
		Source.__init__(self, _("Kupfer Plugins"))

	def get_items(self):
		setctl = settings.GetSettingsController()
		for info in plugins.get_plugin_info():
			plugin_id = info["name"]
			if setctl.get_plugin_is_hidden(plugin_id):
				continue
			yield Plugin(info, info["localized_name"])

	def should_sort_lexically(self):
		return True

	def provides(self):
		yield Plugin

	def get_icon_name(self):
		return "package-x-generic"

	@classmethod
	def decorates_type(cls):
		return Plugin

	@classmethod
	def decorate_item(cls, obj):
		if cls.is_self_plugin(obj):
			return cls()

	@classmethod
	def is_self_plugin(cls, obj):
		self_plug_id = __name__.split(".")[-1]
		return obj.object['name'] == self_plug_id

	def get_leaf_repr(self):
		for obj in self.get_leaves():
			if self.is_self_plugin(obj):
				return obj


########NEW FILE########
__FILENAME__ = locate
__kupfer_name__ = _("Locate Files")
__kupfer_actions__ = (
		"Locate",
	)
__description__ = _("Search filesystem using locate")
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import subprocess

from kupfer.objects import Action, Source
from kupfer.objects import TextLeaf
from kupfer import icons, plugin_support
from kupfer.obj.objects import ConstructFileLeaf


__kupfer_settings__ = plugin_support.PluginSettings(
	{
		"key" : "ignore_case",
		"label": _("Ignore case distinctions when searching files"),
		"type": bool,
		"value": True,
	},
)

class Locate (Action):
	def __init__(self):
		Action.__init__(self, _("Locate Files"))

	def is_factory(self):
		return True
	def activate(self, leaf):
		return LocateQuerySource(leaf.object)
	def item_types(self):
		yield TextLeaf

	def get_description(self):
		return _("Search filesystem using locate")
	def get_gicon(self):
		return icons.ComposedIcon("gnome-terminal", self.get_icon_name())
	def get_icon_name(self):
		return "edit-find"

class LocateQuerySource (Source):
	def __init__(self, query):
		Source.__init__(self, name=_('Results for "%s"') % query)
		self.query = query
		self.max_items = 500

	def repr_key(self):
		return self.query

	def get_items(self):
		ignore_case = '--ignore-case' if __kupfer_settings__["ignore_case"] else ''
		# Start two processes, one to take the first hits, one
		# to take the remaining up to maximum. We start both at the same time
		# (regrettably, locate wont output streamingly to stdout)
		# but we ask the second for results only after iterating the first few
		first_num = 12
		first_command = ("locate --null --limit %d %s '%s'" %
				(first_num, ignore_case, self.query))
		full_command = ("locate --null --limit %d %s '%s'" %
				(self.max_items, ignore_case, self.query))
		p1 = subprocess.Popen(first_command, shell=True, stdout=subprocess.PIPE)
		p2 = subprocess.Popen(full_command, shell=True, stdout=subprocess.PIPE)

		def get_locate_output(proc, offset=0):
			out, ignored_err = proc.communicate()
			return (ConstructFileLeaf(f) for f in out.split("\x00")[offset:-1])

		for F in get_locate_output(p1, 0):
			yield F
		for F in get_locate_output(p2, first_num):
			yield F

	def get_gicon(self):
		return icons.ComposedIcon("gnome-terminal", self.get_icon_name())
	def get_icon_name(self):
		return "edit-find"

########NEW FILE########
__FILENAME__ = multihead
# TRANS: Multihead refers to support for multiple computer displays
# TRANS: In this case, it only concerns the special configuration
# TRANS: with multiple X "screens"
__kupfer_name__ = _("Multihead Support")
__kupfer_sources__ = ()
__description__ = ("Will run the keyboard shortcut relay service on additional"
                   " X screens if needed.")
__version__ = ""
__author__ = ""

import os

import gtk

from kupfer import pretty
from kupfer import utils

child_pids = []

def initialize_plugin(name):
	global pid
	## check for multihead
	display = gtk.gdk.display_get_default()
	screen = display.get_default_screen()
	if display.get_n_screens() > 1:
		pretty.print_info(__name__, "Starting Multi X screen support")
		for idx in xrange(display.get_n_screens()):
			if idx != screen.get_number():
				pretty.print_info(__name__, "Launching keyrelay for screen", idx)
				screen_x = display.get_screen(idx)
				# run helper without respawning it
				pid = utils.start_plugin_helper("kupfer.keyrelay",
						False, screen_x.make_display_name())
				child_pids.append(pid)


def finalize_plugin(name):
	for pid in child_pids:
		os.kill(pid, 1)
	child_pids[:] = []

########NEW FILE########
__FILENAME__ = notes
"""
It *should* be possible to support Tomboy and Gnote equally since
they support the same DBus protocol. This plugin takes this assumption.
"""

__kupfer_name__ = _("Notes")
__kupfer_sources__ = ("NotesSource", )
__kupfer_actions__ = (
		"AppendToNote",
		"CreateNote",
		"GetNoteSearchResults",
	)
__description__ = _("Gnote or Tomboy notes")
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import locale
import os
import time
import xml.sax.saxutils

import dbus
import xdg.BaseDirectory as base

from kupfer.objects import Action, Source, Leaf, TextLeaf
from kupfer.obj.apps import ApplicationSource
from kupfer import icons, plugin_support
from kupfer import pretty, textutils


PROGRAM_IDS = ["gnote", "tomboy", "kzrnote"]
__kupfer_settings__ = plugin_support.PluginSettings(
	{
		"key" : "notes_application",
		"label": _("Work with application"),
		"type": str,
		"value": "",
		"alternatives": ["",] + PROGRAM_IDS
	},
)

plugin_support.check_dbus_connection()

def unicode_strftime(fmt, time_tuple=None):
	enc = locale.getpreferredencoding(False)
	return unicode(time.strftime(fmt, time_tuple), enc, "replace")

## Tuples of  service name, object name, interface name
PROGRAM_SERIVCES = {
	"gnote": ("org.gnome.Gnote",
	          "/org/gnome/Gnote/RemoteControl",
	          "org.gnome.Gnote.RemoteControl"),
	"tomboy": ("org.gnome.Tomboy",
	           "/org/gnome/Tomboy/RemoteControl",
	           "org.gnome.Tomboy.RemoteControl"),
	"kzrnote": ("se.kaizer.kzrnote",
	            "/se/kaizer/kzrnote",
	            "se.kaizer.kzrnote"),
}

def _get_notes_interface(activate=False):
	"""Return the dbus proxy object for our Note Application.

	if @activate, we will activate it over d-bus (start if not running)
	"""
	bus = dbus.SessionBus()
	proxy_obj = bus.get_object('org.freedesktop.DBus', '/org/freedesktop/DBus')
	dbus_iface = dbus.Interface(proxy_obj, 'org.freedesktop.DBus')

	set_prog = __kupfer_settings__["notes_application"]
	programs = (set_prog, ) if set_prog else PROGRAM_IDS

	for program in programs:
		service_name, obj_name, iface_name = PROGRAM_SERIVCES[program]

		if not activate and not dbus_iface.NameHasOwner(service_name):
			continue

		try:
			searchobj = bus.get_object(service_name, obj_name)
		except dbus.DBusException, e:
			pretty.print_error(__name__, e)
			return
		notes = dbus.Interface(searchobj, iface_name)
		return notes

class Open (Action):
	def __init__(self):
		Action.__init__(self, _("Open"))
	def activate(self, leaf):
		noteuri = leaf.object
		notes = _get_notes_interface(activate=True)
		notes.DisplayNote(noteuri)
	def get_description(self):
		return _("Open with notes application")
	def get_gicon(self):
		app_icon = icons.get_gicon_with_fallbacks(None, PROGRAM_IDS)
		return icons.ComposedIcon(self.get_icon_name(), app_icon)

class AppendToNote (Action):
	def __init__(self):
		Action.__init__(self, _("Append to Note..."))

	def activate(self, leaf, iobj):
		notes = _get_notes_interface(activate=True)
		noteuri = iobj.object
		text = leaf.object

		# NOTE: We search and replace in the XML here
		xmlcontents = notes.GetNoteCompleteXml(noteuri)
		endtag = u"</note-content>"
		xmltext = xml.sax.saxutils.escape(text)
		xmlcontents = xmlcontents.replace(endtag, u"\n%s%s" % (xmltext, endtag))
		notes.SetNoteCompleteXml(noteuri, xmlcontents)

	def item_types(self):
		yield TextLeaf
	def requires_object(self):
		return True
	def object_types(self):
		yield Note
	def object_source(self, for_item=None):
		return NotesSource()
	def get_description(self):
		return _("Add text to existing note")
	def get_icon_name(self):
		return "list-add"

def _prepare_note_text(text):
	## split the text into a title + newline + rest of the text
	## if we only get the title, put in two helpful newlines
	title, body = textutils.extract_title_body(text)
	if body.lstrip():
		return u"%s\n%s" % (title, body)
	else:
		return u"%s\n\n" % (title,)

class CreateNote (Action):
	def __init__(self):
		Action.__init__(self, _("Create Note"))

	def activate(self, leaf):
		notes = _get_notes_interface(activate=True)
		text = _prepare_note_text(leaf.object)
		# FIXME: For Gnote we have to call DisplayNote
		# else we can't change its contents
		noteuri = notes.CreateNote()
		notes.DisplayNote(noteuri)
		notes.SetNoteContents(noteuri, text)

	def item_types(self):
		yield TextLeaf
	def get_description(self):
		return _("Create a new note from this text")
	def get_icon_name(self):
		return "document-new"

class GetNoteSearchResults (Action):
	def __init__(self):
		Action.__init__(self, _("Get Note Search Results..."))

	def is_factory(self):
		return True

	def activate(self, leaf):
		query = leaf.object
		return NoteSearchSource(query)

	def item_types(self):
		yield TextLeaf

	def get_description(self):
		return _("Show search results for this query")

class NoteSearchSource (Source):
	def __init__(self, query):
		self.query = query.lower()
		Source.__init__(self, _("Notes"))

	def get_items(self):
		notes = _get_notes_interface(activate=True)
		noteuris = notes.SearchNotes(self.query, False)
		for noteuri in noteuris:
			title = notes.GetNoteTitle(noteuri)
			date = notes.GetNoteChangeDate(noteuri)
			yield Note(noteuri, title, date)

	def repr_key(self):
		return self.query

	def get_gicon(self):
		return icons.get_gicon_with_fallbacks(None, PROGRAM_IDS)

	def provides(self):
		yield Note

class Note (Leaf):
	"""The Note Leaf's represented object is the Note URI"""
	def __init__(self, obj, name, date):
		self.changedate = date
		Leaf.__init__(self, obj, name)
	def get_actions(self):
		yield Open()
	def repr_key(self):
		# the Note URI is unique&persistent for each note
		return self.object
	def get_description(self):
		today_date = time.localtime()[:3]
		yest_date = time.localtime(time.time() - 3600*24)[:3]
		change_time = time.localtime(self.changedate)

		if today_date == change_time[:3]:
			time_str = _("today, %s") % unicode_strftime("%X", change_time)
		elif yest_date == change_time[:3]:
			time_str = _("yesterday, %s") % unicode_strftime("%X", change_time)
		else:
			time_str = unicode_strftime("%c", change_time)
		# TRANS: Note description, %s is last changed time in locale format
		return _("Last updated %s") % time_str
	def get_icon_name(self):
		return "text-x-generic"

class ClassProperty (property):
	"""Subclass property to make classmethod properties possible"""
	def __get__(self, cls, owner):
		return self.fget.__get__(None, owner)()

class NotesSource (ApplicationSource):
	def __init__(self):
		Source.__init__(self, _("Notes"))
		self._notes = []

	def initialize(self):
		"""Set up filesystem monitors to catch changes"""
		# We monitor all directories that exist of a couple of candidates
		dirs = []
		for program in PROGRAM_IDS:
			notedatapaths = (os.path.join(base.xdg_data_home, program),
					os.path.expanduser("~/.%s" % program))
			dirs.extend(notedatapaths)
		self.monitor_token = self.monitor_directories(*dirs)

	def _update_cache(self, notes):
		try:
			noteuris = notes.ListAllNotes()
		except dbus.DBusException, e:
			self.output_error("%s: %s" % (type(e).__name__, e))
			return

		templates = notes.GetAllNotesWithTag("system:template")

		self._notes = []
		for noteuri in noteuris:
			if noteuri in templates:
				continue
			title = notes.GetNoteTitle(noteuri)
			date = notes.GetNoteChangeDate(noteuri)
			self._notes.append((noteuri, title, date))

	def get_items(self):
		notes = _get_notes_interface()
		if notes:
			self._update_cache(notes)
		for noteuri, title, date in self._notes:
			yield Note(noteuri, title, date=date)

	def provides(self):
		yield Note

	def get_gicon(self):
		return icons.get_gicon_with_fallbacks(None, PROGRAM_IDS)

	def get_icon_name(self):
		return "gnote"

	@ClassProperty
	@classmethod
	def appleaf_content_id(cls):
		return __kupfer_settings__["notes_application"] or PROGRAM_IDS


########NEW FILE########
__FILENAME__ = openoffice
# -*- coding: UTF-8 -*-

__kupfer_name__ = _("OpenOffice / LibreOffice")
__kupfer_sources__ = ("RecentsSource", )
__description__ = _("Recently used documents in OpenOffice/LibreOffice")
__version__ = "2011-04-07"
__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"

'''
Changes:
	2011-04-02: Support new cofiguration file format in LibreOffice.
'''

import os
from xml.etree import cElementTree as ElementTree
import gio

from kupfer.objects import Source, FileLeaf, UrlLeaf, AppLeaf
from kupfer.obj.helplib import FilesystemWatchMixin


_HISTORY_FILE = [
		"~/.config/libreoffice/3/user/registrymodifications.xcu",
		"~/.libreoffice/3/user/registrymodifications.xcu",
		"~/.openoffice.org/3/user/registrymodifications.xcu",
		"~/.openoffice.org/3/user/registry/data/org/openoffice/Office/Histories.xcu",
]
_NAME_ATTR = "{http://openoffice.org/2001/registry}name"
_PATH_ATTR = "{http://openoffice.org/2001/registry}path"
_HISTORY_NODES = "/org.openoffice.Office.Histories/Histories/" \
		"org.openoffice.Office.Histories:HistoryInfo['PickList']/OrderList"


class MultiAppContentMixin (object):
	"""
	Mixin for Source that decorates many app leaves

	This Mixin sees to that the Source is set as content for the applications
	with id 'cls.appleaf_content_id', which may also be a sequence of ids.

	Source has to define the attribute appleaf_content_id and must
	inherit this mixin BEFORE the Source

	This Mixin defines:
	decorates_type,
	decorates_item
	"""
	@classmethod
	def __get_appleaf_id_iter(cls):
		if hasattr(cls.appleaf_content_id, "__iter__"):
			ids = iter(cls.appleaf_content_id)
		else:
			ids = (cls.appleaf_content_id, )
		return ids

	@classmethod
	def decorates_type(cls):
		return AppLeaf

	@classmethod
	def decorate_item(cls, leaf):
		if leaf.get_id() in cls.__get_appleaf_id_iter():
			return cls()


class RecentsSource (MultiAppContentMixin, Source, FilesystemWatchMixin):
	appleaf_content_id = [
			"openoffice.org-writer",
			"openoffice.org-base",
			"openoffice.org-calc",
			"openoffice.org-draw",
			"openoffice.org-impress",
			"openoffice.org-math",
			"openoffice.org-startcenter",
			"libreoffice-writer",
			"libreoffice-base",
			"libreoffice-calc",
			"libreoffice-draw",
			"libreoffice-impress",
			"libreoffice-math",
			"libreoffice-startcenter",
	]

	def __init__(self, name=_("OpenOffice/LibreOffice Recent Items")):
		Source.__init__(self, name)

	def initialize(self):
		hist_file_path = _get_history_files()
		if hist_file_path:
			dirs = map(os.path.dirname, hist_file_path)
			self.monitor_token = self.monitor_directories(*dirs)

	def monitor_include_file(self, gfile):
		return gfile and gfile.get_basename().endswith('.xcu')

	def get_items(self):
		for hist_file_path in _get_history_files():
			self.output_debug('reading', hist_file_path)
			try:
				tree = ElementTree.parse(hist_file_path)
				node_histories = tree.find('node')
				if node_histories and node_histories.attrib[_NAME_ATTR] == 'Histories':
					for list_node in  node_histories.findall('node'):
						if list_node.attrib[_NAME_ATTR] == 'PickList':
							items_node = list_node.find('node')
							if (not items_node \
									or items_node.attrib[_NAME_ATTR] != 'ItemList'):
								return
							for node in items_node.findall('node'):
								hfile = node.attrib[_NAME_ATTR]  # file://.....
								leaf = _create_history_leaf(hfile)
								if leaf:
									yield leaf
							break
				#  new configuration file
				for item in tree.getroot().findall('item'):
					if item.get(_PATH_ATTR) != _HISTORY_NODES:
						continue
					node = item.find('node')
					if not node:
						continue
					prop = node.find('prop')
					if not prop:
						continue
					if prop.get(_NAME_ATTR) != 'HistoryItemRef':
						continue
					value = prop.find('value')
					if value is not None:
						leaf = _create_history_leaf(value.text)
						if leaf:
							yield leaf
			except StandardError, err:
				self.output_error(err)

	def get_description(self):
		return _("Recently used documents in OpenOffice/LibreOffice")

	def get_icon_name(self):
		return "document-open-recent"

	def provides(self):
		yield FileLeaf
		yield UrlLeaf


def _get_history_files():
	''' get all existing files with history '''
	for file_path in _HISTORY_FILE:
		path = os.path.expanduser(file_path)
		if os.path.isfile(path):
			yield path


def _create_history_leaf(path):
	''' Create leaf from file url '''
	if not path:
		return None
	gfile = gio.File(path)
	if not gfile.query_exists():
		None
	if gfile.get_path():
		return FileLeaf(gfile.get_path())
	return UrlLeaf(path, gfile.get_basename())

########NEW FILE########
__FILENAME__ = opera
# -*- coding: UTF-8 -*-
from __future__ import with_statement

__kupfer_name__ = _("Opera Bookmarks")
__kupfer_sources__ = ("BookmarksSource", )
__description__ = _("Index of Opera bookmarks")
__version__ = "2010-01-12"
__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"

import codecs
import os

from kupfer.objects import Source, UrlLeaf
from kupfer.obj.apps import ApplicationSource


BOOKMARKS_FILE = "bookmarks.adr"

class BookmarksSource(ApplicationSource):
	appleaf_content_id = "opera"

	def __init__(self, name=_("Opera Bookmarks")):
		Source.__init__(self, name)
		self.unpickle_finish()

	def unpickle_finish(self):
		self._opera_home = os.path.expanduser("~/.opera/")
		self._bookmarks_path = os.path.join(self._opera_home, BOOKMARKS_FILE)

	def initialize(self):
		self.monitor_token = self.monitor_directories(self._opera_home)

	def monitor_include_file(self, gfile):
		return gfile and gfile.get_basename() == BOOKMARKS_FILE

	def get_items(self):
		name = None
		try:
			with codecs.open(self._bookmarks_path, "r", "UTF-8") as bfile:
				for line in bfile:
					line = line.strip()
					if line.startswith(u'NAME='):
						name = line[5:]
					elif line.startswith(u'URL=') and name:
						yield UrlLeaf(line[4:], name)
		except EnvironmentError, exc:
			self.output_error(exc)
		except UnicodeError, exc:
			self.output_error("File %s not in expected encoding (UTF-8)" %
					self._bookmarks_path)
			self.output_error(exc)

	def get_description(self):
		return _("Index of Opera bookmarks")

	def get_icon_name(self):
		return "opera"

	def provides(self):
		yield UrlLeaf


########NEW FILE########
__FILENAME__ = operamail
# -*- coding: UTF-8 -*-
__kupfer_name__ = _("Opera Mail")
__kupfer_sources__ = ("OperaContactsSource", )
__kupfer_actions__ = ("NewMailAction", )
__description__ = _("Opera Mail contacts and actions")
__version__ = "2010-10-19"
__author__ = "Chris Parsons <cjparsons1@yahoo.co.uk>"

import codecs
import os

from kupfer.objects import Action
from kupfer.objects import TextLeaf, UrlLeaf, RunnableLeaf
from kupfer import utils
from kupfer.obj.helplib import FilesystemWatchMixin
from kupfer.obj.grouping import ToplevelGroupingSource
from kupfer.obj.contacts import ContactLeaf, EmailContact, email_from_leaf


CONTACTS_FILE = "contacts.adr"


class ComposeMail(RunnableLeaf):
	''' Create new mail without recipient '''
	def __init__(self):
		RunnableLeaf.__init__(self, name=_("Compose New Email"))

	def run(self):
		utils.spawn_async(['opera', '-remote', 'openComposer()'])

	def get_description(self):
		return _("Compose a new message in Opera Mail")

	def get_icon_name(self):
		return "mail-message-new"


class NewMailAction(Action):
	''' Create new mail to selected leaf'''
	def __init__(self):
		Action.__init__(self, _('Compose Email'))

	def activate(self, leaf):
		self.activate_multiple((leaf, ))

	def activate_multiple(self, objects):
		recipients = ",".join(email_from_leaf(L) for L in objects)
		utils.spawn_async(['opera', '-remote', 'openURL(mailto:%s)' % recipients])

	def get_icon_name(self):
		return "mail-message-new"

	def item_types(self):
		yield ContactLeaf
		yield TextLeaf
		yield UrlLeaf

	def valid_for_item(self, item):
		return bool(email_from_leaf(item))


class OperaContactsSource(ToplevelGroupingSource, FilesystemWatchMixin):

	def __init__(self, name=_("Opera Mail Contacts")):
		super(OperaContactsSource, self).__init__(name, "Contacts")
		self._opera_home = os.path.expanduser("~/.opera/")
		self._contacts_path = os.path.join(self._opera_home, CONTACTS_FILE)

	def initialize(self):
		ToplevelGroupingSource.initialize(self)
		if not os.path.isdir(self._opera_home):
			return

		self.monitor_token = self.monitor_directories(self._opera_home)

	def monitor_include_file(self, gfile):
		return gfile and gfile.get_basename() == CONTACTS_FILE

	def get_items(self):
		name = None
		folderList = ['TopLevel']
		TRASH = 'XXXTRASHXXX'
		try:
			with codecs.open(self._contacts_path, "r", "UTF-8") as bfile:
				for line in bfile:
					line = line.strip()
					if line.startswith(u'-'):
						folderList.pop()
					elif line.startswith(u'#FOLDER'):
						entryType = 'Folder'
					elif line.startswith(u'#CONTACT'):
						entryType = 'Contact'
					elif line.startswith(u'TRASH FOLDER=YES'):
						folderList[-1] = TRASH
					elif line.startswith(u'NAME='):
						name = line[5:]
						if entryType == 'Folder':
							folderList.append(name)
					elif line.startswith(u'MAIL=') and name and \
							entryType == 'Contact' and not TRASH in folderList:
						# multiple addresses separated with
						# two Ctrl-B (\x02) characters
						emails = line[5:].split('\x02\x02')
						for e in emails:
							yield EmailContact(e, name)
		except EnvironmentError, exc:
			self.output_error(exc)
		except UnicodeError, exc:
			self.output_error("File %s not in expected encoding (UTF-8)" %
					self._bookmarks_path)
			self.output_error(exc)
		yield ComposeMail()

	def should_sort_lexically(self):
		# since it is a grouping source, grouping and non-grouping will be
		# separate and only grouping leaves will be sorted
		return True

	def get_description(self):
		return _("Contacts from Opera Mail")

	def get_icon_name(self):
		return "opera"

	def provides(self):
		yield RunnableLeaf
		yield ContactLeaf
# vi:nosmarttab:noexpandtab:ts=4:sw=4

########NEW FILE########
__FILENAME__ = pidgin
'''Inspiration from the deskbar pidgin plugin and from the gajim kupfer
plugin'''
__kupfer_name__ = _("Pidgin")
__kupfer_sources__ = ("ContactsSource", )
__kupfer_actions__ = (
	"OpenChat",
	"SendMessage",
)
__description__ = _("Access to Pidgin Contacts")
__version__ = "0.1"
__author__ = ("Chmouel Boudjnah <chmouel@chmouel.com>, "
              "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>")

import dbus

from kupfer.objects import Action, TextLeaf, TextSource
from kupfer import pretty, scheduler
from kupfer import icons
from kupfer import plugin_support
from kupfer.obj.apps import AppLeafContentMixin
from kupfer.obj.helplib import PicklingHelperMixin
from kupfer.obj.grouping import ToplevelGroupingSource
from kupfer.weaklib import dbus_signal_connect_weakly
from kupfer.obj.contacts import NAME_KEY, EMAIL_KEY, ContactLeaf, is_valid_email

__kupfer_settings__ = plugin_support.PluginSettings(
	{
		"key" : "show_offline",
		"label": _("Show offline contacts"),
		"type": bool,
		"value": False,
	},
)

plugin_support.check_dbus_connection()

# Contact data contstants
PIDGIN_ACCOUNT = "_PIDGIN_ACCOUNT"
PIDGIN_JID = "_PIDGIN_JID"

# D-Bus "addresses"
SERVICE_NAME = "im.pidgin.purple.PurpleService"
OBJECT_NAME = "/im/pidgin/purple/PurpleObject"
IFACE_NAME = "im.pidgin.purple.PurpleInterface"

def _create_dbus_connection(activate=False):
	''' Create dbus connection to Pidgin
	@activate: true=starts pidgin if not running
	'''
	interface = None
	obj = None
	sbus = dbus.SessionBus()

	try:
		#check for running pidgin (code from note.py)
		proxy_obj = sbus.get_object('org.freedesktop.DBus',
				'/org/freedesktop/DBus')
		dbus_iface = dbus.Interface(proxy_obj, 'org.freedesktop.DBus')
		if activate or dbus_iface.NameHasOwner(SERVICE_NAME):
			obj = sbus.get_object(SERVICE_NAME, OBJECT_NAME)
		if obj:
			interface = dbus.Interface(obj, IFACE_NAME)
	except dbus.exceptions.DBusException, err:
		pretty.print_debug(err)
	return interface


def _send_message_to_contact(pcontact, message, present=False):
	"""
	Send @message to PidginContact @pcontact
	"""
	interface = _create_dbus_connection()
	if not interface:
		return
	account = pcontact[PIDGIN_ACCOUNT]
	jid = pcontact[PIDGIN_JID]
	conversation = interface.PurpleConversationNew(1, account, jid)
	im = interface.PurpleConvIm(conversation)
	interface.PurpleConvImSend(im, message)
	if present:
		interface.PurpleConversationPresent(conversation)

class ContactAction (Action):
	def get_required_slots(self):
		return ()
	def item_types(self):
		yield ContactLeaf
	def valid_for_item(self, leaf):
		return all(slot in leaf for slot in self.get_required_slots())

class OpenChat(ContactAction):
	""" Open Chat Conversation Window with jid """
	# consider it as main action for pidgin contacts
	rank_adjust = 5

	def __init__(self):
		Action.__init__(self, _('Open Chat'))

	def activate(self, leaf):
		_send_message_to_contact(leaf, u"", present=True)

	def get_required_slots(self):
		return [PIDGIN_ACCOUNT, PIDGIN_JID]

class ChatTextSource (TextSource):
	def get_rank(self):
		return 100
	def get_text_items(self, text):
		n = len(text)
		summary = text[:10] + (text[10:11] and "..")
		desc_template = ngettext("%s (%d character)", "%s (%d characters)", n)
		yield TextLeaf(text, desc_template % (summary, n))

	def get_items(self, text):
		return self.get_text_items(text)

class SendMessage (ContactAction):
	""" Send chat message directly from Kupfer """
	def __init__(self):
		Action.__init__(self, _("Send Message..."))

	def activate(self, leaf, iobj):
		_send_message_to_contact(leaf, iobj.object)

	def get_required_slots(self):
		return [PIDGIN_ACCOUNT, PIDGIN_JID]

	def requires_object(self):
		return True
	def object_types(self):
		yield TextLeaf
	def object_source(self, for_item=None):
		return TextSource()
	def valid_object(self, iobj, for_item=None):
		# ugly, but we don't want derived text
		return type(iobj) is TextLeaf

class PidginContact(ContactLeaf):
	""" Leaf represent single contact from Pidgin """
	grouping_slots = ContactLeaf.grouping_slots + (EMAIL_KEY, )
	def __init__(self, jid, name, account, icon, protocol, available,
		status_message):
		slots = {
			EMAIL_KEY: jid,
			NAME_KEY: name or jid,
			PIDGIN_ACCOUNT: account,
			PIDGIN_JID: jid,
		}
		if not is_valid_email(jid):
			slots[EMAIL_KEY] = None

		ContactLeaf.__init__(self, slots, name or jid)

		self.kupfer_add_alias(jid)

		self._description = _("[%(status)s] %(userid)s/%(service)s") % \
				{
					"status": _("Available") if available else _("Away"),
					"userid": jid,
					"service": protocol,
				}

		if status_message:
			self._description += u"\n%s" % status_message

		self.account = account
		self.jid = jid
		self.icon = icon
		self.protocol = protocol

	def repr_key(self):
		# the repr key should be persistent and hopefully unique
		return "%s, %s" % (self.protocol, self.object[PIDGIN_JID])

	def get_description(self):
		return self._description

	def get_thumbnail(self, width, height):
		if not self.icon:
			return
		return icons.get_pixbuf_from_file(self.icon, width, height)

	def get_icon_name(self):
		return "stock_person"


class ContactsSource(AppLeafContentMixin, ToplevelGroupingSource, PicklingHelperMixin):
	''' Get contacts from all on-line accounts in Pidgin via DBus '''
	appleaf_content_id = 'pidgin'

	def __init__(self):
		ToplevelGroupingSource.__init__(self, _('Pidgin Contacts'), "Contacts")
		self._version = 5
		self.unpickle_finish()

	def unpickle_finish(self):
		self.mark_for_update()
		self.pickle_prepare()

	def initialize(self):
		ToplevelGroupingSource.initialize(self)
		self._install_dbus_signal()
		self._buddy_update_timer = scheduler.Timer()
		self._buddy_update_queue = set()

	def pickle_prepare(self):
		# delete data that we do not want to save to next session
		self.all_buddies = {}
		self._buddy_update_timer = None
		self._buddy_update_queue = None

	def _get_pidgin_contact(self, interface, buddy, account=None, protocol=None):
		if not account:
			account = interface.PurpleBuddyGetAccount(buddy)

		if not protocol:
			protocol = interface.PurpleAccountGetProtocolName(account)

		jid = interface.PurpleBuddyGetName(buddy)
		name = interface.PurpleBuddyGetAlias(buddy)
		_icon = interface.PurpleBuddyGetIcon(buddy)
		icon = None
		if _icon != 0:
			icon = interface.PurpleBuddyIconGetFullPath(_icon)
		presenceid = interface.PurpleBuddyGetPresence(buddy)
		statusid = interface.PurplePresenceGetActiveStatus(presenceid)
		availability = interface.PurplePresenceIsAvailable(presenceid)
		status_message = interface.PurpleStatusGetAttrString(statusid, "message")

		return PidginContact(jid, name, account, icon, protocol, availability,
				status_message)

	def _get_all_buddies(self):
		interface = _create_dbus_connection()
		if interface is None:
			return

		accounts = interface.PurpleAccountsGetAllActive()
		show_offline = __kupfer_settings__["show_offline"]
		for account in accounts:
			buddies = interface.PurpleFindBuddies(account, dbus.String(''))
			protocol = interface.PurpleAccountGetProtocolName(account)

			for buddy in buddies:
				if not (show_offline or interface.PurpleBuddyIsOnline(buddy)):
					continue

				self.all_buddies[buddy] = self._get_pidgin_contact(interface,
						buddy, protocol=protocol, account=account)

	def _remove_buddies_not_connected(self):
		""" Remove buddies that belong to accounts no longer connected """
		if not self.all_buddies:
			return
		interface = _create_dbus_connection()
		if interface is None:
			self.all_buddies = {}
			return

		try:
			# extra careful as this will fail when Pidgin is Quitting
			accounts = interface.PurpleAccountsGetAllActive()
		except dbus.DBusException:
			self.all_buddies = {}
			return
		is_disconnected = interface.PurpleAccountIsDisconnected
		conn_accounts = set(a for a in accounts if not is_disconnected(a))
		for buddy, pcontact in self.all_buddies.items():
			if pcontact.account not in conn_accounts:
				del self.all_buddies[buddy]

	def _signing_off(self, conn):
		self.output_debug("Pidgin Signing Off", conn)
		self._remove_buddies_not_connected()
		self.mark_for_update()

	def _update_pending(self):
		"""Update all buddies in the update queue"""
		interface = _create_dbus_connection()
		if interface is None:
			self._buddy_update_queue.clear()
			return
		show_offline = __kupfer_settings__["show_offline"]
		for buddy in self._buddy_update_queue:
			if show_offline or interface.PurpleBuddyIsOnline(buddy):
				self.output_debug("updating buddy", buddy)
				pcontact = self._get_pidgin_contact(interface, buddy)
				self.all_buddies[buddy] = pcontact
			else:
				self.all_buddies.pop(buddy, None)
		self._buddy_update_queue.clear()
		self.mark_for_update()

	def _buddy_needs_update(self, buddy):
		"""add @buddy to the update queue"""
		if self._buddy_update_queue is not None:
			self._buddy_update_queue.add(buddy)
			self._buddy_update_timer.set(1, self._update_pending)

	def _buddy_signed_on(self, buddy):
		if buddy not in self.all_buddies:
			self._buddy_needs_update(buddy)

	def _buddy_signed_off(self, buddy):
		if buddy in self.all_buddies:
			del self.all_buddies[buddy]
			self.mark_for_update()

	def _buddy_status_changed(self, buddy, old, new):
		'''Callback when status is changed reload the entry
		which get the new status'''
		self._buddy_needs_update(buddy)

	def _install_dbus_signal(self):
		'''Add signals to pidgin when buddy goes offline or
		online to update the list'''
		try:
			session_bus = dbus.Bus()
		except dbus.DBusException:
			return

		dbus_signal_connect_weakly(session_bus, "SigningOff",
				self._signing_off, dbus_interface=IFACE_NAME)

		dbus_signal_connect_weakly(session_bus, "BuddySignedOn",
				self._buddy_signed_on, dbus_interface=IFACE_NAME)

		dbus_signal_connect_weakly(session_bus, "BuddyStatusChanged",
				self._buddy_status_changed, dbus_interface=IFACE_NAME)

		dbus_signal_connect_weakly(session_bus, "BuddySignedOff",
				self._buddy_signed_off, dbus_interface=IFACE_NAME)

	def get_items(self):
		if not self.all_buddies:
			self._get_all_buddies()
		return self.all_buddies.values()

	def should_sort_lexically(self):
		return True

	def get_icon_name(self):
		return 'pidgin'

	def provides(self):
		yield PidginContact


# Local Variables: ***
# python-indent: 8 ***
# indent-tabs-mode: t ***
# End: ***

########NEW FILE########
__FILENAME__ = putty
# -*- coding: UTF-8 -*-
from __future__ import with_statement


__kupfer_name__ = _("PuTTY Sessions")
__kupfer_sources__ = ("PuttySessionSource", )
__kupfer_actions__ = ("PuttyOpenSession", )
__description__ = _("Quick access to PuTTY Sessions")
__version__ = "2010-04-12"
__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"


import os
import urllib

from kupfer.objects import Action
from kupfer.obj.helplib import FilesystemWatchMixin, PicklingHelperMixin
from kupfer.obj.apps import AppLeafContentMixin
from kupfer import utils, icons
from kupfer.obj.grouping import ToplevelGroupingSource 
from kupfer.obj.hosts import HOST_NAME_KEY, HostLeaf, HOST_ADDRESS_KEY, \
		HOST_SERVICE_NAME_KEY, HOST_SERVICE_PORT_KEY, HOST_SERVICE_USER_KEY

PUTTY_SESSION_KEY = "PUTTY_SESSION"


class PuttySession(HostLeaf):
	""" Leaf represent session saved in PuTTy"""

	def __init__(self, name, hostname, description):
		slots = {HOST_NAME_KEY: hostname, PUTTY_SESSION_KEY: name,
				HOST_ADDRESS_KEY: hostname, HOST_SERVICE_NAME_KEY: 'ssh'}
		HostLeaf.__init__(self, slots, name)
		self._description = description

	def get_description(self):
		return self._description

	def get_gicon(self):
		return icons.ComposedIconSmall(self.get_icon_name(), "putty")


class PuttyOpenSession(Action):
	''' opens putty session '''
	def __init__(self):
		Action.__init__(self, _('Start Session'))

	def activate(self, leaf):
		if leaf.check_key(PUTTY_SESSION_KEY):
			session = leaf[PUTTY_SESSION_KEY]
			utils.spawn_async(["putty", "-load", session])
		else:
			options = ['putty']
			if leaf.check_key(HOST_SERVICE_USER_KEY):
				options.extend(['-l ', leaf[HOST_SERVICE_USER_KEY]])
			if leaf.check_key(HOST_SERVICE_PORT_KEY):
				options.extend(['-P ', leaf[HOST_SERVICE_PORT_KEY]])
			options.append(leaf[HOST_ADDRESS_KEY])
			utils.spawn_async(options)

	def get_icon_name(self):
		return 'putty'

	def item_types(self):
		yield HostLeaf

	def valid_for_item(self, item):
		if item.check_key(HOST_SERVICE_NAME_KEY):
			if item[HOST_SERVICE_NAME_KEY] == 'ssh':
				return True
		return item.check_key(PUTTY_SESSION_KEY)


class PuttySessionSource(AppLeafContentMixin, ToplevelGroupingSource, 
		PicklingHelperMixin, FilesystemWatchMixin):
	''' indexes session saved in putty '''

	appleaf_content_id = 'putty'

	def __init__(self, name=_("PuTTY Sessions")):
		super(PuttySessionSource, self).__init__(name, "hosts")
		self._version = 2
		self._putty_sessions_dir = os.path.expanduser('~/.putty/sessions')
		self.unpickle_finish()

	def unpickle_finish(self):
		self.monitor_token = self.monitor_directories(self._putty_sessions_dir)

	def get_items(self):
		if not os.path.isdir(self._putty_sessions_dir):
			return

		for filename in os.listdir(self._putty_sessions_dir):
			if filename == 'Default%20Settings':
				continue

			obj_path = os.path.join(self._putty_sessions_dir, filename)
			if os.path.isfile(obj_path):
				name = urllib.unquote(filename)
				description, host = self._load_host_from_session_file(obj_path)
				yield PuttySession(name, host, description)

	def get_description(self):
		return None

	def get_icon_name(self):
		return "putty"

	def provides(self):
		yield PuttySession

	def _load_host_from_session_file(self, filepath):
		user = None
		host = None
		try:
			with open(filepath, 'r') as session_file:
				for line in session_file:
					if line.startswith('HostName='):
						host = line.split('=', 2)[1].strip()

					elif line.startswith('UserName='):
						user = line.split('=', 2)[1].strip()

		except IOError, err:
			self.output_error(err)

		else:
			if host:
				return unicode(user + '@' + host if user else host, "UTF-8",
						"replace"), unicode(host, 'UTF-8', 'replace')

		return u'PuTTY Session', None





########NEW FILE########
__FILENAME__ = quickview
__kupfer_name__ = _("Quick Image Viewer")
__kupfer_actions__ = ("View", )
__description__ = ""
__version__ = ""
__author__ = ""

import shutil

import gio
import glib
import gtk

from kupfer.objects import Action, FileLeaf
from kupfer.objects import OperationError
from kupfer import utils


def is_content_type(fileleaf, ctype):
	predicate = gio.content_type_is_a
	ctype_guess, uncertain = gio.content_type_guess(fileleaf.object, None, True)
	ret = predicate(ctype_guess, ctype)
	if ret or not uncertain:
		return ret
	content_attr = gio.FILE_ATTRIBUTE_STANDARD_CONTENT_TYPE
	gfile = gio.File(fileleaf.object)
	if not gfile.query_exists(None):
		return
	info = gfile.query_info(content_attr)
	content_type = info.get_attribute_string(content_attr)
	return predicate(content_type, ctype)

def _set_size(loader, width, height, max_w, max_h):
	if width <= max_w and height <= max_h:
		return
	w_scale = max_w*1.0/width
	h_scale = max_h*1.0/height
	scale = min(w_scale, h_scale)
	loader.set_size(int(width*scale), int(height*scale))

def load_image_max_size(filename, w, h):
	pl = gtk.gdk.PixbufLoader()
	pl.connect("size-prepared", _set_size, w, h)
	try:
		with open(filename, "rb") as f:
			shutil.copyfileobj(f, pl)
		pl.close()
	except (glib.GError, EnvironmentError) as exc:
		raise OperationError(exc)
	return pl.get_pixbuf()

class View (Action):
	def __init__(self):
		Action.__init__(self, _("View Image"))
		self.open_windows = {}

	def item_types(self):
		yield FileLeaf

	def valid_for_item(self, obj):
		return is_content_type(obj, "image/*")

	def wants_context(self):
		return True

	def activate(self, obj, ctx):
		## If the same file @obj is already open,
		## then close its window.
		if obj.object in self.open_windows:
			open_window = self.open_windows.pop(obj.object)
			open_window.destroy()
			return
		image_widget = gtk.Image()
		h = gtk.gdk.screen_height()
		w = gtk.gdk.screen_width()
		image_widget.set_from_pixbuf(load_image_max_size(obj.object, w, h))
		image_widget.show()
		window = gtk.Window() 
		window.set_title(utils.get_display_path_for_bytestring(obj.object))
		window.set_position(gtk.WIN_POS_CENTER)
		window.add(image_widget)
		ctx.environment.present_window(window)
		window.connect("key-press-event", self.window_key_press, obj.object)
		window.connect("delete-event", self.window_deleted, obj.object)
		self.open_windows[obj.object] = window

	def window_deleted(self, window, event, filename):
		self.open_windows.pop(filename, None)
		return False

	def window_key_press(self, window, event, filepath):
		if gtk.gdk.keyval_name(event.keyval) == "Escape":
			self.window_deleted(window, event, filepath)
			window.destroy()
			return True
		if gtk.gdk.keyval_name(event.keyval) == "Return":
			self.window_deleted(window, event, filepath)
			utils.show_path(filepath)
			window.destroy()
			return True

	def get_description(self):
		return None


########NEW FILE########
__FILENAME__ = rhythmbox
# -*- coding: UTF8 -*-
__kupfer_name__ = _("Rhythmbox")
__kupfer_sources__ = ("RhythmboxSource", )
__description__ = _("Play and enqueue tracks and browse the music library")
__version__ = "2012-10-17"
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

'''
Changes:
	2012-10-17 Karol BÄ™dkowski:
		+ control rhythmbox via dbus interface
		+ load songs via dbus interface
'''


import itertools
from hashlib import md5

import gio
import os

import dbus

from kupfer import pretty
from kupfer.objects import Leaf, Source, Action, RunnableLeaf, SourceLeaf
from kupfer import icons, utils, config
from kupfer.obj.apps import AppLeafContentMixin
from kupfer import plugin_support
from kupfer.plugin import rhythmbox_support

plugin_support.check_dbus_connection()

__kupfer_settings__ = plugin_support.PluginSettings(
	{
		"key" : "toplevel_artists",
		"label": _("Include artists in top level"),
		"type": bool,
		"value": True,
	},
	{
		"key" : "toplevel_albums",
		"label": _("Include albums in top level"),
		"type": bool,
		"value": False,
	},
	{
		"key" : "toplevel_songs",
		"label": _("Include songs in top level"),
		"type": bool,
		"value": False,
	},
)

_BUS_NAME = 'org.gnome.Rhythmbox3'
_OBJ_PATH_MPRIS = '/org/mpris/MediaPlayer2'
_OBJ_NAME_MPRIS_PLAYER = 'org.mpris.MediaPlayer2.Player'
_OBJ_PATH_MEDIASERVC_ALL = '/org/gnome/UPnP/MediaServer2/Library/all'
_OBJ_NAME_MEDIA_CONT = 'org.gnome.UPnP.MediaContainer2'


def _tostr(ustr):
	return ustr.encode("UTF-8")

def _create_dbus_connection_mpris(obj_name, obj_path, activate=False):
	''' Create dbus connection to Rhytmbox
		@activate: if True, start program if not running
	'''
	interface = None
	sbus = dbus.SessionBus()
	try:
		proxy_obj = sbus.get_object('org.freedesktop.DBus',
				'/org/freedesktop/DBus')
		dbus_iface = dbus.Interface(proxy_obj, 'org.freedesktop.DBus')
		if activate or dbus_iface.NameHasOwner(_BUS_NAME):
			obj = sbus.get_object(_BUS_NAME, obj_path)
			if obj:
				interface = dbus.Interface(obj, obj_name)
	except dbus.exceptions.DBusException, err:
		pretty.print_debug(err)
	return interface


def _get_all_songs_via_dbus():
	iface = _create_dbus_connection_mpris(_OBJ_NAME_MEDIA_CONT,
			_OBJ_PATH_MEDIASERVC_ALL)
	if iface:
		for item in iface.ListItems(0, 9999, ['*']):
			yield {'album': unicode(item['Album']),
					'artist': unicode(item['Artist']),
					'title': unicode(item['DisplayName']),
					'track-number': unicode(item['TrackNumber']),
					'title': unicode(item['DisplayName']),
					'location': unicode(item['URLs'][0])}

def play_song(info):
	uri = _tostr(info["location"])
	iface = _create_dbus_connection_mpris(_OBJ_NAME_MPRIS_PLAYER,
				_OBJ_PATH_MPRIS, True)
	if iface:
		iface.OpenUri(uri)
	else:
		utils.spawn_async(("rhythmbox-client", "--play-uri=%s" % uri))

def enqueue_songs(info, clear_queue=False):
	songs = list(info)
	if not songs:
		return
	qargv = ["rhythmbox-client"]
	if clear_queue:
		qargv.append("--clear-queue")
	for song in songs:
		uri = _tostr(song["location"])
		gfile = gio.File(uri)
		path = gfile.get_path()
		qargv.append("--enqueue")
		qargv.append(path)
	utils.spawn_async(qargv)

class Play (RunnableLeaf):
	def __init__(self):
		RunnableLeaf.__init__(self, name=_("Play"))
	def run(self):
		iface = _create_dbus_connection_mpris(_OBJ_NAME_MPRIS_PLAYER,
				_OBJ_PATH_MPRIS, True)
		if iface:
			iface.Play()
		else:
			utils.spawn_async(("rhythmbox-client", "--play"))
	def get_description(self):
		return _("Resume playback in Rhythmbox")
	def get_icon_name(self):
		return "media-playback-start"

class Pause (RunnableLeaf):
	def __init__(self):
		RunnableLeaf.__init__(self, name=_("Pause"))
	def run(self):
		iface = _create_dbus_connection_mpris(_OBJ_NAME_MPRIS_PLAYER,
				_OBJ_PATH_MPRIS, True)
		if iface:
			iface.Pause()
		else:
			utils.spawn_async(("rhythmbox-client", "--no-start", "--pause"))
	def get_description(self):
		return _("Pause playback in Rhythmbox")
	def get_icon_name(self):
		return "media-playback-pause"

class Next (RunnableLeaf):
	def __init__(self):
		RunnableLeaf.__init__(self, name=_("Next"))
	def run(self):
		iface = _create_dbus_connection_mpris(_OBJ_NAME_MPRIS_PLAYER,
				_OBJ_PATH_MPRIS, True)
		if iface:
			iface.Next()
		else:
			utils.spawn_async(("rhythmbox-client", "--no-start", "--next"))
	def get_description(self):
		return _("Jump to next track in Rhythmbox")
	def get_icon_name(self):
		return "media-skip-forward"

class Previous (RunnableLeaf):
	def __init__(self):
		RunnableLeaf.__init__(self, name=_("Previous"))
	def run(self):
		iface = _create_dbus_connection_mpris(_OBJ_NAME_MPRIS_PLAYER,
				_OBJ_PATH_MPRIS, True)
		if iface:
			iface.Previous()
		else:
			utils.spawn_async(("rhythmbox-client", "--no-start", "--previous"))
	def get_description(self):
		return _("Jump to previous track in Rhythmbox")
	def get_icon_name(self):
		return "media-skip-backward"

class ShowPlaying (RunnableLeaf):
	def __init__(self):
		RunnableLeaf.__init__(self, name=_("Show Playing"))
	def run(self):
		utils.spawn_async(("rhythmbox-client", "--no-start", "--notify"))
	def get_description(self):
		return _("Tell which song is currently playing")
	def get_gicon(self):
		return icons.ComposedIcon("dialog-information", "audio-x-generic")
	def get_icon_name(self):
		return "dialog-information"

class ClearQueue (RunnableLeaf):
	def __init__(self):
		RunnableLeaf.__init__(self, name=_("Clear Queue"))
	def run(self):
		utils.spawn_async(("rhythmbox-client", "--no-start", "--clear-queue"))
	def get_icon_name(self):
		return "edit-clear"

def _songs_from_leaf(leaf):
	"return a sequence of songs from @leaf"
	if isinstance(leaf, SongLeaf):
		return (leaf.object, )
	if isinstance(leaf, TrackCollection):
		return list(leaf.object)

class PlayTracks (Action):
	rank_adjust = 5
	def __init__(self):
		Action.__init__(self, _("Play"))

	def activate(self, leaf):
		self.activate_multiple((leaf, ))

	def activate_multiple(self, objects):
		# for multiple dispatch, play the first and enqueue the rest
		to_enqueue = []
		objects = iter(objects)
		# take only the first object in the first loop
		# notice the break
		for leaf in objects:
			songs = _songs_from_leaf(leaf)
			if not songs:
				continue
			play_song(songs[0])
			to_enqueue.extend(songs[1:])
			break
		for leaf in objects:
			to_enqueue.extend(_songs_from_leaf(leaf))
		if to_enqueue:
			enqueue_songs(to_enqueue, clear_queue=True)

	def get_description(self):
		return _("Play tracks in Rhythmbox")
	def get_icon_name(self):
		return "media-playback-start"

class Enqueue (Action):
	def __init__(self):
		Action.__init__(self, _("Enqueue"))
	def activate(self, leaf):
		self.activate_multiple((leaf, ))

	def activate_multiple(self, objects):
		to_enqueue = []
		for leaf in objects:
			to_enqueue.extend(_songs_from_leaf(leaf))
		enqueue_songs(to_enqueue)

	def get_description(self):
		return _("Add tracks to the play queue")
	def get_gicon(self):
		return icons.ComposedIcon("gtk-execute", "media-playback-start")
	def get_icon_name(self):
		return "media-playback-start"

class SongLeaf (Leaf):
	serializable = 1
	def __init__(self, info, name=None):
		"""Init with song info
		@info: Song information dictionary
		"""
		if not name: name = info["title"]
		Leaf.__init__(self, info, name)
	def repr_key(self):
		"""To distinguish songs by the same name"""
		return (self.object["title"], self.object["artist"],
				self.object["album"])
	def get_actions(self):
		yield PlayTracks()
		yield Enqueue()
	def get_description(self):
		# TRANS: Song description
		return _("by %(artist)s from %(album)s") % {
				"artist": self.object["artist"],
				"album": self.object["album"],
				}
	def get_icon_name(self):
		return "audio-x-generic"

class CollectionSource (Source):
	def __init__(self, leaf):
		Source.__init__(self, unicode(leaf))
		self.leaf = leaf
	def get_items(self):
		for song in self.leaf.object:
			yield SongLeaf(song)
	def repr_key(self):
		return self.leaf.repr_key()
	def get_description(self):
		return self.leaf.get_description()
	def get_thumbnail(self, w, h):
		return self.leaf.get_thumbnail(w, h)
	def get_gicon(self):
		return self.leaf.get_gicon()
	def get_icon_name(self):
		return self.leaf.get_icon_name()

class TrackCollection (Leaf):
	"""A generic track collection leaf, such as one for
	an Album or an Artist
	"""
	def __init__(self, info, name):
		"""Init with track collection
		@info: Should be a sequence of song information dictionaries
		"""
		Leaf.__init__(self, info, name)
	def get_actions(self):
		yield PlayTracks()
		yield Enqueue()
	def has_content(self):
		return True
	def content_source(self, alternate=False):
		return CollectionSource(self)
	def get_icon_name(self):
		return "media-optical"

class AlbumLeaf (TrackCollection):
	def get_description(self):
		artist = None
		for song in self.object:
			if not artist:
				artist = song["artist"]
			elif artist != song["artist"]:
				# TRANS: Multiple artist description "Artist1 et. al. "
				artist = _("%s et. al.") % artist
				break
		# TRANS: Album description "by Artist"
		return _("by %s") % (artist, )

	def _get_thumb_local(self):
		# try local filesystem
		uri = self.object[0]["location"]
		artist = self.object[0]["artist"].lower()
		album = self.object[0]["album"].lower()
		gfile = gio.File(uri)
		cdir = gfile.resolve_relative_path("../").get_path()
		# We don't support unicode ATM
		bs_artist_album = \
			" - ".join([us.encode("ascii", "ignore") for us in (artist, album)])
		cover_names = ("cover.jpg", "album.jpg", "albumart.jpg",
				".folder.jpg", "folder.jpg", bs_artist_album + ".jpg")
		for cover_name in os.listdir(cdir):
			if cover_name.lower() in cover_names:
				cfile = gfile.resolve_relative_path("../" + cover_name)
				return cfile.get_path()

	def _get_thumb_mediaart(self):
		"""old thumb location"""
		ltitle = unicode(self).lower()
		# ignore the track artist -- use the space fallback
		# hash of ' ' as fallback
		hspace = "7215ee9c7d9dc229d2921a40e899ec5f"
		htitle = md5(_tostr(ltitle)).hexdigest()
		hartist = hspace
		cache_name = "album-%s-%s.jpeg" % (hartist, htitle)
		return config.get_cache_file(("media-art", cache_name))

	def _get_thumb_rhythmbox(self):
		artist = self.object[0]["artist"]
		album = unicode(self)
		bs_artist_album = \
			" - ".join([us.encode("ascii", "ignore") for us in (artist, album)]) \
			+ ".jpg"
		return config.get_cache_file(("rhythmbox", "covers", bs_artist_album))

	def get_thumbnail(self, width, height):
		if not hasattr(self, "cover_file"):
			self.cover_file = (self._get_thumb_rhythmbox() or
			                   self._get_thumb_mediaart() or
			                   self._get_thumb_local())
		return icons.get_pixbuf_from_file(self.cover_file, width, height)

class ArtistAlbumsSource (CollectionSource):
	def get_items(self):
		albums = {}
		for song in self.leaf.object:
			album = song["album"]
			album_list = albums.get(album, [])
			album_list.append(song)
			albums[album] = album_list
		for album in albums:
			yield AlbumLeaf(albums[album], album)
	def should_sort_lexically(self):
		return True

class ArtistLeaf (TrackCollection):
	def get_description(self):
		# TRANS: Artist songs collection description
		return _("Tracks by %s") % (unicode(self), )
	def get_gicon(self):
		return icons.ComposedIcon("media-optical", "system-users")
	def content_source(self, alternate=False):
		if alternate:
			return CollectionSource(self)
		return ArtistAlbumsSource(self)

class RhythmboxAlbumsSource (Source):
	def __init__(self, library):
		Source.__init__(self, _("Albums"))
		self.library = library

	def get_items(self):
		for album in self.library:
			yield AlbumLeaf(self.library[album], album)
	def should_sort_lexically(self):
		return True

	def get_description(self):
		return _("Music albums in Rhythmbox Library")
	def get_gicon(self):
		return icons.ComposedIcon("rhythmbox", "media-optical",
				emblem_is_fallback=True)
	def get_icon_name(self):
		return "rhythmbox"
	def provides(self):
		yield AlbumLeaf

class RhythmboxArtistsSource (Source):
	def __init__(self, library):
		Source.__init__(self, _("Artists"))
		self.library = library

	def get_items(self):
		for artist in self.library:
			yield ArtistLeaf(self.library[artist], artist)
	def should_sort_lexically(self):
		return True

	def get_description(self):
		return _("Music artists in Rhythmbox Library")
	def get_gicon(self):
		return icons.ComposedIcon("rhythmbox", "system-users",
				emblem_is_fallback=True)
	def get_icon_name(self):
		return "rhythmbox"
	def provides(self):
		yield ArtistLeaf

def _locale_sort_artist_album_songs(artists):
	"""Locale sort dictionary @artists by Artist, then Album;
	each artist in @artists should already contain songs
	grouped by album and sorted by track number.
	"""
	for artist in utils.locale_sort(artists):
		artist_songs = artists[artist]
		albums = {}
		albumkey = lambda song: song["album"]
		for album, songs in itertools.groupby(artist_songs, albumkey):
			albums[album] = list(songs)
		for album in utils.locale_sort(albums):
			for song in albums[album]:
				yield song

class RhythmboxSongsSource (Source):
	"""The whole song library in Leaf representation"""
	def __init__(self, library):
		Source.__init__(self, _("Songs"))
		self.library = library

	def get_items(self):
		for song in _locale_sort_artist_album_songs(self.library):
			yield SongLeaf(song)

	def get_actions(self):
		return ()
	def get_description(self):
		return _("Songs in Rhythmbox library")
	def get_gicon(self):
		return icons.ComposedIcon("rhythmbox", "audio-x-generic",
				emblem_is_fallback=True)
	def provides(self):
		yield SongLeaf

class RhythmboxSource (AppLeafContentMixin, Source):
	appleaf_content_id = "rhythmbox"
	def __init__(self):
		Source.__init__(self, _("Rhythmbox"))
	def get_items(self):
		# first try to load songs via dbus
		songs = list(_get_all_songs_via_dbus())
		if not songs:
			try:
				dbfile = config.get_data_file("rhythmdb.xml", "rhythmbox")
				songs = rhythmbox_support.get_rhythmbox_songs(dbfile=dbfile)
			except StandardError, e:
				self.output_error(e)
				songs = []
		albums = rhythmbox_support.parse_rhythmbox_albums(songs)
		artists = rhythmbox_support.parse_rhythmbox_artists(songs)
		yield Play()
		yield Pause()
		yield Next()
		yield Previous()
		yield ClearQueue()
		yield ShowPlaying()
		artist_source = RhythmboxArtistsSource(artists)
		album_source = RhythmboxAlbumsSource(albums)
		songs_source = RhythmboxSongsSource(artists)
		yield SourceLeaf(artist_source)
		yield SourceLeaf(album_source)
		yield SourceLeaf(songs_source)
		# we use get_leaves here to get sorting etc right
		if __kupfer_settings__["toplevel_artists"]:
			for leaf in artist_source.get_leaves():
				yield leaf
		if __kupfer_settings__["toplevel_albums"]:
			for leaf in album_source.get_leaves():
				yield leaf
		if __kupfer_settings__["toplevel_songs"]:
			for leaf in songs_source.get_leaves():
				yield leaf

	def get_description(self):
		return _("Play and enqueue tracks and browse the music library")
	def get_icon_name(self):
		return "rhythmbox"
	def provides(self):
		yield RunnableLeaf
		yield SourceLeaf
		yield SongLeaf

########NEW FILE########
__FILENAME__ = rhythmbox_support

import os
import xml.etree.cElementTree as ElementTree

NEEDED_KEYS= set(("title", "artist", "album", "track-number", "location", ))
UNICODE_KEYS = set(("title", "artist", "album"))

def _tounicode(bstr):
	# the XML parser returns `str' only when it's ascii, but we want
	# unicode objects all the time
	if isinstance(bstr, unicode):
		return bstr
	return bstr.decode("ascii")

def _lookup_string(string, strmap):
	"""Look up @string in the string map,
	and return the copy in the map.

	If not found, update the map with the string.
	"""
	string = string or ""
	try:
		return strmap[string]
	except KeyError:
		strmap[string] = string
		return string

def get_rhythmbox_songs(dbfile, typ="song", keys=NEEDED_KEYS):
	"""Return a list of info dictionaries for all songs
	in a Rhythmbox library database file, with dictionary
	keys as given in @keys.
	"""
	rhythmbox_dbfile = os.path.expanduser(dbfile)

	lSongs = []
	strmap = {}

	# Parse with iterparse; we get the elements when
	# they are finished, and can remove them directly after use.

	for event, entry in ElementTree.iterparse(rhythmbox_dbfile):
		if not (entry.tag == ("entry") and entry.get("type") == typ):
			continue
		info = {}
		for child in entry.getchildren():
			if child.tag in keys:
				if child.tag in UNICODE_KEYS:
					childtext = _tounicode(child.text)
				else:
					childtext = child.text
				tag = _lookup_string(child.tag, strmap)
				text = _lookup_string(childtext, strmap)
				info[tag] = text
		lSongs.append(info)
		entry.clear()
	return lSongs

def sort_album(album):
	"""Sort album in track order"""
	def get_track_number(rec):
		try:
			tnr = int(rec["track-number"])
		except (KeyError, ValueError):
			tnr = 0
		return tnr
	album.sort(key=get_track_number)

def sort_album_order(songs):
	"""Sort songs in order by album then by track number

	>>> songs = [
	... {"title": "a", "album": "B", "track-number": "2"},
	... {"title": "b", "album": "A", "track-number": "1"},
	... {"title": "c", "album": "B", "track-number": "1"},
	... ]
	>>> sort_album_order(songs)
	>>> [s["title"] for s in songs]
	['b', 'c', 'a']
	"""
	def get_album_order(rec):
		try:
			tnr = int(rec["track-number"])
		except (KeyError, ValueError):
			tnr = 0
		return (rec["album"], tnr)
	songs.sort(key=get_album_order)

def parse_rhythmbox_albums(songs):
	albums = {}
	for song in songs:
		song_artist = song["artist"]
		if not song_artist:
			continue
		song_album = song["album"]
		if not song_album:
			continue
		album = albums.get(song_album, [])
		album.append(song)
		albums[song_album] = album
	# sort album in track order
	for album in albums:
		sort_album(albums[album])
	return albums

def parse_rhythmbox_artists(songs):
	artists = {}
	for song in songs:
		song_artist = song["artist"]
		if not song_artist:
			continue
		artist = artists.get(song_artist, [])
		artist.append(song)
		artists[song_artist] = artist
	# sort in album + track order
	for artist in artists:
		sort_album_order(artists[artist])
	return artists

if __name__ == '__main__':
	import doctest
	doctest.testmod()

########NEW FILE########
__FILENAME__ = rst
__kupfer_name__ = _("reStructuredText")
__kupfer_actions__ = ("RenderView", )
__description__ = _("Render reStructuredText and show the result")
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import os

from kupfer.objects import Action, FileLeaf
from kupfer import utils, icons


# docutils is a critical import -- not a core kupfer dependency
import docutils.core

class RenderView (Action):
	def __init__(self):
		Action.__init__(self, _("View as HTML Document"))

	def activate(self, leaf):
		finput = open(leaf.object, "rb")
		(foutput, fpath) = utils.get_safe_tempfile()
		try:
			docutils.core.publish_file(finput,
					destination=foutput,
					writer_name="html")
		finally:
			finput.close()
			foutput.close()
		utils.show_path(fpath)
	def item_types(self):
		yield FileLeaf
	def valid_for_item(self, leaf):
		root, ext = os.path.splitext(leaf.object)
		return ext.lower() in (".rst", ".rest", ".txt")
	def get_description(self):
		return __description__
	def get_gicon(self):
		return icons.ComposedIcon(Action.get_icon_name(self), "python")

########NEW FILE########
__FILENAME__ = screen
__kupfer_name__ = _("GNU Screen")
__kupfer_sources__ = ("ScreenSessionsSource", )
__description__ = _("Active GNU Screen sessions")
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import os

from kupfer.objects import Leaf, Action, Source
from kupfer.obj.helplib import FilesystemWatchMixin
from kupfer import utils



def screen_sessions_infos():
	"""
	Yield tuples of pid, name, time, status
	for running screen sessions
	"""
	pipe = os.popen("screen -list")
	output = pipe.read()
	for line in output.splitlines():
		fields = line.split("\t")
		if len(fields) == 4:
			empty, pidname, time, status = fields
			pid, name = pidname.split(".", 1)
			time = time.strip("()")
			status = status.strip("()")
			yield (pid, name, time, status)

def get_username():
	"""Return username for current user"""
	import pwd
	info = pwd.getpwuid(os.geteuid())
	return info[0]

class ScreenSession (Leaf):
	"""Represented object is the session pid as string"""
	def get_actions(self):
		return (AttachScreen(),)

	def is_valid(self):
		for pid, name, time, status in screen_sessions_infos():
			if self.object == pid:
				return True
		else:
			return False

	def get_description(self):
		for pid, name, time, status in screen_sessions_infos():
			if self.object == pid:
				break
		else:
			return "%s (%s)" % (self.name, self.object)
		# Handle localization of status
		status_dict = {
			"Attached": _("Attached"),
			"Detached": _("Detached"),
		}
		status = status_dict.get(status, status)
		return (_("%(status)s session (%(pid)s) created %(time)s") %
				{"status": status, "pid": pid, "time": time})

	def get_icon_name(self):
		return "gnome-window-manager"

class ScreenSessionsSource (Source, FilesystemWatchMixin):
	"""Source for GNU Screen sessions"""
	def __init__(self):
		super(ScreenSessionsSource, self).__init__(_("Screen Sessions"))

	def initialize(self):
		## the screen dir might not exist when we start
		## luckily, gio can monitor directories before they exist
		self.screen_dir = (os.getenv("SCREENDIR") or
				"/var/run/screen/S-%s" % get_username())
		if not os.path.exists(self.screen_dir):
			self.output_debug("Screen socket dir or SCREENDIR not found")
		self.monitor_token = self.monitor_directories(self.screen_dir,
		                                              force=True)

	def get_items(self):
		if not os.path.exists(self.screen_dir):
			return
		for pid, name, time, status in screen_sessions_infos():
			yield ScreenSession(pid, name)

	def get_description(self):
		return _("Active GNU Screen sessions")
	def get_icon_name(self):
		return "terminal"
	def provides(self):
		yield ScreenSession

class AttachScreen (Action):
	"""
	"""
	def __init__(self):
		name = _("Attach")
		super(AttachScreen, self).__init__(name)
	def activate(self, leaf):
		pid = leaf.object
		action_argv = ['screen', '-x', '-R', ('%s' % pid)]
		utils.spawn_in_terminal(action_argv)


########NEW FILE########
__FILENAME__ = sendkeys

__kupfer_name__ = _("Send Keys")
__kupfer_actions__ = (
	"CopyAndPaste",
	"SendKeys",
	"TypeText",
	)
__description__ = _("Send synthetic keyboard events using "
                    "xautomation")
__version__ = ""
__author__ = ""

import gtk

from kupfer.objects import Leaf, Action, TextLeaf
from kupfer.objects import OperationError
from kupfer import utils
from kupfer import interface

# delay for first keypress and all following
INIT_DELAY = 'usleep 300000'
INTER_DELAY = 'usleep 50000'

class CopyAndPaste (Action):
	# rank down since it applies everywhere
	rank_adjust = -2
	def __init__(self):
		Action.__init__(self, _("Paste to Foreground Window"))
	def activate(self, leaf):
		clip = gtk.clipboard_get(gtk.gdk.SELECTION_CLIPBOARD)
		interface.copy_to_clipboard(leaf, clip)
		xte_paste_argv = ['xte', INIT_DELAY, 'keydown Control_L',
		                  'key v', 'keyup Control_L']
		try:
			utils.spawn_async_raise(xte_paste_argv)
		except utils.SpawnError as exc:
			raise OperationError(exc)
	def item_types(self):
		yield Leaf
	def valid_for_item(self, leaf):
		try:
			return bool(interface.get_text_representation(leaf))
		except AttributeError:
			pass
	def get_description(self):
		return _("Copy to clipboard and send Ctrl+V to foreground window")
	def get_icon_name(self):
		return "edit-paste"

class SendKeys (Action):
	def __init__(self):
		Action.__init__(self, _("Send Keys"))

	def activate(self, leaf):
		return self.activate_multiple((leaf, ))

	def activate_multiple(self, objects):
		xte_sendkey_argv = ['xte', INIT_DELAY]
		iterobjects = iter(objects)
		for obj in iterobjects:
			xte_sendkey_argv.extend(self.make_keystr_arguments(obj.object))
			break
		for obj in iterobjects:
			xte_sendkey_argv.append(INTER_DELAY)
			xte_sendkey_argv.extend(self.make_keystr_arguments(obj.object))

		try:
			utils.spawn_async_raise(xte_sendkey_argv)
		except utils.SpawnError as exc:
			raise OperationError(exc)

	def make_keystr_arguments(self, keystr):
		keys, orig_mods = gtk.accelerator_parse(keystr)
		m = {
			gtk.gdk.SHIFT_MASK: "Shift_L",
			gtk.gdk.CONTROL_MASK: "Control_L",
			gtk.gdk.SUPER_MASK: "Super_L",
			gtk.gdk.MOD1_MASK: "Alt_L",
		}
		mod_names = []
		mods = orig_mods
		for mod in m:
			if mod & mods:
				mod_names.append(m[mod])
				mods &= ~mod
		if mods != 0:
			raise OperationError("Keys not yet implemented: %s" %
					gtk.accelerator_get_label(keys, orig_mods))
		key_arg = 'key %s' % (gtk.gdk.keyval_name(keys), )
		mods_down = ['keydown ' + n for n in mod_names]
		mods_up = ['keyup ' + n for n in reversed(mod_names)]
		return mods_down + [key_arg] + mods_up

	def item_types(self):
		yield TextLeaf
	def valid_for_item(self, leaf):
		text = leaf.object
		keys, mods = gtk.accelerator_parse(text)
		return keys
	def get_description(self):
		return _("Send keys to foreground window")

class TypeText (Action):
	rank_adjust = -2 
	def __init__(self):
		Action.__init__(self, _("Type Text"))
	def activate(self, leaf):
		text = interface.get_text_representation(leaf)
		xte_paste_argv = ['xte', 'usleep 300000']
		# replace all newlines with 'key Return'
		for line in text.splitlines(True):
			xte_paste_argv.append("str " + line.rstrip("\r\n"))
			if line.endswith("\n"):
				xte_paste_argv.append("key Return")
		try:
			utils.spawn_async_raise(xte_paste_argv)
		except utils.SpawnError as exc:
			raise OperationError(exc)
	def item_types(self):
		yield Leaf
	def valid_for_item(self, leaf):
		try:
			return bool(interface.get_text_representation(leaf))
		except AttributeError:
			pass
	def get_description(self):
		return _("Type the text to foreground window")


########NEW FILE########
__FILENAME__ = services
# -*- coding: UTF-8 -*-
__kupfer_name__ = _("System Services")
__kupfer_sources__ = ("SystemServicesSource", )
__description__ = _("Start, stop or restart system services via init scripts")
__version__ = "0.2"
__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"

import os

from kupfer import plugin_support
from kupfer.objects import Leaf, Action, Source 
from kupfer.obj.helplib import FilesystemWatchMixin
from kupfer import utils

__kupfer_settings__ = plugin_support.PluginSettings(
	{
		'key': 'sudo_cmd',
		'label': _("Sudo-like Command"),
		'type': str,
		'value': 'gksu',
	},
)


# skip this services
_SERVICES_BLACK_LIST = [
		"acpid", "acpi-support", "alsa-utils", "apmd", "binfmt-support",
		"bootlogd", "bootmisc.sh", "checkfs.sh", "checkroot.sh",
		"console-screen.kbd.sh", "console-setup", "dbus", "dns-clean", "glibc.sh", 
		"hal", "halt", "hostname.sh", "hotkey-setup", "hwclockfirst.sh", 
		"hwclock.sh", "keyboard-setup", "killprocs", "klogd", "laptop-mode", 
		"linux-restricted-modules-common", "module-init-tools", 
		"mountall-bootclean.sh", "mountall.sh", "mountdevsubfs.sh", "mountkernfs.sh", 
		"mountnfs-bootclean.sh", "mountnfs.sh", "mountoverflowtmp", "mtab.sh",
		"policykit", "pppd-dns", "procps", "rc", "rc.local", "rcS", "reboot",   
		"readahead", "readahead-desktop", "rmnologin", "screen-cleanup", "sendsigs", 
		"single", "stop-bootlogd", "stop-bootlogd-single", "stop-readahead",
		"sysklogd", "system-tools-backends", "udev", "udev-finish", "umountfs", 
		"umountnfs.sh", "umountroot", "urandom", "vbesave", "wpa-ifupdown", "x11-common", 
		'README'
]


class Service(Leaf):
	""" Represent system service """
	def get_actions(self):
		yield StartService()
		yield StopService()
		yield RestartService()

	def get_description(self):
		return self.object

	def get_icon_name(self):
		return "applications-system"


class _ServiceAction(Action):
	def __init__(self, name, icon, command):
		Action.__init__(self, name)
		self._icon = icon
		self._command = command

	def get_icon_name(self):
		return self._icon

	def activate(self, leaf):
		sudo_cmd = __kupfer_settings__["sudo_cmd"]
		utils.spawn_in_terminal([sudo_cmd, leaf.object, self._command])

	def item_types(self):
		yield Service


class StartService(_ServiceAction):
	""" Start service action """
	def __init__(self):
		_ServiceAction.__init__(self, _('Start Service'), 'start', 'start')


class RestartService(_ServiceAction):
	""" restart service action """
	def __init__(self):
		_ServiceAction.__init__(self, _('Restart Service'), 'reload', 'restart')


class StopService(_ServiceAction):
	""" restart service action """
	def __init__(self):
		_ServiceAction.__init__(self, _('Stop Service'), 'stop', 'stop')


class SystemServicesSource(Source, FilesystemWatchMixin):
	''' Index system services from /etc/*/init.d/ '''

	def __init__(self, name=_("System Services")):
		Source.__init__(self, name)
		self._initd_path = None

	def initialize(self):
		# path to file with list notebooks
		for initd_path in ('/etc/init.d/', '/etc/rc.d/init.d', '/etc/rc.d'):
			if os.path.exists(initd_path) and os.path.isdir(initd_path):
				self._initd_path = initd_path
				self.monitor_token = self.monitor_directories(self._initd_path)
				break


	def monitor_include_file(self, gfile):
		return gfile and not gfile.get_basename() in _SERVICES_BLACK_LIST

	def get_items(self):
		if self._initd_path is None:
			return

		for filename in os.listdir(self._initd_path):
			if (filename in _SERVICES_BLACK_LIST \
					or filename.find('dpkg-') > 0 or filename.endswith('~') \
					or filename.startswith('.')):
				continue

			file_path = os.path.join(self._initd_path, filename)
			if not os.path.isfile(file_path):
				continue

			yield Service(file_path, _("%s Service") % filename)

	def should_sort_lexically(self):
		return True

	def get_icon_name(self):
		return "applications-system"

	def provides(self):
		yield Service


########NEW FILE########
__FILENAME__ = session_gnome
# -*- coding: UTF8 -*-
__kupfer_name__ = _("GNOME Session Management")
__kupfer_sources__ = ("GnomeItemsSource", )
__description__ = _("Special items and actions for GNOME environment")
__version__ = "2012-10-16"
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

"""
Changes:
	2012-10-16 Karol BÄ™dkowski:
		+ support Gnome3; closes lp#788713;
		  author: Joseph Lansdowne
"""

from kupfer.plugin import session_support as support


# sequences of argument lists
LOGOUT_CMD = (["gnome-panel-logout"],
              ["gnome-session-save", "--kill"],
              ["gnome-session-quit", "--logout"])
SHUTDOWN_CMD = (["gnome-panel-logout", "--shutdown"],
                ["gnome-session-save", "--shutdown-dialog"],
                ["gnome-session-quit", "--power-off"])
LOCKSCREEN_CMD = (["gnome-screensaver-command", "--lock"],
                  ["xdg-screensaver", "lock"])

class GnomeItemsSource (support.CommonSource):
	def __init__(self):
		support.CommonSource.__init__(self, _("GNOME Session Management"))
	def get_items(self):
		return (
			support.Logout(LOGOUT_CMD),
			support.LockScreen(LOCKSCREEN_CMD),
			support.Shutdown(SHUTDOWN_CMD),
		)


########NEW FILE########
__FILENAME__ = session_support
'''
Common objects for session_* plugins.
'''

from kupfer.objects import Source, RunnableLeaf
from kupfer import utils, pretty

__version__ = "2009-12-05"
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"


def launch_argv_with_fallbacks(commands, print_error=True):
	"""Try the sequence of @commands with utils.spawn_async,
	and return with the first successful command.
	return False if no command is successful and log an error
	"""
	for argv in commands:
		ret = utils.spawn_async(argv)
		if ret: return ret
	pretty.print_error(__name__, "Unable to run command(s)", commands)
	return False

class CommandLeaf (RunnableLeaf):
	"""The represented object of the CommandLeaf is a list of commandlines"""
	def run(self):
		launch_argv_with_fallbacks(self.object)

class Logout (CommandLeaf):
	"""Log out from desktop"""
	def __init__(self, commands, name=None):
		if not name: name = _("Log Out...")
		CommandLeaf.__init__(self, commands, name)
	def get_description(self):
		return _("Log out or change user")
	def get_icon_name(self):
		return "system-log-out"

class Shutdown (CommandLeaf):
	"""Shutdown computer or reboot"""
	def __init__(self, commands, name=None):
		if not name: name = _("Shut Down...")
		CommandLeaf.__init__(self, commands, name)
	def get_description(self):
		return _("Shut down, restart or suspend computer")
	def get_icon_name(self):
		return "system-shutdown"

class LockScreen (CommandLeaf):
	"""Lock screen"""
	def __init__(self, commands, name=None):
		if not name: name = _("Lock Screen")
		CommandLeaf.__init__(self, commands, name)
	def get_description(self):
		return _("Enable screensaver and lock")
	def get_icon_name(self):
		return "system-lock-screen"

class CommonSource (Source):
	def __init__(self, name):
		super(CommonSource, self).__init__(name)
	def is_dynamic(self):
		return True
	def get_icon_name(self):
		return "system-shutdown"
	def provides(self):
		yield RunnableLeaf

########NEW FILE########
__FILENAME__ = session_xfce
# -*- coding: utf-8 -*

__kupfer_name__ = _("XFCE Session Management")
__kupfer_sources__ = ("XfceItemsSource", )
__description__ = _("Special items and actions for XFCE environment")
__version__ = "2009-12-05"
__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"

from kupfer.plugin import session_support as support


# sequences of argument lists
LOGOUT_CMD = (["xfce4-session-logout", "--logout"],)
SHUTDOWN_CMD = (["xfce4-session-logout"],)
LOCKSCREEN_CMD = (["xdg-screensaver", "lock"], )


class XfceItemsSource (support.CommonSource):
	def __init__(self):
		support.CommonSource.__init__(self, _("XFCE Session Management"))
	def get_items(self):
		return (
			support.Logout(LOGOUT_CMD),
			support.LockScreen(LOCKSCREEN_CMD),
			support.Shutdown(SHUTDOWN_CMD),
		)

########NEW FILE########
__FILENAME__ = shorten_links
# -*- coding: UTF-8 -*-
__kupfer_name__ = _("Shorten Links")
__kupfer_actions__ = ("ShortenLinks", )
__description__ = _("Create short aliases of long URLs")
__version__ = "2011-03-01"
__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"

import httplib
import urllib

from kupfer.objects import Leaf, Action, Source, UrlLeaf, OperationError
from kupfer.plugin import ssl_support
from kupfer import pretty

class _ShortLinksService(Leaf):
	def __init__(self, name):
		Leaf.__init__(self, name, name)
	def get_icon_name(self):
		return "text-html"

class _GETService(_ShortLinksService, pretty.OutputMixin):
	""" A unified shortener service working with GET requests """
	host = None
	path = None
	url_key = "url"
	use_https = False

	def process(self, url):
		"""Shorten @url or raise ValueError"""
		query_string = urllib.urlencode({self.url_key : url})
		try:
			if self.use_https and ssl_support.is_supported():
				conn = ssl_support.VerifiedHTTPSConnection(self.host, timeout=5)
				pretty.print_debug(__name__, "Connected SSL to", self.host)
			else:
				conn = httplib.HTTPConnection(self.host, timeout=5)
			conn.request("GET", self.path+query_string)
			resp = conn.getresponse()
			if resp.status != 200:
				raise ValueError('Invalid response %d, %s' % (resp.status,
					resp.reason))
			
			result = resp.read()
			return result.strip()

		except (httplib.HTTPException, IOError, ValueError) as exc:
			raise ValueError(exc)
		return _('Error')


# NOTE: It's important that we use only sites that provide a stable API

class TinyUrl(_GETService):
	"""
	Website: http://tinyurl.com
	"""
	host = "tinyurl.com"
	path = "/api-create.php?"

	def __init__(self):
		_ShortLinksService.__init__(self, u'TinyUrl.com')

class IsGd(_GETService):
	"""
	Website: http://is.gd
	Reference: http://is.gd/apishorteningreference.php
	"""
	host = 'is.gd'
	path = '/create.php?format=simple&'

	def __init__(self):
		_ShortLinksService.__init__(self, u'Is.gd')

class VGd(_GETService):
	"""
	Website: http://v.gd
	Reference: http://v.gd/apishorteningreference.php

	Like is.gd, but v.gd always shows a preview page.
	"""
	host = 'v.gd'
	path = '/create.php?format=simple&'

	def __init__(self):
		_ShortLinksService.__init__(self, u'V.gd')

class BitLy(_GETService):
	"""
	Website: http://bit.ly
	Reference: http://code.google.com/p/bitly-api/wiki/ApiDocumentation
	"""
	# No password is available for this login name,
	# yet there is a possibility that you could track
	# all URLs shortened using this API key
	BITLY_LOGIN = "kupferkupfer"
	BITLY_API_KEY = "R_a617770f00b647d6c22ce162105125c2"

	host = 'api.bitly.com'
	path = ('/v3/shorten?login=%s&apiKey=%s&format=txt&' %
	        (BITLY_LOGIN, BITLY_API_KEY))
	url_key = "longUrl"

	def __init__(self):
		_ShortLinksService.__init__(self, u'Bit.ly')

class BitLySSL(BitLy):
	host = 'api-ssl.bitly.com'
	use_https = True

	def __init__(self):
		_ShortLinksService.__init__(self, u'Bit.ly (HTTPS)')
	def process(self, url):
		resp = BitLy.process(self, url)
		return resp.replace("http://bit.ly", "https://bit.ly")


class ShortenLinks(Action):
	''' Shorten links with selected engine '''

	def __init__(self):
		Action.__init__(self, _('Shorten With...'))

	def has_result(self):
		return True

	def activate(self, leaf, iobj):
		try:
			result = iobj.process(leaf.object)
		except ValueError as exc:
			raise OperationError(unicode(exc))
		return UrlLeaf(result, result)

	def item_types(self):
		yield UrlLeaf

	def requires_object(self):
		return True

	def object_types(self):
		yield _ShortLinksService

	def object_source(self, for_item=None):
		return ServicesSource()

	def get_description(self):
		return __description__


class ServicesSource(Source):
	def __init__(self):
		Source.__init__(self, _("Services"))

	def get_items(self):
		yield TinyUrl()
		yield IsGd()
		yield VGd()
		yield BitLy()
		if ssl_support.is_supported():
			yield BitLySSL()

	def should_sort_lexically(self):
		return True

	def get_icon_name(self):
		return "applications-internet"

########NEW FILE########
__FILENAME__ = show_qrcode
"""Create QRCodes from texts or urls. Useful for smartphones with QRCode
readers: Create some url with kupfer and QRCode it. Get it with the phone and 
use it's browser to display"""

__kupfer_name__ = _("Show QRCode")
__kupfer_actions__ = (
			"ShowQRCode",
	)
__description__ = _("Display text as QRCode in a window")
__version__ = "0.0.2"
__author__ = "Thomas Renard <cybaer42@web.de>"

import StringIO

import gtk
import qrencode

from kupfer.objects import Action, Leaf

class ShowQRCode (Action):
	"""Create QRCode windows from text or url"""

	def __init__(self):
		"""initialize action"""
		Action.__init__(self, _("Show QRCode"))

	def wants_context(self):
		return True

	def activate(self, leaf, ctx):
		"""Create the image from leaf text and display it on window"""

		image_file = StringIO.StringIO()
		text = leaf.get_text_representation()
		version, size, image = qrencode.encode_scaled(text, size=300)
		image.save(image_file, "ppm")
		image_contents = image_file.getvalue()
		image_file.close()

		loader = gtk.gdk.PixbufLoader("pnm")
		loader.write(image_contents, len(image_contents))
		pixbuf = loader.get_pixbuf()
		loader.close()
		window = gtk.Window()
		window.set_default_size(350, 350)
		image = gtk.Image()
		image.set_from_pixbuf(pixbuf)
		image.show()
		window.add(image)
		ctx.environment.present_window(window)

	def item_types(self):
		yield Leaf

	def valid_for_item(self, leaf):
		return hasattr(leaf, "get_text_representation")

	def get_description(self):
		"""The Action description"""
		return _("Display text as QRCode in a window")

	def get_icon_name(self):
		"""Name of the icon"""
		return "format-text-bold"


########NEW FILE########
__FILENAME__ = show_text
__kupfer_name__ = _("Show Text")
__kupfer_actions__ = (
		"ShowText",
		"LargeType",
		"ShowNotification",
	)
__description__ = _("Display text in a window")
__version__ = ""
__author__ = "US"

from kupfer.objects import Action, Leaf, TextLeaf
from kupfer import icons, uiutils
from kupfer import textutils


class ShowText (Action):
	def __init__(self):
		Action.__init__(self, _("Show Text"))

	def wants_context(self):
		return True

	def activate(self, leaf, ctx):
		uiutils.show_text_result(leaf.get_text_representation(),
			title=_("Show Text"), ctx=ctx)

	def item_types(self):
		yield TextLeaf

	def get_description(self):
		return _("Display text in a window")
	def get_icon_name(self):
		return "format-text-bold"

class LargeType (Action):
	def __init__(self):
		Action.__init__(self, _("Large Type"))

	def wants_context(self):
		return True

	def activate(self, leaf, ctx):
		return self.activate_multiple((leaf, ), ctx)

	def activate_multiple(self, objects, ctx):
		all_texts = []
		for obj in objects:
			all_texts.append(obj.get_text_representation())
		uiutils.show_large_type("\n".join(all_texts), ctx)

	def item_types(self):
		yield Leaf

	def valid_for_item(self, obj):
		return hasattr(obj, "get_text_representation")

	def get_description(self):
		return _("Display text in a window")
	def get_gicon(self):
		return icons.ComposedIcon("format-text-bold", "zoom-in")
	def get_icon_name(self):
		return "format-text-bold"

class ShowNotification (Action):
	def __init__(self):
		Action.__init__(self, _("Show Notification"))

	def activate(self, leaf):
		title, body = textutils.extract_title_body(leaf.object)
		if body:
			uiutils.show_notification(title, body,
					icon_name=self.get_icon_name())
		else:
			uiutils.show_notification(title)

	def item_types(self):
		yield TextLeaf

	def get_icon_name(self):
		return "format-text-bold"


########NEW FILE########
__FILENAME__ = skype
# -*- coding: UTF-8 -*-
__kupfer_name__ = _("Skype")
__kupfer_sources__ = ("ContactsSource", )
__kupfer_actions__ = ("ChangeStatus", 'Chat', 'Call')
__description__ = _("Access to Skype contacts")
__version__ = "2011-02-05"
__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"

import dbus

from kupfer.objects import Leaf, Action, Source
from kupfer.objects import AppLeaf
from kupfer import pretty, icons
from kupfer import plugin_support
from kupfer.obj.apps import AppLeafContentMixin
from kupfer.obj.grouping import ToplevelGroupingSource
from kupfer.obj.contacts import ContactLeaf, SkypeContact



# This plugin Requires D-Bus to work
plugin_support.check_dbus_connection()

SKYPE_IFACE = 'com.Skype.API'
SKYPE_PATH_CLIENT = '/com/Skype/Client'
SKYPE_CLIENT_API = 'com.Skype.API.Client'
SKYPE_KEY = "SKYPE"

_STATUSES = {
		'ONLINE':	_('Available'),
		'SKYPEME':	_('Skype Me'),
		'AWAY':		_('Away'),
		'NA':		_('Not Available'),
		'DND':		_('Busy'),
		'INVISIBLE':_('Invisible'),
		'OFFLINE':	_('Offline'),
		'LOGGEDOUT': _('Logged Out')
}


def _parse_response(response, prefix):
	if response.startswith(prefix):
		return response[len(prefix):].strip()
	return None


class _SkypeNotify(dbus.service.Object):
	def __init__(self, bus, callback):
		dbus.service.Object.__init__(self, bus, SKYPE_PATH_CLIENT)
		self._callback = callback

	@dbus.service.method(SKYPE_CLIENT_API, in_signature='s')
	def Notify(self, com):
		pretty.print_debug(__name__, '_SkypeNotify', 'Notify', com)
		self._callback(com)


class Skype(object):
	""" Handling events from skype"""
	__instance__ = None

	@classmethod
	def get(cls):
		if cls.__instance__ is None:
			cls.__instance__ = cls()
		return cls.__instance__

	def __init__(self):
		self._friends = None
		self._authenticated = False
		try:
			self.bus = bus = dbus.Bus()
		except dbus.DBusException, err:
			pretty.print_error(__name__, 'Skype', '__init__', err)
			return

		self._dbus_name_owner_watch = bus.add_signal_receiver(
				self._signal_dbus_name_owner_changed,
				'NameOwnerChanged',
				'org.freedesktop.DBus',
				'org.freedesktop.DBus',
				'/org/freedesktop/DBus',
				arg0=SKYPE_IFACE)

		self._skype_notify_callback = _SkypeNotify(bus, self._signal_update)
		self._signal_dbus_name_owner_changed()

	def __del__(self):
		if self.bus:
			self.bus.remove_signal_receiver(self._dbus_name_owner_watch)

		self._dbus_name_owner_watch = None
		self._skype_notify_callback = None


	def _get_skype(self, bus):
		''' Check if Skype is running and login to it.
			Return Skype proxy object.
		'''
		try:
			proxy_obj = bus.get_object('org.freedesktop.DBus', '/org/freedesktop/DBus')
			dbus_iface = dbus.Interface(proxy_obj, 'org.freedesktop.DBus')
			if dbus_iface.NameHasOwner(SKYPE_IFACE):
				skype = bus.get_object(SKYPE_IFACE, '/com/Skype')
				if skype and not self._authenticated:
					resp = skype.Invoke("NAME Kupfer")
					if resp.startswith('ERROR'):
						return None
					resp = skype.Invoke("PROTOCOL 5")
					if  resp != 'PROTOCOL 5':
						return None
					self._authenticated = True
				return skype
		except dbus.exceptions.DBusException, err:
			pretty.print_debug(__name__, 'Skype', '_get_skype', err)
		return None

	def _signal_dbus_name_owner_changed(self, *args, **kwarg):
		pretty.print_debug(__name__, 'Skype', '_signal_dbus_name_owner_changed',
				args, kwarg)
		self._authenticated = False
		self._signal_update(*args, **kwarg)

	def _signal_update(self, *args, **kwargs):
		pretty.print_debug(__name__, 'Skype', '_signal_update', args, kwargs)
		self._friends = None

	def _get_friends(self):
		pretty.print_debug(__name__, 'Skype', '_get_friends')
		self._friends = []
		skype = self._get_skype(self.bus)
		if not skype:
			return
		users =  skype.Invoke("SEARCH FRIENDS")
		if not users.startswith('USERS '):
			return
		users = users[6:].split(',')
		for user in users:
			user = user.strip()
			fullname = skype.Invoke('GET USER %s FULLNAME' % user)
			fullname = _parse_response(fullname, 'USER %s FULLNAME' % user)
			displayname = skype.Invoke('GET USER %s DISPLAYNAME' % user)
			displayname = _parse_response(displayname, 'USER %s DISPLAYNAME' % user)
			status = skype.Invoke('GET USER %s ONLINESTATUS' % user)
			status = _parse_response(status, 'USER %s ONLINESTATUS' % user)
			contact = Contact((displayname or fullname or user), user, status)
			self._friends.append(contact)

	@property
	def friends(self):
		if self._friends is None:
			self._get_friends()
		return self._friends

	def open_chat(self, handle):
		skype = self._get_skype(self.bus)
		if not skype:
			return
		resp = skype.Invoke("CHAT CREATE %s" % handle)
		if resp.startswith('CHAT '):
			_chat, chat_id, _status, status = resp.split()
			skype.Invoke('OPEN CHAT %s' % chat_id)

	def call(self, handle):
		skype = self._get_skype(self.bus)
		if skype:
			skype.Invoke("CALL %s" % handle)

	def set_status(self, status):
		skype = self._get_skype(self.bus)
		if skype:
			skype.Invoke("SET USERSTATUS %s" % status)


class Contact(SkypeContact):
	def __init__(self, name, handle, status):
		SkypeContact.__init__(self, handle, name)
		self.kupfer_add_alias(handle)
		self._description = _("[%(status)s] %(userid)s") % \
			dict(status=status, userid=handle)

	def get_description(self):
		return self._description

	def get_gicon(self):
		return icons.ComposedIconSmall(self.get_icon_name(), "skype")


class AccountStatus(Leaf):
	pass


class Chat(Action):
	rank_adjust = 5

	def __init__(self):
		Action.__init__(self, _("Open Chat"))

	def activate(self, leaf):
		handle = SKYPE_KEY in leaf and leaf[SKYPE_KEY]
		if handle:
			Skype.get().open_chat(handle)

	def item_types(self):
		yield ContactLeaf

	def valid_for_item(self, item):
		return SKYPE_KEY in item and item[SKYPE_KEY]

	def get_icon_name(self):
		return 'internet-group-chat'


class Call(Action):
	rank_adjust = 5

	def __init__(self):
		Action.__init__(self, _("Call"))

	def activate(self, leaf):
		handle = SKYPE_KEY in leaf and leaf[SKYPE_KEY]
		if handle:
			Skype.get().call(handle)

	def item_types(self):
		yield ContactLeaf

	def valid_for_item(self, item):
		return SKYPE_KEY in item and item[SKYPE_KEY]

	def get_description(self):
		return _("Place a call to contact")

	def get_icon_name(self):
		return 'call-start'


class ChangeStatus(Action):
	''' Change global status '''
	rank_adjust = 5

	def __init__(self):
		Action.__init__(self, _('Change Global Status To...'))

	def activate(self, leaf, iobj):
		Skype.get().set_status(iobj.object)

	def item_types(self):
		yield AppLeaf

	def valid_for_item(self, leaf):
		return leaf.get_id() == 'skype'

	def requires_object(self):
		return True

	def object_types(self):
		yield AccountStatus

	def object_source(self, for_item=None):
		return StatusSource()


class ContactsSource(AppLeafContentMixin, ToplevelGroupingSource):
	appleaf_content_id = 'skype'

	def __init__(self, name=_('Skype Contacts')):
		super(ContactsSource, self).__init__(name, "Contacts")
		self._version = 3

	def get_items(self):
		pretty.print_debug(__name__, 'ContactsSource', 'get_items')
		return Skype.get().friends

	def get_icon_name(self):
		return 'skype'

	def provides(self):
		yield Contact

	def is_dynamic(self):
		return True


class StatusSource(Source):
	def __init__(self):
		Source.__init__(self, _("Skype Statuses"))

	def get_items(self):
		for status, name in _STATUSES.iteritems():
			yield AccountStatus(status, name)

	def provides(self):
		yield AccountStatus


########NEW FILE########
__FILENAME__ = ssh_hosts
# -*- coding: UTF-8 -*-
__kupfer_name__ = _("SSH Hosts")
__description__ = _("Adds the SSH hosts found in ~/.ssh/config.")
__version__ = "2010-04-12"
__author__ = "Fabian CarlstrÃ¶m"

__kupfer_sources__ = ("SSHSource", )
__kupfer_actions__ = ("SSHConnect", )

import codecs
import os

from kupfer import icons, utils
from kupfer.objects import Action
from kupfer.obj.helplib import FilesystemWatchMixin
from kupfer.obj.grouping import ToplevelGroupingSource
from kupfer.obj.hosts import HOST_NAME_KEY, HostLeaf, HOST_SERVICE_NAME_KEY, \
		HOST_ADDRESS_KEY



class SSHLeaf (HostLeaf):
	"""The SSH host. It only stores the "Host" as it was
	specified in the ssh config.
	"""
	def __init__(self, name):
		slots = {HOST_NAME_KEY: name, HOST_ADDRESS_KEY: name,
				HOST_SERVICE_NAME_KEY: "ssh"}
		HostLeaf.__init__(self, slots, name)

	def get_description(self):
		return _("SSH host")

	def get_gicon(self):
		return icons.ComposedIconSmall(self.get_icon_name(), "applications-internet")


class SSHConnect (Action):
	"""Used to launch a terminal connecting to the specified
	SSH host.
	"""
	def __init__(self):
		Action.__init__(self, name=_("Connect"))

	def activate(self, leaf):
		utils.spawn_in_terminal(["ssh", leaf[HOST_ADDRESS_KEY]])

	def get_description(self):
		return _("Connect to SSH host")

	def get_icon_name(self):
		return "network-server"

	def item_types(self):
		yield HostLeaf

	def valid_for_item(self, item):
		if item.check_key(HOST_SERVICE_NAME_KEY):
			return item[HOST_SERVICE_NAME_KEY] == 'ssh'
		return False


class SSHSource (ToplevelGroupingSource, FilesystemWatchMixin):
	"""Reads ~/.ssh/config and creates leaves for the hosts found.
	"""
	_ssh_home = os.path.expanduser("~/.ssh/")
	_ssh_config_file = "config"
	_config_path = os.path.join(_ssh_home, _ssh_config_file)

	def __init__(self, name=_("SSH Hosts")):
		ToplevelGroupingSource.__init__(self, name, "hosts")
		self._version = 2

	def initialize(self):
		ToplevelGroupingSource.initialize(self)
		self.monitor_token = self.monitor_directories(self._ssh_home)

	def monitor_include_file(self, gfile):
		return gfile and gfile.get_basename() == self._ssh_config_file

	def get_items(self):
		try:
			content = codecs.open(self._config_path, "r", "UTF-8").readlines()
			for line in content:
				line = line.strip()
				words = line.split()
				# Take every word after "Host" as an individual host
				# we must skip entries with wildcards
				if words and words[0].lower() == "host":
					for word in words[1:]:
						if "*" in word:
							continue
						yield SSHLeaf(word)
		except EnvironmentError, exc:
			self.output_error(exc)
		except UnicodeError, exc:
			self.output_error("File %s not in expected encoding (UTF-8)" %
					self._config_path)
			self.output_error(exc)

	def get_description(self):
		return _("SSH hosts as specified in ~/.ssh/config")

	def get_icon_name(self):
		return "applications-internet"

	def provides(self):
		yield SSHLeaf


########NEW FILE########
__FILENAME__ = ssl_support
"""
Stub implementation of HTTPS connections.
"""

class VerifiedHTTPSConnection (object):
	"implementation stub"
	def __init__(self, host, *args, **kwargs):
		pass
	@classmethod
	def is_ssl_supported(cls):
		return False

def is_supported():
	return VerifiedHTTPSConnection and VerifiedHTTPSConnection.is_ssl_supported()

########NEW FILE########
__FILENAME__ = templates
__kupfer_name__ = _("Document Templates")
__kupfer_sources__ = ("TemplatesSource", )
__kupfer_actions__ = ("CreateNewDocument", )
__description__ = _("Create new documents from your templates")
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import os

import gio
import glib

from kupfer.objects import Leaf, Action, Source, FileLeaf
from kupfer import icons, utils
from kupfer.obj import helplib
from kupfer.obj.helplib import FilesystemWatchMixin

DEFAULT_TMPL_DIR = "~/Templates"

class Template (FileLeaf):
	def __init__(self, path):
		basename = glib.filename_display_basename(path)
		nameroot, ext = os.path.splitext(basename)
		FileLeaf.__init__(self, path, _("%s template") % nameroot)

	def get_actions(self):
		yield CreateDocumentIn()
		for a in FileLeaf.get_actions(self):
			yield a

	def get_gicon(self):
		file_gicon = FileLeaf.get_gicon(self)
		return icons.ComposedIcon("text-x-generic-template", file_gicon)

class EmptyFile (Leaf):
	def __init__(self):
		Leaf.__init__(self, None, _("Empty File"))
	def repr_key(self):
		return ""
	def get_actions(self):
		yield CreateDocumentIn()
	def get_icon_name(self):
		return "text-x-generic"

class NewFolder (Leaf):
	def __init__(self):
		Leaf.__init__(self, None, _("New Folder"))
	def repr_key(self):
		return ""
	def get_actions(self):
		yield CreateDocumentIn()
	def get_icon_name(self):
		return "folder"

class CreateNewDocument (Action):
	def __init__(self):
		Action.__init__(self, _("Create New Document..."))

	def has_result(self):
		return True
	def activate(self, leaf, iobj):
		if iobj.object is not None:
			# Copy the template to destination directory
			basename = os.path.basename(iobj.object)
			tmpl_gfile = gio.File(iobj.object)
			destpath = utils.get_destpath_in_directory(leaf.object, basename)
			destfile = gio.File(destpath)
			tmpl_gfile.copy(destfile, flags=gio.FILE_COPY_ALL_METADATA)
		elif isinstance(iobj, NewFolder):
			filename = unicode(iobj)
			destpath = utils.get_destpath_in_directory(leaf.object, filename)
			os.makedirs(destpath)
		else:
			# create new empty file
			filename = unicode(iobj)
			f, destpath = utils.get_destfile_in_directory(leaf.object, filename)
			f.close()
		return FileLeaf(destpath)

	def item_types(self):
		yield FileLeaf
	def valid_for_item(self, leaf):
		return leaf.is_dir()

	def requires_object(self):
		return True
	def object_types(self):
		yield Template
		yield EmptyFile
		yield NewFolder

	def object_source(self, for_item=None):
		return TemplatesSource()

	def get_description(self):
		return _("Create a new document from template")
	def get_icon_name(self):
		return "document-new"

class CreateDocumentIn(helplib.reverse_action(CreateNewDocument)):
	rank_adjust = 10
	def __init__(self):
		Action.__init__(self, _("Create Document In..."))

class TemplatesSource (Source, FilesystemWatchMixin):
	def __init__(self):
		Source.__init__(self, _("Document Templates"))

	@classmethod
	def _get_tmpl_dir(self):
		tmpl_dir = glib.get_user_special_dir(glib.USER_DIRECTORY_TEMPLATES)
		if not tmpl_dir:
			tmpl_dir = os.path.expanduser(DEFAULT_TMPL_DIR)
		return tmpl_dir

	def initialize(self):
		self.monitor_token = self.monitor_directories(self._get_tmpl_dir())

	def get_items(self):
		tmpl_dir = self._get_tmpl_dir()
		yield EmptyFile()
		yield NewFolder()
		try:
			for fname in os.listdir(tmpl_dir):
				yield Template(os.path.join(tmpl_dir, fname))
		except EnvironmentError, exc:
			self.output_error(exc)

	def should_sort_lexically(self):
		return True

	def get_description(self):
		return None
	def get_icon_name(self):
		return "system-file-manager"

	def provides(self):
		yield Template


########NEW FILE########
__FILENAME__ = textfiles
"""
Work with Textfiles: Allow appending and writing new files,
or extracting the content of files.

All Text in Kupfer is in unicode. When we read from textfiles or write
to textfiles, we always work in the locale-defined encoding.

FIXME: Be less strict (use UTF-8 if locale says Ascii)
"""

from __future__ import with_statement

__kupfer_name__ = _("Textfiles")
__kupfer_actions__ = (
		"AppendTo",
		"AppendText",
		"WriteTo",
		"GetTextContents",
	)
__description__ = None
__version__ = "0.1"
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import gio

from kupfer.objects import Action
from kupfer.objects import TextLeaf, FileLeaf
from kupfer.obj import helplib
from kupfer import kupferstring
from kupfer import utils

# FIXME: Sometimes require that the type is *exactly* text/plain?

def is_content_type(fileleaf, ctype):
	predicate = gio.content_type_is_a
	ctype_guess, uncertain = gio.content_type_guess(fileleaf.object, None, True)
	ret = predicate(ctype_guess, ctype)
	if ret or not uncertain:
		return ret
	content_attr = gio.FILE_ATTRIBUTE_STANDARD_CONTENT_TYPE
	gfile = gio.File(fileleaf.object)
	if not gfile.query_exists(None):
		return
	info = gfile.query_info(content_attr)
	content_type = info.get_attribute_string(content_attr)
	return predicate(content_type, ctype)

class AppendTo (Action):
	def __init__(self, name=None):
		if not name:
			name = _("Append To...")
		Action.__init__(self, name)

	def activate(self, leaf, iobj):
		l_text = kupferstring.tolocale(leaf.object)
		with open(iobj.object, "ab") as outfile:
			outfile.write(l_text)
			outfile.write("\n")

	def item_types(self):
		yield TextLeaf

	def requires_object(self):
		return True
	def object_types(self):
		yield FileLeaf
	def valid_object(self, iobj, for_item=None):
		return is_content_type(iobj, "text/plain")

	def get_icon_name(self):
		return "list-add"

class AppendText (helplib.reverse_action(AppendTo)):
	def __init__(self):
		Action.__init__(self, _("Append..."))

class WriteTo (Action):
	def __init__(self):
		Action.__init__(self, _("Write To..."))

	def has_result(self):
		return True

	def activate(self, leaf, iobj):
		outfile, outpath = \
				utils.get_destfile_in_directory(iobj.object, _("Empty File"))
		try:
			l_text = kupferstring.tolocale(leaf.object)
			outfile.write(l_text)
			if not l_text.endswith("\n"):
				outfile.write("\n")
		finally:
			outfile.close()
		return FileLeaf(outpath)

	def item_types(self):
		yield TextLeaf

	def requires_object(self):
		return True
	def object_types(self):
		yield FileLeaf
	def valid_object(self, iobj, for_item=None):
		return iobj.is_dir()

	def get_icon_name(self):
		return "document-new"

class GetTextContents (Action):
	def __init__(self):
		Action.__init__(self, _("Get Text Contents"))

	def has_result(self):
		return True

	def activate(self, leaf):
		with open(leaf.object, "rb") as infile:
			l_text = infile.read()
			us_text = kupferstring.fromlocale(l_text)
		return TextLeaf(us_text)

	def item_types(self):
		yield FileLeaf
	def valid_for_item(self, item):
		return is_content_type(item, "text/plain")

	def get_icon_name(self):
		return "edit-copy"

########NEW FILE########
__FILENAME__ = thunar
__kupfer_name__ = _("Thunar")
__kupfer_sources__ = ("ThunarObjects", )
__kupfer_actions__ = (
	"Reveal",
	"GetInfo",
	"SendTo",
	"CopyTo",
	"LinkTo",
	"MoveTo",
)
__description__ = _("File manager Thunar actions")
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import os

import dbus
import gio

from kupfer.objects import Action, Source
from kupfer.objects import InvalidDataError, NotAvailableError, NoMultiError
from kupfer.objects import FileLeaf, RunnableLeaf, AppLeaf
from kupfer.obj.apps import AppLeafContentMixin
from kupfer import config
from kupfer import plugin_support
from kupfer import pretty

plugin_support.check_dbus_connection()

SERVICE_NAME = "org.xfce.Thunar"
OBJECT_PATH = "/org/xfce/FileManager"
IFACE_NAME = "org.xfce.FileManager"

TRASH_IFACE_NAME = "org.xfce.Trash"

def _get_thunar():
	"""Return the dbus proxy object for Thunar
	we will activate it over d-bus (start if not running)
	"""
	bus = dbus.SessionBus()
	try:
		proxy_obj = bus.get_object(SERVICE_NAME, OBJECT_PATH)
	except dbus.DBusException, e:
		pretty.print_error(__name__, e)
		return
	iface_obj = dbus.Interface(proxy_obj, IFACE_NAME)
	return iface_obj

def _get_thunar_trash():
	"""Return the dbus proxy object for Thunar
	we will activate it over d-bus (start if not running)
	"""
	bus = dbus.SessionBus()
	try:
		proxy_obj = bus.get_object(SERVICE_NAME, OBJECT_PATH)
	except dbus.DBusException, e:
		pretty.print_error(__name__, e)
		return
	iface_obj = dbus.Interface(proxy_obj, TRASH_IFACE_NAME)
	return iface_obj

def _dummy(*args):
	pass

class Reveal (Action):
	def __init__(self):
		Action.__init__(self, _("Select in File Manager"))

	def wants_context(self):
		return True

	def activate(self, leaf, ctx):
		gfile = gio.File(leaf.object)
		parent = gfile.get_parent()
		if not parent:
			return
		uri = parent.get_uri()
		bname = gfile.get_basename()
		id_ = ctx.environment.get_startup_notification_id()
		display = ctx.environment.get_display()
		try:
			# Thunar 1.2 Uses $DISPLAY and $STARTUP_ID args
			_get_thunar().DisplayFolderAndSelect(uri, bname, display,
				id_, reply_handler=_dummy, error_handler=_dummy)
		except TypeError:
			# Thunar 1.0 Uses $DISPLAY
			_get_thunar().DisplayFolderAndSelect(uri, bname, display,
				reply_handler=_dummy, error_handler=_dummy)

	def item_types(self):
		yield FileLeaf

class GetInfo (Action):
	def __init__(self):
		Action.__init__(self, _("Show Properties"))

	def wants_context(self):
		return True

	def activate(self, leaf, ctx):
		gfile = gio.File(leaf.object)
		uri = gfile.get_uri()
		id_ = ctx.environment.get_startup_notification_id()
		display = ctx.environment.get_display()
		try:
			# Thunar 1.2 Uses $DISPLAY and $STARTUP_ID args
			_get_thunar().DisplayFileProperties(uri, display,
				id_, reply_handler=_dummy, error_handler=_dummy)
		except TypeError:
			# Thunar 1.0 Uses $DISPLAY
			_get_thunar().DisplayFileProperties(uri, display,
				reply_handler=_dummy, error_handler=_dummy)

	def item_types(self):
		yield FileLeaf

	def get_description(self):
		return _("Show information about file in file manager")

	def get_icon_name(self):
		return "dialog-information"


class SendTo (Action):
	""" Send files to  selected app from "send to" list """
	def __init__(self):
		Action.__init__(self, _("Send To..."))

	def activate_multiple(self, leaves, iobjs):
		for app in iobjs:
			app.launch(paths=[leaf.object for leaf in leaves])

	def activate(self, leaf, iobj):
		self.activate_multiple((leaf, ), (iobj, ))

	def item_types(self):
		yield FileLeaf

	def requires_object(self):
		return True

	def object_types(self):
		yield AppLeaf

	def object_source(self, for_item=None):
		return _SendToAppsSource()

def _good_destination(dpath, spath):
	"""If directory path @dpath is a valid destination for file @spath
	to be copied or moved to. 
	"""
	if not os.path.isdir(dpath):
		return False
	spath = os.path.normpath(spath)
	dpath = os.path.normpath(dpath)
	cpfx = os.path.commonprefix((spath, dpath))
	if os.path.samefile(dpath, spath) or cpfx == spath:
		return False
	return True

def path_to_uri(filepath):
	return gio.File(filepath).get_uri()

class CopyTo (Action, pretty.OutputMixin):
	def __init__(self):
		Action.__init__(self, _("Copy To..."))

	def wants_context(self):
		return True

	def activate_multiple(self, leaves, iobjects, ctx):
		# Unroll by looping over the destinations,
		# copying everything into each destination
		thunar = _get_thunar()
		work_dir = os.path.expanduser("~/")
		display = ctx.environment.get_display()
		notify_id = ctx.environment.get_startup_notification_id()
		sourcefiles = [path_to_uri(L.object) for L in leaves]

		def _reply(*args):
			self.output_debug("reply got for copying", *args)

		def _reply_error(exc):
			self.output_debug(exc)
			ctx.register_late_error(NotAvailableError(_("Thunar")))

		for dest_iobj in iobjects:
			desturi = path_to_uri(dest_iobj.object)
			thunar.CopyInto(work_dir, sourcefiles, desturi, display, notify_id,
			                reply_handler=_reply,
			                error_handler=_reply_error)

	def activate(self, leaf, iobj, ctx):
		return self.activate_multiple([leaf], [iobj], ctx)

	def item_types(self):
		yield FileLeaf
	def valid_for_item(self, item):
		return True
	def requires_object(self):
		return True
	def object_types(self):
		yield FileLeaf
	def valid_object(self, obj, for_item):
		return _good_destination(obj.object, for_item.object)
	def get_description(self):
		return _("Copy file to a chosen location")

class MoveTo (Action, pretty.OutputMixin):
	def __init__(self):
		Action.__init__(self, _("Move To..."))

	def wants_context(self):
		return True

	def activate_multiple(self, leaves, iobjects, ctx):
		if len(iobjects) != 1:
			raise NoMultiError()

		def _reply():
			self.output_debug("reply got for moving")

		def _reply_error(exc):
			self.output_debug(exc)
			ctx.register_late_error(NotAvailableError(_("Thunar")))

		(dest_iobj,) = iobjects
		# Move everything into the destination
		thunar = _get_thunar()
		work_dir = os.path.expanduser("~/")
		display = ctx.environment.get_display()
		notify_id = ctx.environment.get_startup_notification_id()
		sourcefiles = [path_to_uri(L.object) for L in leaves]
		desturi = path_to_uri(dest_iobj.object)
		thunar.MoveInto(work_dir, sourcefiles, desturi, display, notify_id,
		                reply_handler=_reply,
		                error_handler=_reply_error)

	def activate(self, leaf, iobj, ctx):
		return self.activate_multiple([leaf], [iobj], ctx)

	def item_types(self):
		yield FileLeaf
	def valid_for_item(self, item):
		return True
	def requires_object(self):
		return True
	def object_types(self):
		yield FileLeaf
	def valid_object(self, obj, for_item):
		return _good_destination(obj.object, for_item.object)
	def get_description(self):
		return _("Move file to new location")
	def get_icon_name(self):
		return "go-next"

class LinkTo (Action, pretty.OutputMixin):
	def __init__(self):
		Action.__init__(self, _("Symlink In..."))

	def wants_context(self):
		return True

	def activate_multiple(self, leaves, iobjects, ctx):
		# Unroll by looping over the destinations,
		# copying everything into each destination
		thunar = _get_thunar()
		work_dir = os.path.expanduser("~/")
		display = ctx.environment.get_display()
		notify_id = ctx.environment.get_startup_notification_id()
		sourcefiles = [path_to_uri(L.object) for L in leaves]

		def _reply(*args):
			self.output_debug("reply got for copying", *args)

		def _reply_error(exc):
			self.output_debug(exc)
			ctx.register_late_error(NotAvailableError(_("Thunar")))

		for dest_iobj in iobjects:
			desturi = path_to_uri(dest_iobj.object)
			thunar.LinkInto(work_dir, sourcefiles, desturi, display, notify_id,
			                reply_handler=_reply,
			                error_handler=_reply_error)

	def activate(self, leaf, iobj, ctx):
		return self.activate_multiple([leaf], [iobj], ctx)

	def item_types(self):
		yield FileLeaf
	def valid_for_item(self, item):
		return True
	def requires_object(self):
		return True
	def object_types(self):
		yield FileLeaf
	def valid_object(self, obj, for_item):
		return _good_destination(obj.object, for_item.object)
	def get_description(self):
		return _("Create a symlink to file in a chosen location")

class EmptyTrash (RunnableLeaf):
	def __init__(self):
		RunnableLeaf.__init__(self, None, _("Empty Trash"))

	def wants_context(self):
		return True

	def run(self, ctx):
		id_ = ctx.environment.get_startup_notification_id()
		thunar = _get_thunar_trash()
		try:
			# Thunar 1.2 Uses $DISPLAY and $STARTUP_ID args
			thunar.EmptyTrash(ctx.environment.get_display(), id_,
				reply_handler=_dummy, error_handler=_dummy)
		except TypeError:
			# Thunar 1.0 uses only $DISPLAY arg
			thunar.EmptyTrash(ctx.environment.get_display(),
				reply_handler=_dummy, error_handler=_dummy)

	def get_description(self):
		return None
	def get_icon_name(self):
		return "user-trash-full"

class ThunarObjects (AppLeafContentMixin, Source):
	appleaf_content_id = "Thunar"
	def __init__(self):
		Source.__init__(self, _("Thunar"))

	def get_items(self):
		yield EmptyTrash()

	def provides(self):
		yield RunnableLeaf

	def get_icon_name(self):
		return "Thunar"


class _SendToAppsSource (Source):
	""" Send To items source """
	def __init__(self):
		Source.__init__(self, _("Thunar Send To Objects"))

	def get_items(self):
		for data_dir in config.get_data_dirs("sendto", package="Thunar"):
			for filename in os.listdir(data_dir):
				if not filename.endswith('.desktop'):
					continue
				file_path = os.path.join(data_dir, filename)
				if not os.path.isfile(file_path):
					continue
				try:
					yield AppLeaf(init_path=file_path, require_x=False)
				except InvalidDataError:
					pass

	def get_icon_name(self):
		return "Thunar"

	def provides(self):
		yield AppLeaf

########NEW FILE########
__FILENAME__ = thunderbird
# -*- coding: utf-8 -*-

from __future__ import with_statement
__kupfer_name__ = _("Thunderbird")
__kupfer_sources__ = ("ContactsSource", )
__kupfer_actions__ = ("NewMailAction", )
__description__ = _("Thunderbird/Icedove Contacts and Actions")
__version__ = "2012-03-15"
__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"

from kupfer.objects import Action
from kupfer.objects import TextLeaf, UrlLeaf, RunnableLeaf
from kupfer.obj.apps import AppLeafContentMixin
from kupfer.obj.helplib import FilesystemWatchMixin
from kupfer import utils, icons
from kupfer.obj.grouping import ToplevelGroupingSource
from kupfer.obj.contacts import ContactLeaf, EmailContact, email_from_leaf

from kupfer.plugin import thunderbird_support as support

"""
Changes:
	2012-03-15: Karol BÄ™dkowski
		+ activate_multiple for new mail action
"""


class ComposeMail(RunnableLeaf):
	''' Create new mail without recipient '''
	def __init__(self):
		RunnableLeaf.__init__(self, name=_("Compose New Email"))

	def run(self):
		if not utils.spawn_async(['thunderbird', '--compose']):
			utils.spawn_async(['icedove', '--compose'])

	def get_description(self):
		return _("Compose a new message in Thunderbird")

	def get_icon_name(self):
		return "mail-message-new"


class NewMailAction(Action):
	''' Createn new mail to selected leaf (Contact or TextLeaf)'''
	def __init__(self):
		Action.__init__(self, _('Compose Email'))

	def activate(self, leaf):
		self.activate_multiple((leaf, ))

	def activate_multiple(self, objects):
		recipients = ",".join(email_from_leaf(L) for L in objects)
		if not utils.spawn_async(['thunderbird', 'mailto:%s' % recipients]):
			utils.spawn_async(['icedove', 'mailto:%s' % recipients])

	def get_icon_name(self):
		return "mail-message-new"

	def item_types(self):
		yield ContactLeaf
		# we can enter email
		yield TextLeaf
		yield UrlLeaf

	def valid_for_item(self, item):
		return bool(email_from_leaf(item))


class ContactsSource(AppLeafContentMixin, ToplevelGroupingSource,
		FilesystemWatchMixin):
	appleaf_content_id = ('thunderbird', 'icedove')

	def __init__(self, name=_("Thunderbird Address Book")):
		ToplevelGroupingSource.__init__(self, name, "Contacts")
		self._version = 2

	def initialize(self):
		ToplevelGroupingSource.initialize(self)
		abook_dirs = list(support.get_addressbook_dirs())
		if abook_dirs:
			self.monitor_token = self.monitor_directories(*abook_dirs)

	def monitor_include_file(self, gfile):
		print gfile.get_basename()
		return gfile and (gfile.get_basename().endswith('.mab') \
				or gfile.get_basename() == 'localstore.rdf')

	def get_items(self):
		for name, email in support.get_contacts():
			yield EmailContact(email, name)

		yield ComposeMail()

	def should_sort_lexically(self):
		return True

	def get_description(self):
		return _("Contacts from Thunderbird Address Book")

	def get_gicon(self):
		return icons.get_gicon_with_fallbacks(None, ("thunderbird", "icedove"))

	def provides(self):
		yield ContactLeaf
		yield RunnableLeaf

########NEW FILE########
__FILENAME__ = thunderbird_support
# -*- coding: utf-8 -*-

from __future__ import with_statement

import os
import re
from ConfigParser import RawConfigParser

from kupfer import pretty

__version__ = "2011-04-10"
__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"

'''
Module provide function to read Thunderbird's address book.

Concept for mork parser from:
	- demork.py by Kumaran Santhanam
	- mork.cs from GnomeDo by Pierre Ã–stlund
'''

THUNDERBIRD_HOME = map(os.path.expanduser,
		('~/.mozilla-thunderbird/', '~/.thunderbird', '~/.icedove/'))

THUNDERBIRD_PROFILES = [(thome, os.path.join(thome, 'profiles.ini'))
		for thome in THUNDERBIRD_HOME]


RE_COLS = re.compile(r'<\s*<\(a=c\)>\s*(\/\/)?\s*(\(.+?\))\s*>')
RE_CELL = re.compile(r'\((.+?)\)')
RE_ATOM = re.compile(r'<\s*(\(.+?\))\s*>')
RE_TABLE = re.compile(
		r'\{-?(\d+):\^(..)\s*\{\(k\^(..):c\)\(s=9u?\)\s*(.*?)\}\s*(.+?)\}')
RE_ROW = re.compile(r'(-?)\s*\[(.+?)((\(.+?\)\s*)*)\]')
RE_CELL_TEXT = re.compile(r'\^(.+?)=(.*)')
RE_CELL_OID = re.compile(r'\^(.+?)\^(.+)')
RE_TRAN_BEGIN = re.compile(r'@\$\$\{.+?\{\@')
RE_TRAN_END = re.compile(r'@\$\$\}.+?\}\@')


COLS_TO_KEEP = (
		'DisplayName',
		'FirstName',
		'LastName',
		'PrimaryEmail',
		'SecondEmail',
)

SPECIAL_CHARS = (
		('\\\\', '\\'),
		('\\$', '$'),
		('\\t', chr(9)),
		('\\n', chr(10)),
)

RE_ESCAPED = re.compile(r'(\$[a-f0-9]{2})', re.IGNORECASE)
RE_HEADER = re.compile(r'// <!-- <mdb:mork:z v="(.*)"/> -->')


class _Table(object):
	def __init__(self, tableid):
		self.tableid = tableid
		self.rows = {}

	def __repr__(self):
		return 'Table %r: %r' % (self.tableid, self.rows)

	def add_cell(self, rowid, col, atom):
		if ':' in rowid:
			rowid = rowid.split(':')[0]
		row = self.rows.get(rowid)
		if not row:
			row = self.rows[rowid] = dict()
		row[col] = _unescape_data(atom)

	def del_row(self, rowid):
		if ':' in rowid:
			rowid = rowid.split(':')[0]
		if rowid in self.rows:
			del self.rows[rowid]


def _unescape_character(match):
	value = match.group()
	try:
		return chr(int(value[1:], 16))
	except ValueError:
		return value


def _unescape_data(instr):
	for src, dst in SPECIAL_CHARS:
		instr = instr.replace(src, dst)
	return RE_ESCAPED.sub(_unescape_character, instr)


def _read_mork(filename):
	''' Read mork file, return tables from file '''
	data = []
	with open(filename, 'rt') as mfile:
		header = mfile.readline().strip()
		# check header
		if not RE_HEADER.match(header):
			pretty.print_debug(__name__, '_read_mork: header error', header)
			return {}
		for line in mfile.readlines():
			# remove blank lines and comments
			line = line.strip()
			if not line:
				continue
			# remove comments
			comments = line.find('// ')
			if comments > -1:
				line = line[:comments].strip()
			if line:
				data.append(line)
		data = ''.join(data)

	if not data:
		return {}

	data = data.replace('\\)', '$29')

	# decode data
	cells = {}
	atoms = {}
	tables = {}
	pos = 0
	active_trans = False
	while data:
		data = data[pos:].lstrip()
		if not data:
			break

		# cols
		match = RE_COLS.match(data)
		if match:
			for cell in RE_CELL.findall(match.group()):
				key, val = cell.split('=', 1)
				if val in COLS_TO_KEEP:  # skip necessary columns
					cells[key] = val
			pos = match.span()[1]
			continue

		# atoms
		match = RE_ATOM.match(data)
		if match:
			for cell in RE_CELL.findall(match.group()):
				if '=' in cell:
					key, val = cell.split('=', 1)
					atoms[key] = val
			pos = match.span()[1]
			continue

		# tables
		match = RE_TABLE.match(data)
		if match:
			tableid = ':'.join(match.groups()[0:2])
			table = tables.get(tableid)
			if not table:
				table = tables[tableid] = _Table(tableid)
			for row in RE_ROW.findall(match.group()):
				tran, rowid = row[:2]
				if active_trans and rowid[0] == '-':
					rowid = rowid[1:]
					table.del_row(rowid)
				if not active_trans or tran != '-':
					rowdata = row[2:]
					for rowcell in rowdata:
						if not rowcell:
							continue
						for cell in RE_CELL.findall(rowcell):
							atom, col = None, None
							cmatch = RE_CELL_TEXT.match(cell)
							if cmatch:
								col = cells.get(cmatch.group(1))
								atom = cmatch.group(2)
							else:
								cmatch = RE_CELL_OID.match(cell)
								if cmatch:
									col = cells.get(cmatch.group(1))
									atom = atoms.get(cmatch.group(2))
							if col and atom:
								table.add_cell(rowid, col, atom)
			pos = match.span()[1]
			continue

		# transaction
		match = RE_TRAN_BEGIN.match(data)
		if match:
			active_trans = True
			continue

		match = RE_TRAN_END.match(data)
		if match:
			tran = True
			continue

		# dangling rows
		match = RE_ROW.match(data)
		if match:
			row = match.groups()
			tran, rowid = row[:2]
			table = tables.get('1:80')  # bind to default table
			if rowid[0] == '-':
				rowid = rowid[1:]
				if table:
					table.del_row(rowid)
			if tran != '-':
				rowdata = row[2:]
				if rowdata:
					if not table:
						table = tables['1:80'] = _Table('1:80')
					for rowcell in rowdata:
						if not rowcell:
							continue
						for cell in RE_CELL.findall(str(rowcell)):
							atom, col = None, None
							cmatch = RE_CELL_TEXT.match(cell)
							if cmatch:
								col = cells.get(cmatch.group(1))
								atom = cmatch.group(2)
							else:
								cmatch = RE_CELL_OID.match(cell)
								if cmatch:
									col = cells.get(cmatch.group(1))
									atom = atoms.get(cmatch.group(2))
							if col and atom:
								table.add_cell(rowid, col, atom)
			pos = match.span()[1]
			continue

		pos = 1
	return tables


def _mork2contacts(tables):
	''' Get contacts from mork table prepared by _read_mork '''
	if not tables:
		return
	# get only default table
	table = tables.get('1:80')
	if table:
		for row in table.rows.itervalues():
			display_name = row.get('DisplayName')
			if not display_name:
				first_name = row.get('FirstName', '')
				last_name = row.get('LastName', '')
				display_name = ' '.join((first_name, last_name))
			if display_name:
				display_name = display_name.strip()
			for key in ('PrimaryEmail', 'SecondEmail'):
				email = row.get(key)
				if email:
					yield (display_name or email[:email.find('@')], email)


def get_addressbook_dirs():
	''' Get path to addressbook file from default profile. '''
	for thome, tprofile in THUNDERBIRD_PROFILES:
		if os.path.isfile(tprofile):
			config = RawConfigParser()
			config.read(tprofile)
			for section in config.sections():
				if config.has_option(section, "Path"):
					path = config.get(section, "Path")
					if not os.path.isabs(path):
						path = os.path.join(thome, path)
					if os.path.isdir(path):
						yield path


def get_addressbook_files():
	''' Get full path to all Thunderbird address book files. '''
	for path in get_addressbook_dirs():
		pretty.print_debug(__name__, 'get_addressbook_files dir:', path)
		files = os.listdir(path)
		for filename in files:
			if filename.endswith('.mab'):
				fullpath = os.path.join(path, filename)
				if os.path.isfile(fullpath):
					yield fullpath


def get_contacts():
	''' Get all contacts from all Thunderbird address books as
		((contact name, contact email)) '''
	for abook in get_addressbook_files():
		pretty.print_debug(__name__, 'get_contacts:', abook)
		try:
			tables = _read_mork(abook)
		except IOError, err:
			pretty.print_error(__name__, 'get_contacts error', abook, err)
		else:
			for item in _mork2contacts(tables):
				yield item


if __name__ == '__main__':
	print '\n'.join(map(str, sorted(get_contacts())))

########NEW FILE########
__FILENAME__ = top
# -*- coding: UTF-8 -*-
from __future__ import with_statement

__kupfer_name__ = _("Top")
__kupfer_sources__ = ("TaskSource", )
__description__ = _("Show running tasks and allow sending signals to them")
__version__ = "2009-11-24"
__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"

import os
import signal
import operator

from kupfer.objects import Action, Source, Leaf
from kupfer.obj.helplib import PicklingHelperMixin
from kupfer import scheduler
from kupfer import plugin_support
from kupfer import utils

__kupfer_settings__ = plugin_support.PluginSettings(
	{
		"key" : "sort_order",
		"label": _("Sort Order"),
		"type": str,
		"value": _("Commandline"),
		"alternatives": [_("Commandline"), _("CPU usage (descending)"),
				_("Memory usage (descending)") ]
	},
)


class Task(Leaf):
	def __init__(self, path, name, description=None):
		Leaf.__init__(self, path, name)
		self._description = description

	def get_description(self):
		return self._description

	def get_actions(self):
		yield SendSignal()

	def get_icon_name(self):
		return 'applications-system'


class SendSignal(Action):
	def __init__(self):
		Action.__init__(self, _("Send Signal..."))

	def activate(self, leaf, iobj):
		os.kill(leaf.object, iobj.object)

	def requires_object(self):
		return True
	
	def object_types(self):
		yield _Signal

	def object_source(self, for_item=None):
		return _SignalsSource()


class _Signal(Leaf):
	def get_description(self):
		return "kill -%s ..." % self.object


# get all signals from signal package
_SIGNALS = [
	_Signal(getattr(signal, signame), signame[3:])
	for signame in sorted(dir(signal))
	if signame.startswith('SIG') and not signame.startswith('SIG_')
]


class _SignalsSource(Source):
	def __init__(self):
		Source.__init__(self, _("Signals"))

	def get_items(self):
		return _SIGNALS

	def provides(self):
		yield _Signal
	

class TaskSource(Source, PicklingHelperMixin):
	task_update_interval_sec = 5

	def __init__(self, name=_("Running Tasks")):
		Source.__init__(self, name)
		self._cache = []
		self._version = 2

	def pickle_prepare(self):
		# clear saved processes
		self.mark_for_update()

	def initialize(self):
		self._timer = scheduler.Timer()

	def finalize(self):
		self._timer = None
		self._cache = []

	def _async_top_finished(self, acommand, stdout, stderr):
		self._cache = []

		processes = parse_top_output(stdout)
		# sort processes (top don't allow to sort via cmd line)
		if __kupfer_settings__['sort_order'] == _("Memory usage (descending)"):
			processes = sorted(processes, key=operator.itemgetter(2),
			                   reverse=True)
		elif __kupfer_settings__['sort_order'] == _("Commandline"):
			processes = sorted(processes, key=operator.itemgetter(4))
		# default: by cpu

		fields = _("pid: %(pid)s  cpu: %(cpu)g%%  mem: %(mem)g%%  time: %(time)s")
		for pid, cpu, mem, ptime, cmd in processes:
			description = fields % dict(pid=pid, cpu=cpu, mem=mem, time=ptime)
			self._cache.append(Task(pid, cmd, description))

		self.mark_for_update()

	def _async_top_start(self):
		uid = os.getuid()
		utils.AsyncCommand(["top", "-b", "-n", "1", "-u", "%d" % uid],
		                   self._async_top_finished, 60, env=["LC_NUMERIC=C"])

	def get_items(self):
		for task in self._cache:
			yield task
		update_wait = self.task_update_interval_sec if self._cache else 0
		# update after a few seconds
		self._timer.set(update_wait, self._async_top_start)

	def get_description(self):
		return _("Running tasks for current user")

	def get_icon_name(self):
		return "system"

	def provides(self):
		yield Task


def parse_top_output(out):
	"""
	Yield tuples of (pid, cpu, mem, ptime, cmd)
	"""
	fields_map = None
	fields_count = 0
	header_read = False
	for line in out.split('\n'):
		line = line.strip()
		if line == '':
			header_read = True
			continue

		if not header_read:
			continue

		if line.startswith('PID'): # assume pid is first col
			fields_map = dict(((name, pos) for pos, name in enumerate(line.split())))
			fields_count = len(fields_map)
			continue	# skip header

		line_fields = line.split(None, fields_count-1)
		pid = line_fields[0]
		cpu = line_fields[fields_map['%CPU']]
		mem = line_fields[fields_map['%MEM']]
		ptime = line_fields[fields_map['TIME+']]
		cmd = line_fields[-1]

		# read command line
		proc_file = '/proc/%s/cmdline' % pid
		if os.path.isfile(proc_file): # also skip (finished) missing tasks
			with open(proc_file, 'rt') as f:
				cmd = f.readline().replace('\x00', ' ') or cmd

			yield (int(pid), float(cpu), float(mem), ptime, cmd)


########NEW FILE########
__FILENAME__ = tracker1
"""
Tracker plugins are versioned by the D-Bus API version
This is version works with tracker 0.8.x and 0.10.x, where the API is called
Tracker1

Tracker 0.10 has exactly the same Resources.SparqlQuery API, but according to
its developers it does not have the same class signal api but that does not
impact this plugin.
"""
__kupfer_name__ = _("Tracker")
__kupfer_sources__ = ()
__kupfer_text_sources__ = ()
__kupfer_contents__ = ("TrackerQuerySource", )
__kupfer_actions__ = (
		"TrackerSearch",
		"TrackerSearchHere",
	)
__description__ = _("Tracker desktop search integration")
__version__ = "2010-04-01"
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

from xml.etree.cElementTree import ElementTree

import dbus
import gio
import gobject

from kupfer.objects import Action, Source
from kupfer.objects import TextLeaf, FileLeaf
from kupfer.obj.objects import ConstructFileLeaf
from kupfer import utils, pretty
from kupfer import kupferstring
from kupfer import plugin_support


plugin_support.check_dbus_connection()

SERVICE_NAME = "org.freedesktop.Tracker"
SEARCH_OBJECT_PATH = "/org/freedesktop/Tracker/Search"
SEARCH_INTERFACE = "org.freedesktop.Tracker.Search"

SERVICE1_NAME = "org.freedesktop.Tracker1"
SEARCH_OBJECT1_PATH = "/org/freedesktop/Tracker1/Resources"
SEARCH1_INTERFACE = "org.freedesktop.Tracker1.Resources"


class TrackerSearch (Action):
	def __init__(self):
		Action.__init__(self, _("Search in Tracker"))

	def activate(self, leaf):
		utils.spawn_async(["tracker-search-tool", leaf.object])
	def get_description(self):
		return _("Open Tracker Search Tool and search for this term")
	def get_icon_name(self):
		return "system-search"
	def item_types(self):
		yield TextLeaf

class TrackerSearchHere (Action):
	def __init__(self):
		Action.__init__(self, _("Get Tracker Results..."))

	def is_factory(self):
		return True

	def activate(self, leaf):
		return TrackerQuerySource(leaf.object)

	def get_description(self):
		return _("Show Tracker results for query")
	def get_icon_name(self):
		return "tracker"
	def item_types(self):
		yield TextLeaf

def sparql_escape(ustr):
	"""Escape unicode string @ustr for insertion into a SPARQL query

	Implemented to behave like tracker_sparql_escape in libtracker-client
	"""
	sparql_escape_table = {
		ord(u'\t'): ur'\t',
		ord(u'\n'): ur'\n',
		ord(u'\r'): ur'\r',
		ord(u'\b'): ur'\b',
		ord(u'\f'): ur'\f',
		ord(u'"') : ur'\"',
		ord(u'\\'): u'\\\\',
	}
	return ustr.translate(sparql_escape_table)

def get_file_results_sparql(searchobj, query, max_items):
	clean_query = sparql_escape(query)
	sql = u"""SELECT tracker:coalesce (nie:url (?s), ?s)
	          WHERE {  ?s fts:match "%s*" .  ?s tracker:available true . }
			  ORDER BY tracker:weight(?s)
			  OFFSET 0 LIMIT %d""" % (clean_query, int(max_items))

	pretty.print_debug(__name__, "Searching for %s (%s)",
			repr(clean_query), repr(query))
	pretty.print_debug(__name__, sql)
	results = searchobj.SparqlQuery(sql)

	gio_File = gio.File
	for result in results:
		yield FileLeaf(gio_File(result[0]).get_path())

def get_file_results_old(searchobj, query, max_items):
	try:
		file_hits = searchobj.Text(1, "Files", query, 0, max_items)
	except dbus.DBusException, exc:
		pretty.print_error(__name__, exc)
		return

	for filestr in file_hits:
		# A bit of encoding carousel
		# dbus strings are subclasses of unicode
		# but FileLeaf expects a filesystem encoded object
		bytes = filestr.decode("UTF-8", "replace")
		filename = gobject.filename_from_utf8(bytes)
		yield ConstructFileLeaf(filename)

use_version = None
versions = {
	"0.8": (SERVICE1_NAME, SEARCH_OBJECT1_PATH, SEARCH1_INTERFACE),
	"0.6": (SERVICE_NAME, SEARCH_OBJECT_PATH, SEARCH_INTERFACE),
}

version_query = {
	"0.8": get_file_results_sparql,
	"0.6": get_file_results_old,
}


def get_searchobject(sname, opath, sinface):
	bus = dbus.SessionBus()
	searchobj = None
	try:
		tobj = bus.get_object(sname, opath)
		searchobj = dbus.Interface(tobj, sinface)
	except dbus.DBusException, exc:
		pretty.print_debug(__name__, exc)
	return searchobj

def get_tracker_filequery(query, max_items):
	searchobj = None
	global use_version
	if use_version is None:
		for version, (sname, opath, sinface) in versions.items():
			pretty.print_debug(__name__, "Trying", sname, version)
			searchobj = get_searchobject(sname, opath, sinface)
			if searchobj is not None:
				use_version = version
				break
	else:
		searchobj = get_searchobject(*versions[use_version])
	if searchobj is None:
		use_version = None
		pretty.print_error(__name__, "Could not connect to Tracker")
		return ()

	queryfunc = version_query[use_version]
	return queryfunc(searchobj, query, max_items)

class TrackerQuerySource (Source):
	def __init__(self, query):
		Source.__init__(self, name=_('Results for "%s"') % query)
		self.query = query
		self.max_items = 50

	def repr_key(self):
		return self.query

	def get_items(self):
		return get_tracker_filequery(self.query, self.max_items)

	def get_description(self):
		return _('Results for "%s"') % self.query
	def get_icon_name(self):
		return "tracker"

	@classmethod
	def decorates_type(cls):
		return FileLeaf
	@classmethod
	def decorate_item(cls, leaf):
		# FIXME: Very simplified .savedSearch parsing, so far we only support
		# the query, without additional filtering. The simplest form of
		# .savedSearch file is saved by nautilus as following:
		# <query version="1.0">
		#   <text>QUERY GOES HERE</text>
		# </query>

		if not leaf.object.endswith(".savedSearch"):
			return None
		try:
			et = ElementTree(file=leaf.object)
			query = et.getroot().find("text").text
			us_query = kupferstring.tounicode(query)
			return cls(us_query)
		except Exception:
			return None


# FIXME: Port tracker tag sources and actions
# to the new, much more powerful sparql + dbus API
# (using tracker-tag as in 0.6 is a plain hack and a dead end)


########NEW FILE########
__FILENAME__ = trash
__kupfer_name__ = _("Trash")
__kupfer_actions__ = ("MoveToTrash", "EmptyTrash")
__kupfer_sources__ = ("TrashSource", )
__description__ = _("Access trash contents")
__version__ = "2009-12-06"
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import gio

from kupfer.objects import Leaf, Action, Source, SourceLeaf, FileLeaf
from kupfer.objects import OperationError
from kupfer.obj.fileactions import Open
from kupfer.obj.base import OperationError
from kupfer import utils, icons, pretty



TRASH_URI = 'trash://'

class MoveToTrash (Action):
	# this should never be default
	rank_adjust = -10
	def __init__(self):
		Action.__init__(self, _("Move to Trash"))

	def activate(self, leaf):
		gfile = gio.File(leaf.object)
		try:
			gfile.trash()
		except gio.Error as exc:
			raise OperationError(exc)

	def valid_for_item(self, item):
		gfile = gio.File(item.object)
		if not gfile.query_exists(None):
			return False
		info = gfile.query_info(gio.FILE_ATTRIBUTE_ACCESS_CAN_TRASH)
		return info.get_attribute_boolean(gio.FILE_ATTRIBUTE_ACCESS_CAN_TRASH)
	def get_description(self):
		return _("Move this file to trash")
	def get_icon_name(self):
		return "user-trash-full"
	def item_types(self):
		yield FileLeaf


class RestoreTrashedFile (Action):
	def __init__(self):
		Action.__init__(self, _("Restore"))

	def has_result(self):
		return True

	def activate(self, leaf):
		orig_path = leaf.get_orig_path()
		if not orig_path:
			return
		orig_gfile = gio.File(orig_path)
		cur_gfile = leaf.get_gfile()
		if orig_gfile.query_exists():
			raise IOError("Target file exists at %s" % orig_gfile.get_path())
		pretty.print_debug(__name__, "Move %s to %s" % (cur_gfile, orig_gfile))
		ret = cur_gfile.move(orig_gfile)
		pretty.print_debug(__name__, "Move ret=%s" % (ret, ))
		return FileLeaf(orig_gfile.get_path())

	def get_description(self):
		return _("Move file back to original location")
	def get_icon_name(self):
		return "edit-undo"

class EmptyTrash (Action):
	rank_adjust = -1
	def __init__(self):
		Action.__init__(self, _("Empty Trash"))
	def activate(self, trash):
		gfile = gio.File(TRASH_URI)
		failed = []
		for info in gfile.enumerate_children("standard::*,trash::*"):
			name = info.get_name()
			if not gfile.get_child(name).delete():
				failed.append(name)
		if failed:
			err = _("Could not delete files:\n    ")
			raise OperationError(err + '\n    '.join(failed))
	def get_icon_name(self):
		return "user-trash-full"

class TrashFile (Leaf):
	"""A file in the trash. Represented object is a file info object"""
	def __init__(self, trash_uri, info):
		name = info.get_display_name()
		Leaf.__init__(self, info, name)
		self._trash_uri = trash_uri
	def get_actions(self):
		if self.get_orig_path():
			yield RestoreTrashedFile()
	def get_gfile(self):
		cur_gfile = gio.File(self._trash_uri).get_child(self.object.get_name())
		return cur_gfile
	def get_orig_path(self):
		try:
			orig_path = self.object.get_attribute_byte_string("trash::orig-path")
			return orig_path
		except AttributeError:
			pass
		return None

	def is_valid(self):
		return self.get_gfile().query_exists()

	def get_description(self):
		orig_path = self.get_orig_path()
		return utils.get_display_path_for_bytestring(orig_path) if orig_path \
				else None
	def get_gicon(self):
		return self.object.get_icon()
	def get_icon_name(self):
		return "text-x-generic"

class TrashContentSource (Source):
	def __init__(self, trash_uri, name):
		Source.__init__(self, name)
		self._trash_uri = trash_uri

	def is_dynamic(self):
		return True
	def get_items(self):
		gfile = gio.File(self._trash_uri)
		enumerator = gfile.enumerate_children("standard::*,trash::*")
		for info in enumerator:
			yield TrashFile(self._trash_uri, info)
	def should_sort_lexically(self):
		return True
	def get_gicon(self):
		return icons.get_gicon_for_file(self._trash_uri)

class SpecialLocation (Leaf):
	""" Base class for Special locations (in GIO/GVFS),
	such as trash:/// Here we assume they are all "directories"
	"""
	def __init__(self, location, name=None, description=None, icon_name=None):
		"""Special location with @location and
		@name. If unset, we find @name from filesystem
		@description is Leaf description"""
		gfile = gio.File(location)
		info = gfile.query_info(gio.FILE_ATTRIBUTE_STANDARD_DISPLAY_NAME)
		name = (info.get_attribute_string(gio.FILE_ATTRIBUTE_STANDARD_DISPLAY_NAME) or location)
		Leaf.__init__(self, location, name)
		self.description = description
		self.icon_name = icon_name
	def get_actions(self):
		yield Open()
	def get_description(self):
		return self.description or self.object
	def get_gicon(self):
		# Get icon
		return icons.get_gicon_for_file(self.object)
	def get_icon_name(self):
		return "folder"

class Trash (SpecialLocation):
	def __init__(self, trash_uri, name=None):
		SpecialLocation.__init__(self, trash_uri, name=name)

	def has_content(self):
		return self.get_item_count()
	def content_source(self, alternate=False):
		return TrashContentSource(self.object, name=unicode(self))

	def get_actions(self):
		for action in SpecialLocation.get_actions(self):
			yield action
		if self.get_item_count():
			yield EmptyTrash()

	def get_item_count(self):
		gfile = gio.File(self.object)
		info = gfile.query_info(gio.FILE_ATTRIBUTE_TRASH_ITEM_COUNT)
		return info.get_attribute_uint32(gio.FILE_ATTRIBUTE_TRASH_ITEM_COUNT)

	def get_description(self):
		item_count = self.get_item_count()
		if not item_count:
			return _("Trash is empty")
		# proper translation of plural
		return ngettext("Trash contains one file",
			"Trash contains %(num)s files", item_count) % {"num": item_count}

class InvisibleSourceLeaf (SourceLeaf):
	"""Hack to hide this source"""
	def is_valid(self):
		return False

class TrashSource (Source):
	def __init__(self):
		Source.__init__(self, _("Trash"))
	def get_items(self):
		yield Trash(TRASH_URI)
	def get_leaf_repr(self):
		return InvisibleSourceLeaf(self)
	def provides(self):
		yield SpecialLocation
	def get_icon_name(self):
		return "user-trash"

########NEW FILE########
__FILENAME__ = triggers
__kupfer_name__ = _("Triggers")
__kupfer_sources__ = ("Triggers", )
__kupfer_actions__ = (
	"AddTrigger",
)
__description__ = _("Assign global keybindings (triggers) to objects created "
                    "with 'Compose Command'.")
__version__ = "2009-12-30"
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import gtk
import glib

from kupfer.objects import Action, Source
from kupfer.objects import TextLeaf, RunnableLeaf
from kupfer.objects import OperationError
from kupfer.obj.compose import ComposedLeaf
from kupfer import puid
from kupfer import kupferstring
from kupfer import task

from kupfer.ui import keybindings
from kupfer.ui import uievents
from kupfer.ui import getkey_dialog
from kupfer.core import commandexec


# we import the keybinder module for its side-effects --
# this plugin needs this module, lest it shall not function.
import keybinder

class Trigger (RunnableLeaf):
	def get_actions(self):
		for act in RunnableLeaf.get_actions(self):
			yield act
		yield RemoveTrigger()
	def wants_context(self):
		return True
	def is_valid(self):
		return Triggers.has_trigger(self.object)
	def run(self, ctx):
		return Triggers.perform_trigger(ctx, self.object)
	def repr_key(self):
		return self.object

class Triggers (Source):
	instance = None

	def __init__(self):
		Source.__init__(self, _("Triggers"))
		self.trigger_table = {}

	def config_save(self):
		return {"triggers": self.trigger_table, "version": self.version}

	def config_save_name(self):
		return __name__

	def config_restore(self, state):
		self.trigger_table = state["triggers"]
		return True
	
	def initialize(self):
		Triggers.instance = self
		keybindings.GetKeyboundObject().connect("keybinding",
		                                        self.keybinding_callback)
		for target, (keystr, name, id_) in self.trigger_table.iteritems():
			keybindings.bind_key(keystr, target)
		self.output_debug("Loaded triggers, count:", len(self.trigger_table))

	def finalize(self):
		for target, (keystr, name, id_) in self.trigger_table.iteritems():
			keybindings.bind_key(None, target)

	def keybinding_callback(self, keyobj, target, display, event_time):
		if not self.has_trigger(target):
			return
		ui_ctx = uievents.gui_context_from_keyevent(event_time, display)
		ctx = commandexec.DefaultActionExecutionContext()
		exec_token = ctx.make_execution_token(ui_ctx)
		self.perform_trigger(exec_token, target)

	def get_items(self):
		for target, (keystr, name, id_) in self.trigger_table.iteritems():
			label = gtk.accelerator_get_label(*gtk.accelerator_parse(keystr))
			yield Trigger(target, u"%s (%s)" % (label or keystr, name))

	def should_sort_lexically(self):
		return True

	def provides(self):
		yield Trigger

	@classmethod
	def has_trigger(cls, target):
		return target in cls.instance.trigger_table

	@classmethod
	def perform_trigger(cls, ctx, target):
		try:
			keystr, name, id_ = cls.instance.trigger_table[target]
		except KeyError:
			raise OperationError("Trigger '%s' does not exist" % (target, ))
		obj = puid.resolve_unique_id(id_)
		if obj is None:
			return
		return obj.run(ctx)

	@classmethod
	def add_trigger(cls, leaf, keystr):
		Triggers.instance._add_trigger(leaf, keystr)

	@classmethod
	def remove_trigger(cls, target):
		Triggers.instance._remove_trigger(target)
	
	def _add_trigger(self, leaf, keystr):
		for target in xrange(*keybindings.KEYRANGE_TRIGGERS):
			if target not in self.trigger_table:
				break
		keybindings.bind_key(keystr, target)
		name = unicode(leaf)
		self.trigger_table[target] = (keystr, name, puid.get_unique_id(leaf))
		self.mark_for_update()

	def _remove_trigger(self, target):
		self.trigger_table.pop(target, None)
		keybindings.bind_key(None, target)
		self.mark_for_update()

	def get_icon_name(self):
		return "key_bindings"

def try_bind_key(keystr):
	label = gtk.accelerator_get_label(*gtk.accelerator_parse(keystr))
	ulabel = kupferstring.tounicode(label)
	if len(ulabel) == 1 and ulabel.isalnum():
		return False
	target = keybindings.KEYRANGE_TRIGGERS[-1] - 1
	succ = keybindings.bind_key(keystr, target)
	if succ:
		keybindings.bind_key(None, target)
	return succ

class BindTask (task.Task):
	def __init__(self, leaf, screen):
		self.leaf = leaf
		self.screen = screen

	def start(self, finish_callback):
		glib.idle_add(self.ask_key, finish_callback)

	def ask_key(self, finish_callback):
		keystr = getkey_dialog.ask_for_key(try_bind_key, screen=self.screen)
		if keystr:
			Triggers.add_trigger(self.leaf, keystr)
		finish_callback(self)

class AddTrigger (Action):
	def __init__(self):
		Action.__init__(self, _("Add Trigger..."))
	
	def is_async(self):
		return True

	def wants_context(self):
		return True

	def activate(self, leaf, ctx):
		return BindTask(leaf, ctx.environment.get_screen())

	def item_types(self):
		yield ComposedLeaf

	def get_icon_name(self):
		return "list-add"

class RemoveTrigger (Action):
	def __init__(self):
		Action.__init__(self, _("Remove Trigger"))

	def activate(self, leaf):
		Triggers.remove_trigger(leaf.object)

	def get_icon_name(self):
		return "list-remove"


########NEW FILE########
__FILENAME__ = truecrypt
# -*- coding: UTF-8 -*-

__kupfer_name__ = _("TrueCrypt")
__kupfer_sources__ = ("VolumeSource", )
__kupfer_actions__ = ('DismountAll', 'MountFile')
__description__ = _("Volumes from TrueCrypt history")
__version__ = "2009-11-24"
__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"

import os
from xml.etree import cElementTree as ElementTree
import gio

from kupfer.objects import (Action, Source, Leaf,AppLeaf, FileLeaf)
from kupfer.obj.apps import AppLeafContentMixin
from kupfer.obj.helplib import PicklingHelperMixin
from kupfer import utils



_HISTORY_FILE = "~/.TrueCrypt/History.xml"


def mount_volume_in_truecrypt(filepath):
	''' Mount file in Truecrypt. 
		Escape apostrophes - ie:
		"test'dk 'dlk' dsl''k '' sdkl.test" ->
		"'test'\''dk '\''dlk'\'' dsl'\'''\''k '\'''\'' sdkl.test'"
	'''
	# escape ' characters
	filepath = filepath.replace("'", "'\\''")
	utils.spawn_async(["truecrypt", filepath])


class Volume(Leaf):
	def __init__(self, path, name):
		Leaf.__init__(self, path, name)

	def get_icon_name(self):
		return "truecrypt"

	def get_description(self):
		dispname = utils.get_display_path_for_bytestring(self.object)
		return _("TrueCrypt volume: %(file)s") % dict(file=dispname)

	def get_actions(self):
		yield MountVolume()


class MountVolume(Action):
	def __init__(self):
		Action.__init__(self, _("Mount Volume"))
		
	def activate(self, leaf):
		mount_volume_in_truecrypt(leaf.object)


class MountFile(Action):
	''' Mount selected file in truecrypt. '''
	rank_adjust = -10

	def __init__(self):
		Action.__init__(self, _("Mount in Truecrypt"))

	def activate(self, leaf):
		mount_volume_in_truecrypt(leaf.object)

	def item_types(self):
		yield FileLeaf

	def get_description(self):
		return _("Try to mount file as Truecrypt volume")

	def valid_for_item(self, item):
		return os.path.isfile(item.object)


class DismountAll(Action):
	def __init__(self):
		Action.__init__(self, _("Dismount All Volumes"))

	def activate(self, leaf, iobj=None):
		utils.spawn_async(['truecrypt', '-d'])

	def get_icon_name(self):
		return "hdd_unmount"

	def item_types(self):
		yield AppLeaf

	def valid_for_item(self, leaf):
		return leaf.get_id() == 'truecrypt'


class VolumeSource (AppLeafContentMixin, Source, PicklingHelperMixin):
	appleaf_content_id = "truecrypt"

	def __init__(self, name=_("TrueCrypt Volumes")):
		Source.__init__(self, name)
		self.unpickle_finish()

	def pickle_prepare(self):
		self.monitor = None

	def unpickle_finish(self):
		hist_file_path = _get_history_file_path()
		if not hist_file_path:
			return
		gfile = gio.File(hist_file_path)
		self.monitor = gfile.monitor_file(gio.FILE_MONITOR_NONE, None)
		if self.monitor:
			self.monitor.connect("changed", self._on_history_changed)

	def _on_history_changed(self, monitor, file1, file2, evt_type):
		if evt_type in (gio.FILE_MONITOR_EVENT_CREATED,
				gio.FILE_MONITOR_EVENT_DELETED,
				gio.FILE_MONITOR_EVENT_CHANGED):
			self.mark_for_update()

	def get_items(self):
		hist_file_path = _get_history_file_path()
		if not hist_file_path:
			return
		
		try:
			tree = ElementTree.parse(hist_file_path)
			for volume in tree.find('history').findall('volume'):
				volume_path = volume.text
				if volume_path:
					gfile = gio.File(volume_path)
					if not gfile.query_exists():
						continue
					
					yield Volume(gfile.get_path(), gfile.get_basename())

		except StandardError, err:
			self.output_error(err)

	def get_description(self):
		return _("Volumes from TrueCrypt history")

	def get_icon_name(self):
		return "truecrypt"

	def provides(self):
		yield Volume


def _get_history_file_path():
	path = os.path.expanduser(_HISTORY_FILE)
	return path if os.path.isfile(path) else None


########NEW FILE########
__FILENAME__ = tsclient
# -*- coding: UTF-8 -*-
from __future__ import with_statement

__kupfer_name__ = _("Terminal Server Client")
__kupfer_sources__ = ("TsclientSessionSource", )
__kupfer_actions__ = ("TsclientOpenSession", )
__description__ = _("Session saved in Terminal Server Client")
__version__ = "2010-10-01"
__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"

'''
Changes:
2010-10-01
	Freddie Brandt
	- read files in subdirs ~/.tsclient
	Karol:
	- drop FilesystemWatchMixin, add source_user_reloadable
'''

import os

from kupfer.objects import Action
from kupfer.obj.apps import AppLeafContentMixin
from kupfer import utils, icons
from kupfer.obj.grouping import ToplevelGroupingSource
from kupfer.obj.hosts import HOST_NAME_KEY, HostLeaf


TSCLIENT_SESSION_KEY = "TSCLIENT_SESSION"


class TsclientSession(HostLeaf):
	""" Leaf represent session saved in Tsclient"""

	def __init__(self, obj_path, name, description):
		slots = {HOST_NAME_KEY: name, TSCLIENT_SESSION_KEY: obj_path}
		HostLeaf.__init__(self, slots, name)
		self._description = description

	def get_description(self):
		return self._description

	def get_gicon(self):
		return icons.ComposedIconSmall(self.get_icon_name(), "tsclient")


class TsclientOpenSession(Action):
	''' opens tsclient session '''
	def __init__(self):
		Action.__init__(self, _('Start Session'))

	def activate(self, leaf):
		session = leaf[TSCLIENT_SESSION_KEY]
		utils.spawn_async(["tsclient", "-x", session])

	def get_icon_name(self):
		return 'tsclient'

	def item_types(self):
		yield HostLeaf

	def valid_for_item(self, item):
		return item.check_key(TSCLIENT_SESSION_KEY)


class TsclientSessionSource(AppLeafContentMixin, ToplevelGroupingSource):
	''' indexes session saved in tsclient '''

	appleaf_content_id = 'tsclient'
	source_user_reloadable = True

	def __init__(self, name=_("TSClient sessions")):
		ToplevelGroupingSource.__init__(self, name, "hosts")
		self._sessions_dir = os.path.expanduser('~/.tsclient')
		self._version = 2

	def initialize(self):
		ToplevelGroupingSource.initialize(self)

	def get_items(self):
		if not os.path.isdir(self._sessions_dir):
			return
		for root, sub_folders_, files in os.walk(self._sessions_dir):
			for filename in files:
				if not filename.endswith('.rdp'):
					continue
				obj_path = os.path.join(root, filename)
				if os.path.isfile(obj_path):
					name = filename[:-4]
					description = self._load_descr_from_session_file(obj_path)
					yield TsclientSession(obj_path, name, description)

	def get_description(self):
		return _("Saved sessions in Terminal Server Client")

	def get_icon_name(self):
		return "tsclient"

	def provides(self):
		yield TsclientSession

	def _load_descr_from_session_file(self, filepath):
		user = None
		host = None
		try:
			with open(filepath, 'r') as session_file:
				for line in session_file:
					if line.startswith('full address:s:'):
						host = line.split(':s:', 2)[1].strip()
					elif line.startswith('username:s:'):
						user = line.split(':s:', 2)[1].strip()
		except IOError, err:
			self.output_error(err)
		else:
			if host:
				return unicode(user + '@' + host if user else host, "UTF-8",
						"replace")
		return u'Terminal Server Client Session'

########NEW FILE########
__FILENAME__ = urlactions
__kupfer_name__ = _("URL Actions")
__kupfer_sources__ = ()
__kupfer_text_sources__ = ()
__kupfer_actions__ = (
		"DownloadAndOpen",
		"DownloadTo",
	)
__description__ = _("URL Actions")
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import os
import shutil
import urllib

from kupfer.objects import Action, UrlLeaf, FileLeaf
from kupfer import utils, task

class DownloadTask (task.ThreadTask):
	def __init__(self, uri, destdir=None, tempfile=False, finish_callback=None):
		super(DownloadTask, self).__init__()
		self.uri = uri
		self.download_finish_callback = finish_callback
		self.destdir = destdir
		self.use_tempfile = tempfile

	def thread_do(self):
		self.response = urllib.urlopen(self.uri)

		def url_name(url):
			return os.path.basename(url.rstrip("/"))
		def header_name(headers):
			content_disp = headers.get("Content-Disposition", "")
			for part in content_disp.split(";"):
				if part.strip().lower().startswith("filename="):
					return part.split("=", 1)[-1]
			return content_disp

		destname = (header_name(self.response.headers) or
					url_name(self.response.url))

		if self.use_tempfile:
			(self.destfile, self.destpath) = utils.get_safe_tempfile()
		else:
			(self.destfile, self.destpath) = \
				utils.get_destfile_in_directory(self.destdir, destname)
		try:
			if not self.destfile:
				raise IOError("Could not write output file")

			shutil.copyfileobj(self.response, self.destfile)
		finally:
			self.destfile.close()
			self.response.close()

	def thread_finish(self):
		if self.download_finish_callback:
			self.download_finish_callback(self.destpath)

class DownloadAndOpen (Action):
	"""Asynchronous action to download file and open it"""
	def __init__(self):
		Action.__init__(self, _("Download and Open"))

	def is_async(self):
		return True
	def wants_context(self):
		return True
	def activate(self, leaf, ctx):
		uri = leaf.object
		def finish_action(filename):
			utils.show_path(filename)
			ctx.register_late_result(FileLeaf(filename), show=False)
		return DownloadTask(uri, None, True, finish_action)

	def item_types(self):
		yield UrlLeaf
	def get_description(self):
		return None

class DownloadTo (Action):
	def __init__(self):
		Action.__init__(self, _("Download To..."))

	def is_async(self):
		return True
	def wants_context(self):
		return True
	def activate(self, leaf, obj, ctx):
		uri = leaf.object
		def finish_action(filename):
			ctx.register_late_result(FileLeaf(filename))
		return DownloadTask(uri, obj.object, False, finish_action)

	def item_types(self):
		yield UrlLeaf
	def requires_object(self):
		return True
	def object_types(self):
		yield FileLeaf
	def valid_object(self, obj, for_item=None):
		return utils.is_directory_writable(obj.object)
	def get_description(self):
		return _("Download URL to a chosen location")


########NEW FILE########
__FILENAME__ = plugin
import os
import sys

import dbus
import gio
import glib

from kupfer.objects import Source, FileLeaf, Leaf, Action
from kupfer.objects import OperationError
from kupfer.objects import AppLeaf, TextLeaf, TextSource
from kupfer.obj.objects import Launch
from kupfer.obj.apps import AppLeafContentMixin
from kupfer import datatools
from kupfer import utils
from kupfer import kupferstring
from kupfer import pretty
from kupfer import plugin_support
from kupfer import utils

plugin_support.check_dbus_connection()

PLUGID='vim'

VIM = 'gvim'

def get_vim_files(filepath):
	"""
	Read ~/.viminfo from @filepath

	Look for a line like this:
	*encoding=<encoding>

	Return an iterator of unicode string file paths
	"""
	encoding = "UTF-8"
	recents = []
	with open(filepath, "r") as f:
		for line in f:
			if line.startswith("*encoding="):
				_, enc = line.split("=")
				encoding = enc.strip()
			us_line = line.decode(encoding, "replace")
			## Now find the jumplist
			if us_line.startswith("-'  "):
				parts = us_line.split(None, 3)
				recentfile = os.path.expanduser(parts[-1].strip())
				if recentfile:
					recents.append(recentfile)
	return datatools.UniqueIterator(recents)

class RecentsSource (AppLeafContentMixin, Source):
	appleaf_content_id = ("vim", "gvim")

	vim_viminfo_file = "~/.viminfo"
	def __init__(self, name=None):
		name = name or _("Vim Recent Documents")
		super(RecentsSource, self).__init__(name)

	def initialize(self):
		"""Set up change monitor"""
		viminfofile = os.path.expanduser(self.vim_viminfo_file)
		gfile = gio.File(viminfofile)
		self.monitor = gfile.monitor_file(gio.FILE_MONITOR_NONE, None)
		if self.monitor:
			self.monitor.connect("changed", self._changed)

	def finalize(self):
		if self.monitor:
			self.monitor.cancel()
		self.monitor = None

	def _changed(self, monitor, file1, file2, evt_type):
		"""Change callback; something changed"""
		if evt_type in (gio.FILE_MONITOR_EVENT_CREATED,
				gio.FILE_MONITOR_EVENT_DELETED,
				gio.FILE_MONITOR_EVENT_CHANGED):
			self.mark_for_update()

	def get_items(self):
		viminfofile = os.path.expanduser(self.vim_viminfo_file)
		if not os.path.exists(viminfofile):
			self.output_debug("Viminfo not found at", viminfofile)
			return

		try:
			filepaths = list(get_vim_files(viminfofile))
		except EnvironmentError:
			self.output_exc()
			return

		for filepath in filepaths:
			# The most confusing glib function
			# takes a unicode string and returns a
			# filesystem-encoded bytestring.
			yield FileLeaf(glib.filename_from_utf8(filepath))

	def get_icon_name(self):
		return "document-open-recent"

	def provides(self):
		yield FileLeaf

def get_plugin_iface_name(plugin_id):
	plugin_id = plugin_id.split(".")[-1]
	interface_name = "se.kaizer.kupfer.plugin.%s" % plugin_id
	return interface_name

def get_plugin_service_obj(plugin_id, activate=True):
	"""Return the dbus proxy object for our plugin

	if @activate, we will --exec-helper= the service
	"""
	plugin_id = plugin_id.split(".")[-1]

	service_name = "se.kaizer.kupfer.plugin.%s" % plugin_id
	interface_name = "se.kaizer.kupfer.plugin.%s" % plugin_id
	object_name = "/se/kaizer/kupfer/plugin/%s" % plugin_id
	try:
		bus = dbus.Bus()
	except dbus.DBusException:
		return None
	try:
		proxy_obj = bus.get_object(service_name, object_name)
	except dbus.DBusException as exc:
		if activate:
			service_id = "kupfer.plugin.%s.service" % plugin_id
			return utils.start_plugin_helper(service_id, True)
		return None
	proxy_iface = dbus.Interface(proxy_obj, interface_name)
	return proxy_iface

def stop_plugin_service(plugin_id):
	"""
	Return True if it was running and was stopped
	"""
	plug_iface = get_plugin_service_obj(plugin_id, activate=False)
	if plug_iface:
		plug_iface.Exit(reply_handler=_dummy_handler,
		                error_handler=_dummy_handler)


def _dummy_handler(*args):
	pass

class VimApp (AppLeaf):
	"""
	This is a re-implemented AppLeaf that represents a running Vim session

	with a fake vim self.object for safety (this should not be needed)
	"""
	serializable = None
	def __init__(self, serverid, name):
		try:
			obj = gio.unix.DesktopAppInfo("gvim.desktop")
		except RuntimeError:
			obj = gio.AppInfo(VIM)
		Leaf.__init__(self, obj, name)
		self.serverid = serverid

	def get_id(self):
		# use an ostensibly fake id starting with @/
		return "@/%s/%s" % (__name__, self.serverid or "")

	def __setstate__(self, state):
		raise NotImplementedError

	def __getstate__(self):
		raise NotImplementedError

	def get_actions(self):
		if self.serverid is not None:
			yield Launch(_("Go To"), is_running=True)
			yield SendCommand()
			yield CloseSaveAll()
		else:
			yield Launch()

	def launch(self, files=(), paths=(), activate=False, ctx=None):
		"""
		Launch the represented application

		@files: a seq of GFiles (gio.File)
		@paths: a seq of bytestring paths
		@activate: activate instead of start new
		"""
		if self.serverid is not None:
			argv = [VIM, '--servername', self.serverid, '--remote']
		else:
			argv = [VIM]
		if files:
			paths = [f.get_path() or f.get_uri() for f in files]
		if paths:
			argv.extend(paths)
		if paths or self.serverid is None:
			try:
				utils.spawn_async_raise(argv)
			except utils.SpawnError as exc:
				raise OperationError(exc)
		if self.serverid:
			## focus the window we opened
			def error_handler(exc):
				ctx.register_late_error(OperationError(exc))
			proxy_obj = get_plugin_service_obj(PLUGID)
			if proxy_obj:
				proxy_obj.Foreground(self.serverid,
						reply_handler=_dummy_handler,
						error_handler=error_handler)

	def get_icon_name(self):
		return 'vim'

	def get_description(self):
		return None

class CloseSaveAll (Action):
	""" Close a vim window without forcing """
	rank_adjust = -5
	def __init__(self):
		Action.__init__(self, _("Close (Save All)"))

	def wants_context(self):
		return True
	def activate(self, obj, ctx):
		def error_handler(exc):
			ctx.register_late_error(OperationError(exc))
		proxy_obj = get_plugin_service_obj(PLUGID)
		if proxy_obj:
			proxy_obj.SendEx(obj.serverid, 'wqa',
					reply_handler=_dummy_handler,
					error_handler=error_handler)

	def get_icon_name(self):
		return "window-close"

class SendCommand (Action):
	def __init__(self):
		Action.__init__(self, _("Send..."))

	def wants_context(self):
		return True
	def activate(self, obj, iobj, ctx):
		## accept with or without starting :
		lcmd = kupferstring.tolocale(iobj.object)
		if lcmd.startswith(":"):
			lcmd = lcmd[1:]

		def error_handler(exc):
			ctx.register_late_error(OperationError(exc))
		proxy_obj = get_plugin_service_obj(PLUGID)
		if proxy_obj:
			proxy_obj.SendEx(obj.serverid, lcmd,
					reply_handler=_dummy_handler,
					error_handler=error_handler)


	def requires_object(self):
		return True
	def object_types(self):
		yield TextLeaf
	def object_source(self, for_item=None):
		return TextSource()

	def get_description(self):
		return _("Send ex command")

class InsertInVim (Action):
	"""
	Insert a given text into the currently open buffer in a vim
	session
	"""
	def __init__(self):
		Action.__init__(self, _("Insert in Vim..."))

	def wants_context(self):
		return True
	def activate(self, obj, iobj, ctx):
		tmpf, tmpname = utils.get_safe_tempfile()
		tmpf.write(kupferstring.tolocale(obj.object))
		tmpf.close()
		vim_cmd = "r %s" % tmpname
		glib.timeout_add_seconds(10, os.unlink, tmpname)

		def error_handler(exc):
			ctx.register_late_error(OperationError(exc))

		proxy_obj = get_plugin_service_obj(PLUGID)
		if proxy_obj:
			proxy_obj.SendEx(iobj.serverid, vim_cmd,
					reply_handler=_dummy_handler,
					error_handler=error_handler)

	def item_types(self):
		yield TextLeaf

	def requires_object(self):
		return True

	def object_types(self):
		yield VimApp

	def get_icon_name(self):
		return "insert-text"


class ActiveVim (AppLeafContentMixin, Source):
	appleaf_content_id = ("vim", "gvim")

	def __init__(self):
		Source.__init__(self, _("Active Vim Sessions"))

	def initialize(self):
		ActiveVim.instance = self
		self.serverids = []
		self.signal_match = None
		glib.timeout_add_seconds(1, self.start_helper)

	def start_helper(self):
		bus = dbus.Bus()
		self.signal_match = bus.add_signal_receiver(self.on_new_serverlist,
		                        signal_name="NewServerlist",
		                        dbus_interface=get_plugin_iface_name(PLUGID),
		                        byte_arrays=True)
		get_plugin_service_obj(PLUGID, activate=True)

	def finalize(self):
		ActiveVim.instance = None
		if self.signal_match is not None:
			bus = dbus.Bus()
			bus.remove_signal_receiver(self.signal_match,
		                        signal_name="NewServerlist",
		                        dbus_interface=get_plugin_iface_name(PLUGID))
			self.signal_match = None
		self.mark_for_update()
		stop_plugin_service(PLUGID)

	def get_items(self):
		for x in self.serverids:
			yield VimApp(x, _("Vim Session %s") % kupferstring.fromlocale(x))

	def on_new_serverlist(self, new_list):
		self.output_debug("New list:", list(new_list))
		if set(new_list) != set(self.serverids):
			self.serverids = map(str, new_list)
			self.mark_for_update()

	def provides(self):
		yield VimApp

	@classmethod
	def decorate_item(cls, leaf):
		if cls.instance and not cls.instance.serverids:
			return None
		return super(ActiveVim, cls).decorate_item(leaf)

########NEW FILE########
__FILENAME__ = service

import os
import sys
import traceback

import pygtk
pygtk.require('2.0')

import glib
import gobject

from kupfer.plugin.vim import vimcom

try:
	import dbus
	import dbus.service
	#import dbus.glib
	from dbus.mainloop.glib import DBusGMainLoop

except (ImportError, dbus.exceptions.DBusException) as exc:
	print exc
	raise SystemExit(1)

PLUGID='vim'

server_name = "se.kaizer.kupfer.plugin.%s" % PLUGID
interface_name = "se.kaizer.kupfer.plugin.%s" % PLUGID
object_name = "/se/kaizer/kupfer/plugin/%s" % PLUGID

class Service (dbus.service.Object):
	def __init__(self, mainloop, bus):
		bus_name = dbus.service.BusName(server_name, bus=bus,
				allow_replacement=True, replace_existing=True)
		super(Service, self).__init__(conn=bus, object_path=object_name,
				bus_name=bus_name)
		self.mainloop = mainloop
		self.initialize()

	def unregister(self):
		self.connection.release_name(server_name)

	def initialize(self):
		self.vimcom = vimcom.VimCom(self)
		self.vimcom.vim_hidden = vimcom.poller(name_token="KUPFER")
		self.vimcom.stop_fetching_serverlist()
		self.serverids = []
		glib.timeout_add_seconds(1, self.update_serverlist)

	def finalize(self):
		pid = self.vimcom.vim_hidden.pid
		if pid:
			self.vimcom.send_ex(self.vimcom.vim_hidden.name, 'qa!')
			os.close(self.vimcom.vim_hidden.childfd)
			#os.kill(pid, 15)
			os.waitpid(pid, 0)
		self.vimcom.destroy()
		self.vimcom = None

	def mark_for_update(self):
		self.NewServerlist(self.serverids)

	def vim_new_serverlist(self, serverlist):
		"""this is the inaccurate serverlist"""
		## useless callback from vimcom.VimCom
		pass

	def on_new_serverlist(self, new_list):
		if set(new_list) != set(self.serverids):
			self.serverids = new_list
			self.mark_for_update()

	def update_serverlist(self):
		if self.vimcom:
			self.vimcom.get_hidden_serverlist(self.on_new_serverlist)
			return True

	@dbus.service.method(interface_name, in_signature="ay", out_signature="b",
	                     byte_arrays=True)
	def Foreground(self, server):
		if self.vimcom and server in self.serverids:
			self.vimcom.foreground(server)
			return True
		return False

	@dbus.service.method(interface_name, in_signature="ayay", out_signature="b",
	                     byte_arrays=True)
	def SendEx(self, server, excommand):
		if self.vimcom and server in self.serverids:
			self.vimcom.send_ex(server, excommand)
			return True
		return False

	@dbus.service.signal(interface_name, signature="aay")
	def NewServerlist(self, serverlist):
		pass

	@dbus.service.method(interface_name)
	def Exit(self):
		self.unregister()
		self.finalize()
		self.mainloop.quit()

def start(ml):
	try:
		bus = dbus.Bus()
		service = Service(ml, bus)
	except:
		traceback.print_exc()
		raise SystemExit(1)

def main():
	ml_wrap = DBusGMainLoop(set_as_default=True)
	glib.set_prgname(__name__)
	ml = glib.MainLoop()
	glib.idle_add(start, ml)
	ml.run()

if __name__ == '__main__':
	main()

########NEW FILE########
__FILENAME__ = vimcom
# -*- coding: utf-8 -*- 

# vim:set shiftwidth=4 tabstop=4 expandtab textwidth=79:
#Copyright (c) 2005 Ali Afshar aafshar@gmail.com

#Permission is hereby granted, free of charge, to any person obtaining a copy
#of this software and associated documentation files (the "Software"), to deal
#in the Software without restriction, including without limitation the rights
#to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
#copies of the Software, and to permit persons to whom the Software is
#furnished to do so, subject to the following conditions:

#The above copyright notice and this permission notice shall be included in
#all copies or substantial portions of the Software.

#THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
#IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
#FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
#AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
#LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
#OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
#SOFTWARE.


"""

A library to control vim -g using its X protocol interface (with gdk).

============
How it works
============

=== General Communication ===

The Vim client/server protocol communicates by sending messages to and from an
X communication window. The details are explained in the Vim source.
Essentially, Vim understands two sorts of messages over this interface.

;asynchronous key sends : that are exactly equivalent to to the user of the
remote Vim typing commands.

;synchronous expression evaluations : these are Vim expressions that are
evaluated by the remote Vim, and an answer is replied with the result over the
same protocol.

Although the synchronous messages are called synchronous, the reply itself, in
programming terms is entirely asynchronous, in that there is no way of knowing
when a reply will be received, and one cannot block for it.

Thus, this library allows you to make both of these calls to remote Vims.
Synchronous expressions must provide a call back function that will be called
when the message is replied to.

=== The Server List ===

(It has been an utter nightmare.)

The primary problem is that GTK does not actually know accurately whether
a window with a given window ID has been destroyed. This is how Vim does
it (using the X libraries) after checking an attribute for registered Vim
sessions with the X root window. This way each Vim doesn't need to
unregister itself with the X root window on dying, it just assumes that
any other client attempting to connect to it will know that the window
has been destroyed. As mentioned, GTK totally fails to do what the X
library does, and ascertain whether the window is alive. It succeeds
sometimes, but not at others. The result is a GDK window that appears
alive, and ready to communicate with, but which causes an uncatchable and
fatal application error.

Step in other potential methods of getting an accurate list of servers.
Firstly, and most obviously, one can call the command 'vim --serverlist'
on a simple system pipe and read the list off. This is entirely reliable,
and effective, but the cost of forking a process and starting Vim each
time is not fun, and effectively blocks.

Another option is to force users to start Vim through Pida and keep an
account of the child processes. This would work very effectively, but it
restricts the user, and the entire system.

The final, and current solution is to start Vim itself on a
pseudoterminal as a hidden instance, and then communicate with that over
the Vim protocol. The reason this can be reliably done, is that since the
process is a child, it can be polled to check whether it is alive. This
is performed each time the serverlist is requested, and if the hidden
instance has been destroyed (eg by the user) a new one is spawned, thus
preventing an attempt to communicate with an already-destroyed GDK
window.

The cost of this solution is that we spawn an extra Vim process. I
believe that the added solidity it brings to the entire system is easily
worth it, and it ensures that Pida can communicate with Vim it started
and Vim it didn't start.
"""
# Gtk imports
import gtk
import gtk.gdk as gdk
import gobject
# System imports
import os
import pty
import time
import tempfile

class poller(object):
    """
    DEPRECATED: WE DO NOT USE THIS ANYMORE

    An instance of Vim on a pseudoterminal which can be reliably polled.

    This class is used to provide an instance of Vim which can be communicated
    with using the Vim client/server protocol, in order to retrieve an accurate
    and current server list, and also which can be polled accurately as to
    whether it is alive before communicating with it.

    This method is much cheaper in resources than running vim --serverlist each
    time, and much more accurate than using the root window's VimRegistry
    property, and also more accurate than using GDK methods for assessing
    whether a window is alive.
    """

    def __init__(self, name_token="PIDA_HIDDEN", extra_args=[]):
        """
        Constructor.
        
        Create a temporary and unique name for use as the servername, and
        initialise the instance variables.

        @param cb: An instance of the main application class.
        @type cb: pida.main.Application.
        """
        # Prefacing with '__' means it will be ignored in the internal server
        # list.
        self.name = '__%s_%s' % (time.time(), name_token)
        # Checked to evaluate False on starting.
        self.pid = None
        self.extra_args = extra_args

    def start(self):
        """
        Start the Vim instance if it is not already running.
        
        This command forks in a pseudoterminal, and starts Vim, if Vim is not
        already running. The pid is stored for later use.
        """
        if not self.pid:
            # Get the console vim executable path
            #command = self.prop_main_registry.commands.vim.value()
            command = 'gvim'
            # Fork using pty.fork to prevent Vim taking the terminal
            sock = gtk.Socket()
            w = gtk.Window()
            w.realize()
            w.add(sock)
            xid = sock.get_id()
            pid, fd = pty.fork()
            if pid == 0:
                # Child, execute Vim with the correct servername argument
                argv = ['gvim', '-f', '--servername', self.name,
                    '--socketid', '%s' % xid]
                argv.extend(self.extra_args)
                os.execvp(command, argv)
                # os.system('%s -v --servername %s' % (command, self.name))
            else:
                # Parent, store the pid, and file descriptor for later.
                self.pid = pid
                self.childfd = fd
                #self.do_action('accountfork', self.pid)

    def is_alive(self):
        """
        Check if the Vim instance is alive.
        
        This method uses os.waitpid, with no blocking to determine whether the
        process is still alive. If it is not, it sets the internal pid
        attribute to None, so that it may be restarted.
        
        @returns: alive
        @rtype alive: boolean
        """
        if self.pid:
            try:
                # call os.waitpid, returns 0 if the pid is alive
                pid, sts = os.waitpid(self.pid, os.WNOHANG)
            except OSError:
                # might still be starting up
                return False
            if pid == self.pid:
                # has shut down
                self.pid = None
                return False
            else:
                # is still alive
                return True
        else:
            # Not started yet
            return False

class communication_window(gtk.Window):
    """
    A GTK window that can communicate with any number Vim instances.

    This is an actual GTK window (which it must be to accurately detect
    property events inside the GTK main loop) but has its GDK window correctly
    set to receive such events. This is notably the "Vim" property which must
    be present and set to a version string, in this case "6.0" is used.
    """
    def __init__(self, cb):
        """
        Constructor.

        The Window is instantiated, the properties are correctly set, the event
        mask is modified, and the instance variables are initialized.

        @param cb: An instance of the main Application class.
        @type cb: pida.main.Application.
        """
        gtk.Window.__init__(self)
        self.cb = cb
        # Window needs to be realized to do anything useful with it. Realizing
        # does not show the window to the user, so we can use it, but not have
        # an ugly blank frame while it loads.
        self.realize()
        # The "Vim" property
        self.window.property_change("Vim", gdk.SELECTION_TYPE_STRING, 8,
                            gdk.PROP_MODE_REPLACE, "6.0")
        # Set the correct event mask and connect the notify event
        self.add_events(gtk.gdk.PROPERTY_CHANGE_MASK)
        self.connect('property-notify-event', self.cb_notify)
        # The serial number used for sending synchronous messages
        self.serial = 1
        # A dictionary of callbacks for synchronous messages. The key is the
        # serial number, and the value is a callable that will be called with
        # the result of the synchronous evaluation.
        self.callbacks = {}
        # A dictionary to store the working directories for each Vim so they
        # only have to be fetched once.
        self.server_cwds = {}
        # An instance of the root window, so it only has to be fetched once.
        self.root_window = gdk.get_default_root_window()
        # fetch the serverlist to begin with to know when we are started
        self.oldservers = None
        self.keep_fetching_serverlist = True
        gobject.timeout_add(250, self.fetch_serverlist)
    
    def fetch_serverlist(self):
        """
        Fetch the serverlist, and if it has changed, feed it to the client.

        The serverlist is requested asynchrnously, and passed the gotservers
        function as a callback. The gotservers function is then called with the
        server list, gets the appropriate working directory (if required) and
        feeds the new server list to the client if it has changed.
        """
        def gotservers(serverlist):
            """
            Called back on receiving the serverlist.

            Fetch working directories for new Vim instances, and feed the
            server list to the client if it has changed.
            """
            for server in serverlist:
                # Check if we already have the working directory.
                if server not in self.server_cwds:
                    # We don't, fetch it
                    self.fetch_cwd(server)
            # Check if the server list has changed
            if serverlist != self.oldservers:
                self.oldservers = serverlist
                # A ew serverlist to feed to the client.
                self.feed_serverlist(serverlist)
        gotservers(self.get_rootwindow_serverlist())
        # decide whether to keep fetching server list
        return self.keep_fetching_serverlist

    def stop_fetching_serverlist(self):
        self.keep_fetching_serverlist = False

    def get_rootwindow_serverlist(self):
        """
        Get the X root window's version of the current Vim serverlist.

        On starting with the client-server feature, GVim or Vim with the
        --servername option registers its server name and X window id as part
        of the "VimRegistry" parameter on the X root window.

        This method extracts and parses that property, and returns the server
        list.

        Note: Vim does not actually unregister itself with the root window on
        dying, so the presence of a server in the root window list is no
        gurantee that it is alive.

        @return: servers
        @rtype servers: dict of ("server", "window id") key, value
        """
        servers = {}
        # Read the property
        vimregistry = self.root_window.property_get("VimRegistry")
        # If it exists
        if vimregistry:
            # Get the list of servers by splitting with '\0'
            vimservers = vimregistry[-1].split('\0')
            # Parse each individual server and add to the results list
            for rawserver in vimservers:
                # Sometimes blank servers exist in the list
                if rawserver:
                    # split the raw value for the name and id
                    name_id = rawserver.split()
                    # Set the value in the results dict, remembering to convert
                    # the window id to a long int.
                    servers[name_id[1]] = long(int(name_id[0], 16))
        # return the list of resuts
        return servers

    def get_shell_serverlist(self):
        """
        DEPRACATED: WE NEVER NEED A SERVERLIST
        (This is here for educative purposes)

        Get the server list by starting console Vim on a Pipe.

        This blocks, so we don't use it. It is one of the alternative methods
        of retrieving an accurate serverlist. It is slow, and expensive.
        """
        vimcom = 'gvim'
        p = os.popen('%s --serverlist' % vimcom)
        servers = p.read()
        p.close()
        return servers.splitlines()
 
    def get_hidden_serverlist(self, callbackfunc):
        """
        DEPRACATED: WE NEVER NEED A SERVERLIST
        (This is here for educative purposes)

        Get the serverlist from the hidden Vim instance and call the callback
        function with the results.

        This method checks first whther the Vim instance is alive, and then
        evaluates the serverlist() function remotely in it, with a local call
        back function which parses the result and calls the user-provided
        callback function.

        @param callbackfunc: The call back function to be called with the
            server list.
        @type callbackfunc: callable
        """
        def cb(serverstring):
            """
            Called back with the raw server list.

            Parse the lines and call the call back function, ignoring any
            instances starting with "__" which represent hidden instances. If
            the hidden Vim instance is not alive, it is restarted.
            """
            servers = serverstring.splitlines()
            # Call the callback function
            callbackfunc([svr for svr in servers if not svr.startswith('__')])
        # Check if the hidden Vim is alive. 
        if self.vim_hidden.is_alive():
            # It is alive, get the serverlist.
            self.send_expr(self.vim_hidden.name, 'serverlist()', cb)
        else:
            # It is not alive, restart it.
            self.vim_hidden.start()

    def get_server_wid(self, servername):
        """
        Get the X Window id for a named Vim server.

        This function returns the id from the root window server list, if it
        exists, or None if it does not.

        @param servername: The name of the server
        @type servername: str

        @return: wid
        @rtype wid: long
        """
        try:
            # get the window id from the root window
            wid = self.get_rootwindow_serverlist()[servername]
        except KeyError:
            # The server is not registered in the root window so return None
            wid = None
        # Return wid if it is not none, or None
        return wid and long(wid) or None

    def get_server_window(self, wid):
        """
        Create and return a GDK window for a given window ID.
        
        This method simply calls gdk.window_foreign_new, which should return
        None if the window has been destroyed, but does not, in some cases.

        @param wid: The window ID.
        @type wid: long
        """
        return gtk.gdk.window_foreign_new(wid)

    def feed_serverlist(self, serverlist):
        """
        Feed the given list of servers to the client.

        This is achieved by calling the clients serverlist event. In Pida, this
        event is passed on to all the plugins.

        @param serverlist: The list of servers.
        @type serverlist: list
        """
        # Call the event.
        #self.do_evt('serverlist', serverlist)
        self.cb.vim_new_serverlist(serverlist)

    def fetch_cwd(self, servername):
        """
        Fetch the working directory for a named server and store the result.
        """
        def gotcwd(cwd):
            """
            Called back on receiving the working directory, store it for later
            use.
            """
            self.server_cwds[servername] = cwd
        # Evaluate the expression with the gotcwd callback
        self.send_expr(servername, "getcwd()", gotcwd)

    def get_cwd(self, server):
        if server in self.server_cwds:
            return self.server_cwds[server]

    def abspath(self, servername, filename):
        """
        Return the absolute path of a buffer name in the context of the named
        server.
        """
        # Only alter non-absolute paths
        if not filename.startswith('/'):
            try:
                # Try to find the current working directory
                cwd = self.server_cwds[servername]
            except KeyError:
                # The working directory is not set
                # Use a sane default, and fetch it
                cwd = os.path.expanduser('~')
                self.fetch_cwd(servername)
            filename = os.path.join(cwd, filename)
        return filename

    def generate_message(self, server, cork, message, sourceid):
        """
        Generate a message.
        """
        # Increment the serial number used for synchronous messages
        if cork:
            self.serial = self.serial + 1
            # Pick an arbitrary number where we recycle.
            if self.serial > 65530:
                self.serial = 1
        # return the generated string
        return '\0%s\0-n %s\0-s %s\0-r %x %s\0' % (cork,
                                                   server,
                                                   message,
                                                   sourceid,
                                                   self.serial)
 
    def parse_message(self, message):
        """
        Parse a received message and return the message atributes as a
        dictionary.
        """
        messageattrs = {}
        for t in [s.split(' ') for s in message.split('\0')]:
            if t and len(t[0]):
                if t[0].startswith('-'):
                    #attributes start with a '-', strip it and set the value
                    if len(t) > 1:
                        messageattrs[t[0][1:]] = t[1]
                else:
                    # Otherwise set the t attribute
                    messageattrs['t'] = t[0]
        return messageattrs

    def send_message(self, servername, message, asexpr, callback):
        wid = self.get_server_wid(servername)
        if wid:
            cork = (asexpr and 'c') or 'k'
            sw = self.get_server_window(wid)
            if sw and sw.property_get("Vim"):
                mp = self.generate_message(servername, cork, message,
                                        self.window.xid)
                sw.property_change("Comm", gdk.TARGET_STRING, 8,
                                        gdk.PROP_MODE_APPEND, mp)
                if asexpr and callback:
                    self.callbacks['%s' % (self.serial)] = callback

    def send_expr(self, server, message, callback):
        self.send_message(server, message, True, callback)

    def send_keys(self, server, message):
        self.send_message(server, message, False, False)

    def send_esc(self, server):
        self.send_keys(server, '<C-\><C-N>')

    def send_ret(self, server):
        self.send_keys(server, '<RETURN>')

    def send_ex(self, server, message):
        self.send_esc(server)
        self.send_keys(server, ':%s' % message)
        self.send_ret(server)

    def get_option(self, server, option, callbackfunc):
        self.send_expr(server, '&%s' % option, callbackfunc)

    def foreground(self, server):
        def cb(*args):
            pass
        self.send_expr(server, 'foreground()', cb)
        
    def change_buffer(self, server, filename):
        self.send_ex(server, "exe 'b!'.bufnr('%s')" % filename)

    def change_buffer_number(self, server, number):
        self.send_ex(server, "b!%s" % number)

    def close_buffer(self, server, buffername):
        self.send_ex(server, "exe 'confirm bw'.bufnr('%s')" % buffername)

    def close_current_buffer(self, server):
        self.send_ex(server, 'confirm bw')

    def change_cursor(self, server, x, y):
        self.send_message(server, 'cursor(%s, %s)' % (y, x), True, False)
        self.send_esc(server)

    def save_session(self, name):
        self.send_ex('mks %s' % name)

    def escape_filename(self, name):
        for s in ['\\', '?', '*', ' ', "'", '"', '[', '	', '$', '{', '}']:
            name = name.replace (s, '\\%s' % s)
        return name

    def open_file(self, server, name):
        self.send_ex(server, 'confirm e %s' % self.escape_filename(name))

    def new_file(self, server):
        f, path = tempfile.mkstemp()
        self.open_file(server, path)
        return path

    def goto_line(self, server, linenumber):
        self.send_ex(server, '%s' % linenumber)
        self.send_esc(server)
        self.send_keys(server, 'zz')
        self.send_keys(server, 'zv')

    def revert(self, server):
        self.send_ex(server, 'e')

    def load_script(self, server, scriptpath):
        self.send_ex(server, 'so %s' % scriptpath)

    def preview_file(self, server, fn):
        self.send_ex(server, 'pc')
        self.send_ex(server, 'set nopreviewwindow')
        self.send_ex(server, 'pedit %s' % fn)

    def get_bufferlist(self, server):
        def cb(bl):
            if bl:
                l = [i.split(':') for i in bl.strip(';').split(';')]
                L = []
                for n in l:
                    if not n[0].startswith('E'):
                        L.append([n[0], self.abspath(server, n[1])])
                self.do_evt('bufferlist', L)
        #self.get_cwd(server)
        self.send_expr(server, 'Bufferlist()', cb)

    def get_current_buffer(self, server):
        def cb(bs):
            bn = bs.split(',')
            bn[1] = self.abspath(server, bn[1])
            self.do_evt('bufferchange', *bn)
        #self.get_cwd(server)
        self.send_expr(server, "bufnr('%').','.bufname('%')", cb)

    def save(self, server):
        self.send_ex(server, 'w')

    def save_as(self, server, filename):
        print filename
        self.send_ex(server, 'saveas %s' % filename)

    def undo(self, server):
        self.send_esc(server)
        self.send_keys(server, 'u')

    def redo(self, server):
        self.send_esc(server)
        self.send_keys(server, '<C-r>')

    def cut(self, server):
        self.send_keys(server, '"+x')

    def copy(self, server):
        self.send_keys(server, '"+y')

    def paste(self, server):
        self.send_esc(server)
        self.send_keys(server, 'p')

    def set_colorscheme(self, server, colorscheme):
        self.send_ex(server, 'colorscheme %s' % colorscheme)

    def set_menu_visible(self, server, visible):
        if visible:
            op = '+'
        else:
            op = '-'
        self.send_ex(server, 'set guioptions%s=m' % op)

    def quit(self, server):
        self.send_ex(server, 'q!')

    def define_sign(self, server, name, icon, linehl, text, texthl):
        self.send_ex(server, 'sign define %s icon=%s linehl=%s text=%s texthl=%s '%
                             (name, icon, linehl, text, texthl))

    def undefine_sign(self, server, name):
        self.send_ex(server, 'sign undefine %s' % name)
   
    def show_sign(self, server, index, type, filename, line):
        self.send_ex(server, 'sign place %s line=%s name=%s file=%s' %
                             (index + 1, line, type, filename))
   
    def hide_sign(self, server, index, filename):
        self.send_ex(server, 'sign unplace %s' % (index + 1))
   
    def cb_notify(self, *a):
        win, ev =  a
        if hasattr(ev, 'atom'):
            if ev.atom == 'Comm':
                message = self.window.property_get('Comm', pdelete=True)
                if message:
                    self.cb_reply(message[-1])
        return True

    def cb_reply(self, data):
        mdict = self.parse_message(data)
        if mdict['t'] == 'r':
            if mdict['s'] in self.callbacks:
                self.callbacks[mdict['s']](mdict['r'])
        else:
            s = [t for t in data.split('\0') if t.startswith('-n')].pop()[3:]
            self.cb_reply_async(s)

    def cb_reply_async(self, data):
        if data.count(':'):
            server, data = data.split(':', 1)
        else:
            server = None
        if data.count(','):
            evt, d = data.split(',', 1)
            self.vim_event(server, evt, d)
        else:
            print 'bad async reply', data

    def vim_event(self, server, evt, d):
        funcname = 'vim_%s' % evt
        if hasattr(self.cb, funcname):
            getattr(self.cb, funcname)(server, *d.split(','))
        else:
            print 'unhandled event', evt

VimCom = communication_window


NMAP_COM = '%smap %s :call %s<lt>CR>'
UNMAP_COM = '%sun %s'
VIMSCRIPT = ''':silent function! Bufferlist()
let i = 1
    let max = bufnr('$') + 1
    let lis = ""
    while i < max
        if bufexists(i)
            let lis = lis.";".i.":".bufname(i)
        endif
        let i = i + 1
    endwhile
    return lis
:endfunction
:silent function! BreakPoint(l)
    call Async_event(v:servername.":set_breakpoint,".a:l)
:endfunction
:silent function! Yank_visual()
    y
    return @"
:endfunction
:silent function! Async_event(e)
    let c = "silent call server2client('".expand('<client>')."', '".a:e."')"
    try
        exec c
    catch /.*/
        echo c
    endtry
:endfunction
:silent function! Pida_Started()
    silent call Async_event(v:servername.":filesave,")
    echo "PIDA connected"
:endfunction
:silent sign define break text=!B
:silent augroup pida
:silent set guioptions-=T
:silent set guioptions-=m
:silent au! pida
:silent au pida BufEnter * silent call Async_event(v:servername.":bufferchange,".getcwd().",".bufname('%').",".bufnr('%'))
:silent au pida BufDelete * silent call Async_event(v:servername.":bufferunload,".expand('<amatch>'))
:silent au pida VimLeave * silent call Async_event(v:servername.":shutdown,")
:silent au pida VimEnter * silent call Pida_Started()
:silent au pida BufWritePost * silent call Async_event(v:servername.":filesave,")
'''
        

########NEW FILE########
__FILENAME__ = vinagre
# -*- coding: UTF-8 -*-
from __future__ import with_statement

__kupfer_name__ = _("Vinagre")
__kupfer_sources__ = ("SessionSource", )
__kupfer_actions__ = ('VinagreStartSession', )
__description__ = _("Vinagre bookmarks and actions")
__version__ = "2009-11-24"
__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"


import os
import gio
from xml.etree import cElementTree as ElementTree

from kupfer.objects import Action, UrlLeaf
from kupfer.obj.helplib import PicklingHelperMixin
from kupfer.obj.apps import AppLeafContentMixin
from kupfer import utils, icons
from kupfer.obj.grouping import ToplevelGroupingSource 
from kupfer.obj.hosts import HostServiceLeaf, HOST_ADDRESS_KEY, \
		HOST_SERVICE_NAME_KEY, HOST_SERVICE_PORT_KEY, HOST_SERVICE_USER_KEY

BOOKMARKS_FILE = '~/.local/share/vinagre/vinagre-bookmarks.xml'


class Bookmark(HostServiceLeaf):
	def get_gicon(self):
		return icons.ComposedIconSmall(self.get_icon_name(), "vinagre")


class VinagreStartSession(Action):
	def __init__(self):
		Action.__init__(self, _('Start Vinagre Session'))

	def activate(self, leaf):
		if isinstance(leaf, UrlLeaf):
			utils.spawn_async(["vinagre", leaf.object])
		else:
			service = leaf[HOST_SERVICE_NAME_KEY]
			host = leaf[HOST_ADDRESS_KEY]
			port = ''
			if leaf.check_key(HOST_SERVICE_PORT_KEY):
				port = ':' + leaf[HOST_SERVICE_PORT_KEY]
			user = ''
			if leaf.check_key(HOST_SERVICE_USER_KEY):
				user = leaf[HOST_SERVICE_USER_KEY] + '@'
			url = '%s://%s%s%s' % (service, user, host, port)
			utils.spawn_async(["vinagre", url])

	def get_icon_name(self):
		return 'vinagre'

	def item_types(self):
		yield HostServiceLeaf
		yield UrlLeaf

	def valid_for_item(self, item):
		if isinstance(item, HostServiceLeaf):
			if item.check_key(HOST_SERVICE_NAME_KEY):
				service = item[HOST_SERVICE_NAME_KEY]
				return service in ('ssh', 'vnc')
			return False
		return (item.object.startswith('ssh://') \
				or item.object.startswith('vnc://'))


class SessionSource(AppLeafContentMixin, ToplevelGroupingSource,
		PicklingHelperMixin):
	appleaf_content_id = 'vinagre'

	def __init__(self, name=_("Vinagre Bookmarks")):
		ToplevelGroupingSource.__init__(self, name, 'hosts')
		self._version = 2

	def pickle_prepare(self):
		self.monitor = None

	def initialize(self):
		ToplevelGroupingSource.initialize(self)
		bookmark_file = os.path.expanduser(BOOKMARKS_FILE)
		gfile = gio.File(bookmark_file)
		self.monitor = gfile.monitor_file(gio.FILE_MONITOR_NONE, None)
		if self.monitor:
			self.monitor.connect("changed", self._on_bookmarks_changed)

	def _on_bookmarks_changed(self, monitor, file1, file2, evt_type):
		if evt_type in (gio.FILE_MONITOR_EVENT_CREATED,
				gio.FILE_MONITOR_EVENT_DELETED,
				gio.FILE_MONITOR_EVENT_CHANGED):
			self.mark_for_update()

	def get_items(self):
		bookmark_file = os.path.expanduser(BOOKMARKS_FILE)
		if not os.path.isfile(bookmark_file):
			return

		try:
			tree = ElementTree.parse(bookmark_file)
			for item in tree.findall('item'):
				protocol = item.find('protocol').text
				name = item.find('name').text
				host = item.find('host').text
				port = item.find('port').text
				url = '%s://%s:%s' % (protocol, host, port)
				user = None
				if host.find('@') > 0:
					user, host = host.split('@', 1)
				yield Bookmark(name, host, protocol, url, port, user)
		except StandardError, err:
			self.output_error(err)

	def get_description(self):
		return None

	def get_icon_name(self):
		return "vinagre"

	def provides(self):
		yield Bookmark



########NEW FILE########
__FILENAME__ = constants
# -*- coding: UTF-8 -*-
'''
virtualbox_const_support.py

Constants for VirtualBox.
'''
__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"
__version__ = '0.3'

# virtual machine states
VM_STATE_POWEROFF = 0
VM_STATE_POWERON = 1
VM_STATE_PAUSED = 2
VM_STATE_SAVED = 3

# virtual machine actions
VM_START_NORMAL = 1
VM_START_HEADLESS = 2
VM_PAUSE = 3
VM_POWEROFF = 4
VM_ACPI_POWEROFF = 5
VM_REBOOT = 6
VM_RESUME = 7
VM_SAVE = 8

########NEW FILE########
__FILENAME__ = ose_support
# -*- coding: UTF-8 -*-
'''
virtualbox_ose_support.py

Control VirtualBox via command-line interface.
Support both Sun VirtualBox and VirtualBox OpenSource Edition.
'''
from __future__ import with_statement

__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"
__version__ = '0.3'

import os
from xml.dom import minidom

from kupfer import pretty, utils
from kupfer.plugin.virtualbox import constants as vbox_const

_VBOX_CONFIG_DIR = os.path.expanduser('~/.VirtualBox/')
_VBOX_CONFIG_FILE = os.path.join(_VBOX_CONFIG_DIR, 'VirtualBox.xml')

MONITORED_DIRS = (_VBOX_CONFIG_DIR, )
IS_DYNAMIC = False
ICON = "virtualbox-ose"
APP_ID = "virtualbox-ose"

# parameters for VBoxManage
_ACTIONS = {
		vbox_const.VM_POWEROFF: 'poweroff',
		vbox_const.VM_ACPI_POWEROFF: 'acpipowerbutton',
		vbox_const.VM_PAUSE: 'pause',
		vbox_const.VM_REBOOT: 'reset',
		vbox_const.VM_RESUME: 'resume',
		vbox_const.VM_SAVE: 'savestate',
}


def get_machine_state(vm_uuid):
	''' check vms state (on/off/paused) '''
	state = vbox_const.VM_STATE_POWEROFF
	try:
		str_state = 'poweroff'
		with os.popen('VBoxManage showvminfo %s --machinereadable' % vm_uuid) \
				as pinfo:
			for line in pinfo:
				if line.startswith('VMState="'):
					str_state = line.strip()[9:-1]
					break
		if str_state == 'paused':
			state = vbox_const.VM_STATE_PAUSED
		elif str_state == 'running':
			state = vbox_const.VM_STATE_POWERON
		elif str_state == 'saved':
			state = vbox_const.VM_STATE_SAVED
	except IOError, err:
		pretty.print_error(__name__, 'get_machine_state', vm_uuid, 'error', err)
		state = vbox_const.VM_STATE_POWEROFF

	return state


def vm_action(action, vm_uuid):
	''' change state of the virtual machine. Call VBoxManage.
		@param action - one of the const VM_*
		@param vm_uuid - virtual machine uuid
	'''
	if action == vbox_const.VM_START_NORMAL:
		utils.spawn_async(['VBoxManage', 'startvm', vm_uuid, '--type', 'gui'])
	elif action == vbox_const.VM_START_HEADLESS:
		utils.spawn_async(['VBoxManage', 'startvm', vm_uuid, '--type',
		                   'headless'])
	else:
		command = _ACTIONS[action]
		utils.spawn_async(['VBoxManage', 'controlvm', vm_uuid, command])


def _get_virtual_machines(config_file):
	''' load (virtual machine uuid, path to vm config) from virtualbox
		configuration.
		@param config_file - path to VirtualBox.xml file
	'''
	try:
		dtree = minidom.parse(config_file)
		machine_registry = dtree.getElementsByTagName('MachineRegistry')[0]
		for machine in machine_registry.getElementsByTagName('MachineEntry'):
			yield (machine.getAttribute('uuid')[1:-1],
					machine.getAttribute('src'))
	except StandardError, err:
		pretty.print_error(__name__, '_get_virtual_machines', config_file,
				'error', err)


def _get_machine_info(vm_uuid, config_file):
	''' load information about virtual machines from its configuration file.
		@param vm_uuid - uuid virtual machine
		@param config_file - path to vm configuration file
	'''
	if not os.path.isfile(config_file):
		return None, None

	try:
		dtree = minidom.parse(config_file)
		machine_registry = dtree.getElementsByTagName('Machine')[0]
		os_type = machine_registry.getAttribute('OSType')
		name = machine_registry.getAttribute('name')
		description = None
		for machine_registry_child in machine_registry.childNodes:
			if machine_registry_child.nodeName == 'Description':
				if machine_registry_child.hasChildNodes():
					description = machine_registry_child.firstChild.nodeValue
				break
		return (name, description or os_type)
	except StandardError, err:
		pretty.print_error(__name__, '_get_machine_info', vm_uuid, 'error' + \
				config_file, err)
	return None, None


def get_machines():
	if os.path.isfile(_VBOX_CONFIG_FILE):
		for vm_uuid, config in _get_virtual_machines(_VBOX_CONFIG_FILE):
			if not os.path.isabs(config):
				config = os.path.join(os.path.dirname(_VBOX_CONFIG_FILE), config)
			name, description = _get_machine_info(vm_uuid, config)
			if name:
				yield (vm_uuid, name, description)


def unload():
	pass

########NEW FILE########
__FILENAME__ = vboxapi4_support
# -*- coding: UTF-8 -*-
'''
virtualbox_vboxapi_support.py

Control VirtualBox via Python interface (vboxapi).
Only (?) Sun VirtualBox (no OSE).
'''
__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"
__version__ = "2011-03-06"

import vboxapi

from kupfer import pretty


# check api
try:
	vboxapi.VirtualBoxReflectionInfo(None).SessionState_Locked
except AttributeError:
	raise ImportError()

from kupfer.plugin.virtualbox import constants as vbox_const

MONITORED_DIRS = None
IS_DYNAMIC = False
ICON = "VBox"
APP_ID = "virtualbox"


_ACTIONS = {
		vbox_const.VM_POWEROFF: lambda c: c.powerDown(),
		vbox_const.VM_ACPI_POWEROFF: lambda c: c.powerButton(),
		vbox_const.VM_PAUSE: lambda c: c.pause(),
		vbox_const.VM_REBOOT: lambda c: c.reset(),
		vbox_const.VM_RESUME: lambda c: c.resume(),
		vbox_const.VM_SAVE: lambda c: c.saveState(),
}


def _get_object_session():
	''' get new session to vm '''
	vbox, session = None, None
	try:
		vbox = vboxapi.VirtualBoxManager(None, None)
		session = vbox.mgr.getSessionObject(vbox.vbox)
	except Exception, err:
		pretty.print_error(__name__, 'virtualbox: get session error ', err)
	return vbox, session


def _get_existing_session(vm_uuid):
	''' get existing session by machine uuid '''
	vbox, session = None, None
	try:
		vbox = vboxapi.VirtualBoxManager(None, None)
		session = vbox.mgr.getSessionObject(vbox.vbox)
	except Exception, err:
		pretty.print_error(__name__, 'virtualbox: get session error', vm_uuid,
				err)
	return vbox, session


def get_machine_by_id(vbox, mid):
	try:
		mach = vbox.getMachine(mid)
	except:
		mach = vbox.findMachine(mid)
	return mach


def get_machine_state(machine_id):
	''' check vms state (on/off/paused) '''
	vbox, vbox_sess = _get_object_session()
	if vbox_sess is None:
		return vbox_const.VM_STATE_POWEROFF
	state = vbox_const.VM_STATE_POWERON
	try:
		machine = get_machine_by_id(vbox.vbox, machine_id)
		machine_state = machine.state
		if machine_state == vbox.constants.MachineState_Paused:
			state = vbox_const.VM_STATE_PAUSED
		elif machine_state in (vbox.constants.MachineState_PoweredOff,
				vbox.constants.MachineState_Aborted,
				vbox.constants.MachineState_Starting):
			state = vbox_const.VM_STATE_POWEROFF
		elif machine_state == vbox.constants.MachineState_Saved:
			state = vbox_const.VM_STATE_SAVED
	except Exception, err:  # exception == machine is off (xpcom.Exception)
		pretty.print_debug(__name__, 'get_machine_state', machine_state, err)
		# silently set state to off
		state = vbox_const.VM_STATE_POWEROFF
	return state


def _machine_start(vm_uuid, mode):
	''' Start virtual machine
		@param vm_uuid - uuid of virtual machine
		@param mode - mode: gui, headless
	'''
	vbox, session = _get_object_session()
	if session:
		try:
			mach = get_machine_by_id(vbox.vbox, vm_uuid)
			remote_sess = mach.launchVMProcess(session, mode, '')
			remote_sess.waitForCompletion(-1)
			session.unlockMachine()
		except Exception, err:
			pretty.print_error(__name__, "StartVM:", vm_uuid, "Mode ", mode,
					"error", err)


def _execute_machine_action(vm_uuid, action):
	''' Start virtual machine
		@param vm_uuid - uuid of virtual machine
		@param action - function called on vbox session
	'''
	vbox, session = _get_existing_session(vm_uuid)
	try:
		mach = get_machine_by_id(vbox.vbox, vm_uuid)
		mach.lockMachine(session, vbox.constants.LockType_Shared)
		action(session.console)
		session.unlockMachine()
	except Exception, err:
		pretty.print_error(__name__, "_execute_machine_action:", repr(action),
				" vm:", vm_uuid, "error", err)


def vm_action(action, vm_uuid):
	''' change state of the virtual machine
		@param action - one of the const VM_*
		@param vm_uuid - virtual machine uuid
	'''
	if action == vbox_const.VM_START_NORMAL:
		_machine_start(vm_uuid, 'gui')
	elif action == vbox_const.VM_START_HEADLESS:
		_machine_start(vm_uuid, 'headless')
	else:
		command = _ACTIONS[action]
		_execute_machine_action(vm_uuid, command)


def get_machines():
	''' Get generator of items:
		(machine uuid, machine name, machine description)
	'''
	vbox, vbox_sess = _get_object_session()
	if vbox_sess is None:
		return

	machines = vbox.getArray(vbox.vbox, 'machines')
	for machine in machines:
		if not machine.accessible:
			continue
		description = machine.description or machine.OSTypeId
		yield (machine.id, machine.name, description)


def unload():
	pass

########NEW FILE########
__FILENAME__ = vboxapi_support
# -*- coding: UTF-8 -*-
'''
virtualbox_vboxapi_support.py

Control VirtualBox via Python interface (vboxapi).
Only (?) Sun VirtualBox (no OSE).
'''
__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"
__version__ = "2011-03-06"


from kupfer import pretty

import vboxapi


from kupfer.plugin.virtualbox import constants as vbox_const

MONITORED_DIRS = None
IS_DYNAMIC = False
ICON = "VBox"
APP_ID = "virtualbox"

_ACTIONS = {
		vbox_const.VM_POWEROFF: lambda c: c.powerDown(),
		vbox_const.VM_ACPI_POWEROFF: lambda c: c.powerButton(),
		vbox_const.VM_PAUSE: lambda c: c.pause(),
		vbox_const.VM_REBOOT: lambda c: c.reset(),
		vbox_const.VM_RESUME: lambda c: c.resume(),
		vbox_const.VM_SAVE: lambda c: c.saveState(),
}


def _get_object_session():
	''' get new session to vm '''
	pretty.print_debug(__name__, '_get_object_session start')
	vbox, session = None, None
	try:
		vbox = vboxapi.VirtualBoxManager(None, None)
		session = vbox.mgr.getSessionObject(vbox.vbox)
	except Exception, err:
		pretty.print_error(__name__, 'virtualbox: get session error ', err)
	pretty.print_debug(__name__, '_get_object_session finished', vbox, session)
	return vbox, session


def _get_existing_session(vm_uuid):
	''' get existing session by machine uuid '''
	pretty.print_debug(__name__, '_get_existing_session start')
	vbox, session = None, None
	try:
		vbox = vboxapi.VirtualBoxManager(None, None)
		session = vbox.mgr.getSessionObject(vbox.vbox)
		vbox.vbox.openExistingSession(session, vm_uuid)
	except Exception, err:
		pretty.print_error(__name__, 'virtualbox: get session error', vm_uuid,
				err)
	pretty.print_debug(__name__, '_get_existing_session finished', vbox, session)
	return vbox, session


def get_machine_state(machine_id):
	''' check vms state (on/off/paused) '''
	pretty.print_debug(__name__, 'get_machine_state', machine_id)
	vbox, vbox_sess = _get_object_session()
	if vbox_sess is None:
		return vbox_const.VM_STATE_POWEROFF
	state = vbox_const.VM_STATE_POWERON
	try:
		vbox.vbox.openExistingSession(vbox_sess, machine_id)
		machine_state = vbox_sess.machine.state
		if machine_state == vbox.constants.MachineState_Paused:
			state = vbox_const.VM_STATE_PAUSED
		elif machine_state in (vbox.constants.MachineState_PoweredOff,
				vbox.constants.MachineState_Aborted,
				vbox.constants.MachineState_Starting):
			state = vbox_const.VM_STATE_POWEROFF
		elif machine_state == vbox.constants.MachineState_Saved:
			state = vbox_const.VM_STATE_SAVED
	except Exception, err:  # exception == machine is off (xpcom.Exception)
		# silently set state to off
		state = vbox_const.VM_STATE_POWEROFF
		pretty.print_debug(__name__, 'get_machine_state error', err)
	try:
		if vbox_sess.state == vbox.constants.SessionState_Open:
			vbox_sess.close()
	except Exception:  # varoius errors (xpcom.Exception)
		pass
	pretty.print_debug(__name__, 'get_machine_state finish', machine_id, state)
	return state


def _machine_start(vm_uuid, mode):
	''' Start virtual machine
		@param vm_uuid - uuid of virtual machine
		@param mode - mode: gui, headless
	'''
	vbox, session = _get_object_session()
	if session:
		try:
			remote_sess = vbox.vbox.openRemoteSession(session, vm_uuid, mode,
					'')
			remote_sess.waitForCompletion(-1)
		except Exception, err:
			pretty.print_error(__name__, "StartVM:", vm_uuid, "Mode ", mode,
					"error", err)
		try:
			if session.state == vbox.constants.SessionState_Open:
				session.close()
		except Exception:  # varoius errors (xpcom.Exception)
			pass


def _execute_machine_action(vm_uuid, action):
	''' Start virtual machine
		@param vm_uuid - uuid of virtual machine
		@param action - function called on vbox session
	'''
	vbox, session = _get_existing_session(vm_uuid)
	try:
		action(session.console)
	except Exception, err:
		pretty.print_error(__name__, "_execute_machine_action:", repr(action),
				" vm:", vm_uuid, "error", err)
	try:
		if session.state == vbox.constants.SessionState_Open:
			session.close()
	except Exception:  # varoius errors (xpcom.Exception)
		pass


def vm_action(action, vm_uuid):
	''' change state of the virtual machine
		@param action - one of the const VM_*
		@param vm_uuid - virtual machine uuid
	'''
	if action == vbox_const.VM_START_NORMAL:
		_machine_start(vm_uuid, 'gui')
	elif action == vbox_const.VM_START_HEADLESS:
		_machine_start(vm_uuid, 'headless')
	else:
		command = _ACTIONS[action]
		_execute_machine_action(vm_uuid, command)


def get_machines():
	''' Get generator of items:
		(machine uuid, machine name, machine description)
	'''
	pretty.print_debug(__name__, 'get_machines start')
	vbox, vbox_sess = _get_object_session()
	if vbox_sess is None:
		return
	machines = vbox.getArray(vbox.vbox, 'machines')
	for machine in machines:
		pretty.print_debug(__name__, 'get_machines; found machine',
				machine.id, machine.name)
		description = machine.description or machine.OSTypeId
		yield (machine.id, machine.name, description)
	pretty.print_debug(__name__, 'get_machines finished')


def unload():
	pass

########NEW FILE########
__FILENAME__ = volumes
__kupfer_name__ = _("Volumes and Disks")
__kupfer_sources__ = ("VolumesSource", )
__description__ = _("Mounted volumes and disks")
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import gio

from kupfer.objects import Action, Source, FileLeaf
from kupfer.obj.fileactions import Open, OpenTerminal
from kupfer import utils


class Volume (FileLeaf):
	"""
	The Volume class actually represents one instance
	of GIO's GMount (as long as it is mounted)
	"""
	# NOTE: marking as non-serializable
	serializable = None

	def __init__(self, volume):
		self.volume = volume
		fil = self.volume.get_root()
		path = fil.get_path()
		super(Volume, self).__init__(obj=path, name=volume.get_name())
		self.kupfer_add_alias(fil.get_basename())

	def get_actions(self):
		yield Open()
		yield OpenTerminal()
		if self.volume.can_eject():
			yield Eject()
		elif self.volume.can_unmount():
			yield Unmount()

	def is_valid(self):
		vm = gio.volume_monitor_get()
		return any(self.volume == v for v in vm.get_mounts())

	def get_description(self):
		return _("Volume mounted at %s") % \
				utils.get_display_path_for_bytestring(self.object)
	def get_gicon(self):
		return self.volume.get_icon()
	def get_icon_name(self):
		return "drive-removable-media"

class Unmount (Action):
	def __init__(self, name=None):
		super(Unmount, self).__init__(name or _("Unmount"))

	def eject_callback(self, mount, async_result, ctx):
		try:
			mount.eject_finish(async_result)
		except gio.Error:
			ctx.register_late_error()

	def unmount_callback(self, mount, async_result, ctx):
		try:
			mount.unmount_finish(async_result)
		except gio.Error:
			ctx.register_late_error()

	def wants_context(self):
		return True

	def activate(self, leaf, ctx):
		if not leaf.is_valid():
			return
		vol = leaf.volume
		if vol.can_eject():
			vol.eject(self.eject_callback, user_data=ctx)
		elif vol.can_unmount():
			vol.unmount(self.unmount_callback, user_data=ctx)

	def get_description(self):
		return _("Unmount this volume")

	def get_icon_name(self):
		return "media-eject"

class Eject (Unmount):
	def __init__(self):
		super(Eject, self).__init__(_("Eject"))

	def get_description(self):
		return _("Unmount and eject this media")

class VolumesSource (Source):
	def __init__(self, name=_("Volumes and Disks")):
		super(VolumesSource, self).__init__(name)
	def is_dynamic(self):
		return True
	def get_items(self):
		vm = gio.volume_monitor_get()
		# get_mounts gets all mounted removable media
		return (Volume(v) for v in vm.get_mounts())

	def get_description(self):
		return _("Mounted volumes and disks")
	def get_icon_name(self):
		return "drive-removable-media"
	def provides(self):
		yield Volume

########NEW FILE########
__FILENAME__ = websearch
__kupfer_name__ = _("Search the Web")
__kupfer_sources__ = ("OpenSearchSource", )
__kupfer_text_sources__ = ()
__kupfer_actions__ = (
		"SearchFor",
		"SearchWithEngine",
	)
__description__ = _("Search the web with OpenSearch search engines")
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import locale
import os
import urllib
import xml.etree.cElementTree as ElementTree

from kupfer.objects import Action, Source, Leaf
from kupfer.objects import TextLeaf
from kupfer import utils, config

from kupfer.plugin import firefox_support


def _noescape_urlencode(items):
	"""Assemble an url param string from @items, without
	using any url encoding.
	"""
	return "?" + "&".join("%s=%s" % (n,v) for n,v in items)

def _urlencode(word):
	"""Urlencode a single string of bytes @word"""
	return urllib.urlencode({"q": word})[2:]

def _do_search_engine(terms, search_url, encoding="UTF-8"):
	"""Show an url searching for @search_url with @terms"""
	search_url = search_url.encode(encoding, "ignore")
	terms_enc = terms.encode(encoding, "ignore")
	query_url = search_url.replace("{searchTerms}", _urlencode(terms_enc))
	utils.show_url(query_url)

class SearchWithEngine (Action):
	"""TextLeaf -> SearchWithEngine -> SearchEngine"""
	def __init__(self):
		Action.__init__(self, _("Search With..."))

	def activate(self, leaf, iobj):
		coding = iobj.object.get("InputEncoding")
		url = iobj.object["Url"]
		_do_search_engine(leaf.object, url, encoding=coding)

	def item_types(self):
		yield TextLeaf

	def requires_object(self):
		return True
	def object_types(self):
		yield SearchEngine

	def object_source(self, for_item=None):
		return OpenSearchSource()

	def get_description(self):
		return _("Search the web with OpenSearch search engines")
	def get_icon_name(self):
		return "edit-find"

class SearchFor (Action):
	"""SearchEngine -> SearchFor -> TextLeaf

	This is the opposite action to SearchWithEngine
	"""
	def __init__(self):
		Action.__init__(self, _("Search For..."))

	def activate(self, leaf, iobj):
		coding = leaf.object.get("InputEncoding")
		url = leaf.object["Url"]
		terms = iobj.object
		_do_search_engine(terms, url, encoding=coding)

	def item_types(self):
		yield SearchEngine

	def requires_object(self):
		return True
	def object_types(self):
		yield TextLeaf

	def get_description(self):
		return _("Search the web with OpenSearch search engines")
	def get_icon_name(self):
		return "edit-find"

class SearchEngine (Leaf):
	def get_description(self):
		desc = self.object.get("Description")
		return desc if desc != unicode(self) else None
	def get_icon_name(self):
		return "text-html"

def coroutine(func):
	"""Coroutine decorator: Start the coroutine"""
	def startcr(*ar, **kw):
		cr = func(*ar, **kw)
		cr.next()
		return cr
	return startcr

class OpenSearchParseError (StandardError):
	pass

class OpenSearchSource (Source):
	def __init__(self):
		Source.__init__(self, _("Search Engines"))

	@coroutine
	def _parse_opensearch(self, target):
		"""This is a coroutine to parse OpenSearch files"""
		vital_keys = set(["Url", "ShortName"])
		keys =  set(["Description", "Url", "ShortName", "InputEncoding"])
		#mozns = '{http://www.mozilla.org/2006/browser/search/}'
		#osns = '{http://a9.com/-/spec/opensearch/1.1/}'
		roots = ('OpenSearchDescription', 'SearchPlugin')
		gettagname = lambda tag: tag.rsplit("}", 1)[-1]

		def parse_etree(etree, name=None):
			if not gettagname(etree.getroot().tag) in roots:
				raise OpenSearchParseError("Search %s has wrong type" % name)
			search = {}
			for child in etree.getroot():
				tagname = gettagname(child.tag)
				if tagname not in keys:
					continue
				# Only pick up Url tags with type="text/html"
				if tagname == "Url":
					if (child.get("type") == "text/html" and
						child.get("template")):
						text = child.get("template")
						params = {}
						for ch in child.getchildren():
							if gettagname(ch.tag) == "Param":
								params[ch.get("name")] = ch.get("value")
						if params:
							text += _noescape_urlencode(params.items())
					else:
						continue
				else:
					text = (child.text or "").strip()
				search[tagname] = text
			if not vital_keys.issubset(search.keys()):
				raise OpenSearchParseError("Search %s missing keys" % name)
			return search

		while True:
			try:
				path = (yield)
				etree = ElementTree.parse(path)
				target.send(parse_etree(etree, name=path))
			except StandardError, exc:
				self.output_debug("%s: %s" % (type(exc).__name__, exc))

	def get_items(self):
		plugin_dirs = []

		# accept in kupfer data dirs
		plugin_dirs.extend(config.get_data_dirs("searchplugins"))

		# firefox in home directory
		ffx_home = firefox_support.get_firefox_home_file("searchplugins")
		if ffx_home and os.path.isdir(ffx_home):
			plugin_dirs.append(ffx_home)

		plugin_dirs.extend(config.get_data_dirs("searchplugins",
			package="firefox"))
		plugin_dirs.extend(config.get_data_dirs("searchplugins",
			package="iceweasel"))

		addon_dir = "/usr/lib/firefox-addons/searchplugins"
		cur_lang, _ignored = locale.getlocale(locale.LC_MESSAGES)
		suffixes = ["en-US"]
		if cur_lang:
			suffixes = [cur_lang.replace("_", "-"), cur_lang[:2]] + suffixes
		for suffix in suffixes:
			addon_lang_dir = os.path.join(addon_dir, suffix)
			if os.path.exists(addon_lang_dir):
				plugin_dirs.append(addon_lang_dir)
				break

		# debian iceweasel
		if os.path.isdir("/etc/iceweasel/searchplugins/common"):
			plugin_dirs.append("/etc/iceweasel/searchplugins/common")
		for suffix in suffixes:
			addon_dir = os.path.join("/etc/iceweasel/searchplugins/locale",
					suffix)
			if os.path.isdir(addon_dir):
				plugin_dirs.append(addon_dir)

		# try to find all versions of firefox
		for dirname in os.listdir("/usr/lib/"):
			if dirname.startswith("firefox") or dirname.startswith("iceweasel"):
				addon_dir = os.path.join("/usr/lib", dirname, "searchplugins")
				if os.path.isdir(addon_dir):
					plugin_dirs.append(addon_dir)

		self.output_debug("Found following searchplugins directories",
				sep="\n", *plugin_dirs)

		@coroutine
		def collect(seq):
			"""Collect items in list @seq"""
			while True:
				seq.append((yield))

		searches = []
		collector = collect(searches)
		parser = self._parse_opensearch(collector)
		# files are unique by filename to allow override
		visited_files = set()
		for pdir in plugin_dirs:
			try:
				for f in os.listdir(pdir):
					if f in visited_files:
						continue
					parser.send(os.path.join(pdir, f))
					visited_files.add(f)
			except EnvironmentError, exc:
				self.output_error(exc)

		for s in searches:
			yield SearchEngine(s, s["ShortName"])

	def should_sort_lexically(self):
		return True

	def provides(self):
		yield SearchEngine

	def get_icon_name(self):
		return "applications-internet"

########NEW FILE########
__FILENAME__ = wikipedia
"""
This is a simple plugin demonstration, how to add single, simple actions
"""

__kupfer_name__ = _("Wikipedia")
__kupfer_sources__ = ()
__kupfer_actions__ = ("WikipediaSearch", )
__description__ = _("Search in Wikipedia")
__version__ = ""
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import urllib

from kupfer.objects import Action, TextLeaf
from kupfer import utils, plugin_support


__kupfer_settings__ = plugin_support.PluginSettings(
	{
		"key": "lang",
		"label": _("Wikipedia language"),
		"type": str,
		# TRANS: Default wikipedia language code
		"value": _("en"),
	},
)


class WikipediaSearch (Action):
	def __init__(self):
		Action.__init__(self, _("Search in Wikipedia"))

	def activate(self, leaf):
		# Send in UTF-8 encoding
		lang_code = __kupfer_settings__["lang"]
		search_url="http://%s.wikipedia.org/w/index.php?title=Special:Search&go=Go" % lang_code
		# will encode search=text, where `text` is escaped
		query_url = search_url + "&" + urllib.urlencode({"search": leaf.object})
		utils.show_url(query_url)
	def item_types(self):
		yield TextLeaf
	def get_description(self):
		lang_code = __kupfer_settings__["lang"]
		return _("Search for this term in %s.wikipedia.org") % lang_code
	def get_icon_name(self):
		return "edit-find"


########NEW FILE########
__FILENAME__ = windows
__kupfer_name__ = _("Window List")
__kupfer_sources__ = ("WindowsSource", "WorkspacesSource", )
__description__ = _("All windows on all workspaces")
__version__ = "2010-01-08"
__author__ = "Ulrik Sverdrup <ulrik.sverdrup@gmail.com>"

import wnck

from kupfer.objects import Leaf, Action, Source
from kupfer.weaklib import gobject_connect_weakly
from kupfer.obj.helplib import PicklingHelperMixin


class WindowLeaf (Leaf):
	def get_actions(self):
		yield WindowActivateWorkspace()
		yield WindowMoveToWorkspace()
		yield WindowAction(_("Activate"), "activate", time=True)

		W = self.object
		T = type(W)
		yield ToggleAction(_("Shade"), _("Unshade"),
				"shade", "unshade",
				W.is_shaded(), T.is_shaded)
		yield ToggleAction(_("Minimize"), _("Unminimize"),
				"minimize", "unminimize",
				W.is_minimized(), T.is_minimized,
				time=True, icon="list-remove")
		yield ToggleAction(_("Maximize"), _("Unmaximize"),
				"maximize", "unmaximize",
				W.is_maximized(), T.is_maximized,
				icon="list-add")
		yield ToggleAction(_("Maximize Vertically"), _("Unmaximize Vertically"),
				"maximize_vertically", "unmaximize_vertically",
				W.is_maximized_vertically(), T.is_maximized_vertically,
				icon="list-add")
		yield WindowAction(_("Close"), "close", time=True, icon="window-close")

	def is_valid(self):
		return self.object and self.object.get_xid()

	def get_description(self):
		workspace = self.object.get_workspace()
		if not workspace:
			return u""
		nr, name = workspace.get_number(), workspace.get_name()
		# TRANS: Window on (Workspace name), window description
		return _("Window on %(wkspc)s") % {"wkspc": name}

	def get_icon_name(self):
		return "gnome-window-manager"

class FrontmostWindow (WindowLeaf):
	qf_id = "frontwindow"
	def __init__(self):
		WindowLeaf.__init__(self, None, _("Frontmost Window"))

	# HACK: Make self.object a property
	# so that this leaf is *not* immutable
	def _set_object(self, obj):
		pass
	def _get_object(self):
		scr = wnck.screen_get_default()
		active = scr.get_active_window() or scr.get_previously_active_window()
		# FIXME: Ignore Kupfer's main window reliably
		if active and active.get_application().get_name() != "kupfer.py":
			if not active.is_skip_tasklist():
				return active
		wspc = scr.get_active_workspace()
		for win in reversed(scr.get_windows_stacked()):
			if not win.is_skip_tasklist():
				if win.is_on_workspace(wspc):
					return win
	object = property(_get_object, _set_object)

	def repr_key(self):
		return ""

	def get_description(self):
		return self.object and self.object.get_name()

class NextWindow (WindowLeaf):
	qf_id = "nextwindow"
	def __init__(self):
		WindowLeaf.__init__(self, None, _("Next Window"))

	def _set_object(self, obj):
		pass
	def _get_object(self):
		scr = wnck.screen_get_default()
		wspc = scr.get_active_workspace()
		for win in scr.get_windows_stacked():
			if not win.is_skip_tasklist():
				if win.is_on_workspace(wspc):
					return win
	object = property(_get_object, _set_object)

	def repr_key(self):
		return ""

	def get_description(self):
		return self.object and self.object.get_name()

class WindowActivateWorkspace (Action):
	def __init__(self, name=_("Go To")):
		super(WindowActivateWorkspace, self).__init__(name)
	def wants_context(self):
		return True
	def activate (self, leaf, ctx):
		window = leaf.object
		workspace = window.get_workspace()
		time = ctx.environment.get_timestamp()
		workspace.activate(time)
		window.activate(time)
	def get_description(self):
		return _("Jump to this window's workspace and focus")
	def get_icon_name(self):
		return "go-jump"

class WindowMoveToWorkspace (Action):
	def __init__(self):
		Action.__init__(self, _("Move To..."))

	def wants_context(self):
		return True

	def activate(self, leaf, iobj, ctx):
		window = leaf.object
		workspace = iobj.object
		window.move_to_workspace(workspace)
		time = ctx.environment.get_timestamp()
		workspace.activate(time)
		window.activate(time)

	def requires_object(self):
		return True
	def object_types(self):
		yield Workspace
	def object_source(self, for_item=None):
		return WorkspacesSource()

	def valid_object(self, iobj, for_item):
		window = for_item.object
		return not window.is_on_workspace(iobj.object)

	def get_icon_name(self):
		return "forward"

class WindowAction (Action):
	def __init__(self, name, action, time=False, icon=None):
		super(Action, self).__init__(name)
		if not action: action = name.lower()
		self.action = action
		self.time = time
		self.icon_name = icon

	def repr_key(self):
		return self.action

	def wants_context(self):
		return True

	def activate(self, leaf, ctx):
		time = self._get_time(ctx) if self.time else None
		self._perform_action(self.action, leaf, time)

	@classmethod
	def _perform_action(cls, action_attr, leaf, time=None):
		window = leaf.object
		action_method = getattr(window, action_attr)
		if time is not None:
			action_method(time)
		else:
			action_method()

	@classmethod
	def _get_time(cls, ctx):
		# @time will be != 0 if we are "inside"
		# a current gtk event
		return ctx.environment.get_timestamp()

	def get_icon_name(self):
		if not self.icon_name:
			return super(WindowAction, self).get_icon_name()
		return self.icon_name

class ToggleAction (WindowAction):
	"""A toggle action, performing the enable / disable action as needed,
	for example minimize/unminimize.

	@istate: Initial state
	@predicate: Callable for state taking the window object as only argument
	"""
	def __init__(self, ename, uname, eaction, uaction, istate, predicate,
			time=False, icon=None):
		name = uname if istate else ename
		WindowAction.__init__(self, name, eaction, time=time, icon=icon)
		self.predicate = predicate
		self.uaction = uaction

	def activate(self, leaf, ctx):
		if self.predicate(leaf.object):
			# only use time on the disable action
			time = self._get_time(ctx) if self.time else None
			self._perform_action(self.uaction, leaf, time)
		else:
			self._perform_action(self.action, leaf)

class WindowsSource (Source):
	def __init__(self, name=_("Window List")):
		super(WindowsSource, self).__init__(name)
		# "preload" windows: Ask for them early
		# since the first call "primes" the event loop
		# and always comes back empty
		screen = wnck.screen_get_default()
		screen.get_windows_stacked()

	def is_dynamic(self):
		return True
	def get_items(self):
		# wnck should be "primed" now to return the true list
		screen = wnck.screen_get_default()
		yield FrontmostWindow()
		yield NextWindow()
		for win in reversed(screen.get_windows_stacked()):
			if not win.is_skip_tasklist():
				name, app = (win.get_name(), win.get_application().get_name())
				if name != app and app not in name:
					name = "%s (%s)" % (name, app)
				yield WindowLeaf(win, name)

	def get_description(self):
		return _("All windows on all workspaces")
	def get_icon_name(self):
		return "gnome-window-manager"
	def provides(self):
		yield WindowLeaf

class Workspace (Leaf):
	def get_actions(self):
		yield ActivateWorkspace()
	def repr_key(self):
		return self.object.get_number()
	def get_icon_name(self):
		return "gnome-window-manager"
	def get_description(self):
		screen = wnck.screen_get_default()
		if screen:
			n_windows = sum([1 for w in screen.get_windows()
			                if w.get_workspace() == self.object])

			w_msg = (ngettext("%d window", "%d windows", n_windows) % n_windows)

			active_wspc = screen.get_active_workspace()
			if active_wspc == self.object:
				return _("Active workspace") + " (%s)" % w_msg
			if n_windows:
				return u"(%s)" % w_msg
		return None

class ActivateWorkspace (Action):
	rank_adjust = 5
	def __init__(self):
		Action.__init__(self, _("Go To"))

	def wants_context(self):
		return True
	def activate (self, leaf, ctx):
		workspace = leaf.object
		time = ctx.environment.get_timestamp()
		workspace.activate(time)

	def get_description(self):
		return _("Jump to this workspace")
	def get_icon_name(self):
		return "go-jump"


class WorkspacesSource (Source, PicklingHelperMixin):
	def __init__(self):
		Source.__init__(self, _("Workspaces"))
		screen = wnck.screen_get_default()
		screen.get_workspaces()

	def pickle_prepare(self):
		self.mark_for_update()

	def initialize(self):
		screen = wnck.screen_get_default()
		gobject_connect_weakly(screen, "workspace-created", self._changed)
		gobject_connect_weakly(screen, "workspace-destroyed", self._changed)

	def _changed(self, screen, workspace):
		self.mark_for_update()

	def get_items(self):
		# wnck should be "primed" now to return the true list
		screen = wnck.screen_get_default()
		for wspc in screen.get_workspaces():
			yield Workspace(wspc, wspc.get_name())

	def get_icon_name(self):
		return "gnome-window-manager"
	def provides(self):
		yield Workspace


########NEW FILE########
__FILENAME__ = zim
# -*- coding: UTF-8 -*-
from __future__ import with_statement

__kupfer_name__ = _("Zim")
__kupfer_sources__ = ("ZimPagesSource", )
__kupfer_actions__ = (
		"CreateZimPage",
		"CreateZimPageInNotebook",
		"CreateZimQuickNote",
	)
__description__ = _("Access to Pages stored in Zim - "
                    "A Desktop Wiki and Outliner")
__version__ = "2011-12-03"
__author__ = "Karol BÄ™dkowski <karol.bedkowski@gmail.com>"

import os
import time

import gio
import glib

from kupfer.objects import Leaf, Action, Source, TextLeaf, TextSource
from kupfer.obj.apps import AppLeafContentMixin
from kupfer import config, utils, pretty, icons, plugin_support


__kupfer_settings__ = plugin_support.PluginSettings(
	{
		"key": "page_name_starts_colon",
		"label": _("Page names start with :colon"),
		"type": bool,
		"value": False,
	},
	{
		"key": "quicknote_basename",
		"label": _("Default page name for quick notes"),
		"type": str,
		"value": _("Note %x %X"),
		"tooltip": _("Strftime tags can be used: %H - hour, %M - minutes, etc\n"
				"Please check python documentation for details.\n"
				"NOTE: comma will be replaced by _"),
	},
	{
		"key": "quicknote_namespace",
		"label": _("Default namespace for quick notes"),
		"type": str,
		"value": "",
	},
)

'''
Changes:
	2011-12-02 Karol BÄ™dkowski
		fix loading notebook list from zim 0.53
	2011-12-03 Karol BÄ™dkowski
		add CreateZimQuickNote action
TODO:
	use FilesystemWatchMixin (?)
'''


def _start_zim(notebook, page):
	''' Start zim and open given notebook and page. '''
	utils.spawn_async(("zim", notebook, page.replace("'", "_")))


class ZimPage(Leaf):
	""" Represent single Zim page """
	def __init__(self, page_id, page_name, notebook_path, notebook_name):
		Leaf.__init__(self, page_id, page_name)
		self.page = page_name
		self.notebook = notebook_path
		self.notebook_name = notebook_name

	def get_actions(self):
		yield OpenZimPage()
		yield CreateZimSubPage()

	def get_description(self):
		return _('Zim Page from Notebook "%s"') % self.notebook_name

	def get_icon_name(self):
		return "text-x-generic"


class CreateZimPage(Action):
	""" Create new page in default notebook """
	def __init__(self):
		Action.__init__(self, _('Create Zim Page'))

	def activate(self, leaf):
		notebook = _get_default_notebook()
		_start_zim(notebook, ":" + leaf.object.strip(':'))

	def get_description(self):
		return _("Create page in default notebook")

	def get_icon_name(self):
		return 'document-new'

	def item_types(self):
		yield TextLeaf


class CreateZimPageInNotebook(Action):
	""" Create new page in default notebook """
	def __init__(self):
		Action.__init__(self, _('Create Zim Page In...'))

	def activate(self, leaf, iobj):
		_start_zim(iobj.object, ":" + leaf.object.strip(':'))

	def get_icon_name(self):
		return 'document-new'

	def item_types(self):
		yield TextLeaf

	def requires_object(self):
		return True

	def object_types(self):
		yield ZimNotebook

	def object_source(self, for_item=None):
		return ZimNotebooksSource()


class CreateZimQuickNote(Action):
	""" Create new page using quicknote plugin """
	def __init__(self):
		Action.__init__(self, _('Insert QuickNote into Zim'))

	def activate(self, leaf):
		self._create_note(leaf.object)

	def activate_multiple(self, objects):
		text = '\n'.join(str(leaf.object) for leaf in objects)
		self._create_note(text)

	def get_description(self):
		return _("Quick note selected text into Zim notebook")

	def get_icon_name(self):
		return 'document-new'

	def item_types(self):
		yield TextLeaf

	def _create_note(self, text):
		argv = ['zim', '--plugin', 'quicknote', 'input=stdin']
		basename = __kupfer_settings__['quicknote_basename']
		if basename:
			try:
				basename = time.strftime(basename, time.localtime())
				basename = basename.replace(':', '_')
			except:
				pass
			argv.append("basename=" + basename)
		namespace = __kupfer_settings__['quicknote_namespace']
		if namespace:
			argv.append("namespace=" + namespace)

		def finish_callback(acommand, stdout, stderr):
			pretty.print_debug(__name__, "CreateZimQuickNote.finish_callback", acommand,
					stdout, stderr)

		utils.AsyncCommand(argv, finish_callback, None, stdin=text)


class OpenZimPage(Action):
	""" Open Zim page  """
	rank_adjust = 10

	def __init__(self):
		Action.__init__(self, _('Open'))

	def activate(self, leaf):
		_start_zim(leaf.notebook, leaf.page)

	def get_icon_name(self):
		return 'document-open'

	def item_types(self):
		yield ZimPage


class CreateZimSubPage(Action):
	""" Open Zim page  """
	def __init__(self):
		Action.__init__(self, _('Create Subpage...'))

	def activate(self, leaf, iobj):
		_start_zim(leaf.notebook, leaf.page + ":" + iobj.object.strip(':'))

	def get_icon_name(self):
		return 'document-new'

	def item_types(self):
		yield ZimPage

	def requires_object(self):
		return True

	def object_types(self):
		yield TextLeaf

	def object_source(self, for_item=None):
		return TextSource()


def _read_zim_notebooks_old(zim_notebooks_file):
	''' Yield (notebook name, notebook path) from zim config

	@notebook_name: Unicode name
	@notebook_path: Filesystem byte string
	'''
	# We assume the notebook description is UTF-8 encoded
	with open(zim_notebooks_file, 'r') as notebooks_file:
		for line in notebooks_file.readlines():
			if not line.startswith('_default_'):
				notebook_name, notebook_path = line.strip().split('\t', 2)
				notebook_name = notebook_name.decode("UTF-8", "replace")
				notebook_path = os.path.expanduser(notebook_path)
				yield (notebook_name, notebook_path)


def _get_default_notebook():
	''' Find default notebook '''
	zim_notebooks_file = config.get_config_file("notebooks.list", package="zim")
	if not zim_notebooks_file:
		pretty.print_error(__name__, "Zim notebooks.list not found")
		return None
	lines = None
	with open(zim_notebooks_file, 'r') as notebooks_file:
		lines = notebooks_file.readlines()
	if not lines:
		return ''
	if lines[0].strip() == '[NotebookList]':
		# new version
		# first section looks like:
		# [NotebookList]
		# Default=~/doc/zim
		# ~/doc/zim
		# ~/tmp/test
		for line in lines[1:]:
			if line.startswith('Default='):
				_dummy, name = line.split('=', 1)
				name = name.strip()
				if name:
					pretty.print_debug(__name__, '_get_default_notebook:', name)
					return name
			return line
		return ''
	# old version
	# format '<notebook name | _default_>\t<path>'
	name = ''
	for line in lines:
		if '\t' in line:
			notebook_name, notebook_path = line.strip().split('\t', 1)
			if notebook_name == '_default_':
				# _default_ is pointing at name of the default notebook
				name = notebook_path.decode("UTF-8", "replace")
			else:
				# assume first notebook as default
				name = notebook_name.decode("UTF-8", "replace")
			break
	pretty.print_debug(__name__, '_get_default_notebook (old):', name)
	return name


def _read_zim_notebook_name(notebook_path):
	npath = os.path.join(notebook_path, "notebook.zim")
	with open(npath, "r") as notebook_file:
		for line in notebook_file:
			if line.startswith("name="):
				_ignored, b_name = line.strip().split("=", 1)
				us_name = b_name.decode("unicode_escape")
				return us_name
	return os.path.basename(notebook_path)


def _read_zim_notebooks_new(zim_notebooks_file):
	''' Yield (notebook name, notebook path) from zim config

	NOTE: we can't use ConfigParser - zim config file is not parsable

	Sample file:
		[NotebookList]
		Default=~/doc/zim
		~/doc/zim
		~/tmp/test

		[Notebook]
		uri=~/doc/zim
		name=doc
		interwiki=None
		icon=

		[Notebook]
		....

	@notebook_name: Unicode name
	@notebook_path: Filesystem byte string
	'''
	notebooks = []
	last_section = None
	with open(zim_notebooks_file, 'r') as notebooks_file:
		for line in notebooks_file:
			line = line.strip()
			if line.startswith("["):
				if line == '[Notebook]':
					notebooks.append(dict())
				last_section = line
				continue
			if not line:
				last_section = None
				continue
			if last_section == '[Notebook]':
				if '=' in line:
					key, val = line.split('=', 1)
					notebooks[-1][key] = val
	for notebook in notebooks:
		uri = notebook.get('uri')
		if not uri:
			continue
		notebook_path = gio.File(os.path.expanduser(uri)).get_path()
		notebook_name = notebook.get('name')
		if not notebook_name:
			# old version: name don't present in config
			try:
				notebook_name = _read_zim_notebook_name(notebook_path)
			except IOError:
				pass
		if not notebook_name:
			notebook_name = notebook_path.split('/')[-1]
		yield (notebook_name, notebook_path)


def _get_zim_notebooks():
	''' Yield (notebook name, notebook path) from zim config

	@notebook_name: Unicode name
	@notebook_path: Filesystem byte string
	'''
	# We assume the notebook description is UTF-8 encoded
	zim_notebooks_file = config.get_config_file("notebooks.list", package="zim")
	if not zim_notebooks_file:
		pretty.print_error(__name__, "Zim notebooks.list not found")
		return []
	try:
		config_first_line = None
		with open(zim_notebooks_file, 'r') as notebooks_file:
			config_first_line = notebooks_file.readline().strip()
		if config_first_line == "[NotebookList]":
			return _read_zim_notebooks_new(zim_notebooks_file)
		else:
			return _read_zim_notebooks_old(zim_notebooks_file)
	except IOError, err:
		pretty.print_error(__name__, err)


class ZimNotebook (Leaf):
	def get_gicon(self):
		return icons.get_gicon_for_file(self.object)


class ZimNotebooksSource (Source):
	def __init__(self):
		Source.__init__(self, _("Zim Notebooks"))

	def get_items(self):
		for name, path in _get_zim_notebooks():
			yield ZimNotebook(path, name)

	def get_icon_name(self):
		return "zim"

	def provides(self):
		yield ZimNotebook


class ZimPagesSource(AppLeafContentMixin, Source):
	''' Index pages in all Zim notebooks '''
	appleaf_content_id = "zim"

	def __init__(self, name=_("Zim Pages")):
		Source.__init__(self, name)
		# path to file with list notebooks
		self._version = 2

	def get_items(self):
		strip_name_first_colon = not __kupfer_settings__["page_name_starts_colon"]
		for notebook_name, notebook_path in _get_zim_notebooks():
			for root, dirs, files in os.walk(notebook_path):
				# find pages in notebook
				for filename in files:
					file_path = os.path.join(root, filename)
					page_name, ext = os.path.splitext(file_path)
					if not ext.lower() == ".txt":
						continue
					page_name = page_name.replace(notebook_path, "", 1)
					# Ask GLib for the correct unicode representation
					# of the page's filename
					page_name = glib.filename_display_name(page_name)
					if strip_name_first_colon:
						page_name = page_name.lstrip(os.path.sep)
					page_name = (page_name
							.replace(os.path.sep, u":")
							.replace(u"_", u" "))
					yield ZimPage(file_path, page_name, notebook_path,
							notebook_name)

	def get_description(self):
		return _("Pages stored in Zim Notebooks")

	def get_icon_name(self):
		return "zim"

	def provides(self):
		yield ZimPage

########NEW FILE########
__FILENAME__ = plugin_support
import sys

import gobject

keyring = None

from kupfer import pretty
from kupfer import config
from kupfer.core import settings
from kupfer.core import plugins
from kupfer import utils

__all__ = [
	"UserNamePassword",
	"PluginSettings",
	"check_dbus_connection",
	"check_keyring_support",
]

def _is_core_setting(key):
	return key.startswith("kupfer_")

class PluginSettings (gobject.GObject, pretty.OutputMixin):
	"""Allows plugins to have preferences by assigning an instance
	of this class to the plugin's __kupfer_settings__ attribute.

	Setting values are accessed by the getitem operator [] with
	the setting's 'key' attribute

	Signals:

		plugin-setting-changed: key, value

	"""
	__gtype_name__ = "PluginSettings"

	def __init__(self, *setdescs):
		"""Create a settings collection by passing in dictionaries
		as arguments, where each dictionary must have the following keys:
			key
			type
			value (default value)
			label (localized label)

		the @key may be any string except strings starting with
		'kupfer_', which are reserved
		"""
		gobject.GObject.__init__(self)
		self.setting_descriptions = {}
		self.setting_key_order = []
		self.signal_connection = -1
		req_keys = set(("key", "value", "type", "label"))
		for desc in setdescs:
			if not req_keys.issubset(desc.keys()):
				missing = req_keys.difference(desc.keys())
				raise KeyError("Plugin setting missing keys: %s" % missing)
			self.setting_descriptions[desc["key"]] = dict(desc)
			self.setting_key_order.append(desc["key"])

	def __iter__(self):
		return iter(self.setting_key_order)

	def initialize(self, plugin_name):
		"""Init by reading from global settings and setting up callbacks"""
		setctl = settings.GetSettingsController()
		for key in self:
			value_type = self.setting_descriptions[key]["type"]
			value = setctl.get_plugin_config(plugin_name, key, value_type)
			if value is not None:
				self[key] = value
			elif _is_core_setting(key):
				default = self.setting_descriptions[key]["value"]
				setctl.set_plugin_config(plugin_name, key, default, value_type)
		setctl.connect("value-changed", self._value_changed, plugin_name)
		# register for unload notification
		if not plugin_name.startswith("core."):
			plugins.register_plugin_unimport_hook(plugin_name,
					self._disconnect_all, plugin_name)

	def __getitem__(self, key):
		return self.setting_descriptions[key]["value"]
	def __setitem__(self, key, value):
		value_type = self.setting_descriptions[key]["type"]
		self.setting_descriptions[key]["value"] = value_type(value)
		if not _is_core_setting(key):
			self.emit("plugin-setting-changed::"+str(key), key, value)

	def _value_changed(self, setctl, section, key, value, plugin_name):
		"""Preferences changed, update object"""
		if key in self and plugin_name in section:
			self[key] = value

	def get_value_type(self, key):
		"""Return type of setting @key"""
		return self.setting_descriptions[key]["type"]
	def get_label(self, key):
		"""Return label for setting @key"""
		return self.setting_descriptions[key]["label"]
	def get_alternatives(self, key):
		"""Return alternatives for setting @key (if any)"""
		return self.setting_descriptions[key].get("alternatives")
	def get_tooltip(self, key):
		"""Return tooltip string for setting @key (if any)"""
		return self.setting_descriptions[key].get("tooltip")

	def connect_settings_changed_cb(self, callback, *args):
		self.signal_connection = \
				self.connect("plugin-setting-changed", callback, *args)

	def _disconnect_all(self, plugin_name):
		if self.signal_connection != -1:
			self.disconnect(self.signal_connection)


# Arguments: Key, Value
# Detailed by the key
gobject.signal_new("plugin-setting-changed", PluginSettings,
		gobject.SIGNAL_RUN_LAST | gobject.SIGNAL_DETAILED,
		gobject.TYPE_BOOLEAN,
		(gobject.TYPE_STRING, gobject.TYPE_PYOBJECT))

# Plugin convenience functions for dependencies

_has_dbus_connection = None

def check_dbus_connection():
	"""
	Check if a connection to the D-Bus daemon is available,
	else raise ImportError with an explanatory error message.

	For plugins that can not be used without contact with D-Bus;
	if this check is used, the plugin may use D-Bus and assume it
	is available in the Plugin's code.
	"""
	global _has_dbus_connection
	if _has_dbus_connection is None:
		import dbus
		try:
			dbus.Bus()
			_has_dbus_connection = True
		except dbus.DBusException:
			_has_dbus_connection = False
	if not _has_dbus_connection:
		raise ImportError(_("No D-Bus connection to desktop session"))

class UserNamePassword (settings.ExtendedSetting):
	''' Configuration type for storing username/password values.
	Username is stored in Kupfer config, password in keyring '''
	def __init__(self, obj=None):
		settings.ExtendedSetting.__init__(self)
		self.username = None
		self.password = None
		if obj:
			self.username = obj.username
			self.password = obj.password

	def __repr__(self):
		return '<UserNamePassword "%s", %s>' % (self.username,
		                                        bool(self.password))

	@classmethod
	def is_backend_encrypted(cls):
		import keyring.core
		return keyring.core.get_keyring().supported() == 1

	@classmethod
	def get_backend_name(cls):
		import keyring.core
		import keyring.backend
		keyring_map = {
				keyring.backend.GnomeKeyring : _("GNOME Keyring"),
				keyring.backend.KDEKWallet : _("KWallet"),
				keyring.backend.UncryptedFileKeyring: _("Unencrypted File"),
			}
		kr = keyring.get_keyring()
		keyring_name = keyring_map.get(type(kr), type(kr).__name__)
		return keyring_name

	def load(self, plugin_id, key, username):
		self.password = keyring.get_password(plugin_id, username)
		self.username = username

	def save(self, plugin_id, key):
		''' save @user_password - store password in keyring and return username
		to save in standard configuration file '''
		keyring.set_password(plugin_id, str(self.username), self.password)
		return self.username

def check_keyring_support():
	"""
	Check if the UserNamePassword class can be used,
	else raise ImportError with an explanatory error message.
	"""
	global keyring
	# if gnomekeyring exists, block kde libraries
	old_pykde4 = sys.modules.get('PyKDE4')
	try:
		import gnomekeyring
	except ImportError:
		pass
	else:
		sys.modules['PyKDE4'] = None
	try:
		import keyring
	except ImportError:
		global UserNamePassword
		class UserNamePassword (object):
			pass
		raise
	else:
		# Configure the fallback keyring's configuration file if used
		import keyring.backend
		kr = keyring.get_keyring()
		if hasattr(kr, "crypted_password"):
			keyring.set_keyring(keyring.backend.UncryptedFileKeyring())
			kr = keyring.get_keyring()
		if hasattr(kr, "file_path"):
			kr.file_path = config.save_config_file("keyring.cfg")
	finally:
		# now unblock kde libraries again
		if old_pykde4:
			sys.modules['PyKDE4'] = old_pykde4


def _plugin_configuration_error(plugin, err):
	pretty.print_error(__name__, err)


def _is_valid_terminal(term_dict):
	if len(term_dict["argv"]) < 1:
		return False
	exe = term_dict["argv"][0]
	return bool(utils.lookup_exec_path(exe))


_available_alternatives = {
	"terminal": {
		"filter": _is_valid_terminal,
		"required_keys": {
			'name': unicode,
			'argv': list,
			'exearg': str,
			'desktopid': str,
			'startup_notify': bool,
		},
	},
	"icon_renderer": {
		"filter": None,
		"required_keys": {
			'name': unicode,
			'renderer': object,
		},
	},
}

_alternatives = {
	"terminal": {},
	"icon_renderer": {},
}


def register_alternative(caller, category_key, id_, **kwargs):
	"""
	Register a new alternative for the category @category_key

	@caller: Must be the caller's plugin id (Plugin __name__ variable)

	@id_ is a string identifier for the object to register
	@kwargs are the keyed arguments for the alternative constructor

	Returns True with success
	"""
	caller = str(caller)
	category_key = str(category_key)
	id_ = str(id_)

	if category_key not in _available_alternatives:
		_plugin_configuration_error(caller,
				"Category '%s' does not exist" % category_key)
		return
	alt = _available_alternatives[category_key]
	id_ = caller + "." + id_
	kw_set = set(kwargs)
	req_set = set(alt["required_keys"])
	if not req_set.issubset(kw_set):
		_plugin_configuration_error(caller,
			"Configuration error for alternative '%s':" % category_key)
		_plugin_configuration_error(caller, "Missing keys: %s" %
				(req_set - kw_set))
		return
	_alternatives[category_key][id_] = kwargs
	pretty.print_debug(__name__,
		"Registered alternative %s: %s" % (category_key, id_))
	setctl = settings.GetSettingsController()
	setctl._update_alternatives(category_key, _alternatives[category_key],
	                            alt["filter"])

	# register the alternative to be unloaded
	plugin_id = ".".join(caller.split(".")[2:])
	if plugin_id and not plugin_id.startswith("core."):
		plugins.register_plugin_unimport_hook(plugin_id,
				_unregister_alternative, caller, category_key, id_)
	return True

def _unregister_alternative(caller, category_key, full_id_):
	"""
	Remove the alternative for category @category_key
	(this is done automatically at plugin unload)
	"""
	if category_key not in _available_alternatives:
		_plugin_configuration_error(caller,
				"Category '%s' does not exist" % category_key)
		return
	alt = _available_alternatives[category_key]
	id_ = full_id_
	try:
		del _alternatives[category_key][id_]
	except KeyError:
		_plugin_configuration_error(caller,
				"Alternative '%s' does not exist" % (id_, ))
		return
	pretty.print_debug(__name__,
		"Unregistered alternative %s: %s" % (category_key, id_))
	setctl = settings.GetSettingsController()
	setctl._update_alternatives(category_key, _alternatives[category_key],
	                            alt["filter"])
	return True



########NEW FILE########
__FILENAME__ = pretty
from __future__ import print_function

debug = False

import sys
import traceback

class OutputMixin (object):
	"""
	A mixin class providing prefixed output
	standard output and debug output
	"""
	def _output_category(self):
		return "[%s] %s:" % (type(self).__module__, type(self).__name__)

	def _output_core(self, prefix, sep, end, stream, *items):
		category = self._output_category()
		print(prefix+category, *items, sep=sep, end=end, file=stream)

	def output_info(self, *items, **kwargs):
		"""
		Output given items using @sep as separator,
		ending the line with @end
		"""
		sep = kwargs.get("sep", " ")
		end = kwargs.get("end", "\n")
		self._output_core("", sep, end, sys.stdout, *items)

	def output_exc(self, exc_info=None):
		"""Output current exception, or use @exc_info if given"""
		etype, value, tb = (exc_info or sys.exc_info())
		if debug:
			self._output_core("Exception in ", "", "\n", sys.stderr)
			traceback.print_exception(etype, value, tb, file=sys.stderr)
		else:
			msg = "%s: %s" % (etype.__name__, value)
			self._output_core("Exception in ", " ", "\n", sys.stderr, msg)

	def output_debug(self, *items, **kwargs):
		if debug:
			sep = kwargs.get("sep", " ")
			end = kwargs.get("end", "\n")
			self._output_core("D ", sep, end, sys.stderr, *items)

	def output_error(self, *items, **kwargs):
		sep = kwargs.get("sep", " ")
		end = kwargs.get("end", "\n")
		self._output_core("Error ", sep, end, sys.stderr, *items)

class _StaticOutput (OutputMixin):
	current_calling_module = None
	def _output_category(self):
		return "[%s]:" % (self.current_calling_module, )

	def print_info(self, modulename, *args, **kwargs):
		self.current_calling_module = modulename
		self.output_info(*args, **kwargs)

	def print_error(self, modulename, *args, **kwargs):
		self.current_calling_module = modulename
		self.output_error(*args, **kwargs)

	def print_exc(self, modulename, *args, **kwargs):
		self.current_calling_module = modulename
		self.output_exc(*args, **kwargs)

	def print_debug(self, modulename, *args, **kwargs):
		if debug:
			self.current_calling_module = modulename
			self.output_debug(*args, **kwargs)
_StaticOutput = _StaticOutput()

print_info = _StaticOutput.print_info
print_debug = _StaticOutput.print_debug
print_error = _StaticOutput.print_error
print_exc = _StaticOutput.print_exc

########NEW FILE########
__FILENAME__ = puid
"""
Persistent Globally Unique Indentifiers for KupferObjects.

Some objects are assigned identifiers by reference, some are assigned
identifiers containing the whole object data (SerializedObject).

SerializedObject is a saved representation of a KupferObject, i.e. a
data model user-level object.

We unpickle SerializedObjects in an especially conservative way: new
module loading is always refused; this way, we avoid loading parts of
the program that we didn't wish to activate.
"""

import contextlib
import pickle

from kupfer import pretty
from kupfer.core import actioncompat
from kupfer.core import qfurl
from kupfer.core.sources import GetSourceController
from kupfer.conspickle import ConservativeUnpickler

__all__ = [
	"SerializedObject", "SERIALIZABLE_ATTRIBUTE",
	"resolve_unique_id", "resolve_action_id", "get_unique_id", "is_reference",
]


SERIALIZABLE_ATTRIBUTE = "serializable"


class SerializedObject (object):
	# treat the serializable attribute as a version number, defined on the class
	def __init__(self, obj):
		self.version = getattr(obj, SERIALIZABLE_ATTRIBUTE)
		self.data = pickle.dumps(obj, pickle.HIGHEST_PROTOCOL)
	def __eq__(self, other):
		return (isinstance(other, type(self)) and self.data == other.data and
		        self.version == other.version)
	def reconstruct(self):
		obj = ConservativeUnpickler.loads(self.data)
		if self.version != getattr(obj, SERIALIZABLE_ATTRIBUTE):
			raise ValueError("Version mismatch for reconstructed %s" % obj)
		return obj

def get_unique_id(obj):
	if obj is None:
		return None
	if hasattr(obj, "qf_id"):
		return str(qfurl.qfurl(obj))
	if getattr(obj, SERIALIZABLE_ATTRIBUTE, None) is not None:
		try:
			return SerializedObject(obj)
		except pickle.PicklingError, exc:
			pretty.print_error(__name__, type(exc).__name__, exc)
			return None
	return repr(obj)

def is_reference(puid):
	"Return True if @puid is a reference-type ID"
	return not isinstance(puid, SerializedObject)

# A Context manager to block recursion when seeking inside a
# catalog; we have a stack (@_excluding) of the sources we
# are visiting, and nested context with the _exclusion
# context manager

_excluding = []
@contextlib.contextmanager
def _exclusion(src):
	try:
		_excluding.append(src)
		yield
	finally:
		_excluding.pop()

def _is_currently_excluding(src):
	return src is not None and src in _excluding

def _find_obj_in_catalog(puid, catalog):
	if puid.startswith(qfurl.QFURL_SCHEME):
		qfu = qfurl.qfurl(url=puid)
		return qfu.resolve_in_catalog(catalog)
	for src in catalog:
		if _is_currently_excluding(src):
			continue
		with _exclusion(src):
			for obj in src.get_leaves():
				if repr(obj) == puid:
					return obj
	return None

def resolve_unique_id(puid, excluding=None):
	"""
	Resolve unique id @puid

	The caller (if a Source) should pass itself as @excluding,
	so that recursion into itself is avoided.
	"""
	if excluding is not None:
		with _exclusion(excluding):
			return resolve_unique_id(puid, None)

	if puid is None:
		return None
	if isinstance(puid, SerializedObject):
		try:
			return puid.reconstruct()
		except Exception, exc:
			pretty.print_debug(__name__, type(exc).__name__, exc)
			return None
	sc = GetSourceController()
	obj = _find_obj_in_catalog(puid, sc._firstlevel)
	if obj is not None:
		return obj
	other_sources = set(sc.sources) - set(sc._firstlevel)
	obj = _find_obj_in_catalog(puid, other_sources)
	return obj

def resolve_action_id(puid, for_item=None):
	if puid is None:
		return None
	if isinstance(puid, SerializedObject):
		return resolve_unique_id(puid)
	get_action_id = repr
	sc = GetSourceController()
	if for_item is not None:
		for action in actioncompat.actions_for_item(for_item, sc):
			if get_unique_id(action) == puid:
				return action
	for item_type, actions in sc.action_decorators.iteritems():
		for action in actions:
			if get_action_id(action) == puid:
				return action
	pretty.print_debug(__name__, "Unable to resolve %s (%s)" % (puid, for_item))
	return None

########NEW FILE########
__FILENAME__ = runtimehelper
import gio

from kupfer.objects import FileLeaf

def register_async_file_result(ctx, filepath):
	"""
	Register that @filepath may appear soon
	@ctx: The action's execution context token
	"""
	return AsyncFileResult(ctx, filepath)

class AsyncFileResult (object):
	"""Expect a given file path to be created, and when (probably) done,
	post the file as a late result.
	"""
	def __init__(self, ctx, filepath):
		self.ctx = ctx
		gfile = gio.File(filepath)
		self.monitor = gfile.monitor_file(gio.FILE_MONITOR_NONE)
		self.callback_id = self.monitor.connect("changed", self.changed)

	def changed(self, monitor, gfile1, gfile2, event):
		if event == gio.FILE_MONITOR_EVENT_CHANGES_DONE_HINT:
			self.ctx.register_late_result(FileLeaf(gfile1.get_path()))
			self.monitor.disconnect(self.callback_id)
			self.monitor = None



########NEW FILE########
__FILENAME__ = scheduler

import gobject

from kupfer import pretty
from kupfer.weaklib import gobject_connect_weakly

_scheduler = None

def GetScheduler():
	"""Get the shared instance"""
	global _scheduler
	if not _scheduler:
		_scheduler = Scheduler()
	return _scheduler

class Scheduler (gobject.GObject, pretty.OutputMixin):
	__gtype_name__ = "Scheduler"
	def __init__(self):
		super(Scheduler, self).__init__()
	def load(self):
		self.output_debug("Loading")
		self.emit("load")
		self.emit("loaded")
		self.output_debug("Loaded")
	def display(self):
		self.output_debug("Display")
		self.emit("display")
		gobject.idle_add(self._after_display)
	def _after_display(self):
		self.output_debug("After Display")
		self.emit("after-display")
	def finish(self):
		self.emit("finish")
gobject.signal_new("load", Scheduler, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN, ())
gobject.signal_new("loaded", Scheduler, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN, ())
gobject.signal_new("display", Scheduler, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN, ())
gobject.signal_new("after-display", Scheduler, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN, ())
gobject.signal_new("finish", Scheduler, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN, ())

class Timer (object):
	def __init__(self, call_at_finish=False):
		self._current_timer = -1
		self._call_at_finish = call_at_finish
		self._current_callback = None
		gobject_connect_weakly(GetScheduler(), "finish", self._on_finish)

	def set(self, timeout_seconds, callback, *arguments):
		"""Setup timer to call @timeout_seconds in the future.
		If the timer was previously set, it is postponed
		"""
		self.invalidate()
		self._current_callback = lambda : callback(*arguments)
		self._current_timer = gobject.timeout_add_seconds(timeout_seconds,
				self._call)

	def set_ms(self, timeout_milliseconds, callback, *arguments):
		"""Setup timer to call @timeout_milliseconds in the future.
		If the timer was previously set, it is postponed
		"""
		self.invalidate()
		self._current_callback = lambda : callback(*arguments)
		self._current_timer = gobject.timeout_add(int(timeout_milliseconds),
				self._call)

	def set_idle(self, callback, *arguments):
		self.invalidate()
		self._current_callback = lambda : callback(*arguments)
		self._current_timer = gobject.idle_add(self._call)

	def _call(self, timer=None):
		self._current_timer = -1
		self._current_callback()
	
	def invalidate(self):
		if self._current_timer > 0:
			gobject.source_remove(self._current_timer)
		self._current_timer = -1

	def is_valid(self):
		"""If Timer is currently set"""
		return (self._current_timer > 0)

	def _on_finish(self, scheduler):
		if self._call_at_finish and self.is_valid():
			self._call()
		else:
			self.invalidate()

########NEW FILE########
__FILENAME__ = task
import sys
import threading

import gobject

from kupfer import scheduler, pretty

class Task (object):
	"""Represent a task that can be done in the background

	The finish_callback received in Task.start(..) must be stored,
	and regardless if the task exits with an error, or completes
	successfully, the callback *must* be called.

	The finish callback must pass the Task instance itself as
	the only and first argument:

	    finish_callback(self)
	"""
	def __init__(self, name=None):
		self.name = name

	def __unicode__(self):
		return self.name

	def start(self, finish_callback):
		raise NotImplementedError

class ThreadTask (Task):
	"""Run in a thread"""
	def __init__(self, name=None):
		Task.__init__(self, name)
		self._finish_callback = None

	def thread_do(self):
		"""Override this to run what should be done in the thread"""
		raise NotImplementedError

	def thread_finish(self):
		"""This finish function runs in the main thread after thread
		completion, and can be used to communicate with the GUI.
		"""
		pass

	def thread_finally(self, exc_info):
		"""Always run at thread finish"""
		if exc_info is not None:
			etype, value, tb = exc_info
			raise etype, value, tb

	def _thread_finally(self, exc_info):
		try:
			self.thread_finally(exc_info)
		finally:
			self._finish_callback(self)

	def _run_thread(self):
		try:
			self.thread_do()
			gobject.idle_add(self.thread_finish)
		except:
			exc_info = sys.exc_info()
		else:
			exc_info = None
		finally:
			gobject.idle_add(self._thread_finally, exc_info)

	def start(self, finish_callback):
		self._finish_callback = finish_callback
		thread = threading.Thread(target=self._run_thread)
		thread.start()


class TaskRunner (pretty.OutputMixin):
	"""Run Tasks in the idle Loop"""
	def __init__(self, end_on_finish):
		self.tasks = set()
		self.end_on_finish = end_on_finish
		scheduler.GetScheduler().connect("finish", self._finish_cleanup)

	def _task_finished(self, task):
		self.output_debug("Task finished", task)
		self.tasks.remove(task)

	def add_task(self, task):
		"""Register @task to be run"""
		self.tasks.add(task)
		task.start(self._task_finished)

	def _finish_cleanup(self, sched):
		if self.end_on_finish:
			self.tasks.clear()
			return
		if self.tasks:
			self.output_info("Uncompleted tasks:")
			for task in self.tasks:
				self.output_info(task)

########NEW FILE########
__FILENAME__ = terminal
from kupfer.core import settings

def is_known_terminal_executable(exearg):
	setctl = settings.GetSettingsController()
	for id_, term in setctl.get_all_alternatives('terminal').iteritems():
		if exearg == term["argv"][0]:
			return True
	return False


def get_configured_terminal():
	"""
	Return the configured Terminal object
	"""
	setctl = settings.GetSettingsController()
	return setctl.get_preferred_alternative('terminal')


########NEW FILE########
__FILENAME__ = textutils
# encoding: utf-8

def _unicode_truncate(ustr, length, encoding="UTF-8"):
	"Truncate @ustr to specific encoded byte length"
	bstr = ustr.encode(encoding)[:length]
	return bstr.decode(encoding, 'ignore')

def extract_title_body(text, maxtitlelen=60):
	u"""Prepare @text: Return a (title, body) tuple

	@text: A user-submitted paragraph or otherwise snippet of text. We
	try to detect an obvious title and then return the title and the
	following body. Otherwise we extract a title from the first words,
	and return the full text as body.

	@maxtitlelen: A unitless measure of approximate length of title.
	The default value yields a resulting title of approximately 60 ascii
	characters, or 20 asian characters.

	>>> extract_title_body(u"Short Text")
	(u'Short Text', u'')

	>>> title, body = extract_title_body(u"åŸ·ç­†æ–¹é‡ã«ã¤ã„ã¦ã¯ã€é …ç›®åã®ä»˜ã‘æ–¹ã€"
	...     "ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆã‚„è¡¨è¨˜ä¸Šã®è«¸å•é¡Œã«é–¢ã—ã¦å¤šãã®æ–¹é‡ãŒå­˜åœ¨ã—ã¦ã„ã‚‹ã€‚")
	>>> print title
	åŸ·ç­†æ–¹é‡ã«ã¤ã„ã¦ã¯ã€é …ç›®åã®ä»˜ã‘æ–¹ã€ãƒ•ã‚©
	>>> print body			# doctest: +ELLIPSIS
	åŸ·ç­†æ–¹é‡ã«ã¤ã„ã¦ã¯ã€é …ç›®åã®ä»˜ã‘æ–¹ã€ãƒ•ã‚©...ã—ã¦å¤šãã®æ–¹é‡ãŒå­˜åœ¨ã—ã¦ã„ã‚‹ã€‚
	"""
	# if you don't make real tests, it's not not worth doing it at all.

	if not text.strip():
		return text, u""

	def split_first_line(text):
		"""Take first non-empty line of text"""
		lines = iter(text.splitlines())
		for l in lines:
			l = l.strip()
			if not l:
				continue
			rest = u"\n".join(lines)
			return l, rest

	# We use the UTF-8 encoding and truncate due to it:
	# this is a good heuristic for ascii vs "wide characters"
	# it results in taking fewer characters if they are asian, which
	# is exactly what we want
	def split_first_words(text, maxlen):
		text = text.lstrip()
		first_text = _unicode_truncate(text, maxlen)
		words = first_text.split()
		if len(words) > 3:
			words = words[:-1]
			first_words = u" ".join(words[:-1])
			if text.startswith(first_words):
				first_text = first_words
		rest_text = text[len(first_text):]
		return first_text, rest_text

	firstline, rest = split_first_line(text)
	if len(firstline.encode("UTF-8")) > maxtitlelen:
		firstline, rest = split_first_words(text, maxtitlelen)
	else:
		return firstline, rest
	if rest.strip():
		return firstline, text
	else:
		return text, u""

if __name__ == '__main__':
	# unicode doctest hack
	import sys
	reload(sys)
	sys.setdefaultencoding("UTF-8")

	import doctest
	doctest.testmod()

########NEW FILE########
__FILENAME__ = accelerators

ACCELERATOR_NAMES = {
	# TRANS: Names of accelerators in the interface
	'activate': _('Alternate Activate'),
	# TRANS: The "Comma Trick"/"Put Selection on Stack" allows the
	# TRANS: user to select many objects to be used for one action
	'comma_trick': _('Comma Trick'),
	# TRANS: "Compose Command" makes one object out of the selected
	# TRANS: object + action (+iobject)
	'compose_action': _('Compose Command'),
	'mark_as_default': _('Mark Default Action'),
	'erase_affinity_for_first_pane': _('Forget Object'),
	'reset_all': _('Reset All'),
	'select_quit': _('Select Quit'),
	'select_selected_file': _('Select Selected File'),
	'select_selected_text': _('Select Selected Text'),
	'show_help': _('Show Help'),
	'show_preferences': _('Show Preferences'),
	'switch_to_source': _('Switch to First Pane'),
	"toggle_text_mode_quick": _('Toggle Text Mode'),
}

########NEW FILE########
__FILENAME__ = browser
# -*- coding: UTF-8 -*-

import io
import itertools
import signal
import sys
import textwrap
import time

import gtk
import gio
import gobject
import cairo

from kupfer import kupferui
from kupfer import version

from kupfer import scheduler
from kupfer.ui import accelerators
from kupfer.ui import keybindings
from kupfer.ui import listen
from kupfer.ui import uievents
from kupfer.core import data, relevance, learn
from kupfer.core import settings
from kupfer import icons
from kupfer import interface
from kupfer import pretty


_escape_table = {
		ord(u"&"): u"&amp;",
		ord(u"<"): u"&lt;",
		ord(u">"): u"&gt;",
	}

def tounicode(ustr):
	if isinstance(ustr, unicode):
		return ustr
	return ustr.decode("UTF-8", "replace")

def escape_markup_str(mstr):
	"""
	Use a simeple homegrown replace table to replace &, <, > with
	entities in @mstr
	"""
	return tounicode(mstr).translate(_escape_table)

def text_direction_is_ltr():
	return gtk.widget_get_default_direction() != gtk.TEXT_DIR_RTL

def make_rounded_rect(cr,x,y,width,height,radius):
	"""
	Draws a rounded rectangle with corners of @radius
	"""
	MPI = 3.1415926535897931
	cr.save()

	w,h = width, height

	cr.move_to(radius, 0)
	cr.line_to(w-radius,0)
	cr.arc(w-radius, radius, radius, 3*MPI/2, 2*MPI)
	cr.line_to(w, h-radius)
	cr.arc(w-radius, h-radius, radius, 0, MPI/2)
	cr.line_to(radius, h)
	cr.arc(radius, h-radius, radius, MPI/2, MPI)
	cr.line_to(0, radius)
	cr.arc(radius, radius, radius, MPI, 3*MPI/2)
	cr.close_path()
	cr.restore()

def get_glyph_pixbuf(text, sz, center_vert=True, color=None):
	"""Return pixbuf for @text

	if @center_vert, then center completely vertically
	"""
	margin = sz * 0.1
	ims = cairo.ImageSurface(cairo.FORMAT_ARGB32, sz, sz)
	cc = cairo.Context(ims)

	cc.move_to(margin, sz-margin)
	cc.set_font_size(sz/2)
	if color is None:
		cc.set_source_rgba(0,0,0,1)
	else:
		cc.set_source_rgb(*color)

	cc.text_path(text)
	x1, y1, x2, y2 =cc.path_extents()
	skew_horiz = ((sz-x2) - (x1))/2.0
	skew_vert = ((sz-y2) - (y1))/2.0
	if not center_vert:
		skew_vert = skew_vert*0.2 - margin*0.5
	cc.new_path()
	cc.move_to(margin+skew_horiz, sz-margin+skew_vert)
	cc.text_path(text)
	cc.fill()

	ims.flush()
	f = io.BytesIO()
	ims.write_to_png(f)

	loader = gtk.gdk.PixbufLoader()
	loader.write(f.getvalue())
	loader.close()

	return loader.get_pixbuf()


# State Constants
class State (object):
	Wait, Match, NoMatch = (1,2,3)

class LeafModel (object):
	"""A base for a tree view
	With a magic load-on-demand feature.

	self.set_base will set its base iterator
	and self.populate(num) will load @num items into
	the model
	"""
	def __init__(self):
		"""
		First column is always the object -- returned by get_object
		it needs not be specified in columns
		"""
		columns = (gobject.TYPE_OBJECT, str, str, str)
		self.store = gtk.ListStore(gobject.TYPE_PYOBJECT, *columns)
		self.object_column = 0
		self.base = None
		self._setup_columns()

	def __len__(self):
		return len(self.store)

	def _setup_columns(self):
		self.icon_col = 1
		self.val_col = 2
		self.info_col = 3
		self.rank_col = 4

		# only show in debug mode
		show_rank_col = pretty.debug

		from pango import ELLIPSIZE_MIDDLE
		cell = gtk.CellRendererText()
		cell.set_property("ellipsize", ELLIPSIZE_MIDDLE)
		cell.set_property("width-chars", 45)
		col = gtk.TreeViewColumn("item", cell)

		"""
		info_cell = gtk.CellRendererPixbuf()
		info_cell.set_property("height", 16)
		info_cell.set_property("width", 16)
		info_col = gtk.TreeViewColumn("info", info_cell)
		info_col.add_attribute(info_cell, "icon-name", self.info_col)
		"""
		info_cell = gtk.CellRendererText()
		info_cell.set_property("width-chars", 1)
		info_col = gtk.TreeViewColumn("info", info_cell)
		info_col.add_attribute(info_cell, "text", self.info_col)

		col.add_attribute(cell, "markup", self.val_col)

		nbr_cell = gtk.CellRendererText()
		nbr_col = gtk.TreeViewColumn("rank", nbr_cell)
		nbr_cell.set_property("width-chars", 3)
		nbr_col.add_attribute(nbr_cell, "text", self.rank_col)

		icon_cell = gtk.CellRendererPixbuf()
		#icon_cell.set_property("height", 32)
		#icon_cell.set_property("width", 32)
		#icon_cell.set_property("stock-size", gtk.ICON_SIZE_LARGE_TOOLBAR)

		icon_col = gtk.TreeViewColumn("icon", icon_cell)
		icon_col.add_attribute(icon_cell, "pixbuf", self.icon_col)

		self.columns = [icon_col, col, info_col,]
		if show_rank_col:
			self.columns += (nbr_col, )

	def _get_column(self, treepath, col):
		iter = self.store.get_iter(treepath)
		val = self.store.get_value(iter, col)
		return val

	def get_object(self, path):
		return self._get_column(path, self.object_column)

	def get_store(self):
		return self.store

	def clear(self):
		"""Clear the model and reset its base"""
		self.store.clear()
		self.base = None

	def set_base(self, baseiter):
		self.base = iter(baseiter)

	def populate(self, num=None):
		"""
		populate model with num items from its base
		and return first item inserted
		if num is none, insert everything
		"""
		if not self.base:
			return None
		if num:
			iterator = itertools.islice(self.base, num)
		first = None
		for item in iterator:
			self.add(item)
			if not first: first = item.object
		# first.object is a leaf
		return first

	def _get_row(self, rankable):
		"""Use the UI description functions get_*
		to initialize @rankable into the model
		"""
		leaf, rank = rankable.object, rankable.rank
		icon = self.get_icon(leaf)
		markup = self.get_label_markup(rankable)
		info = self.get_aux_info(leaf)
		rank_str = self.get_rank_str(rank)
		return (rankable, icon, markup, info, rank_str)

	def add(self, rankable):
		self.store.append(self._get_row(rankable))

	def add_first(self, rankable):
		self.store.prepend(self._get_row(rankable))

	def get_icon_size(self):
		return gtk.icon_size_lookup(gtk.icon_size_from_name("kupfer-small"))[0]

	def get_icon(self, leaf):
		sz = self.get_icon_size()
		if sz >= 8:
			return leaf.get_thumbnail(sz, sz) or leaf.get_pixbuf(sz)

	def get_label_markup(self, rankable):
		leaf = rankable.object
		# Here we use the items real name
		# Previously we used the alias that was matched,
		# but it can be too confusing or ugly
		name = escape_markup_str(unicode(leaf))
		desc = escape_markup_str(leaf.get_description() or "")
		if desc:
			text = u'%s\n<small>%s</small>' % (name, desc, )
		else:
			text = u'%s' % (name, )
		return text

	def get_aux_info(self, leaf):
		# info: display arrow if leaf has content
		fill_space = u"\N{EM SPACE}"
		if text_direction_is_ltr():
			content_mark = u"\N{BLACK RIGHT-POINTING SMALL TRIANGLE}"
		else:
			content_mark = u"\N{BLACK LEFT-POINTING SMALL TRIANGLE}"

		info = u""
		if learn.is_favorite(leaf):
			info += u"\N{BLACK STAR}"
		else:
			info += fill_space
		if hasattr(leaf, "has_content") and leaf.has_content():
			info += content_mark
		return info
	def get_rank_str(self, rank):
		# Display rank empty instead of 0 since it looks better
		return str(int(rank)) if rank else ""

class MatchView (gtk.Bin):
	"""
	A Widget for displaying name, icon and underlining properly if
	it matches
	"""
	__gtype_name__ = "MatchView"

	def __init__(self):
		gobject.GObject.__init__(self)
		# object attributes
		self.label_char_width = 25
		self.preedit_char_width = 5
		self.match_state = State.Wait

		self.object_stack = []

		self.connect("realize", self._update_theme)
		self.connect("style-set", self._update_theme)
		# finally build widget
		self.build_widget()
		self.cur_icon = None
		self.cur_text = None
		self.cur_match = None

	@property
	def icon_size(self):
		return gtk.icon_size_lookup(gtk.icon_size_from_name("kupfer-large"))[0]

	def _update_theme(self, *args):
		# Style subtables to choose from
		# fg, bg, text, base
		# light, mid, dark

		# Use a darker color for selected state
		# leave active state as preset
		selectedc = self.style.dark[gtk.STATE_SELECTED]
		self.event_box.modify_bg(gtk.STATE_SELECTED, selectedc)

	def build_widget(self):
		"""
		Core initalization method that builds the widget
		"""
		from pango import ELLIPSIZE_MIDDLE
		self.label = gtk.Label("<match>")
		self.label.set_single_line_mode(True)
		self.label.set_width_chars(self.label_char_width)
		self.label.set_ellipsize(ELLIPSIZE_MIDDLE)
		self.icon_view = gtk.Image()

		# infobox: icon and match name
		icon_align = gtk.Alignment(0.5, 0.5, 0, 0)
		icon_align.set_property("top-padding", 5)
		icon_align.add(self.icon_view)
		infobox = gtk.HBox()
		infobox.pack_start(icon_align, True, True, 0)
		box = gtk.VBox()
		box.pack_start(infobox, True, False, 0)
		self._editbox = gtk.HBox()
		self._editbox.pack_start(self.label, True, True, 0)
		box.pack_start(self._editbox, False, True, 0)
		self.event_box = gtk.EventBox()
		self.event_box.add(box)
		self.event_box.connect("expose-event", self._box_expose)
		self.event_box.set_app_paintable(True)
		self.add(self.event_box)
		self.event_box.show_all()
		self.__child = self.event_box

	def _box_expose(self, widget, event):
		"Draw background on the EventBox"
		rect = widget.get_allocation()
		context = widget.window.cairo_create()
		# set a clip region for the expose event
		context.rectangle(event.area.x, event.area.y,
		                  event.area.width, event.area.height)
		scale = 1.0/2**16
		# paint over GtkEventBox's default background
		context.clip_preserve()
		context.set_operator(cairo.OPERATOR_SOURCE)
		normc = widget.style.bg[gtk.STATE_NORMAL]
		toplevel_window = widget.get_toplevel()
		if toplevel_window.is_composited():
			opacity = 0.01*toplevel_window.style_get_property('opacity')
			context.set_source_rgba(normc.red*scale,
					normc.green*scale, normc.blue*scale, opacity)
		else:
			context.set_source_rgba(normc.red*scale,
					normc.green*scale, normc.blue*scale, 1.0)
		context.fill()

		radius = self.style_get_property('corner-radius')
		make_rounded_rect(context, 0, 0, rect.width, rect.height, radius=radius)
		# Get the current selection color
		newc = widget.style.bg[widget.get_state()]
		context.set_operator(cairo.OPERATOR_SOURCE)
		opacity = 0.01*self.style_get_property('opacity')
		context.set_source_rgba(newc.red*scale,
				newc.green*scale, newc.blue*scale, opacity)
		context.fill()
		return False

	def do_size_request (self, requisition):
		requisition.width, requisition.height = self.__child.size_request ()

	def do_size_allocate (self, allocation):
		self.__child.size_allocate (allocation)

	def do_forall (self, include_internals, callback, user_data):
		callback (self.__child, user_data)

	def _render_composed_icon(self, base, pixbufs, small_size):
		"""
		Render the main selection + a string of objects on the stack.

		Scale the main image into the upper portion, leaving a clear
		strip at the bottom where we line up the small icons.

		@base: main selection pixbuf
		@pixbufs: icons of the object stack, in final (small) size
		@small_size: the size of the small icons
		"""
		sz = self.icon_size
		base_scale = min((sz-small_size)*1.0/base.get_height(),
				sz*1.0/base.get_width())
		new_sz_x = int(base_scale*base.get_width())
		new_sz_y = int(base_scale*base.get_height())
		if not base.get_has_alpha():
			base = base.add_alpha(False, 0, 0, 0)
		destbuf = base.scale_simple(sz, sz, gtk.gdk.INTERP_NEAREST)
		destbuf.fill(0x00000000)
		# Align in the middle of the area
		offset_x = (sz - new_sz_x)/2
		offset_y = ((sz - small_size) - new_sz_y)/2
		base.composite(destbuf, offset_x, offset_y, new_sz_x, new_sz_y,
				offset_x, offset_y,
				base_scale, base_scale, gtk.gdk.INTERP_BILINEAR, 255)

		# @fr is the scale compared to the destination pixbuf
		fr = small_size*1.0/sz
		dest_y = offset_y = int((1-fr)*sz)
		for idx, pbuf in enumerate(pixbufs):
			dest_x = offset_x = int(fr*sz)*idx
			pbuf.copy_area(0,0, small_size,small_size, destbuf, dest_x,dest_y)
		return destbuf

	def update_match(self):
		"""
		Update interface to display the currently selected match
		"""
		# update icon
		icon = self.cur_icon
		if icon:
			if self.match_state is State.NoMatch:
				icon = self._dim_icon(icon)
			if icon and self.object_stack:
				small_max = 6
				small_size = 16
				pixbufs = [o.get_pixbuf(small_size) for o in
						self.object_stack[-small_max:]]
				icon = self._render_composed_icon(icon, pixbufs, small_size)
			self.icon_view.set_from_pixbuf(icon)
		else:
			self.icon_view.set_from_icon_name("gtk-file", self.icon_size)
			self.icon_view.set_pixel_size(self.icon_size)

		if not self.cur_text:
			self.label.set_text("<no text>")
			return

		if not self.cur_match:
			if self.match_state is not State.Match:
				# Allow markup in the text string if we have no match
				self.label.set_markup(self.cur_text)
			else:
				self.label.set_text(self.cur_text)
			return

		# update the text label
		text = unicode(self.cur_text)
		key = unicode(self.cur_match).lower()

		format_match=(lambda m: u"<u><b>%s</b></u>" % escape_markup_str(m))
		markup = relevance.formatCommonSubstrings(text, key,
				format_clean=escape_markup_str,
				format_match=format_match)

		self.label.set_markup(markup)

	@classmethod
	def _dim_icon(cls, icon):
		if icon:
			dim_icon = icon.copy()
			icon.saturate_and_pixelate(dim_icon, 0, True)
		else:
			dim_icon = None
		return dim_icon

	def set_object(self, text, icon, update=True):
		self.cur_text = text
		self.cur_icon = icon
		if update:
			self.update_match()

	def set_match(self, match=None, state=None, update=True):
		self.cur_match = match
		if state:
			self.match_state = state
		else:
			self.match_state = (State.NoMatch, State.Match)[self.cur_match != None]
		if update:
			self.update_match()

	def set_match_state(self, text, icon, match=None, state=None, update=True):
		self.set_object(text,icon, update=False)
		self.set_match(match, state, update=False)
		if update:
			self.update_match()

	def set_match_text(self, text, update=True):
		self.cur_match = text
		if update:
			self.update_match()

	def expand_preedit(self, preedit):
		new_label_width = self.label_char_width - self.preedit_char_width
		self.label.set_width_chars(new_label_width)
		preedit.set_width_chars(self.preedit_char_width)
		pass

	def shrink_preedit(self, preedit):
		self.label.set_width_chars(self.label_char_width)
		preedit.set_width_chars(0)
		pass

	def inject_preedit(self, preedit):
		"""
		@preedit: Widget to be injected or None
		"""
		if preedit:
			old_parent = preedit.get_parent()
			if old_parent:
				old_parent.remove(preedit)
			self.shrink_preedit(preedit)
			self._editbox.pack_start(preedit, False, True, 0)
			selectedc = self.style.dark[gtk.STATE_SELECTED]
			preedit.modify_bg(gtk.STATE_SELECTED, selectedc)
			preedit.show()
			preedit.grab_focus()
		else:
			self.label.set_width_chars(self.label_char_width)
			self.label.set_alignment(.5,.5)

gobject.type_register(MatchView)
gtk.widget_class_install_style_property(MatchView,
		('corner-radius', gobject.TYPE_INT, 'Corner radius',
		 'Radius of bezel around match',
		 0, 50, 15,
		 gobject.PARAM_READABLE))
gtk.widget_class_install_style_property(MatchView,
		('opacity', gobject.TYPE_INT, 'Bezel opacity',
		 'Opacity of bezel around match',
		 50, 100, 95,
		 gobject.PARAM_READABLE))

class Search (gtk.Bin):
	"""
	A Widget for displaying search results
	icon + aux table etc

	Signals
	* cursor-changed: def callback(widget, selection)
		called with new selected (represented) object or None
	* activate: def callback(widget, selection)
		called with activated leaf, when the widget is activated
		by double-click in table
	* table-event: def callback(widget, table, event)
		called when the user types in the table
	"""
	__gtype_name__ = 'Search'
	def __init__(self):
		gobject.GObject.__init__(self)
		# object attributes
		self.model = LeafModel()
		self.match = None
		self.match_state = State.Wait
		self.text = u""
		# internal constants
		self.show_initial = 10
		self.show_more = 10
		# number rows to skip when press PgUp/PgDown
		self.page_step = 7
		self.source = None
		self._old_win_position=None
		self._has_search_result = False
		self._initialized = False
		# finally build widget
		self.build_widget()
		self.icon_size = None
		self.on_style_set()
		self.setup_empty()
		self.connect("style-set", self.on_style_set)

	def on_style_set(self, *args):
		self.icon_size = \
			gtk.icon_size_lookup(gtk.icon_size_from_name("kupfer-large"))[0]

	def build_widget(self):
		"""
		Core initalization method that builds the widget
		"""
		self.match_view = MatchView()

		self.table = gtk.TreeView(self.model.get_store())
		self.table.set_headers_visible(False)
		self.table.set_property("enable-search", False)

		for col in self.model.columns:
			self.table.append_column(col)

		self.table.connect("row-activated", self._row_activated)
		self.table.connect("cursor-changed", self._cursor_changed)

		self.scroller = gtk.ScrolledWindow()
		self.scroller.set_policy(gtk.POLICY_NEVER, gtk.POLICY_AUTOMATIC)
		self.scroller.add(self.table)
		vscroll = self.scroller.get_vscrollbar()
		vscroll.connect("change-value", self._table_scroll_changed)

		self.list_window = gtk.Window(gtk.WINDOW_POPUP)
		self.list_window.set_name("kupfer-list")

		box = gtk.VBox()
		box.pack_start(self.match_view, True, True, 0)
		self.add(box)
		box.show_all()
		self.__child = box

		self.list_window.add(self.scroller)
		self.scroller.show_all()

	def get_current(self):
		"""
		return current selection
		"""
		return self.match

	def set_object_stack(self, stack):
		self.match_view.object_stack[:] = stack
		self.match_view.update_match()

	def set_source(self, source):
		"""Set current source (to get icon, name etc)"""
		self.source = source

	def get_match_state(self):
		return self.match_state
	def get_match_text(self):
		return self.text

	def do_size_request (self, requisition):
		requisition.width, requisition.height = self.__child.size_request ()

	def do_size_allocate (self, allocation):
		self.__child.size_allocate (allocation)

	def do_forall (self, include_internals, callback, user_data):
		callback (self.__child, user_data)

	def get_table_visible(self):
		return self.list_window.get_property("visible")

	def hide_table(self):
		self.list_window.hide()

	def _show_table(self):
		table_maxlen = self.style_get_property('list-length')
		opacity = 0.01*self.style_get_property('list-opacity')
		# self.window is a GdkWindow (of self's parent)
		win_width, win_height = self.window.get_size()
		pos_x, pos_y = self.window.get_position()
		# find origin in parent's coordinates
		self_x, self_y = self.translate_coordinates(self.get_parent(), 0, 0)
		self_width = self.size_request()[0]
		sub_x = pos_x
		sub_y = pos_y + win_height
		table_w, table_len = self.table.size_request()
		subwin_height = min(table_len, table_maxlen) or 100
		subwin_width = self_width*2 - self_x
		if not text_direction_is_ltr():
			sub_x += win_width - subwin_width + self_x
		else:
			sub_x -= self_x
		self.list_window.move(sub_x, sub_y)
		self.list_window.resize(subwin_width, subwin_height)

		win = self.get_toplevel()
		self.list_window.set_transient_for(win)
		self.list_window.set_property("focus-on-map", False)
		self.list_window.set_opacity(opacity)
		self.list_window.show()
		self._old_win_position = pos_x, pos_y

	def show_table(self):
		self.go_down(True)

	def _table_scroll_changed(self, scrollbar, scroll_type, value):
		"""When the scrollbar changes due to user interaction"""
		# page size: size of currently visible area
		adj = scrollbar.get_adjustment()
		upper = adj.get_property("upper")
		page_size = adj.get_property("page-size")

		if value + page_size >= upper:
			self.populate(self.show_more)

	# table methods
	def _table_set_cursor_at_row(self, row):
		path_at_row = lambda r: (r,)
		self.table.set_cursor(path_at_row(row))

	def go_up(self, rows_count=1):
		"""
		Upwards in the table
		"""
		row_at_path = lambda p: p[0]

		# go up, simply. close table if we go up from row 0
		path, col = self.table.get_cursor()
		if path:
			r = row_at_path(path)
			if r >= 1:
				self._table_set_cursor_at_row(r-min(rows_count, r))
			else:
				self.hide_table()

	def go_down(self, force=False, rows_count=1):
		"""
		Down in the table
		"""
		row_at_path = lambda p: p[0]

		table_visible = self.get_table_visible()
		# if no data is loaded (frex viewing catalog), load
		# if too little data is loaded, try load more
		if len(self.model) <= 1:
			self.populate(self.show_more)
		if len(self.model) >= 1:
			path, col = self.table.get_cursor()
			if path:
				r = row_at_path(path)
				if len(self.model) - rows_count <= r:
					self.populate(self.show_more)
				# go down only if table is visible
				if table_visible:
					step = min(len(self.model) - r - 1, rows_count)
					if step > 0:
						self._table_set_cursor_at_row(r + step)
			else:
				self._table_set_cursor_at_row(0)
			self._show_table()
		if force:
			self._show_table()

	def go_page_up(self):
		''' move list one page up '''
		self.go_up(self.page_step)

	def go_page_down(self):
		''' move list one page down '''
		self.go_down(rows_count=self.page_step)

	def go_first(self):
		''' Rewind to first item '''
		if self.get_table_visible():
			self._table_set_cursor_at_row(0)

	def _window_config(self, widget, event):
		"""
		When the window moves
		"""
		winpos = event.x, event.y
		# only hide on move, not resize
		# set old win position in _show_table
		if self.get_table_visible() and winpos != self._old_win_position:
			self.hide_table()
			gobject.timeout_add(300, self._show_table)

	def _window_hidden(self, window):
		"""
		Window changed hid
		"""
		self.hide_table()

	def _row_activated(self, treeview, path, col):
		obj = self.get_current()
		self.emit("activate", obj)

	def _cursor_changed(self, treeview):
		path, col = treeview.get_cursor()
		match = self.model.get_object(path)
		self._set_match(match)

	def _set_match(self, rankable=None):
		"""
		Set the currently selected (represented) object, either as
		@rankable or KupferObject @obj

		Emits cursor-changed
		"""
		self.match = (rankable.object if rankable else None)
		self.emit("cursor-changed", self.match)
		if self.match:
			match_text = (rankable and rankable.value)
			self.match_state = State.Match
			m = self.match
			pbuf = (m.get_thumbnail(self.icon_size*4//3, self.icon_size) or
				m.get_pixbuf(self.icon_size))
			self.match_view.set_match_state(match_text, pbuf,
					match=self.text, state=self.match_state)

	def set_match_plain(self, obj):
		"""Set match to object @obj, without search or matches"""
		self.text = None
		self._set_match(obj)
		self.model.add_first(obj)
		self._table_set_cursor_at_row(0)

	def relax_match(self):
		"""Remove match text highlight"""
		self.match_view.set_match_text(None)
		self.text = None

	def has_result(self):
		"""A search with explicit search term is active"""
		return self._has_search_result

	def is_showing_result(self):
		"""Showing search result:
		A search with explicit search term is active,
		and the result list is shown.
		"""
		return self._has_search_result and self.get_table_visible()

	def update_match(self, key, matchrankable, matches):
		"""
		@matchrankable: Rankable first match or None
		@matches: Iterable to rest of matches
		"""
		self._has_search_result = bool(key)
		self.model.clear()
		self.text = key
		if not matchrankable:
			self._set_match(None)
			return self.handle_no_matches(empty=not key)
		self._set_match(matchrankable)
		self.model.set_base(iter(matches))
		self._browsing_match = False
		if not self.model and self.get_table_visible():
			self.go_down()

	def reset(self):
		self._has_search_result = False
		self._initialized = True
		self.model.clear()
		self.setup_empty()

	def setup_empty(self):
		self.match_state = State.NoMatch
		self.match_view.set_match_state(u"No match", None, state=State.NoMatch)
		self.relax_match()

	def get_is_browsing(self):
		"""Return if self is browsing"""
		return self._browsing_match

	def populate(self, num):
		"""populate model with num items"""
		return self.model.populate(num)

	def handle_no_matches(self, empty=False):
		"""if @empty, there were no matches to find"""
		name, icon = self.get_nomatch_name_icon(empty=empty)
		self.match_state = State.NoMatch
		self.match_view.set_match_state(name, icon, state=State.NoMatch)

# Take care of gobject things to set up the Search class
gobject.type_register(Search)
gobject.signal_new("activate", Search, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN, (gobject.TYPE_PYOBJECT, ))
gobject.signal_new("cursor-changed", Search, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN, (gobject.TYPE_PYOBJECT, ))
gtk.widget_class_install_style_property(Search,
		('list-opacity', gobject.TYPE_INT, 'Result list opacity',
		 'Opacity of the whole result list',
		 50, 100, 93,
		 gobject.PARAM_READABLE))

gtk.widget_class_install_style_property(Search,
		('list-length', gobject.TYPE_INT, 'Result list length',
		 'Maximum length of the result list',
		 50, 1024, 200,
		 gobject.PARAM_READABLE))

class LeafSearch (Search):
	"""
	Customize for leaves search
	"""
	def get_nomatch_name_icon(self, empty):
		get_pbuf = \
			lambda m: (m.get_thumbnail(self.icon_size*4/3, self.icon_size) or \
					m.get_pixbuf(self.icon_size))
		if empty and self.source:
			return (_("%s is empty") %
					escape_markup_str(unicode(self.source)),
					get_pbuf(self.source))
		elif self.source:
			return (_('No matches in %(src)s for "%(query)s"') % {
				"src": u"<i>%s</i>" % escape_markup_str(unicode(self.source)),
				"query": escape_markup_str(self.text),
				},
				get_pbuf(self.source))
		else:
			return _("No matches"), icons.get_icon_for_name("kupfer-object",
					self.icon_size)

	def setup_empty(self):
		icon = None
		title = _("Type to search")
		def get_pbuf(m):
			return (m.get_thumbnail(self.icon_size*4//3, self.icon_size) or
					m.get_pixbuf(self.icon_size))
		if self.source:
			icon = get_pbuf(self.source)
			title = (_("Type to search %s") %
					u"<i>%s</i>" % escape_markup_str(unicode(self.source)))

		self._set_match(None)
		self.match_state = State.Wait
		self.match_view.set_match_state(title, icon, state=State.Wait)

class ActionSearch (Search):
	"""
	Customization for Actions
	"""
	def get_nomatch_name_icon(self, empty=False):
		# don't look up icons too early
		if not self._initialized:
			return ("", None)
		return _("No action"), icons.get_icon_for_name("kupfer-execute",
				self.icon_size)
	def setup_empty(self):
		self.handle_no_matches()
		self.hide_table()

class Interface (gobject.GObject):
	"""
	Controller object that controls the input and
	the state (current active) search object/widget

	Signals:
	* cancelled: def callback(controller)
		escape was typed
	"""
	__gtype_name__ = "Interface"

	def __init__(self, controller, window):
		"""
		@controller: DataController
		@window: toplevel window
		"""
		gobject.GObject.__init__(self)

		self.search = LeafSearch()
		self.action = ActionSearch()
		self.third = LeafSearch()
		self.entry = gtk.Entry()
		self.label = gtk.Label()
		self.preedit = gtk.Entry()
		## make sure we lose the preedit focus ring
		self.preedit.set_name("kupfer-preedit")
		gtk.rc_parse_string("""
		style "kupferpreedit"
		{
			GtkEntry :: focus-line-width = 0
		}
		widget "*.%s" style "kupferpreedit"
		""" % (self.preedit.path(), ))

		self.current = None

		self._widget = None
		self._ui_transition_timer = scheduler.Timer()
		self._pane_three_is_visible = False
		self._is_text_mode = False
		self._latest_input_timer = scheduler.Timer()
		self._slow_input_interval = 2
		self._key_press_time = None
		self._key_press_interval = 0.3
		self._key_press_repeat_threshold = 0.02
		self._key_repeat_key = None
		self._key_repeat_active = False
		self._reset_to_toplevel = False
		self._reset_when_back = False
		self.entry.connect("realize", self._entry_realized)
		self.preedit.set_has_frame(False)
		self.preedit.set_inner_border(gtk.Border(0, 0, 0, 0))
		self.preedit.set_width_chars(0)
		self.preedit.set_alignment(1)

		from pango import ELLIPSIZE_MIDDLE
		self.label.set_width_chars(50)
		self.label.set_single_line_mode(True)
		self.label.set_ellipsize(ELLIPSIZE_MIDDLE)
		self.label.set_name("kupfer-description")

		self.switch_to_source()
		self.entry.connect("changed", self._changed)
		self.preedit.connect("changed", self._preedit_changed)
		## preedit-changed is GTK+ 2.20
		## if not available, silently skip it
		try:
			self.preedit.connect("preedit-changed", self._preedit_im_changed)
		except TypeError:
			pass
		for widget in (self.entry, self.preedit):
			widget.connect("activate", self._activate, None)
			widget.connect("key-press-event", self._entry_key_press)
			widget.connect("key-release-event", self._entry_key_release)
			widget.connect("copy-clipboard", self._entry_copy_clipboard)
			widget.connect("cut-clipboard", self._entry_cut_clipboard)
			widget.connect("paste-clipboard", self._entry_paste_clipboard)

		# set up panewidget => self signals
		# as well as window => panewidgets
		for widget in (self.search, self.action, self.third):
			widget.connect("activate", self._activate)
			widget.connect("button-press-event", self._panewidget_button_press)
			widget.connect("cursor-changed", self._selection_changed)
			# window signals
			window.connect("configure-event", widget._window_config)
			window.connect("hide", widget._window_hidden)

		self.data_controller = controller
		self.data_controller.connect("search-result", self._search_result)
		self.data_controller.connect("source-changed", self._new_source)
		self.data_controller.connect("pane-reset", self._pane_reset)
		self.data_controller.connect("mode-changed", self._show_hide_third)
		self.data_controller.connect("object-stack-changed", self._object_stack_changed)
		self.widget_to_pane = {
			id(self.search) : data.SourcePane,
			id(self.action) : data.ActionPane,
			id(self.third) : data.ObjectPane,
			}
		self.pane_to_widget = {
			data.SourcePane : self.search,
			data.ActionPane : self.action,
			data.ObjectPane : self.third,
		}
		# Setup keyval mapping
		keys = (
			"Up", "Down", "Right", "Left",
			"Tab", "ISO_Left_Tab", "BackSpace", "Escape", "Delete",
			"space", 'Page_Up', 'Page_Down', 'Home', 'End',
			"Return",
			)
		self.key_book = dict((k, gtk.gdk.keyval_from_name(k)) for k in keys)
		if not text_direction_is_ltr():
			# for RTL languages, simply swap the meaning of Left and Right
			# (for keybindings!)
			D = self.key_book
			D["Left"], D["Right"] = D["Right"], D["Left"]

		self.keys_sensible = set(self.key_book.itervalues())
		self.search.reset()

	def get_widget(self):
		"""Return a Widget containing the whole Interface"""
		if self._widget:
			return self._widget
		box = gtk.HBox()
		box.pack_start(self.search, True, True, 3)
		box.pack_start(self.action, True, True, 3)
		box.pack_start(self.third, True, True, 3)
		vbox = gtk.VBox()
		vbox.pack_start(box, True, True, 0)

		label_align = gtk.Alignment(0.5, 1, 0, 0)
		label_align.set_property("top-padding", 3)
		label_align.add(self.label)
		vbox.pack_start(label_align, False, False, 0)
		vbox.pack_start(self.entry, False, False, 0)
		vbox.show_all()
		self.third.hide()
		self._widget = vbox
		return vbox

	def _entry_realized(self, widget):
		self.update_text_mode()

	def _entry_key_release(self, entry, event):
		return
		# check for key repeat activation (disabled)
		if self._key_repeat_key == event.keyval:
			if self._key_repeat_active:
				self.activate()
			self._key_repeat_key = None
			self._key_repeat_active = False
			self._update_active()

	def _entry_key_press(self, entry, event):
		"""
		Intercept arrow keys and manipulate table
		without losing focus from entry field
		"""

		direct_text_key = gtk.gdk.keyval_from_name("period")
		init_text_keys = map(gtk.gdk.keyval_from_name, ("slash", "equal"))
		init_text_keys.append(direct_text_key)
		keymap = gtk.gdk.keymap_get_default()
		# translate keys properly
		keyv, egroup, level, consumed = keymap.translate_keyboard_state(
					event.hardware_keycode, event.state, event.group)
		all_modifiers = gtk.accelerator_get_default_mod_mask()
		modifiers = all_modifiers & ~consumed
		# MOD1_MASK is alt/option
		mod1_mask = ((event.state & modifiers) == gtk.gdk.MOD1_MASK)
		shift_mask = ((event.state & all_modifiers) == gtk.gdk.SHIFT_MASK)

		text_mode = self.get_in_text_mode()
		has_input = bool(self.entry.get_text())

		curtime = time.time()
		self._reset_input_timer()

		setctl = settings.GetSettingsController()
		# process accelerators
		for action, accel in setctl.get_accelerators().iteritems():
			akeyv, amodf = gtk.accelerator_parse(accel)
			if not akeyv:
				continue
			if akeyv == keyv and (amodf == (event.state & modifiers)):
				action_method = getattr(self, action, None)
				if not action_method:
					pretty.print_error(__name__, "Action invalid '%s'" % action)
				else:
					action_method()
				return True

		key_book = self.key_book
		use_command_keys = setctl.get_use_command_keys()
		has_selection = (self.current.get_match_state() is State.Match)
		if not text_mode and use_command_keys:
			# translate extra commands to normal commands here
			# and remember skipped chars
			if keyv == key_book["space"]:
				if shift_mask:
					keyv = key_book["Up"]
				else:
					keyv = key_book["Down"]
			elif keyv == ord("/") and has_selection:
				keyv = key_book["Right"]
			elif keyv == ord(",") and has_selection:
				if self.comma_trick():
					return True
			elif keyv in init_text_keys:
				if self.try_enable_text_mode():
					# swallow if it is the direct key
					swallow = (keyv == direct_text_key)
					return swallow
		if text_mode and keyv in (key_book["Left"], key_book["Right"],
		                          key_book["Home"], key_book["End"]):
			# pass these through in text mode
			return False

		# disabled  repeat-key activation and shift-to-action selection
		# check for repeated key activation
		"""
		if ((not text_mode) and self._key_repeat_key == keyv and
				keyv not in self.keys_sensible and
				curtime - self._key_press_time > self._key_press_repeat_threshold):
			if curtime - self._key_press_time > self._key_press_interval:
				self._key_repeat_active = True
				self._update_active()
			return True
		else:
			# cancel repeat key activation if a new key is pressed
			self._key_press_time = curtime
			self._key_repeat_key = keyv
			if self._key_repeat_active:
				self._key_repeat_active = False
				self._update_active()
		"""

		"""
			## if typing with shift key, switch to action pane
			if not text_mode and use_command_keys and shift_mask:
				uchar = gtk.gdk.keyval_to_unicode(keyv)
				if (uchar and unichr(uchar).isupper() and
				    self.current == self.search):
					self.current.hide_table()
					self.switch_current()
			return False
		"""
		# exit here if it's not a special key
		if keyv not in self.keys_sensible:
			return False
		self._reset_to_toplevel = False

		if keyv == key_book["Escape"]:
			self._escape_key_press()
			return True


		if keyv == key_book["Up"]:
			self.current.go_up()
		elif keyv == key_book["Page_Up"]:
			self.current.go_page_up()
		elif keyv == key_book["Down"]:
			## if typing with shift key, switch to action pane
			if shift_mask and self.current == self.search:
				self.current.hide_table()
				self.switch_current()
			if (not self.current.get_current() and
					self.current.get_match_state() is State.Wait):
				self._populate_search()
			self.current.go_down()
		elif keyv == key_book["Page_Down"]:
			if (not self.current.get_current() and
					self.current.get_match_state() is State.Wait):
				self._populate_search()
			self.current.go_page_down()
		elif keyv == key_book["Right"]:
			self._browse_down(alternate=mod1_mask)
		elif keyv == key_book["BackSpace"]:
			if not has_input:
				self._backspace_key_press()
			elif not text_mode:
				self.entry.delete_text(self.entry.get_text_length() - 1, -1)
			else:
				return False
		elif keyv == key_book["Left"]:
			self._back_key_press()
		elif keyv in (key_book["Tab"], key_book["ISO_Left_Tab"]):
			self.current.hide_table()
			self.switch_current(reverse=(keyv == key_book["ISO_Left_Tab"]))
		elif keyv == key_book['Home']:
			self.current.go_first()
		else:
			# cont. processing
			return False
		return True

	def _entry_copy_clipboard(self, entry):
		# Copy current selection to clipboard
		# delegate to text entry when in text mode

		if self.get_in_text_mode():
			return False
		selection = self.current.get_current()
		if selection is None:
			return False
		clip = gtk.Clipboard(selection=gtk.gdk.SELECTION_CLIPBOARD,
		                     display=entry.get_display())
		return interface.copy_to_clipboard(selection, clip)

	def _entry_cut_clipboard(self, entry):
		if not self._entry_copy_clipboard(entry):
			return False
		self.reset_current()
		self.reset()

	def _entry_paste_data_received(self, clipboard, targets, entry):
		uri_target = "text/uri-list"
		## check if we can insert files
		if uri_target in targets:
			# paste as files
			sdata = clipboard.wait_for_contents(uri_target)
			self.reset_current()
			self.reset()
			self.put_files(sdata.get_uris())
			## done
		else:
			# enable text mode and reemit to paste text
			self.try_enable_text_mode()
			if self.get_in_text_mode():
				entry.emit("paste-clipboard")

	def _entry_paste_clipboard(self, entry):
		if not self.get_in_text_mode():
			self.reset()
			## when not in text mode,
			## stop signal emission so we can handle it
			clipboard = gtk.Clipboard(selection=gtk.gdk.SELECTION_CLIPBOARD,
			                          display=entry.get_display())
			clipboard.request_targets(self._entry_paste_data_received, entry)
			entry.emit_stop_by_name("paste-clipboard")


	def reset_text(self):
		self.entry.set_text("")

	def reset(self):
		self.reset_text()
		self.current.hide_table()

	def reset_current(self, populate=False):
		"""
		Reset the source or action view

		Corresponds to backspace
		"""
		if self.current.get_match_state() is State.Wait:
			self.toggle_text_mode(False)
		if self.current is self.action or populate:
			self._populate_search()
		else:
			self.current.reset()

	def reset_all(self):
		"""Reset all panes and focus the first"""
		self.switch_to_source()
		while self._browse_up():
			pass
		self.toggle_text_mode(False)
		self.data_controller.object_stack_clear_all()
		self.reset_current()
		self.reset()

	def _populate_search(self):
		"""Do a blanket search/empty search to populate current pane"""
		pane = self._pane_for_widget(self.current)
		self.data_controller.search(pane, interactive=True)

	def soft_reset(self, pane=None):
		"""Reset @pane or current pane context/source
		softly (without visible update), and unset _reset_to_toplevel marker.
		"""
		pane = pane or self._pane_for_widget(self.current)
		newsrc = self.data_controller.soft_reset(pane)
		if newsrc:
			self.current.set_source(newsrc)
		self._reset_to_toplevel = False


	def _escape_key_press(self):
		"""Handle escape if first pane is reset, cancel (put away) self.  """
		if self.current.has_result():
			if self.current.is_showing_result():
				self.reset_current(populate=True)
			else:
				self.reset_current()
		else:
			if self.get_in_text_mode():
				self.toggle_text_mode(False)
			elif not self.current.get_table_visible():
				pane = self._pane_for_widget(self.current)
				self.data_controller.object_stack_clear(pane)
				self.emit("cancelled")
			self._reset_to_toplevel = True
			self.current.hide_table()
		self.reset_text()

	def _backspace_key_press(self):
		# backspace: delete from stack
		pane = self._pane_for_widget(self.current)
		if self.data_controller.get_object_stack(pane):
			self.data_controller.object_stack_pop(pane)
			self.reset_text()
			return
		self._back_key_press()

	def _back_key_press(self):
		# leftarrow (or backspace without object stack)
		# delete/go up through stource stack
		if self.current.is_showing_result():
			self.reset_current(populate=True)
		else:
			if self._browse_up():
				pass
			else:
				self.reset()
				self.reset_current()
				self._reset_to_toplevel = True
		self.reset_text()

	def _relax_search_terms(self):
		if self.get_in_text_mode():
			return
		self.reset_text()
		self.current.relax_match()

	def get_in_text_mode(self):
		return self._is_text_mode

	def get_can_enter_text_mode(self):
		"""We can enter text mode if the data backend allows,
		and the text entry is ready for input (empty)
		"""
		pane = self._pane_for_widget(self.current)
		val = self.data_controller.get_can_enter_text_mode(pane)
		entry_text = self.entry.get_text()
		return val and not entry_text

	def try_enable_text_mode(self):
		"""Perform a soft reset if possible and then try enabling text mode"""
		if self._reset_to_toplevel:
			self.soft_reset()
		if self.get_can_enter_text_mode():
			return self.toggle_text_mode(True)
		return False

	def toggle_text_mode(self, val):
		"""Toggle text mode on/off per @val,
		and return the subsequent on/off state.
		"""
		val = bool(val) and self.get_can_enter_text_mode()
		self._is_text_mode = val
		self.update_text_mode()
		self.reset()
		return val

	def toggle_text_mode_quick(self):
		"""Toggle text mode or not, if we can or not, without reset"""
		if self._is_text_mode:
			self._is_text_mode = False
		else:
			self._is_text_mode = True
		self.update_text_mode()

	def update_text_mode(self):
		"""update appearance to whether text mode enabled or not"""
		if self._is_text_mode:
			self.entry.show()
			self.entry.grab_focus()
			self.entry.set_position(-1)
			self.preedit.hide()
			self.preedit.set_width_chars(0)
		else:
			self.entry.hide()
		self._update_active()

	def switch_to_source(self):
		if self.current is not self.search:
			if self.current:
				self.current.hide_table()
			self.current = self.search
			self._update_active()
			if self.get_in_text_mode():
				self.toggle_text_mode_quick()

	def focus(self):
		"""called when the interface is focus (after being away)"""
		if self._reset_when_back:
			self._reset_when_back = False
			self.toggle_text_mode(False)
		# preserve text mode, but switch to source if we are not in it
		if not self.get_in_text_mode():
			self.switch_to_source()
		# Check that items are still valid when "coming back"
		self.data_controller.validate()

	def did_launch(self):
		"called to notify that 'activate' was successful"
		self._reset_when_back = True

	def put_away(self):
		"""Called when the interface is hidden"""
		self._relax_search_terms()
		self._reset_to_toplevel = True
		# no hide / show pane three on put away -> focus anymore

	def select_selected_file(self):
		# Add optional lookup data to narrow the search
		self.data_controller.find_object("qpfer:selectedfile#any.FileLeaf")

	def select_selected_text(self):
		self.data_controller.find_object("qpfer:selectedtext#any.TextLeaf")

	def select_quit(self):
		self.data_controller.find_object("qpfer:quit")

	def show_help(self):
		kupferui.show_help(self._make_gui_ctx())
		self.emit("launched-action")

	def show_preferences(self):
		kupferui.show_preferences(self._make_gui_ctx())
		self.emit("launched-action")

	def compose_action(self):
		self.data_controller.compose_selection()

	def mark_as_default(self):
		if self.action.get_match_state() != State.Match:
			return False
		self.data_controller.mark_as_default(data.ActionPane)
		return True

	def erase_affinity_for_first_pane(self):
		if self.search.get_match_state() != State.Match:
			return False
		self.data_controller.erase_object_affinity(data.SourcePane)
		return True

	def comma_trick(self):
		if self.current.get_match_state() != State.Match:
			return False
		cur = self.current.get_current()
		curpane = self._pane_for_widget(self.current)
		if self.data_controller.object_stack_push(curpane, cur):
			self._relax_search_terms()
			if self.get_in_text_mode():
				self.reset_text()
			return True

	def get_context_actions(self):
		"""
		Get a list of (name, function) currently
		active context actions
		"""
		def get_accel(key):
			""" Return name, method pair for @key"""
			if key not in accelerators.ACCELERATOR_NAMES:
				raise RuntimeError("Missing accelerator: %s" % key)
			return (accelerators.ACCELERATOR_NAMES[key], getattr(self, key))
		def trunc(ustr):
			"truncate long object names"
			return ustr[:25]
		has_match = self.current.get_match_state() == State.Match
		if has_match:
			yield get_accel('compose_action')
		yield get_accel('select_selected_text')
		if self.get_can_enter_text_mode():
			yield get_accel('toggle_text_mode_quick')
		if self.action.get_match_state() == State.Match:
			smatch = self.search.get_current()
			amatch = self.action.get_current()
			label = (_('Make "%(action)s" Default for "%(object)s"') % {
			         'action': trunc(unicode(amatch)),
			         'object': trunc(unicode(smatch)),
			         })
			w_label = textwrap.wrap(label, width=40, subsequent_indent="    ")
			yield (u"\n".join(w_label), self.mark_as_default)
		if has_match:
			if self.data_controller.get_object_has_affinity(data.SourcePane):
				match = self.search.get_current()
				# TRANS: Removing learned and/or configured bonus search score
				yield (_('Forget About "%s"') % trunc(unicode(match)),
				       self.erase_affinity_for_first_pane)
		if has_match:
			yield get_accel('reset_all')

	def _pane_reset(self, controller, pane, item):
		wid = self._widget_for_pane(pane)
		if not item:
			wid.reset()
		else:
			wid.set_match_plain(item)
			if wid is self.search:
				self.reset()
				self.toggle_text_mode(False)
				self.switch_to_source()

	def _new_source(self, sender, pane, source, at_root):
		"""Notification about a new data source,
		(represented object for the self.search object
		"""
		wid = self._widget_for_pane(pane)
		wid.set_source(source)
		wid.reset()
		if pane is data.SourcePane:
			self.switch_to_source()
			self.action.reset()
		if wid is self.current:
			self.toggle_text_mode(False)
			self._reset_to_toplevel = False
			if not at_root:
				self.reset_current(populate=True)
				wid.show_table()

	def _show_hide_third(self, ctr, mode, ignored):
		if mode is data.SourceActionObjectMode:
			# use a delay before showing the third pane,
			# but set internal variable to "shown" already now
			self._pane_three_is_visible = True
			self._ui_transition_timer.set_ms(200, self._show_third_pane, True)
		else:
			self._pane_three_is_visible = False
			self._show_third_pane(False)

	def _show_third_pane(self, show):
		self._ui_transition_timer.invalidate()
		self.third.set_property("visible", show)

	def _update_active(self):
		for panewidget in (self.action, self.search, self.third):
			if panewidget is not self.current:
				panewidget.set_state(gtk.STATE_NORMAL)
			panewidget.match_view.inject_preedit(None)
		if self._is_text_mode or self._key_repeat_active:
			self.current.set_state(gtk.STATE_ACTIVE)
		else:
			self.current.set_state(gtk.STATE_SELECTED)
			self.current.match_view.inject_preedit(self.preedit)
		self._description_changed()

	def switch_current(self, reverse=False):
		# Only allow switch if we have match
		order = [self.search, self.action]
		if self._pane_three_is_visible:
			order.append(self.third)
		curidx = order.index(self.current)
		newidx = curidx -1 if reverse else curidx +1
		newidx %= len(order)
		prev_pane = order[max(newidx -1, 0)]
		new_focus = order[newidx]
		if (prev_pane.get_match_state() is State.Match and
				new_focus is not self.current):
			self.current = new_focus
			# Use toggle_text_mode to reset
			self.toggle_text_mode(False)
			pane = self._pane_for_widget(new_focus)
			self._update_active()
			if self.data_controller.get_should_enter_text_mode(pane):
				self.toggle_text_mode_quick()

	def _browse_up(self):
		pane = self._pane_for_widget(self.current)
		return self.data_controller.browse_up(pane)

	def _browse_down(self, alternate=False):
		pane = self._pane_for_widget(self.current)
		self.data_controller.browse_down(pane, alternate=alternate)

	def _make_gui_ctx(self):
		timestamp = gtk.get_current_event_time()
		return uievents.gui_context_from_widget(timestamp, self._widget)

	def _activate(self, widget, current):
		self.data_controller.activate(ui_ctx=self._make_gui_ctx())

	def activate(self):
		"""Activate current selection (Run action)"""
		self._activate(None, None)

	def execute_file(self, filepath, display, timestamp):
		"""Execute a .kfcom file"""
		def _handle_error(exc_info):
			from kupfer import uiutils
			etype, exc, tb = exc_info
			if not uiutils.show_notification(unicode(exc), icon_name="kupfer"):
				raise
		ctxenv = uievents.gui_context_from_keyevent(timestamp, display)
		self.data_controller.execute_file(filepath, ctxenv, _handle_error)

	def _search_result(self, sender, pane, matchrankable, matches, context):
		# NOTE: "Always-matching" search.
		# If we receive an empty match, we ignore it, to retain the previous
		# results. The user is not served by being met by empty results.
		key = context
		if key and len(key) > 1 and matchrankable is None:
			# with typos or so, reset quicker
			self._latest_input_timer.set(self._slow_input_interval/2,
					self._relax_search_terms)
			return
		wid = self._widget_for_pane(pane)
		wid.update_match(key, matchrankable, matches)

	def _widget_for_pane(self, pane):
		return self.pane_to_widget[pane]
	def _pane_for_widget(self, widget):
		return self.widget_to_pane[id(widget)]

	def _object_stack_changed(self, controller, pane):
		"""
		Stack of objects (for comma trick) changed in @pane
		"""
		wid = self._widget_for_pane(pane)
		wid.set_object_stack(controller.get_object_stack(pane))

	def _panewidget_button_press(self, widget, event):
		" mouse clicked on a pane widget "
		# activate on double-click
		if event.type == gtk.gdk._2BUTTON_PRESS:
			self.activate()
			return True

	def _selection_changed(self, widget, match):
		pane = self._pane_for_widget(widget)
		self.data_controller.select(pane, match)
		if not widget is self.current:
			return
		self._description_changed()

	def _description_changed(self):
		match = self.current.get_current()
		desc = match and match.get_description() or ""
		markup = "<small>%s</small>" % (escape_markup_str(desc), )
		self.label.set_markup(markup)

	def put_text(self, text):
		"""
		Put @text into the interface to search, to use
		for "queries" from other sources
		"""
		self.try_enable_text_mode()
		self.entry.set_text(text)
		self.entry.set_position(-1)

	def put_files(self, fileuris):
		leaves = map(interface.get_fileleaf_for_path,
			filter(None, [gio.File(U).get_path() for U in fileuris]))
		if leaves:
			self.data_controller.insert_objects(data.SourcePane, leaves)

	def _reset_input_timer(self):
		# if input is slow/new, we reset
		self._latest_input_timer.set(self._slow_input_interval,
				self._relax_search_terms)

	def _preedit_im_changed(self, editable, preedit_string):
		"""
		This is called whenever the input method changes its own preedit box.
		We take this opportunity to expand it.
		"""
		if preedit_string:
			self.current.match_view.expand_preedit(self.preedit)
			self._reset_input_timer()

	def _preedit_changed(self, editable):
		"""
		The preedit has changed. As below, we need to use unicode.
		"""
		text = editable.get_text()
		text = text.decode("UTF-8")
		if text:
			self.entry.insert_text(text, -1)
			self.entry.set_position(-1)
			editable.delete_text(0, -1)
			# uncomment this to reset width after every commit.
			# self.current.match_view.shrink_preedit(self.preedit)
			self._reset_input_timer()
			self._update_active()

	def _changed(self, editable):
		"""
		The entry changed callback: Here we have to be sure to use
		**UNICODE** (unicode()) for the entered text
		"""
		# @text is UTF-8
		text = editable.get_text()
		text = text.decode("UTF-8")

		# draw character count as icon
		if self.get_in_text_mode() and text:
			w, h = editable.size_request()
			sz = h - 3
			c = editable.style.text[gtk.STATE_NORMAL]
			textc = (c.red/65535.0, c.green/65535.0, c.blue/65535.0)
			pb = get_glyph_pixbuf(str(len(text)), sz, color=textc)
			editable.set_icon_from_pixbuf(gtk.ENTRY_ICON_SECONDARY, pb)
		else:
			editable.set_icon_from_pixbuf(gtk.ENTRY_ICON_SECONDARY, None)

		# cancel search and return if empty
		if not text:
			self.data_controller.cancel_search()
			# See if it was a deleting key press
			curev = gtk.get_current_event()
			if (curev and curev.type == gtk.gdk.KEY_PRESS and
			    curev.keyval in (self.key_book["Delete"],
			        self.key_book["BackSpace"])):
				self._backspace_key_press()
			return

		# start search for updated query
		pane = self._pane_for_widget(self.current)
		if not self.get_in_text_mode() and self._reset_to_toplevel:
			self.soft_reset(pane)

		self.data_controller.search(pane, key=text, context=text,
				text_mode=self.get_in_text_mode())

gobject.type_register(Interface)
gobject.signal_new("cancelled", Interface, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN, ())
# Send only when the interface itself launched an action directly
gobject.signal_new("launched-action", Interface, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN, ())

class KupferWindow (gtk.Window):
	__gtype_name__ = "KupferWindow"
	def __init__(self, *args):
		super(KupferWindow, self).__init__(*args)
		self.connect("style-set", self.on_style_set)
		self.set_name("kupfer")
		self.connect("expose-event", self.on_expose_event)
		self.connect("size-allocate", self.on_size_allocate)
		self.connect("composited-changed", self.on_composited_changed)
		self.connect("realize", self.on_realize)
		self.set_app_paintable(True)

	def on_style_set(self, widget, old_style):
		widget.set_property('decorated',
				widget.style_get_property('decorated'))
		widget.set_property('border-width',
				widget.style_get_property('border-width'))

	def on_expose_event(self, widget, event):
		cr = widget.window.cairo_create()
		w,h = widget.allocation.width, widget.allocation.height

		region = gtk.gdk.region_rectangle(event.area)
		cr.region(region)
		cr.clip()

		def rgba_from_gdk(c, alpha):
			return (c.red/65535.0, c.green/65535.0, c.blue/65535.0, alpha)

		radius = widget.style_get_property('corner-radius')
		if widget.is_composited():
			opacity = 0.01*widget.style_get_property('opacity')
			#cr.set_operator(cairo.OPERATOR_CLEAR)
			cr.set_operator(cairo.OPERATOR_SOURCE)
			cr.set_source_rgba(0,0,0,0)
			cr.rectangle(0,0,w,h)
			cr.fill()
			#cr.rectangle(0,0,w,h)
			make_rounded_rect(cr, 0, 0, w, h, radius)
			cr.set_operator(cairo.OPERATOR_SOURCE)
			c = widget.style.bg[widget.get_state()]
			cr.set_source_rgba(*rgba_from_gdk(c, opacity))
			cr.fill()

		c = widget.style.dark[gtk.STATE_SELECTED]
		cr.set_operator(cairo.OPERATOR_OVER)
		cr.set_source_rgba(*rgba_from_gdk(c, 0.7))

		make_rounded_rect(cr, 0, 0, w, h, radius)
		cr.set_line_width(1)
		cr.stroke()

	def on_composited_changed(self, widget):
		self.reshape(widget, widget.get_allocation())

	def on_realize(self, widget):
		self.reshape(widget, widget.get_allocation())

	def on_size_allocate(self, widget, allocation):
		if not hasattr(self, "_old_alloc"):
			self._old_alloc = (0,0)
		w,h = allocation.width, allocation.height

		if self._old_alloc == (w,h):
			return
		self._old_alloc = (w,h)
		self.reshape(widget, allocation)

	def reshape(self, widget, allocation):
		## if not composited, use rounded window shape
		w,h = allocation.width, allocation.height
		radius = widget.style_get_property('corner-radius')
		if not widget.is_composited() and radius:
			bitmap = gtk.gdk.Pixmap(None, w, h, 1)
			cr = bitmap.cairo_create()

			cr.set_source_rgb(0.0, 0.0, 0.0)
			cr.set_operator(cairo.OPERATOR_CLEAR)
			cr.paint()

			# radius of rounded corner
			cr.set_source_rgb(1.0, 1.0, 1.0)
			cr.set_operator(cairo.OPERATOR_SOURCE)
			make_rounded_rect(cr, 0, 0, w, h, radius)
			cr.fill()
			widget.shape_combine_mask(bitmap, 0, 0)
		else:
			if widget.window:
				widget.window.shape_combine_mask(None, 0, 0)
		if widget.window:
			widget.window.invalidate_rect(gtk.gdk.Rectangle(0, 0, w, h), False)


gobject.type_register(KupferWindow)
gtk.widget_class_install_style_property(KupferWindow,
		('corner-radius', gobject.TYPE_INT, 'Corner radius',
		 'Radius of bezel around window',
		 0, 50, 15,
		 gobject.PARAM_READABLE))
gtk.widget_class_install_style_property(KupferWindow,
		('opacity', gobject.TYPE_INT, 'Frame opacity',
		 'Opacity of window background',
		 50, 100, 85,
		 gobject.PARAM_READABLE))
gtk.widget_class_install_style_property(KupferWindow,
		('decorated', gobject.TYPE_BOOLEAN, 'Decorated',
		 'Whether to use window decorations',
		 False,
		 gobject.PARAM_READABLE))

gtk.widget_class_install_style_property(KupferWindow,
		('border-width', gobject.TYPE_INT, 'Border width',
		 'Width of border around window content',
		 0, 100, 8,
		 gobject.PARAM_READABLE))

class WindowController (pretty.OutputMixin):
	"""
	This is the fundamental Window (and App) Controller
	"""
	def __init__(self):
		self.window = None
		self.current_screen_handler = 0
		self.current_screen = None
		self.interface = None
		self._statusicon = None
		self._window_hide_timer = scheduler.Timer()

	def initialize(self, data_controller):
		self.window = KupferWindow(gtk.WINDOW_TOPLEVEL)
		self.window.add_events(gtk.gdk.BUTTON_PRESS_MASK)

		#data_controller = data.DataController()
		data_controller.connect("launched-action", self.launch_callback)
		data_controller.connect("command-result", self.result_callback)

		self.interface = Interface(data_controller, self.window)
		self.interface.connect("launched-action", self.launch_callback)
		self.interface.connect("cancelled", self._cancelled)
		self._setup_window()

	def show_statusicon(self):
		if not self._statusicon:
			self._statusicon = self._setup_status_icon()
		try:
			self._statusicon.set_visible(True)
		except AttributeError:
			pass

	def hide_statusicon(self):
		if self._statusicon:
			try:
				self._statusicon.set_visible(False)
			except AttributeError:
				self._statusicon = None

	def _showstatusicon_changed(self, setctl, section, key, value):
		"callback from SettingsController"
		if value:
			self.show_statusicon()
		else:
			self.hide_statusicon()

	def _setup_menu(self, context_menu=False):
		menu = gtk.Menu()
		menu.set_name("kupfer-menu")

		def submenu_callback(menuitem, callback):
			callback()
			return True

		def add_menu_item(icon, callback, label=None, with_ctx=True):
			def mitem_handler(menuitem, callback):
				if with_ctx:
					time = gtk.get_current_event_time()
					ui_ctx = uievents.gui_context_from_widget(time, menuitem)
					callback(ui_ctx)
				else:
					callback()
				if context_menu:
					self.put_away()
				return True

			mitem = None
			if label and not icon:
				mitem = gtk.MenuItem(label=label)
			else:
				mitem = gtk.ImageMenuItem(icon)
			mitem.connect("activate", mitem_handler, callback)
			menu.append(mitem)

		if context_menu:
			add_menu_item(gtk.STOCK_CLOSE, self.put_away, with_ctx=False)
		else:
			add_menu_item(None, self.activate, _("Show Main Interface"))
		menu.append(gtk.SeparatorMenuItem())
		if context_menu:
			for name, func in self.interface.get_context_actions():
				mitem = gtk.MenuItem(label=name)
				mitem.connect("activate", submenu_callback, func)
				menu.append(mitem)
			menu.append(gtk.SeparatorMenuItem())

		add_menu_item(gtk.STOCK_PREFERENCES, kupferui.show_preferences)
		add_menu_item(gtk.STOCK_HELP, kupferui.show_help)
		add_menu_item(gtk.STOCK_ABOUT, kupferui.show_about_dialog)
		menu.append(gtk.SeparatorMenuItem())
		add_menu_item(gtk.STOCK_QUIT, self.quit, with_ctx=False)
		menu.show_all()

		return menu

	def _setup_status_icon(self):
		menu = self._setup_menu()
		try:
			import appindicator
		except ImportError:
			appindicator = None
		else:
			## make sure dbus is available, else appindicator crashes
			import dbus
			try:
				dbus.Bus()
			except dbus.DBusException:
				appindicator = None
		if appindicator:
			return self._setup_appindicator(menu)
		else:
			return self._setup_gtk_status_icon(menu)

	def _setup_gtk_status_icon(self, menu):
		status = gtk.status_icon_new_from_icon_name(version.ICON_NAME)
		status.set_tooltip(version.PROGRAM_NAME)

		status.connect("popup-menu", self._popup_menu, menu)
		status.connect("activate", self.show_hide)
		return status

	def _setup_appindicator(self, menu):
		import appindicator
		indicator = appindicator.Indicator(version.PROGRAM_NAME,
			version.ICON_NAME,
			appindicator.CATEGORY_APPLICATION_STATUS)
		indicator.set_status(appindicator.STATUS_ACTIVE)

		indicator.set_menu(menu)
		return indicator

	def _setup_window(self):
		"""
		Returns window
		"""

		self.window.connect("delete-event", self._close_window)
		self.window.connect("focus-out-event", self._lost_focus)
		self.window.connect("button-press-event", self._window_frame_clicked)
		widget = self.interface.get_widget()
		widget.show()

		# Build the window frame with its top bar
		topbar = gtk.HBox()
		vbox = gtk.VBox()
		vbox.pack_start(topbar, False, False)
		vbox.pack_start(widget, True, True)
		vbox.show()
		self.window.add(vbox)
		title = gtk.Label(u"")
		button = gtk.Label(u"")
		l_programname = version.PROGRAM_NAME.lower()
		# The text on the general+context menu button
		btext = u"<b>%s \N{GEAR}</b>" % (l_programname, )
		button.set_markup(btext)
		button_box = gtk.EventBox()
		button_box.set_visible_window(False)
		button_adj = gtk.Alignment(0.5, 0.5, 0, 0)
		button_adj.set_padding(0, 2, 0, 3)
		button_adj.add(button)
		button_box.add(button_adj)
		button_box.connect("button-press-event", self._context_clicked)
		button_box.connect("enter-notify-event", self._button_enter,
						   button, btext)
		button_box.connect("leave-notify-event", self._button_leave,
						   button, btext)
		button.set_name("kupfer-menu-button")
		title_align = gtk.Alignment(0, 0.5, 0, 0)
		title_align.add(title)
		topbar.pack_start(title_align, True, True)
		topbar.pack_start(button_box, False, False)
		topbar.show_all()

		self.window.set_title(version.PROGRAM_NAME)
		self.window.set_icon_name(version.ICON_NAME)
		self.window.set_type_hint(gtk.gdk.WINDOW_TYPE_HINT_UTILITY)
		self.window.set_property("skip-taskbar-hint", True)
		self.window.set_keep_above(True)

		if not text_direction_is_ltr():
			self.window.set_gravity(gtk.gdk.GRAVITY_NORTH_EAST)
		# Setting not resizable changes from utility window
		# on metacity
		self.window.set_resizable(False)

	def _window_frame_clicked(self, widget, event):
		"Start drag when the window is clicked"
		widget.begin_move_drag(event.button,
				int(event.x_root), int(event.y_root), event.time)

	def _context_clicked(self, widget, event):
		"The context menu label was clicked"
		menu = self._setup_menu(True)
		menu.set_screen(self.window.get_screen())
		menu.popup(None, None, None, event.button, event.time)
		return True

	def _button_enter(self, widget, event, button, udata):
		"Pointer enters context menu button"
		button.set_markup("<u>" + udata + "</u>")

	def _button_leave(self, widget, event, button, udata):
		"Pointer leaves context menu button"
		button.set_markup(udata)

	def _popup_menu(self, status_icon, button, activate_time, menu):
		"""
		When the StatusIcon is right-clicked
		"""
		menu.popup(None, None, gtk.status_icon_position_menu, button, activate_time, status_icon)

	def launch_callback(self, sender):
		# Separate window hide from the action being
		# done. This is to solve a window focus bug when
		# we switch windows using an action
		self.interface.did_launch()
		self._window_hide_timer.set_ms(100, self.put_away)

	def result_callback(self, sender, result_type, ui_ctx):
		if ui_ctx:
			self.on_present(sender, ui_ctx.get_display(), ui_ctx.get_timestamp())
		else:
			self.on_present(sender, "", gtk.get_current_event_time())

	def _lost_focus(self, window, event):
		# Close at unfocus.
		# Since focus-out-event is triggered even
		# when we click inside the window, we'll
		# do some additional math to make sure that
		# that window won't close if the mouse pointer
		# is over it.
		x, y, mods = window.get_screen().get_root_window().get_pointer()
		w_x, w_y = window.get_position()
		w_w, w_h = window.get_size()
		if (x not in xrange(w_x, w_x + w_w) or
			y not in xrange(w_y, w_y + w_h)):
			self._window_hide_timer.set_ms(50, self.put_away)

	def _monitors_changed(self, *ignored):
		self._center_window()

	def is_current_display(self, displayname):
		def norm_name(name):
			"Make :0.0 out of :0"
			if name[-2] == ":":
				return name + ".0"
			return name
		if not self.window.has_screen():
			return False
		cur_disp = self.window.get_screen().get_display().get_name()
		return norm_name(cur_disp) == norm_name(displayname)

	def _window_put_on_screen(self, screen):
		if self.current_screen_handler:
			scr = self.window.get_screen()
			scr.disconnect(self.current_screen_handler)
		rgba = screen.get_rgba_colormap()
		if rgba:
			self.window.unrealize()
			self.window.set_screen(screen)
			self.window.set_colormap(rgba)
			self.window.realize()
		else:
			self.window.set_screen(screen)
		self.current_screen_handler = \
			screen.connect("monitors-changed", self._monitors_changed)
		self.current_screen = screen

	def _center_window(self, displayname=None):
		"""Center Window on the monitor the pointer is currently on"""
		def norm_name(name):
			"Make :0.0 out of :0"
			if name[-2] == ":":
				return name + ".0"
			return name
		if not displayname and self.window.has_screen():
			display = self.window.get_display()
		else:
			display = uievents.GUIEnvironmentContext.ensure_display_open(displayname)
		screen, x, y, modifiers = display.get_pointer()
		self._window_put_on_screen(screen)
		monitor_nr = screen.get_monitor_at_point(x, y)
		geo = screen.get_monitor_geometry(monitor_nr)
		wid, hei = self.window.get_size()
		midx = geo.x + geo.width / 2 - wid / 2
		midy = geo.y + geo.height / 2 - hei / 2
		self.window.move(midx, midy)
		uievents.GUIEnvironmentContext._try_close_unused_displays(screen)

	def _should_recenter_window(self):
		"""Return True if the mouse pointer and the window
		are on different monitors.
		"""
		# Check if the GtkWindow was realized yet
		if not self.window.window:
			return True
		display = self.window.get_screen().get_display()
		screen, x, y, modifiers = display.get_pointer()
		return (screen.get_monitor_at_point(x,y) !=
		        screen.get_monitor_at_window(self.window.window))

	def activate(self, sender=None):
		dispname = self.window.get_screen().make_display_name()
		self.on_present(sender, dispname, gtk.get_current_event_time())

	def on_present(self, sender, display, timestamp):
		"""Present on @display, where None means default display"""
		self._window_hide_timer.invalidate()
		if not display:
			display = gtk.gdk.display_get_default().get_name()
		if (self._should_recenter_window() or
		    not self.is_current_display(display)):
			self._center_window(display)
		self.window.stick()
		self.window.present_with_time(timestamp)
		self.window.window.focus(timestamp=timestamp)
		self.interface.focus()

	def put_away(self):
		self.interface.put_away()
		self.window.hide()

	def _cancelled(self, widget):
		self.put_away()

	def on_show_hide(self, sender, display, timestamp):
		"""
		Toggle activate/put-away
		"""
		if self.window.get_property("visible"):
			self.put_away()
		else:
			self.on_present(sender, display, timestamp)

	def show_hide(self, sender):
		"GtkStatusIcon callback"
		self.on_show_hide(sender, "", gtk.get_current_event_time())

	def _key_binding(self, keyobj, keybinding_number, display, timestamp):
		"""Keybinding activation callback"""
		if keybinding_number == keybindings.KEYBINDING_DEFAULT:
			self.on_show_hide(keyobj, display, timestamp)
		elif keybinding_number == keybindings.KEYBINDING_MAGIC:
			self.on_present(keyobj, display, timestamp)
			self.interface.select_selected_text()
			self.interface.select_selected_file()

	def on_put_text(self, sender, text, display, timestamp):
		"""We got a search text from dbus"""
		self.on_present(sender, display, timestamp)
		self.interface.put_text(text)

	def on_put_files(self, sender, fileuris, display, timestamp):
		self.on_present(sender, display, timestamp)
		self.interface.put_files(fileuris)

	def on_execute_file(self, sender, filepath, display, timestamp):
		self.interface.execute_file(filepath, display, timestamp)

	def _close_window(self, window, event):
		self.put_away()
		return True

	def _destroy(self, widget, data=None):
		self.quit()

	def _sigterm(self, signal, frame):
		self.output_info("Caught signal", signal, "exiting..")
		self.quit()

	def _on_early_interrupt(self, signal, frame):
		sys.exit(1)

	def save_data(self):
		"""Save state before quit"""
		sch = scheduler.GetScheduler()
		sch.finish()

	def quit(self, sender=None):
		gtk.main_quit()

	def quit_now(self):
		"""Quit immediately (state save should already be done)"""
		raise SystemExit

	def _session_save(self, *args):
		"""Old-style session save callback.
		ret True on successful
		"""
		# No quit, only save
		self.output_info("Saving for logout...")
		self.save_data()
		return True

	def _session_die(self, *args):
		"""Session callback on session end
		quit now, without saving, since we already do that on
		Session save!
		"""
		self.quit_now()

	def lazy_setup(self):
		"""Do all setup that can be done after showing main interface.
		Connect to desktop services (keybinding callback, session logout
		callbacks etc).
		"""
		from kupfer.ui import session

		self.output_debug("in lazy_setup")

		setctl = settings.GetSettingsController()
		if setctl.get_show_status_icon():
			self.show_statusicon()
		setctl.connect("value-changed::kupfer.showstatusicon",
		               self._showstatusicon_changed)
		keystr = setctl.get_keybinding()
		magickeystr = setctl.get_magic_keybinding()

		if keystr:
			succ = keybindings.bind_key(keystr)
			self.output_info("Trying to register %s to spawn kupfer.. %s"
					% (keystr, "success" if succ else "failed"))


		if magickeystr:
			succ = keybindings.bind_key(magickeystr,
					keybindings.KEYBINDING_MAGIC)
			self.output_debug("Trying to register %s to spawn kupfer.. %s"
					% (magickeystr, "success" if succ else "failed"))
		keyobj = keybindings.GetKeyboundObject()
		keyobj.connect("keybinding", self._key_binding)

		signal.signal(signal.SIGINT, self._sigterm)
		signal.signal(signal.SIGTERM, self._sigterm)
		signal.signal(signal.SIGHUP, self._sigterm)

		client = session.SessionClient()
		client.connect("save-yourself", self._session_save)
		client.connect("die", self._session_die)

		self.output_debug("finished lazy_setup")

	def main(self, quiet=False):
		"""Start WindowController, present its window (if not @quiet)"""
		signal.signal(signal.SIGINT, self._on_early_interrupt)

		try:
			kserv = listen.Service()
		except listen.AlreadyRunningError:
			self.output_info("An instance is already running, exiting...")
			self.quit_now()
		except listen.NoConnectionError:
			kserv = None
		else:
			keyobj = keybindings.GetKeyboundObject()
			keyobj.connect("bound-key-changed",
			               lambda x,y,z: kserv.BoundKeyChanged(y,z))
			kserv.connect("relay-keys", keyobj.relayed_keys)

		# Load data
		data_controller = data.DataController()
		sch = scheduler.GetScheduler()
		sch.load()
		# Now create UI and display
		self.initialize(data_controller)
		sch.display()

		if kserv:
			kserv.connect("present", self.on_present)
			kserv.connect("show-hide", self.on_show_hide)
			kserv.connect("put-text", self.on_put_text)
			kserv.connect("put-files", self.on_put_files)
			kserv.connect("execute-file", self.on_execute_file)
			kserv.connect("quit", self.quit)

		if not quiet:
			self.activate()
		gobject.idle_add(self.lazy_setup)

		def do_main_iterations(max_events=0):
			# use sentinel form of iter
			for idx, pending in enumerate(iter(gtk.events_pending, False)):
				if max_events and idx > max_events:
					break
				gtk.main_iteration()

		try:
			gtk.main()
			# put away window *before exiting further*
			self.put_away()
			do_main_iterations(10)
		finally:
			self.save_data()

		# tear down but keep hanging
		if kserv:
			kserv.unregister()
		keybindings.bind_key(None, keybindings.KEYBINDING_DEFAULT)
		keybindings.bind_key(None, keybindings.KEYBINDING_MAGIC)

		do_main_iterations(100)
		# if we are still waiting, print a message
		if gtk.events_pending():
			self.output_info("Waiting for tasks to finish...")
			do_main_iterations()

########NEW FILE########
__FILENAME__ = credentials_dialog
import gtk

from kupfer import version, config, kupferstring

class CredentialsDialogController():
	def __init__(self, username, password, infotext=None):
		"""Load ui from data file"""
		builder = gtk.Builder()
		builder.set_translation_domain(version.PACKAGE_NAME)
		ui_file = config.get_data_file("credentials_dialog.ui")
		builder.add_from_file(ui_file)
		builder.connect_signals(self)

		self.window = builder.get_object("credentials_dialog")
		self.entry_user = builder.get_object('entry_username')
		self.entry_pass = builder.get_object('entry_password')
		if infotext:
			hbox_information = builder.get_object('hbox_information')
			label_information = builder.get_object('label_information')
			hbox_information.show()
			label_information.set_text(infotext)

		self.entry_user.set_text(username or '')
		self.entry_pass.set_text(password or '')

	def on_button_ok_clicked(self, widget):
		self.window.response(gtk.RESPONSE_ACCEPT)
		self.window.hide()

	def on_button_cancel_clicked(self, widget):
		self.window.response(gtk.RESPONSE_CANCEL)
		self.window.hide()

	def show(self):
		return self.window.run()

	@property
	def username(self):
		return kupferstring.tounicode(self.entry_user.get_text())

	@property
	def password(self):
		return kupferstring.tounicode(self.entry_pass.get_text())


def ask_user_credentials(user=None, password=None, infotext=None):
	''' Ask user for username and password.
	
	@user, @password - initial values
	@return:
	(user, password) when user press "change"
	None when user press "cancel" button '''
	dialog = CredentialsDialogController(user, password, infotext)
	result = None
	if dialog.show() == gtk.RESPONSE_ACCEPT:
		result = dialog.username, dialog.password
	return result


########NEW FILE########
__FILENAME__ = getkey_dialog

import gtk

from kupfer import version, config


class GetKeyDialogController(object):
	def __init__(self, check_callback=None, previous_key=None, screen=None):
		'''@check_callback - optional function to check is entered key is valid.
		@previous_key - optional previous keybinding, press equal act like cancel'''
		builder = gtk.Builder()
		builder.set_translation_domain(version.PACKAGE_NAME)

		ui_file = config.get_data_file("getkey_dialog.ui")
		builder.add_from_file(ui_file)
		builder.connect_signals(self)
		self.window = builder.get_object("dialoggetkey")
		self.labelkey = builder.get_object('labelkey')
		self.imagekeybindingaux = builder.get_object('imagekeybindingaux')
		self.labelkeybindingaux = builder.get_object('labelkeybindingaux')
		self.labelaccelerator = builder.get_object('labelaccelerator')

		self.imagekeybindingaux.hide()
		self.labelkeybindingaux.hide()

		self._key = None
		self._check_callback = check_callback
		self._previous_key = previous_key
		self._press_time = None

		if screen:
			self.window.set_screen(screen)
		self.window.connect("focus-in-event", self.on_window_focus_in)
		self.window.connect("focus-out-event", self.on_window_focus_out)

	def run(self):
		''' Run dialog, return key codes or None when user press cancel'''
		self.window.set_keep_above(True)
		self.window.run()
		self.window.destroy()
		return self._key

	def _return(self, key):
		" Finish dialog with @key as result"
		self._key = key
		self.window.hide()

	def on_buttoncancel_activate(self, _widget):
		self._return(None)

	def translate_keyboard_event(self, widget, event):
		keymap = gtk.gdk.keymap_get_for_display(widget.get_display())
		# translate keys properly
		keyval, egroup, level, consumed = keymap.translate_keyboard_state(
					event.hardware_keycode, event.state, event.group)
		modifiers = gtk.accelerator_get_default_mod_mask() & ~consumed

		state = event.state & modifiers

		return keyval, state

	def update_accelerator_label(self, keyval, state):
		accel_label = gtk.accelerator_get_label(keyval, state)
		self.labelaccelerator.set_text(accel_label)

	def on_dialoggetkey_key_press_event(self, widget, event):
		self.imagekeybindingaux.hide()
		self.labelkeybindingaux.hide()
		self._press_time = event.time

		keyval, state = self.translate_keyboard_event(widget, event)
		keyname = gtk.accelerator_name(keyval, state)
		if keyname == 'Escape':
			self._return(None)
		elif keyname == 'BackSpace':
			self._return('')
		self.update_accelerator_label(keyval, state)

	def on_dialoggetkey_key_release_event(self, widget, event):
		if not self._press_time:
			return
		keyval, state = self.translate_keyboard_event(widget, event)
		self.update_accelerator_label(0, 0)

		if gtk.accelerator_valid(keyval, state):
			key = gtk.accelerator_name(keyval, state)
			if (self._previous_key is not None and
					key == self._previous_key):
				self._return(None)
				return
			if self._check_callback is None or self._check_callback(key):
				self._return(key)
			else:
				self.imagekeybindingaux.show()
				self.labelkeybindingaux.show()


	def on_window_focus_in(self, window, _event):
		pass

	def on_window_focus_out(self, _window, _event):
		pass


def ask_for_key(check_callback=None, previous_key=None, screen=None):
	dlg = GetKeyDialogController(check_callback, previous_key, screen)
	result = dlg.run()
	return result

########NEW FILE########
__FILENAME__ = keybindings
import gobject

from kupfer import pretty

KEYBINDING_DEFAULT = 1
KEYBINDING_MAGIC = 2

KEYRANGE_RESERVED = (3, 0x1000)
KEYRANGE_TRIGGERS = (0x1000, 0x2000)

_keybound_object = None
def GetKeyboundObject():
	"""Get the shared instance"""
	global _keybound_object
	if not _keybound_object:
		_keybound_object = KeyboundObject()
	return _keybound_object

class KeyboundObject (gobject.GObject):
	"""Keybinder object

	signals:
		keybinding (target, event_time)
		keybinding signal is triggered when the key bound
		for @target is triggered.
	"""
	__gtype_name__ = "KeyboundObject"
	def __init__(self):
		super(KeyboundObject, self).__init__()
	def _keybinding(self, target):
		import keybinder
		time = keybinder.get_current_event_time()
		self.emit("keybinding", target, "", time)
	def emit_bound_key_changed(self, keystring, is_bound):
		self.emit("bound-key-changed", keystring, is_bound)
	def relayed_keys(self, sender, keystring, display, timestamp):
		for target, key in _currently_bound.iteritems():
			if keystring == key:
				self.emit("keybinding", target, display, timestamp)

# Arguments: Target, Display, Timestamp
gobject.signal_new("keybinding", KeyboundObject, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN,
		(gobject.TYPE_INT, gobject.TYPE_STRING, gobject.TYPE_UINT))
# Arguments: Keystring, Boolean
gobject.signal_new("bound-key-changed", KeyboundObject, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN,
		(gobject.TYPE_STRING, gobject.TYPE_BOOLEAN,))

_currently_bound = {}

def get_all_bound_keys():
	return filter(bool, _currently_bound.values())

def get_current_event_time():
	"Return current event time as given by keybinder"
	try:
		import keybinder
	except ImportError:
		return 0
	return keybinder.get_current_event_time()

def _register_bound_key(keystr, target):
	_currently_bound[target] = keystr

def get_currently_bound_key(target=KEYBINDING_DEFAULT):
	return _currently_bound.get(target)

def bind_key(keystr, keybinding_target=KEYBINDING_DEFAULT):
	"""
	Bind @keystr, unbinding any previous key for @keybinding_target.
	If @keystr is a false value, any previous key will be unbound.
	"""
	try:
		import keybinder
	except ImportError:
		pretty.print_error(__name__, "Could not import keybinder, "
				"keybindings disabled!")
		return False

	keybinding_target = int(keybinding_target)
	callback = lambda : GetKeyboundObject()._keybinding(keybinding_target)
	if not _is_sane_keybinding(keystr):
		pretty.print_error(__name__, "Refusing to bind key", repr(keystr))
		return False

	succ = True
	if keystr:
		try:
			succ = keybinder.bind(keystr, callback)
			pretty.print_debug(__name__, "binding", repr(keystr))
			GetKeyboundObject().emit_bound_key_changed(keystr, True)
		except KeyError, exc:
			pretty.print_error(__name__, exc)
			succ = False
	if succ:
		old_keystr = get_currently_bound_key(keybinding_target)
		if old_keystr and old_keystr != keystr:
			keybinder.unbind(old_keystr)
			pretty.print_debug(__name__, "unbinding", repr(old_keystr))
			GetKeyboundObject().emit_bound_key_changed(old_keystr, False)
		_register_bound_key(keystr, keybinding_target)
	return succ


def _is_sane_keybinding(keystr):
	"Refuse keys that we absolutely do not want to bind"
	if keystr is None:
		return True
	if len(keystr) == 1 and keystr.isalnum():
		return False
	if keystr in set(["Return", "space", "BackSpace", "Escape"]):
		return False
	return True

########NEW FILE########
__FILENAME__ = listen
"""
This module has a singleton Service for dbus callbacks,
and ensures there is only one unique service in the Session
"""

import gobject

try:
	import dbus
	import dbus.glib
	import dbus.service
	from kupfer.dbuscompat import ExportedGObject

	dbus.glib.threads_init()

# if dbus unavailable print the exception here
# but further actions (register) will fail without warning
	session_bus = dbus.Bus()
except (ImportError, dbus.exceptions.DBusException), exc:
	session_bus = None
	print exc

from kupfer.ui import uievents

class AlreadyRunningError (Exception):
	"""Service already available on the bus Exception"""
	pass

class NoConnectionError (Exception):
	"""Not possible to establish connection
	for callbacks"""
	pass

server_name = "se.kaizer.kupfer"
interface_name = "se.kaizer.kupfer.Listener"
object_name = "/interface"

class Service (ExportedGObject):
	def __init__(self):
		"""Create a new Kupfer service on the Session Bus

		Raises NoConnectionError, AlreadyRunningError
		"""
		if not session_bus:
			raise NoConnectionError
		if session_bus.name_has_owner(server_name):
			raise AlreadyRunningError
		bus_name = dbus.service.BusName(server_name, bus=session_bus)
		super(Service, self).__init__(conn=session_bus, object_path=object_name,
				bus_name=bus_name)

	def unregister(self):
		if session_bus:
			session_bus.release_name(server_name)

	@dbus.service.method(interface_name)
	def Present(self):
		self.PresentOnDisplay("", "")

	@dbus.service.method(interface_name, in_signature="ay",
	                     byte_arrays=True)
	def PresentWithStartup(self, notify_id):
		self.PresentOnDisplay("", notify_id)

	@dbus.service.method(interface_name, in_signature="ayay",
	                     byte_arrays=True)
	def PresentOnDisplay(self, display, notify_id):
		with uievents.using_startup_notify_id(notify_id) as time:
			self.emit("present", display, time)

	@dbus.service.method(interface_name)
	def ShowHide(self):
		self.emit("show-hide", "", 0)

	@dbus.service.method(interface_name, in_signature="s")
	def PutText(self, text):
		self.PutTextOnDisplay(text, "", "")

	@dbus.service.method(interface_name, in_signature="sayay",
	                     byte_arrays=True)
	def PutTextOnDisplay(self, text, display, notify_id):
		with uievents.using_startup_notify_id(notify_id) as time:
			self.emit("put-text", text, display, time)

	@dbus.service.method(interface_name, in_signature="as")
	def PutFiles(self, fileuris):
		self.PutFilesOnDisplay(fileuris, "", "")

	@dbus.service.method(interface_name, in_signature="asayay",
	                     byte_arrays=True)
	def PutFilesOnDisplay(self, fileuris, display, notify_id):
		# files sent with dbus-send from kupfer have a custom comma
		# escape that we have to unescape here
		fileuris[:] = [f.replace("%%kupfercomma%%", ",") for f in fileuris]
		with uievents.using_startup_notify_id(notify_id) as time:
			self.emit("put-files", fileuris, display, time)

	@dbus.service.method(interface_name, in_signature="s")
	def ExecuteFile(self, filepath):
		self.ExecuteFileOnDisplay(filepath, "", "")

	@dbus.service.method(interface_name, in_signature="sayay",
	                     byte_arrays=True)
	def ExecuteFileOnDisplay(self, filepath, display, notify_id):
		with uievents.using_startup_notify_id(notify_id) as time:
			self.emit("execute-file", filepath, display, time)

	@dbus.service.method(interface_name, in_signature="sayay",
	                     byte_arrays=True)
	def RelayKeysFromDisplay(self, keystring, display, notify_id):
		with uievents.using_startup_notify_id(notify_id) as time:
			self.emit("relay-keys", keystring, display, time)

	@dbus.service.method(interface_name, in_signature=None,
	                     out_signature="as",
	                     byte_arrays=True)
	def GetBoundKeys(self):
		from kupfer.ui import keybindings
		return keybindings.get_all_bound_keys()

	@dbus.service.signal(interface_name, signature="sb")
	def BoundKeyChanged(self, keystr, is_bound):
		pass

	@dbus.service.method(interface_name)
	def Quit(self):
		self.emit("quit")

# Signature: displayname, timestamp
gobject.signal_new("present", Service, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN, (gobject.TYPE_STRING, gobject.TYPE_UINT))

# Signature: displayname, timestamp
gobject.signal_new("show-hide", Service, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN, (gobject.TYPE_STRING, gobject.TYPE_UINT))

# Signature: text, displayname, timestamp
gobject.signal_new("put-text", Service, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN,
		(gobject.TYPE_STRING, gobject.TYPE_STRING, gobject.TYPE_UINT))

# Signature: filearray, displayname, timestamp
gobject.signal_new("put-files", Service, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN,
		(gobject.TYPE_PYOBJECT, gobject.TYPE_STRING, gobject.TYPE_UINT))

# Signature: fileuri, displayname, timestamp
gobject.signal_new("execute-file", Service, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN,
		(gobject.TYPE_STRING, gobject.TYPE_STRING, gobject.TYPE_UINT))

# Signature: ()
gobject.signal_new("quit", Service, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN, ())

# Signature: keystring, displayname, timestamp
gobject.signal_new("relay-keys", Service, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN,
		(gobject.TYPE_STRING, gobject.TYPE_STRING, gobject.TYPE_UINT))



########NEW FILE########
__FILENAME__ = preferences
import os
import re

import gtk
import gio
import gobject
import pango
from xdg import BaseDirectory as base
from xdg import DesktopEntry as desktop
from xdg import Exceptions as xdg_e


from kupfer import config, pretty, utils, icons, version
from kupfer import scheduler, kupferstring
from kupfer import kupferui
from kupfer.core import settings, plugins, relevance, sources
from kupfer.ui import keybindings
from kupfer.ui.credentials_dialog import ask_user_credentials
from kupfer.ui import getkey_dialog
from kupfer.ui import accelerators
from kupfer import plugin_support

# index in GtkNotebook
PLUGIN_LIST_PAGE = 2

# List icon pixel size
LIST_ICON_SIZE = 18

# A major HACK
# http://tadeboro.blogspot.com/2009/05/wrapping-adn-resizing-gtklabel.html
def _cb_allocate(label, allocation, maxwid):
	if maxwid == -1:
		maxwid = 300
	label.set_size_request(min(maxwid, allocation.width), -1)
	pass

def wrapped_label(text=None, maxwid=-1):
	label = gtk.Label(text)
	label.set_line_wrap(True)
	label.connect("size-allocate", _cb_allocate, maxwid)
	return label

def kobject_should_show(obj):
	try:
		leaf_repr = obj.get_leaf_repr()
	except AttributeError:
		pass
	else:
		if leaf_repr is None:
			return True
		if hasattr(leaf_repr, "is_valid") and not leaf_repr.is_valid():
			return False
	return True

class PreferencesWindowController (pretty.OutputMixin):

	KEYBINDING_NAMES = {
		# TRANS: Names of global keyboard shortcuts
		'keybinding': _("Show Main Interface"),
		'magickeybinding': _("Show with Selection"),
	}

	KEYBINDING_TARGETS = {
		"keybinding": keybindings.KEYBINDING_DEFAULT,
		"magickeybinding": keybindings.KEYBINDING_MAGIC,
	}


	def __init__(self):
		"""Load ui from data file"""
		builder = gtk.Builder()
		builder.set_translation_domain(version.PACKAGE_NAME)
		ui_file = config.get_data_file("preferences.ui")

		if ui_file:
			builder.add_from_file(ui_file)
		else:
			self.window = None
			return
		builder.connect_signals(self)
		self.window = builder.get_object("preferenceswindow")
		self.window.set_position(gtk.WIN_POS_CENTER)
		self.window.connect("delete-event", self._close_window)
		self.pluglist_parent = builder.get_object("plugin_list_parent")
		self.dirlist_parent = builder.get_object("directory_list_parent")
		self.plugin_about_parent = builder.get_object("plugin_about_parent")
		self.preferences_notebook = builder.get_object("preferences_notebook")

		self.buttonremovedirectory = builder.get_object("buttonremovedirectory")
		checkautostart = builder.get_object("checkautostart")
		checkstatusicon = builder.get_object("checkstatusicon")
		checkusecommandkeys = builder.get_object("checkusecommandkeys")
		self.entry_plugins_filter = builder.get_object('entry_plugins_filter')
		self.keybindings_list_parent = builder.get_object('keybindings_list_parent')
		self.gkeybindings_list_parent = builder.get_object('gkeybindings_list_parent')
		source_list_parent = builder.get_object("source_list_parent")
		self.sources_list_ctrl = SourceListController(source_list_parent)

		setctl = settings.GetSettingsController()
		checkautostart.set_active(self._get_should_autostart())
		checkstatusicon.set_active(setctl.get_show_status_icon())
		checkusecommandkeys.set_active(setctl.get_use_command_keys())

		# List store with columns (Name, ID) 
		# Make alternative comboboxes
		terminal_combobox = builder.get_object("terminal_combobox")
		icons_combobox = builder.get_object("icons_combobox")

		def make_combobox_model(combobox):
			combobox_store = gtk.ListStore(gobject.TYPE_STRING,
			                               gobject.TYPE_STRING)
			combobox.set_model(combobox_store)
			combobox_cell = gtk.CellRendererText()
			combobox.pack_start(combobox_cell, True)
			combobox.add_attribute(combobox_cell, 'text', 0)

		make_combobox_model(terminal_combobox)
		make_combobox_model(icons_combobox)

		self._update_alternative_combobox('terminal', terminal_combobox)
		self._update_alternative_combobox('icon_renderer', icons_combobox)
		self.terminal_combobox = terminal_combobox
		self.icons_combobox = icons_combobox
		setctl.connect("alternatives-changed", self._on_alternatives_changed)


		# Plugin List
		columns = [
			{"key": "plugin_id", "type": str },
			{"key": "enabled", "type": bool },
			{"key": "icon-name", "type": str },
			{"key": "text", "type": str },
		]
		# setup plugin list table
		column_types = [c["type"] for c in columns]
		self.columns = [c["key"] for c in columns]
		self.store = gtk.ListStore(*column_types)
		self.table = gtk.TreeView(self.store)
		self.table.set_headers_visible(False)
		self.table.set_property("enable-search", False)
		self.table.set_rules_hint(True)
		self.table.connect("cursor-changed", self.plugin_table_cursor_changed)
		self.table.get_selection().set_mode(gtk.SELECTION_BROWSE)

		checkcell = gtk.CellRendererToggle()
		checkcol = gtk.TreeViewColumn("item", checkcell)
		checkcol.add_attribute(checkcell, "active",
				self.columns.index("enabled"))
		checkcell.connect("toggled", self.on_checkplugin_toggled)

		icon_cell = gtk.CellRendererPixbuf()
		icon_cell.set_property("height", LIST_ICON_SIZE)
		icon_cell.set_property("width", LIST_ICON_SIZE)

		icon_col = gtk.TreeViewColumn("icon", icon_cell)
		icon_col.add_attribute(icon_cell, "icon-name",
				self.columns.index("icon-name"))

		cell = gtk.CellRendererText()
		col = gtk.TreeViewColumn("item", cell)
		col.add_attribute(cell, "text", self.columns.index("text"))

		self.table.append_column(checkcol)
		# hide icon for now
		#self.table.append_column(icon_col)
		self.table.append_column(col)

		self.plugin_list_timer = scheduler.Timer()
		self.plugin_info = utils.locale_sort(plugins.get_plugin_info(),
				key= lambda rec: rec["localized_name"])
		self._refresh_plugin_list()
		self.output_debug("Standard Plugins: %d" % len(self.store))
		self.table.show()
		self.pluglist_parent.add(self.table)

		# Directory List
		self.dir_store = gtk.ListStore(str, gio.Icon, str)
		self.dir_table = gtk.TreeView(self.dir_store)
		self.dir_table.set_headers_visible(False)
		self.dir_table.set_property("enable-search", False)
		self.dir_table.connect("cursor-changed", self.dir_table_cursor_changed)
		self.dir_table.get_selection().set_mode(gtk.SELECTION_BROWSE)

		icon_cell = gtk.CellRendererPixbuf()

		icon_col = gtk.TreeViewColumn("icon", icon_cell)
		icon_col.add_attribute(icon_cell, "gicon", 1)

		cell = gtk.CellRendererText()
		col = gtk.TreeViewColumn("name", cell)
		col.add_attribute(cell, "text", 2)
		cell.set_property("ellipsize", pango.ELLIPSIZE_END)
		self.dir_table.append_column(icon_col)
		self.dir_table.append_column(col)
		self.dir_table.show()
		self.dirlist_parent.add(self.dir_table)
		self.read_directory_settings()

		# keybindings list
		self.keybind_table, self.keybind_store = _create_conf_keys_list()
		self.keybindings_list_parent.add(self.keybind_table)
		self.keybind_table.connect("row-activated", self.on_keybindings_row_activate)
		# global keybindings list
		self.gkeybind_table, self.gkeybind_store = _create_conf_keys_list()
		self.gkeybindings_list_parent.add(self.gkeybind_table)
		self.gkeybind_table.connect("row-activated",
				self.on_gkeybindings_row_activate)

		self._show_keybindings(setctl)
		self._show_gkeybindings(setctl)

	def _show_keybindings(self, setctl):
		names = self.KEYBINDING_NAMES
		self.keybind_store.clear()
		for binding in sorted(names, key=lambda k: names[k]):
			accel = setctl.get_global_keybinding(binding) or ""
			label = gtk.accelerator_get_label(*gtk.accelerator_parse(accel))
			self.keybind_store.append((names[binding], label, binding))

	def _show_gkeybindings(self, setctl):
		names = accelerators.ACCELERATOR_NAMES
		self.gkeybind_store.clear()
		for binding in sorted(names, key=lambda k: names[k]):
			accel = setctl.get_accelerator(binding) or ""
			label = gtk.accelerator_get_label(*gtk.accelerator_parse(accel))
			self.gkeybind_store.append((names[binding], label, binding))

	def read_directory_settings(self):
		setctl = settings.GetSettingsController()
		dirs = setctl.get_directories()
		for d in dirs:
			self.add_directory_model(d, store=False)

	def add_directory_model(self, d, store=False):
		have = list(os.path.normpath(row[0]) for row in self.dir_store)
		if d in have:
			self.output_debug("Ignoring duplicate directory: ", d)
			return
		else:
			have.append(d)

		d = os.path.expanduser(d)
		dispname = utils.get_display_path_for_bytestring(d)
		gicon = icons.get_gicon_for_file(d)
		self.dir_store.append((d, gicon, dispname))

		if store:
			setctl = settings.GetSettingsController()
			setctl.set_directories(have)

	def remove_directory_model(self, rowiter, store=True):
		self.dir_store.remove(rowiter)
		if store:
			have = list(os.path.normpath(row[0]) for row in self.dir_store)
			setctl = settings.GetSettingsController()
			setctl.set_directories(have)

	def on_preferenceswindow_key_press_event(self, widget, event):
		if event.keyval == gtk.gdk.keyval_from_name("Escape"):
			self.hide()
			return True

	def on_checkstatusicon_toggled(self, widget):
		setctl = settings.GetSettingsController()
		setctl.set_show_status_icon(widget.get_active())

	def _get_should_autostart(self):
		KUPFER_DESKTOP = "kupfer.desktop"
		AUTOSTART_KEY = "X-GNOME-Autostart-enabled"
		autostart_dir = base.save_config_path("autostart")
		autostart_file = os.path.join(autostart_dir, KUPFER_DESKTOP)
		if not os.path.exists(autostart_file):
			return False
		try:
			dfile = desktop.DesktopEntry(autostart_file)
		except xdg_e.ParsingError, exception:
			pretty.print_error(__name__, exception)
			return False
		return (dfile.hasKey(AUTOSTART_KEY) and
				dfile.get(AUTOSTART_KEY, type="boolean"))

	def on_checkautostart_toggled(self, widget):
		KUPFER_DESKTOP = "kupfer.desktop"
		AUTOSTART_KEY = "X-GNOME-Autostart-enabled"
		autostart_dir = base.save_config_path("autostart")
		autostart_file = os.path.join(autostart_dir, KUPFER_DESKTOP)
		if not os.path.exists(autostart_file):
			desktop_files = list(base.load_data_paths("applications",
				KUPFER_DESKTOP))
			if not desktop_files:
				self.output_error("Installed kupfer desktop file not found!")
				return
			desktop_file_path = desktop_files[0]
			# Read installed file and modify it
			try:
				dfile = desktop.DesktopEntry(desktop_file_path)
			except xdg_e.ParsingError, exception:
				pretty.print_error(__name__, exception)
				return
			executable = dfile.getExec()
			## append no-splash
			if "--no-splash" not in executable:
				executable += " --no-splash"
			dfile.set("Exec", executable)
		else:
			try:
				dfile = desktop.DesktopEntry(autostart_file)
			except xdg_e.ParsingError, exception:
				pretty.print_error(__name__, exception)
				return
		activestr = str(bool(widget.get_active())).lower()
		self.output_debug("Setting autostart to", activestr)
		dfile.set(AUTOSTART_KEY, activestr)
		## remove the format specifiers
		executable = dfile.getExec().replace("%F", "")
		dfile.set("Exec", executable)
		dfile.write(filename=autostart_file)

	def on_entrykeybinding_changed(self, widget):
		pass

	def on_buttonkeybinding_clicked(self, widget):
		keystr = getkey_dialog.ask_for_key(keybindings.bind_key,
					screen=widget.get_screen())
		if keystr:
			self.entrykeybinding.set_text(keystr)
			self.output_debug("Try set keybinding with", keystr)
			keybindings.bind_key(keystr)
			setctl = settings.GetSettingsController()
			setctl.set_keybinding(keystr)

	def on_helpbutton_clicked(self, widget):
		kupferui.show_help()

	def on_closebutton_clicked(self, widget):
		self.hide()

	def _refresh_plugin_list(self, us_filter=None):
		"List plugins that pass text filter @us_filter or list all if None"
		self.store.clear()
		setctl = settings.GetSettingsController()

		if us_filter:
			self.plugin_list_timer.set_ms(300, self._show_focus_topmost_plugin)
		else:
			self.plugin_list_timer.invalidate()

		for info in self.plugin_info:
			plugin_id = info["name"]
			if setctl.get_plugin_is_hidden(plugin_id):
				continue
			enabled = setctl.get_plugin_enabled(plugin_id)
			name = info["localized_name"]
			folded_name = kupferstring.tofolded(name)
			desc = info["description"]
			text = u"%s" % name

			if us_filter:
				name_score = relevance.score(name, us_filter)
				fold_name_score = relevance.score(folded_name, us_filter)
				desc_score = relevance.score(desc, us_filter)
				if not name_score and not fold_name_score and desc_score < 0.9:
					continue

			self.store.append((plugin_id, enabled, "kupfer-object", text))

	def _show_focus_topmost_plugin(self):
		try:
			first_row = iter(self.store).next()
		except StopIteration:
			return
		plugin_id = first_row[0]
		self.show_focus_plugin(plugin_id, 0)

	def on_checkplugin_toggled(self, cell, path):
		checkcol = self.columns.index("enabled")
		plugin_id = self._id_for_table_path(path)
		it = self.store.get_iter(path)
		plugin_is_enabled = not self.store.get_value(it, checkcol)
		self.store.set_value(it, checkcol, plugin_is_enabled)
		setctl = settings.GetSettingsController()
		setctl.set_plugin_enabled(plugin_id, plugin_is_enabled)
		self.plugin_sidebar_update(plugin_id)

	def _id_for_table_path(self, path):
		it = self.store.get_iter(path)
		id_col = self.columns.index("plugin_id")
		plugin_id = self.store.get_value(it, id_col)
		return plugin_id

	def _table_path_for_id(self, id_):
		"""
		Find the tree path of plugin @id_
		"""
		id_col = self.columns.index("plugin_id")
		for row in self.store:
			plugin_id = row[id_col]
			if plugin_id == id_:
				return row.path
		raise ValueError("No such plugin %s" % id_)


	def _plugin_info_for_id(self, plugin_id):
		for info in self.plugin_info:
			if info["name"] == plugin_id:
				return info
		return None

	def plugin_table_cursor_changed(self, table):
		curpath, curcol = table.get_cursor()
		if not curpath:
			return
		plugin_id = self._id_for_table_path(curpath)
		self.plugin_sidebar_update(plugin_id)

	def plugin_sidebar_update(self, plugin_id):
		about = gtk.VBox()
		about.set_property("spacing", 15)
		about.set_property("border-width", 5)
		info = self._plugin_info_for_id(plugin_id)
		title_label = gtk.Label()
		m_localized_name = gobject.markup_escape_text(info["localized_name"])
		title_label.set_markup(u"<b><big>%s</big></b>" % m_localized_name)
		version, description, author = plugins.get_plugin_attributes(plugin_id,
				( "__version__", "__description__", "__author__", ))
		about.pack_start(title_label, False)
		infobox = gtk.VBox()
		infobox.set_property("spacing", 3)
		# TRANS: Plugin info fields
		for field, val in zip((_("Description"), _("Author")),
				(description, author)):
			if not val:
				continue
			label = gtk.Label()
			label.set_alignment(0, 0)
			label.set_markup(u"<b>%s</b>" % field)
			infobox.pack_start(label, False)
			label = wrapped_label()
			label.set_alignment(0, 0)
			label.set_markup(u"%s" % gobject.markup_escape_text(val))
			label.set_selectable(True)
			infobox.pack_start(label, False)
		if version:
			label = wrapped_label()
			label.set_alignment(0, 0)
			m_version = gobject.markup_escape_text(version)
			label.set_markup(u"<b>%s:</b> %s" % (_("Version"), m_version))
			label.set_selectable(True)
			infobox.pack_start(label, False)
		about.pack_start(infobox, False)

		# Check for plugin load exception
		exc_info = plugins.get_plugin_error(plugin_id)
		if exc_info is not None:
			etype, error, tb = exc_info
			# TRANS: Error message when Plugin needs a Python module to load
			import_error_localized = _("Python module '%s' is needed") % u"\\1"
			import_error_pat = u"No module named ([^\s]+)"
			errmsg = unicode(error)
			if re.match(import_error_pat, errmsg):
				errstr = re.sub(import_error_pat,
						import_error_localized,
						errmsg, count=1)
			else:
				import traceback
				errstr = "".join(traceback.format_exception(*exc_info))

			label = wrapped_label()
			label.set_alignment(0, 0)
			label.set_markup(u"<b>%s</b>\n\n%s" % (
				_("Plugin could not be read due to an error:"),
				gobject.markup_escape_text(errstr),
				))
			label.set_selectable(True)
			about.pack_start(label, False)
		elif not plugins.is_plugin_loaded(plugin_id):
			label = gtk.Label()
			label.set_alignment(0, 0)
			label.set_text(u"(%s)" % _("disabled"))
			about.pack_start(label, False)

		wid = self._make_plugin_info_widget(plugin_id)
		about.pack_start(wid, False)
		psettings_wid = self._make_plugin_settings_widget(plugin_id)
		if psettings_wid:
			about.pack_start(psettings_wid, False)

		oldch = self.plugin_about_parent.get_child()
		if oldch:
			self.plugin_about_parent.remove(oldch)
		vp = gtk.Viewport()
		vp.set_shadow_type(gtk.SHADOW_NONE)
		vp.add(about)
		self.plugin_about_parent.add(vp)
		self.plugin_about_parent.show_all()

	def _make_plugin_info_widget(self, plugin_id):
		sources, actions, text_sources = \
				plugins.get_plugin_attributes(plugin_id, (
				plugins.sources_attribute,
				plugins.action_decorators_attribute,
				plugins.text_sources_attribute)
				)
		vbox = gtk.VBox()
		vbox.set_property("spacing", 5)

		def make_objects_frame(objs, title):
			frame_label = gtk.Label()
			frame_label.set_markup(u"<b>%s</b>" %
			                       gobject.markup_escape_text(title))
			frame_label.set_alignment(0, 0)
			objvbox = gtk.VBox()
			objvbox.pack_start(frame_label, False)
			objvbox.set_property("spacing", 3)
			for item in objs:
				plugin_type = plugins.get_plugin_attribute(plugin_id, item)
				if not plugin_type:
					continue
				hbox = gtk.HBox()
				hbox.set_property("spacing", 3)
				obj = plugin_type()
				name = unicode(obj)
				desc = obj.get_description() or u""
				gicon = obj.get_icon()
				im = gtk.Image()
				im.set_property("gicon", gicon)
				im.set_property("pixel-size", 32)
				hbox.pack_start(im, False)
				m_name = gobject.markup_escape_text(name)
				m_desc = gobject.markup_escape_text(desc)
				name_label = \
					u"%s\n<small>%s</small>" % (m_name, m_desc) if m_desc else \
					u"%s" % (m_name, )
				label = wrapped_label()
				label.set_markup(name_label)
				hbox.pack_start(label, False)
				objvbox.pack_start(hbox)
				# Display information for application content-sources.
				if not kobject_should_show(obj):
					continue
				try:
					leaf_repr = obj.get_leaf_repr()
				except AttributeError:
					continue
				if leaf_repr is None:
					continue
				hbox = gtk.HBox()
				hbox.set_property("spacing", 3)
				gicon = leaf_repr.get_icon()
				im = gtk.Image()
				im.set_property("gicon", gicon)
				im.set_property("pixel-size", 16)
				hbox.pack_start(gtk.Label(_("Content of")), False)
				hbox.pack_start(im, False)
				hbox.pack_start(gtk.Label(unicode(leaf_repr)), False)
				objvbox.pack_start(hbox)
			return objvbox

		sources = list(sources or ()) + list(text_sources or ())
		if sources:
			# TRANS: Plugin contents header
			swid = make_objects_frame(sources, _("Sources"))
			vbox.pack_start(swid)
		if actions:
			# TRANS: Plugin contents header
			awid = make_objects_frame(actions, _("Actions"))
			vbox.pack_start(awid)

		vbox.show_all()
		return vbox

	def _get_plugin_change_callback(self, plugin_id, key, value_type,
			get_attr, no_false_values=False):
		"""Callback factory for the plugin parameter configuration"""
		def callback(widget):
			value = getattr(widget, get_attr)()
			if no_false_values and not value:
				return
			setctl = settings.GetSettingsController()
			setctl.set_plugin_config(plugin_id, key, value, value_type)
		return callback

	def _get_plugin_credentials_callback(self, plugin_id, key):
		def callback(widget):
			setctl = settings.GetSettingsController()
			val_type = plugin_support.UserNamePassword
			backend_name = plugin_support.UserNamePassword.get_backend_name()
			if plugin_support.UserNamePassword.is_backend_encrypted():
				information = _("Using encrypted password storage: %s") % backend_name
			else:
				information = _("Using password storage: %s") % backend_name
			upass = setctl.get_plugin_config(plugin_id, key, val_type) \
					or plugin_support.UserNamePassword()
			user_password = ask_user_credentials(upass.username, upass.password, information)
			if user_password:
				upass.username, upass.password = user_password
				setctl.set_plugin_config(plugin_id, key, upass, val_type)
		return callback

	def _make_plugin_settings_widget(self, plugin_id):
		plugin_settings = plugins.get_plugin_attribute(plugin_id,
				plugins.settings_attribute)
		if not plugin_settings:
			return None

		title_label = gtk.Label()
		# TRANS: Plugin-specific configuration (header)
		title_label.set_markup(u"<b>%s</b>" % _("Configuration"))
		title_label.set_alignment(0, 0)

		vbox = gtk.VBox()
		vbox.pack_start(title_label, False)
		#vbox.set_property("spacing", 5)

		plugin_settings_keys = iter(plugin_settings) if plugin_settings else ()
		for setting in plugin_settings_keys:
			typ = plugin_settings.get_value_type(setting)
			alternatives = plugin_settings.get_alternatives(setting)
			tooltip = plugin_settings.get_tooltip(setting)
			wid = None
			hbox = gtk.HBox()
			hbox.set_property("spacing", 10)
			if tooltip:
				hbox.set_tooltip_text(tooltip)
			label = plugin_settings.get_label(setting)

			if issubclass(typ, plugin_support.UserNamePassword):
				wid = gtk.Button(label or _("Set username and password"))
				wid.connect("clicked", self._get_plugin_credentials_callback(
						plugin_id, setting))
				hbox.pack_start(wid, False)
				vbox.pack_start(hbox, False)
				continue

			label_wid = wrapped_label(label, maxwid=200)
			if issubclass(typ, basestring):
				if alternatives:
					wid = gtk.combo_box_new_text()
					val = plugin_settings[setting]
					active_index = -1
					for idx, text in enumerate(alternatives):
						wid.append_text(text)
						if text == val:
							active_index = idx
					if active_index < 0:
						wid.prepend_text(val)
						active_index = 0
					wid.set_active(active_index)
					wid.connect("changed", self._get_plugin_change_callback(
						plugin_id, setting, typ, "get_active_text"))
				else:
					wid = gtk.Entry()
					wid.set_text(plugin_settings[setting])
					wid.connect("changed", self._get_plugin_change_callback(
						plugin_id, setting, typ, "get_text",
						no_false_values=True))
				hbox.pack_start(label_wid, False)
				hbox.pack_start(wid, True)

			elif issubclass(typ, bool):
				wid = gtk.CheckButton(label)
				wid.set_active(plugin_settings[setting])
				hbox.pack_start(wid, False)
				wid.connect("toggled", self._get_plugin_change_callback(
					plugin_id, setting, typ, "get_active"))
			elif issubclass(typ, int):
				wid = gtk.SpinButton()
				wid.set_increments(1, 1)
				wid.set_range(0, 1000)
				wid.set_value(plugin_settings[setting])
				hbox.pack_start(label_wid, False)
				hbox.pack_start(wid, False)
				wid.connect("changed", self._get_plugin_change_callback(
					plugin_id, setting, typ, "get_text", no_false_values=True))
			vbox.pack_start(hbox, False)

		vbox.show_all()
		return vbox

	def on_buttonadddirectory_clicked(self, widget):
		# TRANS: File Chooser Title
		chooser_dialog = gtk.FileChooserDialog(title=_("Choose a Directory"),
				action=gtk.FILE_CHOOSER_ACTION_SELECT_FOLDER,
				buttons=(gtk.STOCK_CANCEL, gtk.RESPONSE_REJECT,
					gtk.STOCK_OK, gtk.RESPONSE_ACCEPT))
		chooser_dialog.set_select_multiple(True)
		if chooser_dialog.run() == gtk.RESPONSE_ACCEPT:
			for selected_dir in chooser_dialog.get_filenames():
				self.add_directory_model(selected_dir, store=True)
		chooser_dialog.hide()

	def on_buttonremovedirectory_clicked(self, widget):
		curpath, curcol = self.dir_table.get_cursor()
		if not curpath:
			return
		it = self.dir_store.get_iter(curpath)
		self.remove_directory_model(it, store=True)

	def on_entry_plugins_filter_changed(self, widget):
		s_filter = widget.get_text()
		us_filter = kupferstring.tounicode(s_filter).lower()
		self._refresh_plugin_list(us_filter)

	def on_entry_plugins_filter_icon_press(self, entry, icon_pos, event):
		entry.set_text('')

	def on_keybindings_row_activate(self, treeview, path, view_column):
		def bind_key_func(target):
			def bind_key(keystr):
				return keybindings.bind_key(keystr, target)
			return bind_key

		it = self.keybind_store.get_iter(path)
		keybind_id = self.keybind_store.get_value(it, 2)
		setctl = settings.GetSettingsController()
		curr_key = setctl.get_global_keybinding(keybind_id)
		bind_func = bind_key_func(self.KEYBINDING_TARGETS[keybind_id])
		keystr = getkey_dialog.ask_for_key(bind_func, curr_key,
								screen=treeview.get_screen())
		if keystr == '':
			keybindings.bind_key(None, self.KEYBINDING_TARGETS[keybind_id])
			setctl.set_global_keybinding(keybind_id, keystr)
			self.keybind_store.set_value(it, 1, '')
		elif keystr is not None:
			setctl.set_global_keybinding(keybind_id, keystr)
			label = gtk.accelerator_get_label(*gtk.accelerator_parse(keystr))
			self.keybind_store.set_value(it, 1, label)

	def _is_good_keystr(self, keystr):
		# Reject single letters so you can't bind 'A' etc
		if keystr is None:
			return
		label = gtk.accelerator_get_label(*gtk.accelerator_parse(keystr))
		ulabel = kupferstring.tounicode(label)
		return not (len(ulabel) == 1 and ulabel.isalnum())

	def on_gkeybindings_row_activate(self, treeview, path, view_column):
		it = self.gkeybind_store.get_iter(path)
		keybind_id = self.gkeybind_store.get_value(it, 2)
		setctl = settings.GetSettingsController()
		curr_key = setctl.get_accelerator(keybind_id)
		keystr = getkey_dialog.ask_for_key(self._is_good_keystr,
				previous_key=curr_key, screen=treeview.get_screen())
		if keystr is not None:
			setctl.set_accelerator(keybind_id, keystr)
			label = gtk.accelerator_get_label(*gtk.accelerator_parse(keystr))
			self.gkeybind_store.set_value(it, 1, label)

	def on_button_reset_keys_clicked(self, button):
		if self.ask_user_for_reset_keybinding():
			setctl = settings.GetSettingsController()
			setctl.reset_keybindings()
			self._show_keybindings(setctl)
			# Unbind all before re-binding
			for keybind_id, target in self.KEYBINDING_TARGETS.iteritems():
				keybindings.bind_key(None, target)
			for keybind_id, target in self.KEYBINDING_TARGETS.iteritems():
				keystr = setctl.get_global_keybinding(keybind_id)
				keybindings.bind_key(keystr, target)

	def on_button_reset_gkeys_clicked(self, button):
		if self.ask_user_for_reset_keybinding():
			setctl = settings.GetSettingsController()
			setctl.reset_accelerators()
			self._show_gkeybindings(setctl)

	def on_checkusecommandkeys_toggled(self, widget):
		setctl = settings.GetSettingsController()
		setctl.set_use_command_keys(widget.get_active())

	def dir_table_cursor_changed(self, table):
		curpath, curcol = table.get_cursor()
		if not curpath or not self.dir_store:
			self.buttonremovedirectory.set_sensitive(False)
			return
		self.buttonremovedirectory.set_sensitive(True)

	def on_terminal_combobox_changed(self, widget):
		setctl = settings.GetSettingsController()
		itr = widget.get_active_iter()
		if itr:
			term_id = widget.get_model().get_value(itr, 1)
			setctl.set_preferred_tool('terminal', term_id)

	def on_icons_combobox_changed(self, widget):
		setctl = settings.GetSettingsController()
		itr = widget.get_active_iter()
		if itr:
			term_id = widget.get_model().get_value(itr, 1)
			setctl.set_preferred_tool('icon_renderer', term_id)

	def _update_alternative_combobox(self, category_key, combobox):
		"""
		Alternatives changed
		"""
		combobox_store = combobox.get_model()
		combobox_store.clear()
		setctl = settings.GetSettingsController()
		term_id = setctl.get_preferred_tool(category_key)
		# fill in the available alternatives
		alternatives = utils.locale_sort(
				setctl.get_valid_alternative_ids(category_key), key=lambda t:t[1])
		term_iter = None
		for (id_, name) in alternatives:
			_it = combobox_store.append((name, id_))
			if id_ == term_id:
				term_iter = _it
		# Update selection
		term_iter = term_iter or combobox_store.get_iter_first()
		combobox.set_sensitive(len(combobox_store) > 1)
		if term_iter:
			combobox.set_active_iter(term_iter)


	def _on_alternatives_changed(self, setctl, category_key):
		if category_key == 'terminal':
			self._update_alternative_combobox(category_key,
					self.terminal_combobox)
		elif category_key == 'icon_renderer':
			self._update_alternative_combobox(category_key,
					self.icons_combobox)

	def on_preferences_notebook_switch_page(self, notebook, page, page_num):
		## focus the search box on the plugin tab
		if page_num == PLUGIN_LIST_PAGE:
			gobject.idle_add(self.entry_plugins_filter.grab_focus)

	def show(self, timestamp):
		self.window.present_with_time(timestamp)

	def show_on_screen(self, timestamp, screen):
		self.window.set_screen(screen)
		self.show(timestamp)
		## focus the search box on the plugin tab
		if self.preferences_notebook.get_current_page() == PLUGIN_LIST_PAGE:
			self.entry_plugins_filter.grab_focus()

	def show_focus_plugin(self, plugin_id, timestamp):
		"""
		Open and show information about plugin @plugin_id
		"""
		try:
			table_path = self._table_path_for_id(plugin_id)
		except ValueError:
			self.entry_plugins_filter.set_text(u"")
			self._refresh_plugin_list()
			table_path = self._table_path_for_id(plugin_id)
		self.table.set_cursor(table_path)
		self.table.scroll_to_cell(table_path)
		self.preferences_notebook.set_current_page(PLUGIN_LIST_PAGE)
		self.window.present_with_time(timestamp)

	def hide(self):
		self.window.hide()
	def _close_window(self, *ignored):
		self.hide()
		return True

	def ask_user_for_reset_keybinding(self):
		dlg = gtk.MessageDialog(self.window, gtk.DIALOG_MODAL, gtk.MESSAGE_QUESTION)
		dlg.set_markup(_("Reset all shortcuts to default values?"))
		dlg.add_buttons(gtk.STOCK_CANCEL, gtk.RESPONSE_CLOSE,
				_('Reset'), gtk.RESPONSE_ACCEPT)
		result = dlg.run() == gtk.RESPONSE_ACCEPT
		dlg.destroy()
		return result


_conf_keys_list_columns = [{"key": "name", "type":str, 'header': _('Command')},
		{"key": "key", "type": str, 'header': _('Shortcut') },
		{"key": "keybinding_id", "type": str, 'header':  None}]
_conf_keys_list_column_types = [c["type"] for c in _conf_keys_list_columns]

def _create_conf_keys_list():
	keybind_store = gtk.ListStore(*_conf_keys_list_column_types)
	keybind_table = gtk.TreeView(keybind_store)
	for idx, col in enumerate(_conf_keys_list_columns):
		renderer = gtk.CellRendererText()
		column = gtk.TreeViewColumn(col['header'], renderer, text=idx)
		column.set_visible(col['header'] is not None)
		keybind_table.append_column(column)
	keybind_table.set_property("enable-search", False)
	keybind_table.set_rules_hint(True)
	keybind_table.set_headers_visible(True)
	keybind_table.show()
	return keybind_table, keybind_store


_preferences_window = None

def GetPreferencesWindowController():
	global _preferences_window
	if _preferences_window is None:
		_preferences_window = PreferencesWindowController()
	return _preferences_window

class SourceListController (object):
	def __init__(self, parent_widget):
		columns = [
			{"key": "source", "type": gobject.TYPE_PYOBJECT },
			{"key": "plugin_id", "type": str },
			{"key": "toplevel", "type": bool },
			{"key": "icon", "type": gio.Icon },
			{"key": "text", "type": str },
		]
		# setup plugin list table
		column_types = [c["type"] for c in columns]
		self.columns = [c["key"] for c in columns]
		self.store = gtk.ListStore(*column_types)
		self.table = gtk.TreeView(self.store)
		self.table.set_headers_visible(False)
		self.table.set_property("enable-search", False)
		self.table.set_rules_hint(True)
		#self.table.connect("cursor-changed", self.plugin_table_cursor_changed)
		self.table.get_selection().set_mode(gtk.SELECTION_NONE)

		checkcell = gtk.CellRendererToggle()
		checkcol = gtk.TreeViewColumn("item", checkcell)
		checkcol.add_attribute(checkcell, "active",
				self.columns.index("toplevel"))
		checkcell.connect("toggled", self.on_checktoplevel_enabled)

		icon_cell = gtk.CellRendererPixbuf()
		icon_cell.set_property("height", LIST_ICON_SIZE)
		icon_cell.set_property("width", LIST_ICON_SIZE)

		icon_col = gtk.TreeViewColumn("icon", icon_cell)
		icon_col.add_attribute(icon_cell, "gicon",
				self.columns.index("icon"))

		cell = gtk.CellRendererText()
		col = gtk.TreeViewColumn("item", cell)
		col.add_attribute(cell, "text", self.columns.index("text"))

		self.table.append_column(checkcol)
		self.table.append_column(icon_col)
		self.table.append_column(col)

		self._refresh()
		self.table.show()
		parent_widget.add(self.table)

		setctl = settings.GetSettingsController()
		setctl.connect("plugin-enabled-changed", self._refresh)

	def _refresh(self, *ignored):
		self.store.clear()
		setctl = settings.GetSettingsController()
		sc = sources.GetSourceController()
		srcs = sorted(sc.get_sources(), key=unicode)

		for src in srcs:
			name = unicode(src)
			plugin_id = sc.get_plugin_id_for_object(src)
			if not plugin_id or setctl.get_plugin_is_hidden(plugin_id):
				continue
			if not kobject_should_show(src):
				continue
			gicon = src.get_icon()
			toplevel = setctl.get_source_is_toplevel(plugin_id, src)

			self.store.append((src, plugin_id, toplevel, gicon, name))

	def on_checktoplevel_enabled(self, cell, path):
		it = self.store.get_iter(path)
		checkcol = self.columns.index("toplevel")
		idcol = self.columns.index("plugin_id")
		srccol = self.columns.index("source")
		is_toplevel = not self.store.get_value(it, checkcol)
		plugin_id = self.store.get_value(it, idcol)
		src = self.store.get_value(it, srccol)

		sc = sources.GetSourceController()
		sc.set_toplevel(src, is_toplevel)

		setctl = settings.GetSettingsController()
		setctl.set_source_is_toplevel(plugin_id, src, is_toplevel)
		self.store.set_value(it, checkcol, is_toplevel)

########NEW FILE########
__FILENAME__ = progress_dialog
import functools

import glib
import gtk

from kupfer import version, config

def idle_call(func):
	@functools.wraps(func)
	def idle_wrapper(*args):
		glib.idle_add(func, *args)
	return idle_wrapper


_HEADER_MARKUP = '<span weight="bold" size="larger">%s</span>'

class ProgressDialogController (object):
	def __init__(self, title, header=None, max_value=100):
		"""Create a new progress dialog

		@header: first line of dialog

		The methods show, hide and update are all wrapped to be
		safe to call from any thread.
		"""
		self.aborted = False
		self.max_value = float(max_value)
		ui_file = config.get_data_file("progress_dialog.ui")
		self._construct_dialog(ui_file, title, header)

	@idle_call
	def _construct_dialog(self, ui_file, title, header):

		builder = gtk.Builder()
		builder.set_translation_domain(version.PACKAGE_NAME)

		builder.add_from_file(ui_file)
		builder.connect_signals(self)
		self.window = builder.get_object("window_progress")
		self.button_abort = builder.get_object('button_abort')
		self.progressbar = builder.get_object('progressbar')
		self.label_info = builder.get_object('label_info')
		self.label_header = builder.get_object('label_header')

		self.window.set_title(title)
		if header:
			self.label_header.set_markup(_HEADER_MARKUP %
					glib.markup_escape_text(header))
		else:
			self.label_header.hide()

		self.update(0, '', '')

	def on_button_abort_clicked(self, widget):
		self.aborted = True
		self.button_abort.set_sensitive(False)

	@idle_call
	def show(self):
		self.window.present()

	@idle_call
	def hide(self):
		self.window.hide()

	@idle_call
	def update(self, value, label, text):
		""" Update dialog information.

		@value: value to set for progress bar
		@label: current action (displayed in emphasized style)
		@text: current information (normal style)
		"""
		self.progressbar.set_fraction(min(value/self.max_value, 1.0))
		self.label_info.set_markup(u"<b>%s</b> %s" %
			(
				glib.markup_escape_text(label),
				glib.markup_escape_text(text),
			))
		return self.aborted


########NEW FILE########
__FILENAME__ = session
"""
session sets up the program as a client to the current
desktop session and enables notifications on session
close, to be able to save state before being killed;

the module API does not depend on the session API used
"""

import os
import time

import dbus
import gobject

from kupfer import pretty, version

class SessionClient (gobject.GObject, pretty.OutputMixin):
	"""Session handling controller

	signals:
	save-yourself: Program should save state
	die:           Program should quit immediately
	"""
	__gtype_name__ = "SessionClient"

	def __init__(self):
		"""Set up program as client to current Session"""
		gobject.GObject.__init__(self)

		succ = False
		try:
			succ = self._connect_session_manager()
		except dbus.DBusException, exc:
			self.output_error(exc)
		if not succ:
			# try to bind to xfce session manager
			try:
				succ = self._connect_xfce_session_manager()
			except dbus.DBusException, exc:
				self.output_error(exc)
		if not succ:
			succ = self._connect_gnomeui()

		# unset autostart id so that it is not transferred
		os.putenv("DESKTOP_AUTOSTART_ID", "")
		self._enabled = succ
		if not self.enabled:
			self.output_info("Warning: Not able to connect to current "
				"desktop session, please Quit before logout to save "
				"kupfer's data.")

	def _connect_gnomeui(self):
		try:
			import gnome
			import gnome.ui
		except ImportError, exc:
			self.output_debug(exc)
			return False

		gnome.program_init(version.PACKAGE_NAME, version.VERSION)
		client = gnome.ui.master_client()
		client.connect("save-yourself", self._session_save)
		client.connect("die", self._session_die)
		self.output_debug("Setting up session connection using GnomeClient")
		return True

	def _connect_session_manager(self):
		bus = dbus.SessionBus()
		proxy_obj = bus.get_object('org.freedesktop.DBus',
				'/org/freedesktop/DBus')
		dbus_iface = dbus.Interface(proxy_obj, 'org.freedesktop.DBus')
		service_name = "org.gnome.SessionManager"
		obj_name = "/org/gnome/SessionManager"
		iface_name = service_name

		if not dbus_iface.NameHasOwner(service_name):
			self.output_debug("D-Bus name %s not found" % service_name)
			return False

		try:
			obj = bus.get_object(service_name, obj_name)
		except dbus.DBusException, e:
			pretty.print_error(__name__, e)
			return False
		smanager = dbus.Interface(obj, iface_name)

		app_id = version.PACKAGE_NAME
		startup_id = os.getenv("DESKTOP_AUTOSTART_ID") or ""
		self.client_id = smanager.RegisterClient(app_id, startup_id)
		self._session_ended = False
		self.output_debug("Connected to session as client",
				self.client_id, startup_id)

		private_iface_name = "org.gnome.SessionManager.ClientPrivate"
		bus.add_signal_receiver(self._query_end_session, "QueryEndSession",
				dbus_interface=private_iface_name)
		bus.add_signal_receiver(self._end_session_signal, "EndSession",
				dbus_interface=private_iface_name)
		bus.add_signal_receiver(self._stop_signal, "Stop",
				dbus_interface=private_iface_name)
		return True

	def _connect_xfce_session_manager(self):
		bus = dbus.SessionBus()
		proxy_obj = bus.get_object('org.freedesktop.DBus',
				'/org/freedesktop/DBus')
		dbus_iface = dbus.Interface(proxy_obj, 'org.freedesktop.DBus')
		service_name = "org.xfce.SessionManager"
		obj_name = "/org/xfce/SessionManager"

		if not dbus_iface.NameHasOwner(service_name):
			self.output_debug("D-Bus name %s not found" % service_name)
			return False

		try:
			bus.get_object(service_name, obj_name)
		except dbus.DBusException, e:
			pretty.print_error(__name__, e)
			return False

		private_iface_name = "org.xfce.Session.Manager"
		bus.add_signal_receiver(self._xfce_session_state_changed, "StateChanged",
				dbus_interface=private_iface_name)
		return True

	def _get_response_obj(self):
		"""Return D-Bus session object for ClientPrivate Interface"""
		service_name = "org.gnome.SessionManager"
		obj_name = self.client_id
		iface_name = "org.gnome.SessionManager.ClientPrivate"

		try:
			bus = dbus.Bus()
			obj = bus.get_object(service_name, obj_name)
		except dbus.DBusException, e:
			pretty.print_error(__name__, e)
			return None
		smanager = dbus.Interface(obj, iface_name)
		return smanager

	def _query_end_session(self, flags):
		self.output_debug("Query end", flags)

		smanager = self._get_response_obj()
		smanager and smanager.EndSessionResponse(True, "Always OK")

	def _end_session_signal(self, flags):
		self.output_debug("Session end", flags)
		if not self._session_ended:
			self._session_ended = True
			self.emit("save-yourself")
		smanager = self._get_response_obj()
		smanager and smanager.EndSessionResponse(True, "Always OK")

	def _xfce_session_state_changed(self, old_value, new_value):
		self.output_debug("XFCE Session change", time.asctime(),
				old_value, new_value)
		if new_value == 4:
			self.emit("save-yourself")

	def _stop_signal(self):
		self.output_debug("Session stop")
		self.emit("die")
	def _session_save(self, obj, *args):
		self.emit("save-yourself")
	def _session_die(self, obj, *args):
		self.emit("die")
	@property
	def enabled(self):
		"""If a session connection is available"""
		return self._enabled

gobject.signal_new("save-yourself", SessionClient, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN, ())
gobject.signal_new("die", SessionClient, gobject.SIGNAL_RUN_LAST,
		gobject.TYPE_BOOLEAN, ())

########NEW FILE########
__FILENAME__ = uievents
import contextlib
import os

import gtk

from kupfer import pretty
from kupfer.ui import keybindings

def gui_context_from_widget(timestamp, widget):
	return GUIEnvironmentContext(timestamp, widget.get_screen())

def gui_context_from_timestamp(timestamp):
	return GUIEnvironmentContext(timestamp, None)

def gui_context_from_keyevent(timestamp, display):
	new_display = GUIEnvironmentContext.ensure_display_open(display)
	screen, x, y, modifiers = new_display.get_pointer()
	return GUIEnvironmentContext(timestamp, screen)

class GUIEnvironmentContext (object):
	"""
	Context object for action execution
	in the current GUI context
	"""
	_open_displays = set()

	def __init__(self, timestamp, screen=None):
		self._timestamp = timestamp
		self._screen = screen or gtk.gdk.screen_get_default()

	@classmethod
	def ensure_display_open(cls, display):
		"""
		Return GdkDisplay for name @display.

		Return default if @display is None.
		"""
		def norm_name(name):
			"normalize display name"
			if name[-2] == ":":
				return name+".0"
			return name
		dm = gtk.gdk.display_manager_get()
		if display:
			new_display = None
			for disp in dm.list_displays():
				if norm_name(disp.get_name()) == norm_name(display):
					new_display = disp
					break
			if new_display is None:
				pretty.print_debug(__name__,
						"Opening display in ensure_display_open", display)
				new_display = gtk.gdk.Display(display)
		else:
			new_display = gtk.gdk.display_get_default()
		## Hold references to all open displays
		cls._open_displays = set(dm.list_displays())
		return new_display

	@classmethod
	def _try_close_unused_displays(cls, screen):
		"""@screen is current GdkScreen

		Try to close inactive displays...
		Take all GtkWindow that are hidden, and move to the
		current screen. If no windows remain then we close
		the display, but we never close the default display.
		"""
		def debug(*x):
			pretty.print_debug(__name__, *x)
		display = screen.get_display()
		dm = gtk.gdk.display_manager_get()
		for disp in list(dm.list_displays()):
			if disp != display and disp != gtk.gdk.display_get_default():
				debug("Trying to close", disp.get_name())
				open_windows = 0
				for window in gtk.window_list_toplevels():
					# find windows on @disp
					if window.get_screen().get_display() != disp:
						continue
					if not window.get_property("visible"):
						debug("Moving window", window.get_name())
						debug("Moving", window.get_title())
						window.set_screen(screen)
					else:
						debug("Open window blocks close")
						open_windows += 1
				if not open_windows:
					debug("Closing display", disp.get_name())
					disp.close()


	def get_timestamp(self):
		return self._timestamp

	def get_startup_notification_id(self):
		"""
		Always returns a byte string
		"""
		return _make_startup_notification_id(self.get_timestamp())

	def get_display(self):
		"""return the display name to show new windows on

		Always returns a byte string
		"""
		return self._screen.make_display_name()

	def get_screen(self):
		return self._screen

	def present_window(self, window):
		"""
		Show and present @window on the current
		workspace, screen & display as appropriate.

		@window: A gtk.Window
		"""
		window.set_screen(self.get_screen())
		window.present_with_time(self.get_timestamp())

class _internal_data (object):
	seq = 0
	current_event_time = 0

	@classmethod
	def inc_seq(cls):
		cls.seq = cls.seq + 1

def _make_startup_notification_id(time):
	_internal_data.inc_seq()
	return "%s-%d-%s_TIME%d" % ("kupfer", os.getpid(), _internal_data.seq, time)

def current_event_time():
	return (gtk.get_current_event_time() or
	        keybindings.get_current_event_time() or
	        _internal_data.current_event_time)

def _parse_notify_id(startup_notification_id):
	"""
	Return timestamp or 0 from @startup_notification_id
	"""
	time = 0
	if "_TIME" in startup_notification_id:
		_ign, bstime = startup_notification_id.split("_TIME", 1)
		try:
			time = abs(int(bstime))
		except ValueError:
			pass
	return time

@contextlib.contextmanager
def using_startup_notify_id(notify_id):
	"""
	Pass in a DESKTOP_STARTUP_ID

	with using_startup_notify_id(...) as time:
		pass
	
	The yelt object is the parsed timestamp
	"""
	timestamp = _parse_notify_id(notify_id)
	if timestamp:
		gtk.gdk.notify_startup_complete_with_id(notify_id)
	try:
		pretty.print_debug(__name__, "Using startup id", repr(notify_id))
		_internal_data.current_event_time = timestamp
		yield timestamp
	finally:
		_internal_data.current_event_time = gtk.gdk.CURRENT_TIME


########NEW FILE########
__FILENAME__ = uiutils
"""
User Interface Utility Functions for Kupfer

These helper functions can be called from plugins (are meant to serve this
purpose), but care should be taken to only call UI functions from the main
(default) thread.
"""

import gtk
import pango

from kupfer import pretty
from kupfer import config, version
from kupfer.ui import uievents

def _window_destroy_on_escape(widget, event):
	"""
	Callback function for Window's key press event, will destroy window
	on escape
	"""
	if event.keyval == gtk.gdk.keyval_from_name("Escape"):
		widget.destroy()
		return True

def builder_get_objects_from_file(fname, attrs, autoconnect_to=None):
	"""
	Open @fname with gtk.Builder and yield objects named @attrs

	@fname is sought in the data directories.
	If @autoconnect_to is not None, signals are autoconnected to this object,
	and a user_data object is passed as a namespace containing all @attrs
	"""
	builder = gtk.Builder()
	builder.set_translation_domain(version.PACKAGE_NAME)

	ui_file = config.get_data_file(fname)
	builder.add_from_file(ui_file)
	class Namespace (object):
		pass
	names = Namespace()
	for attr in attrs:
		obj = builder.get_object(attr)
		setattr(names, attr, obj)
		yield obj
	if autoconnect_to:
		builder.connect_signals(autoconnect_to, user_data=names)

def show_text_result(text, title=None, ctx=None):
	"""
	Show @text in a result window.

	Use @title to set a window title
	"""
	class ResultWindowBehavior (object):
		def on_text_result_window_key_press_event(self, widget, event, names):
			return _window_destroy_on_escape(widget, event)

		def on_close_button_clicked(self, widget, names):
			names.text_result_window.window.destroy()
			return True
		def on_copy_button_clicked(self, widget, names):
			clip = gtk.clipboard_get(gtk.gdk.SELECTION_CLIPBOARD)
			textview = names.result_textview
			buf = textview.get_buffer()
			buf.select_range(*buf.get_bounds())
			buf.copy_clipboard(clip)

	window, textview = builder_get_objects_from_file("result.ui",
			("text_result_window", "result_textview"),
			autoconnect_to=ResultWindowBehavior())


	# Set up text buffer
	buf = gtk.TextBuffer()
	buf.set_text(text)
	monospace = gtk.TextTag("fixed")
	monospace.set_property("family", "Monospace")
	monospace.set_property("scale", pango.SCALE_LARGE)
	beg, end = buf.get_bounds()
	tag_table = buf.get_tag_table()
	tag_table.add(monospace)
	buf.apply_tag(monospace, beg, end)

	textview.set_buffer(buf)
	textview.set_wrap_mode(gtk.WRAP_NONE)

	if title:
		window.set_title(title)

	if ctx:
		ctx.environment.present_window(window)

	window.show_all()

	# Fix Sizing:
	# We want to size the window so that the
	# TextView is displayed without scrollbars
	# initially, if it fits on screen.
	oldwid, oldhei = textview.window.get_size()
	winwid, winhei = window.get_size()

	max_hsize, max_vsize = window.get_default_size()
	wid, hei = textview.size_request()
	textview.set_wrap_mode(gtk.WRAP_WORD)

	vsize = int(min(hei + (winhei - oldhei) + 5, max_vsize))
	hsize = int(min(wid + (winwid - oldwid) + 5, max_hsize))

	window.resize(hsize, vsize)
	if ctx:
		ctx.environment.present_window(window)
	else:
		window.present_with_time(uievents.current_event_time())

def _wrap_paragraphs(text):
	"""
	Return @text with linewrapped paragraphs
	"""
	import textwrap
	return u"\n\n".join(textwrap.fill(par) for par in text.split("\n\n"))

def show_large_type(text, ctx=None):
	"""
	Show @text, large, in a result window.
	"""
	import math

	text = text.strip()
	window = gtk.Window()
	label = gtk.Label()
	label.set_text(text)

	def set_font_size(label, fontsize=48.0):
		siz_attr = pango.AttrFontDesc(
				pango.FontDescription (str(fontsize)), 0, -1)
		attrs = pango.AttrList()
		attrs.insert(siz_attr)
		label.set_attributes(attrs)
	label.show()

	size = 72.0
	set_font_size(label, size)

	if ctx:
		screen = ctx.environment.get_screen()
		window.set_screen(screen)
	else:
		screen = gtk.gdk.screen_get_default()

	maxwid = screen.get_width() - 50
	maxhei = screen.get_height() - 100
	wid, hei = label.size_request()

	# If the text contains long lines, we try to
	# hard-wrap the text
	if ((wid > maxwid or hei > maxhei) and
			any(len(L) > 100 for L in text.splitlines())):
		label.set_text(_wrap_paragraphs(text))

	wid, hei = label.size_request()

	if wid > maxwid or hei > maxhei:
		# Round size down to fit inside
		wscale = maxwid * 1.0/wid
		hscale = maxhei * 1.0/hei
		set_font_size(label, math.floor(min(wscale, hscale)*size) or 1.0)

	window.add(label)
	window.set_position(gtk.WIN_POS_CENTER)
	window.set_resizable(False)
	window.set_decorated(False)
	window.set_property("border-width", 10)
	window.modify_bg(gtk.STATE_NORMAL, gtk.gdk.color_parse("black"))
	label.modify_fg(gtk.STATE_NORMAL, gtk.gdk.color_parse("white"))

	def _window_destroy(widget, event):
		widget.destroy()
		return True
	window.connect("key-press-event", _window_destroy)
	window.show_all()
	if ctx:
		ctx.environment.present_window(window)
	else:
		window.present_with_time(uievents.current_event_time())

SERVICE_NAME = "org.freedesktop.Notifications"
OBJECT_PATH = "/org/freedesktop/Notifications"
IFACE_NAME = "org.freedesktop.Notifications"
def _get_notification_iface():
	"we will activate it over d-bus (start if not running)"
	import dbus
	try:
		bus = dbus.SessionBus()
		proxy_obj = bus.get_object(SERVICE_NAME, OBJECT_PATH)
	except dbus.DBusException, e:
		pretty.print_debug(__name__, e)
		return
	iface_obj = dbus.Interface(proxy_obj, IFACE_NAME)
	return iface_obj

def show_notification(title, text="", icon_name="", nid=0):
	"""
	@nid: If not 0, the id of the notification to replace.

	Returns the id of the displayed notification.
	"""
	notifications = _get_notification_iface()
	if not notifications:
		return None
	rid = notifications.Notify("kupfer",
	                           nid, icon_name, title, text, (), {}, -1)
	return rid



########NEW FILE########
__FILENAME__ = utils
import itertools
import os
from os import path as os_path
import locale
import signal
import sys

import gobject
import glib


from kupfer import pretty
from kupfer import kupferstring
from kupfer import desktop_launch
from kupfer import launch
from kupfer import desktop_parse
from kupfer import terminal

from kupfer.desktop_launch import SpawnError


def get_dirlist(folder, depth=0, include=None, exclude=None):
	"""
	Return a list of absolute paths in folder
	include, exclude: a function returning a boolean
	def include(filename):
		return ShouldInclude
	"""
	from os import walk
	paths = []
	def include_file(file):
		return (not include or include(file)) and (not exclude or not exclude(file))
		
	for dirname, dirnames, fnames in walk(folder):
		# skip deep directories
		head, dp = dirname, 0
		while not os_path.samefile(head, folder):
			head, tail = os_path.split(head)
			dp += 1
		if dp > depth:
			del dirnames[:]
			continue
		
		excl_dir = []
		for dir in dirnames:
			if not include_file(dir):
				excl_dir.append(dir)
				continue
			abspath = os_path.join(dirname, dir)
			paths.append(abspath)
		
		for file in fnames:
			if not include_file(file):
				continue
			abspath = os_path.join(dirname, file)
			paths.append(abspath)

		for dir in reversed(excl_dir):
			dirnames.remove(dir)

	return paths

def locale_sort(seq, key=unicode):
	"""Return @seq of objects with @key function as a list sorted
	in locale lexical order

	>>> locale.setlocale(locale.LC_ALL, "C")
	'C'
	>>> locale_sort("abcABC")
	['A', 'B', 'C', 'a', 'b', 'c']

	>>> locale.setlocale(locale.LC_ALL, "en_US.UTF-8")
	'en_US.UTF-8'
	>>> locale_sort("abcABC")
	['a', 'A', 'b', 'B', 'c', 'C']
	"""
	locale_cmp = lambda s, o: locale.strcoll(key(s), key(o))
	seq = seq if isinstance(seq, list) else list(seq)
	seq.sort(cmp=locale_cmp)
	return seq

def _argv_to_locale(argv):
	"encode unicode strings in @argv according to the locale encoding"
	return [kupferstring.tolocale(A) if isinstance(A, unicode) else A
			for A in argv]

class AsyncCommand (object):
	"""
	Run a command asynchronously (using the GLib mainloop)

	call @finish_callback when command terminates, or
	when command is killed after @timeout_s seconds, whichever
	comes first.

	If @timeout_s is None, no timeout is used

	If stdin is a byte string, it is supplied on the command's stdin.

	If env is None, command will inherit the parent's environment.

	finish_callback -> (AsyncCommand, stdout_output, stderr_output)

	Attributes:
	self.exit_status  Set after process exited
	self.finished     bool

	"""
	# the maximum input (bytes) we'll read in one shot (one io_callback)
	max_input_buf = 512 * 1024

	def __init__(self, argv, finish_callback, timeout_s, stdin=None, env=None):
		self.stdout = []
		self.stderr = []
		self.stdin = []
		self.timeout = False
		self.killed = False
		self.finished = False
		self.finish_callback = finish_callback

		argv = _argv_to_locale(argv)
		pretty.print_debug(__name__, "AsyncCommand:", argv)

		flags = (glib.SPAWN_SEARCH_PATH | glib.SPAWN_DO_NOT_REAP_CHILD)
		pid, stdin_fd, stdout_fd, stderr_fd = \
		     glib.spawn_async(argv, standard_output=True, standard_input=True,
		                      standard_error=True, flags=flags, envp=env)

		if stdin:
			self.stdin[:] = self._split_string(stdin, self.max_input_buf)
			in_io_flags = glib.IO_OUT | glib.IO_ERR | glib.IO_HUP | glib.IO_NVAL
			glib.io_add_watch(stdin_fd, in_io_flags, self._in_io_callback,
			                  self.stdin)
		else:
			os.close(stdin_fd)

		io_flags = glib.IO_IN | glib.IO_ERR | glib.IO_HUP | glib.IO_NVAL
		glib.io_add_watch(stdout_fd, io_flags, self._io_callback, self.stdout)
		glib.io_add_watch(stderr_fd, io_flags, self._io_callback, self.stderr)
		self.pid = pid
		glib.child_watch_add(pid, self._child_callback)
		if timeout_s is not None:
			glib.timeout_add_seconds(timeout_s, self._timeout_callback)

	def _split_string(self, s, length):
		"""Split @s in pieces of @length"""
		L = []
		for i in xrange(0, len(s)//length + 1):
			L.append(s[i*length:(i+1)*length])
		return L

	def _io_callback(self, sourcefd, condition, databuf):
		if condition & glib.IO_IN:
			databuf.append(os.read(sourcefd, self.max_input_buf))
			return True
		return False

	def _in_io_callback(self, sourcefd, condition, databuf):
		"""write to child's stdin"""
		if condition & glib.IO_OUT:
			if not databuf:
				os.close(sourcefd)
				return False
			s = databuf.pop(0)
			written = os.write(sourcefd, s)
			if written < len(s):
				databuf.insert(0, s[written:])
			return True
		return False

	def _child_callback(self, pid, condition):
		# @condition is the &status field of waitpid(2) (C library)
		self.exit_status = os.WEXITSTATUS(condition)
		self.finished = True
		self.finish_callback(self, "".join(self.stdout), "".join(self.stderr))

	def _timeout_callback(self):
		"send term signal on timeout"
		if not self.finished:
			self.timeout = True
			os.kill(self.pid, signal.SIGTERM)
			glib.timeout_add_seconds(2, self._kill_callback)

	def _kill_callback(self):
		"Last resort, send kill signal"
		if not self.finished:
			self.killed = True
			os.kill(self.pid, signal.SIGKILL)


def spawn_terminal(workdir=None, screen=None):
	" Raises SpawnError "
	term = terminal.get_configured_terminal()
	notify = term["startup_notify"]
	app_id = term["desktopid"]
	argv = term["argv"]
	desktop_launch.spawn_app_id(app_id, argv, workdir, notify, screen)

def spawn_in_terminal(argv, workdir=None):
	" Raises SpawnError "
	term = terminal.get_configured_terminal()
	notify = term["startup_notify"]
	_argv = list(term["argv"])
	if term["exearg"]:
		_argv.append(term["exearg"])
	_argv.extend(argv)
	desktop_launch.spawn_app_id(term["desktopid"], _argv , workdir, notify)

def spawn_async_notify_as(app_id, argv):
	"""
	Spawn argument list @argv and startup-notify as
	if application @app_id is starting (if possible)

	raises SpawnError
	"""
	desktop_launch.spawn_app_id(app_id, argv , None, True)

def spawn_async(argv, in_dir="."):
	"""
	Silently spawn @argv in the background

	Returns False on failure
	"""
	try:
		return spawn_async_raise(argv, in_dir)
	except SpawnError as exc:
		pretty.print_debug(__name__, "spawn_async", argv, exc)
		return False

def spawn_async_raise(argv, workdir="."):
	"""
	A version of spawn_async that raises on error.

	raises SpawnError
	"""
	argv = _argv_to_locale(argv)
	pretty.print_debug(__name__, "spawn_async", argv, workdir)
	try:
		return gobject.spawn_async (argv, working_directory=workdir,
				flags=gobject.SPAWN_SEARCH_PATH)
	except gobject.GError as exc:
		raise SpawnError(exc)

def argv_for_commandline(cli):
	return desktop_parse.parse_argv(cli)

def launch_commandline(cli, name=None, in_terminal=False):
	" Raises SpawnError "
	argv = desktop_parse.parse_argv(cli)
	pretty.print_error(__name__, "Launch commandline is deprecated ")
	pretty.print_debug(__name__, "Launch commandline (in_terminal=", in_terminal, "):", argv, sep="")
	if in_terminal:
		return spawn_in_terminal(argv)
	return spawn_async(argv)

def launch_app(app_info, files=(), uris=(), paths=()):
	" Raises SpawnError "

	# With files we should use activate=False
	return launch.launch_application(app_info, files, uris, paths,
			activate=False)

def show_path(path):
	"""Open local @path with default viewer"""
	from gio import File
	# Implemented using gtk.show_uri
	gfile = File(path)
	if not gfile:
		return
	url = gfile.get_uri()
	show_url(url)

def show_url(url):
	"""Open any @url with default viewer"""
	from gtk import show_uri, get_current_event_time
	from gtk.gdk import screen_get_default
	from glib import GError
	try:
		pretty.print_debug(__name__, "show_url", url)
		return show_uri(screen_get_default(), url, get_current_event_time())
	except GError, exc:
		pretty.print_error(__name__, "gtk.show_uri:", exc)

def _on_child_exit(pid, condition, user_data):
	# @condition is the &status field of waitpid(2) (C library)
	argv, respawn = user_data
	if respawn:
		is_signal = os.WIFSIGNALED(condition)
		if is_signal and respawn:
			def callback(*args):
				spawn_child(*args)
				return False
			glib.timeout_add_seconds(10, callback, argv, respawn)

def _try_register_pr_pdeathsig():
    """
    Register PR_SET_PDEATHSIG (linux-only) for the calling process
    which is a signal delivered when its parent dies.

    This should ensure child processes die with the parent.
    """
    PR_SET_PDEATHSIG=1
    SIGHUP=1
    if sys.platform != 'linux2':
        return
    try:
        import ctypes
    except ImportError:
        return
    try:
        libc = ctypes.CDLL("libc.so.6")
        libc.prctl(PR_SET_PDEATHSIG, SIGHUP)
    except (AttributeError, OSError):
        pass

def spawn_child(argv, respawn=True, display=None):
	"""
	Spawn argv in the mainloop and keeping it as a child process
	(it will be made sure to exit with the parent).

	@respawn: If True, respawn if child dies abnormally

	raises utils.SpawnError
	returns pid
	"""
	flags = (glib.SPAWN_SEARCH_PATH | glib.SPAWN_DO_NOT_REAP_CHILD)
	kwargs = {}
	if display:
		# environment is passed as a sequence of strings
		envd = os.environ.copy()
		envd['DISPLAY'] = display
		kwargs['envp'] = ['='.join((k,v)) for k,v in envd.items()]

	try:
		pid, stdin_fd, stdout_fd, stderr_fd = \
			glib.spawn_async(argv, flags=flags,
			                 child_setup=_try_register_pr_pdeathsig,
			                 **kwargs)
	except glib.GError as exc:
		raise utils.SpawnError(unicode(exc))
	if pid:
		glib.child_watch_add(pid, _on_child_exit, (argv, respawn))
	return pid

def start_plugin_helper(name, respawn, display=None):
	"""
	@respawn: If True, respawn if child dies abnormally

	raises SpawnError
	"""
	argv = [sys.executable]
	argv.extend(sys.argv)
	argv.append('--exec-helper=%s' % name)
	pretty.print_debug(__name__, "Spawning", argv)
	return spawn_child(argv, respawn, display=display)

def show_help_url(url):
	"""
	Try at length to display a startup notification for the help browser.

	Return False if there is no handler for the help URL
	"""
	import gio
	## Check that the system help viewer is Yelp,
	## and if it is, launch its startup notification.
	scheme = gio.File(url).get_uri_scheme()
	default = gio.app_info_get_default_for_uri_scheme(scheme)
	help_viewer_id = "yelp.desktop"
	if not default:
		return False
	try:
		yelp = gio.unix.DesktopAppInfo(help_viewer_id)
	except RuntimeError:
		return show_url(url)
	cmd_path = lookup_exec_path(default.get_executable())
	yelp_path = lookup_exec_path(yelp.get_executable())
	if cmd_path and yelp_path and os.path.samefile(cmd_path, yelp_path):
		try:
			spawn_async_notify_as(help_viewer_id, [cmd_path, url])
			return True
		except SpawnError:
			pass
	return show_url(url)

def lookup_exec_path(exename):
	"Return path for @exename in $PATH or None"
	PATH = os.environ.get("PATH") or os.defpath
	for execdir in PATH.split(os.pathsep):
		exepath = os.path.join(execdir, exename)
		if os.access(exepath, os.R_OK|os.X_OK) and os.path.isfile(exepath):
			return exepath

def is_directory_writable(dpath):
	"""If directory path @dpath is a valid destination to write new files?
	"""
	if not os_path.isdir(dpath):
		return False
	return os.access(dpath, os.R_OK | os.W_OK | os.X_OK)

def get_destpath_in_directory(directory, filename, extension=None):
	"""Find a good destpath for a file named @filename in path @directory
	Try naming the file as filename first, before trying numbered versions
	if the previous already exist.

	If @extension, it is used as the extension. Else the filename is split and
	the last extension is used
	"""
	# find a nonexisting destname
	ctr = itertools.count(1)
	basename = filename + (extension or "")
	destpath = os_path.join(directory, basename)
	while True:
		if not os_path.exists(destpath):
			break
		if extension:
			root, ext = filename, extension
		else:
			root, ext = os_path.splitext(filename)
		basename = "%s-%s%s" % (root, ctr.next(), ext)
		destpath = os_path.join(directory, basename)
	return destpath

def get_destfile_in_directory(directory, filename, extension=None):
	"""Find a good destination for a file named @filename in path @directory.

	Like get_destpath_in_directory, but returns an open file object, opened
	atomically to avoid race conditions.

	Return (fileobj, filepath)
	"""
	# retry if it fails
	for retry in xrange(3):
		destpath = get_destpath_in_directory(directory, filename, extension)
		try:
			fd = os.open(destpath, os.O_CREAT | os.O_EXCL | os.O_WRONLY, 0666)
		except OSError, exc:
			pretty.print_error(__name__, exc)
		else:
			return (os.fdopen(fd, "wb"), destpath)
	return (None, None)

def get_safe_tempfile():
	"""Return (fileobj, filepath) pointing to an open temporary file"""
	import tempfile
	fd, path = tempfile.mkstemp()
	return (os.fdopen(fd, "wb"), path)

def get_display_path_for_bytestring(filepath):
	"""Return a unicode path for display for bytestring @filepath

	Will use glib's filename decoding functions, and will
	format nicely (denote home by ~/ etc)
	"""
	desc = gobject.filename_display_name(filepath)
	homedir = os.path.expanduser("~/")
	if desc.startswith(homedir) and homedir != desc:
		desc = desc.replace(homedir, "~/", 1)
	return desc

def parse_time_interval(tstr):
	"""
	Parse a time interval in @tstr, return whole number of seconds

	>>> parse_time_interval("2")
	2
	>>> parse_time_interval("1h 2m 5s")
	3725
	>>> parse_time_interval("2 min")
	120
	"""
	weights = {
		"s": 1, "sec": 1,
		"m": 60, "min": 60,
		"h": 3600, "hours": 3600,
	}
	try:
		return int(tstr)
	except ValueError:
		pass

	total = 0
	amount = 0
	# Split the string in runs of digits and runs of characters
	for isdigit, group in itertools.groupby(tstr, lambda k: k.isdigit()):
		part = "".join(group).strip()
		if not part:
			continue
		if isdigit:
			amount = int(part)
		else:
			total += amount * weights.get(part.lower(), 0)
			amount = 0
	return total


if __name__ == '__main__':
	import doctest
	doctest.testmod()

########NEW FILE########
__FILENAME__ = version
# encoding: UTF-8

VERSION = "development version"
PACKAGE_NAME = "kupfer"

try:
	from kupfer import version_subst
except ImportError:
	pass
else:
	VERSION = version_subst.VERSION
	PACKAGE_NAME = version_subst.PACKAGE_NAME

ICON_NAME = "kupfer"
PROGRAM_NAME = _("Kupfer")

AUTHORS = u"""Ulrik Sverdrup <ulrik.sverdrup@gmail.com>
Karol BÄ™dkowski
Francesco Marella
Chmouel Boudjnah
Horia V. Corcalciuc
Grigory Javadyan
Chris Parsons
Fabian CarlstrÃ¶m
Jakh Daven
Thomas Renard
""".splitlines()

PACKAGERS=u"""
Luca Falavigna (Debian, Ubuntu)
Francesco Marella (Ubuntu PPA)
""".splitlines()

TRANSLATORS=u"""
Marek ÄŒernockÃ½ (cs)
Petr Kovar (cs)
Joe Hansen (da)
Thibaud Roth (de)
Mario BlÃ¤ttermann (de)
Leandro Leites (es)
JesÃºs Barbero RodrÃ­guez (es)
Jorge GonzÃ¡lez (es)
Daniel Mustieles (es)
Oier Mees (eu)
IÃ±aki LarraÃ±aga Murgoitio (eu)
Christophe Benz (fr)
Marcos Lans (gl)
Fran DiÃ©guez (gl)
Andrea Zagli (it)
Francesco Marella (it)
Martin Koelewijn (nl)
Kjartan Maraas (no)
Maciej Kwiatkowski (pl)
Karol BÄ™dkowski (pl)
Carlos Pais (pt)
Andrej Å½nidarÅ¡iÄ (sl)
Matej UrbanÄiÄ (sl)
M. Deran Delice (tr)
lh (zh_CN)
Aron Xu (zh_CN)
Yinghua Wang (zh_CN)
""".splitlines()

ARTISTS=u"""Nasser Alshammari <designernasser@gmail.com>
""".splitlines()

AUTHORS += ARTISTS + PACKAGERS + TRANSLATORS

DOCUMENTERS = []

# TRANS: Don't translate literally!
# TRANS: This should be a list of all translators of this language
TRANSLATOR_CREDITS = _("translator-credits")

WEBSITE = u"http://kaizer.se/wiki/kupfer/"
HELP_WEBSITE = u"http://kaizer.se/wiki/kupfer/help/"

SHORT_DESCRIPTION = _("A free software (GPLv3+) launcher")
COPYRIGHT = u"""Copyright Â© 2007--2011 Ulrik Sverdrup with others"""

LICENSE = _("""
This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see <http://www.gnu.org/licenses/>.
""")

# follows strings used elsewhere

_("Could not find running Kupfer")

########NEW FILE########
__FILENAME__ = weaklib
"""
This module is a part of the program Kupfer, see the main program file for
more information.
"""
import weakref

class WeakCallback (object):
	"""A Weak Callback object that will keep a reference to
	the connecting object with weakref semantics.

	This allows object A to pass a callback method to object S,
	without object S keeping A alive.
	"""
	def __init__(self, mcallback):
		"""Create a new Weak Callback calling the method @mcallback"""
		obj = mcallback.im_self
		attr = mcallback.im_func.__name__
		self.wref = weakref.ref(obj, self.object_deleted)
		self.callback_attr = attr
		self.token = None

	def __call__(self, *args, **kwargs):
		obj = self.wref()
		if obj:
			attr = getattr(obj, self.callback_attr)
			attr(*args, **kwargs)
		else:
			self.default_callback(*args, **kwargs)

	def default_callback(self, *args, **kwargs):
		"""Called instead of callback when expired"""
		pass

	def object_deleted(self, wref):
		"""Called when callback expires"""
		pass

class DbusWeakCallback (WeakCallback):
	"""
	Will use @token if set as follows:
		token.remove()
	"""
	def object_deleted(self, wref):
		if self.token:
			self.token.remove()
			self.token = None

def dbus_signal_connect_weakly(bus, signal, mcallback, **kwargs):
	"""
	Connect method @mcallback to dbus signal using a weak callback

	Connect to @signal on @bus, passing on all keyword arguments
	"""
	weak_cb = DbusWeakCallback(mcallback)
	weak_cb.token = bus.add_signal_receiver(weak_cb, signal, **kwargs)

class GobjectWeakCallback (WeakCallback):
	"""
	Will use @token if set as follows:
		sender.disconnect(token)
	"""
	__senders = {}

	def object_deleted(self, wref):
		sender = self.__senders.pop(self.token, None)
		if sender:
			sender.disconnect(self.token)

	@classmethod
	def _connect(cls, sender, signal, mcallback, *user_args):
		# We save references to the sender in a class variable,
		# this is the only way to have it accessible when obj expires.
		wc = cls(mcallback)
		wc.token = sender.connect(signal, wc, *user_args)
		cls.__senders[wc.token] = sender

def gobject_connect_weakly(sender, signal, mcallback, *user_args):
	"""Connect weakly to GObject @sender's @signal,
	with a callback method @mcallback

	>>> import gtk
	>>> btn = gtk.Button()
	>>> class Handler (object):
	...   def handle(self): pass
	...   def __del__(self): print "deleted"
	...
	>>> h = Handler()
	>>> gobject_connect_weakly(btn, "clicked", h.handle)
	>>> del h
	deleted
	>>>
	"""
	GobjectWeakCallback._connect(sender, signal, mcallback, *user_args)

if __name__ == '__main__':
	import doctest
	doctest.testmod()

########NEW FILE########
__FILENAME__ = kupfer
"""
kupfer      A convenient access and command tool

Copyright 2007--2010 Ulrik Sverdrup <ulrik.sverdrup@gmail.com>

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see <http://www.gnu.org/licenses/>.
"""

if __name__ == '__main__':
	from kupfer import main
	main.main()

########NEW FILE########
__FILENAME__ = ansiterm
import sys, os
try:
	if not (sys.stderr.isatty() and sys.stdout.isatty()):
		raise ValueError('not a tty')

	from ctypes import *

	class COORD(Structure):
		_fields_ = [("X", c_short), ("Y", c_short)]

	class SMALL_RECT(Structure):
		_fields_ = [("Left", c_short), ("Top", c_short), ("Right", c_short), ("Bottom", c_short)]

	class CONSOLE_SCREEN_BUFFER_INFO(Structure):
		_fields_ = [("Size", COORD), ("CursorPosition", COORD), ("Attributes", c_short), ("Window", SMALL_RECT), ("MaximumWindowSize", COORD)]

	class CONSOLE_CURSOR_INFO(Structure):
		_fields_ = [('dwSize',c_ulong), ('bVisible', c_int)]

	sbinfo = CONSOLE_SCREEN_BUFFER_INFO()
	csinfo = CONSOLE_CURSOR_INFO()
	hconsole = windll.kernel32.GetStdHandle(-11)
	windll.kernel32.GetConsoleScreenBufferInfo(hconsole, byref(sbinfo))
	if sbinfo.Size.X < 9 or sbinfo.Size.Y < 9: raise ValueError('small console')
	windll.kernel32.GetConsoleCursorInfo(hconsole, byref(csinfo))
except Exception:
	pass
else:
	import re, threading

	is_vista = getattr(sys, "getwindowsversion", None) and sys.getwindowsversion()[0] >= 6

	try:
		_type = unicode
	except:
		_type = str

	to_int = lambda number, default: number and int(number) or default
	wlock = threading.Lock()

	STD_OUTPUT_HANDLE = -11
	STD_ERROR_HANDLE = -12

	class AnsiTerm(object):
		"""
		emulate a vt100 terminal in cmd.exe
		"""
		def __init__(self):
			self.encoding = sys.stdout.encoding
			self.hconsole = windll.kernel32.GetStdHandle(STD_OUTPUT_HANDLE)
			self.cursor_history = []
			self.orig_sbinfo = CONSOLE_SCREEN_BUFFER_INFO()
			self.orig_csinfo = CONSOLE_CURSOR_INFO()
			windll.kernel32.GetConsoleScreenBufferInfo(self.hconsole, byref(self.orig_sbinfo))
			windll.kernel32.GetConsoleCursorInfo(hconsole, byref(self.orig_csinfo))

		def screen_buffer_info(self):
			sbinfo = CONSOLE_SCREEN_BUFFER_INFO()
			windll.kernel32.GetConsoleScreenBufferInfo(self.hconsole, byref(sbinfo))
			return sbinfo

		def clear_line(self, param):
			mode = param and int(param) or 0
			sbinfo = self.screen_buffer_info()
			if mode == 1: # Clear from begining of line to cursor position
				line_start = COORD(0, sbinfo.CursorPosition.Y)
				line_length = sbinfo.Size.X
			elif mode == 2: # Clear entire line
				line_start = COORD(sbinfo.CursorPosition.X, sbinfo.CursorPosition.Y)
				line_length = sbinfo.Size.X - sbinfo.CursorPosition.X
			else: # Clear from cursor position to end of line
				line_start = sbinfo.CursorPosition
				line_length = sbinfo.Size.X - sbinfo.CursorPosition.X
			chars_written = c_int()
			windll.kernel32.FillConsoleOutputCharacterA(self.hconsole, c_wchar(' '), line_length, line_start, byref(chars_written))
			windll.kernel32.FillConsoleOutputAttribute(self.hconsole, sbinfo.Attributes, line_length, line_start, byref(chars_written))

		def clear_screen(self, param):
			mode = to_int(param, 0)
			sbinfo = self.screen_buffer_info()
			if mode == 1: # Clear from begining of screen to cursor position
				clear_start = COORD(0, 0)
				clear_length = sbinfo.CursorPosition.X * sbinfo.CursorPosition.Y
			elif mode == 2: # Clear entire screen and return cursor to home
				clear_start = COORD(0, 0)
				clear_length = sbinfo.Size.X * sbinfo.Size.Y
				windll.kernel32.SetConsoleCursorPosition(self.hconsole, clear_start)
			else: # Clear from cursor position to end of screen
				clear_start = sbinfo.CursorPosition
				clear_length = ((sbinfo.Size.X - sbinfo.CursorPosition.X) + sbinfo.Size.X * (sbinfo.Size.Y - sbinfo.CursorPosition.Y))
			chars_written = c_int()
			windll.kernel32.FillConsoleOutputCharacterA(self.hconsole, c_wchar(' '), clear_length, clear_start, byref(chars_written))
			windll.kernel32.FillConsoleOutputAttribute(self.hconsole, sbinfo.Attributes, clear_length, clear_start, byref(chars_written))

		def push_cursor(self, param):
			sbinfo = self.screen_buffer_info()
			self.cursor_history.append(sbinfo.CursorPosition)

		def pop_cursor(self, param):
			if self.cursor_history:
				old_pos = self.cursor_history.pop()
				windll.kernel32.SetConsoleCursorPosition(self.hconsole, old_pos)

		def set_cursor(self, param):
			y, sep, x = param.partition(';')
			x = to_int(x, 1) - 1
			y = to_int(y, 1) - 1
			sbinfo = self.screen_buffer_info()
			new_pos = COORD(
				min(max(0, x), sbinfo.Size.X),
				min(max(0, y), sbinfo.Size.Y)
			)
			windll.kernel32.SetConsoleCursorPosition(self.hconsole, new_pos)

		def set_column(self, param):
			x = to_int(param, 1) - 1
			sbinfo = self.screen_buffer_info()
			new_pos = COORD(
				min(max(0, x), sbinfo.Size.X),
				sbinfo.CursorPosition.Y
			)
			windll.kernel32.SetConsoleCursorPosition(self.hconsole, new_pos)

		def move_cursor(self, x_offset=0, y_offset=0):
			sbinfo = self.screen_buffer_info()
			new_pos = COORD(
				min(max(0, sbinfo.CursorPosition.X + x_offset), sbinfo.Size.X),
				min(max(0, sbinfo.CursorPosition.Y + y_offset), sbinfo.Size.Y)
			)
			windll.kernel32.SetConsoleCursorPosition(self.hconsole, new_pos)

		def move_up(self, param):
			self.move_cursor(y_offset = -to_int(param, 1))

		def move_down(self, param):
			self.move_cursor(y_offset = to_int(param, 1))

		def move_left(self, param):
			self.move_cursor(x_offset = -to_int(param, 1))

		def move_right(self, param):
			self.move_cursor(x_offset = to_int(param, 1))

		def next_line(self, param):
			sbinfo = self.screen_buffer_info()
			self.move_cursor(
				x_offset = -sbinfo.CursorPosition.X,
				y_offset = to_int(param, 1)
			)

		def prev_line(self, param):
			sbinfo = self.screen_buffer_info()
			self.move_cursor(
				x_offset = -sbinfo.CursorPosition.X,
				y_offset = -to_int(param, 1)
			)

		def rgb2bgr(self, c):
			return ((c&1) << 2) | (c&2) | ((c&4)>>2)

		def set_color(self, param):
			cols = param.split(';')
			sbinfo = CONSOLE_SCREEN_BUFFER_INFO()
			windll.kernel32.GetConsoleScreenBufferInfo(self.hconsole, byref(sbinfo))
			attr = sbinfo.Attributes
			for c in cols:
				if is_vista:
					c = int(c)
				else:
					c = to_int(c, 0)
				if c in range(30,38): # fgcolor
					attr = (attr & 0xfff0) | self.rgb2bgr(c-30)
				elif c in range(40,48): # bgcolor
					attr = (attr & 0xff0f) | (self.rgb2bgr(c-40) << 4)
				elif c == 0: # reset
					attr = self.orig_sbinfo.Attributes
				elif c == 1: # strong
					attr |= 0x08
				elif c == 4: # blink not available -> bg intensity
					attr |= 0x80
				elif c == 7: # negative
					attr = (attr & 0xff88) | ((attr & 0x70) >> 4) | ((attr & 0x07) << 4)
			windll.kernel32.SetConsoleTextAttribute(self.hconsole, attr)

		def show_cursor(self,param):
			csinfo.bVisible = 1
			windll.kernel32.SetConsoleCursorInfo(self.hconsole, byref(csinfo))

		def hide_cursor(self,param):
			csinfo.bVisible = 0
			windll.kernel32.SetConsoleCursorInfo(self.hconsole, byref(csinfo))

		ansi_command_table = {
			'A': move_up,
			'B': move_down,
			'C': move_right,
			'D': move_left,
			'E': next_line,
			'F': prev_line,
			'G': set_column,
			'H': set_cursor,
			'f': set_cursor,
			'J': clear_screen,
			'K': clear_line,
			'h': show_cursor,
			'l': hide_cursor,
			'm': set_color,
			's': push_cursor,
			'u': pop_cursor,
		}
		# Match either the escape sequence or text not containing escape sequence
		ansi_tokens = re.compile('(?:\x1b\[([0-9?;]*)([a-zA-Z])|([^\x1b]+))')
		def write(self, text):
			try:
				wlock.acquire()
				for param, cmd, txt in self.ansi_tokens.findall(text):
					if cmd:
						cmd_func = self.ansi_command_table.get(cmd)
						if cmd_func:
							cmd_func(self, param)
					else:
						self.writeconsole(txt)
			finally:
				wlock.release()

		def writeconsole(self, txt):
			chars_written = c_int()
			writeconsole = windll.kernel32.WriteConsoleA
			if isinstance(txt, _type):
				writeconsole = windll.kernel32.WriteConsoleW

			TINY_STEP = 3000
			for x in range(0, len(txt), TINY_STEP):
			    # According MSDN, size should NOT exceed 64 kb (issue #746)
			    tiny = txt[x : x + TINY_STEP]
			    writeconsole(self.hconsole, tiny, len(tiny), byref(chars_written), None)

		def flush(self):
			pass

		def isatty(self):
			return True

	sys.stderr = sys.stdout = AnsiTerm()
	os.environ['TERM'] = 'vt100'


########NEW FILE########
__FILENAME__ = Build
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2005-2010 (ita)

"""
Classes related to the build phase (build, clean, install, step, etc)

The inheritance tree is the following:

"""

import os, sys, errno, re, shutil
try: import cPickle
except: import pickle as cPickle
from waflib import Runner, TaskGen, Utils, ConfigSet, Task, Logs, Options, Context, Errors
import waflib.Node

CACHE_DIR = 'c4che'
"""Location of the cache files"""

CACHE_SUFFIX = '_cache.py'
"""Suffix for the cache files"""

INSTALL = 1337
"""Positive value '->' install, see :py:attr:`waflib.Build.BuildContext.is_install`"""

UNINSTALL = -1337
"""Negative value '<-' uninstall, see :py:attr:`waflib.Build.BuildContext.is_install`"""

SAVED_ATTRS = 'root node_deps raw_deps task_sigs'.split()
"""Build class members to save between the runs (root, node_deps, raw_deps, task_sigs)"""

CFG_FILES = 'cfg_files'
"""Files from the build directory to hash before starting the build (``config.h`` written during the configuration)"""

POST_AT_ONCE = 0
"""Post mode: all task generators are posted before the build really starts"""

POST_LAZY = 1
"""Post mode: post the task generators group after group"""

POST_BOTH = 2
"""Post mode: post the task generators at once, then re-check them for each group"""

class BuildContext(Context.Context):
	'''executes the build'''

	cmd = 'build'
	variant = ''

	def __init__(self, **kw):
		super(BuildContext, self).__init__(**kw)

		self.is_install = 0
		"""Non-zero value when installing or uninstalling file"""

		self.top_dir = kw.get('top_dir', Context.top_dir)

		self.run_dir = kw.get('run_dir', Context.run_dir)

		self.post_mode = POST_AT_ONCE
		"""post the task generators at once, group-by-group, or both"""

		# output directory - may be set until the nodes are considered
		self.out_dir = kw.get('out_dir', Context.out_dir)

		self.cache_dir = kw.get('cache_dir', None)
		if not self.cache_dir:
			self.cache_dir = self.out_dir + os.sep + CACHE_DIR

		# map names to environments, the '' must be defined
		self.all_envs = {}

		# ======================================= #
		# cache variables

		self.task_sigs = {}
		"""Signatures of the tasks (persists between build executions)"""

		self.node_deps = {}
		"""Dict of node dependencies found by :py:meth:`waflib.Task.Task.scan` (persists between build executions)"""

		self.raw_deps = {}
		"""Dict of custom data returned by :py:meth:`waflib.Task.Task.scan` (persists between build executions)"""

		# list of folders that are already scanned
		# so that we do not need to stat them one more time
		self.cache_dir_contents = {}

		self.task_gen_cache_names = {}

		self.launch_dir = Context.launch_dir

		self.jobs = Options.options.jobs
		self.targets = Options.options.targets
		self.keep = Options.options.keep
		self.cache_global = Options.cache_global
		self.nocache = Options.options.nocache
		self.progress_bar = Options.options.progress_bar

		############ stuff below has not been reviewed

		# Manual dependencies.
		self.deps_man = Utils.defaultdict(list)
		"""Manual dependencies set by :py:meth:`waflib.Build.BuildContext.add_manual_dependency`"""

		# just the structure here
		self.current_group = 0
		"""
		Current build group
		"""

		self.groups = []
		"""
		List containing lists of task generators
		"""
		self.group_names = {}
		"""
		Map group names to the group lists. See :py:meth:`waflib.Build.BuildContext.add_group`
		"""

	def get_variant_dir(self):
		"""Getter for the variant_dir attribute"""
		if not self.variant:
			return self.out_dir
		return os.path.join(self.out_dir, self.variant)
	variant_dir = property(get_variant_dir, None)

	def __call__(self, *k, **kw):
		"""
		Create a task generator and add it to the current build group. The following forms are equivalent::

			def build(bld):
				tg = bld(a=1, b=2)

			def build(bld):
				tg = bld()
				tg.a = 1
				tg.b = 2

			def build(bld):
				tg = TaskGen.task_gen(a=1, b=2)
				bld.add_to_group(tg, None)

		:param group: group name to add the task generator to
		:type group: string
		"""
		kw['bld'] = self
		ret = TaskGen.task_gen(*k, **kw)
		self.task_gen_cache_names = {} # reset the cache, each time
		self.add_to_group(ret, group=kw.get('group', None))
		return ret

	def __copy__(self):
		"""Implemented to prevents copies of build contexts (raises an exception)"""
		raise Errors.WafError('build contexts are not supposed to be copied')

	def install_files(self, *k, **kw):
		"""Actual implementation provided by :py:meth:`waflib.Build.InstallContext.install_files`"""
		pass

	def install_as(self, *k, **kw):
		"""Actual implementation provided by :py:meth:`waflib.Build.InstallContext.install_as`"""
		pass

	def symlink_as(self, *k, **kw):
		"""Actual implementation provided by :py:meth:`waflib.Build.InstallContext.symlink_as`"""
		pass

	def load_envs(self):
		"""
		The configuration command creates files of the form ``build/c4che/NAMEcache.py``. This method
		creates a :py:class:`waflib.ConfigSet.ConfigSet` instance for each ``NAME`` by reading those
		files. The config sets are then stored in the dict :py:attr:`waflib.Build.BuildContext.allenvs`.
		"""
		node = self.root.find_node(self.cache_dir)
		if not node:
			raise Errors.WafError('The project was not configured: run "waf configure" first!')
		lst = node.ant_glob('**/*%s' % CACHE_SUFFIX, quiet=True)

		if not lst:
			raise Errors.WafError('The cache directory is empty: reconfigure the project')

		for x in lst:
			name = x.path_from(node).replace(CACHE_SUFFIX, '').replace('\\', '/')
			env = ConfigSet.ConfigSet(x.abspath())
			self.all_envs[name] = env
			for f in env[CFG_FILES]:
				newnode = self.root.find_resource(f)
				try:
					h = Utils.h_file(newnode.abspath())
				except (IOError, AttributeError):
					Logs.error('cannot find %r' % f)
					h = Utils.SIG_NIL
				newnode.sig = h

	def init_dirs(self):
		"""
		Initialize the project directory and the build directory by creating the nodes
		:py:attr:`waflib.Build.BuildContext.srcnode` and :py:attr:`waflib.Build.BuildContext.bldnode`
		corresponding to ``top_dir`` and ``variant_dir`` respectively. The ``bldnode`` directory will be
		created if it does not exist.
		"""

		if not (os.path.isabs(self.top_dir) and os.path.isabs(self.out_dir)):
			raise Errors.WafError('The project was not configured: run "waf configure" first!')

		self.path = self.srcnode = self.root.find_dir(self.top_dir)
		self.bldnode = self.root.make_node(self.variant_dir)
		self.bldnode.mkdir()

	def execute(self):
		"""
		Restore the data from previous builds and call :py:meth:`waflib.Build.BuildContext.execute_build`. Overrides from :py:func:`waflib.Context.Context.execute`
		"""
		self.restore()
		if not self.all_envs:
			self.load_envs()

		self.execute_build()

	def execute_build(self):
		"""
		Execute the build by:

		* reading the scripts (see :py:meth:`waflib.Context.Context.recurse`)
		* calling :py:meth:`waflib.Build.BuildContext.pre_build` to call user build functions
		* calling :py:meth:`waflib.Build.BuildContext.compile` to process the tasks
		* calling :py:meth:`waflib.Build.BuildContext.post_build` to call user build functions
		"""

		Logs.info("Waf: Entering directory `%s'" % self.variant_dir)
		self.recurse([self.run_dir])
		self.pre_build()

		# display the time elapsed in the progress bar
		self.timer = Utils.Timer()

		if self.progress_bar:
			sys.stderr.write(Logs.colors.cursor_off)
		try:
			self.compile()
		finally:
			if self.progress_bar == 1:
				c = len(self.returned_tasks) or 1
				self.to_log(self.progress_line(c, c, Logs.colors.BLUE, Logs.colors.NORMAL))
				print('')
				sys.stdout.flush()
				sys.stderr.write(Logs.colors.cursor_on)
			Logs.info("Waf: Leaving directory `%s'" % self.variant_dir)
		self.post_build()

	def restore(self):
		"""
		Load the data from a previous run, sets the attributes listed in :py:const:`waflib.Build.SAVED_ATTRS`
		"""
		try:
			env = ConfigSet.ConfigSet(os.path.join(self.cache_dir, 'build.config.py'))
		except (IOError, OSError):
			pass
		else:
			if env['version'] < Context.HEXVERSION:
				raise Errors.WafError('Version mismatch! reconfigure the project')
			for t in env['tools']:
				self.setup(**t)

		f = None
		try:
			dbfn = os.path.join(self.variant_dir, Context.DBFILE)
			try:
				f = open(dbfn, 'rb')
			except (IOError, EOFError):
				# handle missing file/empty file
				Logs.debug('build: could not load the build cache %s (missing)' % dbfn)
			else:
				try:
					waflib.Node.pickle_lock.acquire()
					waflib.Node.Nod3 = self.node_class
					try:
						data = cPickle.load(f)
					except Exception as e:
						Logs.debug('build: could not pickle the build cache %s: %r' % (dbfn, e))
					else:
						for x in SAVED_ATTRS:
							setattr(self, x, data[x])
				finally:
					waflib.Node.pickle_lock.release()
		finally:
			if f:
				f.close()

		self.init_dirs()

	def store(self):
		"""
		Store the data for next runs, sets the attributes listed in :py:const:`waflib.Build.SAVED_ATTRS`. Uses a temporary
		file to avoid problems on ctrl+c.
		"""

		data = {}
		for x in SAVED_ATTRS:
			data[x] = getattr(self, x)
		db = os.path.join(self.variant_dir, Context.DBFILE)

		try:
			waflib.Node.pickle_lock.acquire()
			waflib.Node.Nod3 = self.node_class

			f = None
			try:
				f = open(db + '.tmp', 'wb')
				cPickle.dump(data, f)
			finally:
				if f:
					f.close()
		finally:
			waflib.Node.pickle_lock.release()

		try:
			st = os.stat(db)
			os.unlink(db)
			if not Utils.is_win32: # win32 has no chown but we're paranoid
				os.chown(db + '.tmp', st.st_uid, st.st_gid)
		except (AttributeError, OSError):
			pass

		# do not use shutil.move (copy is not thread-safe)
		os.rename(db + '.tmp', db)

	def compile(self):
		"""
		Run the build by creating an instance of :py:class:`waflib.Runner.Parallel`
		The cache file is not written if the build is up to date (no task executed).
		"""
		Logs.debug('build: compile()')

		# use another object to perform the producer-consumer logic (reduce the complexity)
		self.producer = Runner.Parallel(self, self.jobs)
		self.producer.biter = self.get_build_iterator()
		self.returned_tasks = [] # not part of the API yet
		try:
			self.producer.start()
		except KeyboardInterrupt:
			self.store()
			raise
		else:
			if self.producer.dirty:
				self.store()

		if self.producer.error:
			raise Errors.BuildError(self.producer.error)

	def setup(self, tool, tooldir=None, funs=None):
		"""
		Import waf tools, used to import those accessed during the configuration::

			def configure(conf):
				conf.load('glib2')

			def build(bld):
				pass # glib2 is imported implicitly

		:param tool: tool list
		:type tool: list
		:param tooldir: optional tool directory (sys.path)
		:type tooldir: list of string
		:param funs: unused variable
		"""
		if isinstance(tool, list):
			for i in tool: self.setup(i, tooldir)
			return

		module = Context.load_tool(tool, tooldir)
		if hasattr(module, "setup"): module.setup(self)

	def get_env(self):
		"""Getter for the env property"""
		try:
			return self.all_envs[self.variant]
		except KeyError:
			return self.all_envs['']
	def set_env(self, val):
		"""Setter for the env property"""
		self.all_envs[self.variant] = val

	env = property(get_env, set_env)

	def add_manual_dependency(self, path, value):
		"""
		Adds a dependency from a node object to a value::

			def build(bld):
				bld.add_manual_dependency(
					bld.path.find_resource('wscript'),
					bld.root.find_resource('/etc/fstab'))

		:param path: file path
		:type path: string or :py:class:`waflib.Node.Node`
		:param value: value to depend on
		:type value: :py:class:`waflib.Node.Node`, string, or function returning a string
		"""
		if isinstance(path, waflib.Node.Node):
			node = path
		elif os.path.isabs(path):
			node = self.root.find_resource(path)
		else:
			node = self.path.find_resource(path)
		self.deps_man[id(node)].append(value)

	def launch_node(self):
		"""Returns the launch directory as a :py:class:`waflib.Node.Node` object"""
		try:
			# private cache
			return self.p_ln
		except AttributeError:
			self.p_ln = self.root.find_dir(self.launch_dir)
			return self.p_ln

	def hash_env_vars(self, env, vars_lst):
		"""
		Hash configuration set variables::

			def build(bld):
				bld.hash_env_vars(bld.env, ['CXX', 'CC'])

		:param env: Configuration Set
		:type env: :py:class:`waflib.ConfigSet.ConfigSet`
		:param vars_lst: list of variables
		:type vars_list: list of string
		"""

		if not env.table:
			env = env.parent
			if not env:
				return Utils.SIG_NIL

		idx = str(id(env)) + str(vars_lst)
		try:
			cache = self.cache_env
		except AttributeError:
			cache = self.cache_env = {}
		else:
			try:
				return self.cache_env[idx]
			except KeyError:
				pass

		lst = [env[a] for a in vars_lst]
		ret = Utils.h_list(lst)
		Logs.debug('envhash: %s %r', Utils.to_hex(ret), lst)

		cache[idx] = ret

		return ret

	def get_tgen_by_name(self, name):
		"""
		Retrieves a task generator from its name or its target name
		the name must be unique::

			def build(bld):
				tg = bld(name='foo')
				tg == bld.get_tgen_by_name('foo')
		"""
		cache = self.task_gen_cache_names
		if not cache:
			# create the index lazily
			for g in self.groups:
				for tg in g:
					try:
						cache[tg.name] = tg
					except AttributeError:
						# raised if not a task generator, which should be uncommon
						pass
		try:
			return cache[name]
		except KeyError:
			raise Errors.WafError('Could not find a task generator for the name %r' % name)

	def progress_line(self, state, total, col1, col2):
		"""
		Compute the progress bar used by ``waf -p``
		"""
		n = len(str(total))

		Utils.rot_idx += 1
		ind = Utils.rot_chr[Utils.rot_idx % 4]

		pc = (100.*state)/total
		eta = str(self.timer)
		fs = "[%%%dd/%%%dd][%%s%%2d%%%%%%s][%s][" % (n, n, ind)
		left = fs % (state, total, col1, pc, col2)
		right = '][%s%s%s]' % (col1, eta, col2)

		cols = Logs.get_term_cols() - len(left) - len(right) + 2*len(col1) + 2*len(col2)
		if cols < 7: cols = 7

		ratio = ((cols*state)//total) - 1

		bar = ('='*ratio+'>').ljust(cols)
		msg = Utils.indicator % (left, bar, right)

		return msg

	def declare_chain(self, *k, **kw):
		"""
		Wrapper for :py:func:`waflib.TaskGen.declare_chain` provided for convenience
		"""
		return TaskGen.declare_chain(*k, **kw)

	def pre_build(self):
		"""Execute user-defined methods before the build starts, see :py:meth:`waflib.Build.BuildContext.add_pre_fun`"""
		for m in getattr(self, 'pre_funs', []):
			m(self)

	def post_build(self):
		"""Executes the user-defined methods after the build is successful, see :py:meth:`waflib.Build.BuildContext.add_post_fun`"""
		for m in getattr(self, 'post_funs', []):
			m(self)

	def add_pre_fun(self, meth):
		"""
		Bind a method to execute after the scripts are read and before the build starts::

			def mycallback(bld):
				print("Hello, world!")

			def build(bld):
				bld.add_pre_fun(mycallback)
		"""
		try:
			self.pre_funs.append(meth)
		except AttributeError:
			self.pre_funs = [meth]

	def add_post_fun(self, meth):
		"""
		Bind a method to execute immediately after the build is successful::

			def call_ldconfig(bld):
				bld.exec_command('/sbin/ldconfig')

			def build(bld):
				if bld.cmd == 'install':
					bld.add_pre_fun(call_ldconfig)
		"""
		try:
			self.post_funs.append(meth)
		except AttributeError:
			self.post_funs = [meth]

	def get_group(self, x):
		"""
		Get the group x, or return the current group if x is None

		:param x: name or number or None
		:type x: string, int or None
		"""
		if not self.groups:
			self.add_group()
		if x is None:
			return self.groups[self.current_group]
		if x in self.group_names:
			return self.group_names[x]
		return self.groups[x]

	def add_to_group(self, tgen, group=None):
		"""add a task or a task generator for the build"""
		# paranoid
		assert(isinstance(tgen, TaskGen.task_gen) or isinstance(tgen, Task.TaskBase))
		tgen.bld = self
		self.get_group(group).append(tgen)

	def get_group_name(self, g):
		"""name for the group g (utility)"""
		if not isinstance(g, list):
			g = self.groups[g]
		for x in self.group_names:
			if id(self.group_names[x]) == id(g):
				return x
		return ''

	def get_group_idx(self, tg):
		"""
		Index of the group containing the task generator given as argument::

			def build(bld):
				tg = bld(name='nada')
				0 == bld.get_group_idx(tg)

		:param tg: Task generator object
		:type tg: :py:class:`waflib.TaskGen.task_gen`
		"""
		se = id(tg)
		for i in range(len(self.groups)):
			for t in self.groups[i]:
				if id(t) == se:
					return i
		return None

	def add_group(self, name=None, move=True):
		"""
		Add a new group of tasks/task generators. By default the new group becomes the default group for new task generators.

		:param name: name for this group
		:type name: string
		:param move: set the group created as default group (True by default)
		:type move: bool
		"""
		#if self.groups and not self.groups[0].tasks:
		#	error('add_group: an empty group is already present')
		if name and name in self.group_names:
			Logs.error('add_group: name %s already present' % name)
		g = []
		self.group_names[name] = g
		self.groups.append(g)
		if move:
			self.current_group = len(self.groups) - 1

	def set_group(self, idx):
		"""
		Set the current group to be idx: now new task generators will be added to this group by default::

			def build(bld):
				bld(rule='touch ${TGT}', target='foo.txt')
				bld.add_group() # now the current group is 1
				bld(rule='touch ${TGT}', target='bar.txt')
				bld.set_group(0) # now the current group is 0
				bld(rule='touch ${TGT}', target='truc.txt') # build truc.txt before bar.txt

		:param idx: group name or group index
		:type idx: string or int
		"""
		if isinstance(idx, str):
			g = self.group_names[idx]
			for i in range(len(self.groups)):
				if id(g) == id(self.groups[i]):
					self.current_group = i
		else:
			self.current_group = idx

	def total(self):
		"""
		Approximate task count: this value may be inaccurate if task generators are posted lazily (see :py:attr:`waflib.Build.BuildContext.post_mode`).
		The value :py:attr:`waflib.Runner.Parallel.total` is updated during the task execution.
		"""
		total = 0
		for group in self.groups:
			for tg in group:
				try:
					total += len(tg.tasks)
				except AttributeError:
					total += 1
		return total

	def get_targets(self):
		"""
		Return the task generator corresponding to the 'targets' list, used by :py:meth:`waflib.Build.BuildContext.get_build_iterator`::

			$ waf --targets=myprogram,myshlib
		"""
		to_post = []
		min_grp = 0
		for name in self.targets.split(','):
			tg = self.get_tgen_by_name(name)
			if not tg:
				raise Errors.WafError('target %r does not exist' % name)

			m = self.get_group_idx(tg)
			if m > min_grp:
				min_grp = m
				to_post = [tg]
			elif m == min_grp:
				to_post.append(tg)
		return (min_grp, to_post)

	def post_group(self):
		"""
		Post the task generators from the group indexed by self.cur, used by :py:meth:`waflib.Build.BuildContext.get_build_iterator`
		"""
		if self.targets == '*':
			for tg in self.groups[self.cur]:
				try:
					f = tg.post
				except AttributeError:
					pass
				else:
					f()
		elif self.targets:
			if self.cur < self._min_grp:
				for tg in self.groups[self.cur]:
					try:
						f = tg.post
					except AttributeError:
						pass
					else:
						f()
			else:
				for tg in self._exact_tg:
					tg.post()
		else:
			ln = self.launch_node()
			for tg in self.groups[self.cur]:
				try:
					f = tg.post
				except AttributeError:
					pass
				else:
					if tg.path.is_child_of(ln):
						f()

	def get_tasks_group(self, idx):
		"""
		Return all the tasks for the group of num idx, used by :py:meth:`waflib.Build.BuildContext.get_build_iterator`
		"""
		tasks = []
		for tg in self.groups[idx]:
			# TODO a try-except might be more efficient
			if isinstance(tg, Task.TaskBase):
				tasks.append(tg)
			else:
				tasks.extend(tg.tasks)
		return tasks

	def get_build_iterator(self):
		"""
		Creates a generator object that returns lists of tasks executable in parallel (yield)

		:return: tasks which can be executed immediatly
		:rtype: list of :py:class:`waflib.Task.TaskBase`
		"""
		self.cur = 0

		if self.targets and self.targets != '*':
			(self._min_grp, self._exact_tg) = self.get_targets()

		global lazy_post
		if self.post_mode != POST_LAZY:
			while self.cur < len(self.groups):
				self.post_group()
				self.cur += 1
			self.cur = 0

		while self.cur < len(self.groups):
			# first post the task generators for the group
			if self.post_mode != POST_AT_ONCE:
				self.post_group()

			# then extract the tasks
			tasks = self.get_tasks_group(self.cur)
			# if the constraints are set properly (ext_in/ext_out, before/after)
			# the call to set_file_constraints may be removed (can be a 15% penalty on no-op rebuilds)
			# (but leave set_file_constraints for the installation step)
			#
			# if the tasks have only files, set_file_constraints is required but set_precedence_constraints is not necessary
			#
			Task.set_file_constraints(tasks)
			Task.set_precedence_constraints(tasks)

			self.cur_tasks = tasks
			self.cur += 1
			if not tasks: # return something else the build will stop
				continue
			yield tasks
		while 1:
			yield []


	#def install_dir(self, path, env=None):
	#	"""
	#	Create empty folders for the installation (very rarely used) TODO
	#	"""
	#	return

class inst(Task.Task):
	"""
    Special task used for installing files and symlinks, it behaves both like a task
	and like a task generator
	"""
	color = 'CYAN'

	def post(self):
		"""
		Same interface as in :py:meth:`waflib.TaskGen.task_gen.post`
		"""
		buf = []
		for x in self.source:
			if isinstance(x, waflib.Node.Node):
				y = x
			else:
				y = self.path.find_resource(x)
				if not y:
					if Logs.verbose:
						Logs.warn('Could not find %s immediately (may cause broken builds)' % x)
					idx = self.generator.bld.get_group_idx(self)
					for tg in self.generator.bld.groups[idx]:
						if not isinstance(tg, inst) and id(tg) != id(self):
							tg.post()
						y = self.path.find_resource(x)
						if y:
							break
					else:
						raise Errors.WafError('could not find %r in %r' % (x, self.path))
			buf.append(y)
		self.inputs = buf

	def runnable_status(self):
		"""
		Installation tasks are always executed, so this method returns either :py:const:`waflib.Task.ASK_LATER` or :py:const:`waflib.Task.RUN_ME`.
		"""
		ret = super(inst, self).runnable_status()
		if ret == Task.SKIP_ME:
			return Task.RUN_ME
		return ret

	def __str__(self):
		"""Return an empty string to disable the display"""
		return ''

	def run(self):
		"""The attribute 'exec_task' holds the method to execute"""
		return self.generator.exec_task()

	def get_install_path(self, destdir=True):
		"""
		Installation path obtained from ``self.dest`` and prefixed by the destdir.
		The variables such as '${PREFIX}/bin' are substituted.
		"""
		dest = Utils.subst_vars(self.dest, self.env)
		dest = dest.replace('/', os.sep)
		if destdir and Options.options.destdir:
			dest = os.path.join(Options.options.destdir, os.path.splitdrive(dest)[1].lstrip(os.sep))
		return dest

	def exec_install_files(self):
		"""
		Predefined method for installing files
		"""
		destpath = self.get_install_path()
		if not destpath:
			raise Errors.WafError('unknown installation path %r' % self.generator)
		for x, y in zip(self.source, self.inputs):
			if self.relative_trick:
				destfile = os.path.join(destpath, y.path_from(self.path))
				Utils.check_dir(os.path.dirname(destfile))
			else:
				destfile = os.path.join(destpath, y.name)
			self.generator.bld.do_install(y.abspath(), destfile, self.chmod)

	def exec_install_as(self):
		"""
		Predefined method for installing one file with a given name
		"""
		destfile = self.get_install_path()
		self.generator.bld.do_install(self.inputs[0].abspath(), destfile, self.chmod)

	def exec_symlink_as(self):
		"""
		Predefined method for installing a symlink
		"""
		destfile = self.get_install_path()
		self.generator.bld.do_link(self.link, destfile)

class InstallContext(BuildContext):
	'''installs the targets on the system'''
	cmd = 'install'

	def __init__(self, **kw):
		super(InstallContext, self).__init__(**kw)

		# list of targets to uninstall for removing the empty folders after uninstalling
		self.uninstall = []
		self.is_install = INSTALL

	def do_install(self, src, tgt, chmod=Utils.O644):
		"""
		Copy a file from src to tgt with given file permissions. The actual copy is not performed
		if the source and target file have the same size and the same timestamps. When the copy occurs,
		the file is first removed and then copied (prevent stale inodes).

		This method is overridden in :py:meth:`waflib.Build.UninstallContext.do_install` to remove the file.

		:param src: file name as absolute path
		:type src: string
		:param tgt: file destination, as absolute path
		:type tgt: string
		:param chmod: installation mode
		:type chmod: int
		"""
		d, _ = os.path.split(tgt)
		if not d:
			raise Errors.WafError('Invalid installation given %r->%r' % (src, tgt))
		Utils.check_dir(d)

		srclbl = src.replace(self.srcnode.abspath() + os.sep, '')
		if not Options.options.force:
			# check if the file is already there to avoid a copy
			try:
				st1 = os.stat(tgt)
				st2 = os.stat(src)
			except OSError:
				pass
			else:
				# same size and identical timestamps -> make no copy
				if st1.st_mtime + 2 >= st2.st_mtime and st1.st_size == st2.st_size:
					if not self.progress_bar:
						Logs.info('- install %s (from %s)' % (tgt, srclbl))
					return False

		if not self.progress_bar:
			Logs.info('+ install %s (from %s)' % (tgt, srclbl))

		# following is for shared libs and stale inodes (-_-)
		try:
			os.remove(tgt)
		except OSError:
			pass

		try:
			shutil.copy2(src, tgt)
			os.chmod(tgt, chmod)
		except IOError:
			try:
				os.stat(src)
			except (OSError, IOError):
				Logs.error('File %r does not exist' % src)
			raise Errors.WafError('Could not install the file %r' % tgt)

	def do_link(self, src, tgt):
		"""
		Create a symlink from tgt to src.

		This method is overridden in :py:meth:`waflib.Build.UninstallContext.do_link` to remove the symlink.

		:param src: file name as absolute path
		:type src: string
		:param tgt: file destination, as absolute path
		:type tgt: string
		"""
		d, _ = os.path.split(tgt)
		Utils.check_dir(d)

		link = False
		if not os.path.islink(tgt):
			link = True
		elif os.readlink(tgt) != src:
			link = True

		if link:
			try: os.remove(tgt)
			except OSError: pass
			if not self.progress_bar:
				Logs.info('+ symlink %s (to %s)' % (tgt, src))
			os.symlink(src, tgt)
		else:
			if not self.progress_bar:
				Logs.info('- symlink %s (to %s)' % (tgt, src))

	def run_task_now(self, tsk, postpone):
		"""
		This method is called by :py:meth:`waflib.Build.InstallContext.install_files`,
		:py:meth:`waflib.Build.InstallContext.install_as` and :py:meth:`waflib.Build.InstallContext.symlink_as` immediately
		after the installation task is created. Its role is to force the immediate execution if necessary, that is when
		``postpone=False`` was given.
		"""
		tsk.post()
		if not postpone:
			if tsk.runnable_status() == Task.ASK_LATER:
				raise self.WafError('cannot post the task %r' % tsk)
			tsk.run()

	def install_files(self, dest, files, env=None, chmod=Utils.O644, relative_trick=False, cwd=None, add=True, postpone=True):
		"""
		Create a task to install files on the system::

			def build(bld):
				bld.install_files('${DATADIR}', self.path.find_resource('wscript'))

		:param dest: absolute path of the destination directory
		:type dest: string
		:param files: input files
		:type files: list of strings or list of nodes
		:param env: configuration set for performing substitutions in dest
		:type env: Configuration set
		:param relative_trick: preserve the folder hierarchy when installing whole folders
		:type relative_trick: bool
		:param cwd: parent node for searching srcfile, when srcfile is not a :py:class:`waflib.Node.Node`
		:type cwd: :py:class:`waflib.Node.Node`
		:param add: add the task created to a build group - set ``False`` only if the installation task is created after the build has started
		:type add: bool
		:param postpone: execute the task immediately to perform the installation
		:type postpone: bool
		"""
		tsk = inst(env=env or self.env)
		tsk.bld = self
		tsk.path = cwd or self.path
		tsk.chmod = chmod
		if isinstance(files, waflib.Node.Node):
			tsk.source =  [files]
		else:
			tsk.source = Utils.to_list(files)
		tsk.dest = dest
		tsk.exec_task = tsk.exec_install_files
		tsk.relative_trick = relative_trick
		if add: self.add_to_group(tsk)
		self.run_task_now(tsk, postpone)
		return tsk

	def install_as(self, dest, srcfile, env=None, chmod=Utils.O644, cwd=None, add=True, postpone=True):
		"""
		Create a task to install a file on the system with a different name::

			def build(bld):
				bld.install_as('${PREFIX}/bin', 'myapp', chmod=Utils.O755)

		:param dest: absolute path of the destination file
		:type dest: string
		:param srcfile: input file
		:type srcfile: string or node
		:param cwd: parent node for searching srcfile, when srcfile is not a :py:class:`waflib.Node.Node`
		:type cwd: :py:class:`waflib.Node.Node`
		:param env: configuration set for performing substitutions in dest
		:type env: Configuration set
		:param add: add the task created to a build group - set ``False`` only if the installation task is created after the build has started
		:type add: bool
		:param postpone: execute the task immediately to perform the installation
		:type postpone: bool
		"""
		tsk = inst(env=env or self.env)
		tsk.bld = self
		tsk.path = cwd or self.path
		tsk.chmod = chmod
		tsk.source = [srcfile]
		tsk.dest = dest
		tsk.exec_task = tsk.exec_install_as
		if add: self.add_to_group(tsk)
		self.run_task_now(tsk, postpone)
		return tsk

	def symlink_as(self, dest, src, env=None, cwd=None, add=True, postpone=True):
		"""
		Create a task to install a symlink::

			def build(bld):
				bld.symlink_as('${PREFIX}/lib/libfoo.so', 'libfoo.so.1.2.3')

		:param dest: absolute path of the symlink
		:type dest: string
		:param src: absolute or relative path of the link
		:type src: string
		:param env: configuration set for performing substitutions in dest
		:type env: Configuration set
		:param add: add the task created to a build group - set ``False`` only if the installation task is created after the build has started
		:type add: bool
		:param postpone: execute the task immediately to perform the installation
		:type postpone: bool
		"""

		if Utils.is_win32:
			# symlinks *cannot* work on that platform
			return

		tsk = inst(env=env or self.env)
		tsk.bld = self
		tsk.dest = dest
		tsk.path = cwd or self.path
		tsk.source = []
		tsk.link = src
		tsk.exec_task = tsk.exec_symlink_as
		if add: self.add_to_group(tsk)
		self.run_task_now(tsk, postpone)
		return tsk

class UninstallContext(InstallContext):
	'''removes the targets installed'''
	cmd = 'uninstall'

	def __init__(self, **kw):
		super(UninstallContext, self).__init__(**kw)
		self.is_install = UNINSTALL

	def do_install(self, src, tgt, chmod=Utils.O644):
		"""See :py:meth:`waflib.Build.InstallContext.do_install`"""
		if not self.progress_bar:
			Logs.info('- remove %s' % tgt)

		self.uninstall.append(tgt)
		try:
			os.remove(tgt)
		except OSError as e:
			if e.errno != errno.ENOENT:
				if not getattr(self, 'uninstall_error', None):
					self.uninstall_error = True
					Logs.warn('build: some files could not be uninstalled (retry with -vv to list them)')
				if Logs.verbose > 1:
					Logs.warn('could not remove %s (error code %r)' % (e.filename, e.errno))

		# TODO ita refactor this into a post build action to uninstall the folders (optimization)
		while tgt:
			tgt = os.path.dirname(tgt)
			try:
				os.rmdir(tgt)
			except OSError:
				break

	def do_link(self, src, tgt):
		"""See :py:meth:`waflib.Build.InstallContext.do_link`"""
		try:
			if not self.progress_bar:
				Logs.info('- unlink %s' % tgt)
			os.remove(tgt)
		except OSError:
			pass

		# TODO ita refactor this into a post build action to uninstall the folders (optimization)?
		while tgt:
			tgt = os.path.dirname(tgt)
			try:
				os.rmdir(tgt)
			except OSError:
				break

	def execute(self):
		"""
		See :py:func:`waflib.Context.Context.execute`
		"""
		try:
			# do not execute any tasks
			def runnable_status(self):
				return Task.SKIP_ME
			setattr(Task.Task, 'runnable_status_back', Task.Task.runnable_status)
			setattr(Task.Task, 'runnable_status', runnable_status)

			super(UninstallContext, self).execute()
		finally:
			setattr(Task.Task, 'runnable_status', Task.Task.runnable_status_back)

class CleanContext(BuildContext):
	'''cleans the project'''
	cmd = 'clean'
	def execute(self):
		"""
		See :py:func:`waflib.Context.Context.execute`
		"""
		self.restore()
		if not self.all_envs:
			self.load_envs()

		self.recurse([self.run_dir])
		try:
			self.clean()
		finally:
			self.store()

	def clean(self):
		"""clean the data and some files in the build dir .. well, TODO"""
		Logs.debug('build: clean called')

		if self.bldnode != self.srcnode:
			# would lead to a disaster if top == out
			lst = [self.root.find_or_declare(f) for f in self.env[CFG_FILES]]
			for n in self.bldnode.ant_glob('**/*', excl='lock* *conf_check_*/** config.log c4che/*', quiet=True):
				if n in lst:
					continue
				n.delete()
		self.root.children = {}

		for v in 'node_deps task_sigs raw_deps'.split():
			setattr(self, v, {})

class ListContext(BuildContext):
	'''lists the targets to execute'''

	cmd = 'list'
	def execute(self):
		"""
		See :py:func:`waflib.Context.Context.execute`.
		"""
		self.restore()
		if not self.all_envs:
			self.load_envs()

		self.recurse([self.run_dir])
		self.pre_build()

		# display the time elapsed in the progress bar
		self.timer = Utils.Timer()

		for g in self.groups:
			for tg in g:
				try:
					f = tg.post
				except AttributeError:
					pass
				else:
					f()

		try:
			# force the cache initialization
			self.get_tgen_by_name('')
		except:
			pass
		lst = list(self.task_gen_cache_names.keys())
		lst.sort()
		for k in lst:
			Logs.pprint('GREEN', k)

class StepContext(BuildContext):
	'''executes tasks in a step-by-step fashion, for debugging'''
	cmd = 'step'

	def __init__(self, **kw):
		super(StepContext, self).__init__(**kw)
		self.files = Options.options.files

	def compile(self):
		"""
		Compile the tasks matching the input/output files given (regular expression matching). Derived from :py:meth:`waflib.Build.BuildContext.compile`::

			$ waf step --files=foo.c,bar.c,in:truc.c,out:bar.o
			$ waf step --files=in:foo.cpp.1.o # link task only

		"""
		if not self.files:
			Logs.warn('Add a pattern for the debug build, for example "waf step --files=main.c,app"')
			BuildContext.compile(self)
			return

		for g in self.groups:
			for tg in g:
				try:
					f = tg.post
				except AttributeError:
					pass
				else:
					f()

			for pat in self.files.split(','):
				matcher = self.get_matcher(pat)
				for tg in g:
					if isinstance(tg, Task.TaskBase):
						lst = [tg]
					else:
						lst = tg.tasks
					for tsk in lst:
						do_exec = False
						for node in getattr(tsk, 'inputs', []):
							if matcher(node, output=False):
								do_exec = True
								break
						for node in getattr(tsk, 'outputs', []):
							if matcher(node, output=True):
								do_exec = True
								break
						if do_exec:
							ret = tsk.run()
							Logs.info('%s -> exit %r' % (str(tsk), ret))

	def get_matcher(self, pat):
		# this returns a function
		inn = True
		out = True
		if pat.startswith('in:'):
			out = False
			pat = pat.replace('in:', '')
		elif pat.startswith('out:'):
			inn = False
			pat = pat.replace('out:', '')

		anode = self.root.find_node(pat)
		pattern = None
		if not anode:
			if not pat.startswith('^'):
				pat = '^.+?%s' % pat
			if not pat.endswith('$'):
				pat = '%s$' % pat
			pattern = re.compile(pat)

		def match(node, output):
			if output == True and not out:
				return False
			if output == False and not inn:
				return False

			if anode:
				return anode == node
			else:
				return pattern.match(node.abspath())
		return match

BuildContext.store = Utils.nogc(BuildContext.store)
BuildContext.restore = Utils.nogc(BuildContext.restore)


########NEW FILE########
__FILENAME__ = ConfigSet
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2005-2010 (ita)

"""

ConfigSet: a special dict

The values put in :py:class:`ConfigSet` must be lists
"""

import copy, re, os
from waflib import Logs, Utils
re_imp = re.compile('^(#)*?([^#=]*?)\ =\ (.*?)$', re.M)

class ConfigSet(object):
	"""
	A dict that honor serialization and parent relationships. The serialization format
	is human-readable (python-like) and performed by using eval() and repr().
	For high performance prefer pickle. Do not store functions as they are not serializable.

	The values can be accessed by attributes or by keys::

		from waflib.ConfigSet import ConfigSet
		env = ConfigSet()
		env.FOO = 'test'
		env['FOO'] = 'test'
	"""
	__slots__ = ('table', 'parent')
	def __init__(self, filename=None):
		self.table = {}
		"""
		Internal dict holding the object values
		"""
		#self.parent = None

		if filename:
			self.load(filename)

	def __contains__(self, key):
		"""
		Enable the *in* syntax::

			if 'foo' in env:
				print env['foo']
		"""
		if key in self.table: return True
		try: return self.parent.__contains__(key)
		except AttributeError: return False # parent may not exist

	def keys(self):
		"""Dict interface (unknown purpose)"""
		keys = set()
		cur = self
		while cur:
			keys.update(cur.table.keys())
			cur = getattr(cur, 'parent', None)
		keys = list(keys)
		keys.sort()
		return keys

	def __str__(self):
		"""Text representation of the ConfigSet (for debugging purposes)"""
		return "\n".join(["%r %r" % (x, self.__getitem__(x)) for x in self.keys()])

	def __getitem__(self, key):
		"""
		Dictionary interface: get value from key::

			def configure(conf):
				conf.env['foo'] = {}
				print(env['foo'])
		"""
		try:
			while 1:
				x = self.table.get(key, None)
				if not x is None:
					return x
				self = self.parent
		except AttributeError:
			return []

	def __setitem__(self, key, value):
		"""
		Dictionary interface: get value from key
		"""
		self.table[key] = value

	def __delitem__(self, key):
		"""
		Dictionary interface: get value from key
		"""
		self[key] = []

	def __getattr__(self, name):
		"""
		Attribute access provided for convenience. The following forms are equivalent::

			def configure(conf):
				conf.env.value
				conf.env['value']
		"""
		if name in self.__slots__:
			return object.__getattr__(self, name)
		else:
			return self[name]

	def __setattr__(self, name, value):
		"""
		Attribute access provided for convenience. The following forms are equivalent::

			def configure(conf):
				conf.env.value = x
				env['value'] = x
		"""
		if name in self.__slots__:
			object.__setattr__(self, name, value)
		else:
			self[name] = value

	def __delattr__(self, name):
		"""
		Attribute access provided for convenience. The following forms are equivalent::

			def configure(conf):
				del env.value
				del env['value']
		"""
		if name in self.__slots__:
			object.__delattr__(self, name)
		else:
			del self[name]

	def derive(self):
		"""
		Returns a new ConfigSet deriving from self. The copy returned
		will be a shallow copy::

			from waflib.ConfigSet import ConfigSet
			env = ConfigSet()
			env.append_value('CFLAGS', ['-O2'])
			child = env.derive()
			child.CFLAGS.append('test') # warning! this will modify 'env'
			child.CFLAGS = ['-O3'] # new list, ok
			child.append_value('CFLAGS', ['-O3']) # ok

		Use :py:func:`ConfigSet.detach` to detach the child from the parent.
		"""
		newenv = ConfigSet()
		newenv.parent = self
		return newenv

	def detach(self):
		"""
		Detach self from its parent (if existing)

		Modifying the parent :py:class:`ConfigSet` will not change the current object
		Modifying this :py:class:`ConfigSet` will not modify the parent one.
		"""
		tbl = self.get_merged_dict()
		try:
			delattr(self, 'parent')
		except AttributeError:
			pass
		else:
			keys = tbl.keys()
			for x in keys:
				tbl[x] = copy.deepcopy(tbl[x])
			self.table = tbl

	def get_flat(self, key):
		"""
		Return a value as a string. If the input is a list, the value returned is space-separated.

		:param key: key to use
		:type key: string
		"""
		s = self[key]
		if isinstance(s, str): return s
		return ' '.join(s)

	def _get_list_value_for_modification(self, key):
		"""
		Return a list value for further modification.

		The list may be modified inplace and there is no need to do this afterwards::

			self.table[var] = value
		"""
		try:
			value = self.table[key]
		except KeyError:
			try: value = self.parent[key]
			except AttributeError: value = []
			if isinstance(value, list):
				value = value[:]
			else:
				value = [value]
		else:
			if not isinstance(value, list):
				value = [value]
		self.table[key] = value
		return value

	def append_value(self, var, val):
		"""
		Appends a value to the specified config key::

			def build(bld):
				bld.env.append_value('CFLAGS', ['-O2'])

		The value must be a list or a tuple
		"""
		current_value = self._get_list_value_for_modification(var)
		if isinstance(val, str): # if there were string everywhere we could optimize this
			val = [val]
		current_value.extend(val)

	def prepend_value(self, var, val):
		"""
		Prepends a value to the specified item::

			def configure(conf):
				conf.env.prepend_value('CFLAGS', ['-O2'])

		The value must be a list or a tuple
		"""
		if isinstance(val, str):
			val = [val]
		self.table[var] =  val + self._get_list_value_for_modification(var)

	def append_unique(self, var, val):
		"""
		Append a value to the specified item only if it's not already present::

			def build(bld):
				bld.env.append_unique('CFLAGS', ['-O2', '-g'])

		The value must be a list or a tuple
		"""
		if isinstance(val, str):
			val = [val]
		current_value = self._get_list_value_for_modification(var)

		for x in val:
			if x not in current_value:
				current_value.append(x)

	def get_merged_dict(self):
		"""
		Compute the merged dictionary from the fusion of self and all its parent

		:rtype: a ConfigSet object
		"""
		table_list = []
		env = self
		while 1:
			table_list.insert(0, env.table)
			try: env = env.parent
			except AttributeError: break
		merged_table = {}
		for table in table_list:
			merged_table.update(table)
		return merged_table

	def store(self, filename):
		"""
		Write the :py:class:`ConfigSet` data into a file. See :py:meth:`ConfigSet.load` for reading such files.

		:param filename: file to use
		:type filename: string
		"""
		try:
			os.makedirs(os.path.split(filename)[0])
		except OSError:
			pass

		f = None
		try:
			f = open(filename, 'w')
			merged_table = self.get_merged_dict()
			keys = list(merged_table.keys())
			keys.sort()
			for k in keys:
				if k != 'undo_stack':
					f.write('%s = %r\n' % (k, merged_table[k]))
		finally:
			if f:
				f.close()

	def load(self, filename):
		"""
		Retrieve the :py:class:`ConfigSet` data from a file. See :py:meth:`ConfigSet.store` for writing such files

		:param filename: file to use
		:type filename: string
		"""
		tbl = self.table
		code = Utils.readf(filename)
		for m in re_imp.finditer(code):
			g = m.group
			tbl[g(2)] = eval(g(3))
		Logs.debug('env: %s' % str(self.table))

	def update(self, d):
		"""
		Dictionary interface: replace values from another dict

		:param d: object to use the value from
		:type d: dict-like object
		"""
		for k, v in d.items():
			self[k] = v

	def stash(self):
		"""
		Store the object state, to provide a kind of transaction support::

			env = ConfigSet()
			env.stash()
			try:
				env.append_value('CFLAGS', '-O3')
				call_some_method(env)
			finally:
				env.revert()

		The history is kept in a stack, and is lost during the serialization by :py:meth:`ConfigSet.store`
		"""
		self.undo_stack = self.undo_stack + [self.table]
		self.table = self.table.copy()

	def revert(self):
		"""
		Reverts the object to a previous state. See :py:meth:`ConfigSet.stash`
		"""
		self.table = self.undo_stack.pop(-1)


########NEW FILE########
__FILENAME__ = Configure
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2005-2010 (ita)

"""
Configuration system

A :py:class:`waflib.Configure.ConfigurationContext` instance is created when ``waf configure`` is called, it is used to:

* create data dictionaries (ConfigSet instances)
* store the list of modules to import
* hold configuration routines such as ``find_program``, etc
"""

import os, shlex, sys, time
from waflib import ConfigSet, Utils, Options, Logs, Context, Build, Errors

try:
	from urllib import request
except:
	from urllib import urlopen
else:
	urlopen = request.urlopen

BREAK    = 'break'
"""In case of a configuration error, break"""

CONTINUE = 'continue'
"""In case of a configuration error, continue"""

WAF_CONFIG_LOG = 'config.log'
"""Name of the configuration log file"""

autoconfig = False
"""Execute the configuration automatically"""

conf_template = '''# project %(app)s configured on %(now)s by
# waf %(wafver)s (abi %(abi)s, python %(pyver)x on %(systype)s)
# using %(args)s
#'''

def download_check(node):
	"""
	Hook to check for the tools which are downloaded. Replace with your function if necessary.
	"""
	pass

def download_tool(tool, force=False, ctx=None):
	"""
	Download a Waf tool from the remote repository defined in :py:const:`waflib.Context.remote_repo`::

		$ waf configure --download
	"""
	for x in Utils.to_list(Context.remote_repo):
		for sub in Utils.to_list(Context.remote_locs):
			url = '/'.join((x, sub, tool + '.py'))
			try:
				web = urlopen(url)
				try:
					if web.getcode() != 200:
						continue
				except AttributeError:
					pass
			except Exception:
				# on python3 urlopen throws an exception
				# python 2.3 does not have getcode and throws an exception to fail
				continue
			else:
				tmp = ctx.root.make_node(os.sep.join((Context.waf_dir, 'waflib', 'extras', tool + '.py')))
				tmp.write(web.read())
				Logs.warn('Downloaded %s from %s' % (tool, url))
				download_check(tmp)
				try:
					module = Context.load_tool(tool)
				except:
					Logs.warn('The tool %s from %s is unusable' % (tool, url))
					try:
						tmp.delete()
					except:
						pass
					continue
				return module
	raise Errors.WafError('Could not load the Waf tool')

class ConfigurationContext(Context.Context):
	'''configures the project'''

	cmd = 'configure'

	error_handlers = []
	"""
	Additional functions to handle configuration errors
	"""

	def __init__(self, **kw):
		super(ConfigurationContext, self).__init__(**kw)
		self.environ = dict(os.environ)
		self.all_envs = {}

		self.top_dir = None
		self.out_dir = None

		self.tools = [] # tools loaded in the configuration, and that will be loaded when building

		self.hash = 0
		self.files = []

		self.tool_cache = []

		self.setenv('')

	def setenv(self, name, env=None):
		"""
		Set a new config set for conf.env. If a config set of that name already exists,
		recall it without modification.

		The name is the filename prefix to save to ``c4che/NAME_cache.py``, and it
		is also used as *variants* by the build commands.
		Though related to variants, whatever kind of data may be stored in the config set::

			def configure(cfg):
				cfg.env.ONE = 1
				cfg.setenv('foo')
				cfg.env.ONE = 2

			def build(bld):
				2 == bld.env_of_name('foo').ONE

		:param name: name of the configuration set
		:type name: string
		:param env: ConfigSet to copy, or an empty ConfigSet is created
		:type env: :py:class:`waflib.ConfigSet.ConfigSet`
		"""
		if name not in self.all_envs or env:
			if not env:
				env = ConfigSet.ConfigSet()
				self.prepare_env(env)
			else:
				env = env.derive()
			self.all_envs[name] = env
		self.variant = name

	def get_env(self):
		"""Getter for the env property"""
		return self.all_envs[self.variant]
	def set_env(self, val):
		"""Setter for the env property"""
		self.all_envs[self.variant] = val

	env = property(get_env, set_env)

	def init_dirs(self):
		"""
		Initialize the project directory and the build directory
		"""

		top = self.top_dir
		if not top:
			top = Options.options.top
		if not top:
			top = getattr(Context.g_module, Context.TOP, None)
		if not top:
			top = self.path.abspath()
		top = os.path.abspath(top)

		self.srcnode = (os.path.isabs(top) and self.root or self.path).find_dir(top)
		assert(self.srcnode)

		out = self.out_dir
		if not out:
			out = Options.options.out
		if not out:
			out = getattr(Context.g_module, Context.OUT, None)
		if not out:
			out = Options.lockfile.replace('.lock-waf_%s_' % sys.platform, '').replace('.lock-waf', '')

		self.bldnode = (os.path.isabs(out) and self.root or self.path).make_node(out)
		self.bldnode.mkdir()

		if not os.path.isdir(self.bldnode.abspath()):
			conf.fatal('could not create the build directory %s' % self.bldnode.abspath())

	def execute(self):
		"""
		See :py:func:`waflib.Context.Context.execute`
		"""
		self.init_dirs()

		self.cachedir = self.bldnode.make_node(Build.CACHE_DIR)
		self.cachedir.mkdir()

		path = os.path.join(self.bldnode.abspath(), WAF_CONFIG_LOG)
		self.logger = Logs.make_logger(path, 'cfg')

		app = getattr(Context.g_module, 'APPNAME', '')
		if app:
			ver = getattr(Context.g_module, 'VERSION', '')
			if ver:
				app = "%s (%s)" % (app, ver)

		now = time.ctime()
		pyver = sys.hexversion
		systype = sys.platform
		args = " ".join(sys.argv)
		wafver = Context.WAFVERSION
		abi = Context.ABI
		self.to_log(conf_template % vars())

		self.msg('Setting top to', self.srcnode.abspath())
		self.msg('Setting out to', self.bldnode.abspath())

		if id(self.srcnode) == id(self.bldnode):
			Logs.warn('Setting top == out (remember to use "update_outputs")')
		elif id(self.path) != id(self.srcnode):
			if self.srcnode.is_child_of(self.path):
				Logs.warn('Are you certain that you do not want to set top="." ?')

		super(ConfigurationContext, self).execute()

		self.store()

		Context.top_dir = self.srcnode.abspath()
		Context.out_dir = self.bldnode.abspath()

		# this will write a configure lock so that subsequent builds will
		# consider the current path as the root directory (see prepare_impl).
		# to remove: use 'waf distclean'
		env = ConfigSet.ConfigSet()
		env['argv'] = sys.argv
		env['options'] = Options.options.__dict__

		env.run_dir = Context.run_dir
		env.top_dir = Context.top_dir
		env.out_dir = Context.out_dir

		# conf.hash & conf.files hold wscript files paths and hash
		# (used only by Configure.autoconfig)
		env['hash'] = self.hash
		env['files'] = self.files
		env['environ'] = dict(self.environ)

		if not self.env.NO_LOCK_IN_RUN:
			env.store(Context.run_dir + os.sep + Options.lockfile)
		if not self.env.NO_LOCK_IN_TOP:
			env.store(Context.top_dir + os.sep + Options.lockfile)
		if not self.env.NO_LOCK_IN_OUT:
			env.store(Context.out_dir + os.sep + Options.lockfile)

	def prepare_env(self, env):
		"""
		Insert *PREFIX*, *BINDIR* and *LIBDIR* values into ``env``

		:type env: :py:class:`waflib.ConfigSet.ConfigSet`
		:param env: a ConfigSet, usually ``conf.env``
		"""
		if not env.PREFIX:
			env.PREFIX = os.path.abspath(os.path.expanduser(Options.options.prefix))
		if not env.BINDIR:
			env.BINDIR = Utils.subst_vars('${PREFIX}/bin', env)
		if not env.LIBDIR:
			env.LIBDIR = Utils.subst_vars('${PREFIX}/lib', env)

	def store(self):
		"""Save the config results into the cache file"""
		n = self.cachedir.make_node('build.config.py')
		n.write('version = 0x%x\ntools = %r\n' % (Context.HEXVERSION, self.tools))

		if not self.all_envs:
			self.fatal('nothing to store in the configuration context!')

		for key in self.all_envs:
			tmpenv = self.all_envs[key]
			tmpenv.store(os.path.join(self.cachedir.abspath(), key + Build.CACHE_SUFFIX))

	def load(self, input, tooldir=None, funs=None, download=True):
		"""
		Load Waf tools, which will be imported whenever a build is started.

		:param input: waf tools to import
		:type input: list of string
		:param tooldir: paths for the imports
		:type tooldir: list of string
		:param funs: functions to execute from the waf tools
		:type funs: list of string
		:param download: whether to download the tool from the waf repository
		:type download: bool
		"""

		tools = Utils.to_list(input)
		if tooldir: tooldir = Utils.to_list(tooldir)
		for tool in tools:
			# avoid loading the same tool more than once with the same functions
			# used by composite projects

			mag = (tool, id(self.env), funs)
			if mag in self.tool_cache:
				self.to_log('(tool %s is already loaded, skipping)' % tool)
				continue
			self.tool_cache.append(mag)

			module = None
			try:
				module = Context.load_tool(tool, tooldir)
			except ImportError as e:
				if Options.options.download:
					module = download_tool(tool, ctx=self)
					if not module:
						self.fatal('Could not load the Waf tool %r or download a suitable replacement from the repository (sys.path %r)\n%s' % (tool, sys.path, e))
				else:
					self.fatal('Could not load the Waf tool %r from %r (try the --download option?):\n%s' % (tool, sys.path, e))
			except Exception as e:
				self.to_log('imp %r (%r & %r)' % (tool, tooldir, funs))
				self.to_log(Utils.ex_stack())
				raise

			if funs is not None:
				self.eval_rules(funs)
			else:
				func = getattr(module, 'configure', None)
				if func:
					if type(func) is type(Utils.readf): func(self)
					else: self.eval_rules(func)

			self.tools.append({'tool':tool, 'tooldir':tooldir, 'funs':funs})

	def post_recurse(self, node):
		"""
		Records the path and a hash of the scripts visited, see :py:meth:`waflib.Context.Context.post_recurse`

		:param node: script
		:type node: :py:class:`waflib.Node.Node`
		"""
		super(ConfigurationContext, self).post_recurse(node)
		self.hash = hash((self.hash, node.read('rb')))
		self.files.append(node.abspath())

	def eval_rules(self, rules):
		"""
		Execute the configuration tests. The method :py:meth:`waflib.Configure.ConfigurationContext.err_handler`
		is used to process the eventual exceptions

		:param rules: list of configuration method names
		:type rules: list of string
		"""
		self.rules = Utils.to_list(rules)
		for x in self.rules:
			f = getattr(self, x)
			if not f: self.fatal("No such method '%s'." % x)
			try:
				f()
			except Exception as e:
				ret = self.err_handler(x, e)
				if ret == BREAK:
					break
				elif ret == CONTINUE:
					continue
				else:
					raise

	def err_handler(self, fun, error):
		"""
		Error handler for the configuration tests, the default is to let the exception raise

		:param fun: configuration test
		:type fun: method
		:param error: exception
		:type error: exception
		"""
		pass

def conf(f):
	"""
	Decorator: attach new configuration functions to :py:class:`waflib.Build.BuildContext` and
	:py:class:`waflib.Configure.ConfigurationContext`. The methods bound will accept a parameter
	named 'mandatory' to disable the configuration errors::

		def configure(conf):
			conf.find_program('abc', mandatory=False)

	:param f: method to bind
	:type f: function
	"""
	def fun(*k, **kw):
		mandatory = True
		if 'mandatory' in kw:
			mandatory = kw['mandatory']
			del kw['mandatory']

		try:
			return f(*k, **kw)
		except Errors.ConfigurationError as e:
			if mandatory:
				raise e

	setattr(ConfigurationContext, f.__name__, fun)
	setattr(Build.BuildContext, f.__name__, fun)
	return f

@conf
def add_os_flags(self, var, dest=None):
	"""
	Import operating system environment values into ``conf.env`` dict::

		def configure(conf):
			conf.add_os_flags('CFLAGS')

	:param var: variable to use
	:type var: string
	:param dest: destination variable, by default the same as var
	:type dest: string
	"""
	# do not use 'get' to make certain the variable is not defined
	try: self.env.append_value(dest or var, shlex.split(self.environ[var]))
	except KeyError: pass

@conf
def cmd_to_list(self, cmd):
	"""
	Detect if a command is written in pseudo shell like ``ccache g++`` and return a list.

	:param cmd: command
	:type cmd: a string or a list of string
	"""
	if isinstance(cmd, str) and cmd.find(' '):
		try:
			os.stat(cmd)
		except OSError:
			return shlex.split(cmd)
		else:
			return [cmd]
	return cmd

@conf
def check_waf_version(self, mini='1.6.0', maxi='1.7.0'):
	"""
	check for the waf version

	Versions should be supplied as hex. 0x01000000 means 1.0.0,
	0x010408 means 1.4.8, etc.

	:type  mini: number, tuple or string
	:param mini: Minimum required version
	:type  maxi: number, tuple or string
	:param maxi: Maximum allowed version
	"""
	self.start_msg('Checking for waf version in %s-%s' % (str(mini), str(maxi)))
	ver = Context.HEXVERSION
	if Utils.num2ver(mini) > ver:
		self.fatal('waf version should be at least %r (%r found)' % (Utils.num2ver(mini), ver))

	if Utils.num2ver(maxi) < ver:
		self.fatal('waf version should be at most %r (%r found)' % (Utils.num2ver(maxi), ver))
	self.end_msg('ok')

@conf
def find_file(self, filename, path_list=[]):
	"""
	Find a file in a list of paths

	:param filename: name of the file to search for
	:param path_list: list of directories to search
	:return: the first occurrence filename or '' if filename could not be found
	"""
	for n in Utils.to_list(filename):
		for d in Utils.to_list(path_list):
			p = os.path.join(d, n)
			if os.path.exists(p):
				return p
	self.fatal('Could not find %r' % filename)

@conf
def find_program(self, filename, **kw):
	"""
	Search for a program on the operating system

	When var is used, you may set os.environ[var] to help find a specific program version, for example::

		$ VALAC=/usr/bin/valac_test waf configure

	:param path_list: paths to use for searching
	:type param_list: list of string
	:param var: store the result to conf.env[var], by default use filename.upper()
	:type var: string
	:param ext: list of extensions for the binary (do not add an extension for portability)
	:type ext: list of string
	"""

	exts = kw.get('exts', Utils.is_win32 and '.exe,.com,.bat,.cmd' or ',.sh,.pl,.py')

	environ = kw.get('environ', os.environ)

	ret = ''
	filename = Utils.to_list(filename)

	var = kw.get('var', '')
	if not var:
		var = filename[0].upper()

	if self.env[var]:
		ret = self.env[var]
	elif var in environ:
		ret = environ[var]

	path_list = kw.get('path_list', '')
	if not ret:
		if path_list:
			path_list = Utils.to_list(path_list)
		else:
			path_list = environ.get('PATH', '').split(os.pathsep)

		if not isinstance(filename, list):
			filename = [filename]

		for a in exts.split(','):
			if ret:
				break
			for b in filename:
				if ret:
					break
				for c in path_list:
					if ret:
						break
					x = os.path.expanduser(os.path.join(c, b + a))
					if os.path.isfile(x):
						ret = x

	if not ret and Utils.winreg:
		ret = Utils.get_registry_app_path(Utils.winreg.HKEY_CURRENT_USER, filename)
	if not ret and Utils.winreg:
		ret = Utils.get_registry_app_path(Utils.winreg.HKEY_LOCAL_MACHINE, filename)

	self.msg('Checking for program ' + ','.join(filename), ret or False)
	self.to_log('find program=%r paths=%r var=%r -> %r' % (filename, path_list, var, ret))

	if not ret:
		self.fatal(kw.get('errmsg', '') or 'Could not find the program %s' % ','.join(filename))

	if var:
		self.env[var] = ret
	return ret


@conf
def find_perl_program(self, filename, path_list=[], var=None, environ=None, exts=''):
	"""
	Search for a perl program on the operating system

	:param filename: file to search for
	:type filename: string
	:param path_list: list of paths to look into
	:type path_list: list of string
	:param var: store the results into *conf.env.var*
	:type var: string
	:param environ: operating system environment to pass to :py:func:`waflib.Configure.find_program`
	:type environ: dict
	:param exts: extensions given to :py:func:`waflib.Configure.find_program`
	:type exts: list
	"""

	try:
		app = self.find_program(filename, path_list=path_list, var=var, environ=environ, exts=exts)
	except:
		self.find_program('perl', var='PERL')
		app = self.find_file(filename, os.environ['PATH'].split(os.pathsep))
		if not app:
			raise
		if var:
			self.env[var] = Utils.to_list(self.env['PERL']) + [app]
	self.msg('Checking for %r' % filename, app)


########NEW FILE########
__FILENAME__ = Context
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2010 (ita)

"""
Classes and functions required for waf commands
"""

import os, imp, sys
from waflib import Utils, Errors, Logs
import waflib.Node

# the following 3 constants are updated on each new release (do not touch)
HEXVERSION=0x1060b00
"""Constant updated on new releases"""

WAFVERSION="1.6.11"
"""Constant updated on new releases"""

WAFREVISION="a7e69d6b81b04729804754c4d5214da063779a65"
"""Constant updated on new releases"""

ABI = 98
"""Version of the build data cache file format (used in :py:const:`waflib.Context.DBFILE`)"""

DBFILE = '.wafpickle-%d' % ABI
"""Name of the pickle file for storing the build data"""

APPNAME = 'APPNAME'
"""Default application name (used by ``waf dist``)"""

VERSION = 'VERSION'
"""Default application version (used by ``waf dist``)"""

TOP  = 'top'
"""The variable name for the top-level directory in wscript files"""

OUT  = 'out'
"""The variable name for the output directory in wscript files"""

WSCRIPT_FILE = 'wscript'
"""Name of the waf script files"""


launch_dir = ''
"""Directory from which waf has been called"""
run_dir = ''
"""Location of the wscript file to use as the entry point"""
top_dir = ''
"""Location of the project directory (top), if the project was configured"""
out_dir = ''
"""Location of the build directory (out), if the project was configured"""
waf_dir = ''
"""Directory containing the waf modules"""

local_repo = ''
"""Local repository containing additional Waf tools (plugins)"""
remote_repo = 'http://waf.googlecode.com/git/'
"""
Remote directory containing downloadable waf tools. The missing tools can be downloaded by using::

	$ waf configure --download
"""

remote_locs = ['waflib/extras', 'waflib/Tools']
"""
Remote directories for use with :py:const:`waflib.Context.remote_repo`
"""

g_module = None
"""
Module representing the main wscript file (see :py:const:`waflib.Context.run_dir`)
"""

STDOUT = 1
STDERR = -1
BOTH   = 0

classes = []
"""
List of :py:class:`waflib.Context.Context` subclasses that can be used as waf commands. The classes
are added automatically by a metaclass.
"""


def create_context(cmd_name, *k, **kw):
	"""
	Create a new :py:class:`waflib.Context.Context` instance corresponding to the given command.
	Used in particular by :py:func:`waflib.Scripting.run_command`

	:param cmd_name: command
	:type cmd_name: string
	:param k: arguments to give to the context class initializer
	:type k: list
	:param k: keyword arguments to give to the context class initializer
	:type k: dict
	"""
	global classes
	for x in classes:
		if x.cmd == cmd_name:
			return x(*k, **kw)
	ctx = Context(*k, **kw)
	ctx.fun = cmd_name
	return ctx

class store_context(type):
	"""
	Metaclass for storing the command classes into the list :py:const:`waflib.Context.classes`
	Context classes must provide an attribute 'cmd' representing the command to execute
	"""
	def __init__(cls, name, bases, dict):
		super(store_context, cls).__init__(name, bases, dict)
		name = cls.__name__

		if name == 'ctx' or name == 'Context':
			return

		try:
			cls.cmd
		except AttributeError:
			raise Errors.WafError('Missing command for the context class %r (cmd)' % name)

		if not getattr(cls, 'fun', None):
			cls.fun = cls.cmd

		global classes
		classes.insert(0, cls)

ctx = store_context('ctx', (object,), {})
"""Base class for the :py:class:`waflib.Context.Context` classes"""

class Context(ctx):
	"""
	Default context for waf commands, and base class for new command contexts.

	Context objects are passed to top-level functions::

		def foo(ctx):
			print(ctx.__class__.__name__) # waflib.Context.Context

	Subclasses must define the attribute 'cmd':

	:param cmd: command to execute as in ``waf cmd``
	:type cmd: string
	:param fun: function name to execute when the command is called
	:type fun: string

	.. inheritance-diagram:: waflib.Context.Context waflib.Build.BuildContext waflib.Build.InstallContext waflib.Build.UninstallContext waflib.Build.StepContext waflib.Build.ListContext waflib.Configure.ConfigurationContext waflib.Scripting.Dist waflib.Scripting.DistCheck waflib.Build.CleanContext

	"""

	errors = Errors
	"""
	Shortcut to :py:mod:`waflib.Errors` provided for convenience
	"""

	tools = {}
	"""
	A cache for modules (wscript files) read by :py:meth:`Context.Context.load`
	"""

	def __init__(self, **kw):
		try:
			rd = kw['run_dir']
		except KeyError:
			global run_dir
			rd = run_dir

		# binds the context to the nodes in use to avoid a context singleton
		class node_class(waflib.Node.Node):
			pass
		self.node_class = node_class
		self.node_class.__module__ = "waflib.Node"
		self.node_class.__name__ = "Nod3"
		self.node_class.ctx = self

		self.root = self.node_class('', None)
		self.cur_script = None
		self.path = self.root.find_dir(rd)

		self.stack_path = []
		self.exec_dict = {'ctx':self, 'conf':self, 'bld':self, 'opt':self}
		self.logger = None

	def __hash__(self):
		"""
		Return a hash value for storing context objects in dicts or sets. The value is not persistent.

		:return: hash value
		:rtype: int
		"""
		return id(self)

	def load(self, tool_list, *k, **kw):
		"""
		Load a Waf tool as a module, and try calling the function named :py:const:`waflib.Context.Context.fun` from it.
		A ``tooldir`` value may be provided as a list of module paths.

		:type tool_list: list of string or space-separated string
		:param tool_list: list of Waf tools to use
		"""
		tools = Utils.to_list(tool_list)
		path = Utils.to_list(kw.get('tooldir', ''))

		for t in tools:
			module = load_tool(t, path)
			fun = getattr(module, kw.get('name', self.fun), None)
			if fun:
				fun(self)

	def execute(self):
		"""
		Execute the command. Redefine this method in subclasses.
		"""
		global g_module
		self.recurse([os.path.dirname(g_module.root_path)])

	def pre_recurse(self, node):
		"""
		Method executed immediately before a folder is read by :py:meth:`waflib.Context.Context.recurse`. The node given is set
		as an attribute ``self.cur_script``, and as the current path ``self.path``

		:param node: script
		:type node: :py:class:`waflib.Node.Node`
		"""
		self.stack_path.append(self.cur_script)

		self.cur_script = node
		self.path = node.parent

	def post_recurse(self, node):
		"""
		Restore ``self.cur_script`` and ``self.path`` right after :py:meth:`waflib.Context.Context.recurse` terminates.

		:param node: script
		:type node: :py:class:`waflib.Node.Node`
		"""
		self.cur_script = self.stack_path.pop()
		if self.cur_script:
			self.path = self.cur_script.parent

	def recurse(self, dirs, name=None, mandatory=True, once=True):
		"""
		Run user code from the supplied list of directories.
		The directories can be either absolute, or relative to the directory
		of the wscript file. The methods :py:meth:`waflib.Context.Context.pre_recurse` and :py:meth:`waflib.Context.Context.post_recurse`
		are called immediately before and after a script has been executed.

		:param dirs: List of directories to visit
		:type dirs: list of string or space-separated string
		:param name: Name of function to invoke from the wscript
		:type  name: string
		:param mandatory: whether sub wscript files are required to exist
		:type  mandatory: bool
		:param once: read the script file once for a particular context
		:type once: bool
		"""
		try:
			cache = self.recurse_cache
		except:
			cache = self.recurse_cache = {}

		for d in Utils.to_list(dirs):

			if not os.path.isabs(d):
				# absolute paths only
				d = os.path.join(self.path.abspath(), d)

			WSCRIPT     = os.path.join(d, WSCRIPT_FILE)
			WSCRIPT_FUN = WSCRIPT + '_' + (name or self.fun)

			node = self.root.find_node(WSCRIPT_FUN)
			if node and (not once or node not in cache):
				cache[node] = True
				self.pre_recurse(node)
				try:
					function_code = node.read('rU')
					exec(compile(function_code, node.abspath(), 'exec'), self.exec_dict)
				finally:
					self.post_recurse(node)
			elif not node:
				node = self.root.find_node(WSCRIPT)
				tup = (node, name or self.fun)
				if node and (not once or tup not in cache):
					cache[tup] = True
					self.pre_recurse(node)
					try:
						wscript_module = load_module(node.abspath())
						user_function = getattr(wscript_module, (name or self.fun), None)
						if not user_function:
							if not mandatory:
								continue
							raise Errors.WafError('No function %s defined in %s' % (name or self.fun, node.abspath()))
						user_function(self)
					finally:
						self.post_recurse(node)
				elif not node:
					if not mandatory:
						continue
					raise Errors.WafError('No wscript file in directory %s' % d)

	def exec_command(self, cmd, **kw):
		"""
		Execute a command and return the exit status. If the context has the attribute 'log',
		capture and log the process stderr/stdout for logging purposes::

			def run(tsk):
				ret = tsk.generator.bld.exec_command('touch foo.txt')
				return ret

		Do not confuse this method with :py:meth:`waflib.Context.Context.cmd_and_log` which is used to
		return the standard output/error values.

		:param cmd: command argument for subprocess.Popen
		:param kw: keyword arguments for subprocess.Popen
		"""
		subprocess = Utils.subprocess
		kw['shell'] = isinstance(cmd, str)
		Logs.debug('runner: %r' % cmd)
		Logs.debug('runner_env: kw=%s' % kw)

		try:
			if self.logger:
				# warning: may deadlock with a lot of output (subprocess limitation)

				self.logger.info(cmd)

				kw['stdout'] = kw['stderr'] = subprocess.PIPE
				p = subprocess.Popen(cmd, **kw)
				(out, err) = p.communicate()
				if out:
					self.logger.debug('out: %s' % out.decode(sys.stdout.encoding or 'iso8859-1'))
				if err:
					self.logger.error('err: %s' % err.decode(sys.stdout.encoding or 'iso8859-1'))
				return p.returncode
			else:
				p = subprocess.Popen(cmd, **kw)
				return p.wait()
		except OSError:
			return -1

	def cmd_and_log(self, cmd, **kw):
		"""
		Execute a command and return stdout if the execution is successful.
		An exception is thrown when the exit status is non-0. In that case, both stderr and stdout
		will be bound to the WafError object::

			def configure(conf):
				out = conf.cmd_and_log(['echo', 'hello'], output=waflib.Context.STDOUT, quiet=waflib.Context.BOTH)
				(out, err) = conf.cmd_and_log(['echo', 'hello'], output=waflib.Context.BOTH)
				try:
					conf.cmd_and_log(['which', 'someapp'], output=waflib.Context.BOTH)
				except Exception as e:
					print(e.stdout, e.stderr)

		:param cmd: args for subprocess.Popen
		:param kw: keyword arguments for subprocess.Popen
		"""
		subprocess = Utils.subprocess
		kw['shell'] = isinstance(cmd, str)
		Logs.debug('runner: %r' % cmd)

		if 'quiet' in kw:
			quiet = kw['quiet']
			del kw['quiet']
		else:
			quiet = None

		if 'output' in kw:
			to_ret = kw['output']
			del kw['output']
		else:
			to_ret = STDOUT

		kw['stdout'] = kw['stderr'] = subprocess.PIPE
		if quiet is None:
			self.to_log(cmd)
		try:
			p = subprocess.Popen(cmd, **kw)
			(out, err) = p.communicate()
		except Exception as e:
			raise Errors.WafError('Execution failure: %s' % str(e), ex=e)

		if not isinstance(out, str):
			out = out.decode(sys.stdout.encoding or 'iso8859-1')
		if not isinstance(err, str):
			err = err.decode(sys.stdout.encoding or 'iso8859-1')

		if out and quiet != STDOUT and quiet != BOTH:
			self.to_log('out: %s' % out)
		if err and quiet != STDERR and quiet != BOTH:
			self.to_log('err: %s' % err)

		if p.returncode:
			e = Errors.WafError('Command %r returned %r' % (cmd, p.returncode))
			e.returncode = p.returncode
			e.stderr = err
			e.stdout = out
			raise e

		if to_ret == BOTH:
			return (out, err)
		elif to_ret == STDERR:
			return err
		return out

	def fatal(self, msg, ex=None):
		"""
		Raise a configuration error to interrupt the execution immediately::

			def configure(conf):
				conf.fatal('a requirement is missing')

		:param msg: message to display
		:type msg: string
		:param ex: optional exception object
		:type ex: exception
		"""
		if self.logger:
			self.logger.info('from %s: %s' % (self.path.abspath(), msg))
		try:
			msg = '%s\n(complete log in %s)' % (msg, self.logger.handlers[0].baseFilename)
		except:
			pass
		raise self.errors.ConfigurationError(msg, ex=ex)

	def to_log(self, msg):
		"""
		Log some information to the logger (if present), or to stderr. If the message is empty,
		it is not printed::

			def build(bld):
				bld.to_log('starting the build')

		When in doubt, override this method, or provide a logger on the context class.

		:param msg: message
		:type msg: string
		"""
		if not msg:
			return
		if self.logger:
			self.logger.info(msg)
		else:
			sys.stderr.write(str(msg))
			sys.stderr.flush()


	def msg(self, msg, result, color=None):
		"""
		Print a configuration message of the form ``msg: result``.
		The second part of the message will be in colors. The output
		can be disabled easly by setting ``in_msg`` to a positive value::

			def configure(conf):
				self.in_msg = 1
				conf.msg('Checking for library foo', 'ok')
				# no output

		:param msg: message to display to the user
		:type msg: string
		:param result: result to display
		:type result: string or boolean
		:param color: color to use, see :py:const:`waflib.Logs.colors_lst`
		:type color: string
		"""
		self.start_msg(msg)

		if not isinstance(color, str):
			color = result and 'GREEN' or 'YELLOW'

		self.end_msg(result, color)

	def start_msg(self, msg):
		"""
		Print the beginning of a 'Checking for xxx' message. See :py:meth:`waflib.Context.Context.msg`
		"""
		try:
			if self.in_msg:
				self.in_msg += 1
				return
		except:
			self.in_msg = 0
		self.in_msg += 1

		try:
			self.line_just = max(self.line_just, len(msg))
		except AttributeError:
			self.line_just = max(40, len(msg))
		for x in (self.line_just * '-', msg):
			self.to_log(x)
		Logs.pprint('NORMAL', "%s :" % msg.ljust(self.line_just), sep='')

	def end_msg(self, result, color=None):
		"""Print the end of a 'Checking for' message. See :py:meth:`waflib.Context.Context.msg`"""
		self.in_msg -= 1
		if self.in_msg:
			return

		defcolor = 'GREEN'
		if result == True:
			msg = 'ok'
		elif result == False:
			msg = 'not found'
			defcolor = 'YELLOW'
		else:
			msg = str(result)

		self.to_log(msg)
		Logs.pprint(color or defcolor, msg)


	def load_special_tools(self, var, ban=[]):
		global waf_dir
		lst = self.root.find_node(waf_dir).find_node('waflib/extras').ant_glob(var)
		for x in lst:
			if not x.name in ban:
				load_tool(x.name.replace('.py', ''))

cache_modules = {}
"""
Dictionary holding already loaded modules, keyed by their absolute path.
The modules are added automatically by :py:func:`waflib.Context.load_module`
"""

def load_module(path):
	"""
	Load a source file as a python module.

	:param path: file path
	:type path: string
	:return: Loaded Python module
	:rtype: module
	"""
	try:
		return cache_modules[path]
	except KeyError:
		pass

	module = imp.new_module(WSCRIPT_FILE)
	try:
		code = Utils.readf(path, m='rU')
	except (IOError, OSError):
		raise Errors.WafError('Could not read the file %r' % path)

	module_dir = os.path.dirname(path)
	sys.path.insert(0, module_dir)

	exec(compile(code, path, 'exec'), module.__dict__)
	sys.path.remove(module_dir)

	cache_modules[path] = module

	return module

def load_tool(tool, tooldir=None):
	"""
	Import a Waf tool (python module), and store it in the dict :py:const:`waflib.Context.Context.tools`

	:type  tool: string
	:param tool: Name of the tool
	:type  tooldir: list
	:param tooldir: List of directories to search for the tool module
	"""
	tool = tool.replace('++', 'xx')
	tool = tool.replace('java', 'javaw')
	tool = tool.replace('compiler_cc', 'compiler_c')

	if tooldir:
		assert isinstance(tooldir, list)
		sys.path = tooldir + sys.path
		try:
			__import__(tool)
			ret = sys.modules[tool]
			Context.tools[tool] = ret
			return ret
		finally:
			for d in tooldir:
				sys.path.remove(d)
	else:
		global waf_dir
		try:
			os.stat(os.path.join(waf_dir, 'waflib', 'extras', tool + '.py'))
			d = 'waflib.extras.%s' % tool
		except:
			try:
				os.stat(os.path.join(waf_dir, 'waflib', 'Tools', tool + '.py'))
				d = 'waflib.Tools.%s' % tool
			except:
				d = tool # user has messed with sys.path

		__import__(d)
		ret = sys.modules[d]
		Context.tools[tool] = ret
		return ret


########NEW FILE########
__FILENAME__ = Errors
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2010 (ita)

"""
Exceptions used in the Waf code
"""

import traceback, sys

class WafError(Exception):
	"""Base class for all Waf errors"""
	def __init__(self, msg='', ex=None):
		"""
		:param msg: error message
		:type msg: string
		:param ex: exception causing this error (optional)
		:type ex: exception
		"""
		self.msg = msg
		assert not isinstance(msg, Exception)

		self.stack = []
		if ex:
			if not msg:
				self.msg = str(ex)
			if isinstance(ex, WafError):
				self.stack = ex.stack
			else:
				self.stack = traceback.extract_tb(sys.exc_info()[2])
		self.stack += traceback.extract_stack()[:-1]
		self.verbose_msg = ''.join(traceback.format_list(self.stack))

	def __str__(self):
		return str(self.msg)

class BuildError(WafError):
	"""
	Errors raised during the build and install phases
	"""
	def __init__(self, error_tasks=[]):
		"""
		:param error_tasks: tasks that could not complete normally
		:type error_tasks: list of task objects
		"""
		self.tasks = error_tasks
		WafError.__init__(self, self.format_error())

	def format_error(self):
		"""format the error messages from the tasks that failed"""
		lst = ['Build failed']
		for tsk in self.tasks:
			txt = tsk.format_error()
			if txt: lst.append(txt)
		return '\n'.join(lst)

class ConfigurationError(WafError):
	"""
	Configuration exception raised in particular by :py:meth:`waflib.Context.Context.fatal`
	"""
	pass

class TaskRescan(WafError):
	"""task-specific exception type, trigger a signature recomputation"""
	pass

class TaskNotReady(WafError):
	"""task-specific exception type, raised when the task signature cannot be computed"""
	pass


########NEW FILE########
__FILENAME__ = compat15
#! /usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2010 (ita)

"""
This file is provided to enable compatibility with waf 1.5, it will be removed in waf 1.7
"""

import sys
from waflib import ConfigSet, Logs, Options, Scripting, Task, Build, Configure, Node, Runner, TaskGen, Utils, Errors, Context

# the following is to bring some compatibility with waf 1.5 "import waflib.Configure â†’ import Configure"
sys.modules['Environment'] = ConfigSet
ConfigSet.Environment = ConfigSet.ConfigSet

sys.modules['Logs'] = Logs
sys.modules['Options'] = Options
sys.modules['Scripting'] = Scripting
sys.modules['Task'] = Task
sys.modules['Build'] = Build
sys.modules['Configure'] = Configure
sys.modules['Node'] = Node
sys.modules['Runner'] = Runner
sys.modules['TaskGen'] = TaskGen
sys.modules['Utils'] = Utils

from waflib.Tools import c_preproc
sys.modules['preproc'] = c_preproc

from waflib.Tools import c_config
sys.modules['config_c'] = c_config

ConfigSet.ConfigSet.copy = ConfigSet.ConfigSet.derive
ConfigSet.ConfigSet.set_variant = Utils.nada

Build.BuildContext.add_subdirs = Build.BuildContext.recurse
Build.BuildContext.new_task_gen = Build.BuildContext.__call__
Build.BuildContext.is_install = 0
Node.Node.relpath_gen = Node.Node.path_from

def name_to_obj(self, s, env=None):
	Logs.warn('compat: change "name_to_obj(name, env)" by "get_tgen_by_name(name)"')
	return self.get_tgen_by_name(s)
Build.BuildContext.name_to_obj = name_to_obj

def env_of_name(self, name):
	try:
		return self.all_envs[name]
	except KeyError:
		Logs.error('no such environment: '+name)
		return None
Build.BuildContext.env_of_name = env_of_name


def set_env_name(self, name, env):
	self.all_envs[name] = env
	return env
Configure.ConfigurationContext.set_env_name = set_env_name

def retrieve(self, name, fromenv=None):
	try:
		env = self.all_envs[name]
	except KeyError:
		env = ConfigSet.ConfigSet()
		self.prepare_env(env)
		self.all_envs[name] = env
	else:
		if fromenv: Logs.warn("The environment %s may have been configured already" % name)
	return env
Configure.ConfigurationContext.retrieve = retrieve

Configure.ConfigurationContext.sub_config = Configure.ConfigurationContext.recurse
Configure.ConfigurationContext.check_tool = Configure.ConfigurationContext.load
Configure.conftest = Configure.conf
Configure.ConfigurationError = Errors.ConfigurationError

Options.OptionsContext.sub_options = Options.OptionsContext.recurse
Options.OptionsContext.tool_options = Context.Context.load
Options.Handler = Options.OptionsContext

Task.simple_task_type = Task.task_type_from_func = Task.task_factory
Task.TaskBase.classes = Task.classes

def setitem(self, key, value):
	if key.startswith('CCFLAGS'):
		key = key[1:]
	self.table[key] = value
ConfigSet.ConfigSet.__setitem__ = setitem

@TaskGen.feature('d')
@TaskGen.before('apply_incpaths')
def old_importpaths(self):
	if getattr(self, 'importpaths', []):
		self.includes = self.importpaths

from waflib import Context
eld = Context.load_tool
def load_tool(*k, **kw):
	ret = eld(*k, **kw)
	if 'set_options' in ret.__dict__:
		Logs.warn('compat: rename "set_options" to options')
		ret.options = ret.set_options
	if 'detect' in ret.__dict__:
		Logs.warn('compat: rename "detect" to "configure"')
		ret.configure = ret.detect
	return ret
Context.load_tool = load_tool

rev = Context.load_module
def load_module(path):
	ret = rev(path)
	if 'set_options' in ret.__dict__:
		Logs.warn('compat: rename "set_options" to "options" (%r)' % path)
		ret.options = ret.set_options
	if 'srcdir' in ret.__dict__:
		Logs.warn('compat: rename "srcdir" to "top" (%r)' % path)
		ret.top = ret.srcdir
	if 'blddir' in ret.__dict__:
		Logs.warn('compat: rename "blddir" to "out" (%r)' % path)
		ret.out = ret.blddir
	return ret
Context.load_module = load_module

old_post = TaskGen.task_gen.post
def post(self):
	self.features = self.to_list(self.features)
	if 'cc' in self.features:
		Logs.warn('compat: the feature cc does not exist anymore (use "c")')
		self.features.remove('cc')
		self.features.append('c')
	if 'cstaticlib' in self.features:
		Logs.warn('compat: the feature cstaticlib does not exist anymore (use "cstlib" or "cxxstlib")')
		self.features.remove('cstaticlib')
		self.features.append(('cxx' in self.features) and 'cxxstlib' or 'cstlib')
	if getattr(self, 'ccflags', None):
		Logs.warn('compat: "ccflags" was renamed to "cflags"')
		self.cflags = self.ccflags
	return old_post(self)
TaskGen.task_gen.post = post

def waf_version(*k, **kw):
	Logs.warn('wrong version (waf_version was removed in waf 1.6)')
Utils.waf_version = waf_version


import os
@TaskGen.feature('c', 'cxx', 'd')
@TaskGen.before('apply_incpaths', 'propagate_uselib_vars')
@TaskGen.after('apply_link', 'process_source')
def apply_uselib_local(self):
	"""
	process the uselib_local attribute
	execute after apply_link because of the execution order set on 'link_task'
	"""
	env = self.env
	from waflib.Tools.ccroot import stlink_task

	# 1. the case of the libs defined in the project (visit ancestors first)
	# the ancestors external libraries (uselib) will be prepended
	self.uselib = self.to_list(getattr(self, 'uselib', []))
	self.includes = self.to_list(getattr(self, 'includes', []))
	names = self.to_list(getattr(self, 'uselib_local', []))
	get = self.bld.get_tgen_by_name
	seen = set([])
	tmp = Utils.deque(names) # consume a copy of the list of names
	if tmp:
		Logs.warn('compat: "uselib_local" is deprecated, replace by "use"')
	while tmp:
		lib_name = tmp.popleft()
		# visit dependencies only once
		if lib_name in seen:
			continue

		y = get(lib_name)
		y.post()
		seen.add(lib_name)

		# object has ancestors to process (shared libraries): add them to the end of the list
		if getattr(y, 'uselib_local', None):
			for x in self.to_list(getattr(y, 'uselib_local', [])):
				obj = get(x)
				obj.post()
				if getattr(obj, 'link_task', None):
					if not isinstance(obj.link_task, stlink_task):
						tmp.append(x)

		# link task and flags
		if getattr(y, 'link_task', None):

			link_name = y.target[y.target.rfind(os.sep) + 1:]
			if isinstance(y.link_task, stlink_task):
				env.append_value('STLIB', [link_name])
			else:
				# some linkers can link against programs
				env.append_value('LIB', [link_name])

			# the order
			self.link_task.set_run_after(y.link_task)

			# for the recompilation
			self.link_task.dep_nodes += y.link_task.outputs

			# add the link path too
			tmp_path = y.link_task.outputs[0].parent.bldpath()
			if not tmp_path in env['LIBPATH']:
				env.prepend_value('LIBPATH', [tmp_path])

		# add ancestors uselib too - but only propagate those that have no staticlib defined
		for v in self.to_list(getattr(y, 'uselib', [])):
			if not env['STLIB_' + v]:
				if not v in self.uselib:
					self.uselib.insert(0, v)

		# if the library task generator provides 'export_includes', add to the include path
		# the export_includes must be a list of paths relative to the other library
		if getattr(y, 'export_includes', None):
			self.includes.extend(y.to_incnodes(y.export_includes))

@TaskGen.feature('cprogram', 'cxxprogram', 'cstlib', 'cxxstlib', 'cshlib', 'cxxshlib', 'dprogram', 'dstlib', 'dshlib')
@TaskGen.after('apply_link')
def apply_objdeps(self):
	"add the .o files produced by some other object files in the same manner as uselib_local"
	names = getattr(self, 'add_objects', [])
	if not names:
		return
	names = self.to_list(names)

	get = self.bld.get_tgen_by_name
	seen = []
	while names:
		x = names[0]

		# visit dependencies only once
		if x in seen:
			names = names[1:]
			continue

		# object does not exist ?
		y = get(x)

		# object has ancestors to process first ? update the list of names
		if getattr(y, 'add_objects', None):
			added = 0
			lst = y.to_list(y.add_objects)
			lst.reverse()
			for u in lst:
				if u in seen: continue
				added = 1
				names = [u]+names
			if added: continue # list of names modified, loop

		# safe to process the current object
		y.post()
		seen.append(x)

		for t in getattr(y, 'compiled_tasks', []):
			self.link_task.inputs.extend(t.outputs)

@TaskGen.after('apply_link')
def process_obj_files(self):
	if not hasattr(self, 'obj_files'):
		return
	for x in self.obj_files:
		node = self.path.find_resource(x)
		self.link_task.inputs.append(node)

@TaskGen.taskgen_method
def add_obj_file(self, file):
	"""Small example on how to link object files as if they were source
	obj = bld.create_obj('cc')
	obj.add_obj_file('foo.o')"""
	if not hasattr(self, 'obj_files'): self.obj_files = []
	if not 'process_obj_files' in self.meths: self.meths.append('process_obj_files')
	self.obj_files.append(file)


old_define = Configure.ConfigurationContext.__dict__['define']

@Configure.conf
def define(self, key, val, quote=True):
	old_define(self, key, val, quote)
	if key.startswith('HAVE_'):
		self.env[key] = 1

old_undefine = Configure.ConfigurationContext.__dict__['undefine']

@Configure.conf
def undefine(self, key):
	old_undefine(self, key)
	if key.startswith('HAVE_'):
		self.env[key] = 0

# some people might want to use export_incdirs, but it was renamed
def set_incdirs(self, val):
	Logs.warn('compat: change "export_incdirs" by "export_includes"')
	self.export_includes = val
TaskGen.task_gen.export_incdirs = property(None, set_incdirs)


########NEW FILE########
__FILENAME__ = local_rpath
#! /usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2011 (ita)

from waflib.TaskGen import after_method, feature

@after_method('propagate_uselib_vars')
@feature('cprogram', 'cshlib', 'cxxprogram', 'cxxshlib', 'fcprogram', 'fcshlib')
def add_rpath_stuff(self):
	all = self.to_list(getattr(self, 'use', []))
	while all:
		name = all.pop()
		try:
			tg = self.bld.get_tgen_by_name(name)
		except:
			continue
		self.env.append_value('RPATH', tg.link_task.outputs[0].parent.abspath())
		all.extend(self.to_list(getattr(tg, 'use', [])))


########NEW FILE########
__FILENAME__ = lru_cache
#! /usr/bin/env python
# encoding: utf-8
# Thomas Nagy 2011

import os, shutil, re
from waflib import Options, Build, Logs

"""
Apply a least recently used policy to the Waf cache.

For performance reasons, it is called after the build is complete.

We assume that the the folders are written atomically

Do export WAFCACHE=/tmp/foo_xyz where xyz represents the cache size in bytes
If missing, the default cache size will be set to 10GB
"""

re_num = re.compile('[a-zA-Z_-]+(\d+)')

CACHESIZE = 10*1024*1024*1024 # in bytes
CLEANRATIO = 0.8
DIRSIZE = 4096

def compile(self):
	if Options.cache_global and not Options.options.nocache:
		try:
			os.makedirs(Options.cache_global)
		except:
			pass

	try:
		self.raw_compile()
	finally:
		if Options.cache_global and not Options.options.nocache:
			self.sweep()

def sweep(self):
	global CACHESIZE
	CACHEDIR = Options.cache_global

	# get the cache max size from the WAFCACHE filename
	re_num = re.compile('[a-zA-Z_]+(\d+)')
	val = re_num.sub('\\1', os.path.basename(Options.cache_global))
	try:
		CACHESIZE = int(val)
	except:
		pass

	# map folder names to timestamps
	flist = {}
	for x in os.listdir(CACHEDIR):
		j = os.path.join(CACHEDIR, x)
		if os.path.isdir(j) and len(x) == 64: # dir names are md5 hexdigests
			flist[x] = [os.stat(j).st_mtime, 0]

	for (x, v) in flist.items():
		cnt = DIRSIZE # each entry takes 4kB
		d = os.path.join(CACHEDIR, x)
		for k in os.listdir(d):
			cnt += os.stat(os.path.join(d, k)).st_size
		flist[x][1] = cnt

	total = sum([x[1] for x in flist.values()])
	Logs.debug('lru: Cache size is %r' % total)

	if total >= CACHESIZE:
		Logs.debug('lru: Trimming the cache since %r > %r' % (total, CACHESIZE))

		# make a list to sort the folders by timestamp
		lst = [(p, v[0], v[1]) for (p, v) in flist.items()]
		lst.sort(key=lambda x: x[1]) # sort by timestamp
		lst.reverse()

		while total >= CACHESIZE * CLEANRATIO:
			(k, t, s) = lst.pop()
			p = os.path.join(CACHEDIR, k)
			v = p + '.del'
			try:
				os.rename(p, v)
			except:
				# someone already did it
				pass
			else:
				try:
					shutil.rmtree(v)
				except:
					# this should not happen, but who knows?
					Logs.warn('If you ever see this message, report it (%r)' % v)
			total -= s
			del flist[k]

	Logs.debug('lru: Total at the end %r' % total)

Build.BuildContext.raw_compile = Build.BuildContext.compile
Build.BuildContext.compile = compile
Build.BuildContext.sweep = sweep


########NEW FILE########
__FILENAME__ = make
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2011 (ita)

"""
A make-like way of executing the build, following the relationships between inputs/outputs

This algorithm will lead to slower builds, will not be as flexible as "waf build", but
it might be useful for building data files (?)

It is likely to break in the following cases:
- files are created dynamically (no inputs or outputs)
- headers
- building two files from different groups
"""

import re
from waflib import Options, Task, Logs
from waflib.Build import BuildContext

class MakeContext(BuildContext):
	'''executes tasks in a step-by-step manner, following dependencies between inputs/outputs'''
	cmd = 'make'
	fun = 'build'

	def __init__(self, **kw):
		super(MakeContext, self).__init__(**kw)
		self.files = Options.options.files

	def get_build_iterator(self):
		if not self.files:
			while 1:
				yield super(MakeContext, self).get_build_iterator()

		for g in self.groups:
			for tg in g:
				try:
					f = tg.post
				except AttributeError:
					pass
				else:
					f()

			provides = {}
			uses = {}
			all_tasks = []
			tasks = []
			for pat in self.files.split(','):
				matcher = self.get_matcher(pat)
				for tg in g:
					if isinstance(tg, Task.TaskBase):
						lst = [tg]
					else:
						lst = tg.tasks
					for tsk in lst:
						all_tasks.append(tsk)

						do_exec = False
						for node in getattr(tsk, 'inputs', []):
							try:
								uses[node].append(tsk)
							except:
								uses[node] = [tsk]

							if matcher(node, output=False):
								do_exec = True
								break

						for node in getattr(tsk, 'outputs', []):
							try:
								provides[node].append(tsk)
							except:
								provides[node] = [tsk]

							if matcher(node, output=True):
								do_exec = True
								break
						if do_exec:
							tasks.append(tsk)

			# so we have the tasks that we need to process, the list of all tasks,
			# the map of the tasks providing nodes, and the map of tasks using nodes

			if not tasks:
				# if there are no tasks matching, return everything in the current group
				result = all_tasks
			else:
				# this is like a big filter...
				result = set([])
				seen = set([])
				cur = set(tasks)
				while cur:
					result |= cur
					tosee = set([])
					for tsk in cur:
						for node in getattr(tsk, 'inputs', []):
							if node in seen:
								continue
							seen.add(node)
							tosee |= set(provides.get(node, []))
					cur = tosee
				result = list(result)

			Task.set_file_constraints(result)
			Task.set_precedence_constraints(result)
			yield result

		while 1:
			yield []

	def get_matcher(self, pat):
		# this returns a function
		inn = True
		out = True
		if pat.startswith('in:'):
			out = False
			pat = pat.replace('in:', '')
		elif pat.startswith('out:'):
			inn = False
			pat = pat.replace('out:', '')

		anode = self.root.find_node(pat)
		pattern = None
		if not anode:
			if not pat.startswith('^'):
				pat = '^.+?%s' % pat
			if not pat.endswith('$'):
				pat = '%s$' % pat
			pattern = re.compile(pat)

		def match(node, output):
			if output == True and not out:
				return False
			if output == False and not inn:
				return False

			if anode:
				return anode == node
			else:
				return pattern.match(node.abspath())
		return match


########NEW FILE########
__FILENAME__ = md5_tstamp
#! /usr/bin/env python
# encoding: utf-8

"""
Store some values on the buildcontext mapping file paths to
stat values and md5 values (timestamp + md5)
this way the md5 hashes are computed only when timestamp change (can be faster)
There is usually little or no gain from enabling this, but it can be used to enable
the second level cache with timestamps (WAFCACHE)

You may have to run distclean or to remove the build directory before enabling/disabling
this hashing scheme
"""

import os, stat
try: import cPickle
except: import pickle as cPickle
from waflib import Utils, Build, Context

STRONGEST = True
Context.DBFILE += '_md5tstamp'

Build.hashes_md5_tstamp = {}
Build.SAVED_ATTRS.append('hashes_md5_tstamp')
def store(self):
	# save the hash cache as part of the default pickle file
	self.hashes_md5_tstamp = Build.hashes_md5_tstamp
	self.store_real()
Build.BuildContext.store_real = Build.BuildContext.store
Build.BuildContext.store      = store

def restore(self):
	# we need a module variable for h_file below
	self.restore_real()
	try:
		Build.hashes_md5_tstamp = self.hashes_md5_tstamp or {}
	except Exception as e:
		Build.hashes_md5_tstamp = {}
Build.BuildContext.restore_real = Build.BuildContext.restore
Build.BuildContext.restore      = restore

def h_file(filename):
	st = os.stat(filename)
	if stat.S_ISDIR(st[stat.ST_MODE]): raise IOError('not a file')

	if filename in Build.hashes_md5_tstamp:
		if Build.hashes_md5_tstamp[filename][0] == str(st.st_mtime):
			return Build.hashes_md5_tstamp[filename][1]
	m = Utils.md5()

	if STRONGEST:
		f = open(filename, 'rb')
		read = 1
		try:
			while read:
				read = f.read(100000)
				m.update(read)
		finally:
			f.close()
	else:
		m.update(str(st.st_mtime))
		m.update(str(st.st_size))
		m.update(filename)

	# ensure that the cache is overwritten
	Build.hashes_md5_tstamp[filename] = (str(st.st_mtime), m.digest())
	return m.digest()
Utils.h_file = h_file


########NEW FILE########
__FILENAME__ = misc
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2006-2010 (ita)

"""
This tool is totally deprecated

Try using:
	.pc.in files for .pc files
	the feature intltool_in - see demos/intltool
	make-like rules
"""

import shutil, re, os
from waflib import TaskGen, Node, Task, Utils, Build, Errors
from waflib.TaskGen import feature, after_method, before_method
from waflib.Logs import debug

def copy_attrs(orig, dest, names, only_if_set=False):
	"""
	copy class attributes from an object to another
	"""
	for a in Utils.to_list(names):
		u = getattr(orig, a, ())
		if u or not only_if_set:
			setattr(dest, a, u)

def copy_func(tsk):
	"Make a file copy. This might be used to make other kinds of file processing (even calling a compiler is possible)"
	env = tsk.env
	infile = tsk.inputs[0].abspath()
	outfile = tsk.outputs[0].abspath()
	try:
		shutil.copy2(infile, outfile)
	except (OSError, IOError):
		return 1
	else:
		if tsk.chmod: os.chmod(outfile, tsk.chmod)
		return 0

def action_process_file_func(tsk):
	"Ask the function attached to the task to process it"
	if not tsk.fun: raise Errors.WafError('task must have a function attached to it for copy_func to work!')
	return tsk.fun(tsk)

@feature('cmd')
def apply_cmd(self):
	"call a command everytime"
	if not self.fun: raise Errors.WafError('cmdobj needs a function!')
	tsk = Task.TaskBase()
	tsk.fun = self.fun
	tsk.env = self.env
	self.tasks.append(tsk)
	tsk.install_path = self.install_path

@feature('copy')
@before_method('process_source')
def apply_copy(self):
	Utils.def_attrs(self, fun=copy_func)
	self.default_install_path = 0

	lst = self.to_list(self.source)
	self.meths.remove('process_source')

	for filename in lst:
		node = self.path.find_resource(filename)
		if not node: raise Errors.WafError('cannot find input file %s for processing' % filename)

		target = self.target
		if not target or len(lst)>1: target = node.name

		# TODO the file path may be incorrect
		newnode = self.path.find_or_declare(target)

		tsk = self.create_task('copy', node, newnode)
		tsk.fun = self.fun
		tsk.chmod = getattr(self, 'chmod', Utils.O644)

		if not tsk.env:
			tsk.debug()
			raise Errors.WafError('task without an environment')

def subst_func(tsk):
	"Substitutes variables in a .in file"

	m4_re = re.compile('@(\w+)@', re.M)

	code = tsk.inputs[0].read() #Utils.readf(infile)

	# replace all % by %% to prevent errors by % signs in the input file while string formatting
	code = code.replace('%', '%%')

	s = m4_re.sub(r'%(\1)s', code)

	env = tsk.env
	di = getattr(tsk, 'dict', {}) or getattr(tsk.generator, 'dict', {})
	if not di:
		names = m4_re.findall(code)
		for i in names:
			di[i] = env.get_flat(i) or env.get_flat(i.upper())

	tsk.outputs[0].write(s % di)

@feature('subst')
@before_method('process_source')
def apply_subst(self):
	Utils.def_attrs(self, fun=subst_func)
	lst = self.to_list(self.source)
	self.meths.remove('process_source')

	self.dict = getattr(self, 'dict', {})

	for filename in lst:
		node = self.path.find_resource(filename)
		if not node: raise Errors.WafError('cannot find input file %s for processing' % filename)

		if self.target:
			newnode = self.path.find_or_declare(self.target)
		else:
			newnode = node.change_ext('')

		try:
			self.dict = self.dict.get_merged_dict()
		except AttributeError:
			pass

		if self.dict and not self.env['DICT_HASH']:
			self.env = self.env.derive()
			keys = list(self.dict.keys())
			keys.sort()
			lst = [self.dict[x] for x in keys]
			self.env['DICT_HASH'] = str(Utils.h_list(lst))

		tsk = self.create_task('copy', node, newnode)
		tsk.fun = self.fun
		tsk.dict = self.dict
		tsk.dep_vars = ['DICT_HASH']
		tsk.chmod = getattr(self, 'chmod', Utils.O644)

		if not tsk.env:
			tsk.debug()
			raise Errors.WafError('task without an environment')

####################
## command-output ####
####################

class cmd_arg(object):
	"""command-output arguments for representing files or folders"""
	def __init__(self, name, template='%s'):
		self.name = name
		self.template = template
		self.node = None

class input_file(cmd_arg):
	def find_node(self, base_path):
		assert isinstance(base_path, Node.Node)
		self.node = base_path.find_resource(self.name)
		if self.node is None:
			raise Errors.WafError("Input file %s not found in " % (self.name, base_path))

	def get_path(self, env, absolute):
		if absolute:
			return self.template % self.node.abspath()
		else:
			return self.template % self.node.srcpath()

class output_file(cmd_arg):
	def find_node(self, base_path):
		assert isinstance(base_path, Node.Node)
		self.node = base_path.find_or_declare(self.name)
		if self.node is None:
			raise Errors.WafError("Output file %s not found in " % (self.name, base_path))

	def get_path(self, env, absolute):
		if absolute:
			return self.template % self.node.abspath()
		else:
			return self.template % self.node.bldpath()

class cmd_dir_arg(cmd_arg):
	def find_node(self, base_path):
		assert isinstance(base_path, Node.Node)
		self.node = base_path.find_dir(self.name)
		if self.node is None:
			raise Errors.WafError("Directory %s not found in " % (self.name, base_path))

class input_dir(cmd_dir_arg):
	def get_path(self, dummy_env, dummy_absolute):
		return self.template % self.node.abspath()

class output_dir(cmd_dir_arg):
	def get_path(self, env, dummy_absolute):
		return self.template % self.node.abspath()


class command_output(Task.Task):
	color = "BLUE"
	def __init__(self, env, command, command_node, command_args, stdin, stdout, cwd, os_env, stderr):
		Task.Task.__init__(self, env=env)
		assert isinstance(command, (str, Node.Node))
		self.command = command
		self.command_args = command_args
		self.stdin = stdin
		self.stdout = stdout
		self.cwd = cwd
		self.os_env = os_env
		self.stderr = stderr

		if command_node is not None: self.dep_nodes = [command_node]
		self.dep_vars = [] # additional environment variables to look

	def run(self):
		task = self
		#assert len(task.inputs) > 0

		def input_path(node, template):
			if task.cwd is None:
				return template % node.bldpath()
			else:
				return template % node.abspath()
		def output_path(node, template):
			fun = node.abspath
			if task.cwd is None: fun = node.bldpath
			return template % fun()

		if isinstance(task.command, Node.Node):
			argv = [input_path(task.command, '%s')]
		else:
			argv = [task.command]

		for arg in task.command_args:
			if isinstance(arg, str):
				argv.append(arg)
			else:
				assert isinstance(arg, cmd_arg)
				argv.append(arg.get_path(task.env, (task.cwd is not None)))

		if task.stdin:
			stdin = open(input_path(task.stdin, '%s'))
		else:
			stdin = None

		if task.stdout:
			stdout = open(output_path(task.stdout, '%s'), "w")
		else:
			stdout = None

		if task.stderr:
			stderr = open(output_path(task.stderr, '%s'), "w")
		else:
			stderr = None

		if task.cwd is None:
			cwd = ('None (actually %r)' % os.getcwd())
		else:
			cwd = repr(task.cwd)
		debug("command-output: cwd=%s, stdin=%r, stdout=%r, argv=%r" %
			     (cwd, stdin, stdout, argv))

		if task.os_env is None:
			os_env = os.environ
		else:
			os_env = task.os_env
		command = Utils.subprocess.Popen(argv, stdin=stdin, stdout=stdout, stderr=stderr, cwd=task.cwd, env=os_env)
		return command.wait()

@feature('command-output')
def init_cmd_output(self):
	Utils.def_attrs(self,
		stdin = None,
		stdout = None,
		stderr = None,
		# the command to execute
		command = None,

		# whether it is an external command; otherwise it is assumed
		# to be an executable binary or script that lives in the
		# source or build tree.
		command_is_external = False,

		# extra parameters (argv) to pass to the command (excluding
		# the command itself)
		argv = [],

		# dependencies to other objects -> this is probably not what you want (ita)
		# values must be 'task_gen' instances (not names!)
		dependencies = [],

		# dependencies on env variable contents
		dep_vars = [],

		# input files that are implicit, i.e. they are not
		# stdin, nor are they mentioned explicitly in argv
		hidden_inputs = [],

		# output files that are implicit, i.e. they are not
		# stdout, nor are they mentioned explicitly in argv
		hidden_outputs = [],

		# change the subprocess to this cwd (must use obj.input_dir() or output_dir() here)
		cwd = None,

		# OS environment variables to pass to the subprocess
		# if None, use the default environment variables unchanged
		os_env = None)

@feature('command-output')
@after_method('init_cmd_output')
def apply_cmd_output(self):
	if self.command is None:
		raise Errors.WafError("command-output missing command")
	if self.command_is_external:
		cmd = self.command
		cmd_node = None
	else:
		cmd_node = self.path.find_resource(self.command)
		assert cmd_node is not None, ('''Could not find command '%s' in source tree.
Hint: if this is an external command,
use command_is_external=True''') % (self.command,)
		cmd = cmd_node

	if self.cwd is None:
		cwd = None
	else:
		assert isinstance(cwd, CmdDirArg)
		self.cwd.find_node(self.path)

	args = []
	inputs = []
	outputs = []

	for arg in self.argv:
		if isinstance(arg, cmd_arg):
			arg.find_node(self.path)
			if isinstance(arg, input_file):
				inputs.append(arg.node)
			if isinstance(arg, output_file):
				outputs.append(arg.node)

	if self.stdout is None:
		stdout = None
	else:
		assert isinstance(self.stdout, str)
		stdout = self.path.find_or_declare(self.stdout)
		if stdout is None:
			raise Errors.WafError("File %s not found" % (self.stdout,))
		outputs.append(stdout)

	if self.stderr is None:
		stderr = None
	else:
		assert isinstance(self.stderr, str)
		stderr = self.path.find_or_declare(self.stderr)
		if stderr is None:
			raise Errors.WafError("File %s not found" % (self.stderr,))
		outputs.append(stderr)

	if self.stdin is None:
		stdin = None
	else:
		assert isinstance(self.stdin, str)
		stdin = self.path.find_resource(self.stdin)
		if stdin is None:
			raise Errors.WafError("File %s not found" % (self.stdin,))
		inputs.append(stdin)

	for hidden_input in self.to_list(self.hidden_inputs):
		node = self.path.find_resource(hidden_input)
		if node is None:
			raise Errors.WafError("File %s not found in dir %s" % (hidden_input, self.path))
		inputs.append(node)

	for hidden_output in self.to_list(self.hidden_outputs):
		node = self.path.find_or_declare(hidden_output)
		if node is None:
			raise Errors.WafError("File %s not found in dir %s" % (hidden_output, self.path))
		outputs.append(node)

	if not (inputs or getattr(self, 'no_inputs', None)):
		raise Errors.WafError('command-output objects must have at least one input file or give self.no_inputs')
	if not (outputs or getattr(self, 'no_outputs', None)):
		raise Errors.WafError('command-output objects must have at least one output file or give self.no_outputs')

	cwd = self.bld.variant_dir
	task = command_output(self.env, cmd, cmd_node, self.argv, stdin, stdout, cwd, self.os_env, stderr)
	task.generator = self
	copy_attrs(self, task, 'before after ext_in ext_out', only_if_set=True)
	self.tasks.append(task)

	task.inputs = inputs
	task.outputs = outputs
	task.dep_vars = self.to_list(self.dep_vars)

	for dep in self.dependencies:
		assert dep is not self
		dep.post()
		for dep_task in dep.tasks:
			task.set_run_after(dep_task)

	if not task.inputs:
		# the case for svnversion, always run, and update the output nodes
		task.runnable_status = type(Task.TaskBase.run)(runnable_status, task, task.__class__) # always run
		task.post_run = type(Task.TaskBase.run)(post_run, task, task.__class__)

	# TODO the case with no outputs?

def post_run(self):
	for x in self.outputs:
		x.sig = Utils.h_file(x.abspath())

def runnable_status(self):
	return self.RUN_ME

Task.task_factory('copy', vars=[], func=action_process_file_func)


########NEW FILE########
__FILENAME__ = objcopy
#!/usr/bin/python
# Grygoriy Fuchedzhy 2010

"""
Support for converting linked targets to ihex, srec or binary files using
objcopy. Use the 'objcopy' feature in conjuction with the 'cc' or 'cxx'
feature. The 'objcopy' feature uses the following attributes:

objcopy_bfdname		Target object format name (eg. ihex, srec, binary).
					   Defaults to ihex.
objcopy_target		 File name used for objcopy output. This defaults to the
					   target name with objcopy_bfdname as extension.
objcopy_install_path   Install path for objcopy_target file. Defaults to ${PREFIX}/fw.
objcopy_flags		  Additional flags passed to objcopy.
"""

from waflib.Utils import def_attrs
from waflib import Task
from waflib.TaskGen import feature, after_method

class objcopy(Task.Task):
	run_str = '${OBJCOPY} -O ${TARGET_BFDNAME} ${OBJCOPYFLAGS} ${SRC} ${TGT}'
	color   = 'CYAN'

@feature('objcopy')
@after_method('apply_link')
def objcopy(self):
	def_attrs(self,
	   objcopy_bfdname = 'ihex',
	   objcopy_target = None,
	   objcopy_install_path = "${PREFIX}/firmware",
	   objcopy_flags = '')

	link_output = self.link_task.outputs[0]
	if not self.objcopy_target:
		self.objcopy_target = link_output.change_ext('.' + self.objcopy_bfdname).name
	task = self.create_task('objcopy',
							src=link_output,
							tgt=self.path.find_or_declare(self.objcopy_target))

	task.env.append_unique('TARGET_BFDNAME', self.objcopy_bfdname)
	try:
		task.env.append_unique('OBJCOPYFLAGS', getattr(self, 'objcopy_flags'))
	except AttributeError:
		pass

	if self.objcopy_install_path:
		self.bld.install_files(self.objcopy_install_path,
							   task.outputs[0],
							   env=task.env.derive())

def configure(ctx):
	objcopy = ctx.find_program('objcopy', var='OBJCOPY', mandatory=True)


########NEW FILE########
__FILENAME__ = ocaml
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2006-2010 (ita)

"ocaml support"

import os, re
from waflib import TaskGen, Utils, Task, Build
from waflib.Logs import error
from waflib.TaskGen import feature, before_method, after_method, extension

EXT_MLL = ['.mll']
EXT_MLY = ['.mly']
EXT_MLI = ['.mli']
EXT_MLC = ['.c']
EXT_ML  = ['.ml']

open_re = re.compile('^\s*open\s+([a-zA-Z]+)(;;){0,1}$', re.M)
foo = re.compile(r"""(\(\*)|(\*\))|("(\\.|[^"\\])*"|'(\\.|[^'\\])*'|.[^()*"'\\]*)""", re.M)
def filter_comments(txt):
	meh = [0]
	def repl(m):
		if m.group(1): meh[0] += 1
		elif m.group(2): meh[0] -= 1
		elif not meh[0]: return m.group(0)
		return ''
	return foo.sub(repl, txt)

def scan(self):
	node = self.inputs[0]
	code = filter_comments(node.read())

	global open_re
	names = []
	import_iterator = open_re.finditer(code)
	if import_iterator:
		for import_match in import_iterator:
			names.append(import_match.group(1))
	found_lst = []
	raw_lst = []
	for name in names:
		nd = None
		for x in self.incpaths:
			nd = x.find_resource(name.lower()+'.ml')
			if not nd: nd = x.find_resource(name+'.ml')
			if nd:
				found_lst.append(nd)
				break
		else:
			raw_lst.append(name)

	return (found_lst, raw_lst)

native_lst=['native', 'all', 'c_object']
bytecode_lst=['bytecode', 'all']

@feature('ocaml')
def init_ml(self):
	Utils.def_attrs(self,
		type = 'all',
		incpaths_lst = [],
		bld_incpaths_lst = [],
		mlltasks = [],
		mlytasks = [],
		mlitasks = [],
		native_tasks = [],
		bytecode_tasks = [],
		linktasks = [],
		bytecode_env = None,
		native_env = None,
		compiled_tasks = [],
		includes = '',
		uselib = '',
		are_deps_set = 0)

@feature('ocaml')
@after_method('init_ml')
def init_envs_ml(self):

	self.islibrary = getattr(self, 'islibrary', False)

	global native_lst, bytecode_lst
	self.native_env = None
	if self.type in native_lst:
		self.native_env = self.env.derive()
		if self.islibrary: self.native_env['OCALINKFLAGS']   = '-a'

	self.bytecode_env = None
	if self.type in bytecode_lst:
		self.bytecode_env = self.env.derive()
		if self.islibrary: self.bytecode_env['OCALINKFLAGS'] = '-a'

	if self.type == 'c_object':
		self.native_env.append_unique('OCALINKFLAGS_OPT', '-output-obj')

@feature('ocaml')
@before_method('apply_vars_ml')
@after_method('init_envs_ml')
def apply_incpaths_ml(self):
	inc_lst = self.includes.split()
	lst = self.incpaths_lst
	for dir in inc_lst:
		node = self.path.find_dir(dir)
		if not node:
			error("node not found: " + str(dir))
			continue
		if not node in lst:
			lst.append(node)
		self.bld_incpaths_lst.append(node)
	# now the nodes are added to self.incpaths_lst

@feature('ocaml')
@before_method('process_source')
def apply_vars_ml(self):
	for i in self.incpaths_lst:
		if self.bytecode_env:
			app = self.bytecode_env.append_value
			app('OCAMLPATH', ['-I', i.bldpath(), '-I', i.srcpath()])

		if self.native_env:
			app = self.native_env.append_value
			app('OCAMLPATH', ['-I', i.bldpath(), '-I', i.srcpath()])

	varnames = ['INCLUDES', 'OCAMLFLAGS', 'OCALINKFLAGS', 'OCALINKFLAGS_OPT']
	for name in self.uselib.split():
		for vname in varnames:
			cnt = self.env[vname+'_'+name]
			if cnt:
				if self.bytecode_env: self.bytecode_env.append_value(vname, cnt)
				if self.native_env: self.native_env.append_value(vname, cnt)

@feature('ocaml')
@after_method('process_source')
def apply_link_ml(self):

	if self.bytecode_env:
		ext = self.islibrary and '.cma' or '.run'

		linktask = self.create_task('ocalink')
		linktask.bytecode = 1
		linktask.set_outputs(self.path.find_or_declare(self.target + ext))
		linktask.env = self.bytecode_env
		self.linktasks.append(linktask)

	if self.native_env:
		if self.type == 'c_object': ext = '.o'
		elif self.islibrary: ext = '.cmxa'
		else: ext = ''

		linktask = self.create_task('ocalinkx')
		linktask.set_outputs(self.path.find_or_declare(self.target + ext))
		linktask.env = self.native_env
		self.linktasks.append(linktask)

		# we produce a .o file to be used by gcc
		self.compiled_tasks.append(linktask)

@extension(*EXT_MLL)
def mll_hook(self, node):
	mll_task = self.create_task('ocamllex', node, node.change_ext('.ml'))
	mll_task.env = self.native_env.derive()
	self.mlltasks.append(mll_task)

	self.source.append(mll_task.outputs[0])

@extension(*EXT_MLY)
def mly_hook(self, node):
	mly_task = self.create_task('ocamlyacc', node, [node.change_ext('.ml'), node.change_ext('.mli')])
	mly_task.env = self.native_env.derive()
	self.mlytasks.append(mly_task)
	self.source.append(mly_task.outputs[0])

	task = self.create_task('ocamlcmi', mly_task.outputs[1], mly_task.outputs[1].change_ext('.cmi'))
	task.env = self.native_env.derive()

@extension(*EXT_MLI)
def mli_hook(self, node):
	task = self.create_task('ocamlcmi', node, node.change_ext('.cmi'))
	task.env = self.native_env.derive()
	self.mlitasks.append(task)

@extension(*EXT_MLC)
def mlc_hook(self, node):
	task = self.create_task('ocamlcc', node, node.change_ext('.o'))
	task.env = self.native_env.derive()
	self.compiled_tasks.append(task)

@extension(*EXT_ML)
def ml_hook(self, node):
	if self.native_env:
		task = self.create_task('ocamlx', node, node.change_ext('.cmx'))
		task.env = self.native_env.derive()
		task.incpaths = self.bld_incpaths_lst
		self.native_tasks.append(task)

	if self.bytecode_env:
		task = self.create_task('ocaml', node, node.change_ext('.cmo'))
		task.env = self.bytecode_env.derive()
		task.bytecode = 1
		task.incpaths = self.bld_incpaths_lst
		self.bytecode_tasks.append(task)

def compile_may_start(self):

	if not getattr(self, 'flag_deps', ''):
		self.flag_deps = 1

		# the evil part is that we can only compute the dependencies after the
		# source files can be read (this means actually producing the source files)
		if getattr(self, 'bytecode', ''): alltasks = self.generator.bytecode_tasks
		else: alltasks = self.generator.native_tasks

		self.signature() # ensure that files are scanned - unfortunately
		tree = self.generator.bld
		env = self.env
		for node in self.inputs:
			lst = tree.node_deps[self.uid()]
			for depnode in lst:
				for t in alltasks:
					if t == self: continue
					if depnode in t.inputs:
						self.set_run_after(t)

		# TODO necessary to get the signature right - for now
		delattr(self, 'cache_sig')
		self.signature()

	return Task.Task.runnable_status(self)

class ocamlx(Task.Task):
	"""native caml compilation"""
	color   = 'GREEN'
	run_str = '${OCAMLOPT} ${OCAMLPATH} ${OCAMLFLAGS} ${OCAMLINCLUDES} -c -o ${TGT} ${SRC}'
	scan    = scan
	runnable_status = compile_may_start

class ocaml(Task.Task):
	"""bytecode caml compilation"""
	color   = 'GREEN'
	run_str = '${OCAMLC} ${OCAMLPATH} ${OCAMLFLAGS} ${OCAMLINCLUDES} -c -o ${TGT} ${SRC}'
	scan    = scan
	runnable_status = compile_may_start

class ocamlcmi(Task.Task):
	"""interface generator (the .i files?)"""
	color   = 'BLUE'
	run_str = '${OCAMLC} ${OCAMLPATH} ${OCAMLINCLUDES} -o ${TGT} -c ${SRC}'
	before  = ['ocamlcc', 'ocaml', 'ocamlcc']

class ocamlcc(Task.Task):
	"""ocaml to c interfaces"""
	color   = 'GREEN'
	run_str = 'cd ${TGT[0].bld_dir()} && ${OCAMLOPT} ${OCAMLFLAGS} ${OCAMLPATH} ${OCAMLINCLUDES} -c ${SRC[0].abspath()}'

class ocamllex(Task.Task):
	"""lexical generator"""
	color   = 'BLUE'
	run_str = '${OCAMLLEX} ${SRC} -o ${TGT}'
	before  = ['ocamlcmi', 'ocaml', 'ocamlcc']

class ocamlyacc(Task.Task):
	"""parser generator"""
	color   = 'BLUE'
	run_str = '${OCAMLYACC} -b ${TGT[0].bld_base(env)} ${SRC}'
	before  = ['ocamlcmi', 'ocaml', 'ocamlcc']

def link_may_start(self):

	if getattr(self, 'bytecode', 0): alltasks = self.generator.bytecode_tasks
	else: alltasks = self.generator.native_tasks

	for x in alltasks:
		if not x.hasrun:
			return Task.ASK_LATER

	if not getattr(self, 'order', ''):

		# now reorder the inputs given the task dependencies
		# this part is difficult, we do not have a total order on the tasks
		# if the dependencies are wrong, this may not stop
		seen = []
		pendant = []+alltasks
		while pendant:
			task = pendant.pop(0)
			if task in seen: continue
			for x in task.run_after:
				if not x in seen:
					pendant.append(task)
					break
			else:
				seen.append(task)
		self.inputs = [x.outputs[0] for x in seen]
		self.order = 1
	return Task.Task.runnable_status(self)

class ocalink(Task.Task):
	"""bytecode caml link"""
	color   = 'YELLOW'
	run_str = '${OCAMLC} -o ${TGT} ${OCAMLINCLUDES} ${OCALINKFLAGS} ${SRC}'
	runnable_status = link_may_start
	after = ['ocaml', 'ocamlcc']

class ocalinkx(Task.Task):
	"""native caml link"""
	color   = 'YELLOW'
	run_str = '${OCAMLOPT} -o ${TGT} ${OCAMLINCLUDES} ${OCALINKFLAGS_OPT} ${SRC}'
	runnable_status = link_may_start
	after = ['ocamlx', 'ocamlcc']

def configure(conf):
	opt = conf.find_program('ocamlopt', var='OCAMLOPT', mandatory=False)
	occ = conf.find_program('ocamlc', var='OCAMLC', mandatory=False)
	if (not opt) or (not occ):
		conf.fatal('The objective caml compiler was not found:\ninstall it or make it available in your PATH')

	v = conf.env
	v['OCAMLC']       = occ
	v['OCAMLOPT']     = opt
	v['OCAMLLEX']     = conf.find_program('ocamllex', var='OCAMLLEX', mandatory=False)
	v['OCAMLYACC']    = conf.find_program('ocamlyacc', var='OCAMLYACC', mandatory=False)
	v['OCAMLFLAGS']   = ''
	v['OCAMLLIB']     = conf.cmd_and_log(conf.env['OCAMLC']+' -where').strip()+os.sep
	v['LIBPATH_OCAML'] = conf.cmd_and_log(conf.env['OCAMLC']+' -where').strip()+os.sep
	v['INCLUDES_OCAML'] = conf.cmd_and_log(conf.env['OCAMLC']+' -where').strip()+os.sep
	v['LIB_OCAML'] = 'camlrun'


########NEW FILE########
__FILENAME__ = package
#! /usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2011

"""
Obtain packages, unpack them in a location, and add associated uselib variables
(CFLAGS_pkgname, LIBPATH_pkgname, etc).

The default is use a Dependencies.txt file in the source directory.

This is a work in progress.

Usage:

def options(opt):
	opt.load('package')

def configure(conf):
    conf.load_packages()
"""

from waflib import Logs
from waflib.Configure import conf

try:
	from urllib import request
except:
	from urllib import urlopen
else:
	urlopen = request.urlopen


CACHEVAR = 'WAFCACHE_PACKAGE'

@conf
def get_package_cache_dir(self):
	cache = None
	if CACHEVAR in conf.environ:
		cache = conf.environ[CACHEVAR]
		cache = self.root.make_node(cache)
	elif self.env[CACHEVAR]:
		cache = self.env[CACHEVAR]
		cache = self.root.make_node(cache)
	else:
		cache = self.srcnode.make_node('.wafcache_package')
	cache.mkdir()
	return cache

@conf
def download_archive(self, src, dst):
	for x in self.env.PACKAGE_REPO:
		url = '/'.join((x, src))
		try:
			web = urlopen(url)
			try:
				if web.getcode() != 200:
					continue
			except AttributeError:
				pass
		except Exception:
			# on python3 urlopen throws an exception
			# python 2.3 does not have getcode and throws an exception to fail
			continue
		else:
			tmp = self.root.make_node(dst)
			tmp.write(web.read())
			Logs.warn('Downloaded %s from %s' % (tmp.abspath(), url))
			break
	else:
		self.fatal('Could not get the package %s' % src)

@conf
def load_packages(self):
	cache = self.get_package_cache_dir()
	# read the dependencies, get the archives, ..


########NEW FILE########
__FILENAME__ = parallel_debug
#! /usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2007-2010 (ita)

"""
Debugging helper for parallel compilation, outputs
a file named pdebug.svg in the source directory::

	def options(opt):
		opt.load('parallel_debug')
	def configure(conf):
		conf.load('parallel_debug')
	def build(bld):
   	 ...
"""

import os, time, sys
try: from Queue import Queue
except: from queue import Queue
from waflib import Runner, Options, Utils, Task, Logs, Errors

#import random
#random.seed(100)

def options(opt):
	opt.add_option('--dtitle', action='store', default='Parallel build representation for %r' % ' '.join(sys.argv),
		help='title for the svg diagram', dest='dtitle')
	opt.add_option('--dwidth', action='store', type='int', help='diagram width', default=800, dest='dwidth')
	opt.add_option('--dtime', action='store', type='float', help='recording interval in seconds', default=0.009, dest='dtime')
	opt.add_option('--dband', action='store', type='int', help='band width', default=22, dest='dband')
	opt.add_option('--dmaxtime', action='store', type='float', help='maximum time, for drawing fair comparisons', default=0, dest='dmaxtime')

# red   #ff4d4d
# green #4da74d
# lila  #a751ff

color2code = {
	'GREEN'  : '#4da74d',
	'YELLOW' : '#fefe44',
	'PINK'   : '#a751ff',
	'RED'    : '#cc1d1d',
	'BLUE'   : '#6687bb',
	'CYAN'   : '#34e2e2',
}

mp = {}
info = [] # list of (text,color)

def map_to_color(name):
	if name in mp:
		return mp[name]
	try:
		cls = Task.classes[name]
	except KeyError:
		return color2code['RED']
	if cls.color in mp:
		return mp[cls.color]
	if cls.color in color2code:
		return color2code[cls.color]
	return color2code['RED']

def process(self):
	m = self.master
	if m.stop:
		m.out.put(self)
		return

	self.master.set_running(1, id(Utils.threading.currentThread()), self)

	# remove the task signature immediately before it is executed
	# in case of failure the task will be executed again
	try:
		del self.generator.bld.task_sigs[self.uid()]
	except:
		pass

	try:
		self.generator.bld.returned_tasks.append(self)
		self.log_display(self.generator.bld)
		ret = self.run()
	except Exception:
		self.err_msg = Utils.ex_stack()
		self.hasrun = Task.EXCEPTION

		# TODO cleanup
		m.error_handler(self)
		m.out.put(self)
		return

	if ret:
		self.err_code = ret
		self.hasrun = Task.CRASHED
	else:
		try:
			self.post_run()
		except Errors.WafError:
			pass
		except Exception:
			self.err_msg = Utils.ex_stack()
			self.hasrun = Task.EXCEPTION
		else:
			self.hasrun = Task.SUCCESS
	if self.hasrun != Task.SUCCESS:
		m.error_handler(self)

	self.master.set_running(-1, id(Utils.threading.currentThread()), self)
	m.out.put(self)
Task.TaskBase.process_back = Task.TaskBase.process
Task.TaskBase.process = process

old_start = Runner.Parallel.start
def do_start(self):
	try:
		Options.options.dband
	except AttributeError:
		self.bld.fatal('use def options(opt): opt.load("parallel_debug")!')

	self.taskinfo = Queue()
	old_start(self)
	if self.dirty:
		process_colors(self)
Runner.Parallel.start = do_start

def set_running(self, by, i, tsk):
	self.taskinfo.put( (i, id(tsk), time.time(), tsk.__class__.__name__, self.processed, self.count, by)  )
Runner.Parallel.set_running = set_running

def name2class(name):
	return name.replace(' ', '_').replace('.', '_')

def process_colors(producer):
	# first, cast the parameters
	tmp = []
	try:
		while True:
			tup = producer.taskinfo.get(False)
			tmp.append(list(tup))
	except:
		pass

	try:
		ini = float(tmp[0][2])
	except:
		return

	if not info:
		seen = []
		for x in tmp:
			name = x[3]
			if not name in seen:
				seen.append(name)
			else:
				continue

			info.append((name, map_to_color(name)))
		info.sort(key=lambda x: x[0])

	thread_count = 0
	acc = []
	for x in tmp:
		thread_count += x[6]
		acc.append("%d %d %f %r %d %d %d" % (x[0], x[1], x[2] - ini, x[3], x[4], x[5], thread_count))
	data_node = producer.bld.path.make_node('pdebug.dat')
	data_node.write('\n'.join(acc))

	tmp = [lst[:2] + [float(lst[2]) - ini] + lst[3:] for lst in tmp]

	st = {}
	for l in tmp:
		if not l[0] in st:
			st[l[0]] = len(st.keys())
	tmp = [  [st[lst[0]]] + lst[1:] for lst in tmp ]
	THREAD_AMOUNT = len(st.keys())

	st = {}
	for l in tmp:
		if not l[1] in st:
			st[l[1]] = len(st.keys())
	tmp = [  [lst[0]] + [st[lst[1]]] + lst[2:] for lst in tmp ]


	BAND = Options.options.dband

	seen = {}
	acc = []
	for x in range(len(tmp)):
		line = tmp[x]
		id = line[1]

		if id in seen:
			continue
		seen[id] = True

		begin = line[2]
		thread_id = line[0]
		for y in range(x + 1, len(tmp)):
			line = tmp[y]
			if line[1] == id:
				end = line[2]
				#print id, thread_id, begin, end
				#acc.append(  ( 10*thread_id, 10*(thread_id+1), 10*begin, 10*end ) )
				acc.append( (BAND * begin, BAND*thread_id, BAND*end - BAND*begin, BAND, line[3]) )
				break

	if Options.options.dmaxtime < 0.1:
		gwidth = 1
		for x in tmp:
			m = BAND * x[2]
			if m > gwidth:
				gwidth = m
	else:
		gwidth = BAND * Options.options.dmaxtime

	ratio = float(Options.options.dwidth) / gwidth
	gwidth = Options.options.dwidth

	gheight = BAND * (THREAD_AMOUNT + len(info) + 1.5)

	out = []

	out.append("""<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>
<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.0//EN\"
\"http://www.w3.org/TR/2001/REC-SVG-20010904/DTD/svg10.dtd\">
<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" version=\"1.0\"
   x=\"%r\" y=\"%r\" width=\"%r\" height=\"%r\"
   id=\"svg602\" xml:space=\"preserve\">

<style type='text/css' media='screen'>
	g.over rect  { stroke:#FF0000; fill-opacity:0.4 }
</style>

<script type='text/javascript'><![CDATA[
var svg  = document.getElementsByTagName('svg')[0];

svg.addEventListener('mouseover', function(e) {
	var g = e.target.parentNode;
	var x = document.getElementById('r_' + g.id);
	if (x) {
		g.setAttribute('class', g.getAttribute('class') + ' over');
		x.setAttribute('class', x.getAttribute('class') + ' over');
		showInfo(e, g.id);
	}
}, false);

svg.addEventListener('mouseout', function(e) {
		var g = e.target.parentNode;
		var x = document.getElementById('r_' + g.id);
		if (x) {
			g.setAttribute('class', g.getAttribute('class').replace(' over', ''));
			x.setAttribute('class', x.getAttribute('class').replace(' over', ''));
			hideInfo(e);
		}
}, false);

function showInfo(evt, txt) {
	tooltip = document.getElementById('tooltip');

	var t = document.getElementById('tooltiptext');
	t.firstChild.data = txt;

	var x = evt.clientX + 9;
	if (x > 250) { x -= t.getComputedTextLength() + 16; }
	var y = evt.clientY + 20;
	tooltip.setAttribute("transform", "translate(" + x + "," + y + ")");
	tooltip.setAttributeNS(null, "visibility", "visible");

	var r = document.getElementById('tooltiprect');
	r.setAttribute('width', t.getComputedTextLength() + 6);
}

function hideInfo(evt) {
	var tooltip = document.getElementById('tooltip');
	tooltip.setAttributeNS(null,"visibility","hidden");
}
]]></script>

<!-- inkscape requires a big rectangle or it will not export the pictures properly -->
<rect
   x='%r' y='%r'
   width='%r' height='%r'
   style=\"font-size:10;fill:#ffffff;fill-opacity:0.01;fill-rule:evenodd;stroke:#ffffff;\"
   />\n

""" % (0, 0, gwidth + 4, gheight + 4,   0, 0, gwidth + 4, gheight + 4))

	# main title
	if Options.options.dtitle:
		out.append("""<text x="%d" y="%d" style="font-size:15px; text-anchor:middle; font-style:normal;font-weight:normal;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;font-family:Bitstream Vera Sans">%s</text>
""" % (gwidth/2, gheight - 5, Options.options.dtitle))

	# the rectangles

	groups = {}
	for (x, y, w, h, clsname) in acc:
		try:
			groups[clsname].append((x, y, w, h))
		except:
			groups[clsname] = [(x, y, w, h)]
	for cls in groups:
		out.append("<g id='%s'>\n" % name2class(cls))

		for (x, y, w, h) in groups[cls]:
			out.append("""<rect
   x='%r' y='%r'
   width='%r' height='%r'
   style=\"font-size:10;fill:%s;fill-rule:evenodd;stroke:#000000;stroke-width:0.4;\"
   />\n""" % (2 + x*ratio, 2 + y, w*ratio, h, map_to_color(cls)))
		out.append("</g>\n")

	# output the caption
	cnt = THREAD_AMOUNT

	for (text, color) in info:
		# caption box
		b = BAND/2
		out.append("""<g id='r_%s'><rect
		x='%r' y='%r'
		width='%r' height='%r'
		style=\"font-size:10;fill:%s;fill-rule:evenodd;stroke:#000000;stroke-width:0.4;\"
  />\n""" %                       (name2class(text), 2 + BAND,     5 + (cnt + 0.5) * BAND, b, b, color))

		# caption text
		out.append("""<text
   style="font-size:12px;font-style:normal;font-weight:normal;fill:#000000;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;font-family:Bitstream Vera Sans"
   x="%r" y="%d">%s</text></g>\n""" % (2 + 2 * BAND, 5 + (cnt + 0.5) * BAND + 10, text))
		cnt += 1

	out.append("""
<g transform="translate(0,0)" visibility="hidden" id="tooltip">
  <rect id="tooltiprect" y="-15" x="-3" width="1" height="20" style="stroke:black;fill:#edefc2;stroke-width:1"/>
  <text id="tooltiptext" style="font-family:Arial; font-size:12;fill:black;"> </text>
</g>""")

	out.append("\n</svg>")

	node = producer.bld.path.make_node('pdebug.svg')
	node.write("".join(out))
	Logs.warn('Created the diagram %r' % node.abspath())

	p = node.parent.abspath()
	producer.bld.exec_command(['convert', p + os.sep + 'pdebug.svg', p + os.sep + 'pdebug.png'])


########NEW FILE########
__FILENAME__ = pep8
#! /usr/bin/env python
# encoding: utf-8
#
# written by Sylvain Rouquette, 2011

'''
Install pep8 module:
$ easy_install pep8
	or
$ pip install pep8

To add the boost tool to the waf file:
$ ./waf-light --tools=compat15,pep8
	or, if you have waf >= 1.6.2
$ ./waf update --files=pep8


Then add this to your wscript:

[at]extension('.py', 'wscript')
def run_pep8(self, node):
	self.create_task('Pep8', node)

'''

import threading
from waflib import TaskGen, Task, Options

pep8 = __import__('pep8')


class Pep8(Task.Task):
	color = 'PINK'
	lock = threading.Lock()

	def check_options(self):
		if pep8.options:
			return
		pep8.options = Options.options
		pep8.options.prog = 'pep8'
		excl = pep8.options.exclude.split(',')
		pep8.options.exclude = [s.rstrip('/') for s in excl]
		if pep8.options.filename:
			pep8.options.filename = pep8.options.filename.split(',')
		if pep8.options.select:
			pep8.options.select = pep8.options.select.split(',')
		else:
			pep8.options.select = []
		if pep8.options.ignore:
			pep8.options.ignore = pep8.options.ignore.split(',')
		elif pep8.options.select:
			# Ignore all checks which are not explicitly selected
			pep8.options.ignore = ['']
		elif pep8.options.testsuite or pep8.options.doctest:
			# For doctest and testsuite, all checks are required
			pep8.options.ignore = []
		else:
			# The default choice: ignore controversial checks
			pep8.options.ignore = pep8.DEFAULT_IGNORE.split(',')
		pep8.options.physical_checks = pep8.find_checks('physical_line')
		pep8.options.logical_checks = pep8.find_checks('logical_line')
		pep8.options.counters = dict.fromkeys(pep8.BENCHMARK_KEYS, 0)
		pep8.options.messages = {}

	def run(self):
		with Pep8.lock:
			self.check_options()
		pep8.input_file(self.inputs[0].abspath())
		return 0 if not pep8.get_count() else -1


def options(opt):
	opt.add_option('-q', '--quiet', default=0, action='count',
				   help="report only file names, or nothing with -qq")
	opt.add_option('-r', '--repeat', action='store_true',
				   help="show all occurrences of the same error")
	opt.add_option('--exclude', metavar='patterns',
				   default=pep8.DEFAULT_EXCLUDE,
				   help="exclude files or directories which match these "
				   "comma separated patterns (default: %s)" %
				   pep8.DEFAULT_EXCLUDE,
				   dest='exclude')
	opt.add_option('--filename', metavar='patterns', default='*.py',
				   help="when parsing directories, only check filenames "
				   "matching these comma separated patterns (default: "
				   "*.py)")
	opt.add_option('--select', metavar='errors', default='',
				   help="select errors and warnings (e.g. E,W6)")
	opt.add_option('--ignore', metavar='errors', default='',
				   help="skip errors and warnings (e.g. E4,W)")
	opt.add_option('--show-source', action='store_true',
				   help="show source code for each error")
	opt.add_option('--show-pep8', action='store_true',
				   help="show text of PEP 8 for each error")
	opt.add_option('--statistics', action='store_true',
				   help="count errors and warnings")
	opt.add_option('--count', action='store_true',
				   help="print total number of errors and warnings "
				   "to standard error and set exit code to 1 if "
				   "total is not null")
	opt.add_option('--benchmark', action='store_true',
				   help="measure processing speed")
	opt.add_option('--testsuite', metavar='dir',
				   help="run regression tests from dir")
	opt.add_option('--doctest', action='store_true',
				   help="run doctest on myself")

########NEW FILE########
__FILENAME__ = print_commands
#! /usr/bin/env python

"""
Illustrate how to override a class method to do something

In this case, print the commands being executed as strings
(the commands are usually lists, so this can be misleading)
"""

import sys
from waflib import Context, Utils, Logs

def exec_command(self, cmd, **kw):
	subprocess = Utils.subprocess
	kw['shell'] = isinstance(cmd, str)

	txt = cmd
	if isinstance(cmd, list):
		txt = ' '.join(cmd)

	print(txt)
	Logs.debug('runner_env: kw=%s' % kw)

	try:
		if self.logger:
			# warning: may deadlock with a lot of output (subprocess limitation)

			self.logger.info(cmd)

			kw['stdout'] = kw['stderr'] = subprocess.PIPE
			p = subprocess.Popen(cmd, **kw)
			(out, err) = p.communicate()
			if out:
				self.logger.debug('out: %s' % out.decode(sys.stdout.encoding or 'iso8859-1'))
			if err:
				self.logger.error('err: %s' % err.decode(sys.stdout.encoding or 'iso8859-1'))
			return p.returncode
		else:
			p = subprocess.Popen(cmd, **kw)
			return p.wait()
	except OSError:
		return -1

Context.Context.exec_command = exec_command



########NEW FILE########
__FILENAME__ = proc
#! /usr/bin/env python
# per rosengren 2011

from os import environ, path
from waflib import TaskGen, Utils

def options(opt):
	grp = opt.add_option_group('Oracle ProC Options')
	grp.add_option('--oracle_home', action='store', default=environ.get('PROC_ORACLE'), help='Path to Oracle installation home (has bin/lib)')
	grp.add_option('--tns_admin', action='store', default=environ.get('TNS_ADMIN'), help='Directory containing server list (TNS_NAMES.ORA)')
	grp.add_option('--connection', action='store', default='dummy-user/dummy-password@dummy-server', help='Format: user/password@server')

def configure(cnf):
	env = cnf.env
	if not env.PROC_ORACLE:
		env.PROC_ORACLE = cnf.options.oracle_home
	if not env.PROC_TNS_ADMIN:
		env.PROC_TNS_ADMIN = cnf.options.tns_admin
	if not env.PROC_CONNECTION:
		env.PROC_CONNECTION = cnf.options.connection
	cnf.find_program('proc', var='PROC', path_list=env.PROC_ORACLE + path.sep + 'bin')

def proc(tsk):
	env = tsk.env
	gen = tsk.generator
	bld = gen.bld
	inc_nodes = gen.to_incnodes(Utils.to_list(getattr(gen,'includes',[])) + env['INCLUDES'])

	# FIXME the if-else construct will not work in python 2
	cmd = (
		[env.PROC] +
		['SQLCHECK=SEMANTICS'] +
		(['SYS_INCLUDE=(' + ','.join(env.PROC_INCLUDES) + ')']
			if env.PROC_INCLUDES else []) +
		['INCLUDE=(' + ','.join(
			[i.bldpath() for i in inc_nodes]
		) + ')'] +
		['userid=' + env.PROC_CONNECTION] +
		['INAME=' + tsk.inputs[0].bldpath()] +
		['ONAME=' + tsk.outputs[0].bldpath()]
	)
	exec_env = {
		'ORACLE_HOME': env.PROC_ORACLE,
		'LD_LIBRARY_PATH': env.PROC_ORACLE + path.sep + 'lib',
	}
	if env.PROC_TNS_ADMIN:
		exec_env['TNS_ADMIN'] = env.PROC_TNS_ADMIN
	return tsk.exec_command(cmd, env=exec_env)

TaskGen.declare_chain(
	name = 'proc',
	rule = proc,
	ext_in = '.pc',
	ext_out = '.c',
)


########NEW FILE########
__FILENAME__ = relocation
#! /usr/bin/env python
# encoding: utf-8

"""
Waf 1.6

Try to detect if the project directory was relocated, and if it was,
change the node representing the project directory. Just call:

 waf configure build

Note that if the project directory name changes, the signatures for the tasks using
files in that directory will change, causing a partial build.
"""

import os
from waflib import Build, ConfigSet, Task, Utils, Errors
from waflib.TaskGen import feature, before_method, after_method

EXTRA_LOCK = '.old_srcdir'

old1 = Build.BuildContext.store
def store(self):
	old1(self)
	db = os.path.join(self.variant_dir, EXTRA_LOCK)
	env = ConfigSet.ConfigSet()
	env.SRCDIR = self.srcnode.abspath()
	env.store(db)
Build.BuildContext.store = store

old2 = Build.BuildContext.init_dirs
def init_dirs(self):

	if not (os.path.isabs(self.top_dir) and os.path.isabs(self.out_dir)):
		raise Errors.WafError('The project was not configured: run "waf configure" first!')

	srcdir = None
	db = os.path.join(self.variant_dir, EXTRA_LOCK)
	env = ConfigSet.ConfigSet()
	try:
		env.load(db)
		srcdir = env.SRCDIR
	except:
		pass

	if srcdir:
		d = self.root.find_node(srcdir)
		if d and srcdir != self.top_dir and getattr(d, 'children', ''):
			srcnode = self.root.make_node(self.top_dir)
			print("relocating the source directory %r -> %r" % (srcdir, self.top_dir))
			srcnode.children = {}

			for (k, v) in d.children.items():
				srcnode.children[k] = v
				v.parent = srcnode
			d.children = {}

	old2(self)

Build.BuildContext.init_dirs = init_dirs


def uid(self):
	try:
		return self.uid_
	except AttributeError:
		# this is not a real hot zone, but we want to avoid surprizes here
		m = Utils.md5()
		up = m.update
		up(self.__class__.__name__.encode())
		for x in self.inputs + self.outputs:
			up(x.path_from(x.ctx.srcnode).encode())
		self.uid_ = m.digest()
		return self.uid_
Task.Task.uid = uid

@feature('c', 'cxx', 'd', 'go', 'asm', 'fc', 'includes')
@after_method('propagate_uselib_vars', 'process_source')
def apply_incpaths(self):
	lst = self.to_incnodes(self.to_list(getattr(self, 'includes', [])) + self.env['INCLUDES'])
	self.includes_nodes = lst
	bld = self.bld
	self.env['INCPATHS'] = [x.is_child_of(bld.srcnode) and x.path_from(bld.bldnode) or x.abspath() for x in lst]



########NEW FILE########
__FILENAME__ = review
#!/usr/bin/env python
# encoding: utf-8
# Laurent Birtz, 2011
# moved the code into a separate tool (ita)

"""
There are several things here:
- a different command-line option management making options persistent
- the review command to display the options set

Assumptions:
- configuration options are not always added to the right group (and do not count on the users to do it...)
- the options are persistent between the executions (waf options are NOT persistent by design), even for the configuration
- when the options change, the build is invalidated (forcing a reconfiguration)
"""

import os, textwrap, shutil
from waflib import Logs, Context, ConfigSet, Options, Build, Configure

class Odict(dict):
	"""Ordered dictionary"""
	def __init__(self, data=None):
		self._keys = []
		dict.__init__(self)
		if data:
			# we were provided a regular dict
			if isinstance(data, dict):
				self.append_from_dict(data)

			# we were provided a tuple list
			elif type(data) == list:
				self.append_from_plist(data)

			# we were provided invalid input
			else:
				raise Exception("expected a dict or a tuple list")

	def append_from_dict(self, dict):
		map(self.__setitem__, dict.keys(), dict.values())

	def append_from_plist(self, plist):
		for pair in plist:
			if len(pair) != 2:
				raise Exception("invalid pairs list")
		for (k, v) in plist:
			self.__setitem__(k, v)

	def __delitem__(self, key):
		if not key in self._keys:
			raise KeyError(key)
		dict.__delitem__(self, key)
		self._keys.remove(key)

	def __setitem__(self, key, item):
		dict.__setitem__(self, key, item)
		if key not in self._keys:
			self._keys.append(key)

	def clear(self):
		dict.clear(self)
		self._keys = []

	def copy(self):
		return Odict(self.plist())

	def items(self):
		return zip(self._keys, self.values())

	def keys(self):
		return list(self._keys) # return a copy of the list

	def values(self):
		return map(self.get, self._keys)

	def plist(self):
		p = []
		for k, v in self.items():
			p.append( (k, v) )
		return p

	def __str__(self):
		s = "{"
		l = len(self._keys)
		for k, v in self.items():
			l -= 1
			strkey = str(k)
			if isinstance(k, basestring): strkey = "'"+strkey+"'"
			strval = str(v)
			if isinstance(v, basestring): strval = "'"+strval+"'"
			s += strkey + ":" + strval
			if l > 0: s += ", "
		s += "}"
		return s

review_options = Odict()
"""
Ordered dictionary mapping configuration option names to their optparse option.
"""

review_defaults = {}
"""
Dictionary mapping configuration option names to their default value.
"""

old_review_set = None
"""
Review set containing the configuration values before parsing the command line.
"""

new_review_set = None
"""
Review set containing the configuration values after parsing the command line.
"""

class OptionsReview(Options.OptionsContext):
	def __init__(self, **kw):
		super(self.__class__, self).__init__(**kw)

	def prepare_config_review(self):
		"""
		Find the configuration options that are reviewable, detach
		their default value from their optparse object and store them
		into the review dictionaries.
		"""
		gr = self.get_option_group('configure options')
		for opt in gr.option_list:
			if opt.action != 'store' or opt.dest in ("out", "top"):
				continue
			review_options[opt.dest] = opt
			review_defaults[opt.dest] = opt.default
			if gr.defaults.has_key(opt.dest):
				del gr.defaults[opt.dest]
			opt.default = None

	def parse_args(self):
		self.prepare_config_review()
		self.parser.get_option('--prefix').help = 'installation prefix'
		super(OptionsReview, self).parse_args()
		Context.create_context('review').refresh_review_set()

class ReviewContext(Context.Context):
	'''reviews the configuration values'''

	cmd = 'review'

	def __init__(self, **kw):
		super(self.__class__, self).__init__(**kw)

		out = Options.options.out
		if not out:
			out = getattr(Context.g_module, Context.OUT, None)
		if not out:
			out = Options.lockfile.replace('.lock-waf', '')
		self.build_path = (os.path.isabs(out) and self.root or self.path).make_node(out).abspath()
		"""Path to the build directory"""

		self.cache_path = os.path.join(self.build_path, Build.CACHE_DIR)
		"""Path to the cache directory"""

		self.review_path = os.path.join(self.cache_path, 'review.cache')
		"""Path to the review cache file"""

	def execute(self):
		"""
		Display and store the review set. Invalidate the cache as required.
		"""
		if not self.compare_review_set(old_review_set, new_review_set):
			self.invalidate_cache()
		self.store_review_set(new_review_set)
		print(self.display_review_set(new_review_set))

	def invalidate_cache(self):
		"""Invalidate the cache to prevent bad builds."""
		try:
			Logs.warn("Removing the cached configuration since the options have changed")
			shutil.rmtree(self.cache_path)
		except:
			pass

	def refresh_review_set(self):
		"""
		Obtain the old review set and the new review set, and import the new set.
		"""
		global old_review_set, new_review_set
		old_review_set = self.load_review_set()
		new_review_set = self.update_review_set(old_review_set)
		self.import_review_set(new_review_set)

	def load_review_set(self):
		"""
		Load and return the review set from the cache if it exists.
		Otherwise, return an empty set.
		"""
		if os.path.isfile(self.review_path):
			return ConfigSet.ConfigSet(self.review_path)
		return ConfigSet.ConfigSet()

	def store_review_set(self, review_set):
		"""
		Store the review set specified in the cache.
		"""
		if not os.path.isdir(self.cache_path):
			os.makedirs(self.cache_path)
		review_set.store(self.review_path)

	def update_review_set(self, old_set):
		"""
		Merge the options passed on the command line with those imported
		from the previous review set and return the corresponding
		preview set.
		"""

		# Convert value to string. It's important that 'None' maps to
		# the empty string.
		def val_to_str(val):
			if val == None or val == '':
				return ''
			return str(val)

		new_set = ConfigSet.ConfigSet()
		opt_dict = Options.options.__dict__

		for name in review_options.keys():
			# the option is specified explicitly on the command line
			if name in opt_dict:
				# if the option is the default, pretend it was never specified
				if val_to_str(opt_dict[name]) != val_to_str(review_defaults[name]):
					new_set[name] = opt_dict[name]
			# the option was explicitly specified in a previous command
			elif name in old_set:
				new_set[name] = old_set[name]

		return new_set

	def import_review_set(self, review_set):
		"""
		Import the actual value of the reviewable options in the option
		dictionary, given the current review set.
		"""
		for name in review_options.keys():
			if name in review_set:
				value = review_set[name]
			else:
				value = review_defaults[name]
			setattr(Options.options, name, value)

	def compare_review_set(self, set1, set2):
		"""
		Return true if the review sets specified are equal.
		"""
		if len(set1.keys()) != len(set2.keys()): return False
		for key in set1.keys():
			if not key in set2 or set1[key] != set2[key]:
				return False
		return True

	def display_review_set(self, review_set):
		"""
		Return the string representing the review set specified.
		"""
		term_width = Logs.get_term_cols()
		lines = []
		for dest in review_options.keys():
			opt = review_options[dest]
			name = ", ".join(opt._short_opts + opt._long_opts)
			help = opt.help
			actual = None
			if dest in review_set: actual = review_set[dest]
			default = review_defaults[dest]
			lines.append(self.format_option(name, help, actual, default, term_width))
		return "Configuration:\n\n" + "\n\n".join(lines) + "\n"

	def format_option(self, name, help, actual, default, term_width):
		"""
		Return the string representing the option specified.
		"""
		def val_to_str(val):
			if val == None or val == '':
				return "(void)"
			return str(val)

		max_name_len = 20
		sep_len = 2

		w = textwrap.TextWrapper()
		w.width = term_width - 1
		if w.width < 60: w.width = 60

		out = ""

		# format the help
		out += w.fill(help) + "\n"

		# format the name
		name_len = len(name)
		out += Logs.colors.CYAN + name + Logs.colors.NORMAL

		# set the indentation used when the value wraps to the next line
		w.subsequent_indent = " ".rjust(max_name_len + sep_len)
		w.width -= (max_name_len + sep_len)

		# the name string is too long, switch to the next line
		if name_len > max_name_len:
			out += "\n" + w.subsequent_indent

		# fill the remaining of the line with spaces
		else:
			out += " ".rjust(max_name_len + sep_len - name_len)

		# format the actual value, if there is one
		if actual != None:
			out += Logs.colors.BOLD + w.fill(val_to_str(actual)) + Logs.colors.NORMAL + "\n" + w.subsequent_indent

		# format the default value
		default_fmt = val_to_str(default)
		if actual != None:
			default_fmt = "default: " + default_fmt
		out += Logs.colors.NORMAL + w.fill(default_fmt) + Logs.colors.NORMAL

		return out

# Monkey-patch ConfigurationContext.execute() to have it store the review set.
old_configure_execute = Configure.ConfigurationContext.execute
def new_configure_execute(self):
	old_configure_execute(self)
	Context.create_context('review').store_review_set(new_review_set)
Configure.ConfigurationContext.execute = new_configure_execute


########NEW FILE########
__FILENAME__ = smart_continue
#! /usr/bin/env python
# Thomas Nagy, 2011

# Try to cancel the tasks that cannot run with the option -k when an error occurs:
# 1 direct file dependencies
# 2 tasks listed in the before/after/ext_in/ext_out attributes

from waflib import Task, Runner

Task.CANCELED = 4

def cancel_next(self, tsk):
	if not isinstance(tsk, Task.TaskBase):
		return
	if tsk.hasrun >= Task.SKIPPED:
		# normal execution, no need to do anything here
		return

	try:
		canceled_tasks, canceled_nodes = self.canceled_tasks, self.canceled_nodes
	except AttributeError:
		canceled_tasks = self.canceled_tasks = set([])
		canceled_nodes = self.canceled_nodes = set([])

	try:
		canceled_nodes.update(tsk.outputs)
	except AttributeError:
		pass

	try:
		canceled_tasks.add(tsk)
	except AttributeError:
		pass

def get_out(self):
	tsk = self.out.get()
	if not self.stop:
		self.add_more_tasks(tsk)
	self.count -= 1
	self.dirty = True
	self.cancel_next(tsk) # new code

def error_handler(self, tsk):
	if not self.bld.keep:
		self.stop = True
	self.error.append(tsk)
	self.cancel_next(tsk) # new code

Runner.Parallel.cancel_next = cancel_next
Runner.Parallel.get_out = get_out
Runner.Parallel.error_handler = error_handler

def get_next_task(self):
	tsk = self.get_next_task_smart_continue()
	if not tsk:
		return tsk

	try:
		canceled_tasks, canceled_nodes = self.canceled_tasks, self.canceled_nodes
	except AttributeError:
		pass
	else:
		# look in the tasks that this one is waiting on
		# if one of them was canceled, cancel this one too
		for x in tsk.run_after:
			if x in canceled_tasks:
				tsk.hasrun = Task.CANCELED
				self.cancel_next(tsk)
				break
		else:
			# so far so good, now consider the nodes
			for x in getattr(tsk, 'inputs', []) + getattr(tsk, 'deps', []):
				if x in canceled_nodes:
					tsk.hasrun = Task.CANCELED
					self.cancel_next(tsk)
					break
	return tsk

Runner.Parallel.get_next_task_smart_continue = Runner.Parallel.get_next_task
Runner.Parallel.get_next_task = get_next_task


########NEW FILE########
__FILENAME__ = subprocess
# borrowed from python 2.5.2c1
# Copyright (c) 2003-2005 by Peter Astrand <astrand@lysator.liu.se>
# Licensed to PSF under a Contributor Agreement.

import sys
mswindows = (sys.platform == "win32")

import os
import types
import traceback
import gc

class CalledProcessError(Exception):
    def __init__(self, returncode, cmd):
        self.returncode = returncode
        self.cmd = cmd
    def __str__(self):
        return "Command '%s' returned non-zero exit status %d" % (self.cmd, self.returncode)

if mswindows:
    import threading
    import msvcrt
    if 0:
        import pywintypes
        from win32api import GetStdHandle, STD_INPUT_HANDLE, \
                             STD_OUTPUT_HANDLE, STD_ERROR_HANDLE
        from win32api import GetCurrentProcess, DuplicateHandle, \
                             GetModuleFileName, GetVersion
        from win32con import DUPLICATE_SAME_ACCESS, SW_HIDE
        from win32pipe import CreatePipe
        from win32process import CreateProcess, STARTUPINFO, \
                                 GetExitCodeProcess, STARTF_USESTDHANDLES, \
                                 STARTF_USESHOWWINDOW, CREATE_NEW_CONSOLE
        from win32event import WaitForSingleObject, INFINITE, WAIT_OBJECT_0
    else:
        from _subprocess import *
        class STARTUPINFO:
            dwFlags = 0
            hStdInput = None
            hStdOutput = None
            hStdError = None
            wShowWindow = 0
        class pywintypes:
            error = IOError
else:
    import select
    import errno
    import fcntl
    import pickle

__all__ = ["Popen", "PIPE", "STDOUT", "call", "check_call", "CalledProcessError"]

try:
    MAXFD = os.sysconf("SC_OPEN_MAX")
except:
    MAXFD = 256

try:
    False
except NameError:
    False = 0
    True = 1

_active = []

def _cleanup():
    for inst in _active[:]:
        if inst.poll(_deadstate=sys.maxint) >= 0:
            try:
                _active.remove(inst)
            except ValueError:
                pass

PIPE = -1
STDOUT = -2


def call(*popenargs, **kwargs):
    return Popen(*popenargs, **kwargs).wait()

def check_call(*popenargs, **kwargs):
    retcode = call(*popenargs, **kwargs)
    cmd = kwargs.get("args")
    if cmd is None:
        cmd = popenargs[0]
    if retcode:
        raise CalledProcessError(retcode, cmd)
    return retcode


def list2cmdline(seq):
    result = []
    needquote = False
    for arg in seq:
        bs_buf = []

        if result:
            result.append(' ')

        needquote = (" " in arg) or ("\t" in arg) or arg == ""
        if needquote:
            result.append('"')

        for c in arg:
            if c == '\\':
                bs_buf.append(c)
            elif c == '"':
                result.append('\\' * len(bs_buf)*2)
                bs_buf = []
                result.append('\\"')
            else:
                if bs_buf:
                    result.extend(bs_buf)
                    bs_buf = []
                result.append(c)

        if bs_buf:
            result.extend(bs_buf)

        if needquote:
            result.extend(bs_buf)
            result.append('"')

    return ''.join(result)

class Popen(object):
    def __init__(self, args, bufsize=0, executable=None,
                 stdin=None, stdout=None, stderr=None,
                 preexec_fn=None, close_fds=False, shell=False,
                 cwd=None, env=None, universal_newlines=False,
                 startupinfo=None, creationflags=0):
        _cleanup()

        self._child_created = False
        if not isinstance(bufsize, (int, long)):
            raise TypeError("bufsize must be an integer")

        if mswindows:
            if preexec_fn is not None:
                raise ValueError("preexec_fn is not supported on Windows platforms")
            if close_fds:
                raise ValueError("close_fds is not supported on Windows platforms")
        else:
            if startupinfo is not None:
                raise ValueError("startupinfo is only supported on Windows platforms")
            if creationflags != 0:
                raise ValueError("creationflags is only supported on Windows platforms")

        self.stdin = None
        self.stdout = None
        self.stderr = None
        self.pid = None
        self.returncode = None
        self.universal_newlines = universal_newlines

        (p2cread, p2cwrite,
         c2pread, c2pwrite,
         errread, errwrite) = self._get_handles(stdin, stdout, stderr)

        self._execute_child(args, executable, preexec_fn, close_fds,
                            cwd, env, universal_newlines,
                            startupinfo, creationflags, shell,
                            p2cread, p2cwrite,
                            c2pread, c2pwrite,
                            errread, errwrite)

        if mswindows:
            if stdin is None and p2cwrite is not None:
                os.close(p2cwrite)
                p2cwrite = None
            if stdout is None and c2pread is not None:
                os.close(c2pread)
                c2pread = None
            if stderr is None and errread is not None:
                os.close(errread)
                errread = None

        if p2cwrite:
            self.stdin = os.fdopen(p2cwrite, 'wb', bufsize)
        if c2pread:
            if universal_newlines:
                self.stdout = os.fdopen(c2pread, 'rU', bufsize)
            else:
                self.stdout = os.fdopen(c2pread, 'rb', bufsize)
        if errread:
            if universal_newlines:
                self.stderr = os.fdopen(errread, 'rU', bufsize)
            else:
                self.stderr = os.fdopen(errread, 'rb', bufsize)


    def _translate_newlines(self, data):
        data = data.replace("\r\n", "\n")
        data = data.replace("\r", "\n")
        return data


    def __del__(self, sys=sys):
        if not self._child_created:
            return
        self.poll(_deadstate=sys.maxint)
        if self.returncode is None and _active is not None:
            _active.append(self)


    def communicate(self, input=None):
        if [self.stdin, self.stdout, self.stderr].count(None) >= 2:
            stdout = None
            stderr = None
            if self.stdin:
                if input:
                    self.stdin.write(input)
                self.stdin.close()
            elif self.stdout:
                stdout = self.stdout.read()
            elif self.stderr:
                stderr = self.stderr.read()
            self.wait()
            return (stdout, stderr)

        return self._communicate(input)


    if mswindows:
        def _get_handles(self, stdin, stdout, stderr):
            if stdin is None and stdout is None and stderr is None:
                return (None, None, None, None, None, None)

            p2cread, p2cwrite = None, None
            c2pread, c2pwrite = None, None
            errread, errwrite = None, None

            if stdin is None:
                p2cread = GetStdHandle(STD_INPUT_HANDLE)
            if p2cread is not None:
                pass
            elif stdin is None or stdin == PIPE:
                p2cread, p2cwrite = CreatePipe(None, 0)
                p2cwrite = p2cwrite.Detach()
                p2cwrite = msvcrt.open_osfhandle(p2cwrite, 0)
            elif isinstance(stdin, int):
                p2cread = msvcrt.get_osfhandle(stdin)
            else:
                p2cread = msvcrt.get_osfhandle(stdin.fileno())
            p2cread = self._make_inheritable(p2cread)

            if stdout is None:
                c2pwrite = GetStdHandle(STD_OUTPUT_HANDLE)
            if c2pwrite is not None:
                pass
            elif stdout is None or stdout == PIPE:
                c2pread, c2pwrite = CreatePipe(None, 0)
                c2pread = c2pread.Detach()
                c2pread = msvcrt.open_osfhandle(c2pread, 0)
            elif isinstance(stdout, int):
                c2pwrite = msvcrt.get_osfhandle(stdout)
            else:
                c2pwrite = msvcrt.get_osfhandle(stdout.fileno())
            c2pwrite = self._make_inheritable(c2pwrite)

            if stderr is None:
                errwrite = GetStdHandle(STD_ERROR_HANDLE)
            if errwrite is not None:
                pass
            elif stderr is None or stderr == PIPE:
                errread, errwrite = CreatePipe(None, 0)
                errread = errread.Detach()
                errread = msvcrt.open_osfhandle(errread, 0)
            elif stderr == STDOUT:
                errwrite = c2pwrite
            elif isinstance(stderr, int):
                errwrite = msvcrt.get_osfhandle(stderr)
            else:
                errwrite = msvcrt.get_osfhandle(stderr.fileno())
            errwrite = self._make_inheritable(errwrite)

            return (p2cread, p2cwrite,
                    c2pread, c2pwrite,
                    errread, errwrite)
        def _make_inheritable(self, handle):
            return DuplicateHandle(GetCurrentProcess(), handle, GetCurrentProcess(), 0, 1, DUPLICATE_SAME_ACCESS)

        def _find_w9xpopen(self):
            w9xpopen = os.path.join(os.path.dirname(GetModuleFileName(0)), "w9xpopen.exe")
            if not os.path.exists(w9xpopen):
                w9xpopen = os.path.join(os.path.dirname(sys.exec_prefix), "w9xpopen.exe")
                if not os.path.exists(w9xpopen):
                    raise RuntimeError("Cannot locate w9xpopen.exe, which is needed for Popen to work with your shell or platform.")
            return w9xpopen

        def _execute_child(self, args, executable, preexec_fn, close_fds,
                           cwd, env, universal_newlines,
                           startupinfo, creationflags, shell,
                           p2cread, p2cwrite,
                           c2pread, c2pwrite,
                           errread, errwrite):

            if not isinstance(args, types.StringTypes):
                args = list2cmdline(args)

            if startupinfo is None:
                startupinfo = STARTUPINFO()
            if None not in (p2cread, c2pwrite, errwrite):
                startupinfo.dwFlags |= STARTF_USESTDHANDLES
                startupinfo.hStdInput = p2cread
                startupinfo.hStdOutput = c2pwrite
                startupinfo.hStdError = errwrite

            if shell:
                startupinfo.dwFlags |= STARTF_USESHOWWINDOW
                startupinfo.wShowWindow = SW_HIDE
                comspec = os.environ.get("COMSPEC", "cmd.exe")
                args = comspec + " /c " + args
                if (GetVersion() >= 0x80000000L or
                        os.path.basename(comspec).lower() == "command.com"):
                    w9xpopen = self._find_w9xpopen()
                    args = '"%s" %s' % (w9xpopen, args)
                    creationflags |= CREATE_NEW_CONSOLE

            try:
                hp, ht, pid, tid = CreateProcess(executable, args, None, None, 1, creationflags, env, cwd, startupinfo)
            except pywintypes.error, e:
                raise WindowsError(*e.args)

            self._child_created = True
            self._handle = hp
            self.pid = pid
            ht.Close()

            if p2cread is not None:
                p2cread.Close()
            if c2pwrite is not None:
                c2pwrite.Close()
            if errwrite is not None:
                errwrite.Close()


        def poll(self, _deadstate=None):
            if self.returncode is None:
                if WaitForSingleObject(self._handle, 0) == WAIT_OBJECT_0:
                    self.returncode = GetExitCodeProcess(self._handle)
            return self.returncode


        def wait(self):
            if self.returncode is None:
                obj = WaitForSingleObject(self._handle, INFINITE)
                self.returncode = GetExitCodeProcess(self._handle)
            return self.returncode

        def _readerthread(self, fh, buffer):
            buffer.append(fh.read())

        def _communicate(self, input):
            stdout = None
            stderr = None

            if self.stdout:
                stdout = []
                stdout_thread = threading.Thread(target=self._readerthread, args=(self.stdout, stdout))
                stdout_thread.setDaemon(True)
                stdout_thread.start()
            if self.stderr:
                stderr = []
                stderr_thread = threading.Thread(target=self._readerthread, args=(self.stderr, stderr))
                stderr_thread.setDaemon(True)
                stderr_thread.start()

            if self.stdin:
                if input is not None:
                    self.stdin.write(input)
                self.stdin.close()

            if self.stdout:
                stdout_thread.join()
            if self.stderr:
                stderr_thread.join()

            if stdout is not None:
                stdout = stdout[0]
            if stderr is not None:
                stderr = stderr[0]

            if self.universal_newlines and hasattr(file, 'newlines'):
                if stdout:
                    stdout = self._translate_newlines(stdout)
                if stderr:
                    stderr = self._translate_newlines(stderr)

            self.wait()
            return (stdout, stderr)

    else:
        def _get_handles(self, stdin, stdout, stderr):
            p2cread, p2cwrite = None, None
            c2pread, c2pwrite = None, None
            errread, errwrite = None, None

            if stdin is None:
                pass
            elif stdin == PIPE:
                p2cread, p2cwrite = os.pipe()
            elif isinstance(stdin, int):
                p2cread = stdin
            else:
                p2cread = stdin.fileno()

            if stdout is None:
                pass
            elif stdout == PIPE:
                c2pread, c2pwrite = os.pipe()
            elif isinstance(stdout, int):
                c2pwrite = stdout
            else:
                c2pwrite = stdout.fileno()

            if stderr is None:
                pass
            elif stderr == PIPE:
                errread, errwrite = os.pipe()
            elif stderr == STDOUT:
                errwrite = c2pwrite
            elif isinstance(stderr, int):
                errwrite = stderr
            else:
                errwrite = stderr.fileno()

            return (p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite)

        def _set_cloexec_flag(self, fd):
            try:
                cloexec_flag = fcntl.FD_CLOEXEC
            except AttributeError:
                cloexec_flag = 1

            old = fcntl.fcntl(fd, fcntl.F_GETFD)
            fcntl.fcntl(fd, fcntl.F_SETFD, old | cloexec_flag)

        def _close_fds(self, but):
            for i in xrange(3, MAXFD):
                if i == but:
                    continue
                try:
                    os.close(i)
                except:
                    pass

        def _execute_child(self, args, executable, preexec_fn, close_fds,
                           cwd, env, universal_newlines, startupinfo, creationflags, shell,
                           p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite):

            if isinstance(args, types.StringTypes):
                args = [args]
            else:
                args = list(args)

            if shell:
                args = ["/bin/sh", "-c"] + args

            if executable is None:
                executable = args[0]

            errpipe_read, errpipe_write = os.pipe()
            self._set_cloexec_flag(errpipe_write)

            gc_was_enabled = gc.isenabled()
            gc.disable()
            try:
                self.pid = os.fork()
            except:
                if gc_was_enabled:
                    gc.enable()
                raise
            self._child_created = True
            if self.pid == 0:
                try:
                    if p2cwrite:
                        os.close(p2cwrite)
                    if c2pread:
                        os.close(c2pread)
                    if errread:
                        os.close(errread)
                    os.close(errpipe_read)

                    if p2cread:
                        os.dup2(p2cread, 0)
                    if c2pwrite:
                        os.dup2(c2pwrite, 1)
                    if errwrite:
                        os.dup2(errwrite, 2)

                    if p2cread and p2cread not in (0,):
                        os.close(p2cread)
                    if c2pwrite and c2pwrite not in (p2cread, 1):
                        os.close(c2pwrite)
                    if errwrite and errwrite not in (p2cread, c2pwrite, 2):
                        os.close(errwrite)

                    if close_fds:
                        self._close_fds(but=errpipe_write)

                    if cwd is not None:
                        os.chdir(cwd)

                    if preexec_fn:
                        apply(preexec_fn)

                    if env is None:
                        os.execvp(executable, args)
                    else:
                        os.execvpe(executable, args, env)

                except:
                    exc_type, exc_value, tb = sys.exc_info()
                    exc_lines = traceback.format_exception(exc_type, exc_value, tb)
                    exc_value.child_traceback = ''.join(exc_lines)
                    os.write(errpipe_write, pickle.dumps(exc_value))

                os._exit(255)

            if gc_was_enabled:
                gc.enable()
            os.close(errpipe_write)
            if p2cread and p2cwrite:
                os.close(p2cread)
            if c2pwrite and c2pread:
                os.close(c2pwrite)
            if errwrite and errread:
                os.close(errwrite)

            data = os.read(errpipe_read, 1048576)
            os.close(errpipe_read)
            if data != "":
                os.waitpid(self.pid, 0)
                child_exception = pickle.loads(data)
                raise child_exception

        def _handle_exitstatus(self, sts):
            if os.WIFSIGNALED(sts):
                self.returncode = -os.WTERMSIG(sts)
            elif os.WIFEXITED(sts):
                self.returncode = os.WEXITSTATUS(sts)
            else:
                raise RuntimeError("Unknown child exit status!")

        def poll(self, _deadstate=None):
            if self.returncode is None:
                try:
                    pid, sts = os.waitpid(self.pid, os.WNOHANG)
                    if pid == self.pid:
                        self._handle_exitstatus(sts)
                except os.error:
                    if _deadstate is not None:
                        self.returncode = _deadstate
            return self.returncode

        def wait(self):
            if self.returncode is None:
                pid, sts = os.waitpid(self.pid, 0)
                self._handle_exitstatus(sts)
            return self.returncode

        def _communicate(self, input):
            read_set = []
            write_set = []
            stdout = None
            stderr = None

            if self.stdin:
                self.stdin.flush()
                if input:
                    write_set.append(self.stdin)
                else:
                    self.stdin.close()
            if self.stdout:
                read_set.append(self.stdout)
                stdout = []
            if self.stderr:
                read_set.append(self.stderr)
                stderr = []

            input_offset = 0
            while read_set or write_set:
                rlist, wlist, xlist = select.select(read_set, write_set, [])

                if self.stdin in wlist:
                    bytes_written = os.write(self.stdin.fileno(), buffer(input, input_offset, 512))
                    input_offset += bytes_written
                    if input_offset >= len(input):
                        self.stdin.close()
                        write_set.remove(self.stdin)

                if self.stdout in rlist:
                    data = os.read(self.stdout.fileno(), 1024)
                    if data == "":
                        self.stdout.close()
                        read_set.remove(self.stdout)
                    stdout.append(data)

                if self.stderr in rlist:
                    data = os.read(self.stderr.fileno(), 1024)
                    if data == "":
                        self.stderr.close()
                        read_set.remove(self.stderr)
                    stderr.append(data)

            if stdout is not None:
                stdout = ''.join(stdout)
            if stderr is not None:
                stderr = ''.join(stderr)

            if self.universal_newlines and hasattr(file, 'newlines'):
                if stdout:
                    stdout = self._translate_newlines(stdout)
                if stderr:
                    stderr = self._translate_newlines(stderr)

            self.wait()
            return (stdout, stderr)


########NEW FILE########
__FILENAME__ = syms
#! /usr/bin/env python
# encoding: utf-8

"""
this tool supports the export_symbols_regex to export the symbols in a shared library.
by default, all symbols are exported by gcc, and nothing by msvc.
to use the tool, do something like:

def build(ctx):
	ctx(features='c cshlib syms', source='a.c b.c', export_symbols_regex='mylib_.*', target='testlib')

only the symbols starting with 'mylib_' will be exported.
"""

import re
from waflib.Context import STDOUT
from waflib.Task import Task
from waflib.Errors import WafError
from waflib.TaskGen import feature, after_method

class gen_sym(Task):
	def run(self):
		obj = self.inputs[0]
		if 'msvc' in (self.env.CC_NAME, self.env.CXX_NAME):
			re_nm = re.compile(r'External\s+\|\s+_(' + self.generator.export_symbols_regex + r')\b')
			cmd = ['dumpbin', '/symbols', obj.abspath()]
		else:
			if self.env.DEST_BINFMT == 'pe': #gcc uses nm, and has a preceding _ on windows
				re_nm = re.compile(r'T\s+_(' + self.generator.export_symbols_regex + r')\b')
			else:
				re_nm = re.compile(r'T\s+(' + self.generator.export_symbols_regex + r')\b')
			cmd = ['nm', '-g', obj.abspath()]
		syms = re_nm.findall(self.generator.bld.cmd_and_log(cmd, quiet=STDOUT))
		self.outputs[0].write('%r' % syms)

class compile_sym(Task):
	def run(self):
		syms = {}
		for x in self.inputs:
			slist = eval(x.read())
			for s in slist:
				syms[s] = 1
		lsyms = syms.keys()
		lsyms.sort()
		if self.env.DEST_BINFMT == 'pe':
			self.outputs[0].write('EXPORTS\n' + '\n'.join(lsyms))
		elif self.env.DEST_BINFMT == 'elf':
			self.outputs[0].write('{ global:\n' + ';\n'.join(lsyms) + ";\nlocal: *; };\n")
		else:
			raise WafError('NotImplemented')

@feature('syms')
@after_method('process_source', 'process_use', 'apply_link', 'process_uselib_local')
def do_the_symbol_stuff(self):
	ins = [x.outputs[0] for x in self.compiled_tasks]
	self.gen_sym_tasks = [self.create_task('gen_sym', x, x.change_ext('.%d.sym' % self.idx)) for x in ins]

	tsk = self.create_task('compile_sym',
			       [x.outputs[0] for x in self.gen_sym_tasks],
			       self.path.find_or_declare(getattr(self, 'sym_filename', self.target + '.def')))
	self.link_task.set_run_after(tsk)
	self.link_task.dep_nodes = [tsk.outputs[0]]
	if 'msvc' in (self.env.CC_NAME, self.env.CXX_NAME):
		self.link_task.env.append_value('LINKFLAGS', ['/def:' + tsk.outputs[0].bldpath()])
	elif self.env.DEST_BINFMT == 'pe': #gcc on windows takes *.def as an additional input
		self.link_task.inputs.append(tsk.outputs[0])
	elif self.env.DEST_BINFMT == 'elf':
		self.link_task.env.append_value('LINKFLAGS', ['-Wl,-version-script', '-Wl,' + tsk.outputs[0].bldpath()])
	else:
		raise WafError('NotImplemented')


########NEW FILE########
__FILENAME__ = fixpy2
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2010 (ita)

"""
burn a book, save a tree
"""

import os
all_modifs = {}

def fixdir(dir):
	"""call all the substitution functions on the waf folders"""
	global all_modifs
	for k in all_modifs:
		for v in all_modifs[k]:
			modif(os.path.join(dir, 'waflib'), k, v)

def modif(dir, name, fun):
	"""execute a substitution function"""
	if name == '*':
		lst = []
		for y in '. Tools extras'.split():
			for x in os.listdir(os.path.join(dir, y)):
				if x.endswith('.py'):
					lst.append(y + os.sep + x)
		for x in lst:
			modif(dir, x, fun)
		return

	filename = os.path.join(dir, name)
	f = open(filename, 'r')
	txt = f.read()
	f.close()

	txt = fun(txt)

	f = open(filename, 'w')
	f.write(txt)
	f.close()

def subst(*k):
	"""register a substitution function"""
	def do_subst(fun):
		global all_modifs
		for x in k:
			try:
				all_modifs[x].append(fun)
			except KeyError:
				all_modifs[x] = [fun]
		return fun
	return do_subst

@subst('*')
def r1(code):
	"utf-8 fixes for python < 2.6"
	code = code.replace('as e:', ',e:')
	code = code.replace(".decode(sys.stdout.encoding or 'iso8859-1')", '')
	code = code.replace('.encode()', '')
	return code

@subst('Runner.py')
def r4(code):
	"generator syntax"
	code = code.replace('next(self.biter)', 'self.biter.next()')
	return code


########NEW FILE########
__FILENAME__ = Logs
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2005-2010 (ita)

"""
logging, colors, terminal width and pretty-print
"""

import os, re, traceback, sys

_nocolor = os.environ.get('NOCOLOR', 'no') not in ('no', '0', 'false')
try:
	if not _nocolor:
		import waflib.ansiterm
except:
	# optional module for colors on win32, just ignore if it cannot be imported
	pass

import logging # do it after

LOG_FORMAT = "%(asctime)s %(c1)s%(zone)s%(c2)s %(message)s"
HOUR_FORMAT = "%H:%M:%S"

zones = ''
verbose = 0

colors_lst = {
'USE' : True,
'BOLD'  :'\x1b[01;1m',
'RED'   :'\x1b[01;31m',
'GREEN' :'\x1b[32m',
'YELLOW':'\x1b[33m',
'PINK'  :'\x1b[35m',
'BLUE'  :'\x1b[01;34m',
'CYAN'  :'\x1b[36m',
'NORMAL':'\x1b[0m',
'cursor_on'  :'\x1b[?25h',
'cursor_off' :'\x1b[?25l',
}

got_tty = not os.environ.get('TERM', 'dumb') in ['dumb', 'emacs']
if got_tty:
	try:
		got_tty = sys.stderr.isatty()
	except AttributeError:
		got_tty = False

if (not got_tty and os.environ.get('TERM', 'dumb') != 'msys') or _nocolor:
	colors_lst['USE'] = False

def get_term_cols():
	return 80

# If console packages are available, replace the dummy function with a real
# implementation
try:
	import struct, fcntl, termios
except ImportError:
	pass
else:
	if got_tty:
		def get_term_cols_real():
			"""
			Private use only.
			"""

			dummy_lines, cols = struct.unpack("HHHH", \
			fcntl.ioctl(sys.stderr.fileno(),termios.TIOCGWINSZ , \
			struct.pack("HHHH", 0, 0, 0, 0)))[:2]
			return cols
		# try the function once to see if it really works
		try:
			get_term_cols_real()
		except:
			pass
		else:
			get_term_cols = get_term_cols_real

get_term_cols.__doc__ = """
	Get the console width in characters.

	:return: the number of characters per line
	:rtype: int
	"""

def get_color(cl):
	if not colors_lst['USE']: return ''
	return colors_lst.get(cl, '')

class color_dict(object):
	"""attribute-based color access, eg: colors.PINK"""
	def __getattr__(self, a):
		return get_color(a)
	def __call__(self, a):
		return get_color(a)

colors = color_dict()

re_log = re.compile(r'(\w+): (.*)', re.M)
class log_filter(logging.Filter):
	"""
	The waf logs are of the form 'name: message', and can be filtered by 'waf --zones=name'.
	For example, the following::

		from waflib import Logs
		Logs.debug('test: here is a message')

	Will be displayed only when executing::

		$ waf --zones=test
	"""
	def __init__(self, name=None):
		pass

	def filter(self, rec):
		"""
		filter a record, adding the colors automatically

		* error: red
		* warning: yellow

		:param rec: message to record
		"""

		rec.c1 = colors.PINK
		rec.c2 = colors.NORMAL
		rec.zone = rec.module
		if rec.levelno >= logging.INFO:
			if rec.levelno >= logging.ERROR:
				rec.c1 = colors.RED
			elif rec.levelno >= logging.WARNING:
				rec.c1 = colors.YELLOW
			else:
				rec.c1 = colors.GREEN
			return True

		m = re_log.match(rec.msg)
		if m:
			rec.zone = m.group(1)
			rec.msg = m.group(2)

		if zones:
			return getattr(rec, 'zone', '') in zones or '*' in zones
		elif not verbose > 2:
			return False
		return True

class formatter(logging.Formatter):
	"""Simple log formatter which handles colors"""
	def __init__(self):
		logging.Formatter.__init__(self, LOG_FORMAT, HOUR_FORMAT)

	def format(self, rec):
		"""Messages in warning, error or info mode are displayed in color by default"""
		if rec.levelno >= logging.WARNING or rec.levelno == logging.INFO:
			try:
				msg = rec.msg.decode('utf-8')
			except:
				msg = rec.msg
			return '%s%s%s' % (rec.c1, msg, rec.c2)
		return logging.Formatter.format(self, rec)

log = None
"""global logger for Logs.debug, Logs.error, etc"""

def debug(*k, **kw):
	"""
	Wrap logging.debug, the output is filtered for performance reasons
	"""
	if verbose:
		k = list(k)
		k[0] = k[0].replace('\n', ' ')
		global log
		log.debug(*k, **kw)

def error(*k, **kw):
	"""
	Wrap logging.errors, display the origin of the message when '-vv' is set
	"""
	global log
	log.error(*k, **kw)
	if verbose > 2:
		st = traceback.extract_stack()
		if st:
			st = st[:-1]
			buf = []
			for filename, lineno, name, line in st:
				buf.append('  File "%s", line %d, in %s' % (filename, lineno, name))
				if line:
					buf.append('	%s' % line.strip())
			if buf: log.error("\n".join(buf))

def warn(*k, **kw):
	"""
	Wrap logging.warn
	"""
	global log
	log.warn(*k, **kw)

def info(*k, **kw):
	"""
	Wrap logging.info
	"""
	global log
	log.info(*k, **kw)

def init_log():
	"""
	Initialize the loggers globally
	"""
	global log
	log = logging.getLogger('waflib')
	log.handlers = []
	log.filters = []
	hdlr = logging.StreamHandler()
	hdlr.setFormatter(formatter())
	log.addHandler(hdlr)
	log.addFilter(log_filter())
	log.setLevel(logging.DEBUG)

def make_logger(path, name):
	"""
	Create a simple logger, which is often used to redirect the context command output::

		from waflib import Logs
		bld.logger = Logs.make_logger('test.log', 'build')
		bld.check(header_name='sadlib.h', features='cxx cprogram', mandatory=False)
		bld.logger = None

	:param path: file name to write the log output to
	:type path: string
	:param name: logger name (loggers are reused)
	:type name: string
	"""
	logger = logging.getLogger(name)
	hdlr = logging.FileHandler(path, 'w')
	formatter = logging.Formatter('%(message)s')
	hdlr.setFormatter(formatter)
	logger.addHandler(hdlr)
	logger.setLevel(logging.DEBUG)
	return logger

def make_mem_logger(name, to_log, size=10000):
	"""
	Create a memory logger to avoid writing concurrently to the main logger
	"""
	from logging.handlers import MemoryHandler
	logger = logging.getLogger(name)
	hdlr = MemoryHandler(size, target=to_log)
	formatter = logging.Formatter('%(message)s')
	hdlr.setFormatter(formatter)
	logger.addHandler(hdlr)
	logger.memhandler = hdlr
	logger.setLevel(logging.DEBUG)
	return logger

def pprint(col, str, label='', sep='\n'):
	"""
	Print messages in color immediately on stderr::

		from waflib import Logs
		Logs.pprint('RED', 'Something bad just happened')

	:param col: color name to use in :py:const:`Logs.colors_lst`
	:type col: string
	:param str: message to display
	:type str: string or a value that can be printed by %s
	:param label: a message to add after the colored output
	:type label: string
	:param sep: a string to append at the end (line separator)
	:type sep: string
	"""
	sys.stderr.write("%s%s%s %s%s" % (colors(col), str, colors.NORMAL, label, sep))


########NEW FILE########
__FILENAME__ = Node
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2005-2010 (ita)

"""
Node: filesystem structure, contains lists of nodes

#. Each file/folder is represented by exactly one node.

#. Some potential class properties are stored on :py:class:`waflib.Build.BuildContext` : nodes to depend on, etc.
   Unused class members can increase the `.wafpickle` file size sensibly.

#. Node objects should never be created directly, use
   the methods :py:func:`Node.make_node` or :py:func:`Node.find_node`

#. The methods :py:func:`Node.find_resource`, :py:func:`Node.find_dir` :py:func:`Node.find_or_declare` should be
   used when a build context is present

#. Each instance of :py:class:`waflib.Context.Context` has a unique :py:class:`Node` subclass.
   (:py:class:`waflib.Node.Nod3`, see the :py:class:`waflib.Context.Context` initializer). A reference to the context owning a node is held as self.ctx
"""

import os, re, sys, shutil
from waflib import Utils, Errors

exclude_regs = '''
**/*~
**/#*#
**/.#*
**/%*%
**/._*
**/CVS
**/CVS/**
**/.cvsignore
**/SCCS
**/SCCS/**
**/vssver.scc
**/.svn
**/.svn/**
**/BitKeeper
**/.git
**/.git/**
**/.gitignore
**/.bzr
**/.bzrignore
**/.bzr/**
**/.hg
**/.hg/**
**/_MTN
**/_MTN/**
**/.arch-ids
**/{arch}
**/_darcs
**/_darcs/**
**/.DS_Store'''
"""
Ant patterns for files and folders to exclude while doing the
recursive traversal in :py:meth:`waflib.Node.Node.ant_glob`
"""

# TODO optimize split_path by performing a replacement when unpacking?

def split_path(path):
	"""
	Split a path by os.sep (This is not os.path.split)

	:param path: path to split
	:type path: string
	:rtype: list of string
	:return: the path, split
	"""
	return path.split('/')

def split_path_cygwin(path):
	if path.startswith('//'):
		ret = path.split('/')[2:]
		ret[0] = '/' + ret[0]
		return ret
	return path.split('/')

re_sp = re.compile('[/\\\\]')
def split_path_win32(path):
	if path.startswith('\\\\'):
		ret = re.split(re_sp, path)[2:]
		ret[0] = '\\' + ret[0]
		return ret
	return re.split(re_sp, path)

if sys.platform == 'cygwin':
	split_path = split_path_cygwin
elif Utils.is_win32:
	split_path = split_path_win32

class Node(object):
	"""
	This class is organized in two parts

	* The basic methods meant for filesystem access (compute paths, create folders, etc)
	* The methods bound to a :py:class:`waflib.Build.BuildContext` (require ``bld.srcnode`` and ``bld.bldnode``)

	The Node objects are not thread safe in any way.
	"""

	__slots__ = ('name', 'sig', 'children', 'parent', 'cache_abspath', 'cache_isdir')
	def __init__(self, name, parent):
		self.name = name
		self.parent = parent

		if parent:
			if name in parent.children:
				raise Errors.WafError('node %s exists in the parent files %r already' % (name, parent))
			parent.children[name] = self

	def __setstate__(self, data):
		"Deserializes from data"
		self.name = data[0]
		self.parent = data[1]
		if data[2] is not None:
			self.children = data[2]
		if data[3] is not None:
			self.sig = data[3]

	def __getstate__(self):
		"Serialize the node info"
		return (self.name, self.parent, getattr(self, 'children', None), getattr(self, 'sig', None))

	def __str__(self):
		"String representation (name), for debugging purposes"
		return self.name

	def __repr__(self):
		"String representation (abspath), for debugging purposes"
		return self.abspath()

	def __hash__(self):
		"Node hash, used for storage in dicts. This hash is not persistent."
		return id(self)

	def __eq__(self, node):
		"Node comparison, based on the IDs"
		return id(self) == id(node)

	def __copy__(self):
		"Implemented to prevent nodes from being copied (raises an exception)"
		raise Errors.WafError('nodes are not supposed to be copied')

	def read(self, flags='r'):
		"""
		Return the contents of the file represented by this node::

			def build(bld):
				bld.path.find_node('wscript').read()

		:type  fname: string
		:param fname: Path to file
		:type  m: string
		:param m: Open mode
		:rtype: string
		:return: File contents
		"""
		return Utils.readf(self.abspath(), flags)

	def write(self, data, flags='w'):
		"""
		Write some text to the physical file represented by this node::

			def build(bld):
				bld.path.make_node('foo.txt').write('Hello, world!')

		:type  data: string
		:param data: data to write
		:type  flags: string
		:param flags: Write mode
		"""
		f = None
		try:
			f = open(self.abspath(), flags)
			f.write(data)
		finally:
			if f:
				f.close()

	def chmod(self, val):
		"""
		Change file/dir permissions::

			def build(bld):
				bld.path.chmod(493) # 0755
		"""
		os.chmod(self.abspath(), val)

	def delete(self):
		"""Delete the file/folder physically (but not the node)"""
		try:
			if getattr(self, 'children', None):
				shutil.rmtree(self.abspath())
			else:
				os.unlink(self.abspath())
		except:
			pass

		try:
			delattr(self, 'children')
		except:
			pass

	def suffix(self):
		"""Return the file extension"""
		k = max(0, self.name.rfind('.'))
		return self.name[k:]

	def height(self):
		"""Depth in the folder hierarchy from the filesystem root or from all the file drives"""
		d = self
		val = -1
		while d:
			d = d.parent
			val += 1
		return val

	def listdir(self):
		"""List the folder contents"""
		lst = Utils.listdir(self.abspath())
		lst.sort()
		return lst

	def mkdir(self):
		"""
		Create a folder represented by this node, creating intermediate nodes as needed
		An exception will be raised only when the folder cannot possibly exist there
		"""
		if getattr(self, 'cache_isdir', None):
			return

		try:
			self.parent.mkdir()
		except:
			pass

		if self.name:
			try:
				os.makedirs(self.abspath())
			except OSError:
				pass

			if not os.path.isdir(self.abspath()):
				raise Errors.WafError('Could not create the directory %s' % self.abspath())

			try:
				self.children
			except:
				self.children = {}

		self.cache_isdir = True

	def find_node(self, lst):
		"""
		Find a node on the file system (files or folders), create intermediate nodes as needed

		:param lst: path
		:type lst: string or list of string
		"""

		if isinstance(lst, str):
			lst = [x for x in split_path(lst) if x and x != '.']

		cur = self
		for x in lst:
			if x == '..':
				cur = cur.parent or cur
				continue

			try:
				if x in cur.children:
					cur = cur.children[x]
					continue
			except:
				cur.children = {}

			# optimistic: create the node first then look if it was correct to do so
			cur = self.__class__(x, cur)
			try:
				os.stat(cur.abspath())
			except:
				del cur.parent.children[x]
				return None

		ret = cur

		try:
			os.stat(ret.abspath())
		except:
			del ret.parent.children[ret.name]
			return None

		try:
			while not getattr(cur.parent, 'cache_isdir', None):
				cur = cur.parent
				cur.cache_isdir = True
		except AttributeError:
			pass

		return ret

	def make_node(self, lst):
		"""
		Find or create a node without looking on the filesystem

		:param lst: path
		:type lst: string or list of string
		"""
		if isinstance(lst, str):
			lst = [x for x in split_path(lst) if x and x != '.']

		cur = self
		for x in lst:
			if x == '..':
				cur = cur.parent or cur
				continue

			if getattr(cur, 'children', {}):
				if x in cur.children:
					cur = cur.children[x]
					continue
			else:
				cur.children = {}
			cur = self.__class__(x, cur)
		return cur

	def search(self, lst):
		"""
		Search for a node without looking on the filesystem

		:param lst: path
		:type lst: string or list of string
		"""
		if isinstance(lst, str):
			lst = [x for x in split_path(lst) if x and x != '.']

		cur = self
		try:
			for x in lst:
				if x == '..':
					cur = cur.parent or cur
				else:
					cur = cur.children[x]
			return cur
		except:
			pass

	def path_from(self, node):
		"""
		Path of this node seen from the other::

			def build(bld):
				n1 = bld.path.find_node('foo/bar/xyz.txt')
				n2 = bld.path.find_node('foo/stuff/')
				n1.path_from(n2) # './bar/xyz.txt'

		:param node: path to use as a reference
		:type node: :py:class:`waflib.Node.Node`
		"""

		c1 = self
		c2 = node

		c1h = c1.height()
		c2h = c2.height()

		lst = []
		up = 0

		while c1h > c2h:
			lst.append(c1.name)
			c1 = c1.parent
			c1h -= 1

		while c2h > c1h:
			up += 1
			c2 = c2.parent
			c2h -= 1

		while id(c1) != id(c2):
			lst.append(c1.name)
			up += 1

			c1 = c1.parent
			c2 = c2.parent

		for i in range(up):
			lst.append('..')
		lst.reverse()
		return os.sep.join(lst) or '.'

	def abspath(self):
		"""
		Absolute path. A cache is kept in the context as ``cache_node_abspath``
		"""
		try:
			return self.cache_abspath
		except:
			pass
		# think twice before touching this (performance + complexity + correctness)

		if os.sep == '/':
			if not self.parent:
				val = os.sep
			elif not self.parent.name:
				val = os.sep + self.name
			else:
				val = self.parent.abspath() + os.sep + self.name
		else:
			if not self.parent:
				val = ''
			elif not self.parent.name:
				val = self.name + os.sep
			else:
				val = self.parent.abspath().rstrip(os.sep) + os.sep + self.name

		self.cache_abspath = val
		return val

	def is_child_of(self, node):
		"""
		Does this node belong to the subtree node?::

			def build(bld):
				node = bld.path.find_node('wscript')
				node.is_child_of(bld.path) # True

		:param node: path to use as a reference
		:type node: :py:class:`waflib.Node.Node`
		"""
		p = self
		diff = self.height() - node.height()
		while diff > 0:
			diff -= 1
			p = p.parent
		return id(p) == id(node)

	def ant_iter(self, accept=None, maxdepth=25, pats=[], dir=False, src=True, remove=True):
		"""
		Semi-private and recursive method used by ant_glob.

		:param accept: function used for accepting/rejecting a node, returns the patterns that can be still accepted in recursion
		:type accept: function
		:param maxdepth: maximum depth in the filesystem (25)
		:type maxdepth: int
		:param pats: list of patterns to accept and list of patterns to exclude
		:type pats: tuple
		:param dir: return folders too (False by default)
		:type dir: bool
		:param src: return files (True by default)
		:type src: bool
		:param remove: remove files/folders that do not exist (True by default)
		:type remove: bool
		"""
		dircont = self.listdir()
		dircont.sort()

		try:
			lst = set(self.children.keys())
			if remove:
				for x in lst - set(dircont):
					del self.children[x]
		except:
			self.children = {}

		for name in dircont:
			npats = accept(name, pats)
			if npats and npats[0]:
				accepted = [] in npats[0]

				node = self.make_node([name])

				isdir = os.path.isdir(node.abspath())
				if accepted:
					if isdir:
						if dir:
							yield node
					else:
						if src:
							yield node

				if getattr(node, 'cache_isdir', None) or isdir:
					node.cache_isdir = True
					if maxdepth:
						for k in node.ant_iter(accept=accept, maxdepth=maxdepth - 1, pats=npats, dir=dir, src=src, remove=remove):
							yield k
		raise StopIteration

	def ant_glob(self, *k, **kw):
		"""
		This method is used for finding files across folders. It behaves like ant patterns:

		* ``**/*`` find all files recursively
		* ``**/*.class`` find all files ending by .class
		* ``..`` find files having two dot characters

		For example::

			def configure(cfg):
				cfg.path.ant_glob('**/*.cpp') # find all .cpp files
				cfg.root.ant_glob('etc/*.txt') # using the filesystem root can be slow
				cfg.path.ant_glob('*.cpp', excl=['*.c'], src=True, dir=False)

		For more information see http://ant.apache.org/manual/dirtasks.html

		The nodes that correspond to files and folders that do not exist will be removed. To prevent this
		behaviour, pass 'remove=False'

		:param incl: ant patterns or list of patterns to include
		:type incl: string or list of strings
		:param excl: ant patterns or list of patterns to exclude
		:type excl: string or list of strings
		:param dir: return folders too (False by default)
		:type dir: bool
		:param src: return files (True by default)
		:type src: bool
		:param remove: remove files/folders that do not exist (True by default)
		:type remove: bool
		:param maxdepth: maximum depth of recursion
		:type maxdepth: int
		"""

		src = kw.get('src', True)
		dir = kw.get('dir', False)

		excl = kw.get('excl', exclude_regs)
		incl = k and k[0] or kw.get('incl', '**')

		def to_pat(s):
			lst = Utils.to_list(s)
			ret = []
			for x in lst:
				x = x.replace('\\', '/').replace('//', '/')
				if x.endswith('/'):
					x += '**'
				lst2 = x.split('/')
				accu = []
				for k in lst2:
					if k == '**':
						accu.append(k)
					else:
						k = k.replace('.', '[.]').replace('*','.*').replace('?', '.').replace('+', '\\+')
						k = '^%s$' % k
						try:
							#print "pattern", k
							accu.append(re.compile(k))
						except Exception as e:
							raise Errors.WafError("Invalid pattern: %s" % k, e)
				ret.append(accu)
			return ret

		def filtre(name, nn):
			ret = []
			for lst in nn:
				if not lst:
					pass
				elif lst[0] == '**':
					ret.append(lst)
					if len(lst) > 1:
						if lst[1].match(name):
							ret.append(lst[2:])
					else:
						ret.append([])
				elif lst[0].match(name):
					ret.append(lst[1:])
			return ret

		def accept(name, pats):
			nacc = filtre(name, pats[0])
			nrej = filtre(name, pats[1])
			if [] in nrej:
				nacc = []
			return [nacc, nrej]

		ret = [x for x in self.ant_iter(accept=accept, pats=[to_pat(incl), to_pat(excl)], maxdepth=25, dir=dir, src=src, remove=kw.get('remove', True))]
		if kw.get('flat', False):
			return ' '.join([x.path_from(self) for x in ret])

		return ret

	def find_nodes(self, find_dirs=True, find_files=True, match_fun=lambda x: True):
		# FIXME not part of the stable API: find_node vs find_nodes? consistency with argument names on other functions?
		x = """
		Recursively finds nodes::

			def configure(cnf):
				cnf.find_nodes()

		:param find_dirs: whether to return directories
		:param find_files: whether to return files
		:param match_fun: matching function, taking a node as parameter
		:rtype generator
		:return: a generator that iterates over all the requested files
		"""
		files = self.listdir()
		for f in files:
			node = self.make_node([f])
			if os.path.isdir(node.abspath()):
				if find_dirs and match_fun(node):
					yield node
				gen = node.find_nodes(find_dirs, find_files, match_fun)
				for g in gen:
					yield g
			else:
				if find_files and match_fun(node):
					yield node


	# --------------------------------------------------------------------------------
	# the following methods require the source/build folders (bld.srcnode/bld.bldnode)
	# using a subclass is a possibility, but is that really necessary?
	# --------------------------------------------------------------------------------

	def is_src(self):
		"""
		True if the node is below the source directory
		note: !is_src does not imply is_bld()

		:rtype: bool
		"""
		cur = self
		x = id(self.ctx.srcnode)
		y = id(self.ctx.bldnode)
		while cur.parent:
			if id(cur) == y:
				return False
			if id(cur) == x:
				return True
			cur = cur.parent
		return False

	def is_bld(self):
		"""
		True if the node is below the build directory
		note: !is_bld does not imply is_src

		:rtype: bool
		"""
		cur = self
		y = id(self.ctx.bldnode)
		while cur.parent:
			if id(cur) == y:
				return True
			cur = cur.parent
		return False

	def get_src(self):
		"""
		Return the equivalent src node (or self if not possible)

		:rtype: :py:class:`waflib.Node.Node`
		"""
		cur = self
		x = id(self.ctx.srcnode)
		y = id(self.ctx.bldnode)
		lst = []
		while cur.parent:
			if id(cur) == y:
				lst.reverse()
				return self.ctx.srcnode.make_node(lst)
			if id(cur) == x:
				return self
			lst.append(cur.name)
			cur = cur.parent
		return self

	def get_bld(self):
		"""
		Return the equivalent bld node (or self if not possible)

		:rtype: :py:class:`waflib.Node.Node`
		"""
		cur = self
		x = id(self.ctx.srcnode)
		y = id(self.ctx.bldnode)
		lst = []
		while cur.parent:
			if id(cur) == y:
				return self
			if id(cur) == x:
				lst.reverse()
				return self.ctx.bldnode.make_node(lst)
			lst.append(cur.name)
			cur = cur.parent
		# the file is external to the current project, make a fake root in the current build directory
		lst.reverse()
		if lst and Utils.is_win32 and len(lst[0]) == 2 and lst[0].endswith(':'):
			lst[0] = lst[0][0]
		return self.ctx.bldnode.make_node(['__root__'] + lst)

	def find_resource(self, lst):
		"""
		Try to find a declared build node or a source file

		:param lst: path
		:type lst: string or list of string
		"""
		if isinstance(lst, str):
			lst = [x for x in split_path(lst) if x and x != '.']

		node = self.get_bld().search(lst)
		if not node:
			self = self.get_src()
			node = self.find_node(lst)
		try:
			pat = node.abspath()
			if os.path.isdir(pat):
				return None
		except:
			pass
		return node

	def find_or_declare(self, lst):
		"""
		if 'self' is in build directory, try to return an existing node
		if no node is found, go to the source directory
		try to find an existing node in the source directory
		if no node is found, create it in the build directory

		:param lst: path
		:type lst: string or list of string
		"""
		if isinstance(lst, str):
			lst = [x for x in split_path(lst) if x and x != '.']

		node = self.get_bld().search(lst)
		if node:
			if not os.path.isfile(node.abspath()):
				node.sig = None
				try:
					node.parent.mkdir()
				except:
					pass
			return node
		self = self.get_src()
		node = self.find_node(lst)
		if node:
			if not os.path.isfile(node.abspath()):
				node.sig = None
				try:
					node.parent.mkdir()
				except:
					pass
			return node
		node = self.get_bld().make_node(lst)
		node.parent.mkdir()
		return node

	def find_dir(self, lst):
		"""
		Search for a folder in the filesystem

		:param lst: path
		:type lst: string or list of string
		"""
		if isinstance(lst, str):
			lst = [x for x in split_path(lst) if x and x != '.']

		node = self.find_node(lst)
		try:
			if not os.path.isdir(node.abspath()):
				return None
		except (OSError, AttributeError):
			# the node might be None, and raise an AttributeError
			return None
		return node

	# helpers for building things
	def change_ext(self, ext, ext_in=None):
		"""
		:return: A build node of the same path, but with a different extension
		:rtype: :py:class:`waflib.Node.Node`
		"""
		name = self.name
		if ext_in is None:
			k = name.rfind('.')
			if k >= 0:
				name = name[:k] + ext
			else:
				name = name + ext
		else:
			name = name[:- len(ext_in)] + ext

		return self.parent.find_or_declare([name])

	def nice_path(self, env=None):
		"""
		Return the path seen from the launch directory. It is often used for printing nodes in the console to open
		files easily.

		:param env: unused, left for compatibility with waf 1.5
		"""
		return self.path_from(self.ctx.launch_node())

	def bldpath(self):
		"Path seen from the build directory default/src/foo.cpp"
		return self.path_from(self.ctx.bldnode)

	def srcpath(self):
		"Path seen from the source directory ../src/foo.cpp"
		return self.path_from(self.ctx.srcnode)

	def relpath(self):
		"If a file in the build directory, bldpath, else srcpath"
		cur = self
		x = id(self.ctx.bldnode)
		while cur.parent:
			if id(cur) == x:
				return self.bldpath()
			cur = cur.parent
		return self.srcpath()

	def bld_dir(self):
		"Build path without the file name"
		return self.parent.bldpath()

	def bld_base(self):
		"Build path without the extension: src/dir/foo(.cpp)"
		s = os.path.splitext(self.name)[0]
		return self.bld_dir() + os.sep + s

	def get_bld_sig(self):
		"""
		Node signature, assuming the file is in the build directory
		"""
		try:
			ret = self.ctx.hash_cache[id(self)]
		except KeyError:
			pass
		except AttributeError:
			self.ctx.hash_cache = {}
		else:
			return ret

		if not self.is_bld() or self.ctx.bldnode is self.ctx.srcnode:
			self.sig = Utils.h_file(self.abspath())
		self.ctx.hash_cache[id(self)] = ret = self.sig
		return ret

pickle_lock = Utils.threading.Lock()
"""Lock mandatory for thread-safe node serialization"""

class Nod3(Node):
	"""Mandatory subclass for thread-safe node serialization"""
	pass # do not remove



########NEW FILE########
__FILENAME__ = Options
#!/usr/bin/env python
# encoding: utf-8
# Scott Newton, 2005 (scottn)
# Thomas Nagy, 2006-2010 (ita)

"""
Support for waf command-line options

Provides default command-line options,
as well as custom ones, used by the ``options`` wscript function.

"""

import os, tempfile, optparse, sys, re
from waflib import Logs, Utils, Context

cmds = 'distclean configure build install clean uninstall check dist distcheck'.split()
"""
Constant representing the default waf commands displayed in::

	$ waf --help

"""

options = {}
"""
A dictionary representing the command-line options::

	$ waf --foo=bar

"""

commands = []
"""
List of commands to execute extracted from the command-line. This list is consumed during the execution, see :py:func:`waflib.Scripting.run_commands`.
"""

lockfile = os.environ.get('WAFLOCK', '.lock-waf_%s_build' % sys.platform)
try: cache_global = os.path.abspath(os.environ['WAFCACHE'])
except KeyError: cache_global = ''
platform = Utils.unversioned_sys_platform()


class opt_parser(optparse.OptionParser):
	"""
	Command-line options parser.
	"""
	def __init__(self, ctx):
		optparse.OptionParser.__init__(self, conflict_handler="resolve", version='waf %s (%s)' % (Context.WAFVERSION, Context.WAFREVISION))

		self.formatter.width = Logs.get_term_cols()
		p = self.add_option
		self.ctx = ctx

		jobs = ctx.jobs()
		p('-j', '--jobs',     dest='jobs',    default=jobs, type='int', help='amount of parallel jobs (%r)' % jobs)
		p('-k', '--keep',     dest='keep',    default=0,     action='count', help='keep running happily even if errors are found')
		p('-v', '--verbose',  dest='verbose', default=0,     action='count', help='verbosity level -v -vv or -vvv [default: 0]')
		p('--nocache',        dest='nocache', default=False, action='store_true', help='ignore the WAFCACHE (if set)')
		p('--zones',          dest='zones',   default='',    action='store', help='debugging zones (task_gen, deps, tasks, etc)')

		gr = optparse.OptionGroup(self, 'configure options')
		self.add_option_group(gr)

		gr.add_option('-o', '--out', action='store', default='', help='build dir for the project', dest='out')
		gr.add_option('-t', '--top', action='store', default='', help='src dir for the project', dest='top')

		default_prefix = os.environ.get('PREFIX')
		if not default_prefix:
			if platform == 'win32':
				d = tempfile.gettempdir()
				default_prefix = d[0].upper() + d[1:]
				# win32 preserves the case, but gettempdir does not
			else:
				default_prefix = '/usr/local/'
		gr.add_option('--prefix', dest='prefix', default=default_prefix, help='installation prefix [default: %r]' % default_prefix)
		gr.add_option('--download', dest='download', default=False, action='store_true', help='try to download the tools if missing')


		gr = optparse.OptionGroup(self, 'build and install options')
		self.add_option_group(gr)

		gr.add_option('-p', '--progress', dest='progress_bar', default=0, action='count', help= '-p: progress bar; -pp: ide output')
		gr.add_option('--targets',        dest='targets', default='', action='store', help='task generators, e.g. "target1,target2"')

		gr = optparse.OptionGroup(self, 'step options')
		self.add_option_group(gr)
		gr.add_option('--files',          dest='files', default='', action='store', help='files to process, by regexp, e.g. "*/main.c,*/test/main.o"')

		default_destdir = os.environ.get('DESTDIR', '')
		gr = optparse.OptionGroup(self, 'install/uninstall options')
		self.add_option_group(gr)
		gr.add_option('--destdir', help='installation root [default: %r]' % default_destdir, default=default_destdir, dest='destdir')
		gr.add_option('-f', '--force', dest='force', default=False, action='store_true', help='force file installation')

	def get_usage(self):
		"""
		Return the message to print on ``waf --help``
		"""
		cmds_str = {}
		for cls in Context.classes:
			if not cls.cmd or cls.cmd == 'options':
				continue

			s = cls.__doc__ or ''
			cmds_str[cls.cmd] = s

		if Context.g_module:
			for (k, v) in Context.g_module.__dict__.items():
				if k in ['options', 'init', 'shutdown']:
					continue

				if type(v) is type(Context.create_context):
					if v.__doc__ and not k.startswith('_'):
						cmds_str[k] = v.__doc__

		just = 0
		for k in cmds_str:
			just = max(just, len(k))

		lst = ['  %s: %s' % (k.ljust(just), v) for (k, v) in cmds_str.items()]
		lst.sort()
		ret = '\n'.join(lst)

		return '''waf [commands] [options]

Main commands (example: ./waf build -j4)
%s
''' % ret


class OptionsContext(Context.Context):
	"""
	Collect custom options from wscript files and parses the command line.
	Set the global :py:const:`waflib.Options.commands` and :py:const:`waflib.Options.options` values.
	"""

	cmd = 'options'
	fun = 'options'

	def __init__(self, **kw):
		super(OptionsContext, self).__init__(**kw)

		self.parser = opt_parser(self)
		"""Instance of :py:class:`waflib.Options.opt_parser`"""

		self.option_groups = {}

	def jobs(self):
		"""
		Find the amount of cpu cores to set the default amount of tasks executed in parallel. At
		runtime the options can be obtained from :py:const:`waflib.Options.options` ::

			from waflib.Options import options
			njobs = options.jobs

		:return: the amount of cpu cores
		:rtype: int
		"""
		count = int(os.environ.get('JOBS', 0))
		if count < 1:
			if 'NUMBER_OF_PROCESSORS' in os.environ:
				# on Windows, use the NUMBER_OF_PROCESSORS environment variable
				count = int(os.environ.get('NUMBER_OF_PROCESSORS', 1))
			else:
				# on everything else, first try the POSIX sysconf values
				if hasattr(os, 'sysconf_names'):
					if 'SC_NPROCESSORS_ONLN' in os.sysconf_names:
						count = int(os.sysconf('SC_NPROCESSORS_ONLN'))
					elif 'SC_NPROCESSORS_CONF' in os.sysconf_names:
						count = int(os.sysconf('SC_NPROCESSORS_CONF'))
				if not count and os.name not in ('nt', 'java'):
					try:
						tmp = self.cmd_and_log(['sysctl', '-n', 'hw.ncpu'], quiet=0)
					except Exception:
						pass
					else:
						if re.match('^[0-9]+$', tmp):
							count = int(tmp)
		if count < 1:
			count = 1
		elif count > 1024:
			count = 1024
		return count

	def add_option(self, *k, **kw):
		"""
		Wrapper for optparse.add_option::

			def options(ctx):
				ctx.add_option('-u', '--use', dest='use', default=False, action='store_true',
					help='a boolean option')
		"""
		self.parser.add_option(*k, **kw)

	def add_option_group(self, *k, **kw):
		"""
		Wrapper for optparse.add_option_group::

			def options(ctx):
				ctx.add_option_group('some options')
				gr.add_option('-u', '--use', dest='use', default=False, action='store_true')
		"""
		try:
			gr = self.option_groups[k[0]]
		except:
			gr = self.parser.add_option_group(*k, **kw)
		self.option_groups[k[0]] = gr
		return gr

	def get_option_group(self, opt_str):
		"""
		Wrapper for optparse.get_option_group::

			def options(ctx):
				gr = ctx.get_option_group('configure options')
				gr.add_option('-o', '--out', action='store', default='',
					help='build dir for the project', dest='out')

		"""
		try:
			return self.option_groups[opt_str]
		except KeyError:
			for group in self.parser.option_groups:
				if group.title == opt_str:
					return group
			return None

	def parse_args(self, _args=None):
		"""
		Parse arguments from a list (not bound to the command-line).

		:param _args: arguments
		:type _args: list of strings
		"""
		global options, commands
		(options, leftover_args) = self.parser.parse_args(args=_args)
		commands = leftover_args

		if options.destdir:
			options.destdir = os.path.abspath(os.path.expanduser(options.destdir))

		if options.verbose >= 1:
			self.load('errcheck')

	def execute(self):
		"""
		See :py:func:`waflib.Context.Context.execute`
		"""
		super(OptionsContext, self).execute()
		self.parse_args()


########NEW FILE########
__FILENAME__ = Runner
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2005-2010 (ita)

"""
Runner.py: Task scheduling and execution

"""

import random, atexit
try:
	from queue import Queue
except:
	from Queue import Queue
from waflib import Utils, Task, Errors, Logs

GAP = 10
"""
Wait for free tasks if there are at least ``GAP * njobs`` in queue
"""

class TaskConsumer(Utils.threading.Thread):
	"""
	Task consumers belong to a pool of workers

	They wait for tasks in the queue and then use ``task.process(...)``
	"""
	def __init__(self):
		Utils.threading.Thread.__init__(self)
		self.ready = Queue()
		"""
		Obtain :py:class:`waflib.Task.TaskBase` instances from this queue.
		"""
		self.setDaemon(1)
		self.start()

	def run(self):
		"""
		Loop over the tasks to execute
		"""
		try:
			self.loop()
		except:
			pass

	def loop(self):
		"""
		Obtain tasks from :py:attr:`waflib.Runner.TaskConsumer.ready` and call
		:py:meth:`waflib.Task.TaskBase.process`. If the object is a function, execute it.
		"""
		while 1:
			tsk = self.ready.get()
			if not isinstance(tsk, Task.TaskBase):
				tsk(self)
			else:
				tsk.process()

pool = Queue()
"""
Pool of task consumer objects
"""

def get_pool():
	"""
	Obtain a task consumer from :py:attr:`waflib.Runner.pool`.
	Do not forget to put it back by using :py:func:`waflib.Runner.put_pool`
	and reset properly (original waiting queue).

	:rtype: :py:class:`waflib.Runner.TaskConsumer`
	"""
	try:
		return pool.get(False)
	except:
		return TaskConsumer()

def put_pool(x):
	"""
	Return a task consumer to the thread pool :py:attr:`waflib.Runner.pool`

	:param x: task consumer object
	:type x: :py:class:`waflib.Runner.TaskConsumer`
	"""
	pool.put(x)

def _free_resources():
	global pool
	lst = []
	while pool.qsize():
		lst.append(pool.get())
	for x in lst:
		x.ready.put(None)
	for x in lst:
		x.join()
	pool = None
atexit.register(_free_resources)

class Parallel(object):
	"""
	Schedule the tasks obtained from the build context for execution.
	"""
	def __init__(self, bld, j=2):
		"""
		The initialization requires a build context reference
		for computing the total number of jobs.
		"""

		self.numjobs = j
		"""
		Number of consumers in the pool
		"""

		self.bld = bld
		"""
		Instance of :py:class:`waflib.Build.BuildContext`
		"""

		self.outstanding = []
		"""List of :py:class:`waflib.Task.TaskBase` that may be ready to be executed"""

		self.frozen = []
		"""List of :py:class:`waflib.Task.TaskBase` that cannot be executed immediately"""

		self.out = Queue(0)
		"""List of :py:class:`waflib.Task.TaskBase` returned by the task consumers"""

		self.count = 0
		"""Amount of tasks that may be processed by :py:class:`waflib.Runner.TaskConsumer`"""

		self.processed = 1
		"""Amount of tasks processed"""

		self.stop = False
		"""Error flag to stop the build"""

		self.error = []
		"""Tasks that could not be executed"""

		self.biter = None
		"""Task iterator which must give groups of parallelizable tasks when calling ``next()``"""

		self.dirty = False
		"""Flag to indicate that tasks have been executed, and that the build cache must be saved (call :py:meth:`waflib.Build.BuildContext.store`)"""

	def get_next_task(self):
		"""
		Obtain the next task to execute.

		:rtype: :py:class:`waflib.Task.TaskBase`
		"""
		if not self.outstanding:
			return None
		return self.outstanding.pop(0)

	def postpone(self, tsk):
		"""
		A task cannot be executed at this point, put it in the list :py:attr:`waflib.Runner.Parallel.frozen`.

		:param tsk: task
		:type tsk: :py:class:`waflib.Task.TaskBase`
		"""
		if random.randint(0, 1):
			self.frozen.insert(0, tsk)
		else:
			self.frozen.append(tsk)

	def refill_task_list(self):
		"""
		Put the next group of tasks to execute in :py:attr:`waflib.Runner.Parallel.outstanding`.
		"""
		while self.count > self.numjobs * GAP:
			self.get_out()

		while not self.outstanding:
			if self.count:
				self.get_out()
			elif self.frozen:
				try:
					cond = self.deadlock == self.processed
				except:
					pass
				else:
					if cond:
						msg = 'check the build order for the tasks'
						for tsk in self.frozen:
							if not tsk.run_after:
								msg = 'check the methods runnable_status'
								break
						lst = []
						for tsk in self.frozen:
							lst.append('%s\t-> %r' % (repr(tsk), [id(x) for x in tsk.run_after]))
						raise Errors.WafError('Deadlock detected: %s%s' % (msg, ''.join(lst)))
				self.deadlock = self.processed

			if self.frozen:
				self.outstanding += self.frozen
				self.frozen = []
			elif not self.count:
				self.outstanding.extend(next(self.biter))
				self.total = self.bld.total()
				break

	def add_more_tasks(self, tsk):
		"""
		Tasks may be added dynamically during the build by binding them to the task :py:attr:`waflib.Task.TaskBase.more_tasks`

		:param tsk: task
		:type tsk: :py:attr:`waflib.Task.TaskBase`
		"""
		if getattr(tsk, 'more_tasks', None):
			self.outstanding += tsk.more_tasks
			self.total += len(tsk.more_tasks)

	def get_out(self):
		"""
		Obtain one task returned from the task consumers, and update the task count. Add more tasks if necessary through
		:py:attr:`waflib.Runner.Parallel.add_more_tasks`.

		:rtype: :py:attr:`waflib.Task.TaskBase`
		"""
		tsk = self.out.get()
		if not self.stop:
			self.add_more_tasks(tsk)
		self.count -= 1
		self.dirty = True
		return tsk

	def error_handler(self, tsk):
		"""
		Called when a task cannot be executed. The flag :py:attr:`waflib.Runner.Parallel.stop` is set, unless
		the build is executed with::

			$ waf build -k

		:param tsk: task
		:type tsk: :py:attr:`waflib.Task.TaskBase`
		"""
		if not self.bld.keep:
			self.stop = True
		self.error.append(tsk)

	def add_task(self, tsk):
		"""
		Pass a task to a consumer.

		:param tsk: task
		:type tsk: :py:attr:`waflib.Task.TaskBase`
		"""
		try:
			self.pool
		except AttributeError:
			self.init_task_pool()
		self.ready.put(tsk)

	def init_task_pool(self):
		# lazy creation, and set a common pool for all task consumers
		pool = self.pool = [get_pool() for i in range(self.numjobs)]
		self.ready = Queue(0)
		def setq(consumer):
			consumer.ready = self.ready
		for x in pool:
			x.ready.put(setq)
		return pool

	def free_task_pool(self):
		# return the consumers, setting a different queue for each of them
		def setq(consumer):
			consumer.ready = Queue(0)
			self.out.put(self)
		try:
			pool = self.pool
		except:
			pass
		else:
			for x in pool:
				self.ready.put(setq)
			for x in pool:
				self.get_out()
			for x in pool:
				put_pool(x)
			self.pool = []

	def start(self):
		"""
		Give tasks to :py:class:`waflib.Runner.TaskConsumer` instances until the build finishes or the ``stop`` flag is set.
		If only one job is used, then execute the tasks one by one, without consumers.
		"""

		self.total = self.bld.total()

		while not self.stop:

			self.refill_task_list()

			# consider the next task
			tsk = self.get_next_task()
			if not tsk:
				if self.count:
					# tasks may add new ones after they are run
					continue
				else:
					# no tasks to run, no tasks running, time to exit
					break

			if tsk.hasrun:
				# if the task is marked as "run", just skip it
				self.processed += 1
				continue

			if self.stop: # stop immediately after a failure was detected
				break

			try:
				st = tsk.runnable_status()
			except Exception:
				self.processed += 1
				# TODO waf 1.7 this piece of code should go in the error_handler
				tsk.err_msg = Utils.ex_stack()
				if not self.stop and self.bld.keep:
					tsk.hasrun = Task.SKIPPED
					if self.bld.keep == 1:
						# if -k stop at the first exception, if -kk try to go as far as possible
						if Logs.verbose > 1 or not self.error:
							self.error.append(tsk)
						self.stop = True
					else:
						if Logs.verbose > 1:
							self.error.append(tsk)
					continue
				tsk.hasrun = Task.EXCEPTION
				self.error_handler(tsk)
				continue

			if st == Task.ASK_LATER:
				self.postpone(tsk)
			elif st == Task.SKIP_ME:
				self.processed += 1
				tsk.hasrun = Task.SKIPPED
				self.add_more_tasks(tsk)
			else:
				# run me: put the task in ready queue
				tsk.position = (self.processed, self.total)
				self.count += 1
				tsk.master = self
				self.processed += 1

				if self.numjobs == 1:
					tsk.process()
				else:
					self.add_task(tsk)

		# self.count represents the tasks that have been made available to the consumer threads
		# collect all the tasks after an error else the message may be incomplete
		while self.error and self.count:
			self.get_out()

		#print loop
		assert (self.count == 0 or self.stop)

		# free the task pool, if any
		self.free_task_pool()


########NEW FILE########
__FILENAME__ = Scripting
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2005-2010 (ita)

"Module called for configuring, compiling and installing targets"

import os, shutil, traceback, errno, sys, stat
from waflib import Utils, Configure, Logs, Options, ConfigSet, Context, Errors, Build, Node

build_dir_override = None

no_climb_commands = ['configure']

default_cmd = "build"

def waf_entry_point(current_directory, version, wafdir):
	"""
	This is the main entry point, all Waf execution starts here.

	:param current_directory: absolute path representing the current directory
	:type current_directory: string
	:param version: version number
	:type version: string
	:param wafdir: absolute path representing the directory of the waf library
	:type wafdir: string
	"""

	Logs.init_log()

	if Context.WAFVERSION != version:
		Logs.error('Waf script %r and library %r do not match (directory %r)' % (version, Context.WAFVERSION, wafdir))
		sys.exit(1)

	if '--version' in sys.argv:
		Context.run_dir = current_directory
		ctx = Context.create_context('options')
		ctx.curdir = current_directory
		ctx.parse_args()
		sys.exit(0)

	Context.waf_dir = wafdir
	Context.launch_dir = current_directory

	# if 'configure' is in the commands, do not search any further
	no_climb = os.environ.get('NOCLIMB', None)
	if not no_climb:
		for k in no_climb_commands:
			if k in sys.argv:
				no_climb = True
				break

	# try to find a lock file (if the project was configured)
	# at the same time, store the first wscript file seen
	cur = current_directory
	while cur:
		lst = os.listdir(cur)
		if Options.lockfile in lst:
			env = ConfigSet.ConfigSet()
			try:
				env.load(os.path.join(cur, Options.lockfile))
				ino = os.stat(cur)[stat.ST_INO]
			except Exception:
				pass
			else:
				# check if the folder was not moved
				for x in [env.run_dir, env.top_dir, env.out_dir]:
					if Utils.is_win32:
						if cur == x:
							load = True
							break
					else:
						# if the filesystem features symlinks, compare the inode numbers
						try:
							ino2 = os.stat(x)[stat.ST_INO]
						except:
							pass
						else:
							if ino == ino2:
								load = True
								break
				else:
					Logs.warn('invalid lock file in %s' % cur)
					load = False

				if load:
					Context.run_dir = env.run_dir
					Context.top_dir = env.top_dir
					Context.out_dir = env.out_dir
					break

		if not Context.run_dir:
			if Context.WSCRIPT_FILE in lst:
				Context.run_dir = cur

		next = os.path.dirname(cur)
		if next == cur:
			break
		cur = next

		if no_climb:
			break

	if not Context.run_dir:
		if '-h' in sys.argv or '--help' in sys.argv:
			Logs.warn('No wscript file found: the help message may be incomplete')
			Context.run_dir = current_directory
			ctx = Context.create_context('options')
			ctx.curdir = current_directory
			ctx.parse_args()
			sys.exit(0)
		Logs.error('Waf: Run from a directory containing a file named %r' % Context.WSCRIPT_FILE)
		sys.exit(1)

	try:
		os.chdir(Context.run_dir)
	except OSError:
		Logs.error('Waf: The folder %r is unreadable' % Context.run_dir)
		sys.exit(1)

	try:
		set_main_module(Context.run_dir + os.sep + Context.WSCRIPT_FILE)
	except Errors.WafError as e:
		Logs.pprint('RED', e.verbose_msg)
		Logs.error(str(e))
		sys.exit(1)
	except Exception as e:
		Logs.error('Waf: The wscript in %r is unreadable' % Context.run_dir, e)
		traceback.print_exc(file=sys.stdout)
		sys.exit(2)

	"""
	import cProfile, pstats
	cProfile.runctx("import Scripting; Scripting.run_commands()", {}, {}, 'profi.txt')
	p = pstats.Stats('profi.txt')
	p.sort_stats('time').print_stats(25)
	"""
	try:
		run_commands()
	except Errors.WafError as e:
		if Logs.verbose > 1:
			Logs.pprint('RED', e.verbose_msg)
		Logs.error(e.msg)
		sys.exit(1)
	except Exception as e:
		traceback.print_exc(file=sys.stdout)
		sys.exit(2)
	except KeyboardInterrupt:
		Logs.pprint('RED', 'Interrupted')
		sys.exit(68)
	#"""

def set_main_module(file_path):
	"""
	Read the main wscript file into :py:const:`waflib.Context.Context.g_module` and
	bind default functions such as ``init``, ``dist``, ``distclean`` if not defined.
	Called by :py:func:`waflib.Scripting.waf_entry_point` during the initialization.

	:param file_path: absolute path representing the top-level wscript file
	:type file_path: string
	"""
	Context.g_module = Context.load_module(file_path)
	Context.g_module.root_path = file_path

	# note: to register the module globally, use the following:
	# sys.modules['wscript_main'] = g_module

	def set_def(obj):
		name = obj.__name__
		if not name in Context.g_module.__dict__:
			setattr(Context.g_module, name, obj)
	for k in [update, dist, distclean, distcheck, update]:
		set_def(k)
	# add dummy init and shutdown functions if they're not defined
	if not 'init' in Context.g_module.__dict__:
		Context.g_module.init = Utils.nada
	if not 'shutdown' in Context.g_module.__dict__:
		Context.g_module.shutdown = Utils.nada
	if not 'options' in Context.g_module.__dict__:
		Context.g_module.options = Utils.nada

def parse_options():
	"""
	Parse the command-line options and initialize the logging system.
	Called by :py:func:`waflib.Scripting.waf_entry_point` during the initialization.
	"""
	Context.create_context('options').execute()

	if not Options.commands:
		Options.commands = [default_cmd]
	Options.commands = [x for x in Options.commands if x != 'options'] # issue 1076

	# process some internal Waf options
	Logs.verbose = Options.options.verbose
	Logs.init_log()

	if Options.options.zones:
		Logs.zones = Options.options.zones.split(',')
		if not Logs.verbose:
			Logs.verbose = 1
	elif Logs.verbose > 0:
		Logs.zones = ['runner']

	if Logs.verbose > 2:
		Logs.zones = ['*']

def run_command(cmd_name):
	"""
	Execute a single command. Called by :py:func:`waflib.Scripting.run_commands`.

	:param cmd_name: command to execute, like ``build``
	:type cmd_name: string
	"""
	ctx = Context.create_context(cmd_name)
	ctx.options = Options.options # provided for convenience
	ctx.cmd = cmd_name
	ctx.execute()
	return ctx

def run_commands():
	"""
	Execute the commands that were given on the command-line, and the other options
	Called by :py:func:`waflib.Scripting.waf_entry_point` during the initialization, and executed
	after :py:func:`waflib.Scripting.parse_options`.
	"""
	parse_options()
	run_command('init')
	while Options.commands:
		cmd_name = Options.commands.pop(0)

		timer = Utils.Timer()
		run_command(cmd_name)
		if not Options.options.progress_bar:
			elapsed = ' (%s)' % str(timer)
			Logs.info('%r finished successfully%s' % (cmd_name, elapsed))
	run_command('shutdown')

###########################################################################################

def _can_distclean(name):
	# WARNING: this method may disappear anytime
	for k in '.o .moc .exe'.split():
		if name.endswith(k):
			return True
	return False

def distclean_dir(dirname):
	"""
	Distclean function called in the particular case when::

		top == out

	:param dirname: absolute path of the folder to clean
	:type dirname: string
	"""
	for (root, dirs, files) in os.walk(dirname):
		for f in files:
			if _can_distclean(f):
				fname = root + os.sep + f
				try:
					os.unlink(fname)
				except:
					Logs.warn('could not remove %r' % fname)

	for x in [Context.DBFILE, 'config.log']:
		try:
			os.unlink(x)
		except:
			pass

	try:
		shutil.rmtree('c4che')
	except:
		pass

def distclean(ctx):
	'''removes the build directory'''
	lst = os.listdir('.')
	for f in lst:
		if f == Options.lockfile:
			try:
				proj = ConfigSet.ConfigSet(f)
			except:
				Logs.warn('could not read %r' % f)
				continue

			if proj['out_dir'] != proj['top_dir']:
				try:
					shutil.rmtree(proj['out_dir'])
				except IOError:
					pass
				except OSError as e:
					if e.errno != errno.ENOENT:
						Logs.warn('project %r cannot be removed' % proj[Context.OUT])
			else:
				distclean_dir(proj['out_dir'])

			for k in (proj['out_dir'], proj['top_dir'], proj['run_dir']):
				try:
					os.remove(os.path.join(k, Options.lockfile))
				except OSError as e:
					if e.errno != errno.ENOENT:
						Logs.warn('file %r cannot be removed' % f)

		# remove the local waf cache
		if f.startswith('.waf') and not Options.commands:
			shutil.rmtree(f, ignore_errors=True)

class Dist(Context.Context):
	"""
	Create an archive containing the project source code::

		$ waf dist
	"""
	cmd = 'dist'
	fun = 'dist'
	algo = 'tar.bz2'
	ext_algo = {}

	def execute(self):
		"""
		See :py:func:`waflib.Context.Context.execute`
		"""
		self.recurse([os.path.dirname(Context.g_module.root_path)])
		self.archive()

	def archive(self):
		"""
		Create the archive.
		"""
		import tarfile

		arch_name = self.get_arch_name()

		try:
			self.base_path
		except:
			self.base_path = self.path

		node = self.base_path.make_node(arch_name)
		try:
			node.delete()
		except:
			pass

		files = self.get_files()

		if self.algo.startswith('tar.'):
			tar = tarfile.open(arch_name, 'w:' + self.algo.replace('tar.', ''))

			for x in files:
				self.add_tar_file(x, tar)
			tar.close()
		elif self.algo == 'zip':
			import zipfile
			zip = zipfile.ZipFile(arch_name, 'w', compression=zipfile.ZIP_DEFLATED)

			for x in files:
				archive_name = self.get_base_name() + '/' + x.path_from(self.base_path)
				zip.write(x.abspath(), archive_name, zipfile.ZIP_DEFLATED)
			zip.close()
		else:
			self.fatal('Valid algo types are tar.bz2, tar.gz or zip')

		try:
			from hashlib import sha1 as sha
		except ImportError:
			from sha import sha
		try:
			digest = " (sha=%r)" % sha(node.read()).hexdigest()
		except:
			digest = ''

		Logs.info('New archive created: %s%s' % (self.arch_name, digest))

	def get_tar_path(self, node):
		"""
		return the path to use for a node in the tar archive, the purpose of this
		is to let subclases resolve symbolic links or to change file names
		"""
		return node.abspath()

	def add_tar_file(self, x, tar):
		"""
		Add a file to the tar archive. Transform symlinks into files if the files lie out of the project tree.
		"""
		p = self.get_tar_path(x)
		tinfo = tar.gettarinfo(name=p, arcname=self.get_tar_prefix() + '/' + x.path_from(self.base_path))
		tinfo.uid   = 0
		tinfo.gid   = 0
		tinfo.uname = 'root'
		tinfo.gname = 'root'

		fu = None
		try:
			fu = open(p, 'rb')
			tar.addfile(tinfo, fileobj=fu)
		finally:
			if fu:
				fu.close()

	def get_tar_prefix(self):
		try:
			return self.tar_prefix
		except:
			return self.get_base_name()

	def get_arch_name(self):
		"""
		Return the name of the archive to create. Change the default value by setting *arch_name*::

			def dist(ctx):
				ctx.arch_name = 'ctx.tar.bz2'

		:rtype: string
		"""
		try:
			self.arch_name
		except:
			self.arch_name = self.get_base_name() + '.' + self.ext_algo.get(self.algo, self.algo)
		return self.arch_name

	def get_base_name(self):
		"""
		Return the default name of the main directory in the archive, which is set to *appname-version*.
		Set the attribute *base_name* to change the default value::

			def dist(ctx):
				ctx.base_name = 'files'

		:rtype: string
		"""
		try:
			self.base_name
		except:
			appname = getattr(Context.g_module, Context.APPNAME, 'noname')
			version = getattr(Context.g_module, Context.VERSION, '1.0')
			self.base_name = appname + '-' + version
		return self.base_name

	def get_excl(self):
		"""
		Return the patterns to exclude for finding the files in the top-level directory. Set the attribute *excl*
		to change the default value::

			def dist(ctx):
				ctx.excl = 'build **/*.o **/*.class'

		:rtype: string
		"""
		try:
			return self.excl
		except:
			self.excl = Node.exclude_regs + ' **/waf-1.6.* **/.waf-1.6* **/waf3-1.6.* **/.waf3-1.6* **/*~ **/*.rej **/*.orig **/*.pyc **/*.pyo **/*.bak **/*.swp **/.lock-w*'
			nd = self.root.find_node(Context.out_dir)
			if nd:
				self.excl += ' ' + nd.path_from(self.base_path)
			return self.excl

	def get_files(self):
		"""
		The files to package are searched automatically by :py:func:`waflib.Node.Node.ant_glob`. Set
		*files* to prevent this behaviour::

			def dist(ctx):
				ctx.files = ctx.path.find_node('wscript')

		The files are searched from the directory 'base_path', to change it, set::

			def dist(ctx):
				ctx.base_path = path

		:rtype: list of :py:class:`waflib.Node.Node`
		"""
		try:
			files = self.files
		except:
			files = self.base_path.ant_glob('**/*', excl=self.get_excl())
		return files


def dist(ctx):
	'''makes a tarball for redistributing the sources'''
	pass

class DistCheck(Dist):
	"""
	Create an archive of the project, and try to build the project in a temporary directory::

		$ waf distcheck
	"""

	fun = 'distcheck'
	cmd = 'distcheck'

	def execute(self):
		"""
		See :py:func:`waflib.Context.Context.execute`
		"""
		self.recurse([os.path.dirname(Context.g_module.root_path)])
		self.archive()
		self.check()

	def check(self):
		"""
		Create the archive, uncompress it and try to build the project
		"""
		import tempfile, tarfile

		t = None
		try:
			t = tarfile.open(self.get_arch_name())
			for x in t:
				t.extract(x)
		finally:
			if t:
				t.close()

		instdir = tempfile.mkdtemp('.inst', self.get_base_name())
		ret = Utils.subprocess.Popen([sys.argv[0], 'configure', 'install', 'uninstall', '--destdir=' + instdir], cwd=self.get_base_name()).wait()
		if ret:
			raise Errors.WafError('distcheck failed with code %i' % ret)

		if os.path.exists(instdir):
			raise Errors.WafError('distcheck succeeded, but files were left in %s' % instdir)

		shutil.rmtree(self.get_base_name())


def distcheck(ctx):
	'''checks if the project compiles (tarball from 'dist')'''
	pass

def update(ctx):
	'''updates the plugins from the *waflib/extras* directory'''
	lst = Options.options.files.split(',')
	if not lst:
		lst = [x for x in Utils.listdir(Context.waf_dir + '/waflib/extras') if x.endswith('.py')]
	for x in lst:
		tool = x.replace('.py', '')
		try:
			Configure.download_tool(tool, force=True, ctx=ctx)
		except Errors.WafError:
			Logs.error('Could not find the tool %s in the remote repository' % x)

def autoconfigure(execute_method):
	"""
	Decorator used to set the commands that can be configured automatically
	"""
	def execute(self):
		if not Configure.autoconfig:
			return execute_method(self)

		env = ConfigSet.ConfigSet()
		do_config = False
		try:
			env.load(os.path.join(Context.top_dir, Options.lockfile))
		except Exception:
			Logs.warn('Configuring the project')
			do_config = True
		else:
			if env.run_dir != Context.run_dir:
				do_config = True
			else:
				h = 0
				for f in env['files']:
					h = hash((h, Utils.readf(f, 'rb')))
				do_config = h != env.hash

		if do_config:
			Options.commands.insert(0, self.cmd)
			Options.commands.insert(0, 'configure')
			return

		return execute_method(self)
	return execute
Build.BuildContext.execute = autoconfigure(Build.BuildContext.execute)


########NEW FILE########
__FILENAME__ = Task
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2005-2010 (ita)

"""
Tasks represent atomic operations such as processes.
"""

import os, shutil, re, tempfile
from waflib import Utils, Logs, Errors

# task states
NOT_RUN = 0
"""The task was not executed yet"""

MISSING = 1
"""The task has been executed but the files have not been created"""

CRASHED = 2
"""The task execution returned a non-zero exit status"""

EXCEPTION = 3
"""An exception occured in the task execution"""

SKIPPED = 8
"""The task did not have to be executed"""

SUCCESS = 9
"""The task was successfully executed"""

ASK_LATER = -1
"""The task is not ready to be executed"""

SKIP_ME = -2
"""The task does not need to be executed"""

RUN_ME = -3
"""The task must be executed"""

COMPILE_TEMPLATE_SHELL = '''
def f(tsk):
	env = tsk.env
	gen = tsk.generator
	bld = gen.bld
	wd = getattr(tsk, 'cwd', None)
	p = env.get_flat
	tsk.last_cmd = cmd = \'\'\' %s \'\'\' % s
	return tsk.exec_command(cmd, cwd=wd, env=env.env or None)
'''

COMPILE_TEMPLATE_NOSHELL = '''
def f(tsk):
	env = tsk.env
	gen = tsk.generator
	bld = gen.bld
	wd = getattr(tsk, 'cwd', None)
	def to_list(xx):
		if isinstance(xx, str): return [xx]
		return xx
	tsk.last_cmd = lst = []
	%s
	lst = [x for x in lst if x]
	return tsk.exec_command(lst, cwd=wd, env=env.env or None)
'''

def cache_outputs(cls):
	"""
	Task class decorator applied to all task classes by default unless they define the attribute 'nocache'::

		from waflib import Task
		class foo(Task.Task):
			nocache = True

	If bld.cache_global is defined and if the task instances produces output nodes,
	the files will be copied into a folder in the cache directory

	The files may also be retrieved from that folder, if it exists
	"""
	m1 = cls.run
	def run(self):
		bld = self.generator.bld
		if bld.cache_global and not bld.nocache:
			if self.can_retrieve_cache():
				return 0
		return m1(self)
	cls.run = run

	m2 = cls.post_run
	def post_run(self):
		bld = self.generator.bld
		ret = m2(self)
		if bld.cache_global and not bld.nocache:
			self.put_files_cache()
		return ret
	cls.post_run = post_run

	return cls


classes = {}
"class tasks created by user scripts or Waf tools are kept in this dict name -> class object"

class store_task_type(type):
	"""
	Metaclass: store the task types into :py:const:`waflib.Task.classes`.
	The attribute 'run_str' will be processed to compute a method 'run' on the task class
	The decorator :py:func:`waflib.Task.cache_outputs` is also applied to the class
	"""
	def __init__(cls, name, bases, dict):
		super(store_task_type, cls).__init__(name, bases, dict)
		name = cls.__name__

		if name.endswith('_task'):
			name = name.replace('_task', '')
		if name != 'evil' and name != 'TaskBase':
			global classes

			if getattr(cls, 'run_str', None):
				# if a string is provided, convert it to a method
				(f, dvars) = compile_fun(cls.run_str, cls.shell)
				cls.hcode = cls.run_str
				cls.run_str = None
				cls.run = f
				cls.vars = list(set(cls.vars + dvars))
				cls.vars.sort()
			elif getattr(cls, 'run', None) and not 'hcode' in cls.__dict__:
				# getattr(cls, 'hcode') would look in the upper classes
				cls.hcode = Utils.h_fun(cls.run)

			if not getattr(cls, 'nocache', None):
				cls = cache_outputs(cls)

			classes[name] = cls

evil = store_task_type('evil', (object,), {})
"Base class provided to avoid writing a metaclass, so the code can run in python 2.6 and 3.x unmodified"

class TaskBase(evil):
	"""
	Base class for all Waf tasks, which should be seen as an interface.
	For illustration purposes, instances of this class will execute the attribute
	'fun' in :py:meth:`waflib.Task.TaskBase.run`. When in doubt, create
	subclasses of :py:class:`waflib.Task.Task` instead.

	Subclasses should override these methods:

	#. __str__: string to display to the user
	#. runnable_status: ask the task if it should be run, skipped, or if we have to ask later
	#. run: let threads execute the task
	#. post_run: let threads update the data regarding the task (cache)
	"""

	color = 'GREEN'
	"""Color for the console display, see :py:const:`waflib.Logs.colors_lst`"""

	ext_in = []
	"""File extensions that objects of this task class might use"""

	ext_out = []
	"""File extensions that objects of this task class might create"""

	before = []
	"""List of task class names to execute before instances of this class"""

	after = []
	"""List of task class names to execute after instances of this class"""

	hcode = ''
	"""String representing an additional hash for the class representation"""

	def __init__(self, *k, **kw):
		"""
		The base task class requires a task generator, which will be itself if missing
		"""
		self.hasrun = NOT_RUN
		try:
			self.generator = kw['generator']
		except KeyError:
			self.generator = self

	def __repr__(self):
		"for debugging purposes"
		return '\n\t{task %r: %s %s}' % (self.__class__.__name__, id(self), str(getattr(self, 'fun', '')))

	def __str__(self):
		"string to display to the user"
		if hasattr(self, 'fun'):
			return 'executing: %s\n' % self.fun.__name__
		return self.__class__.__name__ + '\n'

	def __hash__(self):
		"Very fast hashing scheme but not persistent (replace/implement in subclasses and see :py:meth:`waflib.Task.Task.uid`)"
		return id(self)

	def exec_command(self, cmd, **kw):
		"""
		Wrapper for :py:meth:`waflib.Context.Context.exec_command` which sets a current working directory to ``build.variant_dir``

		:return: the return code
		:rtype: int
		"""
		bld = self.generator.bld
		try:
			if not kw.get('cwd', None):
				kw['cwd'] = bld.cwd
		except AttributeError:
			bld.cwd = kw['cwd'] = bld.variant_dir
		return bld.exec_command(cmd, **kw)

	def runnable_status(self):
		"""
		State of the task

		:return: a task state in :py:const:`waflib.Task.RUN_ME`, :py:const:`waflib.Task.SKIP_ME` or :py:const:`waflib.Task.ASK_LATER`.
		:rtype: int
		"""
		return RUN_ME

	def process(self):
		"""
		Assume that the task has had a new attribute ``master`` which is an instance of :py:class:`waflib.Runner.Parallel`.
		Execute the task and then put it back in the queue :py:attr:`waflib.Runner.Parallel.out` (may be replaced by subclassing).
		"""
		m = self.master
		if m.stop:
			m.out.put(self)
			return

		# remove the task signature immediately before it is executed
		# in case of failure the task will be executed again
		try:
			del self.generator.bld.task_sigs[self.uid()]
		except:
			pass

		try:
			self.generator.bld.returned_tasks.append(self)
			self.log_display(self.generator.bld)
			ret = self.run()
		except Exception:
			self.err_msg = Utils.ex_stack()
			self.hasrun = EXCEPTION

			# TODO cleanup
			m.error_handler(self)
			m.out.put(self)
			return

		if ret:
			self.err_code = ret
			self.hasrun = CRASHED
		else:
			try:
				self.post_run()
			except Errors.WafError:
				pass
			except Exception:
				self.err_msg = Utils.ex_stack()
				self.hasrun = EXCEPTION
			else:
				self.hasrun = SUCCESS
		if self.hasrun != SUCCESS:
			m.error_handler(self)

		m.out.put(self)

	def run(self):
		"""
		Called by threads to execute the tasks. The default is empty and meant to be overridden in subclasses.
		It is a bad idea to create nodes in this method (so, no node.ant_glob)

		:rtype: int
		"""
		if hasattr(self, 'fun'):
			return self.fun(self)
		return 0

	def post_run(self):
		"Update the cache files (executed by threads). Override in subclasses."
		pass

	def log_display(self, bld):
		"Write the execution status on the context logger"
		bld.to_log(self.display())

	def display(self):
		"""
		Return an execution status for the console, the progress bar, or the IDE output.

		:rtype: string
		"""
		col1 = Logs.colors(self.color)
		col2 = Logs.colors.NORMAL
		master = self.master

		def cur():
			# the current task position, computed as late as possible
			tmp = -1
			if hasattr(master, 'ready'):
				tmp -= master.ready.qsize()
			return master.processed + tmp

		if self.generator.bld.progress_bar == 1:
			return self.generator.bld.progress_line(cur(), master.total, col1, col2)

		if self.generator.bld.progress_bar == 2:
			ela = str(self.generator.bld.timer)
			try:
				ins  = ','.join([n.name for n in self.inputs])
			except AttributeError:
				ins = ''
			try:
				outs = ','.join([n.name for n in self.outputs])
			except AttributeError:
				outs = ''
			return '|Total %s|Current %s|Inputs %s|Outputs %s|Time %s|\n' % (master.total, cur(), ins, outs, ela)

		s = str(self)
		if not s:
			return None

		total = master.total
		n = len(str(total))
		fs = '[%%%dd/%%%dd] %%s%%s%%s' % (n, n)
		return fs % (cur(), total, col1, s, col2)

	def attr(self, att, default=None):
		"""
		Retrieve an attribute from the instance or from the class.

		:param att: variable name
		:type att: string
		:param default: default value
		"""
		ret = getattr(self, att, self)
		if ret is self: return getattr(self.__class__, att, default)
		return ret

	def hash_constraints(self):
		"""
		Identify a task type for all the constraints relevant for the scheduler: precedence, file production

		:return: a hash value
		:rtype: string
		"""
		cls = self.__class__
		tup = (str(cls.before), str(cls.after), str(cls.ext_in), str(cls.ext_out), cls.__name__, cls.hcode)
		h = hash(tup)
		return h

	def format_error(self):
		"""
		Error message to display to the user when a build fails

		:rtype: string
		"""
		msg = getattr(self, 'last_cmd', '')
		name = getattr(self.generator, 'name', '')
		if getattr(self, "err_msg", None):
			return self.err_msg
		elif not self.hasrun:
			return 'task in %r was not executed for some reason: %r' % (name, self)
		elif self.hasrun == CRASHED:
			try:
				return ' -> task in %r failed (exit status %r): %r\n%r' % (name, self.err_code, self, msg)
			except AttributeError:
				return ' -> task in %r failed: %r\n%r' % (name, self, msg)
		elif self.hasrun == MISSING:
			return ' -> missing files in %r: %r\n%r' % (name, self, msg)
		else:
			return 'invalid status for task in %r: %r' % (name, self.hasrun)

	def colon(self, var1, var2):
		"""
		private function for the moment

		used for scriptlet expressions such as ${FOO_ST:FOO}, for example, if
		env.FOO_ST = ['-a', '-b']
		env.FOO    = ['1', '2']
		then the result will be ['-a', '-b', '1', '-a', '-b', '2']
		"""
		tmp = self.env[var1]
		if isinstance(var2, str):
			it = self.env[var2]
		else:
			it = var2
		if isinstance(tmp, str):
			return [tmp % x for x in it]
		else:
			if Logs.verbose and not tmp and it:
				Logs.warn('Missing env variable %r for task %r (generator %r)' % (var1, self, self.generator))
			lst = []
			for y in it:
				lst.extend(tmp)
				lst.append(y)
			return lst

class Task(TaskBase):
	"""
	This class deals with the filesystem (:py:class:`waflib.Node.Node`). The method :py:class:`waflib.Task.Task.runnable_status`
	uses a hash value (from :py:class:`waflib.Task.Task.signature`) which is persistent from build to build. When the value changes,
	the task has to be executed. The method :py:class:`waflib.Task.Task.post_run` will assign the task signature to the output
	nodes (if present).
	"""
	vars = []
	"""Variables to depend on (class attribute used for :py:meth:`waflib.Task.Task.sig_vars`)"""

	shell = False
	"""Execute the command with the shell (class attribute)"""

	def __init__(self, *k, **kw):
		TaskBase.__init__(self, *k, **kw)

		self.env = kw['env']
		"""ConfigSet object (make sure to provide one)"""

		self.inputs  = []
		"""List of input nodes, which represent the files used by the task instance"""

		self.outputs = []
		"""List of output nodes, which represent the files created by the task instance"""

		self.dep_nodes = []
		"""List of additional nodes to depend on"""

		self.run_after = set([])
		"""Set of tasks that must be executed before this one"""

		# Additionally, you may define the following
		#self.dep_vars  = 'PREFIX DATADIR'

	def __str__(self):
		"string to display to the user"
		env = self.env
		src_str = ' '.join([a.nice_path(env) for a in self.inputs])
		tgt_str = ' '.join([a.nice_path(env) for a in self.outputs])
		if self.outputs: sep = ' -> '
		else: sep = ''
		return '%s: %s%s%s\n' % (self.__class__.__name__.replace('_task', ''), src_str, sep, tgt_str)

	def __repr__(self):
		"for debugging purposes"
		return "".join(['\n\t{task %r: ' % id(self), self.__class__.__name__, " ", ",".join([x.name for x in self.inputs]), " -> ", ",".join([x.name for x in self.outputs]), '}'])

	def uid(self):
		"""
		Return an identifier used to determine if tasks are up-to-date. Since the
		identifier will be stored between executions, it must be:

			- unique: no two tasks return the same value (for a given build context)
			- the same for a given task instance

		By default, the node paths, the class name, and the function are used
		as inputs to compute a hash.

		The pointer to the object (python built-in 'id') will change between build executions,
		and must be avoided in such hashes.

		:return: hash value
		:rtype: string
		"""
		try:
			return self.uid_
		except AttributeError:
			# this is not a real hot zone, but we want to avoid surprizes here
			m = Utils.md5()
			up = m.update
			up(self.__class__.__name__.encode())
			for x in self.inputs + self.outputs:
				up(x.abspath().encode())
			self.uid_ = m.digest()
			return self.uid_

	def set_inputs(self, inp):
		"""
		Append the nodes to the *inputs*

		:param inp: input nodes
		:type inp: node or list of nodes
		"""
		if isinstance(inp, list): self.inputs += inp
		else: self.inputs.append(inp)

	def set_outputs(self, out):
		"""
		Append the nodes to the *outputs*

		:param out: output nodes
		:type out: node or list of nodes
		"""
		if isinstance(out, list): self.outputs += out
		else: self.outputs.append(out)

	def set_run_after(self, task):
		"""
		Run this task only after *task*. Affect :py:meth:`waflib.Task.runnable_status`

		:param task: task
		:type task: :py:class:`waflib.Task.Task`
		"""
		# TODO: handle lists too?
		assert isinstance(task, TaskBase)
		self.run_after.add(task)

	def signature(self):
		"""
		Task signatures are stored between build executions, they are use to track the changes
		made to the input nodes (not to the outputs!). The signature hashes data from various sources:

		* explicit dependencies: files listed in the inputs (list of node objects) :py:meth:`waflib.Task.Task.sig_explicit_deps`
		* implicit dependencies: list of nodes returned by scanner methods (when present) :py:meth:`waflib.Task.Task.sig_implicit_deps`
		* hashed data: variables/values read from task.__class__.vars/task.env :py:meth:`waflib.Task.Task.sig_vars`

		If the signature is expected to give a different result, clear the cache kept in ``self.cache_sig``::

			from waflib import Task
			class cls(Task.Task):
				def signature(self):
					sig = super(Task.Task, self).signature()
					delattr(self, 'cache_sig')
					return super(Task.Task, self).signature()
		"""
		try: return self.cache_sig
		except AttributeError: pass

		self.m = Utils.md5()
		self.m.update(self.hcode.encode())

		# explicit deps
		self.sig_explicit_deps()

		# env vars
		self.sig_vars()

		# implicit deps / scanner results
		if self.scan:
			try:
				self.sig_implicit_deps()
			except Errors.TaskRescan:
				return self.signature()

		ret = self.cache_sig = self.m.digest()
		return ret

	def runnable_status(self):
		"""
		Override :py:meth:`waflib.Task.TaskBase.runnable_status` to determine if the task is ready
		to be run (:py:attr:`waflib.Task.Task.run_after`)
		"""
		#return 0 # benchmarking

		for t in self.run_after:
			if not t.hasrun:
				return ASK_LATER

		bld = self.generator.bld

		# first compute the signature
		try:
			new_sig = self.signature()
		except Errors.TaskNotReady:
			return ASK_LATER

		# compare the signature to a signature computed previously
		key = self.uid()
		try:
			prev_sig = bld.task_sigs[key]
		except KeyError:
			Logs.debug("task: task %r must run as it was never run before or the task code changed" % self)
			return RUN_ME

		# compare the signatures of the outputs
		for node in self.outputs:
			try:
				if node.sig != new_sig:
					return RUN_ME
			except AttributeError:
				Logs.debug("task: task %r must run as the output nodes do not exist" % self)
				return RUN_ME

		if new_sig != prev_sig:
			return RUN_ME
		return SKIP_ME

	def post_run(self):
		"""
		Called after successful execution to update the cache data :py:class:`waflib.Node.Node` sigs
		and :py:attr:`waflib.Build.BuildContext.task_sigs`.

		The node signature is obtained from the task signature, but the output nodes may also get the signature
		of their contents. See the class decorator :py:func:`waflib.Task.update_outputs` if you need this behaviour.
		"""
		bld = self.generator.bld
		sig = self.signature()

		for node in self.outputs:
			# check if the node exists ..
			try:
				os.stat(node.abspath())
			except OSError:
				self.hasrun = MISSING
				self.err_msg = '-> missing file: %r' % node.abspath()
				raise Errors.WafError(self.err_msg)

			# important, store the signature for the next run
			node.sig = sig

		bld.task_sigs[self.uid()] = self.cache_sig

	def sig_explicit_deps(self):
		"""
		Used by :py:meth:`waflib.Task.Task.signature`, hash :py:attr:`waflib.Task.Task.inputs`
		and :py:attr:`waflib.Task.Task.dep_nodes` signatures.

		:rtype: hash value
		"""
		bld = self.generator.bld
		upd = self.m.update

		# the inputs
		for x in self.inputs + self.dep_nodes:
			try:
				upd(x.get_bld_sig())
			except (AttributeError, TypeError):
				raise Errors.WafError('Missing node signature for %r (required by %r)' % (x, self))

		# manual dependencies, they can slow down the builds
		if bld.deps_man:
			additional_deps = bld.deps_man
			for x in self.inputs + self.outputs:
				try:
					d = additional_deps[id(x)]
				except KeyError:
					continue

				for v in d:
					if isinstance(v, bld.root.__class__):
						try:
							v = v.get_bld_sig()
						except AttributeError:
							raise Errors.WafError('Missing node signature for %r (required by %r)' % (v, self))
					elif hasattr(v, '__call__'):
						v = v() # dependency is a function, call it
					upd(v)

		return self.m.digest()

	def sig_vars(self):
		"""
		Used by :py:meth:`waflib.Task.Task.signature`, hash :py:attr:`waflib.Task.Task.env` variables/values

		:rtype: hash value
		"""
		bld = self.generator.bld
		env = self.env
		upd = self.m.update

		# dependencies on the environment vars
		act_sig = bld.hash_env_vars(env, self.__class__.vars)
		upd(act_sig)

		# additional variable dependencies, if provided
		dep_vars = getattr(self, 'dep_vars', None)
		if dep_vars:
			upd(bld.hash_env_vars(env, dep_vars))

		return self.m.digest()

	scan = None
	"""
	This method, when provided, returns a tuple containing:

	* a list of nodes corresponding to real files
	* a list of names for files not found in path_lst

	For example::

		from waflib.Task import Task
		class mytask(Task):
			def scan(self, node):
				return ((), ())

	The first and second lists are stored in :py:attr:`waflib.Build.BuildContext.node_deps` and
	:py:attr:`waflib.Build.BuildContext.raw_deps` respectively.
	"""

	def sig_implicit_deps(self):
		"""
		Used by :py:meth:`waflib.Task.Task.signature` hashes node signatures obtained by scanning for dependencies (:py:meth:`waflib.Task.Task.scan`).

		The exception :py:class:`waflib.Errors.TaskRescan` is thrown
		when a file has changed. When this occurs, :py:meth:`waflib.Task.Task.signature` is called
		once again, and this method will be executed once again, this time calling :py:meth:`waflib.Task.Task.scan`
		for searching the dependencies.

		:rtype: hash value
		"""

		bld = self.generator.bld

		# get the task signatures from previous runs
		key = self.uid()
		prev = bld.task_sigs.get((key, 'imp'), [])

		# for issue #379
		if prev:
			try:
				if prev == self.compute_sig_implicit_deps():
					return prev
			except:
				# when a file was renamed (IOError usually), remove the stale nodes (headers in folders without source files)
				# this will break the order calculation for headers created during the build in the source directory (should be uncommon)
				# the behaviour will differ when top != out
				for x in bld.node_deps.get(self.uid(), []):
					if x.is_child_of(bld.srcnode):
						try:
							os.stat(x.abspath())
						except:
							try:
								del x.parent.children[x.name]
							except:
								pass
			del bld.task_sigs[(key, 'imp')]
			raise Errors.TaskRescan('rescan')

		# no previous run or the signature of the dependencies has changed, rescan the dependencies
		(nodes, names) = self.scan()
		if Logs.verbose:
			Logs.debug('deps: scanner for %s returned %s %s' % (str(self), str(nodes), str(names)))

		# store the dependencies in the cache
		bld.node_deps[key] = nodes
		bld.raw_deps[key] = names

		# might happen
		self.are_implicit_nodes_ready()

		# recompute the signature and return it
		try:
			bld.task_sigs[(key, 'imp')] = sig = self.compute_sig_implicit_deps()
		except:
			if Logs.verbose:
				for k in bld.node_deps.get(self.uid(), []):
					try:
						k.get_bld_sig()
					except:
						Logs.warn('Missing signature for node %r (may cause rebuilds)' % k)
		else:
			return sig

	def compute_sig_implicit_deps(self):
		"""
		Used by :py:meth:`waflib.Task.Task.sig_implicit_deps` for computing the actual hash of the
		:py:class:`waflib.Node.Node` returned by the scanner.

		:return: hash value
		:rtype: string
		"""

		upd = self.m.update

		bld = self.generator.bld

		self.are_implicit_nodes_ready()

		# scanner returns a node that does not have a signature
		# just *ignore* the error and let them figure out from the compiler output
		# waf -k behaviour
		for k in bld.node_deps.get(self.uid(), []):
			upd(k.get_bld_sig())
		return self.m.digest()

	def are_implicit_nodes_ready(self):
		"""
		For each node returned by the scanner, see if there is a task behind it, and force the build order

		The performance impact on null builds is nearly invisible (1.66s->1.86s), but this is due to
		agressive caching (1.86s->28s)
		"""
		bld = self.generator.bld
		try:
			cache = bld.dct_implicit_nodes
		except:
			bld.dct_implicit_nodes = cache = {}

		try:
			dct = cache[bld.cur]
		except KeyError:
			dct = cache[bld.cur] = {}
			for tsk in bld.cur_tasks:
				for x in tsk.outputs:
					dct[x] = tsk

		modified = False
		for x in bld.node_deps.get(self.uid(), []):
			if x in dct:
				self.run_after.add(dct[x])
				modified = True

		if modified:
			for tsk in self.run_after:
				if not tsk.hasrun:
					#print "task is not ready..."
					raise Errors.TaskNotReady('not ready')

	def can_retrieve_cache(self):
		"""
		Used by :py:meth:`waflib.Task.cache_outputs`

		Retrieve build nodes from the cache
		update the file timestamps to help cleaning the least used entries from the cache
		additionally, set an attribute 'cached' to avoid re-creating the same cache files

		Suppose there are files in `cache/dir1/file1` and `cache/dir2/file2`:

		#. read the timestamp of dir1
		#. try to copy the files
		#. look at the timestamp again, if it has changed, the data may have been corrupt (cache update by another process)
		#. should an exception occur, ignore the data
		"""

		if not getattr(self, 'outputs', None):
			return None

		sig = self.signature()
		ssig = Utils.to_hex(self.uid()) + Utils.to_hex(sig)

		# first try to access the cache folder for the task
		dname = os.path.join(self.generator.bld.cache_global, ssig)
		try:
			t1 = os.stat(dname).st_mtime
		except OSError:
			return None

		for node in self.outputs:
			orig = os.path.join(dname, node.name)
			try:
				shutil.copy2(orig, node.abspath())
				# mark the cache file as used recently (modified)
				os.utime(orig, None)
			except (OSError, IOError):
				Logs.debug('task: failed retrieving file')
				return None

		# is it the same folder?
		try:
			t2 = os.stat(dname).st_mtime
		except OSError:
			return None

		if t1 != t2:
			return None

		for node in self.outputs:
			node.sig = sig
			if self.generator.bld.progress_bar < 1:
				self.generator.bld.to_log('restoring from cache %r\n' % node.abspath())

		self.cached = True
		return True

	def put_files_cache(self):
		"""
		Used by :py:func:`waflib.Task.cache_outputs` to store the build files in the cache
		"""

		# file caching, if possible
		# try to avoid data corruption as much as possible
		if getattr(self, 'cached', None):
			return None
		if not getattr(self, 'outputs', None):
			return None

		sig = self.signature()
		ssig = Utils.to_hex(self.uid()) + Utils.to_hex(sig)
		dname = os.path.join(self.generator.bld.cache_global, ssig)
		tmpdir = tempfile.mkdtemp(prefix=self.generator.bld.cache_global + os.sep + 'waf')

		try:
			shutil.rmtree(dname)
		except:
			pass

		try:
			for node in self.outputs:
				dest = os.path.join(tmpdir, node.name)
				shutil.copy2(node.abspath(), dest)
		except (OSError, IOError):
			try:
				shutil.rmtree(tmpdir)
			except:
				pass
		else:
			try:
				os.rename(tmpdir, dname)
			except OSError:
				try:
					shutil.rmtree(tmpdir)
				except:
					pass
			else:
				try:
					os.chmod(dname, Utils.O755)
				except:
					pass

def is_before(t1, t2):
	"""
	Return a non-zero value if task t1 is to be executed before task t2::

		t1.ext_out = '.h'
		t2.ext_in = '.h'
		t2.after = ['t1']
		t1.before = ['t2']
		waflib.Task.is_before(t1, t2) # True

	:param t1: task
	:type t1: :py:class:`waflib.Task.TaskBase`
	:param t2: task
	:type t2: :py:class:`waflib.Task.TaskBase`
	"""
	to_list = Utils.to_list
	for k in to_list(t2.ext_in):
		if k in to_list(t1.ext_out):
			return 1

	if t1.__class__.__name__ in to_list(t2.after):
		return 1

	if t2.__class__.__name__ in to_list(t1.before):
		return 1

	return 0

def set_file_constraints(tasks):
	"""
	Adds tasks to the task 'run_after' attribute based on the task inputs and outputs

	:param tasks: tasks
	:type tasks: list of :py:class:`waflib.Task.TaskBase`
	"""
	ins = Utils.defaultdict(set)
	outs = Utils.defaultdict(set)
	for x in tasks:
		for a in getattr(x, 'inputs', []) + getattr(x, 'dep_nodes', []):
			ins[id(a)].add(x)
		for a in getattr(x, 'outputs', []):
			outs[id(a)].add(x)

	links = set(ins.keys()).intersection(outs.keys())
	for k in links:
		for a in ins[k]:
			a.run_after.update(outs[k])

def set_precedence_constraints(tasks):
	"""
	Add tasks to the task 'run_after' attribute based on the after/before/ext_out/ext_in attributes

	:param tasks: tasks
	:type tasks: list of :py:class:`waflib.Task.TaskBase`
	"""
	cstr_groups = Utils.defaultdict(list)
	for x in tasks:
		h = x.hash_constraints()
		cstr_groups[h].append(x)

	keys = list(cstr_groups.keys())
	maxi = len(keys)

	# this list should be short
	for i in range(maxi):
		t1 = cstr_groups[keys[i]][0]
		for j in range(i + 1, maxi):
			t2 = cstr_groups[keys[j]][0]

			# add the constraints based on the comparisons
			if is_before(t1, t2):
				a = i
				b = j
			elif is_before(t2, t1):
				a = j
				b = i
			else:
				continue
			for x in cstr_groups[keys[b]]:
				x.run_after.update(cstr_groups[keys[a]])

def funex(c):
	"""
	Compile a function by 'exec'

	:param c: function to compile
	:type c: string
	:return: the function 'f' declared in the input string
	:rtype: function
	"""
	dc = {}
	exec(c, dc)
	return dc['f']

reg_act = re.compile(r"(?P<backslash>\\)|(?P<dollar>\$\$)|(?P<subst>\$\{(?P<var>\w+)(?P<code>.*?)\})", re.M)
def compile_fun_shell(line):
	"""
	Create a compiled function to execute a process with the shell
	WARNING: this method may disappear anytime, so use compile_fun instead
	"""

	extr = []
	def repl(match):
		g = match.group
		if g('dollar'): return "$"
		elif g('backslash'): return '\\\\'
		elif g('subst'): extr.append((g('var'), g('code'))); return "%s"
		return None

	line = reg_act.sub(repl, line) or line

	parm = []
	dvars = []
	app = parm.append
	for (var, meth) in extr:
		if var == 'SRC':
			if meth: app('tsk.inputs%s' % meth)
			else: app('" ".join([a.path_from(bld.bldnode) for a in tsk.inputs])')
		elif var == 'TGT':
			if meth: app('tsk.outputs%s' % meth)
			else: app('" ".join([a.path_from(bld.bldnode) for a in tsk.outputs])')
		elif meth:
			if meth.startswith(':'):
				m = meth[1:]
				if m == 'SRC':
					m = '[a.path_from(bld.bldnode) for a in tsk.inputs]'
				elif m == 'TGT':
					m = '[a.path_from(bld.bldnode) for a in tsk.outputs]'
				elif m[:3] not in ('tsk', 'gen', 'bld'):
					dvars.extend([var, meth[1:]])
					m = '%r' % m
				app('" ".join(tsk.colon(%r, %s))' % (var, m))
			else:
				app('%s%s' % (var, meth))
		else:
			if not var in dvars: dvars.append(var)
			app("p('%s')" % var)
	if parm: parm = "%% (%s) " % (',\n\t\t'.join(parm))
	else: parm = ''

	c = COMPILE_TEMPLATE_SHELL % (line, parm)

	Logs.debug('action: %s' % c)
	return (funex(c), dvars)

def compile_fun_noshell(line):
	"""
	Create a compiled function to execute a process without the shell
	WARNING: this method may disappear anytime, so use compile_fun instead
	"""
	extr = []
	def repl(match):
		g = match.group
		if g('dollar'): return "$"
		elif g('subst'): extr.append((g('var'), g('code'))); return "<<|@|>>"
		return None

	line2 = reg_act.sub(repl, line)
	params = line2.split('<<|@|>>')
	assert(extr)

	buf = []
	dvars = []
	app = buf.append
	for x in range(len(extr)):
		params[x] = params[x].strip()
		if params[x]:
			app("lst.extend(%r)" % params[x].split())
		(var, meth) = extr[x]
		if var == 'SRC':
			if meth: app('lst.append(tsk.inputs%s)' % meth)
			else: app("lst.extend([a.path_from(bld.bldnode) for a in tsk.inputs])")
		elif var == 'TGT':
			if meth: app('lst.append(tsk.outputs%s)' % meth)
			else: app("lst.extend([a.path_from(bld.bldnode) for a in tsk.outputs])")
		elif meth:
			if meth.startswith(':'):
				m = meth[1:]
				if m == 'SRC':
					m = '[a.path_from(bld.bldnode) for a in tsk.inputs]'
				elif m == 'TGT':
					m = '[a.path_from(bld.bldnode) for a in tsk.outputs]'
				elif m[:3] not in ('tsk', 'gen', 'bld'):
					dvars.extend([var, m])
					m = '%r' % m
				app('lst.extend(tsk.colon(%r, %s))' % (var, m))
			else:
				app('lst.extend(gen.to_list(%s%s))' % (var, meth))
		else:
			app('lst.extend(to_list(env[%r]))' % var)
			if not var in dvars: dvars.append(var)

	if extr:
		if params[-1]:
			app("lst.extend(%r)" % params[-1].split())
	fun = COMPILE_TEMPLATE_NOSHELL % "\n\t".join(buf)
	Logs.debug('action: %s' % fun)
	return (funex(fun), dvars)

def compile_fun(line, shell=False):
	"""
	Parse a string expression such as "${CC} ${SRC} -o ${TGT}" and return a pair containing:

	* the function created (compiled) for use as :py:meth:`waflib.Task.TaskBase.run`
	* the list of variables that imply a dependency from self.env

	for example::

		from waflib.Task import compile_fun
		compile_fun('cxx', '${CXX} -o ${TGT[0]} ${SRC} -I ${SRC[0].parent.bldpath()}')

		def build(bld):
			bld(source='wscript', rule='echo "foo\\${SRC[0].name}\\bar"')

	The env variables (CXX, ..) on the task must not hold dicts (order)
	The reserved keywords *TGT* and *SRC* represent the task input and output nodes

	"""
	if line.find('<') > 0 or line.find('>') > 0 or line.find('&&') > 0:
		shell = True

	if shell:
		return compile_fun_shell(line)
	else:
		return compile_fun_noshell(line)

def task_factory(name, func=None, vars=None, color='GREEN', ext_in=[], ext_out=[], before=[], after=[], shell=False, scan=None):
	"""
	Return a new task subclass with the function ``run`` compiled from the line given.
	Provided for compatibility with waf 1.4-1.5, when we did not use metaclasses to register new objects.

	:param func: method run
	:type func: string or function
	:param vars: list of variables to hash
	:type vars: list of string
	:param color: color to use
	:type color: string
	:param shell: when *func* is a string, enable/disable the use of the shell
	:type shell: bool
	:param scan: method scan
	:type scan: function
	:rtype: :py:class:`waflib.Task.Task`
	"""

	params = {
		'vars': vars or [], # function arguments are static, and this one may be modified by the class
		'color': color,
		'name': name,
		'ext_in': Utils.to_list(ext_in),
		'ext_out': Utils.to_list(ext_out),
		'before': Utils.to_list(before),
		'after': Utils.to_list(after),
		'shell': shell,
		'scan': scan,
	}

	if isinstance(func, str):
		params['run_str'] = func
	else:
		params['run'] = func

	cls = type(Task)(name, (Task,), params)
	global classes
	classes[name] = cls
	return cls


def always_run(cls):
	"""
	Task class decorator

	Set all task instances of this class to be executed whenever a build is started
	The task signature is calculated, but the result of the comparation between
	task signatures is bypassed
	"""
	old = cls.runnable_status
	def always(self):
		ret = old(self)
		if ret == SKIP_ME:
			ret = RUN_ME
		return ret
	cls.runnable_status = always
	return cls

def update_outputs(cls):
	"""
	Task class decorator

	If you want to create files in the source directory. For example, to keep *foo.txt* in the source
	directory, create it first and declare::

		def build(bld):
			bld(rule='cp ${SRC} ${TGT}', source='wscript', target='foo.txt', update_outputs=True)
	"""
	old_post_run = cls.post_run
	def post_run(self):
		old_post_run(self)
		for node in self.outputs:
			node.sig = Utils.h_file(node.abspath())
			self.generator.bld.task_sigs[node.abspath()] = self.uid() # issue #1017
	cls.post_run = post_run


	old_runnable_status = cls.runnable_status
	def runnable_status(self):
		status = old_runnable_status(self)
		if status != RUN_ME:
			return status

		try:
			# by default, we check that the output nodes have the signature of the task
			# perform a second check, returning 'SKIP_ME' as we are expecting that
			# the signatures do not match
			bld = self.generator.bld
			prev_sig = bld.task_sigs[self.uid()]
			if prev_sig == self.signature():
				for x in self.outputs:
					if not x.sig or bld.task_sigs[x.abspath()] != self.uid():
						return RUN_ME
				return SKIP_ME
		except KeyError:
			pass
		except IndexError:
			pass
		except AttributeError:
			pass
		return RUN_ME
	cls.runnable_status = runnable_status

	return cls



########NEW FILE########
__FILENAME__ = TaskGen
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2005-2010 (ita)

"""
Task generators

The class :py:class:`waflib.TaskGen.task_gen` encapsulates the creation of task objects (low-level code)
The instances can have various parameters, but the creation of task nodes (Task.py)
is always postponed. To achieve this, various methods are called from the method "apply"


"""

import copy, re, os
from waflib import Task, Utils, Logs, Errors, ConfigSet

feats = Utils.defaultdict(set)
"""remember the methods declaring features"""

class task_gen(object):
	"""
	Instances of this class create :py:class:`waflib.Task.TaskBase` when
	calling the method :py:meth:`waflib.TaskGen.task_gen.post` from the main thread.
	A few notes:

	* The methods to call (*self.meths*) can be specified dynamically (removing, adding, ..)
	* The 'features' are used to add methods to self.meths and then execute them
	* The attribute 'path' is a node representing the location of the task generator
	* The tasks created are added to the attribute *tasks*
	* The attribute 'idx' is a counter of task generators in the same path
	"""

	mappings = {}
	prec = Utils.defaultdict(list)

	def __init__(self, *k, **kw):
		"""
		The task generator objects predefine various attributes (source, target) for possible
		processing by process_rule (make-like rules) or process_source (extensions, misc methods)

		The tasks are stored on the attribute 'tasks'. They are created by calling methods
		listed in self.meths *or* referenced in the attribute features
		A topological sort is performed to ease the method re-use.

		The extra key/value elements passed in kw are set as attributes
		"""

		# so we will have to play with directed acyclic graphs
		# detect cycles, etc
		self.source = ''
		self.target = ''

		self.meths = []
		"""
		List of method names to execute (it is usually a good idea to avoid touching this)
		"""

		self.prec = Utils.defaultdict(list)
		"""
		Precedence table for sorting the methods in self.meths
		"""

		self.mappings = {}
		"""
		List of mappings {extension -> function} for processing files by extension
		"""

		self.features = []
		"""
		List of feature names for bringing new methods in
		"""

		self.tasks = []
		"""
		List of tasks created.
		"""

		if not 'bld' in kw:
			# task generators without a build context :-/
			self.env = ConfigSet.ConfigSet()
			self.idx = 0
			self.path = None
		else:
			self.bld = kw['bld']
			self.env = self.bld.env.derive()
			self.path = self.bld.path # emulate chdir when reading scripts

			# provide a unique id
			try:
				self.idx = self.bld.idx[id(self.path)] = self.bld.idx.get(id(self.path), 0) + 1
			except AttributeError:
				self.bld.idx = {}
				self.idx = self.bld.idx[id(self.path)] = 1

		for key, val in kw.items():
			setattr(self, key, val)

	def __str__(self):
		"""for debugging purposes"""
		return "<task_gen %r declared in %s>" % (self.name, self.path.abspath())

	def __repr__(self):
		"""for debugging purposes"""
		lst = []
		for x in self.__dict__.keys():
			if x not in ['env', 'bld', 'compiled_tasks', 'tasks']:
				lst.append("%s=%s" % (x, repr(getattr(self, x))))
		return "bld(%s) in %s" % (", ".join(lst), self.path.abspath())

	def get_name(self):
		"""
		If not set, the name is computed from the target name::

			def build(bld):
				x = bld(name='foo')
				x.get_name() # foo
				y = bld(target='bar')
				y.get_name() # bar

		:rtype: string
		:return: name of this task generator
		"""
		try:
			return self._name
		except AttributeError:
			if isinstance(self.target, list):
				lst = [str(x) for x in self.target]
				name = self._name = ','.join(lst)
			else:
				name = self._name = str(self.target)
			return name
	def set_name(self, name):
		self._name = name

	name = property(get_name, set_name)

	def to_list(self, val):
		"""
		Ensure that a parameter is a list

		:type val: string or list of string
		:param val: input to return as a list
		:rtype: list
		"""
		if isinstance(val, str): return val.split()
		else: return val

	def post(self):
		"""
		Create task objects. The following operations are performed:

		#. The body of this method is called only once and sets the attribute ``posted``
		#. The attribute ``features`` is used to add more methods in ``self.meths``
		#. The methods are sorted by the precedence table ``self.prec`` or `:waflib:attr:waflib.TaskGen.task_gen.prec`
		#. The methods are then executed in order
		#. The tasks created are added to :py:attr:`waflib.TaskGen.task_gen.tasks`
		"""

		# we could add a decorator to let the task run once, but then python 2.3 will be difficult to support
		if getattr(self, 'posted', None):
			#error("OBJECT ALREADY POSTED" + str( self))
			return False
		self.posted = True

		keys = set(self.meths)

		# add the methods listed in the features
		self.features = Utils.to_list(self.features)
		for x in self.features + ['*']:
			st = feats[x]
			if not st:
				if not x in Task.classes:
					Logs.warn('feature %r does not exist - bind at least one method to it' % x)
			keys.update(list(st)) # ironpython 2.7 wants the cast to list

		# copy the precedence table
		prec = {}
		prec_tbl = self.prec or task_gen.prec
		for x in prec_tbl:
			if x in keys:
				prec[x] = prec_tbl[x]

		# elements disconnected
		tmp = []
		for a in keys:
			for x in prec.values():
				if a in x: break
			else:
				tmp.append(a)

		# TODO waf 1.7
		#tmp.sort()

		# topological sort
		out = []
		while tmp:
			e = tmp.pop()
			if e in keys: out.append(e)
			try:
				nlst = prec[e]
			except KeyError:
				pass
			else:
				del prec[e]
				for x in nlst:
					for y in prec:
						if x in prec[y]:
							break
					else:
						tmp.append(x)

		if prec:
			raise Errors.WafError('Cycle detected in the method execution %r' % prec)
		out.reverse()
		self.meths = out

		# then we run the methods in order
		Logs.debug('task_gen: posting %s %d' % (self, id(self)))
		for x in out:
			try:
				v = getattr(self, x)
			except AttributeError:
				raise Errors.WafError('%r is not a valid task generator method' % x)
			Logs.debug('task_gen: -> %s (%d)' % (x, id(self)))
			v()

		Logs.debug('task_gen: posted %s' % self.name)
		return True

	def get_hook(self, node):
		"""
		:param node: Input file to process
		:type node: :py:class:`waflib.Tools.Node.Node`
		:return: A method able to process the input node by looking at the extension
		:rtype: function
		"""
		name = node.name
		for k in self.mappings:
			if name.endswith(k):
				return self.mappings[k]
		for k in task_gen.mappings:
			if name.endswith(k):
				return task_gen.mappings[k]
		raise Errors.WafError("File %r has no mapping in %r (did you forget to load a waf tool?)" % (node, task_gen.mappings.keys()))

	def create_task(self, name, src=None, tgt=None):
		"""
		Wrapper for creating task objects easily

		:param name: task class name
		:type name: string
		:param src: input nodes
		:type src: list of :py:class:`waflib.Tools.Node.Node`
		:param tgt: output nodes
		:type tgt: list of :py:class:`waflib.Tools.Node.Node`
		:return: A task object
		:rtype: :py:class:`waflib.Task.TaskBase`
		"""
		task = Task.classes[name](env=self.env.derive(), generator=self)
		if src:
			task.set_inputs(src)
		if tgt:
			task.set_outputs(tgt)
		self.tasks.append(task)
		return task

	def clone(self, env):
		"""
		Make a copy of a task generator. Once the copy is made, it is necessary to ensure that the
		task generator does not create the same output files as the original, or the same files may
		be compiled twice.

		:param env: A configuration set
		:type env: :py:class:`waflib.ConfigSet.ConfigSet`
		:return: A copy
		:rtype: :py:class:`waflib.TaskGen.task_gen`
		"""
		newobj = self.bld()
		for x in self.__dict__:
			if x in ['env', 'bld']:
				continue
			elif x in ['path', 'features']:
				setattr(newobj, x, getattr(self, x))
			else:
				setattr(newobj, x, copy.copy(getattr(self, x)))

		newobj.posted = False
		if isinstance(env, str):
			newobj.env = self.bld.all_envs[env].derive()
		else:
			newobj.env = env.derive()

		return newobj

def declare_chain(name='', rule=None, reentrant=None, color='BLUE',
	ext_in=[], ext_out=[], before=[], after=[], decider=None, scan=None, install_path=None, shell=False):
	"""
	Create a new mapping and a task class for processing files by extension.
	See Tools/flex.py for an example.

	:param name: name for the task class
	:type name: string
	:param rule: function to execute or string to be compiled in a function
	:type rule: string or function
	:param reentrant: re-inject the output file in the process (done automatically, set to 0 to disable)
	:type reentrant: int
	:param color: color for the task output
	:type color: string
	:param ext_in: execute the task only after the files of such extensions are created
	:type ext_in: list of string
	:param ext_out: execute the task only before files of such extensions are processed
	:type ext_out: list of string
	:param before: execute instances of this task before classes of the given names
	:type before: list of string
	:param after: execute instances of this task after classes of the given names
	:type after: list of string
	:param decider: if present, use it to create the output nodes for the task
	:type decider: function
	:param scan: scanner function for the task
	:type scan: function
	:param install_path: installation path for the output nodes
	:type install_path: string
	"""
	ext_in = Utils.to_list(ext_in)
	ext_out = Utils.to_list(ext_out)
	if not name:
		name = rule
	cls = Task.task_factory(name, rule, color=color, ext_in=ext_in, ext_out=ext_out, before=before, after=after, scan=scan, shell=shell)

	def x_file(self, node):
		ext = decider and decider(self, node) or cls.ext_out
		if ext_in:
			_ext_in = ext_in[0]

		tsk = self.create_task(name, node)
		cnt = 0

		keys = self.mappings.keys() + self.__class__.mappings.keys()
		for x in ext:
			k = node.change_ext(x, ext_in=_ext_in)
			tsk.outputs.append(k)

			if reentrant != None:
				if cnt < int(reentrant):
					self.source.append(k)
			else:
				for y in keys: # ~ nfile * nextensions :-/
					if k.name.endswith(y):
						self.source.append(k)
						break
			cnt += 1

		if install_path:
			self.bld.install_files(install_path, tsk.outputs)
		return tsk

	for x in cls.ext_in:
		task_gen.mappings[x] = x_file
	return x_file

def taskgen_method(func):
	"""
	Decorator: register a method as a task generator method.
	The function must accept a task generator as first parameter::

		from waflib.TaskGen import taskgen_method
		@taskgen_method
		def mymethod(self):
			pass

	:param func: task generator method to add
	:type func: function
	:rtype: function
	"""
	setattr(task_gen, func.__name__, func)
	return func

def feature(*k):
	"""
	Decorator: register a task generator method that will be executed when the
	object attribute 'feature' contains the corresponding key(s)::

		from waflib.Task import feature
		@feature('myfeature')
		def myfunction(self):
			print('that is my feature!')
		def build(bld):
			bld(features='myfeature')

	:param k: feature names
	:type k: list of string
	"""
	def deco(func):
		setattr(task_gen, func.__name__, func)
		for name in k:
			feats[name].update([func.__name__])
		return func
	return deco

def before_method(*k):
	"""
	Decorator: register a task generator method which will be executed
	before the functions of given name(s)::

		from waflib.TaskGen import feature, before
		@feature('myfeature')
		@before_method('fun2')
		def fun1(self):
			print('feature 1!')
		@feature('myfeature')
		def fun2(self):
			print('feature 2!')
		def build(bld):
			bld(features='myfeature')

	:param k: method names
	:type k: list of string
	"""
	def deco(func):
		setattr(task_gen, func.__name__, func)
		for fun_name in k:
			if not func.__name__ in task_gen.prec[fun_name]:
				task_gen.prec[fun_name].append(func.__name__)
				#task_gen.prec[fun_name].sort()
		return func
	return deco
before = before_method

def after_method(*k):
	"""
	Decorator: register a task generator method which will be executed
	after the functions of given name(s)::

		from waflib.TaskGen import feature, after
		@feature('myfeature')
		@after_method('fun2')
		def fun1(self):
			print('feature 1!')
		@feature('myfeature')
		def fun2(self):
			print('feature 2!')
		def build(bld):
			bld(features='myfeature')

	:param k: method names
	:type k: list of string
	"""
	def deco(func):
		setattr(task_gen, func.__name__, func)
		for fun_name in k:
			if not fun_name in task_gen.prec[func.__name__]:
				task_gen.prec[func.__name__].append(fun_name)
				#task_gen.prec[func.__name__].sort()
		return func
	return deco
after = after_method

def extension(*k):
	"""
	Decorator: register a task generator method which will be invoked during
	the processing of source files for the extension given::

		from waflib import Task
		class mytask(Task):
			run_str = 'cp ${SRC} ${TGT}'
		@extension('.moo')
		def create_maa_file(self, node):
			self.create_task('mytask', node, node.change_ext('.maa'))
		def build(bld):
			bld(source='foo.moo')
	"""
	def deco(func):
		setattr(task_gen, func.__name__, func)
		for x in k:
			task_gen.mappings[x] = func
		return func
	return deco

# ---------------------------------------------------------------
# The following methods are task generator methods commonly used
# they are almost examples, the rest of waf core does not depend on them

@taskgen_method
def to_nodes(self, lst, path=None):
	"""
	Convert the input list into a list of nodes.
	It is used by :py:func:`waflib.TaskGen.process_source` and :py:func:`waflib.TaskGen.process_rule`.
	It is designed for source files, for folders, see :py:func:`waflib.Tools.ccroot.to_incnodes`:

	:param lst: input list
	:type lst: list of string and nodes
	:param path: path from which to search the nodes (by default, :py:attr:`waflib.TaskGen.task_gen.path`)
	:type path: :py:class:`waflib.Tools.Node.Node`
	:rtype: list of :py:class:`waflib.Tools.Node.Node`
	"""
	tmp = []
	path = path or self.path
	find = path.find_resource

	if isinstance(lst, self.path.__class__):
		lst = [lst]

	# either a list or a string, convert to a list of nodes
	for x in Utils.to_list(lst):
		if isinstance(x, str):
			node = find(x)
		else:
			node = x
		if not node:
			raise Errors.WafError("source not found: %r in %r" % (x, self))
		tmp.append(node)
	return tmp

@feature('*')
def process_source(self):
	"""
	Process each element in the attribute ``source`` by extension.

	#. The *source* list is converted through :py:meth:`waflib.TaskGen.to_nodes` to a list of :py:class:`waflib.Node.Node` first.
	#. File extensions are mapped to methods having the signature: ``def meth(self, node)`` by :py:meth:`waflib.TaskGen.extension`
	#. The method is retrieved through :py:meth:`waflib.TaskGen.task_gen.get_hook`
	#. When called, the methods may modify self.source to append more source to process
	#. The mappings can map an extension or a filename (see the code below)
	"""
	self.source = self.to_nodes(getattr(self, 'source', []))
	for node in self.source:
		self.get_hook(node)(self, node)

@feature('*')
@before_method('process_source')
def process_rule(self):
	"""
	Process the attribute ``rule``. When present, :py:meth:`waflib.TaskGen.process_source` is disabled::

		def build(bld):
			bld(rule='cp ${SRC} ${TGT}', source='wscript', target='bar.txt')
	"""
	if not getattr(self, 'rule', None):
		return

	# create the task class
	name = str(getattr(self, 'name', None) or self.target or self.rule)
	cls = Task.task_factory(name, self.rule,
		getattr(self, 'vars', []),
		shell=getattr(self, 'shell', True), color=getattr(self, 'color', 'BLUE'))

	# now create one instance
	tsk = self.create_task(name)

	if getattr(self, 'target', None):
		if isinstance(self.target, str):
			self.target = self.target.split()
		if not isinstance(self.target, list):
			self.target = [self.target]
		for x in self.target:
			if isinstance(x, str):
				tsk.outputs.append(self.path.find_or_declare(x))
			else:
				x.parent.mkdir() # if a node was given, create the required folders
				tsk.outputs.append(x)
		if getattr(self, 'install_path', None):
			# from waf 1.5
			# although convenient, it does not 1. allow to name the target file and 2. symlinks
			# TODO remove in waf 1.7
			self.bld.install_files(self.install_path, tsk.outputs)

	if getattr(self, 'source', None):
		tsk.inputs = self.to_nodes(self.source)
		# bypass the execution of process_source by setting the source to an empty list
		self.source = []

	if getattr(self, 'scan', None):
		cls.scan = self.scan
	elif getattr(self, 'deps', None):
		def scan(self):
			nodes = []
			for x in self.generator.to_list(self.generator.deps):
				node = self.generator.path.find_resource(x)
				if not node:
					self.generator.bld.fatal('Could not find %r (was it declared?)' % x)
				nodes.append(node)
			return [nodes, []]
		cls.scan = scan

	if getattr(self, 'cwd', None):
		tsk.cwd = self.cwd

	# TODO remove on_results in waf 1.7
	if getattr(self, 'update_outputs', None) or getattr(self, 'on_results', None):
		Task.update_outputs(cls)

	if getattr(self, 'always', None):
		Task.always_run(cls)

	for x in ['after', 'before', 'ext_in', 'ext_out']:
		setattr(cls, x, getattr(self, x, []))

@feature('seq')
def sequence_order(self):
	"""
	Add a strict sequential constraint between the tasks generated by task generators.
	It works because task generators are posted in order.
	It will not post objects which belong to other folders.

	Example::

		bld(features='javac seq')
		bld(features='jar seq')

	To start a new sequence, set the attribute seq_start, for example::

		obj = bld(features='seq')
		obj.seq_start = True

	Note that the method is executed in last position. This is more an
	example than a widely-used solution.
	"""
	if self.meths and self.meths[-1] != 'sequence_order':
		self.meths.append('sequence_order')
		return

	if getattr(self, 'seq_start', None):
		return

	# all the tasks previously declared must be run before these
	if getattr(self.bld, 'prev', None):
		self.bld.prev.post()
		for x in self.bld.prev.tasks:
			for y in self.tasks:
				y.set_run_after(x)

	self.bld.prev = self


re_m4 = re.compile('@(\w+)@', re.M)

class subst_pc(Task.Task):
	"""
	Create *.pc* files from *.pc.in*. The task is executed whenever an input variable used
	in the substitution changes.
	"""

	def run(self):
		"Substitutes variables in a .in file"

		code = self.inputs[0].read()

		# replace all % by %% to prevent errors by % signs
		code = code.replace('%', '%%')

		# extract the vars foo into lst and replace @foo@ by %(foo)s
		lst = []
		def repl(match):
			g = match.group
			if g(1):
				lst.append(g(1))
				return "%%(%s)s" % g(1)
			return ''
		code = re_m4.sub(repl, code)

		try:
			d = self.generator.dct
		except AttributeError:
			d = {}
			for x in lst:
				tmp = getattr(self.generator, x, '') or self.env.get_flat(x) or self.env.get_flat(x.upper())
				d[x] = str(tmp)

		self.outputs[0].write(code % d)
		self.generator.bld.raw_deps[self.uid()] = self.dep_vars = lst

		# make sure the signature is updated
		try: delattr(self, 'cache_sig')
		except AttributeError: pass

		if getattr(self.generator, 'chmod', None):
			os.chmod(self.outputs[0].abspath(), self.generator.chmod)

	def sig_vars(self):
		"""
		Compute a hash (signature) of the variables used in the substitution
		"""
		bld = self.generator.bld
		env = self.env
		upd = self.m.update

		# raw_deps: persistent custom values returned by the scanner
		vars = self.generator.bld.raw_deps.get(self.uid(), [])

		# hash both env vars and task generator attributes
		act_sig = bld.hash_env_vars(env, vars)
		upd(act_sig)

		lst = [getattr(self.generator, x, '') for x in vars]
		upd(Utils.h_list(lst))

		return self.m.digest()

@extension('.pc.in')
def add_pcfile(self, node):
	"""
	Process *.pc.in* files to *.pc*. Install the results to ``${PREFIX}/lib/pkgconfig/``

		def build(bld):
			bld(source='foo.pc.in', install_path='${LIBDIR}/pkgconfig/')
	"""
	tsk = self.create_task('subst_pc', node, node.change_ext('.pc', '.pc.in'))
	self.bld.install_files(getattr(self, 'install_path', '${LIBDIR}/pkgconfig/'), tsk.outputs)

class subst(subst_pc):
	pass

@feature('subst')
@before_method('process_source', 'process_rule')
def process_subst(self):
	"""
	Define a transformation that substitutes the contents of *source* files to *target* files::

		def build(bld):
			bld(
				features='subst',
				source='foo.c.in',
				target='foo.c',
				install_path='${LIBDIR}/pkgconfig',
				VAR = 'val'
			)

	The input files are supposed to contain macros of the form *@VAR@*, where *VAR* is an argument
	of the task generator object.

	This method overrides the processing by :py:meth:`waflib.TaskGen.process_source`.
	"""
	src = self.to_nodes(getattr(self, 'source', []))
	tgt = getattr(self, 'target', [])
	if isinstance(tgt, self.path.__class__):
		tgt = [tgt]
	tgt = [isinstance(x, self.path.__class__) and x or self.path.find_or_declare(x) for x in Utils.to_list(tgt)]

	if len(src) != len(tgt):
		raise Errors.WafError('invalid source or target for %r' % self)

	for x, y in zip(src, tgt):
		if not (x and y):
			raise Errors.WafError('invalid source or target for %r' % self)
		tsk = self.create_task('subst', x, y)
		for a in ('after', 'before', 'ext_in', 'ext_out'):
			val = getattr(self, a, None)
			if val:
				setattr(tsk, a, val)

	inst_to = getattr(self, 'install_path', None)
	if inst_to:
		self.bld.install_files(inst_to, tgt, chmod=getattr(self, 'chmod', Utils.O644))

	self.source = []


########NEW FILE########
__FILENAME__ = ccroot
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2005-2010 (ita)

"""
Classes and methods shared by tools providing support for C-like language such
as C/C++/D/Assembly/Go (this support module is almost never used alone).
"""

import os, sys, re
from waflib import TaskGen, Task, Utils, Logs, Build, Options, Node, Errors
from waflib.Logs import error, debug, warn
from waflib.TaskGen import after_method, before_method, feature, taskgen_method, extension
from waflib.Tools import c_aliases, c_preproc, c_config, c_osx, c_tests
from waflib.Configure import conf

USELIB_VARS = Utils.defaultdict(set)
"""
Mapping for features to :py:class:`waflib.ConfigSet.ConfigSet` variables. See :py:func:`waflib.Tools.ccroot.propagate_uselib_vars`.
"""

USELIB_VARS['c']   = set(['INCLUDES', 'FRAMEWORKPATH', 'DEFINES', 'CPPFLAGS', 'CCDEPS', 'CFLAGS', 'ARCH'])
USELIB_VARS['cxx'] = set(['INCLUDES', 'FRAMEWORKPATH', 'DEFINES', 'CPPFLAGS', 'CXXDEPS', 'CXXFLAGS', 'ARCH'])
USELIB_VARS['d']   = set(['INCLUDES', 'DFLAGS'])

USELIB_VARS['cprogram'] = USELIB_VARS['cxxprogram'] = set(['LIB', 'STLIB', 'LIBPATH', 'STLIBPATH', 'LINKFLAGS', 'RPATH', 'LINKDEPS', 'FRAMEWORK', 'FRAMEWORKPATH', 'ARCH'])
USELIB_VARS['cshlib']   = USELIB_VARS['cxxshlib']   = set(['LIB', 'STLIB', 'LIBPATH', 'STLIBPATH', 'LINKFLAGS', 'RPATH', 'LINKDEPS', 'FRAMEWORK', 'FRAMEWORKPATH', 'ARCH'])
USELIB_VARS['cstlib']   = USELIB_VARS['cxxstlib']   = set(['ARFLAGS', 'LINKDEPS'])

USELIB_VARS['dprogram'] = set(['LIB', 'STLIB', 'LIBPATH', 'STLIBPATH', 'LINKFLAGS', 'RPATH', 'LINKDEPS'])
USELIB_VARS['dshlib']   = set(['LIB', 'STLIB', 'LIBPATH', 'STLIBPATH', 'LINKFLAGS', 'RPATH', 'LINKDEPS'])
USELIB_VARS['dstlib']   = set(['ARFLAGS', 'LINKDEPS'])

USELIB_VARS['go'] = set(['GOCFLAGS'])
USELIB_VARS['goprogram'] = set(['GOLFLAGS'])

USELIB_VARS['asm'] = set(['ASFLAGS'])

# =================================================================================================

@taskgen_method
def create_compiled_task(self, name, node):
	"""
	Create the compilation task: c, cxx, asm, etc. The output node is created automatically (object file with a typical **.o** extension).
	The task is appended to the list *compiled_tasks* which is then used by :py:func:`waflib.Tools.ccroot.apply_link`

	:param name: name of the task class
	:type name: string
	:param node: the file to compile
	:type node: :py:class:`waflib.Node.Node`
	:return: The task created
	:rtype: :py:class:`waflib.Task.Task`
	"""
	out = '%s.%d.o' % (node.name, self.idx)
	task = self.create_task(name, node, node.parent.find_or_declare(out))
	try:
		self.compiled_tasks.append(task)
	except AttributeError:
		self.compiled_tasks = [task]
	return task

@taskgen_method
def to_incnodes(self, inlst):
	"""
	Task generator method provided to convert a list of string/nodes into a list of includes folders.

	The paths are assumed to be relative to the task generator path, except if they begin by **#**
	in which case they are searched from the top-level directory (``bld.srcnode``).
	The folders are simply assumed to be existing.

	The node objects in the list are returned in the output list. The strings are converted
	into node objects if possible. The node is searched from the source directory, and if a match is found,
	the equivalent build directory is created and added to the returned list too. When a folder cannot be found, it is ignored.

	:param inlst: list of folders
	:type inlst: space-delimited string or a list of string/nodes
	:rtype: list of :py:class:`waflib.Node.Node`
	:return: list of include folders as nodes
	"""
	lst = []
	seen = set([])
	for x in self.to_list(inlst):
		if x in seen or not x:
			continue
		seen.add(x)

		if isinstance(x, Node.Node):
			lst.append(x)
		else:
			if os.path.isabs(x):
				lst.append(self.bld.root.make_node(x) or x)
			else:
				if x[0] == '#':
					p = self.bld.bldnode.make_node(x[1:])
					v = self.bld.srcnode.make_node(x[1:])
				else:
					p = self.path.get_bld().make_node(x)
					v = self.path.make_node(x)
				if p.is_child_of(self.bld.bldnode):
					p.mkdir()
				lst.append(p)
				lst.append(v)
	return lst

@feature('c', 'cxx', 'd', 'go', 'asm', 'fc', 'includes')
@after_method('propagate_uselib_vars', 'process_source')
def apply_incpaths(self):
	"""
	Task generator method that processes the attribute *includes*::

		tg = bld(features='includes', includes='.')

	The folders only need to be relative to the current directory, the equivalent build directory is
	added automatically (for headers created in the build directory). This enable using a build directory
	or not (``top == out``).

	This method will add a list of nodes read by :py:func:`waflib.Tools.ccroot.to_incnodes` in ``tg.env.INCPATHS``,
	and the list of include paths in ``tg.env.INCLUDES``.
	"""

	lst = self.to_incnodes(self.to_list(getattr(self, 'includes', [])) + self.env['INCLUDES'])
	self.includes_nodes = lst
	self.env['INCPATHS'] = [x.abspath() for x in lst]

class link_task(Task.Task):
	"""
	Base class for all link tasks. A task generator is supposed to have at most one link task bound in the attribute *link_task*. See :py:func:`waflib.Tools.ccroot.apply_link`.

	.. inheritance-diagram:: waflib.Tools.ccroot.stlink_task waflib.Tools.c.cprogram waflib.Tools.c.cshlib waflib.Tools.cxx.cxxstlib  waflib.Tools.cxx.cxxprogram waflib.Tools.cxx.cxxshlib waflib.Tools.d.dprogram waflib.Tools.d.dshlib waflib.Tools.d.dstlib waflib.Tools.ccroot.fake_shlib waflib.Tools.ccroot.fake_stlib waflib.Tools.asm.asmprogram waflib.Tools.asm.asmshlib waflib.Tools.asm.asmstlib
	"""
	color   = 'YELLOW'

	inst_to = None
	"""Default installation path for the link task outputs, or None to disable"""

	chmod   = Utils.O644
	"""Default installation mode for the link task outputs"""

	def add_target(self, target):
		"""
		Process the *target* attribute to add the platform-specific prefix/suffix such as *.so* or *.exe*.
		The settings are retrieved from ``env.clsname_PATTERN``
		"""
		if isinstance(target, str):
			pattern = self.env[self.__class__.__name__ + '_PATTERN']
			if not pattern:
				pattern = '%s'
			folder, name = os.path.split(target)

			if self.__class__.__name__.find('shlib') > 0:
				if self.env.DEST_BINFMT == 'pe' and getattr(self.generator, 'vnum', None):
					# include the version in the dll file name,
					# the import lib file name stays unversionned.
					name = name + '-' + self.generator.vnum.split('.')[0]

			tmp = folder + os.sep + pattern % name
			target = self.generator.path.find_or_declare(tmp)
		self.set_outputs(target)

class stlink_task(link_task):
	"""
	Base for static link tasks, which use *ar* most of the time.
	The target is always removed before being written.
	"""
	run_str = '${AR} ${ARFLAGS} ${AR_TGT_F}${TGT} ${AR_SRC_F}${SRC}'

def rm_tgt(cls):
	old = cls.run
	def wrap(self):
		try: os.remove(self.outputs[0].abspath())
		except OSError: pass
		return old(self)
	setattr(cls, 'run', wrap)
rm_tgt(stlink_task)

@feature('c', 'cxx', 'd', 'go', 'fc', 'asm')
@after_method('process_source')
def apply_link(self):
	"""
	Collect the tasks stored in ``compiled_tasks`` (created by :py:func:`waflib.Tools.ccroot.create_compiled_task`), and
	use the outputs for a new instance of :py:class:`waflib.Tools.ccroot.link_task`. The class to use is the first link task
	matching a name from the attribute *features*, for example::

			def build(bld):
				tg = bld(features='cxx cxxprogram cprogram', source='main.c', target='app')

	will create the task ``tg.link_task`` as a new instance of :py:class:`waflib.Tools.cxx.cxxprogram`
	"""

	for x in self.features:
		if x == 'cprogram' and 'cxx' in self.features: # limited compat
			x = 'cxxprogram'
		elif x == 'cshlib' and 'cxx' in self.features:
			x = 'cxxshlib'

		if x in Task.classes:
			if issubclass(Task.classes[x], link_task):
				link = x
				break
	else:
		return

	objs = [t.outputs[0] for t in getattr(self, 'compiled_tasks', [])]
	self.link_task = self.create_task(link, objs)
	self.link_task.add_target(self.target)

	# remember that the install paths are given by the task generators
	# we need to define install_task even during the build phase because others might need the installation path
	try:
		inst_to = self.install_path
	except AttributeError:
		inst_to = self.link_task.__class__.inst_to
	if inst_to:
		# install a copy of the node list we have at this moment (implib not added)
		self.install_task = self.bld.install_files(inst_to, self.link_task.outputs[:], env=self.env, chmod=self.link_task.chmod)

@taskgen_method
def use_rec(self, name, **kw):
	"""
	Processes the ``use`` keyword recursively. This method is kind of private and only meant to be used from ``process_use``
	"""

	if name in self.tmp_use_not or name in self.tmp_use_seen:
		return

	try:
		y = self.bld.get_tgen_by_name(name)
	except Errors.WafError:
		self.uselib.append(name)
		self.tmp_use_not.add(name)
		return

	self.tmp_use_seen.append(name)
	y.post()

	# bind temporary attributes on the task generator
	y.tmp_use_objects = objects = kw.get('objects', True)
	y.tmp_use_stlib   = stlib   = kw.get('stlib', True)
	try:
		link_task = y.link_task
	except AttributeError:
		y.tmp_use_var = ''
	else:
		objects = False
		if not isinstance(y.link_task, stlink_task):
			stlib = False
			y.tmp_use_var = 'LIB'
		else:
			y.tmp_use_var = 'STLIB'

	p = self.tmp_use_prec
	for x in self.to_list(getattr(y, 'use', [])):
		try:
			p[x].append(name)
		except:
			p[x] = [name]
		self.use_rec(x, objects=objects, stlib=stlib)

@feature('c', 'cxx', 'd', 'use', 'fc')
@before_method('apply_incpaths', 'propagate_uselib_vars')
@after_method('apply_link', 'process_source')
def process_use(self):
	"""
	Process the ``use`` attribute which contains a list of task generator names::

		def build(bld):
			bld.shlib(source='a.c', target='lib1')
			bld.program(source='main.c', target='app', use='lib1')

	See :py:func:`waflib.Tools.ccroot.use_rec`.
	"""

	use_not = self.tmp_use_not = set([])
	use_seen = self.tmp_use_seen = [] # we would like an ordered set
	use_prec = self.tmp_use_prec = {}
	self.uselib = self.to_list(getattr(self, 'uselib', []))
	self.includes = self.to_list(getattr(self, 'includes', []))
	names = self.to_list(getattr(self, 'use', []))

	for x in names:
		self.use_rec(x)

	for x in use_not:
		if x in use_prec:
			del use_prec[x]

	# topological sort
	out = []
	tmp = []
	for x in self.tmp_use_seen:
		for k in use_prec.values():
			if x in k:
				break
		else:
			tmp.append(x)

	while tmp:
		e = tmp.pop()
		out.append(e)
		try:
			nlst = use_prec[e]
		except KeyError:
			pass
		else:
			del use_prec[e]
			for x in nlst:
				for y in use_prec:
					if x in use_prec[y]:
						break
				else:
					tmp.append(x)
	if use_prec:
		raise Errors.WafError('Cycle detected in the use processing %r' % use_prec)
	out.reverse()

	link_task = getattr(self, 'link_task', None)
	for x in out:
		y = self.bld.get_tgen_by_name(x)
		var = y.tmp_use_var
		if var and link_task:
			if var == 'LIB' or y.tmp_use_stlib:
				self.env.append_value(var, [y.target[y.target.rfind(os.sep) + 1:]])
				self.link_task.dep_nodes.extend(y.link_task.outputs)
				tmp_path = y.link_task.outputs[0].parent.path_from(self.bld.bldnode)
				self.env.append_value(var + 'PATH', [tmp_path])
		else:
			if y.tmp_use_objects:
				self.add_objects_from_tgen(y)

		if getattr(y, 'export_includes', None):
			self.includes.extend(y.to_incnodes(y.export_includes))

	# and finally, add the uselib variables (no recursion needed)
	for x in names:
		try:
			y = self.bld.get_tgen_by_name(x)
		except:
			if not self.env['STLIB_' + x] and not x in self.uselib:
				self.uselib.append(x)
		else:
			for k in self.to_list(getattr(y, 'uselib', [])):
				if not self.env['STLIB_' + k] and not k in self.uselib:
					self.uselib.append(k)

@taskgen_method
def add_objects_from_tgen(self, tg):
	# Not public yet, wait for waf 1.6.7 at least - the purpose of this is to add pdb files to the compiled
	# tasks but not to the link tasks (to avoid errors)
	try:
		link_task = self.link_task
	except AttributeError:
		pass
	else:
		for tsk in getattr(tg, 'compiled_tasks', []):
			for x in tsk.outputs:
				if x.name.endswith('.o') or x.name.endswith('.obj'):
					link_task.inputs.append(x)

@taskgen_method
def get_uselib_vars(self):
	"""
	:return: the *uselib* variables associated to the *features* attribute (see :py:attr:`waflib.Tools.ccroot.USELIB_VARS`)
	:rtype: list of string
	"""
	_vars = set([])
	for x in self.features:
		if x in USELIB_VARS:
			_vars |= USELIB_VARS[x]
	return _vars

@feature('c', 'cxx', 'd', 'fc', 'javac', 'cs', 'uselib')
@after_method('process_use')
def propagate_uselib_vars(self):
	"""
	Process uselib variables for adding flags. For example, the following target::

		def build(bld):
			bld.env.AFLAGS_aaa = ['bar']
			from waflib.Tools.ccroot import USELIB_VARS
			USELIB_VARS['aaa'] = set('AFLAGS')

			tg = bld(features='aaa', aflags='test')

	The *aflags* attribute will be processed and this method will set::

			tg.env.AFLAGS = ['bar', 'test']
	"""
	_vars = self.get_uselib_vars()
	env = self.env

	for x in _vars:
		y = x.lower()
		env.append_unique(x, self.to_list(getattr(self, y, [])))

	for x in self.features:
		for var in _vars:
			compvar = '%s_%s' % (var, x)
			env.append_value(var, env[compvar])

	for x in self.to_list(getattr(self, 'uselib', [])):
		for v in _vars:
			env.append_value(v, env[v + '_' + x])

# ============ the code above must not know anything about import libs ==========

@feature('cshlib', 'cxxshlib', 'fcshlib')
@after_method('apply_link')
def apply_implib(self):
	"""
	Handle dlls and their import libs on Windows-like systems.

	A ``.dll.a`` file called *import library* is generated.
	It must be installed as it is required for linking the library.
	"""
	if not self.env.DEST_BINFMT == 'pe':
		return

	dll = self.link_task.outputs[0]
	if isinstance(self.target, Node.Node):
		name = self.target.name
	else:
		name = os.path.split(self.target)[1]
	implib = self.env['implib_PATTERN'] % name
	implib = dll.parent.find_or_declare(implib)
	self.env.append_value('LINKFLAGS', self.env['IMPLIB_ST'] % implib.bldpath())
	self.link_task.outputs.append(implib)

	if getattr(self, 'defs', None) and self.env.DEST_BINFMT == 'pe':
		node = self.path.find_resource(self.defs)
		if not node:
			raise Errors.WafError('invalid def file %r' % self.defs)
		if 'msvc' in (self.env.CC_NAME, self.env.CXX_NAME):
			self.env.append_value('LINKFLAGS', '/def:%s' % node.path_from(self.bld.bldnode))
			self.link_task.dep_nodes.append(node)
		else:
			#gcc for windows takes *.def file a an input without any special flag
			self.link_task.inputs.append(node)

	try:
		inst_to = self.install_path
	except AttributeError:
		inst_to = self.link_task.__class__.inst_to
	if not inst_to:
		return

	self.implib_install_task = self.bld.install_as('${PREFIX}/lib/%s' % implib.name, implib, self.env)

# ============ the code above must not know anything about vnum processing on unix platforms =========

@feature('cshlib', 'cxxshlib', 'dshlib', 'fcshlib', 'vnum')
@after_method('apply_link')
def apply_vnum(self):
	"""
	Enforce version numbering on shared libraries. The valid version numbers must have at most two dots::

		def build(bld):
			bld.shlib(source='a.c', target='foo', vnum='14.15.16')

	In this example, ``libfoo.so`` is installed as ``libfoo.so.1.2.3``, and the following symbolic links are created:

	* ``libfoo.so   â†’ libfoo.so.1.2.3``
	* ``libfoo.so.1 â†’ libfoo.so.1.2.3``
	"""
	if not getattr(self, 'vnum', '') or os.name != 'posix' or self.env.DEST_BINFMT not in ('elf', 'mac-o'):
		return

	link = self.link_task
	nums = self.vnum.split('.')
	node = link.outputs[0]

	libname = node.name
	if libname.endswith('.dylib'):
		name3 = libname.replace('.dylib', '.%s.dylib' % self.vnum)
		name2 = libname.replace('.dylib', '.%s.dylib' % nums[0])
	else:
		name3 = libname + '.' + self.vnum
		name2 = libname + '.' + nums[0]

	# add the so name for the ld linker - to disable, just unset env.SONAME_ST
	if self.env.SONAME_ST:
		v = self.env.SONAME_ST % name2
		self.env.append_value('LINKFLAGS', v.split())

	# the following task is just to enable execution from the build dir :-/
	tsk = self.create_task('vnum', node, [node.parent.find_or_declare(name2), node.parent.find_or_declare(name3)])

	if getattr(self.bld, 'is_install', None):
		self.install_task.hasrun = Task.SKIP_ME
		bld = self.bld
		path = self.install_task.dest
		t1 = bld.install_as(path + os.sep + name3, node, env=self.env, chmod=self.link_task.chmod)
		t2 = bld.symlink_as(path + os.sep + name2, name3)
		t3 = bld.symlink_as(path + os.sep + libname, name3)
		self.vnum_install_task = (t1, t2, t3)

	if '-dynamiclib' in self.env['LINKFLAGS'] and getattr(self, 'install_task', None):
		path = os.path.join(self.install_task.get_install_path(), self.link_task.outputs[0].name)
		self.env.append_value('LINKFLAGS', ['-install_name', path])

class vnum(Task.Task):
	"""
	Create the symbolic links for a versioned shared library. Instances are created by :py:func:`waflib.Tools.ccroot.apply_vnum`
	"""
	color = 'CYAN'
	quient = True
	ext_in = ['.bin']
	def run(self):
		for x in self.outputs:
			path = x.abspath()
			try:
				os.remove(path)
			except OSError:
				pass

			try:
				os.symlink(self.inputs[0].name, path)
			except OSError:
				return 1

class fake_shlib(link_task):
	"""
	Task used for reading a system library and adding the dependency on it
	"""
	def runnable_status(self):
		for t in self.run_after:
			if not t.hasrun:
				return Task.ASK_LATER

		for x in self.outputs:
			x.sig = Utils.h_file(x.abspath())
		return Task.SKIP_ME

class fake_stlib(stlink_task):
	"""
	Task used for reading a system library and adding the dependency on it
	"""
	def runnable_status(self):
		for t in self.run_after:
			if not t.hasrun:
				return Task.ASK_LATER

		for x in self.outputs:
			x.sig = Utils.h_file(x.abspath())
		return Task.SKIP_ME

@conf
def read_shlib(self, name, paths=[]):
	"""
	Read a system shared library, enabling its use as a local library. Will trigger a rebuild if the file changes::

		def build(bld):
			bld.read_shlib('m')
			bld.program(source='main.c', use='m')
	"""
	return self(name=name, features='fake_lib', lib_paths=paths, lib_type='shlib')

@conf
def read_stlib(self, name, paths=[]):
	"""
	Read a system static library, enabling a use as a local library. Will trigger a rebuild if the file changes.
	"""
	return self(name=name, features='fake_lib', lib_paths=paths, lib_type='stlib')

lib_patterns = {
	'shlib' : ['lib%s.so', '%s.so', 'lib%s.dll', '%s.dll'],
	'stlib' : ['lib%s.a', '%s.a', 'lib%s.dll', '%s.dll', 'lib%s.lib', '%s.lib'],
}

@feature('fake_lib')
def process_lib(self):
	"""
	Find the location of a foreign library. Used by :py:class:`waflib.Tools.ccroot.read_shlib` and :py:class:`waflib.Tools.ccroot.read_stlib`.
	"""
	node = None

	names = [x % self.name for x in lib_patterns[self.lib_type]]
	for x in self.lib_paths + [self.path, '/usr/lib64', '/usr/lib', '/usr/local/lib64', '/usr/local/lib']:
		if not isinstance(x, Node.Node):
			x = self.bld.root.find_node(x) or self.path.find_node(x)
			if not x:
				continue

		for y in names:
			node = x.find_node(y)
			if node:
				node.sig = Utils.h_file(node.abspath())
				break
		else:
			continue
		break
	else:
		raise Errors.WafError('could not find library %r' % self.name)
	self.link_task = self.create_task('fake_%s' % self.lib_type, [], [node])
	self.target = self.name


class fake_o(Task.Task):
	def runnable_status(self):
		return Task.SKIP_ME

@extension('.o', '.obj')
def add_those_o_files(self, node):
	tsk = self.create_task('fake_o', [], node)
	try:
		self.compiled_tasks.append(tsk)
	except AttributeError:
		self.compiled_tasks = [tsk]


########NEW FILE########
__FILENAME__ = c_aliases
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2005-2010 (ita)

"base for all c/c++ programs and libraries"

import os, sys, re
from waflib import Utils, Build
from waflib.Configure import conf

def get_extensions(lst):
	"""
	:param lst: files to process
	:list lst: list of string or :py:class:`waflib.Node.Node`
	:return: list of file extensions
	:rtype: list of string
	"""
	ret = []
	for x in Utils.to_list(lst):
		try:
			if not isinstance(x, str):
				x = x.name
			ret.append(x[x.rfind('.') + 1:])
		except:
			pass
	return ret

def sniff_features(**kw):
	"""
	Look at the source files and return the features for a task generator (mainly cc and cxx)::

		snif_features(source=['foo.c', 'foo.cxx'], type='shlib')
		# returns  ['cxx', 'c', 'cxxshlib', 'cshlib']

	:param source: source files to process
	:type source: list of string or :py:class:`waflib.Node.Node`
	:param type: object type in *program*, *shlib* or *stlib*
	:type type: string
	:return: the list of features for a task generator processing the source files
	:rtype: list of string
	"""
	exts = get_extensions(kw['source'])
	type = kw['_type']
	feats = []

	# watch the order, cxx will have the precedence
	if 'cxx' in exts or 'cpp' in exts or 'c++' in exts or 'cc' in exts or 'C' in exts:
		feats.append('cxx')

	if 'c' in exts or 'vala' in exts:
		feats.append('c')

	if 'd' in exts:
		feats.append('d')

	if 'java' in exts:
		feats.append('java')

	if 'java' in exts:
		return 'java'

	if type in ['program', 'shlib', 'stlib']:
		for x in feats:
			if x in ['cxx', 'd', 'c']:
				feats.append(x + type)

	return feats

def set_features(kw, _type):
	kw['_type'] = _type
	kw['features'] = Utils.to_list(kw.get('features', [])) + Utils.to_list(sniff_features(**kw))

@conf
def program(bld, *k, **kw):
	"""
	Alias for creating programs by looking at the file extensions::

		def build(bld):
			bld.program(source='foo.c', target='app')
			# equivalent to:
			# bld(features='c cprogram', source='foo.c', target='app')

	"""
	set_features(kw, 'program')
	return bld(*k, **kw)

@conf
def shlib(bld, *k, **kw):
	"""
	Alias for creating shared libraries by looking at the file extensions::

		def build(bld):
			bld.shlib(source='foo.c', target='app')
			# equivalent to:
			# bld(features='c cshlib', source='foo.c', target='app')

	"""
	set_features(kw, 'shlib')
	return bld(*k, **kw)

@conf
def stlib(bld, *k, **kw):
	"""
	Alias for creating static libraries by looking at the file extensions::

		def build(bld):
			bld.stlib(source='foo.cpp', target='app')
			# equivalent to:
			# bld(features='cxx cxxstlib', source='foo.cpp', target='app')

	"""
	set_features(kw, 'stlib')
	return bld(*k, **kw)

@conf
def objects(bld, *k, **kw):
	"""
	Alias for creating object files by looking at the file extensions::

		def build(bld):
			bld.objects(source='foo.c', target='app')
			# equivalent to:
			# bld(features='c', source='foo.c', target='app')

	"""
	set_features(kw, 'objects')
	return bld(*k, **kw)


########NEW FILE########
__FILENAME__ = c_config
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2005-2010 (ita)

"""
C/C++/D configuration helpers
"""

import os, imp, sys, re, shlex, shutil
from waflib import Build, Utils, Configure, Task, Options, Logs, TaskGen, Errors, ConfigSet, Runner
from waflib.TaskGen import before_method, after_method, feature
from waflib.Configure import conf

WAF_CONFIG_H   = 'config.h'
"""default name for the config.h file"""

DEFKEYS = 'define_key'
INCKEYS = 'include_key'

cfg_ver = {
	'atleast-version': '>=',
	'exact-version': '==',
	'max-version': '<=',
}

SNIP_FUNCTION = '''
	int main() {
	void *p;
	p=(void*)(%s);
	return 0;
}
'''
"""Code template for checking for functions"""

SNIP_TYPE = '''
int main() {
	if ((%(type_name)s *) 0) return 0;
	if (sizeof (%(type_name)s)) return 0;
}
'''
"""Code template for checking for types"""

SNIP_CLASS = '''
int main() {
	if (
}
'''

SNIP_EMPTY_PROGRAM = '''
int main() {
	return 0;
}
'''

SNIP_FIELD = '''
int main() {
	char *off;
	off = (char*) &((%(type_name)s*)0)->%(field_name)s;
	return (size_t) off < sizeof(%(type_name)s);
}
'''

MACRO_TO_DESTOS = {
'__linux__'                                      : 'linux',
'__GNU__'                                        : 'gnu', # hurd
'__FreeBSD__'                                    : 'freebsd',
'__NetBSD__'                                     : 'netbsd',
'__OpenBSD__'                                    : 'openbsd',
'__sun'                                          : 'sunos',
'__hpux'                                         : 'hpux',
'__sgi'                                          : 'irix',
'_AIX'                                           : 'aix',
'__CYGWIN__'                                     : 'cygwin',
'__MSYS__'                                       : 'msys',
'_UWIN'                                          : 'uwin',
'_WIN64'                                         : 'win32',
'_WIN32'                                         : 'win32',
# Note about darwin: this is also tested with 'defined __APPLE__ && defined __MACH__' somewhere below in this file.
'__ENVIRONMENT_MAC_OS_X_VERSION_MIN_REQUIRED__'  : 'darwin', 
'__ENVIRONMENT_IPHONE_OS_VERSION_MIN_REQUIRED__' : 'darwin', # iphone
'__QNX__'                                        : 'qnx',
'__native_client__'                              : 'nacl' # google native client platform
}

MACRO_TO_DEST_CPU = {
'__x86_64__'  : 'x86_64',
'__i386__'    : 'x86',
'__ia64__'    : 'ia',
'__mips__'    : 'mips',
'__sparc__'   : 'sparc',
'__alpha__'   : 'alpha',
'__arm__'     : 'arm',
'__hppa__'    : 'hppa',
'__powerpc__' : 'powerpc',
}

@conf
def parse_flags(self, line, uselib, env=None, force_static=False):
	"""
	Parse the flags from the input lines, and add them to the relevant use variables::

		def configure(conf):
			conf.parse_flags('-O3', uselib_store='FOO')
			# conf.env.CXXFLAGS_FOO = ['-O3']
			# conf.env.CFLAGS_FOO = ['-O3']

	:param line: flags
	:type line: string
	:param uselib: where to add the flags
	:type uselib: string
	:param env: config set or conf.env by default
	:type env: :py:class:`waflib.ConfigSet.ConfigSet`
	"""

	assert(isinstance(line, str))

	env = env or self.env

	# append_unique is not always possible
	# for example, apple flags may require both -arch i386 and -arch ppc

	app = env.append_value
	appu = env.append_unique
	#lst = shlex.split(line)
	# issue #811
	lex = shlex.shlex(line, posix=False)
	lex.whitespace_split = True
	lex.commenters = ''
	lst = list(lex)

	while lst:
		x = lst.pop(0)
		st = x[:2]
		ot = x[2:]

		if st == '-I' or st == '/I':
			if not ot: ot = lst.pop(0)
			appu('INCLUDES_' + uselib, [ot])
		elif st == '-include':
			tmp = [x, lst.pop(0)]
			app('CFLAGS', tmp)
			app('CXXFLAGS', tmp)
		elif st == '-D' or (self.env.CXX_NAME == 'msvc' and st == '/D'): # not perfect but..
			if not ot: ot = lst.pop(0)
			app('DEFINES_' + uselib, [ot])
		elif st == '-l':
			if not ot: ot = lst.pop(0)
			prefix = force_static and 'STLIB_' or 'LIB_'
			appu(prefix + uselib, [ot])
		elif st == '-L':
			if not ot: ot = lst.pop(0)
			appu('LIBPATH_' + uselib, [ot])
		elif x == '-pthread' or x.startswith('+') or x.startswith('-std'):
			app('CFLAGS_' + uselib, [x])
			app('CXXFLAGS_' + uselib, [x])
			app('LINKFLAGS_' + uselib, [x])
		elif x == '-framework':
			appu('FRAMEWORK_' + uselib, [lst.pop(0)])
		elif x.startswith('-F'):
			appu('FRAMEWORKPATH_' + uselib, [x[2:]])
		elif x.startswith('-Wl'):
			app('LINKFLAGS_' + uselib, [x])
		elif x.startswith('-m') or x.startswith('-f') or x.startswith('-dynamic'):
			app('CFLAGS_' + uselib, [x])
			app('CXXFLAGS_' + uselib, [x])
		elif x.startswith('-bundle'):
			app('LINKFLAGS_' + uselib, [x])
		elif x.startswith('-undefined'):
			arg = lst.pop(0)
			app('LINKFLAGS_' + uselib, [x, arg])
		elif x.startswith('-arch') or x.startswith('-isysroot'):
			tmp = [x, lst.pop(0)]
			app('CFLAGS_' + uselib, tmp)
			app('CXXFLAGS_' + uselib, tmp)
			app('LINKFLAGS_' + uselib, tmp)
		elif x.endswith('.a') or x.endswith('.so') or x.endswith('.dylib'):
			appu('LINKFLAGS_' + uselib, [x]) # not cool, #762

@conf
def ret_msg(self, f, kw):
	if isinstance(f, str):
		return f
	return f(kw)

@conf
def validate_cfg(self, kw):
	"""
	Search for the program *pkg-config* if missing, and validate the parameters to pass to
	:py:func:`waflib.Tools.c_config.exec_cfg`.

	:param path: the **-config program to use** (default is *pkg-config*)
	:type path: list of string
	:param msg: message to display to describe the test executed
	:type msg: string
	:param okmsg: message to display when the test is successful
	:type okmsg: string
	:param errmsg: message to display in case of error
	:type errmsg: string
	"""
	if not 'path' in kw:
		if not self.env.PKGCONFIG:
			self.find_program('pkg-config', var='PKGCONFIG')
		kw['path'] = self.env.PKGCONFIG

	# pkg-config version
	if 'atleast_pkgconfig_version' in kw:
		if not 'msg' in kw:
			kw['msg'] = 'Checking for pkg-config version >= %r' % kw['atleast_pkgconfig_version']
		return

	if not 'okmsg' in kw:
		kw['okmsg'] = 'yes'
	if not 'errmsg' in kw:
		kw['errmsg'] = 'not found'

	if 'modversion' in kw:
		if not 'msg' in kw:
			kw['msg'] = 'Checking for %r version' % kw['modversion']
		return

	# checking for the version of a module, for the moment, one thing at a time
	for x in cfg_ver.keys():
		y = x.replace('-', '_')
		if y in kw:
			if not 'package' in kw:
				raise ValueError('%s requires a package' % x)

			if not 'msg' in kw:
				kw['msg'] = 'Checking for %r %s %s' % (kw['package'], cfg_ver[x], kw[y])
			return

	if not 'msg' in kw:
		kw['msg'] = 'Checking for %r' % (kw['package'] or kw['path'])

@conf
def exec_cfg(self, kw):
	"""
	Execute the program *pkg-config*:

	* if atleast_pkgconfig_version is given, check that pkg-config has the version n and return
	* if modversion is given, then return the module version
	* else, execute the *-config* program with the *args* and *variables* given, and set the flags on the *conf.env.FLAGS_name* variable

	:param atleast_pkgconfig_version: minimum pkg-config version to use (disable other tests)
	:type atleast_pkgconfig_version: string
	:param package: package name, for example *gtk+-2.0*
	:type package: string
	:param uselib_store: if the test is successful, define HAVE\_*name*. It is also used to define *conf.env.FLAGS_name* variables.
	:type uselib_store: string
	:param modversion: if provided, return the version of the given module and define *name*\_VERSION
	:type modversion: string
	:param args: arguments to give to *package* when retrieving flags
	:type args: list of string
	:param variables: return the values of particular variables
	:type variables: list of string
	:param define_variable: additional variables to define (also in conf.env.PKG_CONFIG_DEFINES)
	:type define_variable: dict(string: string)
	"""

	# pkg-config version
	if 'atleast_pkgconfig_version' in kw:
		cmd = [kw['path'], '--atleast-pkgconfig-version=%s' % kw['atleast_pkgconfig_version']]
		self.cmd_and_log(cmd)
		if not 'okmsg' in kw:
			kw['okmsg'] = 'yes'
		return

	# checking for the version of a module
	for x in cfg_ver:
		y = x.replace('-', '_')
		if y in kw:
			self.cmd_and_log([kw['path'], '--%s=%s' % (x, kw[y]), kw['package']])
			if not 'okmsg' in kw:
				kw['okmsg'] = 'yes'
			self.define(self.have_define(kw.get('uselib_store', kw['package'])), 1, 0)
			break

	# retrieving the version of a module
	if 'modversion' in kw:
		version = self.cmd_and_log([kw['path'], '--modversion', kw['modversion']]).strip()
		self.define('%s_VERSION' % Utils.quote_define_name(kw.get('uselib_store', kw['modversion'])), version)
		return version

	lst = [kw['path']]

	defi = kw.get('define_variable', None)
	if not defi:
		defi = self.env.PKG_CONFIG_DEFINES or {}
	for key, val in defi.items():
		lst.append('--define-variable=%s=%s' % (key, val))

	if kw['package']:
		lst.extend(Utils.to_list(kw['package']))

	# retrieving variables of a module
	if 'variables' in kw:
		env = kw.get('env', self.env)
		uselib = kw.get('uselib_store', kw['package'].upper())
		vars = Utils.to_list(kw['variables'])
		for v in vars:
			val = self.cmd_and_log(lst + ['--variable=' + v]).strip()
			var = '%s_%s' % (uselib, v)
			env[var] = val
		if not 'okmsg' in kw:
			kw['okmsg'] = 'yes'
		return

	static = False
	if 'args' in kw:
		args = Utils.to_list(kw['args'])
		if '--static' in args or '--static-libs' in args:
			static = True
		lst += args
	# so we assume the command-line will output flags to be parsed afterwards
	ret = self.cmd_and_log(lst)
	if not 'okmsg' in kw:
		kw['okmsg'] = 'yes'

	self.define(self.have_define(kw.get('uselib_store', kw['package'])), 1, 0)
	self.parse_flags(ret, kw.get('uselib_store', kw['package'].upper()), kw.get('env', self.env), force_static=static)
	return ret

@conf
def check_cfg(self, *k, **kw):
	"""
	Check for configuration flags using a **-config**-like program (pkg-config, sdl-config, etc).
	Encapsulate the calls to :py:func:`waflib.Tools.c_config.validate_cfg` and :py:func:`waflib.Tools.c_config.exec_cfg`

	A few examples::

		def configure(conf):
			conf.load('compiler_c')
			conf.check_cfg(package='glib-2.0', args='--libs --cflags')
			conf.check_cfg(package='glib-2.0', uselib_store='GLIB', atleast_version='2.10.0',
				args='--cflags --libs')
			conf.check_cfg(package='pango')
			conf.check_cfg(package='pango', uselib_store='MYPANGO', args=['--cflags', '--libs'])
			conf.check_cfg(package='pango',
				args=['pango >= 0.1.0', 'pango < 9.9.9', '--cflags', '--libs'],
				msg="Checking for 'pango 0.1.0'")
			conf.check_cfg(path='sdl-config', args='--cflags --libs', package='', uselib_store='SDL')
			conf.check_cfg(path='mpicc', args='--showme:compile --showme:link',
				package='', uselib_store='OPEN_MPI', mandatory=False)

	"""
	if k:
		lst = k[0].split()
		kw['package'] = lst[0]
		kw['args'] = ' '.join(lst[1:])

	self.validate_cfg(kw)
	if 'msg' in kw:
		self.start_msg(kw['msg'])
	ret = None
	try:
		ret = self.exec_cfg(kw)
	except self.errors.WafError as e:
		if 'errmsg' in kw:
			self.end_msg(kw['errmsg'], 'YELLOW')
		if Logs.verbose > 1:
			raise
		else:
			self.fatal('The configuration failed')
	else:
		kw['success'] = ret
		if 'okmsg' in kw:
			self.end_msg(self.ret_msg(kw['okmsg'], kw))

	return ret

@conf
def validate_c(self, kw):
	"""
	pre-check the parameters that will be given to run_c_code

	:param env: an optional environment (modified -> provide a copy)
	:type env: :py:class:`waflib.ConfigSet.ConfigSet`
	:param compiler: c or cxx (tries to guess what is best)
	:type compiler: string
	:param type: cprogram, cshlib, cstlib - not required if *features are given directly*
	:type type: binary to create
	:param feature: desired features for the task generator that will execute the test, for example ``cxx cxxstlib``
	:type feature: list of string
	:param fragment: provide a piece of code for the test (default is to let the system create one)
	:type fragment: string
	:param uselib_store: define variables after the test is executed (IMPORTANT!)
	:type uselib_store: string
	:param use: parameters to use for building (just like the normal *use* keyword)
	:type use: list of string
	:param define_name: define to set when the check is over
	:type define_name: string
	:param execute: execute the resulting binary
	:type execute: bool
	:param define_ret: if execute is set to True, use the execution output in both the define and the return value
	:type define_ret: bool
	:param header_name: check for a particular header
	:type header_name: string
	:param auto_add_header_name: if header_name was set, add the headers in env.INCKEYS so the next tests will include these headers
	:type auto_add_header_name: bool
	"""

	if not 'env' in kw:
		kw['env'] = self.env.derive()
	env = kw['env']

	if not 'compiler' in kw and not 'features' in kw:
		kw['compiler'] = 'c'
		if env['CXX_NAME'] and Task.classes.get('cxx', None):
			kw['compiler'] = 'cxx'
			if not self.env['CXX']:
				self.fatal('a c++ compiler is required')
		else:
			if not self.env['CC']:
				self.fatal('a c compiler is required')

	if not 'compile_mode' in kw:
		kw['compile_mode'] = 'c'
		if 'cxx' in Utils.to_list(kw.get('features',[])) or kw.get('compiler', '') == 'cxx':
			kw['compile_mode'] = 'cxx'

	if not 'type' in kw:
		kw['type'] = 'cprogram'

	if not 'features' in kw:
		kw['features'] = [kw['compile_mode'], kw['type']] # "cprogram c"
	else:
		kw['features'] = Utils.to_list(kw['features'])

	if not 'compile_filename' in kw:
		kw['compile_filename'] = 'test.c' + ((kw['compile_mode'] == 'cxx') and 'pp' or '')


	def to_header(dct):
		if 'header_name' in dct:
			dct = Utils.to_list(dct['header_name'])
			return ''.join(['#include <%s>\n' % x for x in dct])
		return ''

	#OSX
	if 'framework_name' in kw:
		fwkname = kw['framework_name']
		if not 'uselib_store' in kw:
			kw['uselib_store'] = fwkname.upper()

		if not kw.get('no_header', False):
			if not 'header_name' in kw:
				kw['header_name'] = []
			fwk = '%s/%s.h' % (fwkname, fwkname)
			if kw.get('remove_dot_h', None):
				fwk = fwk[:-2]
			kw['header_name'] = Utils.to_list(kw['header_name']) + [fwk]

		kw['msg'] = 'Checking for framework %s' % fwkname
		kw['framework'] = fwkname
		#kw['frameworkpath'] = set it yourself

	if 'function_name' in kw:
		fu = kw['function_name']
		if not 'msg' in kw:
			kw['msg'] = 'Checking for function %s' % fu
		kw['code'] = to_header(kw) + SNIP_FUNCTION % fu
		if not 'uselib_store' in kw:
			kw['uselib_store'] = fu.upper()
		if not 'define_name' in kw:
			kw['define_name'] = self.have_define(fu)

	elif 'type_name' in kw:
		tu = kw['type_name']
		if not 'header_name' in kw:
			kw['header_name'] = 'stdint.h'
		if 'field_name' in kw:
			field = kw['field_name']
			kw['code'] = to_header(kw) + SNIP_FIELD % {'type_name' : tu, 'field_name' : field}
			if not 'msg' in kw:
				kw['msg'] = 'Checking for field %s in %s' % (field, tu)
			if not 'define_name' in kw:
				kw['define_name'] = self.have_define((tu + '_' + field).upper())
		else:
			kw['code'] = to_header(kw) + SNIP_TYPE % {'type_name' : tu}
			if not 'msg' in kw:
				kw['msg'] = 'Checking for type %s' % tu
			if not 'define_name' in kw:
				kw['define_name'] = self.have_define(tu.upper())

	elif 'header_name' in kw:
		if not 'msg' in kw:
			kw['msg'] = 'Checking for header %s' % kw['header_name']

		l = Utils.to_list(kw['header_name'])
		assert len(l)>0, 'list of headers in header_name is empty'

		kw['code'] = to_header(kw) + SNIP_EMPTY_PROGRAM

		if not 'uselib_store' in kw:
			kw['uselib_store'] = l[0].upper()

		if not 'define_name' in kw:
			kw['define_name'] = self.have_define(l[0])

	if 'lib' in kw:
		if not 'msg' in kw:
			kw['msg'] = 'Checking for library %s' % kw['lib']
		if not 'uselib_store' in kw:
			kw['uselib_store'] = kw['lib'].upper()

	if 'stlib' in kw:
		if not 'msg' in kw:
			kw['msg'] = 'Checking for static library %s' % kw['stlib']
		if not 'uselib_store' in kw:
			kw['uselib_store'] = kw['stlib'].upper()

	if 'fragment' in kw:
		# an additional code fragment may be provided to replace the predefined code
		# in custom headers
		kw['code'] = kw['fragment']
		if not 'msg' in kw:
			kw['msg'] = 'Checking for code snippet'
		if not 'errmsg' in kw:
			kw['errmsg'] = 'no'

	for (flagsname,flagstype) in [('cxxflags','compiler'), ('cflags','compiler'), ('linkflags','linker')]:
		if flagsname in kw:
			if not 'msg' in kw:
				kw['msg'] = 'Checking for %s flags %s' % (flagstype, kw[flagsname])
			if not 'errmsg' in kw:
				kw['errmsg'] = 'no'

	if not 'execute' in kw:
		kw['execute'] = False
	if kw['execute']:
		kw['features'].append('test_exec')

	if not 'errmsg' in kw:
		kw['errmsg'] = 'not found'

	if not 'okmsg' in kw:
		kw['okmsg'] = 'yes'

	if not 'code' in kw:
		kw['code'] = SNIP_EMPTY_PROGRAM

	# if there are headers to append automatically to the next tests
	if self.env[INCKEYS]:
		kw['code'] = '\n'.join(['#include <%s>' % x for x in self.env[INCKEYS]]) + '\n' + kw['code']

	if not kw.get('success'): kw['success'] = None

	if 'define_name' in kw:
		self.undefine(kw['define_name'])

	assert 'msg' in kw, 'invalid parameters, read http://freehackers.org/~tnagy/wafbook/single.html#config_helpers_c'

@conf
def post_check(self, *k, **kw):
	"Set the variables after a test executed in :py:func:`waflib.Tools.c_config.check` was run successfully"

	is_success = 0
	if kw['execute']:
		if kw['success'] is not None:
			if kw.get('define_ret', False):
				is_success = kw['success']
			else:
				is_success = (kw['success'] == 0)
	else:
		is_success = (kw['success'] == 0)

	if 'define_name' in kw:
		# TODO simplify?
		if 'header_name' in kw or 'function_name' in kw or 'type_name' in kw or 'fragment' in kw:
			nm = kw['define_name']
			if kw['execute'] and kw.get('define_ret', None) and isinstance(is_success, str):
				self.define(kw['define_name'], is_success, quote=kw.get('quote', 1))
			else:
				self.define_cond(kw['define_name'], is_success)
		else:
			self.define_cond(kw['define_name'], is_success)

	if 'header_name' in kw:
		if kw.get('auto_add_header_name', False):
			self.env.append_value(INCKEYS, Utils.to_list(kw['header_name']))

	if is_success and 'uselib_store' in kw:
		from waflib.Tools import ccroot

		# TODO see get_uselib_vars from ccroot.py
		_vars = set([])
		for x in kw['features']:
			if x in ccroot.USELIB_VARS:
				_vars |= ccroot.USELIB_VARS[x]

		for k in _vars:
			lk = k.lower()
			if k == 'INCLUDES': lk = 'includes'
			if k == 'DEFINES': lk = 'defines'
			if lk in kw:
				val = kw[lk]
				# remove trailing slash
				if isinstance(val, str):
					val = val.rstrip(os.path.sep)
				self.env.append_unique(k + '_' + kw['uselib_store'], val)
	return is_success

@conf
def check(self, *k, **kw):
	"""
	Perform a configuration test by calling :py:func:`waflib.Tools.c_config.run_c_code`.
	For the complete list of parameters, see :py:func:`waflib.Tools.c_config.validate_c`.
	To force a specific compiler, prefer the methods :py:func:`waflib.Tools.c_config.check_cxx` or :py:func:`waflib.Tools.c_config.check_cc`
	"""
	self.validate_c(kw)
	self.start_msg(kw['msg'])
	ret = None
	try:
		ret = self.run_c_code(*k, **kw)
	except self.errors.ConfigurationError as e:
		self.end_msg(kw['errmsg'], 'YELLOW')
		if Logs.verbose > 1:
			raise
		else:
			self.fatal('The configuration failed')
	else:
		kw['success'] = ret
		self.end_msg(self.ret_msg(kw['okmsg'], kw))

	ret = self.post_check(*k, **kw)
	if not ret:
		self.fatal('The configuration failed %r' % ret)
	return ret

class test_exec(Task.Task):
	"""
	A task for executing a programs after they are built. See :py:func:`waflib.Tools.c_config.test_exec_fun`.
	"""
	color = 'PINK'
	def run(self):
		if getattr(self.generator, 'rpath', None):
			if getattr(self.generator, 'define_ret', False):
				self.generator.bld.retval = self.generator.bld.cmd_and_log([self.inputs[0].abspath()])
			else:
				self.generator.bld.retval = self.generator.bld.exec_command([self.inputs[0].abspath()])
		else:
			env = self.env.env or {}
			env.update(dict(os.environ))
			for var in ('LD_LIBRARY_PATH', 'DYLD_LIBRARY_PATH', 'PATH'):
				env[var] = self.inputs[0].parent.abspath() + os.path.pathsep + env.get(var, '')
			if getattr(self.generator, 'define_ret', False):
				self.generator.bld.retval = self.generator.bld.cmd_and_log([self.inputs[0].abspath()], env=env)
			else:
				self.generator.bld.retval = self.generator.bld.exec_command([self.inputs[0].abspath()], env=env)

@feature('test_exec')
@after_method('apply_link')
def test_exec_fun(self):
	"""
	The feature **test_exec** is used to create a task that will to execute the binary
	created (link task output) during the build. The exit status will be set
	on the build context, so only one program may have the feature *test_exec*.
	This is used by configuration tests::

		def configure(conf):
			conf.check(execute=True)
	"""
	self.create_task('test_exec', self.link_task.outputs[0])

CACHE_RESULTS = 1
COMPILE_ERRORS = 2

@conf
def run_c_code(self, *k, **kw):
	"""
	Create a temporary build context to execute a build. A reference to that build
	context is kept on self.test_bld for debugging purposes, and you should not rely
	on it too much (read the note on the cache below).
	The parameters given in the arguments to this function are passed as arguments for
	a single task generator created in the build. Only three parameters are obligatory:

	:param features: features to pass to a task generator created in the build
	:type features: list of string
	:param compile_filename: file to create for the compilation (default: *test.c*)
	:type compile_filename: string
	:param code: code to write in the filename to compile
	:type code: string

	Though this function returns *0* by default, the build may set an attribute named *retval* on the
	build context object to return a particular value. See :py:func:`waflib.Tools.c_config.test_exec_fun` for example.

	This function also provides a limited cache. To use it, provide the following option::

		def options(opt):
			opt.add_option('--confcache', dest='confcache', default=0,
				action='count', help='Use a configuration cache')

	And execute the configuration with the following command-line::

		$ waf configure --confcache

	"""

	lst = [str(v) for (p, v) in kw.items() if p != 'env']
	h = Utils.h_list(lst)
	dir = self.bldnode.abspath() + os.sep + (not Utils.is_win32 and '.' or '') + 'conf_check_' + Utils.to_hex(h)

	try:
		os.makedirs(dir)
	except:
		pass

	try:
		os.stat(dir)
	except:
		self.fatal('cannot use the configuration test folder %r' % dir)

	cachemode = getattr(Options.options, 'confcache', None)
	if cachemode == CACHE_RESULTS:
		try:
			proj = ConfigSet.ConfigSet(os.path.join(dir, 'cache_run_c_code'))
			ret = proj['cache_run_c_code']
		except:
			pass
		else:
			if isinstance(ret, str) and ret.startswith('Test does not build'):
				self.fatal(ret)
			return ret

	bdir = os.path.join(dir, 'testbuild')

	if not os.path.exists(bdir):
		os.makedirs(bdir)

	self.test_bld = bld = Build.BuildContext(top_dir=dir, out_dir=bdir)
	bld.init_dirs()
	bld.progress_bar = 0
	bld.targets = '*'

	if kw['compile_filename']:
		node = bld.srcnode.make_node(kw['compile_filename'])
		node.write(kw['code'])

	bld.logger = self.logger
	bld.all_envs.update(self.all_envs) # not really necessary
	bld.env = kw['env']

	o = bld(features=kw['features'], source=kw['compile_filename'], target='testprog')

	for k, v in kw.items():
		setattr(o, k, v)

	self.to_log("==>\n%s\n<==" % kw['code'])

	# compile the program
	bld.targets = '*'

	ret = -1
	try:
		try:
			bld.compile()
		except Errors.WafError:
			ret = 'Test does not build: %s' % Utils.ex_stack()
			self.fatal(ret)
		else:
			ret = getattr(bld, 'retval', 0)
	finally:
		# cache the results each time
		proj = ConfigSet.ConfigSet()
		proj['cache_run_c_code'] = ret
		proj.store(os.path.join(dir, 'cache_run_c_code'))

	return ret

@conf
def check_cxx(self, *k, **kw):
	"""
	Same as :py:func:`waflib.Tools.c_config.check` but default to the *c++* programming language
	"""
	kw['compiler'] = 'cxx'
	return self.check(*k, **kw)

@conf
def check_cc(self, *k, **kw):
	"""
	Same as :py:func:`waflib.Tools.c_config.check` but default to the *c* programming language
	"""
	kw['compiler'] = 'c'
	return self.check(*k, **kw)

@conf
def define(self, key, val, quote=True):
	"""
	Store a single define and its state into conf.env.DEFINES

	:param key: define name
	:type key: string
	:param val: value
	:type val: int or string
	:param quote: enclose strings in quotes (yes by default)
	:type quote: bool
	"""
	assert key and isinstance(key, str)

	if isinstance(val, int) or isinstance(val, float):
		s = '%s=%s'
	else:
		s = quote and '%s="%s"' or '%s=%s'
	app = s % (key, str(val))

	ban = key + '='
	lst = self.env['DEFINES']
	for x in lst:
		if x.startswith(ban):
			lst[lst.index(x)] = app
			break
	else:
		self.env.append_value('DEFINES', app)

	self.env.append_unique(DEFKEYS, key)

@conf
def undefine(self, key):
	"""
	Remove a define from conf.env.DEFINES

	:param key: define name
	:type key: string
	"""
	assert key and isinstance(key, str)

	ban = key + '='
	lst = [x for x in self.env['DEFINES'] if not x.startswith(ban)]
	self.env['DEFINES'] = lst
	self.env.append_unique(DEFKEYS, key)

@conf
def define_cond(self, key, val):
	"""
	Conditionally define a name::

		def configure(conf):
			conf.define_cond('A', True)
			# equivalent to:
			# if val: conf.define('A', 1)
			# else: conf.undefine('A')

	:param key: define name
	:type key: string
	:param val: value
	:type val: int or string
	"""
	assert key and isinstance(key, str)

	if val:
		self.define(key, 1)
	else:
		self.undefine(key)

@conf
def is_defined(self, key):
	"""
	:param key: define name
	:type key: string
	:return: True if the define is set
	:rtype: bool
	"""
	assert key and isinstance(key, str)

	ban = key + '='
	for x in self.env['DEFINES']:
		if x.startswith(ban):
			return True
	return False

@conf
def get_define(self, key):
	"""
	:param key: define name
	:type key: string
	:return: the value of a previously stored define or None if it is not set
	"""
	assert key and isinstance(key, str)

	ban = key + '='
	for x in self.env['DEFINES']:
		if x.startswith(ban):
			return x[len(ban):]
	return None

@conf
def have_define(self, key):
	"""
	:param key: define name
	:type key: string
	:return: the input key prefixed by *HAVE_* and substitute any invalid characters.
	:rtype: string
	"""
	return self.__dict__.get('HAVE_PAT', 'HAVE_%s') % Utils.quote_define_name(key)

@conf
def write_config_header(self, configfile='', guard='', top=False, env=None, defines=True, headers=False, remove=True):
	"""
	Write a configuration header containing defines and includes::

		def configure(cnf):
			cnf.define('A', 1)
			cnf.write_config_header('config.h')

	:param configfile: relative path to the file to create
	:type configfile: string
	:param env: config set to read the definitions from (default is conf.env)
	:type env: :py:class:`waflib.ConfigSet.ConfigSet`
	:param top: write the configuration header from the build directory (default is from the current path)
	:type top: bool
	:param defines: add the defines (yes by default)
	:type defines: bool
	:param headers: add #include in the file
	:type headers: bool
	:param remove: remove the defines after they are added (yes by default)
	:type remove: bool
	"""
	if not configfile: configfile = WAF_CONFIG_H
	waf_guard = guard or '_%s_WAF' % Utils.quote_define_name(configfile)

	node = top and self.bldnode or self.path.get_bld()
	node = node.make_node(configfile)
	node.parent.mkdir()

	lst = ['/* WARNING! All changes made to this file will be lost! */\n']
	lst.append('#ifndef %s\n#define %s\n' % (waf_guard, waf_guard))
	lst.append(self.get_config_header(defines, headers))
	lst.append('\n#endif /* %s */\n' % waf_guard)

	node.write('\n'.join(lst))

	env = env or self.env

	# config files are not removed on "waf clean"
	env.append_unique(Build.CFG_FILES, [node.abspath()])

	if remove:
		for key in self.env[DEFKEYS]:
			self.undefine(key)
		self.env[DEFKEYS] = []

@conf
def get_config_header(self, defines=True, headers=False):
	"""
	Create the contents of a ``config.h`` file from the defines and includes
	set in conf.env.define_key / conf.env.include_key. No include guards are added.

	:param defines: write the defines values
	:type defines: bool
	:param headers: write the headers
	:type headers: bool
	:return: the contents of a ``config.h`` file
	:rtype: string
	"""
	lst = []
	if headers:
		for x in self.env[INCKEYS]:
			lst.append('#include <%s>' % x)

	if defines:
		for x in self.env[DEFKEYS]:
			if self.is_defined(x):
				val = self.get_define(x)
				lst.append('#define %s %s' % (x, val))
			else:
				lst.append('/* #undef %s */' % x)
	return "\n".join(lst)

@conf
def cc_add_flags(conf):
	"""
	Read the CFLAGS/CPPFLAGS from os.environ and add to conf.env.CFLAGS
	"""
	conf.add_os_flags('CPPFLAGS', 'CFLAGS')
	conf.add_os_flags('CFLAGS')

@conf
def cxx_add_flags(conf):
	"""
	Read the CXXFLAGS/CPPFLAGS and add to conf.env.CXXFLAGS
	"""
	conf.add_os_flags('CPPFLAGS', 'CXXFLAGS')
	conf.add_os_flags('CXXFLAGS')

@conf
def link_add_flags(conf):
	"""
	Read the LINKFLAGS/LDFLAGS and add to conf.env.LDFLAGS
	"""
	conf.add_os_flags('LINKFLAGS')
	conf.add_os_flags('LDFLAGS', 'LINKFLAGS')

@conf
def cc_load_tools(conf):
	"""
	Load the c tool
	"""
	if not conf.env.DEST_OS:
		conf.env.DEST_OS = Utils.unversioned_sys_platform()
	conf.load('c')

@conf
def cxx_load_tools(conf):
	"""
	Load the cxx tool
	"""
	if not conf.env.DEST_OS:
		conf.env.DEST_OS = Utils.unversioned_sys_platform()
	conf.load('cxx')

@conf
def get_cc_version(conf, cc, gcc=False, icc=False):
	"""
	Run the preprocessor to determine the compiler version

	The variables CC_VERSION, DEST_OS, DEST_BINFMT and DEST_CPU will be set in *conf.env*
	"""
	cmd = cc + ['-dM', '-E', '-']
	env = conf.env.env or None
	try:
		p = Utils.subprocess.Popen(cmd, stdin=Utils.subprocess.PIPE, stdout=Utils.subprocess.PIPE, stderr=Utils.subprocess.PIPE, env=env)
		p.stdin.write('\n'.encode())
		out = p.communicate()[0]
	except:
		conf.fatal('Could not determine the compiler version %r' % cmd)

	if not isinstance(out, str):
		out = out.decode(sys.stdout.encoding)

	if gcc:
		if out.find('__INTEL_COMPILER') >= 0:
			conf.fatal('The intel compiler pretends to be gcc')
		if out.find('__GNUC__') < 0:
			conf.fatal('Could not determine the compiler type')

	if icc and out.find('__INTEL_COMPILER') < 0:
		conf.fatal('Not icc/icpc')

	k = {}
	if icc or gcc:
		out = out.split('\n')
		for line in out:
			lst = shlex.split(line)
			if len(lst)>2:
				key = lst[1]
				val = lst[2]
				k[key] = val

		def isD(var):
			return var in k

		def isT(var):
			return var in k and k[var] != '0'

		# Some documentation is available at http://predef.sourceforge.net
		# The names given to DEST_OS must match what Utils.unversioned_sys_platform() returns.
		if not conf.env.DEST_OS:
			conf.env.DEST_OS = ''
		for i in MACRO_TO_DESTOS:
			if isD(i):
				conf.env.DEST_OS = MACRO_TO_DESTOS[i]
				break
		else:
			if isD('__APPLE__') and isD('__MACH__'):
				conf.env.DEST_OS = 'darwin'
			elif isD('__unix__'): # unix must be tested last as it's a generic fallback
				conf.env.DEST_OS = 'generic'

		if isD('__ELF__'):
			conf.env.DEST_BINFMT = 'elf'
		elif isD('__WINNT__') or isD('__CYGWIN__'):
			conf.env.DEST_BINFMT = 'pe'
			conf.env.LIBDIR = conf.env['PREFIX'] + '/bin'
		elif isD('__APPLE__'):
			conf.env.DEST_BINFMT = 'mac-o'

		if not conf.env.DEST_BINFMT:
			# Infer the binary format from the os name.
			conf.env.DEST_BINFMT = Utils.destos_to_binfmt(conf.env.DEST_OS)

		for i in MACRO_TO_DEST_CPU:
			if isD(i):
				conf.env.DEST_CPU = MACRO_TO_DEST_CPU[i]
				break

		Logs.debug('ccroot: dest platform: ' + ' '.join([conf.env[x] or '?' for x in ('DEST_OS', 'DEST_BINFMT', 'DEST_CPU')]))
		if icc:
			ver = k['__INTEL_COMPILER']
			conf.env['CC_VERSION'] = (ver[:-2], ver[-2], ver[-1])
		else:
			conf.env['CC_VERSION'] = (k['__GNUC__'], k['__GNUC_MINOR__'], k['__GNUC_PATCHLEVEL__'])
	return k

@conf
def get_xlc_version(conf, cc):
	"""Get the compiler version"""

	version_re = re.compile(r"IBM XL C/C\+\+.*, V(?P<major>\d*)\.(?P<minor>\d*)", re.I).search
	cmd = cc + ['-qversion']

	try:
		out, err = conf.cmd_and_log(cmd, output=0)
	except Errors.WafError:
		conf.fatal('Could not find xlc %r' % cmd)
	if out: match = version_re(out)
	else: match = version_re(err)
	if not match:
		conf.fatal('Could not determine the XLC version.')
	k = match.groupdict()
	conf.env['CC_VERSION'] = (k['major'], k['minor'])

# ============ the --as-needed flag should added during the configuration, not at runtime =========

@conf
def add_as_needed(self):
	"""
	Add ``--as-needed`` to the *LINKFLAGS*
	"""
	if self.env.DEST_BINFMT == 'elf' and 'gcc' in (self.env.CXX_NAME, self.env.CC_NAME):
		self.env.append_unique('LINKFLAGS', '--as-needed')

# ============ parallel configuration

class cfgtask(Task.TaskBase):
	"""
	A task that executes configuration tests
	make sure that the checks write to conf.env in a thread-safe manner

	for the moment it only executes conf.check
	"""
	def display(self):
		return ''

	def runnable_status(self):
		return Task.RUN_ME

	def run(self):
		conf = self.conf
		bld = Build.BuildContext(top_dir=conf.srcnode.abspath(), out_dir=conf.bldnode.abspath())
		bld.env = conf.env
		bld.init_dirs()
		bld.in_msg = 1 # suppress top-level start_msg
		bld.logger = self.logger
		try:
			bld.check(**self.args)
		except:
			return 1

@conf
def multicheck(self, *k, **kw):
	"""
	Use tuples to perform parallel configuration tests
	"""
	self.start_msg(kw.get('msg', 'Executing %d configuration tests' % len(k)))

	class par(object):
		def __init__(self):
			self.keep = False
			self.cache_global = Options.cache_global
			self.nocache = Options.options.nocache
			self.returned_tasks = []
		def total(self):
			return len(tasks)
		def to_log(self, *k, **kw):
			return

	bld = par()
	tasks = []
	for dct in k:
		x = cfgtask(bld=bld)
		tasks.append(x)
		x.args = dct
		x.bld = bld
		x.conf = self
		x.args = dct

		# bind a logger that will keep the info in memory
		x.logger = Logs.make_mem_logger(str(id(x)), self.logger)

	def it():
		yield tasks
		while 1:
			yield []
	p = Runner.Parallel(bld, Options.options.jobs)
	p.biter = it()
	p.start()

	# flush the logs in order into the config.log
	for x in tasks:
		x.logger.memhandler.flush()

	for x in tasks:
		if x.hasrun != Task.SUCCESS:
			self.end_msg(kw.get('errmsg', 'no'), color='YELLOW')
			self.fatal(kw.get('fatalmsg', None) or 'One of the tests has failed, see the config.log for more information')

	self.end_msg('ok')


########NEW FILE########
__FILENAME__ = c_osx
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy 2008-2010

"""
MacOSX related tools
"""

import os, shutil, sys, platform
from waflib import TaskGen, Task, Build, Options, Utils, Errors
from waflib.TaskGen import taskgen_method, feature, after_method, before_method

app_info = '''
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist SYSTEM "file://localhost/System/Library/DTDs/PropertyList.dtd">
<plist version="0.9">
<dict>
	<key>CFBundlePackageType</key>
	<string>APPL</string>
	<key>CFBundleGetInfoString</key>
	<string>Created by Waf</string>
	<key>CFBundleSignature</key>
	<string>????</string>
	<key>NOTE</key>
	<string>THIS IS A GENERATED FILE, DO NOT MODIFY</string>
	<key>CFBundleExecutable</key>
	<string>%s</string>
</dict>
</plist>
'''
"""
plist template
"""

@feature('c', 'cxx')
def set_macosx_deployment_target(self):
	"""
	see WAF issue 285 and also and also http://trac.macports.org/ticket/17059
	"""
	if self.env['MACOSX_DEPLOYMENT_TARGET']:
		os.environ['MACOSX_DEPLOYMENT_TARGET'] = self.env['MACOSX_DEPLOYMENT_TARGET']
	elif 'MACOSX_DEPLOYMENT_TARGET' not in os.environ:
		if Utils.unversioned_sys_platform() == 'darwin':
			os.environ['MACOSX_DEPLOYMENT_TARGET'] = '.'.join(platform.mac_ver()[0].split('.')[:2])

@taskgen_method
def create_bundle_dirs(self, name, out):
	"""
	Create bundle folders, used by :py:func:`create_task_macplist` and :py:func:`create_task_macapp`
	"""
	bld = self.bld
	dir = out.parent.find_or_declare(name)
	dir.mkdir()
	macos = dir.find_or_declare(['Contents', 'MacOS'])
	macos.mkdir()
	return dir

def bundle_name_for_output(out):
	name = out.name
	k = name.rfind('.')
	if k >= 0:
		name = name[:k] + '.app'
	else:
		name = name + '.app'
	return name

@feature('cprogram', 'cxxprogram')
@after_method('apply_link')
def create_task_macapp(self):
	"""
	To compile an executable into a Mac application (a .app), set its *mac_app* attribute::

		def build(bld):
			bld.shlib(source='a.c', target='foo', mac_app = True)

	To force *all* executables to be transformed into Mac applications::

		def build(bld):
			bld.env.MACAPP = True
			bld.shlib(source='a.c', target='foo')
	"""
	if self.env['MACAPP'] or getattr(self, 'mac_app', False):
		out = self.link_task.outputs[0]

		name = bundle_name_for_output(out)
		dir = self.create_bundle_dirs(name, out)

		n1 = dir.find_or_declare(['Contents', 'MacOS', out.name])

		self.apptask = self.create_task('macapp', self.link_task.outputs, n1)
		inst_to = getattr(self, 'install_path', '/Applications') + '/%s/Contents/MacOS/' % name
		self.bld.install_files(inst_to, n1, chmod=Utils.O755)

		if getattr(self, 'mac_resources', None):
			res_dir = n1.parent.parent.make_node('Resources')
			inst_to = getattr(self, 'install_path', '/Applications') + '/%s/Resources' % name
			for x in self.to_list(self.mac_resources):
				node = self.path.find_node(x)
				if not node:
					raise Errors.WafError('Missing mac_resource %r in %r' % (x, self))

				parent = node.parent
				if os.path.isdir(node.abspath()):
					nodes = node.ant_glob('**')
				else:
					nodes = [node]
				for node in nodes:
					rel = node.path_from(parent)
					tsk = self.create_task('macapp', node, res_dir.make_node(rel))
					self.bld.install_as(inst_to + '/%s' % rel, node)

		if getattr(self.bld, 'is_install', None):
			# disable the normal binary installation
			self.install_task.hasrun = Task.SKIP_ME

@feature('cprogram', 'cxxprogram')
@after_method('apply_link')
def create_task_macplist(self):
	"""
	Create a :py:class:`waflib.Tools.c_osx.macplist` instance.
	"""
	if  self.env['MACAPP'] or getattr(self, 'mac_app', False):
		out = self.link_task.outputs[0]

		name = bundle_name_for_output(out)

		dir = self.create_bundle_dirs(name, out)
		n1 = dir.find_or_declare(['Contents', 'Info.plist'])
		self.plisttask = plisttask = self.create_task('macplist', [], n1)

		if getattr(self, 'mac_plist', False):
			node = self.path.find_resource(self.mac_plist)
			if node:
				plisttask.inputs.append(node)
			else:
				plisttask.code = self.mac_plist
		else:
			plisttask.code = app_info % self.link_task.outputs[0].name

		inst_to = getattr(self, 'install_path', '/Applications') + '/%s/Contents/' % name
		self.bld.install_files(inst_to, n1)

@feature('cshlib', 'cxxshlib')
@before_method('apply_link', 'propagate_uselib_vars')
def apply_bundle(self):
	"""
	To make a bundled shared library (a ``.bundle``), set the *mac_bundle* attribute::

		def build(bld):
			bld.shlib(source='a.c', target='foo', mac_bundle = True)

	To force *all* executables to be transformed into bundles::

		def build(bld):
			bld.env.MACBUNDLE = True
			bld.shlib(source='a.c', target='foo')
	"""
	if self.env['MACBUNDLE'] or getattr(self, 'mac_bundle', False):
		self.env['LINKFLAGS_cshlib'] = self.env['LINKFLAGS_cxxshlib'] = [] # disable the '-dynamiclib' flag
		self.env['cshlib_PATTERN'] = self.env['cxxshlib_PATTERN'] = self.env['macbundle_PATTERN']
		use = self.use = self.to_list(getattr(self, 'use', []))
		if not 'MACBUNDLE' in use:
			use.append('MACBUNDLE')

app_dirs = ['Contents', 'Contents/MacOS', 'Contents/Resources']

class macapp(Task.Task):
	"""
	Create mac applications
	"""
	color = 'PINK'
	def run(self):
		self.outputs[0].parent.mkdir()
		shutil.copy2(self.inputs[0].srcpath(), self.outputs[0].abspath())

class macplist(Task.Task):
	"""
	Create plist files
	"""
	color = 'PINK'
	ext_in = ['.bin']
	def run(self):
		if getattr(self, 'code', None):
			txt = self.code
		else:
			txt = self.inputs[0].read()
		self.outputs[0].write(txt)


########NEW FILE########
__FILENAME__ = c_preproc
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2006-2010 (ita)

"""
C/C++ preprocessor for finding dependencies

Reasons for using the Waf preprocessor by default

#. Some c/c++ extensions (Qt) require a custom preprocessor for obtaining the dependencies (.moc files)
#. Not all compilers provide .d files for obtaining the dependencies (portability)
#. A naive file scanner will not catch the constructs such as "#include foo()"
#. A naive file scanner will catch unnecessary dependencies (change an unused header -> recompile everything)

Regarding the speed concerns:

* the preprocessing is performed only when files must be compiled
* the macros are evaluated only for #if/#elif/#include
* system headers are not scanned by default

Now if you do not want the Waf preprocessor, the tool +gccdeps* uses the .d files produced
during the compilation to track the dependencies (useful when used with the boost libraries).
It only works with gcc >= 4.4 though.

A dumb preprocessor is also available in the tool *c_dumbpreproc*
"""
# TODO: more varargs, pragma once

import re, sys, os, string, traceback
from waflib import Logs, Build, Utils, Errors
from waflib.Logs import debug, error

class PreprocError(Errors.WafError):
	pass

POPFILE = '-'
"Constant representing a special token used in :py:meth:`waflib.Tools.c_preproc.c_parser.start` iteration to switch to a header read previously"

recursion_limit = 150
"Limit on the amount of files to read in the dependency scanner"

go_absolute = False
"Set to True to track headers on files in /usr/include, else absolute paths are ignored (but it becomes very slow)"

standard_includes = ['/usr/include']
if Utils.is_win32:
	standard_includes = []

use_trigraphs = 0
"""Apply trigraph rules (False by default)"""

strict_quotes = 0
"""Reserve the "#include <>" quotes for system includes (do not search for those includes). False by default."""

g_optrans = {
'not':'!',
'and':'&&',
'bitand':'&',
'and_eq':'&=',
'or':'||',
'bitor':'|',
'or_eq':'|=',
'xor':'^',
'xor_eq':'^=',
'compl':'~',
}
"""Operators such as and/or/xor for c++. Set an empty dict to disable."""

# ignore #warning and #error
re_lines = re.compile(
	'^[ \t]*(#|%:)[ \t]*(ifdef|ifndef|if|else|elif|endif|include|import|define|undef|pragma)[ \t]*(.*)\r*$',
	re.IGNORECASE | re.MULTILINE)
"""Match #include lines"""

re_mac = re.compile("^[a-zA-Z_]\w*")
"""Match macro definitions"""

re_fun = re.compile('^[a-zA-Z_][a-zA-Z0-9_]*[(]')
"""Match macro functions"""

re_pragma_once = re.compile('^\s*once\s*', re.IGNORECASE)
"""Match #pragma once statements"""

re_nl = re.compile('\\\\\r*\n', re.MULTILINE)
"""Match newlines"""

re_cpp = re.compile(
	r"""(/\*[^*]*\*+([^/*][^*]*\*+)*/)|//[^\n]*|("(\\.|[^"\\])*"|'(\\.|[^'\\])*'|.[^/"'\\]*)""",
	re.MULTILINE)
"""Filter C/C++ comments"""

trig_def = [('??'+a, b) for a, b in zip("=-/!'()<>", r'#~\|^[]{}')]
"""Trigraph definitions"""

chr_esc = {'0':0, 'a':7, 'b':8, 't':9, 'n':10, 'f':11, 'v':12, 'r':13, '\\':92, "'":39}
"""Escape characters"""

NUM   = 'i'
"""Number token"""

OP    = 'O'
"""Operator token"""

IDENT = 'T'
"""Identifier token"""

STR   = 's'
"""String token"""

CHAR  = 'c'
"""Character token"""

tok_types = [NUM, STR, IDENT, OP]
"""Token types"""

exp_types = [
	r"""0[xX](?P<hex>[a-fA-F0-9]+)(?P<qual1>[uUlL]*)|L*?'(?P<char>(\\.|[^\\'])+)'|(?P<n1>\d+)[Ee](?P<exp0>[+-]*?\d+)(?P<float0>[fFlL]*)|(?P<n2>\d*\.\d+)([Ee](?P<exp1>[+-]*?\d+))?(?P<float1>[fFlL]*)|(?P<n4>\d+\.\d*)([Ee](?P<exp2>[+-]*?\d+))?(?P<float2>[fFlL]*)|(?P<oct>0*)(?P<n0>\d+)(?P<qual2>[uUlL]*)""",
	r'L?"([^"\\]|\\.)*"',
	r'[a-zA-Z_]\w*',
	r'%:%:|<<=|>>=|\.\.\.|<<|<%|<:|<=|>>|>=|\+\+|\+=|--|->|-=|\*=|/=|%:|%=|%>|==|&&|&=|\|\||\|=|\^=|:>|!=|##|[\(\)\{\}\[\]<>\?\|\^\*\+&=:!#;,%/\-\?\~\.]',
]
"""Expression types"""

re_clexer = re.compile('|'.join(["(?P<%s>%s)" % (name, part) for name, part in zip(tok_types, exp_types)]), re.M)
"""Match expressions into tokens"""

accepted  = 'a'
"""Parser state is *accepted*"""

ignored   = 'i'
"""Parser state is *ignored*, for example preprocessor lines in an #if 0 block"""

undefined = 'u'
"""Parser state is *undefined* at the moment"""

skipped   = 's'
"""Parser state is *skipped*, for example preprocessor lines in a #elif 0 block"""

def repl(m):
	"""Replace function used with :py:attr:`waflib.Tools.c_preproc.re_cpp`"""
	s = m.group(1)
	if s:
		return ' '
	return m.group(3) or ''

def filter_comments(filename):
	"""
	Filter the comments from a c/h file, and return the preprocessor lines.
	The regexps :py:attr:`waflib.Tools.c_preproc.re_cpp`, :py:attr:`waflib.Tools.c_preproc.re_nl` and :py:attr:`waflib.Tools.c_preproc.re_lines` are used internally.

	:return: the preprocessor directives as a list of (keyword, line)
	:rtype: a list of string pairs
	"""
	# return a list of tuples : keyword, line
	code = Utils.readf(filename)
	if use_trigraphs:
		for (a, b) in trig_def: code = code.split(a).join(b)
	code = re_nl.sub('', code)
	code = re_cpp.sub(repl, code)
	return [(m.group(2), m.group(3)) for m in re.finditer(re_lines, code)]

prec = {}
"""
Operator precendence rules required for parsing expressions of the form::

	#if 1 && 2 != 0
"""
ops = ['* / %', '+ -', '<< >>', '< <= >= >', '== !=', '& | ^', '&& ||', ',']
for x in range(len(ops)):
	syms = ops[x]
	for u in syms.split():
		prec[u] = x

def trimquotes(s):
	"""
	Remove the single quotes around an expression::

		trimquotes("'test'") == "test"

	:param s: expression to transform
	:type s: string
	:rtype: string
	"""
	if not s: return ''
	s = s.rstrip()
	if s[0] == "'" and s[-1] == "'": return s[1:-1]
	return s

def reduce_nums(val_1, val_2, val_op):
	"""
	Apply arithmetic rules to compute a result

	:param val1: input parameter
	:type val1: int or string
	:param val2: input parameter
	:type val2: int or string
	:param val_op: C operator in *+*, */*, *-*, etc
	:type val_op: string
	:rtype: int
	"""
	#print val_1, val_2, val_op

	# now perform the operation, make certain a and b are numeric
	try:    a = 0 + val_1
	except TypeError: a = int(val_1)
	try:    b = 0 + val_2
	except TypeError: b = int(val_2)

	d = val_op
	if d == '%':  c = a%b
	elif d=='+':  c = a+b
	elif d=='-':  c = a-b
	elif d=='*':  c = a*b
	elif d=='/':  c = a/b
	elif d=='^':  c = a^b
	elif d=='|':  c = a|b
	elif d=='||': c = int(a or b)
	elif d=='&':  c = a&b
	elif d=='&&': c = int(a and b)
	elif d=='==': c = int(a == b)
	elif d=='!=': c = int(a != b)
	elif d=='<=': c = int(a <= b)
	elif d=='<':  c = int(a < b)
	elif d=='>':  c = int(a > b)
	elif d=='>=': c = int(a >= b)
	elif d=='^':  c = int(a^b)
	elif d=='<<': c = a<<b
	elif d=='>>': c = a>>b
	else: c = 0
	return c

def get_num(lst):
	"""
	Try to obtain a number from a list of tokens. The token types are defined in :py:attr:`waflib.Tools.ccroot.tok_types`.

	:param lst: list of preprocessor tokens
	:type lst: list of tuple (tokentype, value)
	:return: a pair containing the number and the rest of the list
	:rtype: tuple(value, list)
	"""
	if not lst: raise PreprocError("empty list for get_num")
	(p, v) = lst[0]
	if p == OP:
		if v == '(':
			count_par = 1
			i = 1
			while i < len(lst):
				(p, v) = lst[i]

				if p == OP:
					if v == ')':
						count_par -= 1
						if count_par == 0:
							break
					elif v == '(':
						count_par += 1
				i += 1
			else:
				raise PreprocError("rparen expected %r" % lst)

			(num, _) = get_term(lst[1:i])
			return (num, lst[i+1:])

		elif v == '+':
			return get_num(lst[1:])
		elif v == '-':
			num, lst = get_num(lst[1:])
			return (reduce_nums('-1', num, '*'), lst)
		elif v == '!':
			num, lst = get_num(lst[1:])
			return (int(not int(num)), lst)
		elif v == '~':
			return (~ int(num), lst)
		else:
			raise PreprocError("Invalid op token %r for get_num" % lst)
	elif p == NUM:
		return v, lst[1:]
	elif p == IDENT:
		# all macros should have been replaced, remaining identifiers eval to 0
		return 0, lst[1:]
	else:
		raise PreprocError("Invalid token %r for get_num" % lst)

def get_term(lst):
	"""
	Evaluate an expression recursively, for example::

		1+1+1 -> 2+1 -> 3

	:param lst: list of tokens
	:type lst: list of tuple(token, value)
	:return: the value and the remaining tokens
	:rtype: value, list
	"""

	if not lst: raise PreprocError("empty list for get_term")
	num, lst = get_num(lst)
	if not lst:
		return (num, [])
	(p, v) = lst[0]
	if p == OP:
		if v == '&&' and not num:
			return (num, [])
		elif v == '||' and num:
			return (num, [])
		elif v == ',':
			# skip
			return get_term(lst[1:])
		elif v == '?':
			count_par = 0
			i = 1
			while i < len(lst):
				(p, v) = lst[i]

				if p == OP:
					if v == ')':
						count_par -= 1
					elif v == '(':
						count_par += 1
					elif v == ':':
						if count_par == 0:
							break
				i += 1
			else:
				raise PreprocError("rparen expected %r" % lst)

			if int(num):
				return get_term(lst[1:i])
			else:
				return get_term(lst[i+1:])

		else:
			num2, lst = get_num(lst[1:])

			if not lst:
				# no more tokens to process
				num2 = reduce_nums(num, num2, v)
				return get_term([(NUM, num2)] + lst)

			# operator precedence
			p2, v2 = lst[0]
			if p2 != OP:
				raise PreprocError("op expected %r" % lst)

			if prec[v2] >= prec[v]:
				num2 = reduce_nums(num, num2, v)
				return get_term([(NUM, num2)] + lst)
			else:
				num3, lst = get_num(lst[1:])
				num3 = reduce_nums(num2, num3, v2)
				return get_term([(NUM, num), (p, v), (NUM, num3)] + lst)


	raise PreprocError("cannot reduce %r" % lst)

def reduce_eval(lst):
	"""
	Take a list of tokens and output true or false for #if/#elif conditions.

	:param lst: a list of tokens
	:type lst: list of tuple(token, value)
	:return: a token
	:rtype: tuple(NUM, int)
	"""
	num, lst = get_term(lst)
	return (NUM, num)

def stringize(lst):
	"""
	Merge a list of tokens into a string

	:param lst: a list of tokens
	:type lst: list of tuple(token, value)
	:rtype: string
	"""
	lst = [str(v2) for (p2, v2) in lst]
	return "".join(lst)

def paste_tokens(t1, t2):
	"""
	Token pasting works between identifiers, particular operators, and identifiers and numbers::

		a ## b  ->  ab
		> ## =  ->  >=
		a ## 2  ->  a2

	:param t1: token
	:type t1: tuple(type, value)
	:param t2: token
	:type t2: tuple(type, value)
	"""
	p1 = None
	if t1[0] == OP and t2[0] == OP:
		p1 = OP
	elif t1[0] == IDENT and (t2[0] == IDENT or t2[0] == NUM):
		p1 = IDENT
	elif t1[0] == NUM and t2[0] == NUM:
		p1 = NUM
	if not p1:
		raise PreprocError('tokens do not make a valid paste %r and %r' % (t1, t2))
	return (p1, t1[1] + t2[1])

def reduce_tokens(lst, defs, ban=[]):
	"""
	Replace the tokens in lst, using the macros provided in defs, and a list of macros that cannot be re-applied

	:param lst: list of tokens
	:type lst: list of tuple(token, value)
	:param defs: macro definitions
	:type defs: dict
	:param ban: macros that cannot be substituted (recursion is not allowed)
	:type ban: list of string
	:return: the new list of tokens
	:rtype: value, list
	"""
	i = 0

	while i < len(lst):
		(p, v) = lst[i]

		if p == IDENT and v == "defined":
			del lst[i]
			if i < len(lst):
				(p2, v2) = lst[i]
				if p2 == IDENT:
					if v2 in defs:
						lst[i] = (NUM, 1)
					else:
						lst[i] = (NUM, 0)
				elif p2 == OP and v2 == '(':
					del lst[i]
					(p2, v2) = lst[i]
					del lst[i] # remove the ident, and change the ) for the value
					if v2 in defs:
						lst[i] = (NUM, 1)
					else:
						lst[i] = (NUM, 0)
				else:
					raise PreprocError("Invalid define expression %r" % lst)

		elif p == IDENT and v in defs:

			if isinstance(defs[v], str):
				a, b = extract_macro(defs[v])
				defs[v] = b
			macro_def = defs[v]
			to_add = macro_def[1]

			if isinstance(macro_def[0], list):
				# macro without arguments
				del lst[i]
				for x in range(len(to_add)):
					lst.insert(i, to_add[x])
					i += 1
			else:
				# collect the arguments for the funcall

				args = []
				del lst[i]

				if i >= len(lst):
					raise PreprocError("expected '(' after %r (got nothing)" % v)

				(p2, v2) = lst[i]
				if p2 != OP or v2 != '(':
					raise PreprocError("expected '(' after %r" % v)

				del lst[i]

				one_param = []
				count_paren = 0
				while i < len(lst):
					p2, v2 = lst[i]

					del lst[i]
					if p2 == OP and count_paren == 0:
						if v2 == '(':
							one_param.append((p2, v2))
							count_paren += 1
						elif v2 == ')':
							if one_param: args.append(one_param)
							break
						elif v2 == ',':
							if not one_param: raise PreprocError("empty param in funcall %s" % p)
							args.append(one_param)
							one_param = []
						else:
							one_param.append((p2, v2))
					else:
						one_param.append((p2, v2))
						if   v2 == '(': count_paren += 1
						elif v2 == ')': count_paren -= 1
				else:
					raise PreprocError('malformed macro')

				# substitute the arguments within the define expression
				accu = []
				arg_table = macro_def[0]
				j = 0
				while j < len(to_add):
					(p2, v2) = to_add[j]

					if p2 == OP and v2 == '#':
						# stringize is for arguments only
						if j+1 < len(to_add) and to_add[j+1][0] == IDENT and to_add[j+1][1] in arg_table:
							toks = args[arg_table[to_add[j+1][1]]]
							accu.append((STR, stringize(toks)))
							j += 1
						else:
							accu.append((p2, v2))
					elif p2 == OP and v2 == '##':
						# token pasting, how can man invent such a complicated system?
						if accu and j+1 < len(to_add):
							# we have at least two tokens

							t1 = accu[-1]

							if to_add[j+1][0] == IDENT and to_add[j+1][1] in arg_table:
								toks = args[arg_table[to_add[j+1][1]]]

								if toks:
									accu[-1] = paste_tokens(t1, toks[0]) #(IDENT, accu[-1][1] + toks[0][1])
									accu.extend(toks[1:])
								else:
									# error, case "a##"
									accu.append((p2, v2))
									accu.extend(toks)
							elif to_add[j+1][0] == IDENT and to_add[j+1][1] == '__VA_ARGS__':
								# TODO not sure
								# first collect the tokens
								va_toks = []
								st = len(macro_def[0])
								pt = len(args)
								for x in args[pt-st+1:]:
									va_toks.extend(x)
									va_toks.append((OP, ','))
								if va_toks: va_toks.pop() # extra comma
								if len(accu)>1:
									(p3, v3) = accu[-1]
									(p4, v4) = accu[-2]
									if v3 == '##':
										# remove the token paste
										accu.pop()
										if v4 == ',' and pt < st:
											# remove the comma
											accu.pop()
								accu += va_toks
							else:
								accu[-1] = paste_tokens(t1, to_add[j+1])

							j += 1
						else:
							# Invalid paste, case    "##a" or "b##"
							accu.append((p2, v2))

					elif p2 == IDENT and v2 in arg_table:
						toks = args[arg_table[v2]]
						reduce_tokens(toks, defs, ban+[v])
						accu.extend(toks)
					else:
						accu.append((p2, v2))

					j += 1


				reduce_tokens(accu, defs, ban+[v])

				for x in range(len(accu)-1, -1, -1):
					lst.insert(i, accu[x])

		i += 1


def eval_macro(lst, defs):
	"""
	Reduce the tokens by :py:func:`waflib.Tools.c_preproc.reduce_tokens` and try to return a 0/1 result by :py:func:`waflib.Tools.c_preproc.reduce_eval`.

	:param lst: list of tokens
	:type lst: list of tuple(token, value)
	:param defs: macro definitions
	:type defs: dict
	:rtype: int
	"""
	reduce_tokens(lst, defs, [])
	if not lst: raise PreprocError("missing tokens to evaluate")
	(p, v) = reduce_eval(lst)
	return int(v) != 0

def extract_macro(txt):
	"""
	Process a macro definition of the form::
		 #define f(x, y) x * y

	into a function or a simple macro without arguments

	:param txt: expression to exact a macro definition from
	:type txt: string
	:return: a tuple containing the name, the list of arguments and the replacement
	:rtype: tuple(string, [list, list])
	"""
	t = tokenize(txt)
	if re_fun.search(txt):
		p, name = t[0]

		p, v = t[1]
		if p != OP: raise PreprocError("expected open parenthesis")

		i = 1
		pindex = 0
		params = {}
		prev = '('

		while 1:
			i += 1
			p, v = t[i]

			if prev == '(':
				if p == IDENT:
					params[v] = pindex
					pindex += 1
					prev = p
				elif p == OP and v == ')':
					break
				else:
					raise PreprocError("unexpected token (3)")
			elif prev == IDENT:
				if p == OP and v == ',':
					prev = v
				elif p == OP and v == ')':
					break
				else:
					raise PreprocError("comma or ... expected")
			elif prev == ',':
				if p == IDENT:
					params[v] = pindex
					pindex += 1
					prev = p
				elif p == OP and v == '...':
					raise PreprocError("not implemented (1)")
				else:
					raise PreprocError("comma or ... expected (2)")
			elif prev == '...':
				raise PreprocError("not implemented (2)")
			else:
				raise PreprocError("unexpected else")

		#~ print (name, [params, t[i+1:]])
		return (name, [params, t[i+1:]])
	else:
		(p, v) = t[0]
		return (v, [[], t[1:]])

re_include = re.compile('^\s*(<(?P<a>.*)>|"(?P<b>.*)")')
def extract_include(txt, defs):
	"""
	Process a line in the form::

		#include foo

	:param txt: include line to process
	:type txt: string
	:param defs: macro definitions
	:type defs: dict
	:return: the file name
	:rtype: string
	"""
	m = re_include.search(txt)
	if m:
		if m.group('a'): return '<', m.group('a')
		if m.group('b'): return '"', m.group('b')

	# perform preprocessing and look at the result, it must match an include
	toks = tokenize(txt)
	reduce_tokens(toks, defs, ['waf_include'])

	if not toks:
		raise PreprocError("could not parse include %s" % txt)

	if len(toks) == 1:
		if toks[0][0] == STR:
			return '"', toks[0][1]
	else:
		if toks[0][1] == '<' and toks[-1][1] == '>':
			return stringize(toks).lstrip('<').rstrip('>')

	raise PreprocError("could not parse include %s." % txt)

def parse_char(txt):
	"""
	Parse a c character

	:param txt: character to parse
	:type txt: string
	:return: a character literal
	:rtype: string
	"""

	if not txt: raise PreprocError("attempted to parse a null char")
	if txt[0] != '\\':
		return ord(txt)
	c = txt[1]
	if c == 'x':
		if len(txt) == 4 and txt[3] in string.hexdigits: return int(txt[2:], 16)
		return int(txt[2:], 16)
	elif c.isdigit():
		if c == '0' and len(txt)==2: return 0
		for i in 3, 2, 1:
			if len(txt) > i and txt[1:1+i].isdigit():
				return (1+i, int(txt[1:1+i], 8))
	else:
		try: return chr_esc[c]
		except KeyError: raise PreprocError("could not parse char literal '%s'" % txt)

@Utils.run_once
def tokenize(s):
	"""
	Convert a string into a list of tokens (shlex.split does not apply to c/c++/d)

	:param s: input to tokenize
	:type s: string
	:return: a list of tokens
	:rtype: list of tuple(token, value)
	"""
	# the same headers are read again and again - 10% improvement on preprocessing the samba headers
	ret = []
	for match in re_clexer.finditer(s):
		m = match.group
		for name in tok_types:
			v = m(name)
			if v:
				if name == IDENT:
					try: v = g_optrans[v]; name = OP
					except KeyError:
						# c++ specific
						if v.lower() == "true":
							v = 1
							name = NUM
						elif v.lower() == "false":
							v = 0
							name = NUM
				elif name == NUM:
					if m('oct'): v = int(v, 8)
					elif m('hex'): v = int(m('hex'), 16)
					elif m('n0'): v = m('n0')
					else:
						v = m('char')
						if v: v = parse_char(v)
						else: v = m('n2') or m('n4')
				elif name == OP:
					if v == '%:': v = '#'
					elif v == '%:%:': v = '##'
				elif name == STR:
					# remove the quotes around the string
					v = v[1:-1]
				ret.append((name, v))
				break
	return ret

@Utils.run_once
def define_name(line):
	"""
	:param line: define line
	:type line: string
	:rtype: string
	:return: the define name
	"""
	return re_mac.match(line).group(0)

class c_parser(object):
	"""
	Used by :py:func:`waflib.Tools.c_preproc.scan` to parse c/h files. Note that by default,
	only project headers are parsed.
	"""
	def __init__(self, nodepaths=None, defines=None):
		self.lines = []
		"""list of lines read"""

		if defines is None:
			self.defs  = {}
		else:
			self.defs  = dict(defines) # make a copy
		self.state = []

		self.count_files = 0
		self.currentnode_stack = []

		self.nodepaths = nodepaths or []
		"""Include paths"""

		self.nodes = []
		"""List of :py:class:`waflib.Node.Node` found so far"""

		self.names = []
		"""List of file names that could not be matched by any file"""

		self.curfile = ''
		"""Current file"""

		self.ban_includes = set([])
		"""Includes that must not be read (#pragma once)"""

	def cached_find_resource(self, node, filename):
		"""
		Find a file from the input directory

		:param node: directory
		:type node: :py:class:`waflib.Node.Node`
		:param filename: header to find
		:type filename: string
		:return: the node if found, or None
		:rtype: :py:class:`waflib.Node.Node`
		"""
		try:
			nd = node.ctx.cache_nd
		except:
			nd = node.ctx.cache_nd = {}

		tup = (node, filename)
		try:
			return nd[tup]
		except KeyError:
			ret = node.find_resource(filename)
			if ret:
				if getattr(ret, 'children', None):
					ret = None
				elif ret.is_child_of(node.ctx.bldnode):
					tmp = node.ctx.srcnode.search(ret.path_from(node.ctx.bldnode))
					if tmp and getattr(tmp, 'children', None):
						ret = None
			nd[tup] = ret
			return ret

	def tryfind(self, filename):
		"""
		Try to obtain a node from the filename based from the include paths. Will add
		the node found to :py:attr:`waflib.Tools.c_preproc.c_parser.nodes` or the file name to
		:py:attr:`waflib.Tools.c_preproc.c_parser.names` if no corresponding file is found. Called by
		:py:attr:`waflib.Tools.c_preproc.c_parser.start`.

		:param filename: header to find
		:type filename: string
		:return: the node if found
		:rtype: :py:class:`waflib.Node.Node`
		"""
		self.curfile = filename

		# for msvc it should be a for loop on the whole stack
		found = self.cached_find_resource(self.currentnode_stack[-1], filename)

		for n in self.nodepaths:
			if found:
				break
			found = self.cached_find_resource(n, filename)

		if found:
			# TODO the duplicates do not increase the no-op build times too much, but they may be worth removing
			self.nodes.append(found)
			if filename[-4:] != '.moc':
				self.addlines(found)
		else:
			if not filename in self.names:
				self.names.append(filename)
		return found

	def addlines(self, node):
		"""
		Add the lines from a header in the list of preprocessor lines to parse

		:param node: header
		:type node: :py:class:`waflib.Node.Node`
		"""

		self.currentnode_stack.append(node.parent)
		filepath = node.abspath()

		self.count_files += 1
		if self.count_files > recursion_limit:
			# issue #812
			raise PreprocError("recursion limit exceeded")
		pc = self.parse_cache
		debug('preproc: reading file %r', filepath)
		try:
			lns = pc[filepath]
		except KeyError:
			pass
		else:
			self.lines.extend(lns)
			return

		try:
			lines = filter_comments(filepath)
			lines.append((POPFILE, ''))
			lines.reverse()
			pc[filepath] = lines # cache the lines filtered
			self.lines.extend(lines)
		except IOError:
			raise PreprocError("could not read the file %s" % filepath)
		except Exception:
			if Logs.verbose > 0:
				error("parsing %s failed" % filepath)
				traceback.print_exc()

	def start(self, node, env):
		"""
		Preprocess a source file to obtain the dependencies, which are accumulated to :py:attr:`waflib.Tools.c_preproc.c_parser.nodes`
		and :py:attr:`waflib.Tools.c_preproc.c_parser.names`.

		:param node: source file
		:type node: :py:class:`waflib.Node.Node`
		:param env: config set containing additional defines to take into account
		:type env: :py:class:`waflib.ConfigSet.ConfigSet`
		"""

		debug('preproc: scanning %s (in %s)', node.name, node.parent.name)

		bld = node.ctx
		try:
			self.parse_cache = bld.parse_cache
		except AttributeError:
			bld.parse_cache = {}
			self.parse_cache = bld.parse_cache

		self.addlines(node)

		# macros may be defined on the command-line, so they must be parsed as if they were part of the file
		if env['DEFINES']:
			try:
				lst = ['%s %s' % (x[0], trimquotes('='.join(x[1:]))) for x in [y.split('=') for y in env['DEFINES']]]
				lst.reverse()
				self.lines.extend([('define', x) for x in lst])
			except AttributeError:
				# if the defines are invalid the compiler will tell the user
				pass

		while self.lines:
			(token, line) = self.lines.pop()
			if token == POPFILE:
				self.count_files -= 1
				self.currentnode_stack.pop()
				continue

			try:
				ve = Logs.verbose
				if ve: debug('preproc: line is %s - %s state is %s', token, line, self.state)
				state = self.state

				# make certain we define the state if we are about to enter in an if block
				if token[:2] == 'if':
					state.append(undefined)
				elif token == 'endif':
					state.pop()

				# skip lines when in a dead 'if' branch, wait for the endif
				if token[0] != 'e':
					if skipped in self.state or ignored in self.state:
						continue

				if token == 'if':
					ret = eval_macro(tokenize(line), self.defs)
					if ret: state[-1] = accepted
					else: state[-1] = ignored
				elif token == 'ifdef':
					m = re_mac.match(line)
					if m and m.group(0) in self.defs: state[-1] = accepted
					else: state[-1] = ignored
				elif token == 'ifndef':
					m = re_mac.match(line)
					if m and m.group(0) in self.defs: state[-1] = ignored
					else: state[-1] = accepted
				elif token == 'include' or token == 'import':
					(kind, inc) = extract_include(line, self.defs)
					if inc in self.ban_includes:
						continue
					if token == 'import': self.ban_includes.add(inc)
					if ve: debug('preproc: include found %s    (%s) ', inc, kind)
					if kind == '"' or not strict_quotes:
						self.tryfind(inc)
				elif token == 'elif':
					if state[-1] == accepted:
						state[-1] = skipped
					elif state[-1] == ignored:
						if eval_macro(tokenize(line), self.defs):
							state[-1] = accepted
				elif token == 'else':
					if state[-1] == accepted: state[-1] = skipped
					elif state[-1] == ignored: state[-1] = accepted
				elif token == 'define':
					try:
						self.defs[define_name(line)] = line
					except:
						raise PreprocError("Invalid define line %s" % line)
				elif token == 'undef':
					m = re_mac.match(line)
					if m and m.group(0) in self.defs:
						self.defs.__delitem__(m.group(0))
						#print "undef %s" % name
				elif token == 'pragma':
					if re_pragma_once.match(line.lower()):
						self.ban_includes.add(self.curfile)
			except Exception as e:
				if Logs.verbose:
					debug('preproc: line parsing failed (%s): %s %s', e, line, Utils.ex_stack())

def scan(task):
	"""
	Get the dependencies using a c/c++ preprocessor, this is required for finding dependencies of the kind::

		#include some_macro()

	This function is bound as a task method on :py:class:`waflib.Tools.c.c` and :py:class:`waflib.Tools.cxx.cxx` for example
	"""

	global go_absolute

	try:
		incn = task.generator.includes_nodes
	except AttributeError:
		raise Errors.WafError('%r is missing a feature such as "c", "cxx" or "includes": ' % task.generator)

	if go_absolute:
		nodepaths = incn + standard_includes
	else:
		nodepaths = [x for x in incn if x.is_child_of(x.ctx.srcnode) or x.is_child_of(x.ctx.bldnode)]

	tmp = c_parser(nodepaths)
	tmp.start(task.inputs[0], task.env)
	if Logs.verbose:
		debug('deps: deps for %r: %r; unresolved %r' % (task.inputs, tmp.nodes, tmp.names))
	return (tmp.nodes, tmp.names)


########NEW FILE########
__FILENAME__ = c_tests
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2010 (ita)

"""
Various configuration tests.
"""

from waflib import Task
from waflib.Configure import conf
from waflib.TaskGen import feature, before_method, after_method
import sys

LIB_CODE = '''
#ifdef _MSC_VER
#define testEXPORT __declspec(dllexport)
#else
#define testEXPORT
#endif
testEXPORT int lib_func(void) { return 9; }
'''

MAIN_CODE = '''
#ifdef _MSC_VER
#define testEXPORT __declspec(dllimport)
#else
#define testEXPORT
#endif
testEXPORT int lib_func(void);
int main(void) {return !(lib_func() == 9);}
'''

@feature('link_lib_test')
@before_method('process_source')
def link_lib_test_fun(self):
	"""
	The configuration test :py:func:`waflib.Tools.ccroot.run_c_code` declares a unique task generator,
	so we need to create other task generators from here to check if the linker is able to link libraries.
	"""
	def write_test_file(task):
		task.outputs[0].write(task.generator.code)

	rpath = []
	if getattr(self, 'add_rpath', False):
		rpath = [self.bld.path.get_bld().abspath()]

	mode = self.mode
	m = '%s %s' % (mode, mode)
	ex = self.test_exec and 'test_exec' or ''
	bld = self.bld
	bld(rule=write_test_file, target='test.' + mode, code=LIB_CODE)
	bld(rule=write_test_file, target='main.' + mode, code=MAIN_CODE)
	bld(features='%sshlib' % m, source='test.' + mode, target='test')
	bld(features='%sprogram %s' % (m, ex), source='main.' + mode, target='app', use='test', rpath=rpath)

@conf
def check_library(self, mode=None, test_exec=True):
	"""
	Check if libraries can be linked with the current linker. Uses :py:func:`waflib.Tools.c_tests.link_lib_test_fun`.

	:param mode: c or cxx or d
	:type mode: string
	"""
	if not mode:
		mode = 'c'
		if self.env.CXX:
			mode = 'cxx'
	self.check(
		compile_filename = [],
		features = 'link_lib_test',
		msg = 'Checking for libraries',
		mode = mode,
		test_exec = test_exec,
		)

########################################################################################

INLINE_CODE = '''
typedef int foo_t;
static %s foo_t static_foo () {return 0; }
%s foo_t foo () {
	return 0;
}
'''
INLINE_VALUES = ['inline', '__inline__', '__inline']

@conf
def check_inline(self, **kw):
	"""
	Check for the right value for inline macro.
	Define INLINE_MACRO to 1 if the define is found.
	If the inline macro is not 'inline', add a define to the ``config.h`` (#define inline __inline__)

	:param define_name: define INLINE_MACRO by default to 1 if the macro is defined
	:type define_name: string
	:param features: by default *c* or *cxx* depending on the compiler present
	:type features: list of string
	"""

	self.start_msg('Checking for inline')

	if not 'define_name' in kw:
		kw['define_name'] = 'INLINE_MACRO'
	if not 'features' in kw:
		if self.env.CXX:
			kw['features'] = ['cxx']
		else:
			kw['features'] = ['c']

	for x in INLINE_VALUES:
		kw['fragment'] = INLINE_CODE % (x, x)

		try:
			self.check(**kw)
		except self.errors.ConfigurationError:
			continue
		else:
			self.end_msg(x)
			if x != 'inline':
				self.define('inline', x, quote=False)
			return x
	self.fatal('could not use inline functions')

########################################################################################

LARGE_FRAGMENT = '#include <unistd.h>\nint main() { return !(sizeof(off_t) >= 8); }\n'

@conf
def check_large_file(self, **kw):
	"""
	Check for large file support and define the macro HAVE_LARGEFILE
	The test is skipped on win32 systems (DEST_BINFMT == pe).

	:param define_name: define to set, by default *HAVE_LARGEFILE*
	:type define_name: string
	:param execute: execute the test (yes by default)
	:type execute: bool
	"""

	if not 'define_name' in kw:
		kw['define_name'] = 'HAVE_LARGEFILE'
	if not 'execute' in kw:
		kw['execute'] = True

	if not 'features' in kw:
		if self.env.CXX:
			kw['features'] = ['cxx', 'cxxprogram']
		else:
			kw['features'] = ['c', 'cprogram']

	kw['fragment'] = LARGE_FRAGMENT

	kw['msg'] = 'Checking for large file support'
	ret = True
	try:
		if self.env.DEST_BINFMT != 'pe':
			ret = self.check(**kw)
	except self.errors.ConfigurationError:
		pass
	else:
		if ret:
			return True

	kw['msg'] = 'Checking for -D_FILE_OFFSET_BITS=64'
	kw['defines'] = ['_FILE_OFFSET_BITS=64']
	try:
		ret = self.check(**kw)
	except self.errors.ConfigurationError:
		pass
	else:
		self.define('_FILE_OFFSET_BITS', 64)
		return ret

	self.fatal('There is no support for large files')

########################################################################################

ENDIAN_FRAGMENT = '''
short int ascii_mm[] = { 0x4249, 0x4765, 0x6E44, 0x6961, 0x6E53, 0x7953, 0 };
short int ascii_ii[] = { 0x694C, 0x5454, 0x656C, 0x6E45, 0x6944, 0x6E61, 0 };
int use_ascii (int i) {
	return ascii_mm[i] + ascii_ii[i];
}
short int ebcdic_ii[] = { 0x89D3, 0xE3E3, 0x8593, 0x95C5, 0x89C4, 0x9581, 0 };
short int ebcdic_mm[] = { 0xC2C9, 0xC785, 0x95C4, 0x8981, 0x95E2, 0xA8E2, 0 };
int use_ebcdic (int i) {
	return ebcdic_mm[i] + ebcdic_ii[i];
}
extern int foo;
'''

class grep_for_endianness(Task.Task):
	color = 'PINK'
	def run(self):
		txt = self.inputs[0].read(flags='rb').decode('iso8859-1')
		if txt.find('LiTTleEnDian') > -1:
			self.generator.tmp.append('little')
		elif txt.find('BIGenDianSyS') > -1:
			self.generator.tmp.append('big')
		else:
			return -1

@feature('grep_for_endianness')
@after_method('process_source')
def grep_for_endianness_fun(self):
	self.create_task('grep_for_endianness', self.compiled_tasks[0].outputs[0])

@conf
def check_endianness(self):
	"""
	Execute a configuration test to determine the endianness
	"""
	tmp = []
	def check_msg(self):
		return tmp[0]
	self.check(fragment=ENDIAN_FRAGMENT, features='c grep_for_endianness', msg="Checking for endianness", define='ENDIANNESS', tmp=tmp, okmsg=check_msg)
	return tmp[0]


########NEW FILE########
__FILENAME__ = gnu_dirs
#!/usr/bin/env python
# encoding: utf-8
# Ali Sabil, 2007

"""
Sets various standard variables such as INCLUDEDIR. SBINDIR and others. To use this module just call::

	opt.load('gnu_dirs')

and::

	conf.load('gnu_dirs')

Add options for the standard GNU directories, this tool will add the options
found in autotools, and will update the environment with the following
installation variables:

============== ========================================= =======================
Variable       Description                               Value
============== ========================================= =======================
PREFIX         architecture-independent files            /usr/local
EXEC_PREFIX    architecture-dependent files              PREFIX
BINDIR         user executables                          EXEC_PREFIX/bin
SBINDIR        user executables                          EXEC_PREFIX/sbin
LIBEXECDIR     program executables                       EXEC_PREFIX/libexec
SYSCONFDIR     read-only single-machine data             PREFIX/etc
SHAREDSTATEDIR modifiable architecture-independent data  PREFIX/com
LOCALSTATEDIR  modifiable single-machine data            PREFIX/var
LIBDIR         object code libraries                     EXEC_PREFIX/lib
INCLUDEDIR     C header files                            PREFIX/include
OLDINCLUDEDIR  C header files for non-gcc                /usr/include
DATAROOTDIR    read-only arch.-independent data root     PREFIX/share
DATADIR        read-only architecture-independent data   DATAROOTDIR
INFODIR        info documentation                        DATAROOTDIR/info
LOCALEDIR      locale-dependent data                     DATAROOTDIR/locale
MANDIR         man documentation                         DATAROOTDIR/man
DOCDIR         documentation root                        DATAROOTDIR/doc/APPNAME
HTMLDIR        html documentation                        DOCDIR
DVIDIR         dvi documentation                         DOCDIR
PDFDIR         pdf documentation                         DOCDIR
PSDIR          ps documentation                          DOCDIR
============== ========================================= =======================
"""

import os
from waflib import Utils, Options, Context

_options = [x.split(', ') for x in '''
bindir, user executables, ${EXEC_PREFIX}/bin
sbindir, system admin executables, ${EXEC_PREFIX}/sbin
libexecdir, program executables, ${EXEC_PREFIX}/libexec
sysconfdir, read-only single-machine data, ${PREFIX}/etc
sharedstatedir, modifiable architecture-independent data, ${PREFIX}/com
localstatedir, modifiable single-machine data, ${PREFIX}/var
libdir, object code libraries, ${EXEC_PREFIX}/lib
includedir, C header files, ${PREFIX}/include
oldincludedir, C header files for non-gcc, /usr/include
datarootdir, read-only arch.-independent data root, ${PREFIX}/share
datadir, read-only architecture-independent data, ${DATAROOTDIR}
infodir, info documentation, ${DATAROOTDIR}/info
localedir, locale-dependent data, ${DATAROOTDIR}/locale
mandir, man documentation, ${DATAROOTDIR}/man
docdir, documentation root, ${DATAROOTDIR}/doc/${PACKAGE}
htmldir, html documentation, ${DOCDIR}
dvidir, dvi documentation, ${DOCDIR}
pdfdir, pdf documentation, ${DOCDIR}
psdir, ps documentation, ${DOCDIR}
'''.split('\n') if x]

def configure(conf):
	"""
	Read the command-line options to set lots of variables in *conf.env*. The variables
	BINDIR and LIBDIR will be overwritten.
	"""
	def get_param(varname, default):
		return getattr(Options.options, varname, '') or default

	env = conf.env
	conf.env.LIBDIR = conf.env.BINDIR = []
	env['EXEC_PREFIX'] = get_param('EXEC_PREFIX', env['PREFIX'])
	env['PACKAGE'] = getattr(Context.g_module, 'APPNAME', None) or env['PACKAGE']

	complete = False
	iter = 0
	while not complete and iter < len(_options) + 1:
		iter += 1
		complete = True
		for name, help, default in _options:
			name = name.upper()
			if not env[name]:
				try:
					env[name] = Utils.subst_vars(get_param(name, default).replace('/', os.sep), env)
				except TypeError:
					complete = False
	if not complete:
		lst = [name for name, _, _ in _options if not env[name.upper()]]
		raise conf.errors.WafError('Variable substitution failure %r' % lst)

def options(opt):
	"""
	Add lots of command-line options, for example::

		--exec-prefix: EXEC_PREFIX
	"""
	inst_dir = opt.add_option_group('Installation directories',
'By default, "waf install" will put the files in\
 "/usr/local/bin", "/usr/local/lib" etc. An installation prefix other\
 than "/usr/local" can be given using "--prefix", for example "--prefix=$HOME"')

	for k in ('--prefix', '--destdir'):
		option = opt.parser.get_option(k)
		if option:
			opt.parser.remove_option(k)
			inst_dir.add_option(option)

	inst_dir.add_option('--exec-prefix',
		help = 'installation prefix [Default: ${PREFIX}]',
		default = '',
		dest = 'EXEC_PREFIX')

	dirs_options = opt.add_option_group('Pre-defined installation directories', '')

	for name, help, default in _options:
		option_name = '--' + name
		str_default = default
		str_help = '%s [Default: %s]' % (help, str_default)
		dirs_options.add_option(option_name, help=str_help, default='', dest=name.upper())


########NEW FILE########
__FILENAME__ = intltool
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2006-2010 (ita)

"""
Support for translation tools such as msgfmt and intltool

Usage::

	def configure(conf):
		conf.load('gnu_dirs intltool')

	def build(bld):
		# process the .po files into .gmo files, and install them in LOCALEDIR
		bld(features='intltool_po', appname='myapp', podir='po', install_path="${LOCALEDIR}")

		# process an input file, substituting the translations from the po dir
		bld(
			features  = "intltool_in",
			podir     = "../po",
			flags     = ["-d", "-q", "-u", "-c"],
			source    = 'kupfer.desktop.in',
			install_path = "${DATADIR}/applications",
		)

Usage of the :py:mod:`waflib.Tools.gnu_dirs` is recommended, but not obligatory.
"""

import os, re
from waflib import Configure, TaskGen, Task, Utils, Runner, Options, Build, Logs
import waflib.Tools.ccroot
from waflib.TaskGen import feature, before_method
from waflib.Logs import error

@before_method('process_source')
@feature('intltool_in')
def apply_intltool_in_f(self):
	"""
	Create tasks to translate files by intltool-merge::

		def build(bld):
			bld(
				features  = "intltool_in",
				podir     = "../po",
				flags     = ["-d", "-q", "-u", "-c"],
				source    = 'kupfer.desktop.in',
				install_path = "${DATADIR}/applications",
			)

	:param podir: location of the .po files
	:type podir: string
	:param source: source files to process
	:type source: list of string
	:param flags: compilation flags ("-quc" by default)
	:type flags: list of string
	:param install_path: installation path
	:type install_path: string
	"""
	try: self.meths.remove('process_source')
	except ValueError: pass

	if not self.env.LOCALEDIR:
		self.env.LOCALEDIR = self.env.PREFIX + '/share/locale'

	for i in self.to_list(self.source):
		node = self.path.find_resource(i)

		podir = getattr(self, 'podir', 'po')
		podirnode = self.path.find_dir(podir)
		if not podirnode:
			error("could not find the podir %r" % podir)
			continue

		cache = getattr(self, 'intlcache', '.intlcache')
		self.env['INTLCACHE'] = os.path.join(self.path.bldpath(), podir, cache)
		self.env['INTLPODIR'] = podirnode.bldpath()
		self.env['INTLFLAGS'] = getattr(self, 'flags', ['-q', '-u', '-c'])

		task = self.create_task('intltool', node, node.change_ext(''))
		inst = getattr(self, 'install_path', '${LOCALEDIR}')
		if inst:
			self.bld.install_files(inst, task.outputs)

@feature('intltool_po')
def apply_intltool_po(self):
	"""
	Create tasks to process po files::

		def build(bld):
			bld(features='intltool_po', appname='myapp', podir='po', install_path="${LOCALEDIR}")

	The relevant task generator arguments are:

	:param podir: directory of the .po files
	:type podir: string
	:param appname: name of the application
	:type appname: string
	:param install_path: installation directory
	:type install_path: string

	The file LINGUAS must be present in the directory pointed by *podir* and list the translation files to process.
	"""
	try: self.meths.remove('process_source')
	except ValueError: pass

	if not self.env.LOCALEDIR:
		self.env.LOCALEDIR = self.env.PREFIX + '/share/locale'

	appname = getattr(self, 'appname', 'set_your_app_name')
	podir = getattr(self, 'podir', '')
	inst = getattr(self, 'install_path', '${LOCALEDIR}')

	linguas = self.path.find_node(os.path.join(podir, 'LINGUAS'))
	if linguas:
		# scan LINGUAS file for locales to process
		file = open(linguas.abspath())
		langs = []
		for line in file.readlines():
			# ignore lines containing comments
			if not line.startswith('#'):
				langs += line.split()
		file.close()
		re_linguas = re.compile('[-a-zA-Z_@.]+')
		for lang in langs:
			# Make sure that we only process lines which contain locales
			if re_linguas.match(lang):
				node = self.path.find_resource(os.path.join(podir, re_linguas.match(lang).group() + '.po'))
				task = self.create_task('po', node, node.change_ext('.mo'))

				if inst:
					filename = task.outputs[0].name
					(langname, ext) = os.path.splitext(filename)
					inst_file = inst + os.sep + langname + os.sep + 'LC_MESSAGES' + os.sep + appname + '.mo'
					self.bld.install_as(inst_file, task.outputs[0], chmod=getattr(self, 'chmod', Utils.O644), env=task.env)

	else:
		Logs.pprint('RED', "Error no LINGUAS file found in po directory")

class po(Task.Task):
	"""
	Compile .po files into .gmo files
	"""
	run_str = '${MSGFMT} -o ${TGT} ${SRC}'
	color   = 'BLUE'

class intltool(Task.Task):
	"""
	Let intltool-merge translate an input file
	"""
	run_str = '${INTLTOOL} ${INTLFLAGS} ${INTLCACHE} ${INTLPODIR} ${SRC} ${TGT}'
	color   = 'BLUE'

def configure(conf):
	"""
	Detect the program *msgfmt* and set *conf.env.MSGFMT*.
	Detect the program *intltool-merge* and set *conf.env.INTLTOOL*.
	It is possible to set INTLTOOL in the environment, but it must not have spaces in it::

		$ INTLTOOL="/path/to/the program/intltool" waf configure

	If a C/C++ compiler is present, execute a compilation test to find the header *locale.h*.
	"""
	conf.find_program('msgfmt', var='MSGFMT')
	conf.find_perl_program('intltool-merge', var='INTLTOOL')

	prefix  = conf.env.PREFIX
	datadir = conf.env.DATADIR
	if not datadir:
		datadir = os.path.join(prefix,'share')

	conf.define('LOCALEDIR', os.path.join(datadir, 'locale').replace('\\', '\\\\'))
	conf.define('DATADIR', datadir.replace('\\', '\\\\'))

	if conf.env.CC or conf.env.CXX:
		conf.check(header_name='locale.h')


########NEW FILE########
__FILENAME__ = python
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2007-2010 (ita)
# Gustavo Carneiro (gjc), 2007

"""
Support for Python, detect the headers and libraries and provide
*use* variables to link C/C++ programs against them::

	def options(opt):
		opt.load('compiler_c python')
	def configure(conf):
		conf.load('compiler_c python')
		conf.check_python_version((2,4,2))
		conf.check_python_headers()
	def build(bld):
		bld.program(features='pyembed', source='a.c', target='myprog')
		bld.shlib(features='pyext', source='b.c', target='mylib')
"""

import os, sys
from waflib import Utils, Options, Errors
from waflib.Logs import debug, warn, info, error
from waflib.TaskGen import extension, before_method, after_method, feature
from waflib.Configure import conf

FRAG = '''
#include <Python.h>
#ifdef __cplusplus
extern "C" {
#endif
	void Py_Initialize(void);
	void Py_Finalize(void);
#ifdef __cplusplus
}
#endif
int main()
{
   Py_Initialize();
   Py_Finalize();
   return 0;
}
'''
"""
Piece of C/C++ code used in :py:func:`waflib.Tools.python.check_python_headers`
"""

INST = '''
import sys, py_compile
py_compile.compile(sys.argv[1], sys.argv[2], sys.argv[3])
'''
"""
Piece of Python code used in :py:func:`waflib.Tools.python.install_pyfile` for installing python files
"""

DISTUTILS_IMP = ['from distutils.sysconfig import get_config_var, get_python_lib']

@extension('.py')
def process_py(self, node):
	"""
	Add a callback using :py:func:`waflib.Tools.python.install_pyfile` to install a python file
	"""
	try:
		if not self.bld.is_install:
			return
	except:
		return

	try:
		if not self.install_path:
			return
	except AttributeError:
		self.install_path = '${PYTHONDIR}'

	# i wonder now why we wanted to do this after the build is over
	# issue #901: people want to preserve the structure of installed files
	def inst_py(ctx):
		install_from = getattr(self, 'install_from', None)
		if install_from:
			install_from = self.path.find_dir(install_from)
		install_pyfile(self, node, install_from)
	self.bld.add_post_fun(inst_py)

def install_pyfile(self, node, install_from=None):
	"""
	Execute the installation of a python file

	:param node: python file
	:type node: :py:class:`waflib.Node.Node`
	"""

	from_node = install_from or node.parent
	tsk = self.bld.install_as(self.install_path + '/' + node.path_from(from_node), node, postpone=False)
	path = tsk.get_install_path()

	if self.bld.is_install < 0:
		info("+ removing byte compiled python files")
		for x in 'co':
			try:
				os.remove(path + x)
			except OSError:
				pass

	if self.bld.is_install > 0:
		try:
			st1 = os.stat(path)
		except:
			error('The python file is missing, this should not happen')

		for x in ['c', 'o']:
			do_inst = self.env['PY' + x.upper()]
			try:
				st2 = os.stat(path + x)
			except OSError:
				pass
			else:
				if st1.st_mtime <= st2.st_mtime:
					do_inst = False

			if do_inst:
				lst = (x == 'o') and [self.env['PYFLAGS_OPT']] or []
				(a, b, c) = (path, path + x, tsk.get_install_path(destdir=False) + x)
				argv = self.env['PYTHON'] + lst + ['-c', INST, a, b, c]
				info('+ byte compiling %r' % (path + x))
				env = self.env.env or None
				ret = Utils.subprocess.Popen(argv, env=env).wait()
				if ret:
					raise Errors.WafError('py%s compilation failed %r' % (x, path))

@feature('py')
def feature_py(self):
	"""
	Dummy feature which does nothing
	"""
	pass

@feature('pyext')
@before_method('propagate_uselib_vars', 'apply_link')
@after_method('apply_bundle')
def init_pyext(self):
	"""
	Change the values of *cshlib_PATTERN* and *cxxshlib_PATTERN* to remove the
	*lib* prefix from library names.
	"""
	try:
		if not self.install_path:
			return
	except AttributeError:
		self.install_path = '${PYTHONARCHDIR}'
	self.uselib = self.to_list(getattr(self, 'uselib', []))
	if not 'PYEXT' in self.uselib:
		self.uselib.append('PYEXT')
	# override shlib_PATTERN set by the osx module
	self.env['cshlib_PATTERN'] = self.env['cxxshlib_PATTERN'] = self.env['macbundle_PATTERN'] = self.env['pyext_PATTERN']

@feature('pyext')
@before_method('apply_link', 'apply_bundle')
def set_bundle(self):
	if Utils.unversioned_sys_platform() == 'darwin':
		self.mac_bundle = True

@before_method('propagate_uselib_vars')
@feature('pyembed')
def init_pyembed(self):
	"""
	Add the PYEMBED variable.
	"""
	self.uselib = self.to_list(getattr(self, 'uselib', []))
	if not 'PYEMBED' in self.uselib:
		self.uselib.append('PYEMBED')

@conf
def get_python_variables(self, variables, imports=None):
	"""
	Spawn a new python process to dump configuration variables

	:param variables: variables to print
	:type variables: list of string
	:param imports: one import by element
	:type imports: list of string
	:return: the variable values
	:rtype: list of string
	"""
	if not imports:
		try:
			imports = self.python_imports
		except AttributeError:
			imports = DISTUTILS_IMP

	program = list(imports) # copy
	program.append('')
	for v in variables:
		program.append("print(repr(%s))" % v)
	os_env = dict(os.environ)
	try:
		del os_env['MACOSX_DEPLOYMENT_TARGET'] # see comments in the OSX tool
	except KeyError:
		pass

	try:
		out = self.cmd_and_log(self.env.PYTHON + ['-c', '\n'.join(program)], env=os_env)
	except Errors.WafError:
		self.fatal('The distutils module is unusable: install "python-devel"?')
	return_values = []
	for s in out.split('\n'):
		s = s.strip()
		if not s:
			continue
		if s == 'None':
			return_values.append(None)
		elif s[0] == "'" and s[-1] == "'":
			return_values.append(s[1:-1])
		elif s[0].isdigit():
			return_values.append(int(s))
		else: break
	return return_values

@conf
def check_python_headers(conf):
	"""
	Check for headers and libraries necessary to extend or embed python by using the module *distutils*.
	On success the environment variables xxx_PYEXT and xxx_PYEMBED are added:

	* PYEXT: for compiling python extensions
	* PYEMBED: for embedding a python interpreter
	"""

	# FIXME rewrite

	if not conf.env['CC_NAME'] and not conf.env['CXX_NAME']:
		conf.fatal('load a compiler first (gcc, g++, ..)')

	if not conf.env['PYTHON_VERSION']:
		conf.check_python_version()

	env = conf.env
	pybin = conf.env.PYTHON
	if not pybin:
		conf.fatal('could not find the python executable')

	v = 'prefix SO LDFLAGS LIBDIR LIBPL INCLUDEPY Py_ENABLE_SHARED MACOSX_DEPLOYMENT_TARGET LDSHARED CFLAGS'.split()
	try:
		lst = conf.get_python_variables(["get_config_var('%s') or ''" % x for x in v])
	except RuntimeError:
		conf.fatal("Python development headers not found (-v for details).")

	vals = ['%s = %r' % (x, y) for (x, y) in zip(v, lst)]
	conf.to_log("Configuration returned from %r:\n%r\n" % (pybin, '\n'.join(vals)))

	dct = dict(zip(v, lst))
	x = 'MACOSX_DEPLOYMENT_TARGET'
	if dct[x]:
		conf.env[x] = conf.environ[x] = dct[x]

	env['pyext_PATTERN'] = '%s' + dct['SO'] # not a mistake

	# Check for python libraries for embedding

	all_flags = dct['LDFLAGS'] + ' ' + dct['CFLAGS']
	conf.parse_flags(all_flags, 'PYEMBED')

	all_flags = dct['LDFLAGS'] + ' ' + dct['LDSHARED'] + ' ' + dct['CFLAGS']
	conf.parse_flags(all_flags, 'PYEXT')

	result = None
	#name = 'python' + env['PYTHON_VERSION']

	# TODO simplify this
	for name in ('python' + env['PYTHON_VERSION'], 'python' + env['PYTHON_VERSION'].replace('.', '')):

		# LIBPATH_PYEMBED is already set; see if it works.
		if not result and env['LIBPATH_PYEMBED']:
			path = env['LIBPATH_PYEMBED']
			conf.to_log("\n\n# Trying default LIBPATH_PYEMBED: %r\n" % path)
			result = conf.check(lib=name, uselib='PYEMBED', libpath=path, mandatory=False, msg='Checking for library %s in LIBPATH_PYEMBED' % name)

		if not result and dct['LIBDIR']:
			path = [dct['LIBDIR']]
			conf.to_log("\n\n# try again with -L$python_LIBDIR: %r\n" % path)
			result = conf.check(lib=name, uselib='PYEMBED', libpath=path, mandatory=False, msg='Checking for library %s in LIBDIR' % name)

		if not result and dct['LIBPL']:
			path = [dct['LIBPL']]
			conf.to_log("\n\n# try again with -L$python_LIBPL (some systems don't install the python library in $prefix/lib)\n")
			result = conf.check(lib=name, uselib='PYEMBED', libpath=path, mandatory=False, msg='Checking for library %s in python_LIBPL' % name)

		if not result:
			path = [os.path.join(dct['prefix'], "libs")]
			conf.to_log("\n\n# try again with -L$prefix/libs, and pythonXY name rather than pythonX.Y (win32)\n")
			result = conf.check(lib=name, uselib='PYEMBED', libpath=path, mandatory=False, msg='Checking for library %s in $prefix/libs' % name)

		if result:
			break # do not forget to set LIBPATH_PYEMBED

	if result:
		env['LIBPATH_PYEMBED'] = path
		env.append_value('LIB_PYEMBED', [name])
	else:
		conf.to_log("\n\n### LIB NOT FOUND\n")

	# under certain conditions, python extensions must link to
	# python libraries, not just python embedding programs.
	if (Utils.is_win32 or sys.platform.startswith('os2')
		or dct['Py_ENABLE_SHARED']):
		env['LIBPATH_PYEXT'] = env['LIBPATH_PYEMBED']
		env['LIB_PYEXT'] = env['LIB_PYEMBED']

	# We check that pythonX.Y-config exists, and if it exists we
	# use it to get only the includes, else fall back to distutils.
	num = '.'.join(env['PYTHON_VERSION'].split('.')[:2])
	conf.find_program(['python%s-config' % num, 'python-config-%s' % num, 'python%sm-config' % num], var='PYTHON_CONFIG', mandatory=False)

	includes = []
	if conf.env.PYTHON_CONFIG:
		for incstr in conf.cmd_and_log([ conf.env.PYTHON_CONFIG, '--includes']).strip().split():
			# strip the -I or /I
			if (incstr.startswith('-I') or incstr.startswith('/I')):
				incstr = incstr[2:]
			# append include path, unless already given
			if incstr not in includes:
				includes.append(incstr)
		conf.to_log("Include path for Python extensions (found via python-config --includes): %r\n" % (includes,))
		env['INCLUDES_PYEXT'] = includes
		env['INCLUDES_PYEMBED'] = includes
	else:
		conf.to_log("Include path for Python extensions "
			       "(found via distutils module): %r\n" % (dct['INCLUDEPY'],))
		env['INCLUDES_PYEXT'] = [dct['INCLUDEPY']]
		env['INCLUDES_PYEMBED'] = [dct['INCLUDEPY']]

	# Code using the Python API needs to be compiled with -fno-strict-aliasing
	if env['CC_NAME'] == 'gcc':
		env.append_value('CFLAGS_PYEMBED', ['-fno-strict-aliasing'])
		env.append_value('CFLAGS_PYEXT', ['-fno-strict-aliasing'])
	if env['CXX_NAME'] == 'gcc':
		env.append_value('CXXFLAGS_PYEMBED', ['-fno-strict-aliasing'])
		env.append_value('CXXFLAGS_PYEXT', ['-fno-strict-aliasing'])

	if env.CC_NAME == "msvc":
		from distutils.msvccompiler import MSVCCompiler
		dist_compiler = MSVCCompiler()
		dist_compiler.initialize()
		env.append_value('CFLAGS_PYEXT', dist_compiler.compile_options)
		env.append_value('CXXFLAGS_PYEXT', dist_compiler.compile_options)
		env.append_value('LINKFLAGS_PYEXT', dist_compiler.ldflags_shared)

	# See if it compiles
	try:
		conf.check(header_name='Python.h', define_name='HAVE_PYTHON_H',
		   uselib='PYEMBED', fragment=FRAG,
		   errmsg='Could not find the python development headers')
	except conf.errors.ConfigurationError:
		# python3.2, oh yeah
		conf.check_cfg(path=conf.env.PYTHON_CONFIG, package='', uselib_store='PYEMBED', args=['--cflags', '--libs'])
		conf.check(header_name='Python.h', define_name='HAVE_PYTHON_H', msg='Getting the python flags from python-config',
			uselib='PYEMBED', fragment=FRAG, errmsg='Could not find the python development headers elsewhere')

@conf
def check_python_version(conf, minver=None):
	"""
	Check if the python interpreter is found matching a given minimum version.
	minver should be a tuple, eg. to check for python >= 2.4.2 pass (2,4,2) as minver.

	If successful, PYTHON_VERSION is defined as 'MAJOR.MINOR'
	(eg. '2.4') of the actual python version found, and PYTHONDIR is
	defined, pointing to the site-packages directory appropriate for
	this python version, where modules/packages/extensions should be
	installed.

	:param minver: minimum version
	:type minver: tuple of int
	"""
	assert minver is None or isinstance(minver, tuple)
	pybin = conf.env['PYTHON']
	if not pybin:
		conf.fatal('could not find the python executable')

	# Get python version string
	cmd = pybin + ['-c', 'import sys\nfor x in sys.version_info: print(str(x))']
	debug('python: Running python command %r' % cmd)
	lines = conf.cmd_and_log(cmd).split()
	assert len(lines) == 5, "found %i lines, expected 5: %r" % (len(lines), lines)
	pyver_tuple = (int(lines[0]), int(lines[1]), int(lines[2]), lines[3], int(lines[4]))

	# compare python version with the minimum required
	result = (minver is None) or (pyver_tuple >= minver)

	if result:
		# define useful environment variables
		pyver = '.'.join([str(x) for x in pyver_tuple[:2]])
		conf.env['PYTHON_VERSION'] = pyver

		if 'PYTHONDIR' in conf.environ:
			pydir = conf.environ['PYTHONDIR']
		else:
			if Utils.is_win32:
				(python_LIBDEST, pydir) = conf.get_python_variables(
					  ["get_config_var('LIBDEST') or ''",
					   "get_python_lib(standard_lib=0, prefix=%r) or ''" % conf.env['PREFIX']])
			else:
				python_LIBDEST = None
				(pydir,) = conf.get_python_variables( ["get_python_lib(standard_lib=0, prefix=%r) or ''" % conf.env['PREFIX']])
			if python_LIBDEST is None:
				if conf.env['LIBDIR']:
					python_LIBDEST = os.path.join(conf.env['LIBDIR'], "python" + pyver)
				else:
					python_LIBDEST = os.path.join(conf.env['PREFIX'], "lib", "python" + pyver)


		if 'PYTHONARCHDIR' in conf.environ:
			pyarchdir = conf.environ['PYTHONARCHDIR']
		else:
			(pyarchdir, ) = conf.get_python_variables( ["get_python_lib(plat_specific=1, standard_lib=0, prefix=%r) or ''" % conf.env['PREFIX']])
			if not pyarchdir:
				pyarchdir = pydir

		if hasattr(conf, 'define'): # conf.define is added by the C tool, so may not exist
			conf.define('PYTHONDIR', pydir)
			conf.define('PYTHONARCHDIR', pyarchdir)

		conf.env['PYTHONDIR'] = pydir
		conf.env['PYTHONARCHDIR'] = pyarchdir

	# Feedback
	pyver_full = '.'.join(map(str, pyver_tuple[:3]))
	if minver is None:
		conf.msg('Checking for python version', pyver_full)
	else:
		minver_str = '.'.join(map(str, minver))
		conf.msg('Checking for python version', pyver_tuple, ">= %s" % (minver_str,) and 'GREEN' or 'YELLOW')

	if not result:
		conf.fatal('The python version is too old, expecting %r' % (minver,))

PYTHON_MODULE_TEMPLATE = '''
import %s as current_module
version = getattr(current_module, '__version__', None)
if version is not None:
    print(str(version))
else:
    print('unknown version')
'''

@conf
def check_python_module(conf, module_name, condition=''):
	"""
	Check if the selected python interpreter can import the given python module::

		def configure(conf):
			conf.check_python_module('pygccxml')
			conf.check_python_module('re', condition="ver > num(2, 0, 4) and ver <= num(3, 0, 0)")

	:param module_name: module
	:type module_name: string
	"""
	msg = 'Python module %s' % module_name
	if condition:
		msg = '%s (%s)' % (msg, condition)
	conf.start_msg(msg)
	try:
		ret = conf.cmd_and_log(conf.env['PYTHON'] + ['-c', PYTHON_MODULE_TEMPLATE % module_name])
	except Exception:
		conf.end_msg(False)
		conf.fatal('Could not find the python module %r' % module_name)

	ret = ret.strip()
	if condition:
		conf.end_msg(ret)
		if ret == 'unknown version':
			conf.fatal('Could not check the %s version' % module_name)

		from distutils.version import LooseVersion
		def num(*k):
			if isinstance(k[0], int):
				return LooseVersion('.'.join([str(x) for x in k]))
			else:
				return LooseVersion(k[0])
		d = {'num': num, 'ver': LooseVersion(ret)}
		ev = eval(condition, {}, d)
		if not ev:
			conf.fatal('The %s version does not satisfy the requirements' % module_name)
	else:
		if ret == 'unknown version':
			conf.end_msg(True)
		else:
			conf.end_msg(ret)

def configure(conf):
	"""
	Detect the python interpreter
	"""
	try:
		conf.find_program('python', var='PYTHON')
	except conf.errors.ConfigurationError:
		warn("could not find a python executable, setting to sys.executable '%s'" % sys.executable)
		conf.env.PYTHON = sys.executable

	if conf.env.PYTHON != sys.executable:
		warn("python executable '%s' different from sys.executable '%s'" % (conf.env.PYTHON, sys.executable))
	conf.env.PYTHON = conf.cmd_to_list(conf.env.PYTHON)

	v = conf.env
	v['PYCMD'] = '"import sys, py_compile;py_compile.compile(sys.argv[1], sys.argv[2])"'
	v['PYFLAGS'] = ''
	v['PYFLAGS_OPT'] = '-O'

	v['PYC'] = getattr(Options.options, 'pyc', 1)
	v['PYO'] = getattr(Options.options, 'pyo', 1)

def options(opt):
	"""
	Add the options ``--nopyc`` and ``--nopyo``
	"""
	opt.add_option('--nopyc',
			action='store_false',
			default=1,
			help = 'Do not install bytecode compiled .pyc files (configuration) [Default:install]',
			dest = 'pyc')
	opt.add_option('--nopyo',
			action='store_false',
			default=1,
			help='Do not install optimised compiled .pyo files (configuration) [Default:install]',
			dest='pyo')


########NEW FILE########
__FILENAME__ = Utils
#!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2005-2010 (ita)

"""
Utilities and platform-specific fixes

The portability fixes try to provide a consistent behavior of the Waf API
through Python versions 2.3 to 3.X and across different platforms (win32, linux, etc)
"""

import os, sys, errno, traceback, inspect, re, shutil, datetime, gc
try:
	import subprocess
except:
	try:
		import waflib.extras.subprocess as subprocess
	except:
		print("The subprocess module is missing (python2.3?):\n try calling 'waf update --files=subprocess'\n or add a copy of subprocess.py to the python libraries")

try:
	from collections import deque
except ImportError:
	class deque(list):
		"""A deque for Python 2.3 which does not have one"""
		def popleft(self):
			return self.pop(0)
try:
	import _winreg as winreg
except:
	try:
		import winreg
	except:
		winreg = None

from waflib import Errors

try:
	from collections import UserDict
except:
	from UserDict import UserDict

try:
	from hashlib import md5
except:
	try:
		from md5 import md5
	except:
		# never fail to enable fixes from another module
		pass

try:
	import threading
except:
	class threading(object):
		"""
			A fake threading class for platforms lacking the threading module.
			Use ``waf -j1`` on those platforms
		"""
		pass
	class Lock(object):
		"""Fake Lock class"""
		def acquire(self):
			pass
		def release(self):
			pass
	threading.Lock = threading.Thread = Lock
else:
	run_old = threading.Thread.run
	def run(*args, **kwargs):
		try:
			run_old(*args, **kwargs)
		except (KeyboardInterrupt, SystemExit):
			raise
		except:
			sys.excepthook(*sys.exc_info())
	threading.Thread.run = run

SIG_NIL = 'iluvcuteoverload'.encode()
"""Arbitrary null value for a md5 hash. This value must be changed when the hash value is replaced (size)"""

O644 = 420
"""Constant representing the permissions for regular files (0644 raises a syntax error on python 3)"""

O755 = 493
"""Constant representing the permissions for executable files (0755 raises a syntax error on python 3)"""

rot_chr = ['\\', '|', '/', '-']
"List of characters to use when displaying the throbber (progress bar)"

rot_idx = 0
"Index of the current throbber character (progress bar)"

try:
	from collections import defaultdict
except ImportError:
	class defaultdict(dict):
		"""
		defaultdict was introduced in python 2.5, so we leave it for python 2.4 and 2.3
		"""
		def __init__(self, default_factory):
			super(defaultdict, self).__init__()
			self.default_factory = default_factory
		def __getitem__(self, key):
			try:
				return super(defaultdict, self).__getitem__(key)
			except KeyError:
				value = self.default_factory()
				self[key] = value
				return value

is_win32 = sys.platform in ('win32', 'cli')

# we should have put this in the Logs.py file instead :-/
indicator = '\x1b[K%s%s%s\r'
if is_win32 and 'NOCOLOR' in os.environ:
	indicator = '%s%s%s\r'

def readf(fname, m='r'):
	"""
	Read an entire file into a string, in practice the wrapper
	node.read(..) should be used instead of this method::

		def build(ctx):
			from waflib import Utils
			txt = Utils.readf(self.path.find_node('wscript').abspath())
			txt = ctx.path.find_node('wscript').read()

	:type  fname: string
	:param fname: Path to file
	:type  m: string
	:param m: Open mode
	:rtype: string
	:return: Content of the file
	"""
	f = open(fname, m)
	try:
		txt = f.read()
	finally:
		f.close()
	return txt

def h_file(filename):
	"""
	Compute a hash value for a file by using md5. This method may be replaced by
	a faster version if necessary. The following uses the file size and the timestamp value::

		import stat
		from waflib import Utils
		def h_file(filename):
			st = os.stat(filename)
			if stat.S_ISDIR(st[stat.ST_MODE]): raise IOError('not a file')
			m = Utils.md5()
			m.update(str(st.st_mtime))
			m.update(str(st.st_size))
			m.update(filename)
			return m.digest()
		Utils.h_file = h_file

	:type filename: string
	:param filename: path to the file to hash
	:return: hash of the file contents
	"""
	f = open(filename, 'rb')
	m = md5()
	try:
		while filename:
			filename = f.read(100000)
			m.update(filename)
	finally:
		f.close()
	return m.digest()

try:
	x = ''.encode('hex')
except:
	import binascii
	def to_hex(s):
		ret = binascii.hexlify(s)
		if not isinstance(ret, str):
			ret = ret.decode('utf-8')
		return ret
else:
	def to_hex(s):
		return s.encode('hex')

to_hex.__doc__ = """
Return the hexadecimal representation of a string

:param s: string to convert
:type s: string
"""

listdir = os.listdir
if is_win32:
	def listdir_win32(s):
		"""
		List the contents of a folder in a portable manner.

		:type s: string
		:param s: a string, which can be empty on Windows for listing the drive letters
		"""
		if not s:
			try:
				import ctypes
			except:
				# there is nothing much we can do
				return [x + ':\\' for x in list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')]
			else:
				dlen = 4 # length of "?:\\x00"
				maxdrives = 26
				buf = ctypes.create_string_buffer(maxdrives * dlen)
				ndrives = ctypes.windll.kernel32.GetLogicalDriveStringsA(maxdrives, ctypes.byref(buf))
				return [ buf.raw[4*i:4*i+3].decode('ascii') for i in range(int(ndrives/dlen)) ]

		if len(s) == 2 and s[1] == ":":
			s += os.sep

		if not os.path.isdir(s):
			e = OSError()
			e.errno = errno.ENOENT
			raise e
		return os.listdir(s)
	listdir = listdir_win32

def num2ver(ver):
	"""
	Convert a string, tuple or version number into an integer. The number is supposed to have at most 4 digits::

		from waflib.Utils import num2ver
		num2ver('1.3.2') == num2ver((1,3,2)) == num2ver((1,3,2,0))

	:type ver: string or tuple of numbers
	:param ver: a version number
	"""
	if isinstance(ver, str):
		ver = tuple(ver.split('.'))
	if isinstance(ver, tuple):
		ret = 0
		for i in range(4):
			if i < len(ver):
				ret += 256**(3 - i) * int(ver[i])
		return ret
	return ver

def ex_stack():
	"""
	Extract the stack to display exceptions

	:return: a string represening the last exception
	"""
	exc_type, exc_value, tb = sys.exc_info()
	exc_lines = traceback.format_exception(exc_type, exc_value, tb)
	return ''.join(exc_lines)

def to_list(sth):
	"""
	Convert a string argument to a list by splitting on spaces, and pass
	through a list argument unchanged::

		from waflib.Utils import to_list
		lst = to_list("a b c d")

	:param sth: List or a string of items separated by spaces
	:rtype: list
	:return: Argument converted to list

	"""
	if isinstance(sth, str):
		return sth.split()
	else:
		return sth

re_nl = re.compile('\r*\n', re.M)
def str_to_dict(txt):
	"""
	Parse a string with key = value pairs into a dictionary::

		from waflib import Utils
		x = Utils.str_to_dict('''
			a = 1
			b = test
		''')

	:type  s: string
	:param s: String to parse
	:rtype: dict
	:return: Dictionary containing parsed key-value pairs
	"""
	tbl = {}

	lines = re_nl.split(txt)
	for x in lines:
		x = x.strip()
		if not x or x.startswith('#') or x.find('=') < 0:
			continue
		tmp = x.split('=')
		tbl[tmp[0].strip()] = '='.join(tmp[1:]).strip()
	return tbl

def split_path(path):
	return path.split('/')

def split_path_cygwin(path):
	if path.startswith('//'):
		ret = path.split('/')[2:]
		ret[0] = '/' + ret[0]
		return ret
	return path.split('/')

re_sp = re.compile('[/\\\\]')
def split_path_win32(path):
	if path.startswith('\\\\'):
		ret = re.split(re_sp, path)[2:]
		ret[0] = '\\' + ret[0]
		return ret
	return re.split(re_sp, path)

if sys.platform == 'cygwin':
	split_path = split_path_cygwin
elif is_win32:
	split_path = split_path_win32

split_path.__doc__ = """
Split a path by / or \\. This function is not like os.path.split

:type  path: string
:param path: path to split
:return:     list of strings
"""

def check_dir(path):
	"""
	Ensure that a directory exists (similar to ``mkdir -p``).

	:type  dir: string
	:param dir: Path to directory
	"""
	if not os.path.isdir(path):
		try:
			os.makedirs(path)
		except OSError as e:
			if not os.path.isdir(path):
				raise Errors.WafError('Cannot create the folder %r' % path, ex=e)

def def_attrs(cls, **kw):
	"""
	Set default attributes on a class instance

	:type cls: class
	:param cls: the class to update the given attributes in.
	:type kw: dict
	:param kw: dictionary of attributes names and values.
	"""
	for k, v in kw.items():
		if not hasattr(cls, k):
			setattr(cls, k, v)

def quote_define_name(s):
	"""
	Convert a string to an identifier suitable for C defines.

	:type  s: string
	:param s: String to convert
	:rtype: string
	:return: Identifier suitable for C defines
	"""
	fu = re.compile("[^a-zA-Z0-9]").sub("_", s)
	fu = fu.upper()
	return fu

def h_list(lst):
	"""
	Hash lists. For tuples, using hash(tup) is much more efficient

	:param lst: list to hash
	:type lst: list of strings
	:return: hash of the list
	"""
	m = md5()
	m.update(str(lst).encode())
	return m.digest()

def h_fun(fun):
	"""
	Hash functions

	:param fun: function to hash
	:type  fun: function
	:return: hash of the function
	"""
	try:
		return fun.code
	except AttributeError:
		try:
			h = inspect.getsource(fun)
		except IOError:
			h = "nocode"
		try:
			fun.code = h
		except AttributeError:
			pass
		return h

reg_subst = re.compile(r"(\\\\)|(\$\$)|\$\{([^}]+)\}")
def subst_vars(expr, params):
	"""
	Replace ${VAR} with the value of VAR taken from a dict or a config set::

		from waflib import Utils
		s = Utils.subst_vars('${PREFIX}/bin', env)

	:type  expr: string
	:param expr: String to perform substitution on
	:param params: Dictionary or config set to look up variable values.
	"""
	def repl_var(m):
		if m.group(1):
			return '\\'
		if m.group(2):
			return '$'
		try:
			# ConfigSet instances may contain lists
			return params.get_flat(m.group(3))
		except AttributeError:
			return params[m.group(3)]
	return reg_subst.sub(repl_var, expr)

def destos_to_binfmt(key):
	"""
	Return the binary format based on the unversioned platform name.

	:param key: platform name
	:type  key: string
	:return: string representing the binary format
	"""
	if key == 'darwin':
		return 'mac-o'
	elif key in ('win32', 'cygwin', 'uwin', 'msys'):
		return 'pe'
	return 'elf'

def unversioned_sys_platform():
	"""
	Return the unversioned platform name.
	Some Python platform names contain versions, that depend on
	the build environment, e.g. linux2, freebsd6, etc.
	This returns the name without the version number. Exceptions are
	os2 and win32, which are returned verbatim.

	:rtype: string
	:return: Unversioned platform name
	"""
	s = sys.platform
	if s == 'java':
		# The real OS is hidden under the JVM.
		from java.lang import System
		s = System.getProperty('os.name')
		# see http://lopica.sourceforge.net/os.html for a list of possible values
		if s == 'Mac OS X':
			return 'darwin'
		elif s.startswith('Windows '):
			return 'win32'
		elif s == 'OS/2':
			return 'os2'
		elif s == 'HP-UX':
			return 'hpux'
		elif s in ('SunOS', 'Solaris'):
			return 'sunos'
		else: s = s.lower()
	
	# powerpc == darwin for our purposes
	if s == 'powerpc':
		return 'darwin'
	if s == 'win32' or s.endswith('os2') and s != 'sunos2': return s
	return re.split('\d+$', s)[0]

def nada(*k, **kw):
	"""
	A function that does nothing

	:return: None
	"""
	pass

class Timer(object):
	"""
	Simple object for timing the execution of commands.
	Its string representation is the current time::

		from waflib.Utils import Timer
		timer = Timer()
		a_few_operations()
		s = str(timer)
	"""
	def __init__(self):
		self.start_time = datetime.datetime.utcnow()

	def __str__(self):
		delta = datetime.datetime.utcnow() - self.start_time
		days = int(delta.days)
		hours = delta.seconds // 3600
		minutes = (delta.seconds - hours * 3600) // 60
		seconds = delta.seconds - hours * 3600 - minutes * 60 + float(delta.microseconds) / 1000 / 1000
		result = ''
		if days:
			result += '%dd' % days
		if days or hours:
			result += '%dh' % hours
		if days or hours or minutes:
			result += '%dm' % minutes
		return '%s%.3fs' % (result, seconds)

if is_win32:
	old = shutil.copy2
	def copy2(src, dst):
		"""
		shutil.copy2 does not copy the file attributes on windows, so we
		hack into the shutil module to fix the problem
		"""
		old(src, dst)
		shutil.copystat(src, dst)
	setattr(shutil, 'copy2', copy2)

if os.name == 'java':
	# Jython cannot disable the gc but they can enable it ... wtf?
	try:
		gc.disable()
		gc.enable()
	except NotImplementedError:
		gc.disable = gc.enable

def read_la_file(path):
	"""
	Read property files, used by msvc.py

	:param path: file to read
	:type path: string
	"""
	sp = re.compile(r'^([^=]+)=\'(.*)\'$')
	dc = {}
	for line in readf(path).splitlines():
		try:
			_, left, right, _ = sp.split(line.strip())
			dc[left] = right
		except ValueError:
			pass
	return dc

def nogc(fun):
	"""
	Decorator: let a function disable the garbage collector during its execution.
	It is used in the build context when storing/loading the build cache file (pickle)

	:param fun: function to execute
	:type fun: function
	:return: the return value of the function executed
	"""
	def f(*k, **kw):
		try:
			gc.disable()
			ret = fun(*k, **kw)
		finally:
			gc.enable()
		return ret
	f.__doc__ = fun.__doc__
	return f

def run_once(fun):
	"""
	Decorator: let a function cache its results, use like this::

		@run_once
		def foo(k):
			return 345*2343

	:param fun: function to execute
	:type fun: function
	:return: the return value of the function executed
	"""
	cache = {}
	def wrap(k):
		try:
			return cache[k]
		except KeyError:
			ret = fun(k)
			cache[k] = ret
			return ret
	wrap.__cache__ = cache
	return wrap

def get_registry_app_path(key, filename):
	if not winreg:
		return None
	try:
		result = winreg.QueryValue(key, "Software\\Microsoft\\Windows\\CurrentVersion\\App Paths\\%s.exe" % filename[0])
	except WindowsError:
		pass
	else:
		if os.path.isfile(result):
			return result


########NEW FILE########
