__FILENAME__ = autoscale
#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Copyright 2013 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

import pyrax
from pyrax.client import BaseClient
from pyrax.cloudloadbalancers import CloudLoadBalancer
import pyrax.exceptions as exc
from pyrax.manager import BaseManager
from pyrax.resource import BaseResource
import pyrax.utils as utils



class ScalingGroup(BaseResource):
    def __init__(self, *args, **kwargs):
        super(ScalingGroup, self).__init__(*args, **kwargs)
        self._non_display = ["active", "launchConfiguration", "links",
        "groupConfiguration", "policies", "scalingPolicies"]
        self._repr_properties = ["name", "cooldown", "metadata",
        "min_entities", "max_entities"]
        self._make_policies()


    def _make_policies(self):
        """
        Convert the 'scalingPolicies' dictionary into AutoScalePolicy objects.
        """
        self.policies = [AutoScalePolicy(self.manager, dct, self)
                for dct in self.scalingPolicies]


    def get_state(self):
        """
        Returns the current state of this scaling group.
        """
        return self.manager.get_state(self)


    def pause(self):
        """
        Pauses all execution of the policies for this scaling group.
        """
        return self.manager.pause(self)


    def resume(self):
        """
        Resumes execution of the policies for this scaling group.
        """
        return self.manager.resume(self)


    def update(self, name=None, cooldown=None, min_entities=None,
            max_entities=None, metadata=None):
        """
        Updates this ScalingGroup. One or more of the attributes can be
        specified.

        NOTE: if you specify metadata, it will *replace* any existing metadata.
        If you want to add to it, you either need to pass the complete dict of
        metadata, or call the update_metadata() method.
        """
        return self.manager.update(self, name=name,
                cooldown=cooldown, min_entities=min_entities,
                max_entities=max_entities, metadata=metadata)


    def update_metadata(self, metadata):
        """
        Adds the given metadata dict to the existing metadata for this scaling
        group.
        """
        return self.manager.update_metadata(self, metadata=metadata)


    def get_configuration(self):
        """
        Returns the scaling group configuration in a dictionary.
        """
        return self.manager.get_configuration(self)


    def get_launch_config(self):
        """
        Returns the launch configuration for this scaling group.
        """
        return self.manager.get_launch_config(self)


    def update_launch_config(self, server_name=None, image=None, flavor=None,
            disk_config=None, metadata=None, personality=None, networks=None,
            load_balancers=None, key_name=None):
        """
        Updates the server launch configuration for this scaling group.
        One or more of the available attributes can be specified.

        NOTE: if you specify metadata, it will *replace* any existing metadata.
        If you want to add to it, you either need to pass the complete dict of
        metadata, or call the update_launch_metadata() method.
        """
        return self.manager.update_launch_config(self, server_name=server_name,
                image=image, flavor=flavor, disk_config=disk_config,
                metadata=metadata, personality=personality, networks=networks,
                load_balancers=load_balancers, key_name=key_name)


    def update_launch_metadata(self, metadata):
        """
        Adds the given metadata dict to the existing metadata for this scaling
        group's launch configuration.
        """
        return self.manager.update_launch_metadata(self, metadata)


    def add_policy(self, name, policy_type, cooldown, change=None,
            is_percent=False, desired_capacity=None, args=None):
        """
        Adds a policy with the given values to this scaling group. The
        'change' parameter is treated as an absolute amount, unless
        'is_percent' is True, in which case it is treated as a percentage.
        """
        return self.manager.add_policy(self, name, policy_type, cooldown,
                change=change, is_percent=is_percent,
                desired_capacity=desired_capacity, args=args)


    def list_policies(self):
        """
        Returns a list of all policies defined for this scaling group.
        """
        return self.manager.list_policies(self)


    def get_policy(self, policy):
        """
        Gets the detail for the specified policy.
        """
        return self.manager.get_policy(self, policy)


    def update_policy(self, policy, name=None, policy_type=None, cooldown=None,
            change=None, is_percent=False, desired_capacity=None, args=None):
        """
        Updates the specified policy. One or more of the parameters may be
        specified.
        """
        return self.manager.update_policy(scaling_group=self, policy=policy,
                name=name, policy_type=policy_type, cooldown=cooldown,
                change=change, is_percent=is_percent,
                desired_capacity=desired_capacity, args=args)


    def execute_policy(self, policy):
        """
        Executes the specified policy for this scaling group.
        """
        return self.manager.execute_policy(scaling_group=self, policy=policy)


    def delete_policy(self, policy):
        """
        Deletes the specified policy from this scaling group.
        """
        return self.manager.delete_policy(scaling_group=self, policy=policy)


    def add_webhook(self, policy, name, metadata=None):
        """
        Adds a webhook to the specified policy.
        """
        return self.manager.add_webhook(self, policy, name, metadata=metadata)


    def list_webhooks(self, policy):
        """
        Returns a list of all webhooks for the specified policy.
        """
        return self.manager.list_webhooks(self, policy)


    def update_webhook(self, policy, webhook, name=None, metadata=None):
        """
        Updates the specified webhook. One or more of the parameters may be
        specified.
        """
        return self.manager.update_webhook(scaling_group=self, policy=policy,
                webhook=webhook, name=name, metadata=metadata)


    def update_webhook_metadata(self, policy, webhook, metadata):
        """
        Adds the given metadata dict to the existing metadata for the specified
        webhook.
        """
        return self.manager.update_webhook_metadata(self, policy, webhook,
                metadata)


    def delete_webhook(self, policy, webhook):
        """
        Deletes the specified webhook from the specified policy.
        """
        return self.manager.delete_webhook(self, policy, webhook)


    @property
    def policy_count(self):
        return len(self.policies)


    ##################################################################
    # The following property declarations allow access to the base attributes
    # of the ScalingGroup held in the 'groupConfiguration' dict as if they
    # were native attributes.
    ##################################################################
    @property
    def name(self):
        return self.groupConfiguration.get("name")

    @name.setter
    def name(self, val):
        self.groupConfiguration["name"] = val

    @property
    def cooldown(self):
        return self.groupConfiguration.get("cooldown")

    @cooldown.setter
    def cooldown(self, val):
        self.groupConfiguration["cooldown"] = val


    @property
    def metadata(self):
        return self.groupConfiguration.get("metadata")

    @metadata.setter
    def metadata(self, val):
        self.groupConfiguration["metadata"] = val


    @property
    def min_entities(self):
        return self.groupConfiguration.get("minEntities")

    @min_entities.setter
    def min_entities(self, val):
        self.groupConfiguration["minEntities"] = val


    @property
    def max_entities(self):
        return self.groupConfiguration.get("maxEntities")

    @max_entities.setter
    def max_entities(self, val):
        self.groupConfiguration["maxEntities"] = val
    ##################################################################



class ScalingGroupManager(BaseManager):
    def __init__(self, api, resource_class=None, response_key=None,
            plural_response_key=None, uri_base=None):
        super(ScalingGroupManager, self).__init__(api,
                resource_class=resource_class, response_key=response_key,
                plural_response_key=plural_response_key, uri_base=uri_base)


    def get_state(self, scaling_group):
        """
        Returns the current state of the specified scaling group as a
        dictionary.
        """
        uri = "/%s/%s/state" % (self.uri_base, utils.get_id(scaling_group))
        resp, resp_body = self.api.method_get(uri)
        data = resp_body["group"]
        ret = {}
        ret["active"] = [itm["id"] for itm in data["active"]]
        ret["active_capacity"] = data["activeCapacity"]
        ret["desired_capacity"] = data["desiredCapacity"]
        ret["pending_capacity"] = data["pendingCapacity"]
        ret["paused"] = data["paused"]
        return ret


    def pause(self, scaling_group):
        """
        Pauses all execution of the policies for the specified scaling group.
        """
        uri = "/%s/%s/pause" % (self.uri_base, utils.get_id(scaling_group))
        resp, resp_body = self.api.method_post(uri)
        return None


    def resume(self, scaling_group):
        """
        Resumes execution of the policies for the specified scaling group.
        """
        uri = "/%s/%s/resume" % (self.uri_base, utils.get_id(scaling_group))
        resp, resp_body = self.api.method_post(uri)
        return None


    def get_configuration(self, scaling_group):
        """
        Returns the scaling group's configuration in a dictionary.
        """
        uri = "/%s/%s/config" % (self.uri_base, utils.get_id(scaling_group))
        resp, resp_body = self.api.method_get(uri)
        return resp_body.get("groupConfiguration")


    def replace(self, scaling_group, name, cooldown, min_entities,
            max_entities, metadata=None):
        """
        Replace an existing ScalingGroup configuration. All of the attributes
        must be specified If you wish to delete any of the optional attributes,
        pass them in as None.
        """
        body = self._create_group_config_body(name, cooldown, min_entities,
                max_entities, metadata=metadata)
        group_id = utils.get_id(scaling_group)
        uri = "/%s/%s/config" % (self.uri_base, group_id)
        resp, resp_body = self.api.method_put(uri, body=body)


    def update(self, scaling_group, name=None, cooldown=None,
            min_entities=None, max_entities=None, metadata=None):
        """
        Updates an existing ScalingGroup. One or more of the attributes can
        be specified.

        NOTE: if you specify metadata, it will *replace* any existing metadata.
        If you want to add to it, you either need to pass the complete dict of
        metadata, or call the update_metadata() method.
        """
        if not isinstance(scaling_group, ScalingGroup):
            scaling_group = self.get(scaling_group)
        uri = "/%s/%s/config" % (self.uri_base, scaling_group.id)
        if cooldown is None:
            cooldown = scaling_group.cooldown
        if min_entities is None:
            min_entities = scaling_group.min_entities
        if max_entities is None:
            max_entities = scaling_group.max_entities
        body = {"name": name or scaling_group.name,
                "cooldown": cooldown,
                "minEntities": min_entities,
                "maxEntities": max_entities,
                "metadata": metadata or scaling_group.metadata,
                }
        resp, resp_body = self.api.method_put(uri, body=body)
        return None


    def update_metadata(self, scaling_group, metadata):
        """
        Adds the given metadata dict to the existing metadata for the scaling
        group.
        """
        if not isinstance(scaling_group, ScalingGroup):
            scaling_group = self.get(scaling_group)
        curr_meta = scaling_group.metadata
        curr_meta.update(metadata)
        return self.update(scaling_group, metadata=curr_meta)


    def get_launch_config(self, scaling_group):
        """
        Returns the launch configuration for the specified scaling group.
        """
        uri = "/%s/%s/launch" % (self.uri_base, utils.get_id(scaling_group))
        resp, resp_body = self.api.method_get(uri)
        ret = {}
        data = resp_body.get("launchConfiguration")
        ret["type"] = data.get("type")
        args = data.get("args", {})
        ret["load_balancers"] = args.get("loadBalancers")
        srv = args.get("server", {})
        ret["name"] = srv.get("name")
        ret["flavor"] = srv.get("flavorRef")
        ret["image"] = srv.get("imageRef")
        ret["disk_config"] = srv.get("OS-DCF:diskConfig")
        ret["metadata"] = srv.get("metadata")
        ret["personality"] = srv.get("personality")
        ret["networks"] = srv.get("networks")
        ret["key_name"] = srv.get("key_name")
        return ret


    def replace_launch_config(self, scaling_group, launch_config_type,
            server_name, image, flavor, disk_config=None, metadata=None,
            personality=None, networks=None, load_balancers=None,
            key_name=None):
        """
        Replace an existing launch configuration. All of the attributes must be
        specified. If you wish to delete any of the optional attributes, pass
        them in as None.
        """
        group_id = utils.get_id(scaling_group)
        uri = "/%s/%s/launch" % (self.uri_base, group_id)
        body = self._create_launch_config_body(
                launch_config_type=launch_config_type, server_name=server_name,
                image=image, flavor=flavor, disk_config=disk_config,
                metadata=metadata, personality=personality, networks=networks,
                load_balancers=load_balancers, key_name=key_name)
        resp, resp_body = self.api.method_put(uri, body=body)


    def update_launch_config(self, scaling_group, server_name=None, image=None,
            flavor=None, disk_config=None, metadata=None, personality=None,
            networks=None, load_balancers=None, key_name=None):
        """
        Updates the server launch configuration for an existing scaling group.
        One or more of the available attributes can be specified.

        NOTE: if you specify metadata, it will *replace* any existing metadata.
        If you want to add to it, you either need to pass the complete dict of
        metadata, or call the update_launch_metadata() method.
        """
        if not isinstance(scaling_group, ScalingGroup):
            scaling_group = self.get(scaling_group)
        uri = "/%s/%s/launch" % (self.uri_base, scaling_group.id)
        largs = scaling_group.launchConfiguration.get("args", {})
        srv_args = largs.get("server", {})
        lb_args = largs.get("loadBalancers", {})
        flav = "%s" % flavor or srv_args.get("flavorRef")
        dconf = disk_config or srv_args.get("OS-DCF:diskConfig")
        pers = personality or srv_args.get("personality")
        body = {"type": "launch_server",
                "args": {
                    "server": {
                        "name": server_name or srv_args.get("name"),
                        "imageRef": image or srv_args.get("imageRef"),
                        "flavorRef": flav,
                        "OS-DCF:diskConfig": dconf,
                        "personality": pers,
                        "networks": networks or srv_args.get("networks"),
                        "metadata": metadata or srv_args.get("metadata"),
                    },
                    "loadBalancers": load_balancers or lb_args,
                },
            }
        key_name = key_name or srv_args.get("key_name")
        if key_name:
            body["args"]["server"] = key_name
        resp, resp_body = self.api.method_put(uri, body=body)
        return None


    def update_launch_metadata(self, scaling_group, metadata):
        """
        Adds the given metadata dict to the existing metadata for the scaling
        group's launch configuration.
        """
        if not isinstance(scaling_group, ScalingGroup):
            scaling_group = self.get(scaling_group)
        curr_meta = scaling_group.launchConfiguration.get("args", {}).get(
                "server", {}).get("metadata", {})
        curr_meta.update(metadata)
        return self.update_launch_config(scaling_group, metadata=curr_meta)


    def add_policy(self, scaling_group, name, policy_type, cooldown,
            change=None, is_percent=False, desired_capacity=None, args=None):
        """
        Adds a policy with the given values to the specified scaling group. The
        'change' parameter is treated as an absolute amount, unless
        'is_percent' is True, in which case it is treated as a percentage.
        """
        uri = "/%s/%s/policies" % (self.uri_base, utils.get_id(scaling_group))
        body = self._create_policy_body(name, policy_type, cooldown,
                change=change, is_percent=is_percent,
                desired_capacity=desired_capacity, args=args)
        # "body" needs to be a list
        body = [body]
        resp, resp_body = self.api.method_post(uri, body=body)
        pol_info = resp_body.get("policies")[0]
        return AutoScalePolicy(self, pol_info, scaling_group)


    def _create_policy_body(self, name, policy_type, cooldown, change=None,
            is_percent=None, desired_capacity=None, args=None):
        body = {"name": name, "cooldown": cooldown, "type": policy_type}
        if change is not None:
            if is_percent:
                body["changePercent"] = change
            else:
                body["change"] = change
        if desired_capacity is not None:
            body["desiredCapacity"] = desired_capacity
        if args is not None:
            body["args"] = args
        return body


    def list_policies(self, scaling_group):
        """
        Returns a list of all policies defined for the specified scaling group.
        """
        uri = "/%s/%s/policies" % (self.uri_base, utils.get_id(scaling_group))
        resp, resp_body = self.api.method_get(uri)
        return [AutoScalePolicy(self, data, scaling_group)
                for data in resp_body.get("policies", [])]


    def get_policy(self, scaling_group, policy):
        """
        Gets the detail for the specified policy.
        """
        uri = "/%s/%s/policies/%s" % (self.uri_base,
                utils.get_id(scaling_group), utils.get_id(policy))
        resp, resp_body = self.api.method_get(uri)
        data = resp_body.get("policy")
        return AutoScalePolicy(self, data, scaling_group)


    def replace_policy(self, scaling_group, policy, name,
            policy_type, cooldown, change=None, is_percent=False,
            desired_capacity=None, args=None):
        """
        Replace an existing policy. All of the attributes must be specified. If
        you wish to delete any of the optional attributes, pass them in as
        None.
        """
        policy_id = utils.get_id(policy)
        group_id = utils.get_id(scaling_group)
        uri = "/%s/%s/policies/%s" % (self.uri_base, group_id, policy_id)
        body = self._create_policy_body(name=name, policy_type=policy_type,
                cooldown=cooldown, change=change, is_percent=is_percent,
                desired_capacity=desired_capacity, args=args)
        resp, resp_body = self.api.method_put(uri, body=body)


    def update_policy(self, scaling_group, policy, name=None, policy_type=None,
            cooldown=None, change=None, is_percent=False,
            desired_capacity=None, args=None):
        """
        Updates the specified policy. One or more of the parameters may be
        specified.
        """
        uri = "/%s/%s/policies/%s" % (self.uri_base,
                utils.get_id(scaling_group), utils.get_id(policy))
        if not isinstance(policy, AutoScalePolicy):
            # Received an ID
            policy = self.get_policy(scaling_group, policy)
        body = {"name": name or policy.name,
                "type": policy_type or policy.type,
                "cooldown": cooldown or policy.cooldown,
                }
        if desired_capacity is not None:
            body["desiredCapacity"] = desired_capacity
        elif change is not None:
            if is_percent:
                body["changePercent"] = change
            else:
                body["change"] = change
        else:
            if getattr(policy, "changePercent", None) is not None:
                body["changePercent"] = policy.changePercent
            elif getattr(policy, "change", None) is not None:
                body["change"] = policy.change
            elif getattr(policy, "desiredCapacity", None) is not None:
                body["desiredCapacity"] = policy.desiredCapacity
        args = args or getattr(policy, "args", None)
        if args is not None:
            body["args"] = args
        resp, resp_body = self.api.method_put(uri, body=body)
        return None


    def execute_policy(self, scaling_group, policy):
        """
        Executes the specified policy for this scaling group.
        """
        uri = "/%s/%s/policies/%s/execute" % (self.uri_base,
                utils.get_id(scaling_group), utils.get_id(policy))
        resp, resp_body = self.api.method_post(uri)
        return None


    def delete_policy(self, scaling_group, policy):
        """
        Deletes the specified policy from the scaling group.
        """
        uri = "/%s/%s/policies/%s" % (self.uri_base,
                utils.get_id(scaling_group), utils.get_id(policy))
        resp, resp_body = self.api.method_delete(uri)

    def _create_webhook_body(self, name, metadata=None):
        if metadata is None:
            # If updating a group with existing metadata, metadata MUST be
            # passed. Leaving it out causes Otter to return 400.
            metadata = {}
        body = {"name": name, "metadata": metadata}
        return body

    def add_webhook(self, scaling_group, policy, name, metadata=None):
        """
        Adds a webhook to the specified policy.
        """
        uri = "/%s/%s/policies/%s/webhooks" % (self.uri_base,
                utils.get_id(scaling_group), utils.get_id(policy))
        body = self._create_webhook_body(name, metadata=metadata)
        # "body" needs to be a list
        body = [body]
        resp, resp_body = self.api.method_post(uri, body=body)
        data = resp_body.get("webhooks")[0]
        return AutoScaleWebhook(self, data, policy, scaling_group)


    def list_webhooks(self, scaling_group, policy):
        """
        Returns a list of all webhooks for the specified policy.
        """
        uri = "/%s/%s/policies/%s/webhooks" % (self.uri_base,
                utils.get_id(scaling_group), utils.get_id(policy))
        resp, resp_body = self.api.method_get(uri)
        return [AutoScaleWebhook(self, data, policy, scaling_group)
                for data in resp_body.get("webhooks", [])]


    def get_webhook(self, scaling_group, policy, webhook):
        """
        Gets the detail for the specified webhook.
        """
        uri = "/%s/%s/policies/%s/webhooks/%s" % (self.uri_base,
                utils.get_id(scaling_group), utils.get_id(policy),
                utils.get_id(webhook))
        resp, resp_body = self.api.method_get(uri)
        data = resp_body.get("webhook")
        return AutoScaleWebhook(self, data, policy, scaling_group)


    def replace_webhook(self, scaling_group, policy, webhook, name,
            metadata=None):
        """
        Replace an existing webhook. All of the attributes must be specified.
        If you wish to delete any of the optional attributes, pass them in as
        None.
        """
        uri = "/%s/%s/policies/%s/webhooks/%s" % (self.uri_base,
                utils.get_id(scaling_group), utils.get_id(policy),
                utils.get_id(webhook))
        group_id = utils.get_id(scaling_group)
        policy_id = utils.get_id(policy)
        webhook_id = utils.get_id(webhook)
        body = self._create_webhook_body(name, metadata=metadata)
        resp, resp_body = self.api.method_put(uri, body=body)


    def update_webhook(self, scaling_group, policy, webhook, name=None,
            metadata=None):
        """
        Updates the specified webhook. One or more of the parameters may be
        specified.
        """
        uri = "/%s/%s/policies/%s/webhooks/%s" % (self.uri_base,
                utils.get_id(scaling_group), utils.get_id(policy),
                utils.get_id(webhook))
        if not isinstance(webhook, AutoScaleWebhook):
            # Received an ID
            webhook = self.get_webhook(scaling_group, policy, webhook)
        body = {"name": name or webhook.name,
                "metadata": metadata or webhook.metadata,
                }
        resp, resp_body = self.api.method_put(uri, body=body)
        webhook.reload()
        return webhook


    def update_webhook_metadata(self, scaling_group, policy, webhook, metadata):
        """
        Adds the given metadata dict to the existing metadata for the specified
        webhook.
        """
        if not isinstance(webhook, AutoScaleWebhook):
            webhook = self.get_webhook(scaling_group, policy, webhook)
        curr_meta = webhook.metadata or {}
        curr_meta.update(metadata)
        return self.update_webhook(scaling_group, policy, webhook,
                metadata=curr_meta)


    def delete_webhook(self, scaling_group, policy, webhook):
        """
        Deletes the specified webhook from the specified policy.
        """
        uri = "/%s/%s/policies/%s/webhooks/%s" % (self.uri_base,
                utils.get_id(scaling_group), utils.get_id(policy),
                utils.get_id(webhook))
        resp, resp_body = self.api.method_delete(uri)
        return None


    @staticmethod
    def _resolve_lbs(load_balancers):
        """
        Takes either a single LB reference or a list of references and returns
        the dictionary required for creating a Scaling Group.

        References can be either a dict that matches the structure required by
        the autoscale API, a CloudLoadBalancer instance, or the ID of the load
        balancer.
        """
        lb_args = []
        if not isinstance(load_balancers, list):
            lbs = [load_balancers]
        else:
            lbs = load_balancers
        for lb in lbs:
            if isinstance(lb, dict):
                lb_args.append(lb)
            elif isinstance(lb, CloudLoadBalancer):
                lb_args.append({
                        "loadBalancerId": lb.id,
                        "port": lb.port,
                        })
            elif isinstance(lb, tuple):
                lb_args.append({"loadBalancerId": lb[0],
                        "port": lb[1]})
            else:
                # See if it's an ID for a Load Balancer
                try:
                    instance = pyrax.cloud_loadbalancers.get(lb)
                except Exception:
                    raise exc.InvalidLoadBalancer("Received an invalid "
                            "specification for a Load Balancer: '%s'" % lb)
                lb_args.append({
                        "loadBalancerId": instance.id,
                        "port": instance.port,
                        })
        return lb_args


    def _create_body(self, name, cooldown, min_entities, max_entities,
            launch_config_type, server_name, image, flavor, disk_config=None,
            metadata=None, personality=None, networks=None,
            load_balancers=None, scaling_policies=None, group_metadata=None,
            key_name=None):
        """
        Used to create the dict required to create any of the following:
            A Scaling Group
        """
#        if disk_config is None:
#            disk_config = "AUTO"
        if metadata is None:
            metadata = {}
        if personality is None:
            personality = []
        if scaling_policies is None:
            scaling_policies = []
        group_config = self._create_group_config_body(name, cooldown,
                min_entities, max_entities, metadata=group_metadata)
        launch_config = self._create_launch_config_body(launch_config_type,
                server_name, image, flavor, disk_config=disk_config,
                metadata=metadata, personality=personality, networks=networks,
                load_balancers=load_balancers, key_name=key_name)
        body = {
                "groupConfiguration": group_config,
                "launchConfiguration": launch_config,
                "scalingPolicies": scaling_policies,
                }
        return body


    def _create_group_config_body(self, name, cooldown, min_entities,
            max_entities, metadata=None):
        if metadata is None:
            # If updating a group with existing metadata, metadata MUST be
            # passed. Leaving it out causes Otter to return 400.
            metadata = {}
        body = {
                "name": name,
                "cooldown": cooldown,
                "minEntities": min_entities,
                "maxEntities": max_entities,
                "metadata": metadata,
                }
        return body


    def _create_launch_config_body(self, launch_config_type,
            server_name, image, flavor, disk_config=None, metadata=None,
            personality=None, networks=None, load_balancers=None,
            key_name=None):
        server_args = {
                "flavorRef": "%s" % flavor,
                "name": server_name,
                "imageRef": utils.get_id(image),
                }
        if metadata is not None:
            server_args["metadata"] = metadata
        if personality is not None:
            server_args["personality"] = personality
        if networks is not None:
            server_args["networks"] = networks
        if disk_config is not None:
            server_args["OS-DCF:diskConfig"] = disk_config
        if key_name is not None:
            server_args["key_name"] = key_name
        if load_balancers is None:
            load_balancers = []
        load_balancer_args = self._resolve_lbs(load_balancers)
        return {"type": launch_config_type,
                "args": {"server": server_args,
                         "loadBalancers": load_balancer_args}}



class AutoScalePolicy(BaseResource):
    def __init__(self, manager, info, scaling_group, *args, **kwargs):
        super(AutoScalePolicy, self).__init__(manager, info, *args, **kwargs)
        if not isinstance(scaling_group, ScalingGroup):
            scaling_group = manager.get(scaling_group)
        self.scaling_group = scaling_group
        self._non_display = ["links", "scaling_group"]


    def get(self):
        """
        Gets the details for this policy.
        """
        return self.manager.get_policy(self.scaling_group, self)
    reload = get


    def delete(self):
        """
        Deletes this policy.
        """
        return self.manager.delete_policy(self.scaling_group, self)


    def update(self, name=None, policy_type=None, cooldown=None, change=None,
            is_percent=False, desired_capacity=None, args=None):
        """
        Updates this policy. One or more of the parameters may be
        specified.
        """
        return self.manager.update_policy(scaling_group=self.scaling_group,
                policy=self, name=name, policy_type=policy_type,
                cooldown=cooldown, change=change, is_percent=is_percent,
                desired_capacity=desired_capacity, args=args)


    def execute(self):
        """
        Executes this policy.
        """
        return self.manager.execute_policy(self.scaling_group, self)


    def add_webhook(self, name, metadata=None):
        """
        Adds a webhook to this policy.
        """
        return self.manager.add_webhook(self.scaling_group, self, name,
                metadata=metadata)


    def list_webhooks(self):
        """
        Returns a list of all webhooks for this policy.
        """
        return self.manager.list_webhooks(self.scaling_group, self)


    def get_webhook(self, webhook):
        """
        Gets the detail for the specified webhook.
        """
        return self.manager.get_webhook(self.scaling_group, self, webhook)


    def update_webhook(self, webhook, name=None, metadata=None):
        """
        Updates the specified webhook. One or more of the parameters may be
        specified.
        """
        return self.manager.update_webhook(self.scaling_group, policy=self,
                webhook=webhook, name=name, metadata=metadata)


    def update_webhook_metadata(self, webhook, metadata):
        """
        Adds the given metadata dict to the existing metadata for the specified
        webhook.
        """
        return self.manager.update_webhook_metadata(self.scaling_group, self,
                webhook, metadata)


    def delete_webhook(self, webhook):
        """
        Deletes the specified webhook from this policy.
        """
        return self.manager.delete_webhook(self.scaling_group, self, webhook)



class AutoScaleWebhook(BaseResource):
    def __init__(self, manager, info, policy, scaling_group, *args, **kwargs):
        super(AutoScaleWebhook, self).__init__(manager, info, *args, **kwargs)
        if not isinstance(policy, AutoScalePolicy):
            policy = manager.get_policy(scaling_group, policy)
        self.policy = policy
        self._non_display = ["links", "policy"]


    def get(self):
        return self.policy.get_webhook(self)
    reload = get


    def update(self, name=None, metadata=None):
        """
        Updates this webhook. One or more of the parameters may be specified.
        """
        return self.policy.update_webhook(self, name=name, metadata=metadata)


    def update_metadata(self, metadata):
        """
        Adds the given metadata dict to the existing metadata for this webhook.
        """
        return self.policy.update_webhook_metadata(self, metadata)


    def delete(self):
        """
        Deletes this webhook.
        """
        return self.policy.delete_webhook(self)



class AutoScaleClient(BaseClient):
    """
    This is the primary class for interacting with AutoScale.
    """
    name = "Autoscale"

    def _configure_manager(self):
        """
        Creates a manager to handle autoscale operations.
        """
        self._manager = ScalingGroupManager(self,
                resource_class=ScalingGroup, response_key="group",
                uri_base="groups")


    def get_state(self, scaling_group):
        """
        Returns the current state of the specified scaling group.
        """
        return self._manager.get_state(scaling_group)


    def pause(self, scaling_group):
        """
        Pauses all execution of the policies for the specified scaling group.
        """
        # NOTE: This is not yet implemented. The code is based on the docs,
        # so it should either work or be pretty close.
        return self._manager.pause(scaling_group)


    def resume(self, scaling_group):
        """
        Resumes execution of the policies for the specified scaling group.
        """
        # NOTE: This is not yet implemented. The code is based on the docs,
        # so it should either work or be pretty close.
        return self._manager.resume(scaling_group)


    def replace(self, scaling_group, name, cooldown, min_entities,
            max_entities, metadata=None):
        """
        Replace an existing ScalingGroup configuration. All of the attributes
        must be specified. If you wish to delete any of the optional
        attributes, pass them in as None.
        """
        return self._manager.replace(scaling_group, name, cooldown,
                min_entities, max_entities, metadata=metadata)


    def update(self, scaling_group, name=None, cooldown=None, min_entities=None,
            max_entities=None, metadata=None):
        """
        Updates an existing ScalingGroup. One or more of the attributes can be
        specified.

        NOTE: if you specify metadata, it will *replace* any existing metadata.
        If you want to add to it, you either need to pass the complete dict of
        metadata, or call the update_metadata() method.
        """
        return self._manager.update(scaling_group, name=name, cooldown=cooldown,
                min_entities=min_entities, max_entities=max_entities,
                metadata=metadata)


    def update_metadata(self, scaling_group, metadata):
        """
        Adds the given metadata dict to the existing metadata for the scaling
        group.
        """
        return self._manager.update_metadata(scaling_group, metadata)


    def get_configuration(self, scaling_group):
        """
        Returns the scaling group's configuration in a dictionary.
        """
        return self._manager.get_configuration(scaling_group)


    def get_launch_config(self, scaling_group):
        """
        Returns the launch configuration for the specified scaling group.
        """
        return self._manager.get_launch_config(scaling_group)


    def replace_launch_config(self, scaling_group, launch_config_type,
            server_name, image, flavor, disk_config=None, metadata=None,
            personality=None, networks=None, load_balancers=None,
            key_name=None):
        """
        Replace an existing launch configuration. All of the attributes must be
        specified. If you wish to delete any of the optional attributes, pass
        them in as None.
        """
        return self._manager.replace_launch_config(scaling_group,
                launch_config_type, server_name, image, flavor,
                disk_config=disk_config, metadata=metadata,
                personality=personality, networks=networks,
                load_balancers=load_balancers, key_name=key_name)


    def update_launch_config(self, scaling_group, server_name=None, image=None,
            flavor=None, disk_config=None, metadata=None, personality=None,
            networks=None, load_balancers=None, key_name=None):
        """
        Updates the server launch configuration for an existing scaling group.
        One or more of the available attributes can be specified.

        NOTE: if you specify metadata, it will *replace* any existing metadata.
        If you want to add to it, you either need to pass the complete dict of
        metadata, or call the update_launch_metadata() method.
        """
        return self._manager.update_launch_config(scaling_group,
                server_name=server_name, image=image, flavor=flavor,
                disk_config=disk_config, metadata=metadata,
                personality=personality, networks=networks,
                load_balancers=load_balancers, key_name=key_name)


    def update_launch_metadata(self, scaling_group, metadata):
        """
        Adds the given metadata dict to the existing metadata for the scaling
        group's launch configuration.
        """
        return self._manager.update_launch_metadata(scaling_group, metadata)


    def add_policy(self, scaling_group, name, policy_type, cooldown,
            change=None, is_percent=False, desired_capacity=None, args=None):
        """
        Adds a policy with the given values to the specified scaling group. The
        'change' parameter is treated as an absolute amount, unless
        'is_percent' is True, in which case it is treated as a percentage.
        """
        return self._manager.add_policy(scaling_group, name, policy_type,
                cooldown, change=change, is_percent=is_percent,
                desired_capacity=desired_capacity, args=args)


    def list_policies(self, scaling_group):
        """
        Returns a list of all policies defined for the specified scaling group.
        """
        return self._manager.list_policies(scaling_group)


    def get_policy(self, scaling_group, policy):
        """
        Gets the detail for the specified policy.
        """
        return self._manager.get_policy(scaling_group, policy)


    def replace_policy(self, scaling_group, policy, name,
            policy_type, cooldown, change=None, is_percent=False,
            desired_capacity=None, args=None):
        """
        Replace an existing policy. All of the attributes must be specified. If
        you wish to delete any of the optional attributes, pass them in as
        None.
        """
        return self._manager.replace_policy(scaling_group, policy, name,
                policy_type, cooldown, change=change, is_percent=is_percent,
                desired_capacity=desired_capacity, args=args)


    def update_policy(self, scaling_group, policy, name=None, policy_type=None,
            cooldown=None, change=None, is_percent=False,
            desired_capacity=None, args=None):
        """
        Updates the specified policy. One or more of the parameters may be
        specified.
        """
        return self._manager.update_policy(scaling_group, policy, name=name,
                policy_type=policy_type, cooldown=cooldown, change=change,
                is_percent=is_percent, desired_capacity=desired_capacity,
                args=args)


    def execute_policy(self, scaling_group, policy):
        """
        Executes the specified policy for the scaling group.
        """
        return self._manager.execute_policy(scaling_group=scaling_group,
                policy=policy)


    def delete_policy(self, scaling_group, policy):
        """
        Deletes the specified policy from the scaling group.
        """
        return self._manager.delete_policy(scaling_group=scaling_group,
                policy=policy)


    def add_webhook(self, scaling_group, policy, name, metadata=None):
        """
        Adds a webhook to the specified policy.
        """
        return self._manager.add_webhook(scaling_group, policy, name,
                metadata=metadata)


    def list_webhooks(self, scaling_group, policy):
        """
        Returns a list of all webhooks defined for the specified policy.
        """
        return self._manager.list_webhooks(scaling_group, policy)


    def get_webhook(self, scaling_group, policy, webhook):
        """
        Gets the detail for the specified webhook.
        """
        return self._manager.get_webhook(scaling_group, policy, webhook)


    def replace_webhook(self, scaling_group, policy, webhook, name,
            metadata=None):
        """
        Replace an existing webhook. All of the attributes must be specified.
        If you wish to delete any of the optional attributes, pass them in as
        None.
        """
        return self._manager.replace_webhook(scaling_group, policy, webhook,
                name, metadata=metadata)


    def update_webhook(self, scaling_group, policy, webhook, name=None,
            metadata=None):
        """
        Updates the specified webhook. One or more of the parameters may be
        specified.
        """
        return self._manager.update_webhook(scaling_group=scaling_group,
                policy=policy, webhook=webhook, name=name, metadata=metadata)


    def update_webhook_metadata(self, scaling_group, policy, webhook, metadata):
        """
        Adds the given metadata dict to the existing metadata for the specified
        webhook.
        """
        return self._manager.update_webhook_metadata(scaling_group, policy,
                webhook, metadata)


    def delete_webhook(self, scaling_group, policy, webhook):
        """
        Deletes the specified webhook from the policy.
        """
        return self._manager.delete_webhook(scaling_group, policy, webhook)

########NEW FILE########
__FILENAME__ = base_identity
#!/usr/bin/env python
# -*- coding: utf-8 -*-


from __future__ import absolute_import

import six.moves.configparser as ConfigParser
import datetime
import json
import re
import requests

try:
    import keyring
except ImportError:
    keyring = None

import pyrax
from . import exceptions as exc
from .resource import BaseResource
from . import utils


_pat = r"""
        (\d{4})-(\d{2})-(\d{2})     # YYYY-MM-DD
        T                           # Separator
        (\d{2}):(\d{2}):(\d{2})     # HH:MM:SS
        \.\d+                       # Decimal and fractional seconds
        ([\-\+])(\d{2}):(\d{2})     # TZ offset, in Â±HH:00 format
        """
_utc_pat = r"""
        (\d{4})-(\d{2})-(\d{2})     # YYYY-MM-DD
        T                           # Separator
        (\d{2}):(\d{2}):(\d{2})     # HH:MM:SS
        \.?\d*                      # Decimal and fractional seconds
        Z                           # UTC indicator
        """
API_DATE_PATTERN = re.compile(_pat, re.VERBOSE)
UTC_API_DATE_PATTERN = re.compile(_utc_pat, re.VERBOSE)
DATE_FORMAT = "%Y-%m-%d %H:%M:%S"

# Default region for all services. Can be individually overridden if needed
default_region = None


class Tenant(BaseResource):
    pass


class User(BaseResource):
    pass


class Role(BaseResource):
    pass


class Service(object):
    """
    Represents an available service from the service catalog.
    """
    def __init__(self, identity, catalog):
        """
        Parse the catalog entry for a particular service.
        """
        self.identity = identity
        self.name = catalog.get("name")
        # Replace any dashes with underscores.
        fulltype = catalog["type"].replace("-", "_")
        # Some provider-specific services are prefixed with that info.
        try:
            self.prefix, self.service_type = fulltype.split(":")
        except ValueError:
            self.prefix = ""
            self.service_type = fulltype
        if self.service_type == "compute":
            if self.name.lower() == "cloudservers":
                # First-generation Rackspace cloud servers
                return
        self.clients = {}
        self.endpoints = utils.DotDict()
        eps = catalog.get("endpoints", [])
        for ep in eps:
            rgn = ep.get("region", "ALL")
            self.endpoints[rgn] = Endpoint(ep, self.service_type, rgn, identity)
        return


    def __repr__(self):
        memloc = hex(id(self))
        return "<'%s' Service object at %s>" % (self.service_type, memloc)


    def _ep_for_region(self, region):
        """
        Given a region, returns the Endpoint for that region, or the Endpoint
        for the ALL region if no match is found. If no match is found, None
        is returned, and it is up to the calling method to handle it
        appropriately.
        """
        rgn = region.upper()
        try:
            rgn_ep = [ep for ep in list(self.endpoints.values())
                    if ep.region.upper() == rgn][0]
        except IndexError:
            # See if there is an 'ALL' region.
            try:
                rgn_ep = [ep for ep in list(self.endpoints.values())
                        if ep.region.upper() == "ALL"][0]
            except IndexError:
                rgn_ep = None
        return rgn_ep


    def get_client(self, region):
        """
        Returns an instance of the appropriate client class for the given
        region. If there is no endpoint for that region, a NoEndpointForRegion
        exception is raised.
        """
        ep = self._ep_for_region(region)
        if not ep:
            raise exc.NoEndpointForRegion("There is no endpoint defined for the "
                    "region '%s' for the '%s' service." % (region,
                    self.service_type))
        return ep.client


    @property
    def regions(self):
        """
        Returns a list of all regions which support this service.
        """
        return list(self.endpoints.keys())



class Endpoint(object):
    """
    Holds the endpoint information, as well as an instance of the appropriate
    client for that service and region.
    """
    public_url = None
    private_url = None
    tenant_id = None
    region = None
    _client = None
    _client_private = None
    attr_map = {"publicURL": "public_url",
            "privateURL": "private_url",
            "internalURL": "private_url",
            "tenantId": "tenant_id",
            }


    def __init__(self, ep_dict, service, region, identity):
        """
        Set local attributes from the supplied dictionary.
        """
        self.service = service
        self.region = region
        self.identity = identity
        for key, val in list(ep_dict.items()):
            att_name = self.attr_map.get(key, key)
            setattr(self, att_name, val)


    def get_new_client(self, public=True):
        """
        Returns a new instance of the client for this endpoint.
        """
        return self._get_client(public=public, cached=False)


    def _get_client(self, public=True, cached=True):
        client_att = "_client" if public else "_client_private"
        clt = getattr(self, client_att)
        if isinstance(clt, exc.NoClientForService):
            # Already failed
            raise clt
        if cached and clt is not None:
            return clt
        # Create the client
        clt_class = pyrax.client_class_for_service(self.service)
        if clt_class is None:
            noclass = exc.NoClientForService("No client for the '%s' service "
                    "has been registered." % self.service)
            setattr(self, client_att, noclass)
            raise noclass
        url_att = "public_url" if public else "private_url"
        url = getattr(self, url_att)
        if not url:
            nourl = exc.NoEndpointForService("No %s endpoint is available for "
                    "the '%s' service." % (url_att, self.service))
            setattr(self, client_att, nourl)
            raise nourl
        clt = self._create_client(clt_class, url, public=public)
        setattr(self, client_att, clt)
        return clt


    def get(self, url_type):
        """
        Accepts either 'public' or 'private' as a parameter, and returns the
        corresponding value for 'public_url' or 'private_url', respectively.
        """
        lowtype = url_type.lower()
        if lowtype == "public":
            return self.public_url
        elif lowtype == "private":
            return self.private_url
        else:
            raise ValueError("Valid values are 'public' or 'private'; "
                    "received '%s'." % url_type)


    def __getattr__(self, att):
        clt = self.client
        ret = getattr(clt, att, None)
        if ret:
            return ret
        else:
            raise AttributeError("Endpoint for service '%s' in region '%s' "
                    "has no attribute '%s'." % (self.service, self.region, att))


    @property
    def client(self):
        return self._get_client(public=True)


    @property
    def client_private(self):
        return self._get_client(public=False)


    def _create_client(self, clt_class, url, public=True):
        """
        Creates a client instance for the service.
        """
        verify_ssl = pyrax.get_setting("verify_ssl")
        if self.service == "object_store":
            # Swiftclient requires different parameters.
            client = pyrax.connect_to_cloudfiles(region=self.region,
                    public=public, context=self.identity)
        elif self.service == "compute":
            # Novaclient also requires special handling.
            client = pyrax.connect_to_cloudservers(region=self.region,
                    context=self.identity)
        else:
            client = clt_class(self.identity, region_name=self.region,
                    management_url=url, verify_ssl=verify_ssl)
        return client



class BaseIdentity(object):
    """
    This class handles all of the basic authentication requirements for working
    with an OpenStack Cloud system.
    """
    _creds_style = "password"

    def __init__(self, username=None, password=None, tenant_id=None,
            tenant_name=None, auth_endpoint=None, api_key=None, token=None,
            credential_file=None, region=None, timeout=None, verify_ssl=True):
        """
        Initializes the attributes for this identity object.
        """
        self.username = username
        self.password = password
        self.tenant_id = tenant_id
        self.tenant_name = tenant_name
        self.token = token
        self.expires = None
        self.region = region
        self._creds_file = credential_file
        self._timeout = timeout
        self.verify_ssl = verify_ssl
        self._auth_endpoint = auth_endpoint
        self.api_key = api_key
        self.services = utils.DotDict()
        self.regions = utils.DotDict()
        self._default_creds_style = "password"
        self.authenticated = False
        self.user_agent = "pyrax"
        self.http_log_debug = False
        self._default_region = None
        self.service_mapping = {
                "cloudservers": "compute",
                "nova": "compute",
                "cloudfiles": "object_store",
                "swift": "object_store",
                "cloud_loadbalancers": "load_balancer",
                "cloud_databases": "database",
                "trove": "database",
                "cloud_blockstorage": "volume",
                "cinder": "volume",
                "cloud_dns": "dns",
                "designate": "dns",
                "cloud_networks": "network",
                "neutron": "network",
                "cloud_monitoring": "monitor",
                "autoscale": "autoscale",
                "images": "image",
                "glance": "image",
                "queues": "queues",
                "marconi": "queues",
                }


    @property
    def auth_token(self):
        """Simple alias to self.token."""
        return self.token


    @property
    def auth_endpoint(self):
        """
        Abstracts out the logic for connecting to different auth endpoints.
        """
        return self._get_auth_endpoint()


    @auth_endpoint.setter
    def auth_endpoint(self, val):
        self._auth_endpoint = val


    def _get_auth_endpoint(self):
        """
        Broken out in case subclasses need to determine endpoints dynamically.
        """
        return self._auth_endpoint or pyrax.get_setting("auth_endpoint")


    def get_default_region(self):
        """
        In cases where the region has not been specified, return the value to
        use. Subclasses may use information in the service catalog to determine
        the appropriate default value.
        """
        return self._default_region


    def __getattr__(self, att):
        """
        Magic to allow for specification of client by region/service or by
        service/region.

        If a service is specified, this should return an object whose endpoints
        contain keys for each available region for that service. If a region is
        specified, an object with keys for each service available in that
        region should be returned.
        """
        if not self.authenticated:
            raise exc.NotAuthenticated("Authentication required before "
                    "accessing the context.")
        # First see if it's a service
        att = self.service_mapping.get(att) or att
        svc = self.services.get(att)
        if svc is not None:
            return svc.endpoints
        # Either invalid service, or a region
        ret = utils.DotDict([(stype, svc.endpoints.get(att))
                for stype, svc in list(self.services.items())
                if svc.endpoints.get(att) is not None])
        ret._att_mapper.update(self.service_mapping)
        if ret:
            return ret
        # Invalid attribute
        raise AttributeError("No such attribute '%s'." % att)


    def get_client(self, service, region, public=True, cached=True):
        """
        Returns the client object for the specified service and region.

        By default the public endpoint is used. If you wish to work with a
        services internal endpoints, specify `public=False`.

        By default, if a client has already been created for the given service,
        region, and public values, that will be returned. To force a new client
        to be created, pass 'cached=False'.
        """
        if not self.authenticated:
            raise exc.NotAuthenticated("You must authenticate before trying "
                    "to create clients.")
        clt = ep = None
        mapped_service = self.service_mapping.get(service) or service
        svc = self.services.get(mapped_service)
        if svc:
            ep = svc.endpoints.get(region)
        if ep:
            if cached:
                clt = ep.client if public else ep.client_private
            else:
                clt = ep.get_new_client(public=public)
        if not clt:
            raise exc.NoSuchClient("There is no client available for the "
                    "service '%s' in the region '%s'." % (service, region))
        return clt


    def set_credentials(self, username, password=None, region=None,
            tenant_id=None, authenticate=False):
        """Sets the username and password directly."""
        self.username = username
        self.password = password
        self.tenant_id = tenant_id
        if region:
            self.region = region
        if authenticate:
            self.authenticate()


    def set_credential_file(self, credential_file, region=None,
            tenant_id=None, authenticate=False):
        """
        Reads in the credentials from the supplied file. It should be
        a standard config file in the format:

        [keystone]
        username = myusername
        password = top_secret
        tenant_id = my_id

        """
        self._creds_file = credential_file
        cfg = ConfigParser.SafeConfigParser()
        try:
            if not cfg.read(credential_file):
                # If the specified file does not exist, the parser returns an
                # empty list.
                raise exc.FileNotFound("The specified credential file '%s' "
                        "does not exist" % credential_file)
        except ConfigParser.MissingSectionHeaderError as e:
            # The file exists, but doesn't have the correct format.
            raise exc.InvalidCredentialFile(e)
        try:
            self._read_credential_file(cfg)
        except (ConfigParser.NoSectionError, ConfigParser.NoOptionError) as e:
            raise exc.InvalidCredentialFile(e)
        if region:
            self.region = region
        if authenticate:
            self.authenticate()


    def auth_with_token(self, token, tenant_id=None, tenant_name=None):
        """
        If a valid token is already known, this call uses it to generate the
        service catalog.
        """
        resp, resp_body = self._call_token_auth(token, tenant_id, tenant_name)
        self._parse_response(resp_body)
        self.authenticated = True


    def _call_token_auth(self, token, tenant_id, tenant_name):
        key = val = None
        if tenant_id:
            key = "tenantId"
            val = tenant_id
        elif tenant_name:
            key = "tenantName"
            val = tenant_name

        body = {"auth": {
                "token": {"id": token},
                }}

        if(key and val):
            body["auth"][key] = val

        headers = {"Content-Type": "application/json",
                "Accept": "application/json",
                }
        resp, resp_body = self.method_post("tokens", data=body, headers=headers,
                std_headers=False)
        if resp.status_code == 401:
            # Invalid authorization
            raise exc.AuthenticationFailed("Incorrect/unauthorized "
                    "credentials received")
        elif resp.status_code > 299:
            msg = resp_body[resp_body.keys()[0]]["message"]
            raise exc.AuthenticationFailed("%s - %s." % (resp.reason, msg))
        return resp, resp_body


    def _read_credential_file(self, cfg):
        """
        Implements the default (keystone) behavior.
        """
        self.username = cfg.get("keystone", "username")
        self.password = cfg.get("keystone", "password", raw=True)
        self.tenant_id = cfg.get("keystone", "tenant_id")


    def _format_credentials(self):
        """
        Returns the current credentials in the format expected by
        the authentication service.
        """
        tenant_name = self.tenant_name or self.username
        tenant_id = self.tenant_id or self.username
        return {"auth": {"passwordCredentials":
                {"username": self.username,
                "password": self.password,
                },
                "tenantId": tenant_id}}


    # The following method_* methods wrap the _call() method.
    def method_head(self, uri, admin=False, data=None, headers=None,
            std_headers=True):
        return self._call("HEAD", uri, admin, data, headers, std_headers)

    def method_get(self, uri, admin=False, data=None, headers=None,
            std_headers=True):
        return self._call("GET", uri, admin, data, headers, std_headers)

    def method_post(self, uri, admin=False, data=None, headers=None,
            std_headers=True):
        return self._call("POST", uri, admin, data, headers, std_headers)

    def method_put(self, uri, admin=False, data=None, headers=None,
            std_headers=True):
        return self._call("PUT", uri, admin, data, headers, std_headers)

    def method_delete(self, uri, admin=False, data=None, headers=None,
            std_headers=True):
        return self._call("DELETE", uri, admin, data, headers,
                std_headers)

    def method_patch(self, uri, admin=False, data=None, headers=None,
            std_headers=True):
        return self._call("PATCH", uri, admin, data, headers,
                std_headers)


    def _call(self, mthd, uri, admin, data, headers, std_headers):
        """
        Handles all the common functionality required for API calls. Returns
        the resulting response object.
        """
        if not uri.startswith("http"):
            uri = "/".join((self.auth_endpoint.rstrip("/"), uri))
        if admin:
            # Admin calls use a different port
            uri = re.sub(r":\d+/", ":35357/", uri)
        if std_headers:
            hdrs = self._standard_headers()
        else:
            hdrs = {}
        if headers:
            hdrs.update(headers)
        kwargs = {"headers": hdrs}
        if data:
            kwargs["body"] = data
        if "tokens" in uri:
            # We'll handle the exception here
            kwargs["raise_exception"] = False
        return pyrax.http.request(mthd, uri, **kwargs)


    def authenticate(self, username=None, password=None, api_key=None,
            tenant_id=None):
        """
        Using the supplied credentials, connects to the specified
        authentication endpoint and attempts to log in.

        Credentials can either be passed directly to this method, or
        previously-stored credentials can be used. If authentication is
        successful, the token and service catalog information is stored, and
        clients for each service and region are created.
        """
        self.username = username or self.username or pyrax.get_setting(
                "username")
        # Different identity systems may pass these under inconsistent names.
        self.password = password or self.password or api_key or self.api_key
        self.api_key = api_key or self.api_key or self.password
        self.tenant_id = tenant_id or self.tenant_id or pyrax.get_setting(
                "tenant_id")
        creds = self._format_credentials()
        headers = {"Content-Type": "application/json",
                "Accept": "application/json",
                }
        resp, resp_body = self.method_post("tokens", data=creds,
                headers=headers, std_headers=False)

        if resp.status_code == 401:
            # Invalid authorization
            raise exc.AuthenticationFailed("Incorrect/unauthorized "
                    "credentials received")
        elif 500 <= resp.status_code < 600:
            # Internal Server Error
            try:
                error_msg = resp_body[list(resp_body.keys())[0]]["message"]
            except KeyError:
                error_msg = "Service Currently Unavailable"
            raise exc.InternalServerError(error_msg)
        elif resp.status_code > 299:
            try:
                msg = resp_body[list(resp_body.keys())[0]]["message"]
            except KeyError:
                msg = None
            if msg:
                err = "%s - %s." % (resp.reason, msg)
            else:
                err = "%s." % resp.reason
            raise exc.AuthenticationFailed(err)
        self._parse_response(resp_body)
        self.authenticated = True


    def _parse_response(self, resp):
        """Gets the authentication information from the returned JSON."""
        access = resp["access"]
        token = access.get("token")
        self.token = token["id"]
        self.tenant_id = token["tenant"]["id"]
        self.tenant_name = token["tenant"]["name"]
        self.expires = self._parse_api_time(token["expires"])
        self.service_catalog = access.get("serviceCatalog")
        self._parse_service_catalog()
        user = access["user"]
        self.user = {}
        self.user["id"] = user["id"]
        self.username = self.user["name"] = user["name"]
        self.user["roles"] = user["roles"]


    def _parse_service_catalog(self):
        self.services = utils.DotDict()
        self.regions = set()
        for svc in self.service_catalog:
            service = Service(self, svc)
            if not hasattr(service, "endpoints"):
                # Not an OpenStack service
                continue
            setattr(self.services, service.service_type, service)
            self.regions.update(list(service.endpoints.keys()))
        # Update the 'ALL' services to include all available regions.
        self.regions.discard("ALL")
        for nm, svc in list(self.services.items()):
            eps = svc.endpoints
            ep = eps.pop("ALL", None)
            if ep:
                for rgn in self.regions:
                    eps[rgn] = ep


    def keyring_auth(self, username=None):
        """
        Uses the keyring module to retrieve the user's password or api_key.
        """
        if not keyring:
            # Module not installed
            raise exc.KeyringModuleNotInstalled("The 'keyring' Python module "
                    "is not installed on this system.")
        if username is None:
            username = pyrax.get_setting("keyring_username")
        if not username:
            raise exc.KeyringUsernameMissing("No username specified for "
                    "keyring authentication.")
        password = keyring.get_password("pyrax", username)
        if password is None:
            raise exc.KeyringPasswordNotFound("No password was found for the "
                    "username '%s'." % username)
        style = self._creds_style or self._default_creds_style
        # Keyring username may be different than the credentials. Use the
        # existing username, if present; otherwise, use the supplied username.
        username = self.username or username
        if style == "apikey":
            return self.authenticate(username=username, api_key=password)
        else:
            return self.authenticate(username=username, password=password)


    def unauthenticate(self):
        """
        Clears out any credentials, tokens, and service catalog info.
        """
        self.username = ""
        self.password = ""
        self.tenant_id = ""
        self.tenant_name = ""
        self.token = ""
        self.expires = None
        self.region = ""
        self._creds_file = None
        self.api_key = ""
        self.services = utils.DotDict()
        self.regions = utils.DotDict()
        self.authenticated = False


    def _standard_headers(self):
        """
        Returns a dict containing the standard headers for API calls.
        """
        return {"Content-Type": "application/json",
                "Accept": "application/json",
                "X-Auth-Token": self.token,
                "X-Auth-Project-Id": self.tenant_id,
                }


    def get_extensions(self):
        """
        Returns a list of extensions enabled on this service.
        """
        resp, resp_body = self.method_get("extensions")
        return resp_body.get("extensions", {}).get("values")


    def get_token(self, force=False):
        """
        Returns the auth token, if it is valid. If not, calls the auth endpoint
        to get a new token. Passing 'True' to 'force' forces a call for a new
        token, even if there already is a valid token.
        """
        self.authenticated = self._has_valid_token()
        if force or not self.authenticated:
            self.authenticate()
        return self.token


    def _has_valid_token(self):
        """
        This only checks the token's existence and expiration. If it has been
        invalidated on the server, this method may indicate that the token is
        valid when it might actually not be.
        """
        return bool(self.token and (self.expires > datetime.datetime.now()))


    def list_tokens(self):
        """
        ADMIN ONLY. Returns a dict containing tokens, endpoints, user info, and
        role metadata.
        """
        resp, resp_body = self.method_get("tokens/%s" % self.token, admin=True)
        if resp.status_code in (401, 403):
            raise exc.AuthorizationFailure("You must be an admin to make this "
                    "call.")
        return resp_body.get("access")


    def check_token(self, token=None):
        """
        ADMIN ONLY. Returns True or False, depending on whether the current
        token is valid.
        """
        if token is None:
            token = self.token
        resp, resp_body = self.method_head("tokens/%s" % token, admin=True)
        if resp.status_code in (401, 403):
            raise exc.AuthorizationFailure("You must be an admin to make this "
                    "call.")
        return 200 <= resp.status_code < 300


    def revoke_token(self, token):
        """
        ADMIN ONLY. Returns True or False, depending on whether deletion of the
        specified token was successful.
        """
        resp, resp_body = self.method_delete("tokens/%s" % token, admin=True)
        if resp.status_code in (401, 403):
            raise exc.AuthorizationFailure("You must be an admin to make this "
                    "call.")
        return 200 <= resp.status_code < 300


    def get_token_endpoints(self):
        """
        ADMIN ONLY. Returns a list of all endpoints for the current auth token.
        """
        resp, resp_body = self.method_get("tokens/%s/endpoints" % self.token,
                admin=True)
        if resp.status_code in (401, 403, 404):
            raise exc.AuthorizationFailure("You are not authorized to list "
                    "token endpoints.")
        return resp_body.get("access", {}).get("endpoints")


    def list_users(self):
        """
        ADMIN ONLY. Returns a list of objects for all users for the tenant
        (account) if this request is issued by a user holding the admin role
        (identity:user-admin).
        """
        resp, resp_body = self.method_get("users", admin=True)
        if resp.status_code in (401, 403, 404):
            raise exc.AuthorizationFailure("You are not authorized to list "
                    "users.")
        # The API is inconsistent; if only one user exists, it does not return
        # a list.
        if "users" in resp_body:
            users = resp_body["users"]
        else:
            users = resp_body
        # The returned values may contain password data. Strip that out.
        for user in users:
            bad_keys = [key for key in list(user.keys())
                    if "password" in key.lower()]
            for bad_key in bad_keys:
                user.pop(bad_key)
        return [User(self, user) for user in users]


    def create_user(self, name, email, password=None, enabled=True):
        """
        ADMIN ONLY. Creates a new user for this tenant (account). The username
        and email address must be supplied. You may optionally supply the
        password for this user; if not, the API server generates a password and
        return it in the 'password' attribute of the resulting User object.
        NOTE: this is the ONLY time the password is returned; after the initial
        user creation, there is NO WAY to retrieve the user's password.

        You may also specify that the user should be created but not active by
        passing False to the enabled parameter.
        """
        # NOTE: the OpenStack docs say that the name key in the following dict
        # is supposed to be 'username', but the service actually expects 'name'.
        data = {"user": {
                "username": name,
                "email": email,
                "enabled": enabled,
                }}
        if password:
            data["user"]["OS-KSADM:password"] = password
        resp, resp_body = self.method_post("users", data=data, admin=True)
        if resp.status_code == 201:
            return User(self, resp_body.get("user", resp_body))
        elif resp.status_code in (401, 403, 404):
            raise exc.AuthorizationFailure("You are not authorized to create "
                    "users.")
        elif resp.status_code == 409:
            raise exc.DuplicateUser("User '%s' already exists." % name)
        elif resp.status_code == 400:
            message = resp_body["badRequest"]["message"]
            if "Expecting valid email address" in message:
                raise exc.InvalidEmail("%s is not valid" % email)
            else:
                raise exc.BadRequest(message)


    def find_user_by_name(self, name):
        """
        Returns a User object by searching for the supplied user name. Returns
        None if there is no match for the given name.
        """
        raise NotImplementedError("This method is not supported.")


    def find_user_by_email(self, email):
        """
        Returns a User object by searching for the supplied user's email
        address. Returns None if there is no match for the given ID.
        """
        raise NotImplementedError("This method is not supported.")


    def find_user_by_id(self, uid):
        """
        Returns a User object by searching for the supplied user ID. Returns
        None if there is no match for the given ID.
        """
        raise NotImplementedError("This method is not supported.")


    def get_user(self, user_id=None, username=None, email=None):
        """
        Returns the user specified by either ID, username or email.

        Since more than user can have the same email address, searching by that
        term returns a list of 1 or more User objects. Searching by username or
        ID returns a single User.

        If a user_id that doesn't belong to the current account is searched
        for, a Forbidden exception is raised. When searching by username or
        email, a NotFound exception is raised if there is no matching user.
        """
        raise NotImplementedError("This method is not supported.")


    # Can we really update the ID? Docs seem to say we can
    def update_user(self, user, email=None, username=None,
            uid=None, enabled=None):
        """
        ADMIN ONLY. Updates the user attributes with the supplied values.
        """
        user_id = utils.get_id(user)
        uri = "users/%s" % user_id
        upd = {"id": user_id}
        if email is not None:
            upd["email"] = email
        if username is not None:
            upd["username"] = username
        if enabled is not None:
            upd["enabled"] = enabled
        data = {"user": upd}
        resp, resp_body = self.method_put(uri, data=data)
        if resp.status_code in (401, 403, 404):
            raise exc.AuthorizationFailure("You are not authorized to update "
                    "users.")
        return User(self, resp_body)


    def delete_user(self, user):
        """
        ADMIN ONLY. Removes the user from the system. There is no 'undo'
        available, so you should be certain that the user specified is the user
        you wish to delete.
        """
        user_id = utils.get_id(user)
        uri = "users/%s" % user_id
        resp, resp_body = self.method_delete(uri)
        if resp.status_code == 404:
            raise exc.UserNotFound("User '%s' does not exist." % user)
        elif resp.status_code in (401, 403):
            raise exc.AuthorizationFailure("You are not authorized to delete "
                    "users.")


    def list_roles_for_user(self, user):
        """
        ADMIN ONLY. Returns a list of roles for the specified user. Each role
        will be a 3-tuple, consisting of (role_id, role_name,
        role_description).
        """
        user_id = utils.get_id(user)
        uri = "users/%s/roles" % user_id
        resp, resp_body = self.method_get(uri)
        if resp.status_code in (401, 403):
            raise exc.AuthorizationFailure("You are not authorized to list "
                    "user roles.")
        roles = resp_body.get("roles")
        return roles


    def list_credentials(self, user=None):
        """
        Returns a user's non-password credentials. If no user is specified, the
        credentials for the currently authenticated user are returned.

        You cannot retrieve passwords by this or any other means.
        """
        if not user:
            user = self.user
        user_id = utils.get_id(user)
        uri = "users/%s/OS-KSADM/credentials" % user_id
        resp, resp_body = self.method_get(uri)
        return resp_body.get("credentials")


    def reset_api_key(self, user=None):
        """
        Not available in basic Keystone identity.
        """
        raise NotImplementedError("The reset_api_key method is not "
                "implemented.")


    def get_tenant(self):
        """
        Returns the tenant for the current user.
        """
        tenants = self._list_tenants(admin=False)
        if tenants:
            return tenants[0]
        return None


    def list_tenants(self, admin=True):
        """
        Lists all tenants associated with the currently authenticated
        user (admin=False), or all tenants (admin=True).
        """
        return self._list_tenants(admin)


    def _list_tenants(self, admin):
        """
        Returns either a list of all tenants (admin=True), or the tenant for
        the currently-authenticated user (admin=False).
        """
        resp, resp_body = self.method_get("tenants", admin=admin)
        if 200 <= resp.status_code < 300:
            tenants = resp_body.get("tenants", [])
            return [Tenant(self, tenant) for tenant in tenants]
        elif resp.status_code in (401, 403):
            raise exc.AuthorizationFailure("You are not authorized to list "
                    "tenants.")
        else:
            raise exc.TenantNotFound("Could not get a list of tenants.")


    def create_tenant(self, name, description=None, enabled=True):
        """
        ADMIN ONLY. Creates a new tenant.
        """
        data = {"tenant": {
                "name": name,
                "enabled": enabled,
                }}
        if description:
            data["tenant"]["description"] = description
        resp, resp_body = self.method_post("tenants", data=data)
        return Tenant(self, resp_body)


    def update_tenant(self, tenant, name=None, description=None, enabled=True):
        """
        ADMIN ONLY. Updates an existing tenant.
        """
        tenant_id = utils.get_id(tenant)
        data = {"tenant": {
                "enabled": enabled,
                }}
        if name:
            data["tenant"]["name"] = name
        if description:
            data["tenant"]["description"] = description
        resp, resp_body = self.method_put("tenants/%s" % tenant_id, data=data)
        return Tenant(self, resp_body)


    def delete_tenant(self, tenant):
        """
        ADMIN ONLY. Removes the tenant from the system. There is no 'undo'
        available, so you should be certain that the tenant specified is the
        tenant you wish to delete.
        """
        tenant_id = utils.get_id(tenant)
        uri = "tenants/%s" % tenant_id
        resp, resp_body = self.method_delete(uri)
        if resp.status_code == 404:
            raise exc.TenantNotFound("Tenant '%s' does not exist." % tenant)


    def list_roles(self, service_id=None, limit=None, marker=None):
        """
        Returns a list of all global roles for users, optionally limited by
        service. Pagination can be handled through the standard 'limit' and
        'marker' parameters.
        """
        uri = "OS-KSADM/roles"
        pagination_items = []
        if service_id is not None:
            pagination_items.append("serviceId=%s" % service_id)
        if limit is not None:
            pagination_items.append("limit=%s" % limit)
        if marker is not None:
            pagination_items.append("marker=%s" % marker)
        pagination = "&".join(pagination_items)
        if pagination:
            uri = "%s?%s" % (uri, pagination)
        resp, resp_body = self.method_get(uri)
        roles = resp_body.get("roles", [])
        return [Role(self, role) for role in roles]


    def get_role(self, role):
        """
        Returns a Role object representing the specified parameter. The 'role'
        parameter can be either an existing Role object, or the ID of the role.

        If an invalid role is passed, a NotFound exception is raised.
        """
        uri = "OS-KSADM/roles/%s" % utils.get_id(role)
        resp, resp_body = self.method_get(uri)
        role = Role(self, resp_body.get("role"))
        return role


    def add_role_to_user(self, role, user):
        """
        Adds the specified role to the specified user.

        There is no return value upon success. Passing a non-existent role or
        user raises a NotFound exception.
        """
        uri = "users/%s/roles/OS-KSADM/%s" % (utils.get_id(user),
                utils.get_id(role))
        resp, resp_body = self.method_put(uri)


    def delete_role_from_user(self, role, user):
        """
        Deletes the specified role from the specified user.

        There is no return value upon success. Passing a non-existent role or
        user raises a NotFound exception.
        """
        uri = "users/%s/roles/OS-KSADM/%s" % (utils.get_id(user),
                utils.get_id(role))
        resp, resp_body = self.method_delete(uri)


    @staticmethod
    def _parse_api_time(timestr):
        """
        Typical expiration times returned from the auth server are in this
        format:
            2012-05-02T14:27:40.000-05:00
        They can also be returned as a UTC value in this format:
            2012-05-02T14:27:40.000Z
        This method returns a proper datetime object from either of these
        formats.
        """
        try:
            reg_groups = API_DATE_PATTERN.match(timestr).groups()
            yr, mth, dy, hr, mn, sc, off_sign, off_hr, off_mn = reg_groups
        except AttributeError:
            # UTC dates don't show offsets.
            utc_groups = UTC_API_DATE_PATTERN.match(timestr).groups()
            yr, mth, dy, hr, mn, sc = utc_groups
            off_sign = "+"
            off_hr = off_mn = 0
        base_dt = datetime.datetime(int(yr), int(mth), int(dy), int(hr),
                int(mn), int(sc))
        delta = datetime.timedelta(hours=int(off_hr), minutes=int(off_mn))
        if off_sign == "+":
            # Time is greater than UTC
            ret = base_dt - delta
        else:
            ret = base_dt + delta
        return ret

########NEW FILE########
__FILENAME__ = client
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import logging
import datetime
from functools import wraps
import hashlib
import hmac
# Use eventlet if available
try:
    import eventlet.green.httplib as httplib
except ImportError:
    import httplib
import locale
import math
import os
import re
import socket
import threading
import time
import urllib
import urlparse
import uuid
import mimetypes

import six

from swiftclient import client as _swift_client
import pyrax
from pyrax.cf_wrapper.container import Container
from pyrax.cf_wrapper.storage_object import StorageObject
import pyrax.utils as utils
import pyrax.exceptions as exc


EARLY_DATE_STR = "1900-01-01T00:00:00"
DATE_FORMAT = "%Y-%m-%dT%H:%M:%S"
HEAD_DATE_FORMAT = "%a, %d %b %Y %H:%M:%S %Z"
# Format of last_modified in list responses, reverse engineered from sample
# responses at
# http://docs.rackspace.com/files/api/v1/cf-devguide/content/
#   Serialized_List_Output-d1e1460.html
LIST_DATE_FORMAT = "%Y-%m-%dT%H:%M:%S.%f"
CONNECTION_TIMEOUT = 20
CONNECTION_RETRIES = 5
AUTH_ATTEMPTS = 2
MAX_BULK_DELETE = 10000

no_such_container_pattern = re.compile(
        r"Container (?:GET|HEAD) failed: .+/(.+) 404")
no_such_object_pattern = re.compile(r"Object (?:GET|HEAD) failed: .+/(.+) 404")
etag_fail_pat = r"Object PUT failed: .+/([^/]+)/(\S+) 422 Unprocessable Entity"
etag_failed_pattern = re.compile(etag_fail_pat)


def _close_swiftclient_conn(conn):
    """Swiftclient often leaves the connection open."""
    try:
        conn.http_conn[1].close()
    except Exception:
        pass


def handle_swiftclient_exception(fnc):
    @wraps(fnc)
    def _wrapped(self, *args, **kwargs):
        attempts = 0
        clt_url = self.connection.url

        while attempts < AUTH_ATTEMPTS:
            attempts += 1
            try:
                _close_swiftclient_conn(self.connection)
                ret = fnc(self, *args, **kwargs)
                return ret
            except _swift_client.ClientException as e:
                str_error = "%s" % e
                if e.http_status == 401:
                    if attempts < AUTH_ATTEMPTS:
                        # Assume it is an auth failure. Re-auth and retry.
                        # NOTE: This is a hack to get around an apparent bug
                        # in python-swiftclient when using Rackspace auth.
                        pyrax.authenticate(connect=False)
                        if pyrax.identity.authenticated:
                            pyrax.plug_hole_in_swiftclient_auth(self, clt_url)
                        continue
                elif e.http_status == 404:
                    bad_container = no_such_container_pattern.search(str_error)
                    if bad_container:
                        raise exc.NoSuchContainer("Container '%s' doesn't exist"
                                % bad_container.groups()[0])
                    bad_object = no_such_object_pattern.search(str_error)
                    if bad_object:
                        raise exc.NoSuchObject("Object '%s' doesn't exist" %
                                bad_object.groups()[0])
                failed_upload = etag_failed_pattern.search(str_error)
                if failed_upload:
                    cont, fname = failed_upload.groups()
                    raise exc.UploadFailed("Upload of file '%(fname)s' to "
                            "container '%(cont)s' failed." % locals())
                # Not handled; re-raise
                raise
    return _wrapped


def ensure_cdn(fnc):
    @wraps(fnc)
    def _wrapped(self, *args, **kwargs):
        if not self.connection.cdn_connection:
            raise exc.NotCDNEnabled("This service does not support "
                    "CDN-enabled containers.")
        return fnc(self, *args, **kwargs)
    return _wrapped


def _convert_head_object_last_modified_to_local(lm_str):
    # Need to convert last modified time to a datetime object.
    # Times are returned in default locale format, so we need to read
    # them as such, no matter what the locale setting may be.
    orig_locale = locale.getlocale(locale.LC_TIME)
    locale.setlocale(locale.LC_TIME, (None, None))
    try:
        tm_tuple = time.strptime(lm_str, HEAD_DATE_FORMAT)
    finally:
        locale.setlocale(locale.LC_TIME, orig_locale)
    dttm = datetime.datetime.fromtimestamp(time.mktime(tm_tuple))
    # Now convert it back to the format returned by GETting the object.
    dtstr = dttm.strftime(DATE_FORMAT)
    return dtstr


def _convert_list_last_modified_to_local(attdict):
    if "last_modified" in attdict:
        attdict = attdict.copy()
        list_date_format_with_tz = LIST_DATE_FORMAT + " %Z"
        last_modified_utc = attdict["last_modified"] + " UTC"
        tm_tuple = time.strptime(last_modified_utc,
                                 list_date_format_with_tz)
        dttm = datetime.datetime.fromtimestamp(time.mktime(tm_tuple))

        dttm_with_micros = datetime.datetime.strptime(last_modified_utc,
                list_date_format_with_tz)
        # Round the date *up* in seconds, to match the last modified time
        # in head requests
        # https://review.openstack.org/#/c/55488/
        if dttm_with_micros.microsecond > 0:
            dttm += datetime.timedelta(seconds=1)
        attdict["last_modified"] = dttm.strftime(DATE_FORMAT)
    return attdict


def _quote(val):
    if isinstance(val, six.text_type):
        val = val.encode("utf-8")
    return urllib.quote(val)



class CFClient(object):
    """
    Wraps the calls to swiftclient with objects representing Containers
    and StorageObjects.

    These classes allow a developer to work with regular Python objects
    instead of calling functions that return primitive types.
    """
    # Defaults for CDN
    cdn_enabled = False
    default_cdn_ttl = 86400
    _container_cache = {}
    _cached_temp_url_key = ""
    # Upload size limit
    max_file_size = 5368709119  # 5GB - 1
    # Folder upload status dict. Each upload will generate its own UUID key.
    # The app can use that key query the status of the upload. This dict
    # will also be used to hold the flag to interrupt uploads in progress.
    folder_upload_status = {}
    # Interval in seconds between checks for completion of bulk deletes.
    bulk_delete_interval = 1


    def __init__(self, auth_endpoint, username, api_key=None, password=None,
            tenant_name=None, preauthurl=None, preauthtoken=None,
            auth_version="2", os_options=None, verify_ssl=True,
            http_log_debug=False):
        self.connection = None
        self.cdn_connection = None
        self.http_log_debug = http_log_debug
        self._http_log = _swift_client.http_log
        os.environ["SWIFTCLIENT_DEBUG"] = "True" if http_log_debug else ""
        self._make_connections(auth_endpoint, username, api_key, password,
                tenant_name=tenant_name, preauthurl=preauthurl,
                preauthtoken=preauthtoken, auth_version=auth_version,
                os_options=os_options, verify_ssl=verify_ssl,
                http_log_debug=http_log_debug)


    # Constants used in metadata headers
    @property
    def account_meta_prefix(self):
        return "X-Account-Meta-"

    @property
    def container_meta_prefix(self):
        return "X-Container-Meta-"

    @property
    def object_meta_prefix(self):
        return "X-Object-Meta-"

    @property
    def cdn_meta_prefix(self):
        return "X-Cdn-"


    def _make_connections(self, auth_endpoint, username, api_key, password,
            tenant_name=None, preauthurl=None, preauthtoken=None,
            auth_version="2", os_options=None, verify_ssl=True,
            http_log_debug=None):
        cdn_url = os_options.pop("object_cdn_url", None)
        pw_key = api_key or password
        insecure = not verify_ssl
        self.connection = Connection(authurl=auth_endpoint, user=username,
                key=pw_key, tenant_name=tenant_name, preauthurl=preauthurl,
                preauthtoken=preauthtoken, auth_version=auth_version,
                os_options=os_options, insecure=insecure,
                http_log_debug=http_log_debug)
        if cdn_url:
            self.connection._make_cdn_connection(cdn_url)


    def _massage_metakeys(self, dct, prfx):
        """
        Returns a copy of the supplied dictionary, prefixing any keys that do
        not begin with the specified prefix accordingly.
        """
        lowprefix = prfx.lower()
        ret = {}
        for k, v in dct.iteritems():
            if not k.lower().startswith(lowprefix):
                k = "%s%s" % (prfx, k)
            ret[k] = v
        return ret


    def _resolve_name(self, val):
        return val if isinstance(val, six.string_types) else val.name


    @handle_swiftclient_exception
    def get_account_metadata(self, prefix=None):
        headers = self.connection.head_account()
        if prefix is None:
            prefix = self.account_meta_prefix
        prefix = prefix.lower()
        ret = {}
        for hkey, hval in headers.iteritems():
            if hkey.lower().startswith(prefix):
                ret[hkey] = hval
        return ret


    @handle_swiftclient_exception
    def set_account_metadata(self, metadata, clear=False,
            extra_info=None, prefix=None):
        """
        Accepts a dictionary of metadata key/value pairs and updates the
        specified account metadata with them.

        If 'clear' is True, any existing metadata is deleted and only the
        passed metadata is retained. Otherwise, the values passed here update
        the account's metadata.

        'extra_info' is an optional dictionary which will be populated with
        'status', 'reason', and 'headers' keys from the underlying swiftclient
        call.

        By default, the standard account metadata prefix ('X-Account-Meta-') is
        prepended to the header name if it isn't present. For non-standard
        headers, you must include a non-None prefix, such as an empty string.
        """
        # Add the metadata prefix, if needed.
        if prefix is None:
            prefix = self.account_meta_prefix
        massaged = self._massage_metakeys(metadata, prefix)
        new_meta = {}
        if clear:
            curr_meta = self.get_account_metadata()
            for ckey in curr_meta:
                new_meta[ckey] = ""
        utils.case_insensitive_update(new_meta, massaged)
        self.connection.post_account(new_meta, response_dict=extra_info)


    @handle_swiftclient_exception
    def get_temp_url_key(self, cached=True):
        """
        Returns the current TempURL key, or None if it has not been set.

        By default the value returned is cached. To force an API call to get
        the current value on the server, pass `cached=False`.
        """
        meta = self._cached_temp_url_key
        if not cached or not meta:
            key = "%stemp-url-key" % self.account_meta_prefix.lower()
            meta = self.get_account_metadata().get(key)
            self._cached_temp_url_key = meta
        return meta


    @handle_swiftclient_exception
    def set_temp_url_key(self, key=None):
        """
        Sets the key for the Temporary URL for the account. It should be a key
        that is secret to the owner.

        If no key is provided, a UUID value will be generated and used. It can
        later be obtained by calling get_temp_url_key().
        """
        if key is None:
            key = uuid.uuid4().hex
        meta = {"Temp-Url-Key": key}
        self.set_account_metadata(meta)
        self._cached_temp_url_key = key


    def get_temp_url(self, container, obj, seconds, method="GET", key=None,
            cached=True):
        """
        Given a storage object in a container, returns a URL that can be used
        to access that object. The URL will expire after `seconds` seconds.

        The only methods supported are GET and PUT. Anything else will raise
        an InvalidTemporaryURLMethod exception.

        If you have your Temporary URL key, you can pass it in directly and
        potentially save an API call to retrieve it. If you don't pass in the
        key, and don't wish to use any cached value, pass `cached=False`.
        """
        cname = self._resolve_name(container)
        oname = self._resolve_name(obj)
        mod_method = method.upper().strip()
        if mod_method not in ("GET", "PUT"):
            raise exc.InvalidTemporaryURLMethod("Method must be either 'GET' "
                    "or 'PUT'; received '%s'." % method)
        if not key:
            key = self.get_temp_url_key(cached=cached)
        if not key:
            raise exc.MissingTemporaryURLKey("You must set the key for "
                    "Temporary URLs before you can generate them. This is "
                    "done via the `set_temp_url_key()` method.")
        conn_url = self.connection.url
        v1pos = conn_url.index("/v1/")
        base_url = conn_url[:v1pos]
        path_parts = (conn_url[v1pos:], cname, oname)
        cleaned = (part.strip("/\\") for part in path_parts)
        pth = "/%s" % "/".join(cleaned)
        if isinstance(pth, six.text_type):
            pth = pth.encode(pyrax.get_encoding())
        expires = int(time.time() + int(seconds))
        hmac_body = "%s\n%s\n%s" % (mod_method, expires, pth)
        try:
            sig = hmac.new(key, hmac_body, hashlib.sha1).hexdigest()
        except TypeError as e:
            raise exc.UnicodePathError("Due to a bug in Python, the TempURL "
                    "function only works with ASCII object paths.")
        temp_url = "%s%s?temp_url_sig=%s&temp_url_expires=%s" % (base_url, pth,
                sig, expires)
        return temp_url


    def delete_object_in_seconds(self, cont, obj, seconds,
            extra_info=None):
        """
        Sets the object in the specified container to be deleted after the
        specified number of seconds.
        """
        meta = {"X-Delete-After": str(seconds)}
        self.set_object_metadata(cont, obj, meta, prefix="", clear=True)


    @handle_swiftclient_exception
    def get_container_metadata(self, container, prefix=None):
        """Returns a dictionary containing the metadata for the container."""
        cname = self._resolve_name(container)
        headers = self.connection.head_container(cname)
        if prefix is None:
            prefix = self.container_meta_prefix
        prefix = prefix.lower()
        ret = {}
        for hkey, hval in headers.iteritems():
            if hkey.lower().startswith(prefix):
                ret[hkey] = hval
        return ret


    @handle_swiftclient_exception
    def set_container_metadata(self, container, metadata, clear=False,
            extra_info=None, prefix=None):
        """
        Accepts a dictionary of metadata key/value pairs and updates the
        specified container metadata with them.

        If 'clear' is True, any existing metadata is deleted and only the
        passed metadata is retained. Otherwise, the values passed here update
        the container's metadata.

        'extra_info' is an optional dictionary which will be populated with
        'status', 'reason', and 'headers' keys from the underlying swiftclient
        call.

        By default, the standard container metadata prefix
        ('X-Container-Meta-') is prepended to the header name if it isn't
        present. For non-standard headers, you must include a non-None prefix,
        such as an empty string.
        """
        # Add the metadata prefix, if needed.
        if prefix is None:
            prefix = self.container_meta_prefix
        massaged = self._massage_metakeys(metadata, prefix)
        cname = self._resolve_name(container)
        new_meta = {}
        if clear:
            curr_meta = self.get_container_metadata(cname)
            for ckey in curr_meta:
                new_meta[ckey] = ""
        utils.case_insensitive_update(new_meta, massaged)
        self.connection.post_container(cname, new_meta,
                response_dict=extra_info)


    @handle_swiftclient_exception
    def remove_container_metadata_key(self, container, key,
            prefix=None, extra_info=None):
        """
        Removes the specified key from the container's metadata. If the key
        does not exist in the metadata, nothing is done.
        """
        if prefix is None:
            prefix = self.container_meta_prefix
        prefix = prefix.lower()
        meta_dict = {key: ""}
        # Add the metadata prefix, if needed.
        massaged = self._massage_metakeys(meta_dict, prefix)
        cname = self._resolve_name(container)
        self.connection.post_container(cname, massaged,
                response_dict=extra_info)


    @ensure_cdn
    @handle_swiftclient_exception
    def get_container_cdn_metadata(self, container):
        """
        Returns a dictionary containing the CDN metadata for the container.
        """
        cname = self._resolve_name(container)
        response = self.connection.cdn_request("HEAD", [cname])
        headers = response.getheaders()
        # Read the response to force it to close for the next request.
        response.read()
        # headers is a list of 2-tuples instead of a dict.
        return dict(headers)


    @ensure_cdn
    @handle_swiftclient_exception
    def set_container_cdn_metadata(self, container, metadata):
        """
        Accepts a dictionary of metadata key/value pairs and updates
        the specified container metadata with them.

        NOTE: arbitrary metadata headers are not allowed. The only metadata
        you can update are: X-Log-Retention, X-CDN-enabled, and X-TTL.
        """
        ct = self.get_container(container)
        allowed = ("x-log-retention", "x-cdn-enabled", "x-ttl")
        hdrs = {}
        bad = []
        for mkey, mval in metadata.iteritems():
            if mkey.lower() not in allowed:
                bad.append(mkey)
                continue
            hdrs[mkey] = str(mval)
        if bad:
            raise exc.InvalidCDNMetadata("The only CDN metadata you can "
                    "update are: X-Log-Retention, X-CDN-enabled, and X-TTL. "
                    "Received the following illegal item(s): %s" %
                    ", ".join(bad))
        response = self.connection.cdn_request("POST", [ct.name], hdrs=hdrs)
        response.close()


    @handle_swiftclient_exception
    def get_object_metadata(self, container, obj, prefix=None):
        """Retrieves any metadata for the specified object."""
        if prefix is None:
            prefix = self.object_meta_prefix
        cname = self._resolve_name(container)
        oname = self._resolve_name(obj)
        headers = self.connection.head_object(cname, oname)
        prefix = prefix.lower()
        ret = {}
        for hkey, hval in headers.iteritems():
            if hkey.lower().startswith(prefix):
                ret[hkey] = hval
        return ret


    @handle_swiftclient_exception
    def set_object_metadata(self, container, obj, metadata, clear=False,
            extra_info=None, prefix=None):
        """
        Accepts a dictionary of metadata key/value pairs and updates the
        specified object metadata with them.

        If 'clear' is True, any existing metadata is deleted and only the
        passed metadata is retained. Otherwise, the values passed here update
        the object's metadata.

        'extra_info; is an optional dictionary which will be populated with
        'status', 'reason', and 'headers' keys from the underlying swiftclient
        call.

        By default, the standard object metadata prefix ('X-Object-Meta-') is
        prepended to the header name if it isn't present. For non-standard
        headers, you must include a non-None prefix, such as an empty string.
        """
        # Add the metadata prefix, if needed.
        if prefix is None:
            prefix = self.object_meta_prefix
        massaged = self._massage_metakeys(metadata, prefix)
        cname = self._resolve_name(container)
        oname = self._resolve_name(obj)
        new_meta = {}
        # Note that the API for object POST is the opposite of that for
        # container POST: for objects, all current metadata is deleted,
        # whereas for containers you need to set the values to an empty
        # string to delete them.
        if not clear:
            obj_meta = self.get_object_metadata(cname, oname, prefix=prefix)
            new_meta = self._massage_metakeys(obj_meta, prefix)
        utils.case_insensitive_update(new_meta, massaged)
        # Remove any empty values, since the object metadata API will
        # store them.
        to_pop = []
        for key, val in new_meta.iteritems():
            if not val:
                to_pop.append(key)
        for key in to_pop:
            new_meta.pop(key)
        self.connection.post_object(cname, oname, new_meta,
                response_dict=extra_info)


    @handle_swiftclient_exception
    def remove_object_metadata_key(self, container, obj, key, prefix=None):
        """
        Removes the specified key from the storage object's metadata. If the
        key does not exist in the metadata, nothing is done.
        """
        self.set_object_metadata(container, obj, {key: ""}, prefix=prefix)


    @handle_swiftclient_exception
    def create_container(self, name, extra_info=None):
        """Creates a container with the specified name.

        'extra_info' is an optional dictionary which will be
        populated with 'status', 'reason', and 'headers' keys from the
        underlying swiftclient call.
        """
        name = self._resolve_name(name)
        self.connection.put_container(name, response_dict=extra_info)
        return self.get_container(name)


    @handle_swiftclient_exception
    def delete_container(self, container, del_objects=False, extra_info=None):
        """
        Deletes the specified container. This will fail if the container
        still has objects stored in it; if that's the case and you want
        to delete the container anyway, set del_objects to True, and
        the container's objects will be deleted before the container is
        deleted.

        'extra_info' is an optional dictionary which will be
        populated with 'status', 'reason', and 'headers' keys from the
        underlying swiftclient call.
        """
        self.remove_container_from_cache(container)
        cname = self._resolve_name(container)
        if del_objects:
            nms = self.get_container_object_names(cname, full_listing=True)
            self.bulk_delete(cname, nms, async=False)
        self.connection.delete_container(cname, response_dict=extra_info)
        return True


    def remove_container_from_cache(self, container):
        """Removes the container from the cache."""
        nm = self._resolve_name(container)
        self._container_cache.pop(nm, None)


    @handle_swiftclient_exception
    def delete_object(self, container, name, extra_info=None):
        """
        Deletes the specified object from the container.

        'extra_info' is an optional dictionary which will be
        populated with 'status', 'reason', and 'headers' keys from the
        underlying swiftclient call.
        """
        ct = self.get_container(container)
        ct.remove_from_cache(name)
        oname = self._resolve_name(name)
        self.connection.delete_object(ct.name, oname,
                response_dict=extra_info)
        return True


    @handle_swiftclient_exception
    def bulk_delete(self, container, object_names, async=False):
        """
        Deletes multiple objects from a container in a single call.

        The bulk deletion call does not return until all of the specified
        objects have been processed. For large numbers of objects, this can
        take quite a while, so there is an 'async' parameter to give you the
        option to have this call return immediately. If 'async' is True, an
        object is returned with a 'completed' attribute that will be set to
        True as soon as the bulk deletion is complete, and a 'results'
        attribute that will contain a dictionary (described below) with the
        results of the bulk deletion.

        When deletion is complete the bulk deletion object's 'results'
        attribute will be populated with the information returned from the API
        call. In synchronous mode this is the value that is returned when the
        call completes. It is a dictionary with the following keys:

            deleted - the number of objects deleted
            not_found - the number of objects not found
            status - the HTTP return status code. '200 OK' indicates success
            errors - a list of any errors returned by the bulk delete call

        This isn't available in swiftclient yet, so it's using code patterned
        after the client code in that library.
        """
        deleter = BulkDeleter(self, container, object_names)
        deleter.start()
        if async:
            return deleter
        while not deleter.completed:
            time.sleep(self.bulk_delete_interval)
        return deleter.results


    @handle_swiftclient_exception
    def get_object(self, container, obj):
        """Returns a StorageObject instance for the object in the container."""
        cname = self._resolve_name(container)
        oname = self._resolve_name(obj)
        obj_info = self.connection.head_object(cname, oname)
        lm_str = obj_info["last-modified"]
        dtstr = _convert_head_object_last_modified_to_local(lm_str)
        obj = StorageObject(self, self.get_container(container),
                name=oname, content_type=obj_info["content-type"],
                total_bytes=int(obj_info["content-length"]),
                last_modified=dtstr, etag=obj_info["etag"])
        return obj


    @handle_swiftclient_exception
    def store_object(self, container, obj_name, data, content_type=None,
            etag=None, content_encoding=None, ttl=None, return_none=False,
            chunk_size=None, extra_info=None):
        """
        Creates a new object in the specified container, and populates it with
        the given data. A StorageObject reference to the uploaded file
        will be returned, unless 'return_none' is set to True.

        'chunk_size' represents the number of bytes of data to write; it
        defaults to 65536. It is used only if the the 'data' parameter is an
        object with a 'read' method; otherwise, it is ignored.

        'extra_info' is an optional dictionary which will be
        populated with 'status', 'reason', and 'headers' keys from the
        underlying swiftclient call.
        """
        cont = self.get_container(container)
        headers = {}
        if content_encoding is not None:
            headers["Content-Encoding"] = content_encoding
        if ttl is not None:
            headers["X-Delete-After"] = ttl
        if chunk_size and hasattr(data, "read"):
            # Chunked file-like object
            self.connection.put_object(cont.name, obj_name, contents=data,
                    content_type=content_type, etag=etag, headers=headers,
                    chunk_size=chunk_size, response_dict=extra_info)
        else:
            with utils.SelfDeletingTempfile() as tmp:
                with open(tmp, "wb") as tmpfile:
                    try:
                        tmpfile.write(data)
                    except UnicodeEncodeError:
                        udata = data.encode("utf-8")
                        tmpfile.write(udata)
                with open(tmp, "rb") as tmpfile:
                    self.connection.put_object(cont.name, obj_name,
                            contents=tmpfile, content_type=content_type,
                            etag=etag, headers=headers, chunk_size=chunk_size,
                            response_dict=extra_info)
        if return_none:
            return None
        else:
            return self.get_object(container, obj_name)


    @handle_swiftclient_exception
    def copy_object(self, container, obj, new_container, new_obj_name=None,
            extra_info=None):
        """
        Copies the object to the new container, optionally giving it a new name.
        If you copy to the same container, you must supply a different name.
        """
        cont = self.get_container(container)
        obj = self.get_object(cont, obj)
        new_cont = self.get_container(new_container)
        if new_obj_name is None:
            new_obj_name = obj.name
        hdrs = {"X-Copy-From": "/%s/%s" % (cont.name, obj.name)}
        return self.connection.put_object(new_cont.name, new_obj_name,
                contents=None, headers=hdrs, response_dict=extra_info)


    @handle_swiftclient_exception
    def move_object(self, container, obj, new_container, new_obj_name=None,
            extra_info=None):
        """
        Works just like copy_object, except that the source object is deleted
        after a successful copy.
        """
        new_obj_etag = self.copy_object(container, obj, new_container,
                new_obj_name=new_obj_name, extra_info=extra_info)
        if new_obj_etag:
            # Copy succeeded; delete the original.
            self.delete_object(container, obj)
        return new_obj_etag


    @handle_swiftclient_exception
    def change_object_content_type(self, container, obj, new_ctype,
            guess=False, extra_info=None):
        """
        Copies object to itself, but applies a new content-type. The guess
        feature requires the container to be CDN-enabled. If not then the
        content-type must be supplied. If using guess with a CDN-enabled
        container, new_ctype can be set to None.
        Failure during the put will result in a swift exception.
        """
        cont = self.get_container(container)
        obj = self.get_object(cont, obj)
        if guess and cont.cdn_enabled:
            # Test against the CDN url to guess the content-type.
            obj_url = "%s/%s" % (cont.cdn_uri, obj.name)
            new_ctype = mimetypes.guess_type(obj_url)[0]
        hdrs = {"X-Copy-From": "/%s/%s" % (cont.name, obj.name)}
        self.connection.put_object(cont.name, obj.name, contents=None,
                headers=hdrs, content_type=new_ctype,
                response_dict=extra_info)
        cont.remove_from_cache(obj.name)
        return

    @handle_swiftclient_exception
    def upload_file(self, container, file_or_path, obj_name=None,
            content_type=None, etag=None, return_none=False,
            content_encoding=None, ttl=None, extra_info=None,
            content_length=None):
        """
        Uploads the specified file to the container. If no name is supplied,
        the file's name will be used. Either a file path or an open file-like
        object may be supplied. A StorageObject reference to the uploaded file
        will be returned, unless 'return_none' is set to True.

        You may optionally set the `content_type` and `content_encoding`
        parameters; pyrax will create the appropriate headers when the object
        is stored.

        If the size of the file is known, it can be passed as `content_length`.

        If you wish for the object to be temporary, specify the time it should
        be stored in seconds in the `ttl` parameter. If this is specified, the
        object will be deleted after that number of seconds.
        """
        # TODO-BC: response_dict when looping? as a list of them?
        cont = self.get_container(container)

        def get_file_size(fileobj):
            """Returns the size of a file-like object."""
            currpos = fileobj.tell()
            fileobj.seek(0, 2)
            total_size = fileobj.tell()
            fileobj.seek(currpos)
            return total_size

        def upload(fileobj, content_type, etag, headers):
            if isinstance(fileobj, six.string_types):
                # This is an empty directory file
                fsize = 0
            else:
                if content_length is None:
                    fsize = get_file_size(fileobj)
                else:
                    fsize = content_length
            if fsize <= self.max_file_size:
                # We can just upload it as-is.
                return self.connection.put_object(cont.name, obj_name,
                        contents=fileobj, content_type=content_type,
                        etag=etag, headers=headers, response_dict=extra_info)
            # Files larger than self.max_file_size must be segmented
            # and uploaded separately.
            num_segments = int(math.ceil(float(fsize) / self.max_file_size))
            digits = int(math.log10(num_segments)) + 1
            # NOTE: This could be greatly improved with threading or other
            # async design.
            for segment in six.moves.range(num_segments):
                sequence = str(segment + 1).zfill(digits)
                seg_name = "%s.%s" % (obj_name, sequence)
                with utils.SelfDeletingTempfile() as tmpname:
                    with open(tmpname, "wb") as tmp:
                        tmp.write(fileobj.read(self.max_file_size))
                    with open(tmpname, "rb") as tmp:
                        # We have to calculate the etag for each segment
                        etag = utils.get_checksum(tmp)
                        self.connection.put_object(cont.name, seg_name,
                                contents=tmp, content_type=content_type,
                                etag=etag, headers=headers,
                                response_dict=extra_info)
            # Upload the manifest
            headers["X-Object-Manifest"] = "%s/%s." % (cont.name, obj_name)
            return self.connection.put_object(cont.name, obj_name,
                    contents=None, headers=headers,
                    response_dict=extra_info)

        ispath = isinstance(file_or_path, six.string_types)
        if ispath:
            # Make sure it exists
            if not os.path.exists(file_or_path):
                raise exc.FileNotFound("The file '%s' does not exist" %
                        file_or_path)
            fname = os.path.basename(file_or_path)
        else:
            try:
                fname = os.path.basename(file_or_path.name)
            except AttributeError:
                fname = None
        if not obj_name:
            obj_name = fname
        if not obj_name:
            raise InvalidUploadID("No filename provided and/or it cannot be "
                    "inferred from context")

        headers = {}
        if content_encoding is not None:
            headers["Content-Encoding"] = content_encoding
        if ttl is not None:
            headers["X-Delete-After"] = ttl

        if ispath and os.path.isfile(file_or_path):
            # Need to wrap the call in a context manager
            with open(file_or_path, "rb") as ff:
                upload(ff, content_type, etag, headers)
        else:
            upload(file_or_path, content_type, etag, headers)
        if return_none:
            return None
        else:
            return self.get_object(container, obj_name)


    def upload_folder(self, folder_path, container=None, ignore=None, ttl=None):
        """
        Convenience method for uploading an entire folder, including any
        sub-folders, to Cloud Files.

        All files will be uploaded to objects with the same name as the file.
        In the case of nested folders, files will be named with the full path
        relative to the base folder. E.g., if the folder you specify contains a
        folder named 'docs', and 'docs' contains a file named 'install.html',
        that file will be uploaded to an object named 'docs/install.html'.

        If 'container' is specified, the folder's contents will be uploaded to
        that container. If it is not specified, a new container with the same
        name as the specified folder will be created, and the files uploaded to
        this new container.

        You can selectively ignore files by passing either a single pattern or
        a list of patterns; these will be applied to the individual folder and
        file names, and any names that match any of the 'ignore' patterns will
        not be uploaded. The patterns should be standard *nix-style shell
        patterns; e.g., '*pyc' will ignore all files ending in 'pyc', such as
        'program.pyc' and 'abcpyc'.

        The upload will happen asynchronously; in other words, the call to
        upload_folder() will generate a UUID and return a 2-tuple of (UUID,
        total_bytes) immediately. Uploading will happen in the background; your
        app can call get_uploaded(uuid) to get the current status of the
        upload. When the upload is complete, the value returned by
        get_uploaded(uuid) will match the total_bytes for the upload.

        If you start an upload and need to cancel it, call
        cancel_folder_upload(uuid), passing the uuid returned by the initial
        call.  It will then be up to you to either keep or delete the
        partially-uploaded content.

        If you specify a `ttl` parameter, the uploaded files will be deleted
        after that number of seconds.
        """
        if not os.path.isdir(folder_path):
            raise exc.FolderNotFound("No such folder: '%s'" % folder_path)

        ignore = utils.coerce_string_to_list(ignore)
        total_bytes = utils.folder_size(folder_path, ignore)
        upload_key = str(uuid.uuid4())
        self.folder_upload_status[upload_key] = {"continue": True,
                "total_bytes": total_bytes,
                "uploaded": 0,
                }
        self._upload_folder_in_background(folder_path, container, ignore,
                upload_key, ttl)
        return (upload_key, total_bytes)


    def _upload_folder_in_background(self, folder_path, container, ignore,
            upload_key, ttl=None):
        """Runs the folder upload in the background."""
        uploader = FolderUploader(folder_path, container, ignore, upload_key,
                self, ttl=ttl)
        uploader.start()


    def sync_folder_to_container(self, folder_path, container, delete=False,
            include_hidden=False, ignore=None, ignore_timestamps=False,
            object_prefix="", verbose=False):
        """
        Compares the contents of the specified folder, and checks to make sure
        that the corresponding object is present in the specified container. If
        there is no remote object matching the local file, it is created. If a
        matching object exists, the etag is examined to determine if the object
        in the container matches the local file; if they differ, the container
        is updated with the local file if the local file is newer when
        `ignore_timestamps' is False (default). If `ignore_timestamps` is True,
        the object is overwritten with the local file contents whenever the
        etags differ. NOTE: the timestamp of a remote object is the time it was
        uploaded, not the original modification time of the file stored in that
        object.  Unless 'include_hidden' is True, files beginning with an
        initial period are ignored.

        If the 'delete' option is True, any objects in the container that do
        not have corresponding files in the local folder are deleted.

        You can selectively ignore files by passing either a single pattern or
        a list of patterns; these will be applied to the individual folder and
        file names, and any names that match any of the 'ignore' patterns will
        not be uploaded. The patterns should be standard *nix-style shell
        patterns; e.g., '*pyc' will ignore all files ending in 'pyc', such as
        'program.pyc' and 'abcpyc'.

        If `object_prefix` is set it will be appended to the object name when
        it is checked and uploaded to the container. For example, if you use
        sync_folder_to_container("folderToSync/", myContainer,
            object_prefix="imgFolder") it will upload the files to the
        container/imgFolder/... instead of just container/...

        Set `verbose` to True to make it print what is going on. It will
        show which files are being uploaded and which ones are not and why.
        """
        cont = self.get_container(container)
        self._local_files = []
        # Load a list of all the remote objects so we don't have to keep
        # hitting the service
        if verbose:
            log = logging.getLogger("pyrax")
            log.info("Loading remote object list (prefix=%s)", object_prefix)
        data = cont.get_objects(prefix=object_prefix, full_listing=True)
        self._remote_files = dict((d.name, d) for d in data)
        self._sync_folder_to_container(folder_path, cont, prefix="",
                delete=delete, include_hidden=include_hidden, ignore=ignore,
                ignore_timestamps=ignore_timestamps,
                object_prefix=object_prefix, verbose=verbose)
        # Unset the _remote_files
        self._remote_files = None


    def _sync_folder_to_container(self, folder_path, cont, prefix, delete,
            include_hidden, ignore, ignore_timestamps, object_prefix, verbose):
        """
        This is the internal method that is called recursively to handle
        nested folder structures.
        """
        fnames = os.listdir(folder_path)
        ignore = utils.coerce_string_to_list(ignore)
        log = logging.getLogger("pyrax")
        if not include_hidden:
            ignore.append(".*")
        for fname in fnames:
            if utils.match_pattern(fname, ignore):
                continue
            pth = os.path.join(folder_path, fname)
            if os.path.isdir(pth):
                subprefix = fname
                if prefix:
                    subprefix = "%s/%s" % (prefix, subprefix)
                self._sync_folder_to_container(pth, cont, prefix=subprefix,
                        delete=delete, include_hidden=include_hidden,
                        ignore=ignore, ignore_timestamps=ignore_timestamps,
                        object_prefix=object_prefix, verbose=verbose)
                continue
            self._local_files.append(os.path.join(object_prefix, prefix, fname))
            local_etag = utils.get_checksum(pth)
            fullname = fname
            fullname_with_prefix = "%s/%s" % (object_prefix, fname)
            if prefix:
                fullname = "%s/%s" % (prefix, fname)
                fullname_with_prefix = "%s/%s/%s" % (object_prefix, prefix, fname)
            try:
                obj = self._remote_files[fullname_with_prefix]
                obj_etag = obj.etag
            except KeyError:
                obj = None
                obj_etag = None
            if local_etag != obj_etag:
                if not ignore_timestamps:
                    if obj:
                        obj_time_str = obj.last_modified[:19]
                    else:
                        obj_time_str = EARLY_DATE_STR
                    local_mod = datetime.datetime.utcfromtimestamp(
                            os.stat(pth).st_mtime)
                    local_mod_str = local_mod.isoformat()
                    if obj_time_str >= local_mod_str:
                        # Remote object is newer
                        if verbose:
                            log.info("%s NOT UPLOADED because remote object is "
                                    "newer", fullname)
                        continue
                cont.upload_file(pth, obj_name=fullname_with_prefix,
                    etag=local_etag, return_none=True)
                if verbose:
                    log.info("%s UPLOADED", fullname)
            else:
                if verbose:
                    log.info("%s NOT UPLOADED because it already exists",
                            fullname)
        if delete and not prefix:
            self._delete_objects_not_in_list(cont, object_prefix)


    def _delete_objects_not_in_list(self, cont, object_prefix=""):
        """
        Finds all the objects in the specified container that are not present
        in the self._local_files list, and deletes them.
        """
        objnames = set(cont.get_object_names(prefix=object_prefix,
                full_listing=True))
        localnames = set(self._local_files)
        to_delete = list(objnames.difference(localnames))
        # We don't need to wait around for this to complete. Store the thread
        # reference in case it is needed at some point.
        self._thread = self.bulk_delete(cont, to_delete, async=True)


    def _valid_upload_key(fnc):
        def wrapped(self, upload_key, *args, **kwargs):
            try:
                self.folder_upload_status[upload_key]
            except KeyError:
                raise exc.InvalidUploadID("There is no folder upload with the "
                        "key '%s'." % upload_key)
            return fnc(self, upload_key, *args, **kwargs)
        return wrapped


    @_valid_upload_key
    def _update_progress(self, upload_key, size):
        self.folder_upload_status[upload_key]["uploaded"] += size


    @_valid_upload_key
    def get_uploaded(self, upload_key):
        """Returns the number of bytes uploaded for the specified process."""
        return self.folder_upload_status[upload_key]["uploaded"]


    @_valid_upload_key
    def cancel_folder_upload(self, upload_key):
        """
        Cancels any folder upload happening in the background. If there is no
        such upload in progress, calling this method has no effect.
        """
        self.folder_upload_status[upload_key]["continue"] = False


    @_valid_upload_key
    def _should_abort_folder_upload(self, upload_key):
        """
        Returns True if the user has canceled upload; returns False otherwise.
        """
        return not self.folder_upload_status[upload_key]["continue"]


    @handle_swiftclient_exception
    def fetch_object(self, container, obj, include_meta=False,
            chunk_size=None, size=None, extra_info=None):
        """
        Fetches the object from storage.

        If 'include_meta' is False, only the bytes representing the
        file is returned.

        Note: if 'chunk_size' is defined, you must fully read the object's
        contents before making another request.

        If 'size' is specified, only the first 'size' bytes of the object will
        be returned. If the object if smaller than 'size', the entire object is
        returned.

        When 'include_meta' is True, what is returned from this method is a
        2-tuple:
            Element 0: a dictionary containing metadata about the file.
            Element 1: a stream of bytes representing the object's contents.

        'extra_info' is an optional dictionary which will be
        populated with 'status', 'reason', and 'headers' keys from the
        underlying swiftclient call.
        """
        cname = self._resolve_name(container)
        oname = self._resolve_name(obj)
        (meta, data) = self.connection.get_object(cname, oname,
                resp_chunk_size=chunk_size, response_dict=extra_info)
        if include_meta:
            return (meta, data)
        else:
            return data


    @handle_swiftclient_exception
    def fetch_partial(self, container, obj, size):
        """
        Returns the first 'size' bytes of an object. If the object is smaller
        than the specified 'size' value, the entire object is returned.
        """
        gen = self.fetch_object(container, obj, chunk_size=size)
        ret = gen.next()
        _close_swiftclient_conn(self.connection)
        return ret


    @handle_swiftclient_exception
    def download_object(self, container, obj, directory, structure=True):
        """
        Fetches the object from storage, and writes it to the specified
        directory. The directory must exist before calling this method.

        If the object name represents a nested folder structure, such as
        "foo/bar/baz.txt", that folder structure will be created in the target
        directory by default. If you do not want the nested folders to be
        created, pass `structure=False` in the parameters.
        """
        if not os.path.isdir(directory):
            raise exc.FolderNotFound("The directory '%s' does not exist." %
                    directory)
        obj_name = self._resolve_name(obj)
        path, fname = os.path.split(obj_name)
        if structure:
            fullpath = os.path.join(directory, path)
            if not os.path.exists(fullpath):
                os.makedirs(fullpath)
            target = os.path.join(fullpath, fname)
        else:
            target = os.path.join(directory, fname)
        with open(target, "wb") as dl:
            dl.write(self.fetch_object(container, obj))


    @handle_swiftclient_exception
    def get_all_containers(self, limit=None, marker=None, **parms):
        hdrs, conts = self.connection.get_container("", limit=limit,
                marker=marker)
        ret = [Container(self, name=cont["name"], object_count=cont["count"],
                total_bytes=cont["bytes"]) for cont in conts]
        return ret


    @handle_swiftclient_exception
    def get_container(self, container, cached=True):
        """
        Returns a reference to the specified container. By default, if a
        reference to that container has already been retrieved, a cached
        reference will be returned. If you need to get an updated version of
        the container, pass `cached=False` to the method call.
        """
        cname = self._resolve_name(container)
        if not cname:
            raise exc.MissingName("No container name specified")
        cont = None
        if cached:
            cont = self._container_cache.get(cname)
        if not cont:
            hdrs = self.connection.head_container(cname)
            cont = Container(self, name=cname,
                    object_count=hdrs.get("x-container-object-count"),
                    total_bytes=hdrs.get("x-container-bytes-used"))
            self._container_cache[cname] = cont
        return cont
    get = get_container


    @handle_swiftclient_exception
    def get_container_objects(self, container, marker=None, limit=None,
            prefix=None, delimiter=None, full_listing=False):
        """
        Return a list of StorageObjects representing the objects in the
        container. You can use the marker and limit params to handle pagination,
        and the prefix and delimiter params to filter the objects returned.
        Also, by default only the first 10,000 objects are returned; if you set
        full_listing to True, all objects in the container are returned.
        """
        cname = self._resolve_name(container)
        hdrs, objs = self.connection.get_container(cname, marker=marker,
                limit=limit, prefix=prefix, delimiter=delimiter,
                full_listing=full_listing)
        cont = self.get_container(cname)
        return [StorageObject(self,
                              container=cont,
                              attdict=_convert_list_last_modified_to_local(obj))
                for obj in objs
                if "name" in obj]
    list_container_objects = get_container_objects


    @handle_swiftclient_exception
    def get_container_object_names(self, container, marker=None, limit=None,
            prefix=None, delimiter=None, full_listing=False):
        cname = self._resolve_name(container)
        hdrs, objs = self.connection.get_container(cname, marker=marker,
                limit=limit, prefix=prefix, delimiter=delimiter,
                full_listing=full_listing)
        cont = self.get_container(cname)
        return [obj["name"] for obj in objs]
    list_container_object_names = get_container_object_names


    @handle_swiftclient_exception
    def list_container_subdirs(self, container, marker=None, limit=None,
            prefix=None, delimiter=None, full_listing=False):
        """
        Return a list of StorageObjects representing the pseudo-subdirectories
        in the specified container. You can use the marker and limit params to
        handle pagination, and the prefix and delimiter params to filter the
        objects returned.
        """
        cname = self._resolve_name(container)
        hdrs, objs = self.connection.get_container(cname, marker=marker,
                limit=limit, prefix=prefix, delimiter=delimiter,
                full_listing=full_listing)
        cont = self.get_container(cname)
        return [StorageObject(self, container=cont, attdict=obj) for obj in objs
                if obj.get("content_type") == "application/directory"]


    @handle_swiftclient_exception
    def get_info(self):
        """
        Returns a tuple for the number of containers and total bytes in
        the account.
        """
        hdrs = self.connection.head_container("")
        return (hdrs["x-account-container-count"], hdrs["x-account-bytes-used"])


    @handle_swiftclient_exception
    def list(self, limit=None, marker=None, **parms):
        """Returns a list of all container objects."""
        hdrs, conts = self.connection.get_container("", limit=limit,
                marker=marker)
        ret = [self.get_container(cont["name"]) for cont in conts]
        return ret
    get_all_containers = list


    @handle_swiftclient_exception
    def list_containers(self, limit=None, marker=None, **parms):
        """Returns a list of all container names as strings."""
        hdrs, conts = self.connection.get_container("", limit=limit,
                marker=marker)
        ret = [cont["name"] for cont in conts]
        return ret
    list_container_names = list_containers


    @handle_swiftclient_exception
    def list_containers_info(self, limit=None, marker=None, **parms):
        """Returns a list of info on Containers.

        For each container, a dict containing the following keys is returned:
        \code
            name - the name of the container
            count - the number of objects in the container
            bytes - the total bytes in the container
        """
        hdrs, conts = self.connection.get_container("", limit=limit,
                marker=marker)
        return conts


    @ensure_cdn
    @handle_swiftclient_exception
    def list_public_containers(self):
        """Returns a list of all CDN-enabled containers."""
        response = self.connection.cdn_request("GET", [""])
        status = response.status
        if not 200 <= status < 300:
            raise exc.CDNFailed("Bad response: (%s) %s" % (status,
                    response.reason))
        return response.read().splitlines()


    def make_container_public(self, container, ttl=None):
        """Enables CDN access for the specified container."""
        return self._cdn_set_access(container, ttl, True)


    def make_container_private(self, container):
        """
        Disables CDN access to a container. It may still appear public until
        its TTL expires.
        """
        return self._cdn_set_access(container, None, False)


    @ensure_cdn
    def _cdn_set_access(self, container, ttl, enabled):
        """Used to enable or disable CDN access on a container."""
        if ttl is None:
            ttl = self.default_cdn_ttl
        ct = self.get_container(container)
        mthd = "PUT"
        hdrs = {"X-CDN-Enabled": "%s" % enabled}
        if enabled:
            hdrs["X-TTL"] = str(ttl)
        response = self.connection.cdn_request(mthd, [ct.name], hdrs=hdrs)
        status = response.status
        if not 200 <= status < 300:
            raise exc.CDNFailed("Bad response: (%s) %s" % (status,
                    response.reason))
        ct.cdn_ttl = ttl
        for hdr in response.getheaders():
            if hdr[0].lower() == "x-cdn-uri":
                ct.cdn_uri = hdr[1]
                break
        self.remove_container_from_cache(container)
        # Read the response to force it to close for the next request.
        response.read()


    def set_cdn_log_retention(self, container, enabled):
        """
        Defer the logic to the container. It will end up calling
        _set_cdn_log_retention() to change it on Cloud Files.
        """
        cont = self.get_container(container)
        cont.cdn_log_retention = enabled


    @ensure_cdn
    def _set_cdn_log_retention(self, container, enabled):
        """This does the actual call to the Cloud Files API."""
        hdrs = {"X-Log-Retention": "%s" % enabled}
        cname = self._resolve_name(container)
        response = self.connection.cdn_request("POST", [cname], hdrs=hdrs)
        status = response.status
        if not 200 <= status < 300:
            raise exc.CDNFailed("Bad response: (%s) %s" % (status,
                    response.reason))
        # Read the response to force it to close for the next request.
        response.read()


    def get_container_streaming_uri(self, container):
        """
        Returns the URI for streaming content, or None if CDN is not enabled.
        """
        cont = self.get_container(container)
        return cont.cdn_streaming_uri


    def get_container_ios_uri(self, container):
        """Returns the iOS URI, or None if CDN is not enabled."""
        cont = self.get_container(container)
        return cont.cdn_ios_uri


    def set_container_web_index_page(self, container, page):
        """
        Sets the header indicating the index page in a container
        when creating a static website.

        Note: the container must be CDN-enabled for this to have
        any effect.
        """
        hdr = {"X-Container-Meta-Web-Index": page}
        return self.set_container_metadata(container, hdr, clear=False)


    def set_container_web_error_page(self, container, page):
        """
        Sets the header indicating the error page in a container
        when creating a static website.

        Note: the container must be CDN-enabled for this to have
        any effect.
        """
        hdr = {"X-Container-Meta-Web-Error": page}
        return self.set_container_metadata(container, hdr, clear=False)


    @ensure_cdn
    @handle_swiftclient_exception
    def purge_cdn_object(self, container, name, email_addresses=None):
        ct = self.get_container(container)
        oname = self._resolve_name(name)
        if not ct.cdn_enabled:
            raise exc.NotCDNEnabled("The object '%s' is not in a "
                    "CDN-enabled container." % oname)
        hdrs = {}
        if email_addresses:
            if not isinstance(email_addresses, (list, tuple)):
                email_addresses = [email_addresses]
            emls = ", ".join(email_addresses)
            hdrs = {"X-Purge-Email": emls}
        response = self.connection.cdn_request("DELETE", [ct.name, oname],
                hdrs=hdrs)
        # Read the response to force it to close for the next request.
        response.read()
        return True


    def _get_user_agent(self):
        return self.connection.user_agent

    def _set_user_agent(self, val):
        self.connection.user_agent = val

    user_agent = property(_get_user_agent, _set_user_agent)


    def _get_http_log_debug(self):
        return self._http_log_debug

    def _set_http_log_debug(self, val):
        self._http_log_debug = val
        if val:
            os.environ["SWIFTCLIENT_DEBUG"] = "True"
        else:
            os.environ.pop("SWIFTCLIENT_DEBUG", False)

    http_log_debug = property(_get_http_log_debug, _set_http_log_debug, None,
            "Determines if all http traffic is logged to the display "
            "for debugging.")



class Connection(_swift_client.Connection):
    """This class wraps the swiftclient connection, adding support for CDN"""
    def __init__(self, *args, **kwargs):
        self.http_log_debug = kwargs.pop("http_log_debug", False)
        self._http_log = _swift_client.http_log
        self.url = None
        super(Connection, self).__init__(*args, **kwargs)
        # Add the user_agent, if not defined
        try:
            self.user_agent
        except AttributeError:
            self.user_agent = "swiftclient"
        self.cdn_connection = None


    def _make_cdn_connection(self, cdn_url=None):
        if cdn_url is not None:
            self.cdn_url = cdn_url
        parsed = urlparse.urlparse(self.cdn_url)
        is_ssl = parsed.scheme == "https"

        # Verify hostnames are valid and parse a port spec (if any)
        match = re.match(r"([a-zA-Z0-9\-\.]+):?([0-9]{2,5})?", parsed.netloc)
        if match:
            (host, port) = match.groups()
        else:
            host = parsed.netloc
            port = None
        if not port:
            port = 443 if is_ssl else 80
        port = int(port)
        path = parsed.path.strip("/")
        conn_class = httplib.HTTPSConnection if is_ssl else httplib.HTTPConnection
        self.cdn_connection = conn_class(host, port, timeout=CONNECTION_TIMEOUT)
        self.cdn_connection.is_ssl = is_ssl


    def cdn_request(self, method, path=[], data="", hdrs=None):
        """
        Given a method (i.e. GET, PUT, POST, etc.), a path, data, header and
        metadata dicts, performs an http request against the CDN service.

        Taken directly from the cloudfiles library and modified for use here.
        """
        pth = "/".join([_quote(elem) for elem in path])
        uri_path = urlparse.urlparse(self.uri).path
        path = "%s/%s" % (uri_path.rstrip("/"), pth)
        headers = {"Content-Length": str(len(data)),
                "User-Agent": self.user_agent,
                "X-Auth-Token": self.token}
        if isinstance(hdrs, dict):
            headers.update(hdrs)

        attempt = 0
        response = None
        while attempt < CONNECTION_RETRIES:
            if attempt:
                # Last try failed; re-create the connection
                self._make_cdn_connection()
            try:
                self.cdn_connection.request(method, path, data, headers)
                response = self.cdn_connection.getresponse()
            except (socket.error, IOError, httplib.HTTPException) as e:
                response = None
            if response:
                if response.status == 401:
                    pyrax.identity.authenticate()
                    headers["X-Auth-Token"] = pyrax.identity.token
                else:
                    break
            attempt += 1
        if self.http_log_debug:
            self._http_log((path, method), {"headers": headers, "data": data},
                    response, "")
        return response


    @property
    def uri(self):
        return self.url



class FolderUploader(threading.Thread):
    """
    Threading class to allow for uploading multiple files in the background.
    """
    def __init__(self, root_folder, container, ignore, upload_key, client,
            ttl=None):
        self.root_folder = root_folder.rstrip("/")
        if container:
            self.container = client.create_container(container)
        else:
            self.container = None
        self.ignore = utils.coerce_string_to_list(ignore)
        self.upload_key = upload_key
        self.ttl = ttl
        self.client = client
        threading.Thread.__init__(self)

    def folder_name_from_path(self, pth):
        """Convenience method that first strips trailing path separators."""
        return os.path.basename(pth.rstrip(os.sep))

    def upload_files_in_folder(self, arg, dirname, fnames):
        """Handles the iteration across files within a folder."""
        if utils.match_pattern(dirname, self.ignore):
            return False
        for fname in (nm for nm in fnames
                if not utils.match_pattern(nm, self.ignore)):
            if self.client._should_abort_folder_upload(self.upload_key):
                return
            full_path = os.path.join(dirname, fname)
            if os.path.isdir(full_path):
                # Skip folders; os.walk will include them in the next pass.
                continue
            obj_name = os.path.relpath(full_path, self.base_path)
            obj_size = os.stat(full_path).st_size
            self.client.upload_file(self.container, full_path,
                    obj_name=obj_name, return_none=True, ttl=self.ttl)
            self.client._update_progress(self.upload_key, obj_size)

    def run(self):
        """Starts the uploading thread."""
        root_path, folder_name = os.path.split(self.root_folder)
        self.base_path = os.path.join(root_path, folder_name)
        os.path.walk(self.root_folder, self.upload_files_in_folder, None)



class BulkDeleter(threading.Thread):
    """
    Threading class to allow for bulk deletion of objects from a container.
    """
    completed = False
    results = None

    def __init__(self, client, container, object_names):
        self.client = client
        self.container = container
        self.object_names = object_names
        threading.Thread.__init__(self)


    def run(self):
        client = self.client
        container = self.container
        object_names = self.object_names
        self.results = {"deleted": 0, "not_found": 0, "status": "",
                "errors": ""}
        res_keys = {"Number Deleted": "deleted",
                "Number Not Found": "not_found",
                "Response Status": "status",
                "Errors": "errors",
                }
        cname = client._resolve_name(container)
        parsed, conn = client.connection.http_connection()
        method = "DELETE"
        headers = {"X-Auth-Token": pyrax.identity.token,
                "Content-type": "text/plain",
                }
        while object_names:
            this_batch, object_names = (object_names[:MAX_BULK_DELETE],
                    object_names[MAX_BULK_DELETE:])
            obj_paths = ("%s/%s" % (cname, nm) for nm in this_batch)
            body = _quote("\n".join(obj_paths))
            pth = "%s/?bulk-delete=1" % parsed.path
            conn.request(method, pth, body, headers)
            resp = conn.getresponse()
            status = resp.status
            reason = resp.reason
            resp_body = resp.read()
            for resp_line in resp_body.splitlines():
                if not resp_line.strip():
                    continue
                resp_key, val = resp_line.split(":", 1)
                result_key = res_keys.get(resp_key)
                if not result_key:
                    continue
                if result_key in ("deleted", "not_found"):
                    self.results[result_key] += int(val.strip())
                else:
                    self.results[result_key] = val.strip()
        self.completed = True

########NEW FILE########
__FILENAME__ = container
#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.


import pyrax

# Used to indicate values that are lazy-loaded
class Fault(object):
    def __nonzero__(self):
        return False

FAULT = Fault()


class Container(object):
    """Represents a CloudFiles container."""
    def __init__(self, client, name, object_count=None, total_bytes=None):
        self.client = client
        self.name = name
        self.object_count = int(object_count)
        self.total_bytes = int(total_bytes)
        self._cdn_uri = FAULT
        self._cdn_ttl = FAULT
        self._cdn_ssl_uri = FAULT
        self._cdn_streaming_uri = FAULT
        self._cdn_ios_uri = FAULT
        self._cdn_log_retention = FAULT
        self._object_cache = {}


    def _set_cdn_defaults(self):
        """Sets all the CDN-related attributes to default values."""
        self._cdn_uri = None
        self._cdn_ttl = self.client.default_cdn_ttl
        self._cdn_ssl_uri = None
        self._cdn_streaming_uri = None
        self._cdn_ios_uri = None
        self._cdn_log_retention = False


    def _fetch_cdn_data(self):
        """Fetches the object's CDN data from the CDN service"""
        if not self.client.cdn_enabled:
            # Not CDN enabled; set the defaults.
            self._set_cdn_defaults()
        response = self.client.connection.cdn_request("HEAD", [self.name])
        if 200 <= response.status < 300:
            # Set defaults in case not all headers are present.
            self._set_cdn_defaults()
            for hdr in response.getheaders():
                low_hdr = hdr[0].lower()
                if low_hdr == "x-cdn-uri":
                    self._cdn_uri = hdr[1]
                elif low_hdr == "x-ttl":
                    self._cdn_ttl = int(hdr[1])
                elif low_hdr == "x-cdn-ssl-uri":
                    self._cdn_ssl_uri = hdr[1]
                elif low_hdr == "x-cdn-streaming-uri":
                    self._cdn_streaming_uri = hdr[1]
                elif low_hdr == "x-cdn-ios-uri":
                    self._cdn_ios_uri = hdr[1]
                elif low_hdr == "x-log-retention":
                    self._cdn_log_retention = (hdr[1] == "True")
        elif response.status == 404:
            # Not CDN enabled; set the defaults.
            self._set_cdn_defaults()
        # We need to read the response in order to clear it for
        # the next call
        response.read()


    def get_objects(self, marker=None, limit=None, prefix=None, delimiter=None,
            full_listing=False):
        """
        Returns a list of StorageObjects representing the objects in the
        container. You can use the marker and limit params to handle pagination,
        and the prefix and delimiter params to filter the objects returned.
        Also, by default only the first 10,000 objects are returned; if you set
        full_listing to True, all objects in the container are returned.
        """
        objs = self.client.get_container_objects(self.name, marker=marker,
                limit=limit, prefix=prefix, delimiter=delimiter,
                full_listing=full_listing)
        return objs
    list = get_objects


    def get_object(self, name, cached=True):
        """
        Return the StorageObject in this container with the specified name. By
        default, if a reference to that object has already been retrieved, a
        cached reference will be returned. If you need to get an updated
        version of the object, pass `cached=False` to the method call.
        """
        if isinstance(name, str):
            name = name.decode(pyrax.get_encoding())
        ret = None
        if cached:
            ret = self._object_cache.get(name)
        if not ret:
            ret = self.client.get_object(self, name)
            self._object_cache[name] = ret
        return ret
    get = get_object


    def get_object_names(self, marker=None, limit=None, prefix=None,
            delimiter=None, full_listing=False):
        """
        Returns a list of the names of all the objects in this container. The
        same pagination parameters apply as in self.get_objects().
        """
        return self.client.get_container_object_names(self.name, marker=marker,
                limit=limit, prefix=prefix, delimiter=delimiter,
                full_listing=full_listing)
    list_object_names = get_object_names


    def list_subdirs(self, marker=None, limit=None, prefix=None, delimiter=None,
            full_listing=False):
        """
        Return a list of StorageObjects representing the pseudo-subdirectories
        in this container. You can use the marker and limit params to handle
        pagination, and the prefix and delimiter params to filter the objects
        returned.
        """
        subdirs = self.client.list_container_subdirs(self.name, marker=marker,
                limit=limit, prefix=prefix, delimiter=delimiter,
                full_listing=full_listing)
        return subdirs


    def store_object(self, obj_name, data, content_type=None, etag=None,
            content_encoding=None, ttl=None, return_none=False,
            extra_info=None):
        """
        Creates a new object in this container, and populates it with
        the given data.
        """
        return self.client.store_object(self, obj_name, data,
                content_type=content_type, etag=etag,
                content_encoding=content_encoding, ttl=ttl,
                return_none=return_none, extra_info=extra_info)


    def upload_file(self, file_or_path, obj_name=None, content_type=None,
            etag=None, return_none=False, content_encoding=None, ttl=None,
            content_length=None):
        """
        Uploads the specified file to this container. If no name is supplied,
        the file's name will be used. Either a file path or an open file-like
        object may be supplied. A StorageObject reference to the uploaded file
        will be returned, unless 'return_none' is set to True.
        """
        return self.client.upload_file(self, file_or_path, obj_name=obj_name,
                content_type=content_type, etag=etag, return_none=return_none,
                content_encoding=content_encoding, ttl=ttl,
                content_length=content_length)


    def delete_object(self, obj):
        """Deletes the specified object from this container."""
        self.remove_from_cache(obj)
        return self.client.delete_object(self, obj)


    def delete_all_objects(self, async=False):
        """
        Deletes all objects from this container.

        By default the call will block until all objects have been deleted. By
        passing True for the 'async' parameter, this method will not block, and
        instead return an object that can be used to follow the progress of the
        deletion. When deletion is complete the bulk deletion object's
        'results' attribute will be populated with the information returned
        from the API call. In synchronous mode this is the value that is
        returned when the call completes. It is a dictionary with the following
        keys:

            deleted - the number of objects deleted
            not_found - the number of objects not found
            status - the HTTP return status code. '200 OK' indicates success
            errors - a list of any errors returned by the bulk delete call
        """
        nms = self.get_object_names(full_listing=True)
        self.client.bulk_delete(self, nms, async=False)


    def remove_from_cache(self, obj):
        """Removes the object from the cache."""
        nm = self.client._resolve_name(obj)
        self._object_cache.pop(nm, None)


    def delete(self, del_objects=False):
        """
        Deletes this Container. If the container contains objects, the
        command will fail unless 'del_objects' is passed as True. In that
        case, each object will be deleted first, and then the container.
        """
        return self.client.delete_container(self.name, del_objects=del_objects)


    def fetch_object(self, obj_name, include_meta=False, chunk_size=None):
        """
        Fetches the object from storage.

        If 'include_meta' is False, only the bytes representing the
        file is returned.

        Note: if 'chunk_size' is defined, you must fully read the object's
        contents before making another request.

        When 'include_meta' is True, what is returned from this method is
        a 2-tuple:
            Element 0: a dictionary containing metadata about the file.
            Element 1: a stream of bytes representing the object's contents.
        """
        return self.client.fetch_object(self, obj_name,
                include_meta=include_meta, chunk_size=chunk_size)


    def download_object(self, obj_name, directory, structure=True):
        """
        Fetches the object from storage, and writes it to the specified
        directory. The directory must exist before calling this method.

        If the object name represents a nested folder structure, such as
        "foo/bar/baz.txt", that folder structure will be created in the target
        directory by default. If you do not want the nested folders to be
        created, pass `structure=False` in the parameters.
        """
        return self.client.download_object(self, obj_name, directory,
                structure=structure)


    def get_metadata(self, prefix=None):
        """
        Returns a dictionary containing the metadata for the container.
        """
        return self.client.get_container_metadata(self, prefix=prefix)


    def set_metadata(self, metadata, clear=False, prefix=None):
        """
        Accepts a dictionary of metadata key/value pairs and updates the
        specified container metadata with them.

        If 'clear' is True, any existing metadata is deleted and only the
        passed metadata is retained. Otherwise, the values passed here update
        the container's metadata.

        'extra_info' is an optional dictionary which will be populated with
        'status', 'reason', and 'headers' keys from the underlying swiftclient
        call.

        By default, the standard container metadata prefix
        ('X-Container-Meta-') is prepended to the header name if it isn't
        present. For non-standard headers, you must include a non-None prefix,
        such as an empty string.
        """
        return self.client.set_container_metadata(self, metadata, clear=clear,
                prefix=prefix)


    def remove_metadata_key(self, key, prefix=None):
        """
        Removes the specified key from the container's metadata. If the key
        does not exist in the metadata, nothing is done.
        """
        return self.client.remove_container_metadata_key(self, key,
                prefix=prefix)


    def set_web_index_page(self, page):
        """
        Sets the header indicating the index page for this container
        when creating a static website.

        Note: the container must be CDN-enabled for this to have
        any effect.
        """
        return self.client.set_container_web_index_page(self, page)


    def set_web_error_page(self, page):
        """
        Sets the header indicating the error page for this container
        when creating a static website.

        Note: the container must be CDN-enabled for this to have
        any effect.
        """
        return self.client.set_container_web_error_page(self, page)


    def make_public(self, ttl=None):
        """Enables CDN access for the specified container."""
        return self.client.make_container_public(self, ttl)


    def make_private(self):
        """
        Disables CDN access to this container. It may still appear public until
        its TTL expires.
        """
        return self.client.make_container_private(self)


    def copy_object(self, obj, new_container, new_obj_name=None,
            extra_info=None):
        """
        Copies the object to the new container, optionally giving it a new name.
        If you copy to the same container, you must supply a different name.
        """
        return self.client.copy_object(self, obj, new_container,
                new_obj_name=new_obj_name, extra_info=extra_info)


    def move_object(self, obj, new_container, new_obj_name=None,
            extra_info=None):
        """
        Works just like copy_object, except that the source object is deleted
        after a successful copy.
        """
        return self.client.move_object(self, obj, new_container,
                new_obj_name=new_obj_name, extra_info=extra_info)


    def change_object_content_type(self, obj, new_ctype, guess=False):
        """
        Copies object to itself, but applies a new content-type. The guess
        feature requires the container to be CDN-enabled. If not then the
        content-type must be supplied. If using guess with a CDN-enabled
        container, new_ctype can be set to None.
        Failure during the put will result in a swift exception.
        """
        self.client.change_object_content_type(self, obj, new_ctype=new_ctype,
                guess=guess)


    def get_temp_url(self, obj, seconds, method="GET"):
        """
        Returns a URL that can be used to access the specified object in this
        container. The URL will expire after `seconds` seconds.

        The only methods supported are GET and PUT. Anything else will raise
        an InvalidTemporaryURLMethod exception.
        """
        return self.client.get_temp_url(self, obj, seconds=seconds,
                method=method)


    def delete_object_in_seconds(self, obj, seconds):
        """
        Sets the object to be deleted after the specified number of seconds.
        """
        self.client.delete_object_in_seconds(self, obj, seconds)


    def __repr__(self):
        return "<Container '%s'>" % self.name


    # BEGIN - CDN property definitions ##
    @property
    def cdn_enabled(self):
        return bool(self.cdn_uri)

    def _get_cdn_log_retention(self):
        if self._cdn_log_retention is FAULT:
            self._fetch_cdn_data()
        return self._cdn_log_retention

    def _set_cdn_log_retention(self, val):
        self.client._set_cdn_log_retention(self, val)
        self._cdn_log_retention = val


    def _get_cdn_uri(self):
        if self._cdn_uri is FAULT:
            self._fetch_cdn_data()
        return self._cdn_uri

    def _set_cdn_uri(self, val):
        self._cdn_uri = val


    def _get_cdn_ttl(self):
        if self._cdn_ttl is FAULT:
            self._fetch_cdn_data()
        return self._cdn_ttl

    def _set_cdn_ttl(self, val):
        self._cdn_ttl = val


    def _get_cdn_ssl_uri(self):
        if self._cdn_ssl_uri is FAULT:
            self._fetch_cdn_data()
        return self._cdn_ssl_uri

    def _set_cdn_ssl_uri(self, val):
        self._cdn_ssl_uri = val


    def _get_cdn_streaming_uri(self):
        if self._cdn_streaming_uri is FAULT:
            self._fetch_cdn_data()
        return self._cdn_streaming_uri

    def _set_cdn_streaming_uri(self, val):
        self._cdn_streaming_uri = val


    def _get_cdn_ios_uri(self):
        if self._cdn_ios_uri is FAULT:
            self._fetch_cdn_data()
        return self._cdn_ios_uri

    def _set_cdn_ios_uri(self, val):
        self._cdn_ios_uri = val


    cdn_log_retention = property(_get_cdn_log_retention, _set_cdn_log_retention)
    cdn_uri = property(_get_cdn_uri, _set_cdn_uri)
    cdn_ttl = property(_get_cdn_ttl, _set_cdn_ttl)
    cdn_ssl_uri = property(_get_cdn_ssl_uri, _set_cdn_ssl_uri)
    cdn_streaming_uri = property(_get_cdn_streaming_uri, _set_cdn_streaming_uri)
    cdn_ios_uri = property(_get_cdn_ios_uri, _set_cdn_ios_uri)
    # END - CDN property definitions ##

########NEW FILE########
__FILENAME__ = storage_object
#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

import six

class StorageObject(object):
    """Represents a CloudFiles storage object."""
    def __init__(self, client, container, name=None, total_bytes=None,
            content_type=None, last_modified=None, etag=None, attdict=None):
        """
        The object can either be initialized with individual params, or by
        passing the dict that is returned by swiftclient.
        """
        self.client = client
        if isinstance(container, six.string_types):
            self.container = self.client.get_container(container)
        else:
            self.container = container
        self.name = name
        self.total_bytes = total_bytes
        self.content_type = content_type
        self.last_modified = last_modified
        self.etag = etag
        if attdict:
            self._read_attdict(attdict)


    def _read_attdict(self, dct):
        """
        Populates the object attributes using the dict returned by swiftclient.
        """
        self.name = dct.get("name")
        if not self.name:
            # Could be a pseudo-subdirectory
            self.name = dct.get("subdir").rstrip("/")
            self.content_type = "pseudo/subdir"
        else:
            self.content_type = dct.get("content_type")
        self.total_bytes = dct.get("bytes")
        self.last_modified = dct.get("last_modified")
        self.etag = dct.get("hash")


    def get(self, include_meta=False, chunk_size=None):
        """
        Fetches the object from storage.

        If 'include_meta' is False, only the bytes representing the
        file is returned.

        Note: if 'chunk_size' is defined, you must fully read the object's
        contents before making another request.

        When 'include_meta' is True, what is returned from this method is a
        2-tuple:
            Element 0: a dictionary containing metadata about the file.
            Element 1: a stream of bytes representing the object's contents.
        """
        return self.client.fetch_object(container=self.container.name,
                obj=self, include_meta=include_meta, chunk_size=chunk_size)
    # Changing the name of this method to 'fetch', as 'get' is overloaded.
    fetch = get


    def download(self, directory, structure=True):
        """
        Fetches the object from storage, and writes it to the specified
        directory. The directory must exist before calling this method.

        If the object name represents a nested folder structure, such as
        "foo/bar/baz.txt", that folder structure will be created in the target
        directory by default. If you do not want the nested folders to be
        created, pass `structure=False` in the parameters.
        """
        return self.client.download_object(self.container, self, directory,
                structure=structure)


    def delete(self):
        """Deletes the object from storage."""
        self.client.delete_object(container=self.container.name, name=self.name)


    def purge(self, email_addresses=[]):
        """
        Purges the object from the CDN network, sending an optional
        email confirmation.
        """
        self.client.purge_cdn_object(container=self.container.name,
                name=self.name, email_addresses=email_addresses)


    def get_metadata(self, prefix=None):
        """Returns this object's metadata."""
        return self.client.get_object_metadata(self.container, self,
                prefix=prefix)


    def set_metadata(self, metadata, clear=False, prefix=None):
        """
        Sets this object's metadata, optionally clearing existing metadata.
        """
        self.client.set_object_metadata(self.container, self, metadata,
                clear=clear, prefix=prefix)


    def remove_metadata_key(self, key, prefix=None):
        """
        Removes the specified key from the storage object's metadata. If the
        key does not exist in the metadata, nothing is done.
        """
        self.client.remove_object_metadata_key(self.container, self, key,
                prefix=prefix)


    def copy(self, new_container, new_obj_name=None, extra_info=None):
        """
        Copies this object to the new container, optionally giving it a new name.
        If you copy to the same container, you must supply a different name.
        """
        return self.container.copy_object(self, new_container,
                new_obj_name=new_obj_name, extra_info=extra_info)


    def move(self, new_container, new_obj_name=None, extra_info=None):
        """
        Works just like copy_object, except that this object is deleted after a
        successful copy. This means that this storage_object reference will no
        longer be valid.
        """
        return self.container.move_object(self, new_container,
                new_obj_name=new_obj_name, extra_info=extra_info)


    def change_content_type(self, new_ctype, guess=False):
        """
        Copies object to itself, but applies a new content-type. The guess
        feature requires the container to be CDN-enabled. If not then the
        content-type must be supplied. If using guess with a CDN-enabled
        container, new_ctype can be set to None.
        Failure during the put will result in a swift exception.
        """
        self.client.change_object_content_type(self.container, self,
                new_ctype=new_ctype, guess=guess)


    def get_temp_url(self, seconds, method="GET"):
        """
        Returns a URL that can be used to access this object. The URL will
        expire after `seconds` seconds.

        The only methods supported are GET and PUT. Anything else will raise
        an InvalidTemporaryURLMethod exception.
        """
        return self.client.get_temp_url(self.container, self, seconds=seconds,
                method=method)


    def delete_in_seconds(self, seconds):
        """
        Sets the object to be deleted after the specified number of seconds.
        """
        self.client.delete_object_in_seconds(self.container, self, seconds)


    def __repr__(self):
        return "<Object '%s' (%s)>" % (self.name, self.content_type)

########NEW FILE########
__FILENAME__ = client
#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Copyright 2010 Jacob Kaplan-Moss
# Copyright 2011 OpenStack LLC.
# Copyright 2011 Piston Cloud Computing, Inc.
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.
"""
OpenStack Client interface. Handles the REST calls and responses.
"""

from __future__ import absolute_import

import json
import logging
import requests
import time
import urllib
from six.moves.urllib import parse as urlparse

import pyrax
import pyrax.exceptions as exc

SAFE_QUOTE_CHARS = "/.?&=,"

class BaseClient(object):
    """
    The base class for all pyrax clients.
    """
    # This will get set by pyrax when the service is started.
    user_agent = None
    # Each client subclass should set their own name.
    name = "base"

    def __init__(self, identity, region_name=None, endpoint_type=None,
            management_url=None, service_name=None, timings=False,
            verify_ssl=True, http_log_debug=False, timeout=None):
        self.version = "v1.1"
        self.identity = identity
        self.region_name = region_name
        self.endpoint_type = endpoint_type
        self.service_name = service_name
        self.management_url = management_url
        self.timings = timings
        self.verify_ssl = verify_ssl
        self.http_log_debug = http_log_debug
        self.timeout = timeout
        self.times = []  # [("item", starttime, endtime), ...]

        self._manager = None
        # Hook method for subclasses to create their manager instance
        # without having to override __init__().
        self._configure_manager()


    def _configure_manager(self):
        """
        This must be overridden in base classes to create
        the required manager class and configure it as needed.
        """
        raise NotImplementedError


    # The next 6 methods are simple pass-through to the manager.
    def list(self, limit=None, marker=None):
        """
        Returns a list of resource objects. Pagination is supported through the
        optional 'marker' and 'limit' parameters.
        """
        return self._manager.list(limit=limit, marker=marker)


    def get(self, item):
        """Gets a specific resource."""
        return self._manager.get(item)


    def create(self, *args, **kwargs):
        """Creates a new resource."""
        return self._manager.create(*args, **kwargs)


    def delete(self, item):
        """Deletes a specific resource."""
        return self._manager.delete(item)


    def find(self, **kwargs):
        """
        Finds a single item with attributes matching ``**kwargs``.

        This isn't very efficient: it loads the entire list then filters on
        the Python side.
        """
        return self._manager.find(**kwargs)


    def findall(self, **kwargs):
        """
        Finds all items with attributes matching ``**kwargs``.

        This isn't very efficient: it loads the entire list then filters on
        the Python side.
        """
        return self._manager.findall(**kwargs)


    def unauthenticate(self):
        """Clears all of our authentication information."""
        self.identity.unauthenticate()


    def get_timings(self):
        """Returns a list of all execution timings."""
        return self.times


    def reset_timings(self):
        """Clears the timing history."""
        self.times = []


    def get_limits(self):
        """
        Returns a dict with the resource and rate limits for the account.
        """
        resp, resp_body = self.method_get("/limits")
        return resp_body


    def _add_custom_headers(self, dct):
        """
        Clients for some services must add headers that are required for that
        service. This is a hook method to allow for such customization.

        If a client needs to add a special header, the 'dct' parameter is a
        dictionary of headers. Add the header(s) and their values as key/value
        pairs to the 'dct'.
        """
        pass


    def request(self, uri, method, *args, **kwargs):
        """
        Formats the request into a dict representing the headers
        and body that will be used to make the API call.
        """
        if self.timeout:
            kwargs["timeout"] = self.timeout
        kwargs["verify"] = self.verify_ssl
        kwargs.setdefault("headers", kwargs.get("headers", {}))
        kwargs["headers"]["User-Agent"] = self.user_agent
        kwargs["headers"]["Accept"] = "application/json"
        # Allow subclasses to add their own headers
        self._add_custom_headers(kwargs["headers"])
        resp, body = pyrax.http.request(method, uri, *args, **kwargs)
        if resp.status_code >= 400:
            raise exc.from_response(resp, body)
        return resp, body


    def _time_request(self, uri, method, **kwargs):
        """Wraps the request call and records the elapsed time."""
        start_time = time.time()
        resp, body = self.request(uri, method, **kwargs)
        self.times.append(("%s %s" % (method, uri),
                start_time, time.time()))
        return resp, body


    def _api_request(self, uri, method, **kwargs):
        """
        Manages the request by adding any auth information, and retries
        the request after authenticating if the initial request returned
        and Unauthorized exception.
        """
        id_svc = self.identity
        if not all((self.management_url, id_svc.token, id_svc.tenant_id)):
            id_svc.authenticate()

        if not self.management_url:
            # We've authenticated but no management_url has been set. This
            # indicates that the service is not available.
            raise exc.ServiceNotAvailable("The '%s' service is not available."
                    % self)
        if uri.startswith("http"):
            parsed = list(urlparse.urlparse(uri))
            for pos, item in enumerate(parsed):
                if pos < 2:
                    # Don't escape the scheme or netloc
                    continue
                parsed[pos] = urllib.quote(parsed[pos], safe=SAFE_QUOTE_CHARS)
            safe_uri = urlparse.urlunparse(parsed)
        else:
            safe_uri = "%s%s" % (self.management_url,
                    urllib.quote(uri, safe=SAFE_QUOTE_CHARS))
        # Perform the request once. If we get a 401 back then it
        # might be because the auth token expired, so try to
        # re-authenticate and try again. If it still fails, bail.
        try:
            kwargs.setdefault("headers", {})["X-Auth-Token"] = id_svc.token
            if id_svc.tenant_id:
                kwargs["headers"]["X-Auth-Project-Id"] = id_svc.tenant_id
            resp, body = self._time_request(safe_uri, method, **kwargs)
            return resp, body
        except exc.Unauthorized as ex:
            try:
                id_svc.authenticate()
                kwargs["headers"]["X-Auth-Token"] = id_svc.token
                resp, body = self._time_request(safe_uri, method, **kwargs)
                return resp, body
            except exc.Unauthorized:
                raise ex


    def method_head(self, uri, **kwargs):
        """Method used to make HEAD requests."""
        return self._api_request(uri, "HEAD", **kwargs)


    def method_get(self, uri, **kwargs):
        """Method used to make GET requests."""
        return self._api_request(uri, "GET", **kwargs)


    def method_post(self, uri, **kwargs):
        """Method used to make POST requests."""
        return self._api_request(uri, "POST", **kwargs)


    def method_put(self, uri, **kwargs):
        """Method used to make PUT requests."""
        return self._api_request(uri, "PUT", **kwargs)


    def method_delete(self, uri, **kwargs):
        """Method used to make DELETE requests."""
        return self._api_request(uri, "DELETE", **kwargs)


    def method_patch(self, uri, **kwargs):
        """Method used to make PATCH requests."""
        return self._api_request(uri, "PATCH", **kwargs)


    def authenticate(self):
        """
        Handles all aspects of authentication against the cloud provider.
        Currently this has only been tested with Rackspace auth; if you wish
        to use this library with a different OpenStack provider, you may have
        to modify this method. Please post your findings on GitHub so that
        others can benefit.
        """
        return self.identity.authenticate()


    @property
    def projectid(self):
        """
        The older parts of this code used 'projectid'; this wraps that
        reference.
        """
        return self.identity.tenant_id

########NEW FILE########
__FILENAME__ = cloudblockstorage
#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from functools import wraps
import time

import six

import pyrax
from pyrax.client import BaseClient
import pyrax.exceptions as exc
from pyrax.manager import BaseManager
from pyrax.resource import BaseResource
import pyrax.utils as utils


MIN_SIZE = 100
MAX_SIZE = 1024
RETRY_INTERVAL = 5


def _resolve_id(val):
    """Takes an object or an ID and returns the ID."""
    return val if isinstance(val, six.string_types) else val.id


def _resolve_name(val):
    """Takes an object or a name and returns the name."""
    return val if isinstance(val, six.string_types) else val.name


def assure_volume(fnc):
    """
    Converts a volumeID passed as the volume to a CloudBlockStorageVolume object.
    """
    @wraps(fnc)
    def _wrapped(self, volume, *args, **kwargs):
        if not isinstance(volume, CloudBlockStorageVolume):
            # Must be the ID
            volume = self._manager.get(volume)
        return fnc(self, volume, *args, **kwargs)
    return _wrapped


def assure_snapshot(fnc):
    """
    Converts a snapshot ID passed as the snapshot to a CloudBlockStorageSnapshot
    object.
    """
    @wraps(fnc)
    def _wrapped(self, snapshot, *args, **kwargs):
        if not isinstance(snapshot, CloudBlockStorageSnapshot):
            # Must be the ID
            snapshot = self._snapshot_manager.get(snapshot)
        return fnc(self, snapshot, *args, **kwargs)
    return _wrapped



class CloudBlockStorageSnapshot(BaseResource):
    """
    This class represents a Snapshot (copy) of a Block Storage Volume.
    """
    def delete(self):
        """
        Adds a check to make sure that the snapshot is able to be deleted.
        """
        if self.status not in ("available", "error"):
            raise exc.SnapshotNotAvailable("Snapshot must be in 'available' "
                    "or 'error' status before deleting. Current status: %s" %
                    self.status)
        # When there are more thann one snapshot for a given volume, attempting to
        # delete them all will throw a 409 exception. This will help by retrying
        # such an error once after a RETRY_INTERVAL second delay.
        try:
            super(CloudBlockStorageSnapshot, self).delete()
        except exc.ClientException as e:
            if "Request conflicts with in-progress 'DELETE" in str(e):
                time.sleep(RETRY_INTERVAL)
                # Try again; if it fails, oh, well...
                super(CloudBlockStorageSnapshot, self).delete()


    def _get_name(self):
        return self.display_name

    def _set_name(self, val):
        self.display_name = val

    name = property(_get_name, _set_name, None,
            "Convenience for referencing the display_name.")

    def _get_description(self):
        return self.display_description

    def _set_description(self, val):
        self.display_description = val

    description = property(_get_description, _set_description, None,
            "Convenience for referencing the display_description.")


class CloudBlockStorageVolumeType(BaseResource):
    """
    This class represents a Block Storage Volume Type.
    """
    pass


class CloudBlockStorageVolume(BaseResource):
    """
    This class represents a Block Storage volume.
    """
    def __init__(self, *args, **kwargs):
        super(CloudBlockStorageVolume, self).__init__(*args, **kwargs)
        region = self.manager.api.region_name
        context = self.manager.api.identity
        cs = pyrax.connect_to_cloudservers(region=region, context=context)
        self._nova_volumes = cs.volumes


    def attach_to_instance(self, instance, mountpoint):
        """
        Attaches this volume to the cloud server instance at the
        specified mountpoint. This requires a call to the cloud servers
        API; it cannot be done directly.
        """
        instance_id = _resolve_id(instance)
        try:
            resp = self._nova_volumes.create_server_volume(instance_id,
                    self.id, mountpoint)
        except Exception as e:
            raise exc.VolumeAttachmentFailed("%s" % e)


    def detach(self):
        """
        Detaches this volume from any device it may be attached to. If it
        is not attached, nothing happens.
        """
        attachments = self.attachments
        if not attachments:
            # Not attached; no error needed, just return
            return
        # A volume can only be attached to one device at a time, but for some
        # reason this is a list instead of a singular value
        att = attachments[0]
        instance_id = att["server_id"]
        attachment_id = att["id"]
        try:
            self._nova_volumes.delete_server_volume(instance_id, attachment_id)
        except Exception as e:
            raise exc.VolumeDetachmentFailed("%s" % e)


    def delete(self, force=False):
        """
        Volumes cannot be deleted if either a) they are attached to a device, or
        b) they have any snapshots. This method overrides the base delete()
        method to both better handle these failures, and also to offer a 'force'
        option. When 'force' is True, the volume is detached, and any dependent
        snapshots are deleted before calling the volume's delete.
        """
        if force:
            self.detach()
            self.delete_all_snapshots()
        try:
            super(CloudBlockStorageVolume, self).delete()
        except exc.VolumeNotAvailable:
            # Notify the user? Record it somewhere?
            # For now, just re-raise
            raise


    def create_snapshot(self, name=None, description=None, force=False):
        """
        Creates a snapshot of this volume, with an optional name and
        description.

        Normally snapshots will not happen if the volume is attached. To
        override this default behavior, pass force=True.
        """
        name = name or ""
        description = description or ""
        # Note that passing in non-None values is required for the _create_body
        # method to distinguish between this and the request to create and
        # instance.
        return self.manager.create_snapshot(volume=self, name=name,
                    description=description, force=force)


    def list_snapshots(self):
        """
        Returns a list of all snapshots of this volume.
        """
        return [snap for snap in self.manager.list_snapshots()
                if snap.volume_id == self.id]


    def delete_all_snapshots(self):
        """
        Locates all snapshots of this volume and deletes them.
        """
        for snap in self.list_snapshots():
            snap.delete()


    def _get_name(self):
        return self.display_name

    def _set_name(self, val):
        self.display_name = val

    name = property(_get_name, _set_name, None,
            "Convenience for referencing the display_name.")

    def _get_description(self):
        return self.display_description

    def _set_description(self, val):
        self.display_description = val

    description = property(_get_description, _set_description, None,
            "Convenience for referencing the display_description.")


class CloudBlockStorageManager(BaseManager):
    """
    Manager class for Cloud Block Storage.
    """
    def _create_body(self, name, size=None, volume_type=None, description=None,
             metadata=None, snapshot_id=None, clone_id=None,
             availability_zone=None):
        """
        Used to create the dict required to create a new volume
        """
        if not isinstance(size, (int, long)) or not (
                MIN_SIZE <= size <= MAX_SIZE):
            raise exc.InvalidSize("Volume sizes must be integers between "
                    "%s and %s." % (MIN_SIZE, MAX_SIZE))
        if volume_type is None:
            volume_type = "SATA"
        if description is None:
            description = ""
        if metadata is None:
            metadata = {}
        body = {"volume": {
                "size": size,
                "snapshot_id": snapshot_id,
                "source_volid": clone_id,
                "display_name": name,
                "display_description": description,
                "volume_type": volume_type,
                "metadata": metadata,
                "availability_zone": availability_zone,
                }}
        return body


    def create(self, *args, **kwargs):
        """
        Catches errors that may be returned, and raises more informational
        exceptions.
        """
        try:
            return super(CloudBlockStorageManager, self).create(*args,
                    **kwargs)
        except exc.BadRequest as e:
            msg = e.message
            if "Clones currently must be >= original volume size" in msg:
                raise exc.VolumeCloneTooSmall(msg)
            else:
                raise


    def update(self, volume, display_name=None, display_description=None):
        """
        Update the specified values on the specified volume. You may specify
        one or more values to update.
        """
        uri = "/%s/%s" % (self.uri_base, utils.get_id(volume))
        param_dict = {}
        if display_name:
            param_dict["display_name"] = display_name
        if display_description:
            param_dict["display_description"] = display_description
        if not param_dict:
            # Nothing to do!
            return
        body = {"volume": param_dict}
        resp, resp_body = self.api.method_put(uri, body=body)


    def list_snapshots(self):
        """
        Pass-through method to allow the list_snapshots() call to be made
        directly on a volume.
        """
        return self.api.list_snapshots()


    def create_snapshot(self, volume, name, description=None, force=False):
        """
        Pass-through method to allow the create_snapshot() call to be made
        directly on a volume.
        """
        return self.api.create_snapshot(volume, name, description=description,
                force=force)



class CloudBlockStorageSnapshotManager(BaseManager):
    """
    Manager class for Cloud Block Storage.
    """
    def _create_body(self, name, description=None, volume=None, force=False):
        """
        Used to create the dict required to create a new snapshot
        """
        body = {"snapshot": {
                "display_name": name,
                "display_description": description,
                "volume_id": volume.id,
                "force": str(force).lower(),
                }}
        return body


    def create(self, name, volume, description=None, force=False):
        """
        Adds exception handling to the default create() call.
        """
        try:
            snap = super(CloudBlockStorageSnapshotManager, self).create(
                    name=name, volume=volume, description=description,
                    force=force)
        except exc.BadRequest as e:
            msg = str(e)
            if "Invalid volume: must be available" in msg:
                # The volume for the snapshot was attached.
                raise exc.VolumeNotAvailable("Cannot create a snapshot from an "
                        "attached volume. Detach the volume before trying "
                        "again, or pass 'force=True' to the create_snapshot() "
                        "call.")
            else:
                # Some other error
                raise
        except exc.ClientException as e:
            if e.code == 409:
                if "Request conflicts with in-progress" in str(e):
                    txt = ("The volume is current creating a snapshot. You "
                            "must wait until that completes before attempting "
                            "to create an additional snapshot.")
                    raise exc.VolumeNotAvailable(txt)
                else:
                    raise
            else:
                raise
        return snap


    def update(self, snapshot, display_name=None, display_description=None):
        """
        Update the specified values on the specified snapshot. You may specify
        one or more values to update.
        """
        uri = "/%s/%s" % (self.uri_base, utils.get_id(snapshot))
        param_dict = {}
        if display_name:
            param_dict["display_name"] = display_name
        if display_description:
            param_dict["display_description"] = display_description
        if not param_dict:
            # Nothing to do!
            return
        body = {"snapshot": param_dict}
        resp, resp_body = self.api.method_put(uri, body=body)


class CloudBlockStorageClient(BaseClient):
    """
    This is the primary class for interacting with Cloud Block Storage.
    """
    name = "Cloud Block Storage"

    def _configure_manager(self):
        """
        Create the manager to handle the instances, and also another
        to handle flavors.
        """
        self._manager = CloudBlockStorageManager(self,
                resource_class=CloudBlockStorageVolume, response_key="volume",
                uri_base="volumes")
        self._types_manager = BaseManager(self,
                resource_class=CloudBlockStorageVolumeType,
                response_key="volume_type", uri_base="types")
        self._snapshot_manager = CloudBlockStorageSnapshotManager(self,
                resource_class=CloudBlockStorageSnapshot,
                response_key="snapshot", uri_base="snapshots")


    def list_types(self):
        """Returns a list of all available volume types."""
        return self._types_manager.list()


    def list_snapshots(self):
        """Returns a list of all snapshots."""
        return self._snapshot_manager.list()


    @assure_volume
    def attach_to_instance(self, volume, instance, mountpoint):
        """Attaches the volume to the specified instance at the mountpoint."""
        return volume.attach_to_instance(instance, mountpoint)


    @assure_volume
    def detach(self, volume):
        """Detaches the volume from whatever device it is attached to."""
        return volume.detach()


    @assure_volume
    def delete_volume(self, volume, force=False):
        """Deletes the volume."""
        return volume.delete(force=force)


    @assure_volume
    def update(self, volume, display_name=None, display_description=None):
        """
        Update the specified values on the specified volume. You may specify
        one or more values to update.
        """
        return self._manager.update(volume, display_name=display_name,
                display_description=display_description)


    @assure_volume
    def create_snapshot(self, volume, name=None, description=None, force=False):
        """
        Creates a snapshot of the volume, with an optional name and description.

        Normally snapshots will not happen if the volume is attached. To
        override this default behavior, pass force=True.
        """
        return self._snapshot_manager.create(volume=volume, name=name,
                description=description, force=force)


    def get_snapshot(self, snapshot):
        """
        Returns the snapshot with the specified snapshot ID value.
        """
        return self._snapshot_manager.get(snapshot)


    @assure_snapshot
    def delete_snapshot(self, snapshot):
        """Deletes the snapshot."""
        return snapshot.delete()


    def update_snapshot(self, snapshot, display_name=None,
            display_description=None):
        """
        Update the specified values on the specified snapshot. You may specify
        one or more values to update.
        """
        return self._snapshot_manager.update(snapshot,
                display_name=display_name,
                display_description=display_description)

########NEW FILE########
__FILENAME__ = clouddatabases
#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from functools import wraps

import six

from pyrax.client import BaseClient
import pyrax.exceptions as exc
from pyrax.manager import BaseManager
from pyrax.resource import BaseResource
import pyrax.utils as utils


def assure_instance(fnc):
    @wraps(fnc)
    def _wrapped(self, instance, *args, **kwargs):
        if not isinstance(instance, CloudDatabaseInstance):
            # Must be the ID
            instance = self._manager.get(instance)
        return fnc(self, instance, *args, **kwargs)
    return _wrapped



class CloudDatabaseVolume(object):
    instance = None
    size = None
    used = None

    def __init__(self, instance, info):
        self.instance = instance
        for key, val in info.items():
            setattr(self, key, val)


    def resize(self, size):
        """
        Resize the volume to the specified size (in GB).
        """
        self.instance.resize_volume(size)
        self.size = size


    def get(self, att):
        """
        For compatibility with regular resource objects.
        """
        return getattr(self, att)



class CloudDatabaseManager(BaseManager):
    """
    This class manages communication with Cloud Database instances.
    """
    def get(self, item):
        """
        This additional code is necessary to properly return the 'volume'
        attribute of the instance as a CloudDatabaseVolume object instead of
        a raw dict.
        """
        resource = super(CloudDatabaseManager, self).get(item)
        resource.volume = CloudDatabaseVolume(resource, resource.volume)
        return resource


    def _create_body(self, name, flavor=None, volume=None, databases=None,
            users=None):
        """
        Used to create the dict required to create a Cloud Database instance.
        """
        if flavor is None:
            flavor = 1
        flavor_ref = self.api._get_flavor_ref(flavor)
        if volume is None:
            volume = 1
        if databases is None:
            databases = []
        if users is None:
            users = []
        body = {"instance": {
                "name": name,
                "flavorRef": flavor_ref,
                "volume": {"size": volume},
                "databases": databases,
                "users": users,
                }}
        return body


    def create_backup(self, instance, name, description=None):
        """
        Creates a backup of the specified instance, giving it the specified
        name along with an optional description.
        """
        body = {"backup": {
                "instance": utils.get_id(instance),
                "name": name,
                }}
        if description is not None:
            body["backup"]["description"] = description
        uri = "/backups"
        resp, resp_body = self.api.method_post(uri, body=body)
        mgr = self.api._backup_manager
        return CloudDatabaseBackup(mgr, body.get("backup"))


    def restore_backup(self, backup, name, flavor, volume):
        """
        Restores a backup to a new database instance. You must supply a backup
        (either the ID or a CloudDatabaseBackup object), a name for the new
        instance, as well as a flavor and volume size (in GB) for the instance.
        """
        flavor_ref = self.api._get_flavor_ref(flavor)
        body = {"instance": {
                "name": name,
                "flavorRef": flavor_ref,
                "volume": {"size": volume},
                "restorePoint": {"backupRef": utils.get_id(backup)},
                }}
        uri = "/%s" % self.uri_base
        resp, resp_body = self.api.method_post(uri, body=body)
        return CloudDatabaseInstance(self, resp_body.get("instance", {}))


    def list_backups(self, instance=None):
        """
        Returns a list of all backups by default, or just for a particular
        instance.
        """
        return self.api._backup_manager.list(instance=instance)


    def _list_backups_for_instance(self, instance):
        """
        Instance-specific backups are handled through the instance manager,
        not the backup manager.
        """
        uri = "/%s/%s/backups" % (self.uri_base, utils.get_id(instance))
        resp, resp_body = self.api.method_get(uri)
        mgr = self.api._backup_manager
        return [CloudDatabaseBackup(mgr, backup)
                for backup in resp_body.get("backups")]



class CloudDatabaseDatabaseManager(BaseManager):
    """
    This class manages communication with databases on Cloud Database instances.
    """
    def _create_body(self, name, character_set=None, collate=None):
        body = {"databases": [
                {"name": name,
                "character_set": character_set,
                "collate": collate,
                }]}
        return body



class CloudDatabaseUserManager(BaseManager):
    """
    This class handles operations on the users in a database on a Cloud
    Database instance.
    """
    def _create_body(self, name, password, databases=None, database_names=None,
            host=None):
        db_dicts = [{"name": db} for db in database_names]
        body = {"users": [
                {"name": name,
                "password": password,
                "databases": db_dicts,
                }]}
        if host:
            body["users"][0]["host"] = host
        return body


    def _get_db_names(self, dbs, strict=True):
        """
        Accepts a single db (name or object) or a list of dbs, and returns a
        list of database names. If any of the supplied dbs do not exist, a
        NoSuchDatabase exception will be raised, unless you pass strict=False.
        """
        dbs = utils.coerce_string_to_list(dbs)
        db_names = [utils.get_name(db) for db in dbs]
        if strict:
            good_dbs = self.instance.list_databases()
            good_names = [utils.get_name(good_db) for good_db in good_dbs]
            bad_names = [db_name for db_name in db_names
                    if db_name not in good_names]
            if bad_names:
                bad = ", ".join(bad_names)
                raise exc.NoSuchDatabase("The following database(s) were not "
                        "found: %s" % bad)
        return db_names


    def change_user_password(self, user, new_pass):
        """
        Changes the password for the user to the supplied value.

        Returns None upon success; raises PasswordChangeFailed if the call
        does not complete successfully.
        """
        return self.update(user, password=new_pass)


    def update(self, user, name=None, password=None, host=None):
        """
        Allows you to change one or more of the user's username, password, or
        host.
        """
        if not any((name, password, host)):
            raise exc.MissingDBUserParameters("You must supply at least one of "
                    "the following: new username, new password, or new host "
                    "specification.")
        if not isinstance(user, CloudDatabaseUser):
            # Must be the ID/name
            user = self.get(user)
        dct = {}
        if name and (name != user.name):
            dct["name"] = name
        if host and (host != user.host):
            dct["host"] = host
        if password:
            dct["password"] = password
        if not dct:
            raise exc.DBUpdateUnchanged("You must supply at least one changed "
                    "value when updating a user.")
        uri = "/%s/%s" % (self.uri_base, user.name)
        body = {"user": dct}
        resp, resp_body = self.api.method_put(uri, body=body)
        return None


    def list_user_access(self, user):
        """
        Returns a list of all database names for which the specified user
        has access rights.
        """
        user = utils.get_name(user)
        uri = "/%s/%s/databases" % (self.uri_base, user)
        try:
            resp, resp_body = self.api.method_get(uri)
        except exc.NotFound as e:
            raise exc.NoSuchDatabaseUser("User '%s' does not exist." % user)
        dbs = resp_body.get("databases", {})
        return [CloudDatabaseDatabase(self, db) for db in dbs]


    def grant_user_access(self, user, db_names, strict=True):
        """
        Gives access to the databases listed in `db_names` to the user. You may
        pass in either a single db or a list of dbs.

        If any of the databases do not exist, a NoSuchDatabase exception will
        be raised, unless you specify `strict=False` in the call.
        """
        user = utils.get_name(user)
        uri = "/%s/%s/databases" % (self.uri_base, user)
        db_names = self._get_db_names(db_names, strict=strict)
        dbs = [{"name": db_name} for db_name in db_names]
        body = {"databases": dbs}
        try:
            resp, resp_body = self.api.method_put(uri, body=body)
        except exc.NotFound as e:
            raise exc.NoSuchDatabaseUser("User '%s' does not exist." % user)


    def revoke_user_access(self, user, db_names, strict=True):
        """
        Revokes access to the databases listed in `db_names` for the user.

        If any of the databases do not exist, a NoSuchDatabase exception will
        be raised, unless you specify `strict=False` in the call.
        """
        user = utils.get_name(user)
        db_names = self._get_db_names(db_names, strict=strict)
        bad_names = []
        for db_name in db_names:
            uri = "/%s/%s/databases/%s" % (self.uri_base, user, db_name)
            resp, resp_body = self.api.method_delete(uri)



class CloudDatabaseBackupManager(BaseManager):
    """
    This class handles operations on backups for a Cloud Database instance.
    """
    def _create_body(self, name, instance, description=None):
        body = {"backup": {
                "instance": utils.get_id(instance),
                "name": name,
                }}
        if description is not None:
            body["backup"]["description"] = description
        return body


    def list(self, instance=None):
        """
        Return a list of all backups by default, or just for a particular
        instance.
        """
        if instance is None:
            return super(CloudDatabaseBackupManager, self).list()
        return self.api._manager._list_backups_for_instance(instance)



class CloudDatabaseInstance(BaseResource):
    """
    This class represents a MySQL instance in the cloud.
    """
    def __init__(self, *args, **kwargs):
        super(CloudDatabaseInstance, self).__init__(*args, **kwargs)
        self._database_manager = CloudDatabaseDatabaseManager(self.manager.api,
                resource_class=CloudDatabaseDatabase, response_key="database",
                uri_base="instances/%s/databases" % self.id)
        self._user_manager = CloudDatabaseUserManager(self.manager.api,
                resource_class=CloudDatabaseUser, response_key="user",
                uri_base="instances/%s/users" % self.id)
        # Add references to the parent instance to the managers.
        self._database_manager.instance = self._user_manager.instance = self
        # Remove the lazy load
        if not self.loaded:
            self.get()


    def get(self):
        """
        Need to override the default get() behavior by making the 'volume'
        attribute into a CloudDatabaseVolume object instead of the raw dict.
        """
        super(CloudDatabaseInstance, self).get()
        # Make the volume into an accessible object instead of a dict
        self.volume = CloudDatabaseVolume(self, self.volume)


    def list_databases(self, limit=None, marker=None):
        """Returns a list of the names of all databases for this instance."""
        return self._database_manager.list(limit=limit, marker=marker)


    def list_users(self, limit=None, marker=None):
        """Returns a list of the names of all users for this instance."""
        return self._user_manager.list(limit=limit, marker=marker)


    def get_user(self, name):
        """
        Finds the user in this instance with the specified name, and
        returns a CloudDatabaseUser object. If no match is found, a
        NoSuchDatabaseUser exception is raised.
        """
        try:
            return self._user_manager.get(name)
        except exc.NotFound:
            raise exc.NoSuchDatabaseUser("No user by the name '%s' exists." %
                    name)


    def get_database(self, name):
        """
        Finds the database in this instance with the specified name, and
        returns a CloudDatabaseDatabase object. If no match is found, a
        NoSuchDatabase exception is raised.
        """
        try:
            return [db for db in self.list_databases()
                    if db.name == name][0]
        except IndexError:
            raise exc.NoSuchDatabase("No database by the name '%s' exists." %
                    name)


    def create_database(self, name, character_set=None, collate=None):
        """
        Creates a database with the specified name. If a database with
        that name already exists, a BadRequest (400) exception will
        be raised.
        """
        if character_set is None:
            character_set = "utf8"
        if collate is None:
            collate = "utf8_general_ci"
        self._database_manager.create(name=name, character_set=character_set,
                collate=collate, return_none=True)
        # Since the API doesn't return the info for creating the database
        # object, we have to do it manually.
        return self._database_manager.find(name=name)


    def create_user(self, name, password, database_names, host=None):
        """
        Creates a user with the specified name and password, and gives that
        user access to the specified database(s).

        If a user with that name already exists, a BadRequest (400) exception
        will be raised.
        """
        if not isinstance(database_names, (list, tuple)):
            database_names = [database_names]
        # The API only accepts names, not DB objects
        database_names = [db if isinstance(db, six.string_types) else db.name
                for db in database_names]
        self._user_manager.create(name=name, password=password,
                database_names=database_names, host=host, return_none=True)
        # Since the API doesn't return the info for creating the user object,
        # we have to do it manually.
        return self._user_manager.find(name=name)


    def delete_database(self, name_or_obj):
        """
        Deletes the specified database. If no database by that name
        exists, no exception will be raised; instead, nothing at all
        is done.
        """
        name = utils.get_name(name_or_obj)
        self._database_manager.delete(name)


    def change_user_password(self, user, new_pass):
        """
        Changes the password for the user to the supplied value.

        Returns None upon success; raises PasswordChangeFailed if the call
        does not complete successfully.
        """
        return self._user_manager.change_user_password(user, new_pass)


    def update_user(self, user, name=None, password=None, host=None):
        """
        Allows you to change one or more of the user's username, password, or
        host.
        """
        return self._user_manager.update(user, name=name, password=password,
                host=host)


    def list_user_access(self, user):
        """
        Returns a list of all database names for which the specified user
        has access rights.
        """
        return self._user_manager.list_user_access(user)


    def grant_user_access(self, user, db_names, strict=True):
        """
        Gives access to the databases listed in `db_names` to the user.
        """
        return self._user_manager.grant_user_access(user, db_names,
                strict=strict)


    def revoke_user_access(self, user, db_names, strict=True):
        """
        Revokes access to the databases listed in `db_names` for the user.
        """
        return self._user_manager.revoke_user_access(user, db_names,
                strict=strict)


    def delete_user(self, user):
        """
        Deletes the specified user. If no user by that name
        exists, no exception will be raised; instead, nothing at all
        is done.
        """
        name = utils.get_name(user)
        self._user_manager.delete(name)


    def enable_root_user(self):
        """
        Enables login from any host for the root user and provides
        the user with a generated root password.
        """
        uri = "/instances/%s/root" % self.id
        resp, body = self.manager.api.method_post(uri)
        return body["user"]["password"]


    def root_user_status(self):
        """
        Returns True or False, depending on whether the root user
        for this instance has been enabled.
        """
        uri = "/instances/%s/root" % self.id
        resp, body = self.manager.api.method_get(uri)
        return body["rootEnabled"]


    def restart(self):
        """Restarts this instance."""
        self.manager.action(self, "restart")


    def resize(self, flavor):
        """Set the size of this instance to a different flavor."""
        # We need the flavorRef, not the flavor or size.
        flavorRef = self.manager.api._get_flavor_ref(flavor)
        body = {"flavorRef": flavorRef}
        self.manager.action(self, "resize", body=body)


    def resize_volume(self, size):
        """Changes the size of the volume for this instance."""
        curr_size = self.volume.size
        if size <= curr_size:
            raise exc.InvalidVolumeResize("The new volume size must be larger "
                    "than the current volume size of '%s'." % curr_size)
        body = {"volume": {"size": size}}
        self.manager.action(self, "resize", body=body)


    def list_backups(self):
        """
        Returns a list of all backups for this instance.
        """
        return self.manager._list_backups_for_instance(self)


    def create_backup(self, name, description=None):
        """
        Creates a backup of this instance, giving it the specified name along
        with an optional description.
        """
        return self.manager.create_backup(self, name, description=description)


    def _get_flavor(self):
        try:
            ret = self._flavor
        except AttributeError:
            ret = self._flavor = CloudDatabaseFlavor(
                    self.manager.api._flavor_manager, {})
        return ret

    def _set_flavor(self, flavor):
        if isinstance(flavor, dict):
            self._flavor = CloudDatabaseFlavor(self.manager.api._flavor_manager,
                    flavor)
        else:
            # Must be an instance
            self._flavor = flavor

    flavor = property(_get_flavor, _set_flavor)


class CloudDatabaseDatabase(BaseResource):
    """
    This class represents a database on a CloudDatabaseInstance. It is not
    a true cloud entity, but a convenience object for dealing with databases
    on instances.
    """
    get_details = True

    def delete(self):
        """This class doesn't have an 'id', so pass the name."""
        self.manager.delete(self.name)


class CloudDatabaseUser(BaseResource):
    """
    This class represents a user on a CloudDatabaseInstance. It is not
    a true cloud entity, but a convenience object for dealing with users
    for instances.
    """
    get_details = False
    name = None
    host = None

    def delete(self):
        """This class doesn't have an 'id', so pass the name."""
        self.manager.delete(self.name)


    def change_password(self, new_pass):
        """
        Changes the password for this user to the supplied value.

        Returns None upon success; raises PasswordChangeFailed if the call
        does not complete successfully.
        """
        self.manager.change_user_password(self, new_pass)


    def update(self, name=None, password=None, host=None):
        """
        Allows you to change one or more of the user's username, password, or
        host.
        """
        return self.manager.update(self, name=name, password=password,
                host=host)


    def list_user_access(self):
        """
        Returns a list of all database names for which the specified user
        has access rights.
        """
        return self.manager.list_user_access(self)


    def grant_user_access(self, db_names, strict=True):
        """
        Gives access to the databases listed in `db_names` to the user.
        """
        return self.manager.grant_user_access(self, db_names, strict=strict)


    def revoke_user_access(self, db_names, strict=True):
        """
        Revokes access to the databases listed in `db_names` for the user.
        """
        return self.manager.revoke_user_access(self, db_names, strict=strict)



class CloudDatabaseFlavor(BaseResource):
    """
    This class represents the available instance configurations, or 'flavors',
    which you use to define the memory and CPU size of your instance. These
    objects are read-only.
    """
    get_details = True
    _non_display = ["links"]



class CloudDatabaseBackup(BaseResource):
    """
    This class represents a database backup.
    """
    get_details = True
    _non_display = ["locationRef"]



class CloudDatabaseClient(BaseClient):
    """
    This is the primary class for interacting with Cloud Databases.
    """
    name = "Cloud Databases"

    def _configure_manager(self):
        """
        Creates a manager to handle the instances, and another
        to handle flavors.
        """
        self._manager = CloudDatabaseManager(self,
                resource_class=CloudDatabaseInstance, response_key="instance",
                uri_base="instances")
        self._flavor_manager = BaseManager(self,
                resource_class=CloudDatabaseFlavor, response_key="flavor",
                uri_base="flavors")
        self._backup_manager = CloudDatabaseBackupManager(self,
                resource_class=CloudDatabaseBackup, response_key="backup",
                uri_base="backups")


    @assure_instance
    def list_databases(self, instance, limit=None, marker=None):
        """Returns all databases for the specified instance."""
        return instance.list_databases(limit=limit, marker=marker)


    @assure_instance
    def create_database(self, instance, name, character_set=None,
            collate=None):
        """Creates a database with the specified name on the given instance."""
        return instance.create_database(name, character_set=character_set,
                collate=collate)


    @assure_instance
    def get_database(self, instance, name):
        """
        Finds the database in the given instance with the specified name, and
        returns a CloudDatabaseDatabase object. If no match is found, a
        NoSuchDatabase exception is raised.
        """
        return instance.get_database(name)


    @assure_instance
    def delete_database(self, instance, name):
        """Deletes the database by name on the given instance."""
        return instance.delete_database(name)


    @assure_instance
    def list_users(self, instance, limit=None, marker=None):
        """Returns all users for the specified instance."""
        return instance.list_users(limit=limit, marker=marker)


    @assure_instance
    def create_user(self, instance, name, password, database_names, host=None):
        """
        Creates a user with the specified name and password, and gives that
        user access to the specified database(s).
        """
        return instance.create_user(name=name, password=password,
                database_names=database_names, host=host)


    @assure_instance
    def get_user(self, instance, name):
        """
        Finds the user in the given instance with the specified name, and
        returns a CloudDatabaseUser object. If no match is found, a
        NoSuchUser exception is raised.
        """
        return instance.get_user(name)


    @assure_instance
    def delete_user(self, instance, name):
        """Deletes the user by name on the given instance."""
        return instance.delete_user(name)


    @assure_instance
    def change_user_password(self, instance, user, new_pass):
        """
        Changes the password for the user of the specified instance to the
        supplied value.

        Returns None upon success; raises PasswordChangeFailed if the call
        does not complete successfully.
        """
        return instance.change_user_password(user, new_pass)


    @assure_instance
    def update_user(self, instance, user, name=None, password=None, host=None):
        """
        Allows you to change one or more of the user's username, password, or
        host.
        """
        return instance.update_user(user, name=name, password=password,
                host=host)


    @assure_instance
    def list_user_access(self, instance, user):
        """
        Returns a list of all database names for which the specified user
        has access rights on the specified instance.
        """
        return instance.list_user_access(user)


    @assure_instance
    def grant_user_access(self, instance, user, db_names, strict=True):
        """
        Gives access to the databases listed in `db_names` to the user
        on the specified instance.
        """
        return instance.grant_user_access(user, db_names, strict=strict)


    @assure_instance
    def revoke_user_access(self, instance, user, db_names, strict=True):
        """
        Revokes access to the databases listed in `db_names` for the user
        on the specified instance.
        """
        return instance.revoke_user_access(user, db_names, strict=strict)


    @assure_instance
    def enable_root_user(self, instance):
        """
        This enables login from any host for the root user and provides
        the user with a generated root password.
        """
        return instance.enable_root_user()


    @assure_instance
    def root_user_status(self, instance):
        """Returns True if the given instance is root-enabled."""
        return instance.root_user_status()


    @assure_instance
    def restart(self, instance):
        """Restarts the instance."""
        return instance.restart()


    @assure_instance
    def resize(self, instance, flavor):
        """Sets the size of the instance to a different flavor."""
        return instance.resize(flavor)


    def get_limits(self):
        """Not implemented in Cloud Databases."""
        raise NotImplementedError("Limits are not available for Cloud Databases")


    def list_flavors(self, limit=None, marker=None):
        """Returns a list of all available Flavors."""
        return self._flavor_manager.list(limit=limit, marker=marker)


    def get_flavor(self, flavor_id):
        """Returns a specific Flavor object by ID."""
        return self._flavor_manager.get(flavor_id)


    def _get_flavor_ref(self, flavor):
        """
        Flavors are odd in that the API expects an href link, not an ID, as with
        nearly every other resource. This method takes either a
        CloudDatabaseFlavor object, a flavor ID, a RAM size, or a flavor name,
        and uses that to determine the appropriate href.
        """
        flavor_obj = None
        if isinstance(flavor, CloudDatabaseFlavor):
            flavor_obj = flavor
        elif isinstance(flavor, int):
            # They passed an ID or a size
            try:
                flavor_obj = self.get_flavor(flavor)
            except exc.NotFound:
                # Must be either a size or bad ID, which will
                # be handled below
                pass
        if flavor_obj is None:
            # Try flavor name
            flavors = self.list_flavors()
            try:
                flavor_obj = [flav for flav in flavors
                        if flav.name == flavor][0]
            except IndexError:
                # No such name; try matching RAM
                try:
                    flavor_obj = [flav for flav in flavors
                            if flav.ram == flavor][0]
                except IndexError:
                    raise exc.FlavorNotFound("Could not determine flavor from "
                            "'%s'." % flavor)
        # OK, we have a Flavor object. Get the href
        href = [link["href"] for link in flavor_obj.links
                if link["rel"] == "self"][0]
        return href


    def list_backups(self, instance=None):
        """
        Returns a list of all backups by default, or just for a particular
        instance.
        """
        return self._backup_manager.list(instance=instance)


    def get_backup(self, backup):
        """
        Returns the CloudDatabaseBackup instance for a given ID.
        """
        return self._backup_manager.get(backup)


    def delete_backup(self, backup):
        """
        Deletes the CloudDatabaseBackup instance for a given ID.
        """
        return self._backup_manager.delete(backup)


    @assure_instance
    def create_backup(self, instance, name, description=None):
        """
        Creates a backup of the specified instance, giving it the specified
        name along with an optional description.
        """
        return instance.create_backup(name, description=description)


    def restore_backup(self, backup, name, flavor, volume):
        """
        Restores a backup to a new database instance. You must supply a backup
        (either the ID or a CloudDatabaseBackup object), a name for the new
        instance, as well as a flavor and size (in GB) for the instance.
        """
        return self._manager.restore_backup(backup, name, flavor, volume)

########NEW FILE########
__FILENAME__ = clouddns
#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from functools import wraps
import json
import re
import time

import six

import pyrax
from pyrax.client import BaseClient
from pyrax.cloudloadbalancers import CloudLoadBalancer
import pyrax.exceptions as exc
from pyrax.manager import BaseManager
from pyrax.resource import BaseResource
import pyrax.utils as utils

# How long (in seconds) to wait for a response from async operations
DEFAULT_TIMEOUT = 5
# How long (in seconds) to wait in between checks for async completion
DEFAULT_DELAY = 0.5
# How many times to retry a GET before raising an error
DEFAULT_RETRY = 3


def assure_domain(fnc):
    @wraps(fnc)
    def _wrapped(self, domain, *args, **kwargs):
        if not isinstance(domain, CloudDNSDomain):
            # Must be the ID or name. Try ID first:
            try:
                domain = self._manager.get(domain)
            except exc.NotFound:
                domain = self._manager.find(name=domain)
        return fnc(self, domain, *args, **kwargs)
    return _wrapped



class CloudDNSRecord(BaseResource):
    """
    This class represents a domain record.
    """
    GET_DETAILS = False
    # Initialize the supported attributes.
    type = None
    name = None
    data = None
    priority = None
    ttl = None
    comment = None


    def update(self, data=None, priority=None, ttl=None, comment=None):
        """
        Modifies this record.
        """
        return self.manager.update_record(self.domain_id, self, data=data,
                priority=priority, ttl=ttl, comment=comment)


    def get(self):
        """
        Gets the full information for an existing record for this domain.
        """
        return self.manager.get_record(self.domain_id, self)


    def delete(self):
        """
        Deletes an existing record for this domain.
        """
        return self.manager.delete_record(self.domain_id, self)



class CloudDNSDomain(BaseResource):
    """
    This class represents a DNS domain.
    """
    def delete(self, delete_subdomains=False):
        """
        Deletes this domain and all of its resource records. If this domain has
        subdomains, each subdomain will now become a root domain. If you wish to
        also delete any subdomains, pass True to 'delete_subdomains'.
        """
        self.manager.delete(self, delete_subdomains=delete_subdomains)


    def changes_since(self, date_or_datetime):
        """
        Gets the changes for this domain since the specified date/datetime.
        The date can be one of:
            - a Python datetime object
            - a Python date object
            - a string in the format 'YYYY-MM-YY HH:MM:SS'
            - a string in the format 'YYYY-MM-YY'

        It returns a list of dicts, whose keys depend on the specific change
        that was made. A simple example of such a change dict:

            {u'accountId': 000000,
             u'action': u'update',
             u'changeDetails': [{u'field': u'serial_number',
               u'newValue': u'1354038941',
               u'originalValue': u'1354038940'},
              {u'field': u'updated_at',
               u'newValue': u'Tue Nov 27 17:55:41 UTC 2012',
               u'originalValue': u'Tue Nov 27 17:55:40 UTC 2012'}],
             u'domain': u'example.com',
             u'targetId': 00000000,
             u'targetType': u'Domain'}
        """
        return self.manager.changes_since(self, date_or_datetime)


    def export(self):
        """
        Provides the BIND (Berkeley Internet Name Domain) 9 formatted contents
        of the requested domain. This call is for a single domain only, and as such,
        does not provide subdomain information.

        Sample export:
            {u'accountId': 000000,
             u'contentType': u'BIND_9',
             u'contents': u'example.com.\t3600\tIN\tSOA\tns.rackspace.com. '
                'foo@example.com. 1354202974 21600 3600 1814400 500'
                'example.com.\t3600\tIN\tNS\tdns1.stabletransit.com.'
                'example.com.\t3600\tIN\tNS\tdns2.stabletransit.com.',
             u'id': 1111111}
        """
        return self.manager.export_domain(self)


    def update(self, emailAddress=None, ttl=None, comment=None):
        """
        Provides a way to modify the following attributes of a domain
        entry:
            - email address
            - ttl setting
            - comment
        """
        return self.manager.update_domain(self, emailAddress=emailAddress,
                ttl=ttl, comment=comment)


    def list_subdomains(self, limit=None, offset=None):
        """
        Returns a list of all subdomains for this domain.
        """
        return self.manager.list_subdomains(self, limit=limit, offset=offset)


    def list_records(self, limit=None, offset=None):
        """
        Returns a list of all records configured for this domain.
        """
        return self.manager.list_records(self, limit=limit, offset=offset)


    def search_records(self, record_type, name=None, data=None):
        """
        Returns a list of all records configured for this domain that match
        the supplied search criteria.
        """
        return self.manager.search_records(self, record_type=record_type,
                name=name, data=data)


    def find_record(self, record_type, name=None, data=None):
        """
        Returns a single record for this domain that matches the supplied
        search criteria.

        If no record matches, a DomainRecordNotFound exception will be raised.
        If more than one matches, a DomainRecordNotUnique exception will
        be raised.
        """
        matches = self.manager.search_records(self, record_type=record_type,
                name=name, data=data)
        if not matches:
            raise exc.DomainRecordNotFound
        elif len(matches) > 1:
            raise exc.DomainRecordNotUnique
        return matches[0]


    def add_records(self, records):
        """
        Adds the records to this domain. Each record should be a dict with the
        following keys:
            - type (required)
            - name (required)
            - data (required)
            - ttl (optional)
            - comment (optional)
            - priority (required for MX and SRV records; forbidden otherwise)
        """
        return self.manager.add_records(self, records)

    # Create an alias, so that adding a single record is more intuitive
    add_record = add_records


    def get_record(self, record):
        """
        Gets the full information for an existing record for this domain.
        """
        return self.manager.get_record(self, record)


    def update_record(self, record, data=None, priority=None,
            ttl=None, comment=None):
        """
        Modifies an existing record for this domain.
        """
        return self.manager.update_record(self, record, data=data,
                priority=priority, ttl=ttl, comment=comment)


    def delete_record(self, record):
        """
        Deletes an existing record for this domain.
        """
        return self.manager.delete_record(self, record)


class CloudDNSPTRRecord(object):
    """
    This represents a Cloud DNS PTR record (reverse DNS).
    """
    def __init__(self, data=None, device=None):
        self.type = self.id = self.data = self.name = None
        self.ttl = self.comment = None
        if data:
            for key, val in data.items():
                setattr(self, key, val)
        self.device = device


    def delete(self):
        """
        Deletes this PTR record from its device.
        """
        return pyrax.cloud_dns.delete_ptr_records(self.device, self.data)


    def __repr__(self):
        reprkeys = ("id", "data", "name", "ttl")
        info = ", ".join("%s=%s" % (key, getattr(self, key)) for key in reprkeys)
        return "<%s %s>" % (self.__class__.__name__, info)



class CloudDNSManager(BaseManager):
    def __init__(self, api, resource_class=None, response_key=None,
            plural_response_key=None, uri_base=None):
        super(CloudDNSManager, self).__init__(api, resource_class=resource_class,
                response_key=response_key, plural_response_key=plural_response_key,
                uri_base=uri_base)
        self._paging = {"domain": {}, "subdomain": {}, "record": {}}
        self._reset_paging(service="all")
        self._timeout = DEFAULT_TIMEOUT
        self._delay = DEFAULT_DELAY


    def _create_body(self, name, emailAddress, ttl=3600, comment=None,
            subdomains=None, records=None):
        """
        Creates the appropriate dict for creating a new domain.
        """
        if subdomains is None:
            subdomains = []
        if records is None:
            records = []
        body = {"domains": [{
                "name": name,
                "emailAddress": emailAddress,
                "ttl": ttl,
                "comment": comment,
                "subdomains": {
                    "domains": subdomains
                    },
                "recordsList": {
                    "records": records
                    },
                }]}
        return body


    def _set_timeout(self, timeout):
        """
        Changes the duration for which the program will wait for a response from
        the DNS system. Setting the timeout to zero will make that program wait
        an indefinite amount of time.
        """
        self._timeout = timeout


    def _set_delay(self, delay):
        """
        Changes the interval that the program will pause in between attempts to
        see if a request has completed.
        """
        self._delay = delay


    def _reset_paging(self, service, body=None):
        """
        Resets the internal attributes when there is no current paging request.
        """
        if service == "all":
            for svc in self._paging.keys():
                svc_dct = self._paging[svc]
                svc_dct["next_uri"] = svc_dct["prev_uri"] = None
                svc_dct["total_entries"] = None
            return
        svc_dct = self._paging[service]
        svc_dct["next_uri"] = svc_dct["prev_uri"] = None
        svc_dct["total_entries"] = None
        if not body:
            return
        svc_dct["total_entries"] = body.get("totalEntries")
        links = body.get("links")
        uri_base = self.uri_base
        if links:
            for link in links:
                href = link["href"]
                pos = href.index(uri_base)
                page_uri = href[pos - 1:]
                if link["rel"] == "next":
                    svc_dct["next_uri"] = page_uri
                elif link["rel"] == "previous":
                    svc_dct["prev_uri"] = page_uri


    def _get_pagination_qs(self, limit, offset):
        pagination_items = []
        if limit is not None:
            pagination_items.append("limit=%s" % limit)
        if offset is not None:
            pagination_items.append("offset=%s" % offset)
        qs = "&".join(pagination_items)
        qs = "?%s" % qs if qs else ""
        return qs


    def list(self, limit=None, offset=None):
        """Gets a list of all domains, or optionally a page of domains."""
        uri = "/%s%s" % (self.uri_base, self._get_pagination_qs(limit, offset))
        return self._list(uri)


    def _list(self, uri, obj_class=None, list_all=False):
        """
        Handles the communication with the API when getting
        a full listing of the resources managed by this class.
        """
        resp, resp_body = self._retry_get(uri)
        if obj_class is None:
            obj_class = self.resource_class

        data = resp_body[self.plural_response_key]
        ret = [obj_class(self, res, loaded=False)
                for res in data if res]
        self._reset_paging("domain", resp_body)
        if list_all:
            dom_paging = self._paging.get("domain", {})
            while dom_paging.get("next_uri"):
                next_uri = dom_paging.get("next_uri")
                ret.extend(self._list(uri=next_uri, obj_class=obj_class,
                        list_all=False))
        return ret


    def list_previous_page(self):
        """
        When paging through results, this will return the previous page, using
        the same limit. If there are no more results, a NoMoreResults exception
        will be raised.
        """
        uri = self._paging.get("domain", {}).get("prev_uri")
        if uri is None:
            raise exc.NoMoreResults("There are no previous pages of domains "
                    "to list.")
        return self._list(uri)


    def list_next_page(self):
        """
        When paging through results, this will return the next page, using the
        same limit. If there are no more results, a NoMoreResults exception
        will be raised.
        """
        uri = self._paging.get("domain", {}).get("next_uri")
        if uri is None:
            raise exc.NoMoreResults("There are no more pages of domains to "
                    "list.")
        return self._list(uri)


    def _get(self, uri):
        """
        Handles the communication with the API when getting
        a specific resource managed by this class.

        Because DNS returns a different format for the body,
        the BaseManager method must be overridden here.
        """
        uri = "%s?showRecords=false&showSubdomains=false" % uri
        resp, body = self._retry_get(uri)
        body["records"] = []
        return self.resource_class(self, body, loaded=True)

    def _retry_get(self, uri):
        """
        Handles GET calls to the Cloud DNS API in order to retry on empty
        body responses.
        """
        for i in six.moves.range(DEFAULT_RETRY):
            resp, body = self.api.method_get(uri)
            if body:
                return resp, body
        # Tried too many times
        raise exc.ServiceResponseFailure("The Cloud DNS service failed to "
                "respond to the request.")

    def _async_call(self, uri, body=None, method="GET", error_class=None,
            has_response=True, *args, **kwargs):
        """
        Handles asynchronous call/responses for the DNS API.

        Returns the response headers and body if the call was successful.
        If an error status is returned, and the 'error_class' parameter is
        specified, that class of error will be raised with the details from
        the response. If no error class is specified, the response headers
        and body will be returned to the calling method, which will have
        to handle the result.
        """
        api_methods = {
                "GET": self._retry_get,
                "POST": self.api.method_post,
                "PUT": self.api.method_put,
                "DELETE": self.api.method_delete,
                }
        api_method = api_methods[method]
        if body is None:
            resp, resp_body = api_method(uri, *args, **kwargs)
        else:
            resp, resp_body = api_method(uri, body=body, *args, **kwargs)
        callbackURL = resp_body["callbackUrl"].split("/status/")[-1]
        massagedURL = "/status/%s?showDetails=true" % callbackURL
        start = time.time()
        timed_out = False
        while (resp_body["status"] == "RUNNING") and not timed_out:
            resp_body = None
            while resp_body is None and not timed_out:
                resp, resp_body = self._retry_get(massagedURL)
                if self._timeout:
                    timed_out = ((time.time() - start) > self._timeout)
                    time.sleep(self._delay)

        if timed_out:
            raise exc.DNSCallTimedOut("The API call to '%s' did not complete "
                    "after %s seconds." % (uri, self._timeout))
        if error_class and (resp_body["status"] == "ERROR"):
            # This call will handle raising the error.
            self._process_async_error(resp_body, error_class)
        if has_response:
            ret = resp, resp_body["response"]
        else:
            ret = resp, resp_body
        try:
            resp_body = json.loads(resp_body)
        except Exception:
            pass
        return ret


    def _process_async_error(self, resp_body, error_class):
        """
        The DNS API does not return a consistent format for their error
        messages. This abstracts out the differences in order to present
        a single unified message in the exception to be raised.
        """
        def _fmt_error(err):
            # Remove the cumbersome Java-esque message
            details = err.get("details", "").replace("\n", " ")
            if not details:
                details = err.get("message", "")
            return "%s (%s)" % (details, err.get("code", ""))

        error = resp_body.get("error", "")
        if "failedItems" in error:
            # Multi-error response
            faults = error.get("failedItems", {}).get("faults", [])
            msgs = [_fmt_error(fault) for fault in faults]
            msg = "\n".join(msgs)
        else:
            msg = _fmt_error(error)
        raise error_class(msg)


    def _create(self, uri, body, records=None, subdomains=None,
            return_none=False, return_raw=False, **kwargs):
        """
        Handles the communication with the API when creating a new
        resource managed by this class.

        Since DNS works completely differently for create() than the other
        APIs, this method overrides the default BaseManager behavior.

        If 'records' are supplied, they should be a list of dicts. Each
        record dict should have the following format:

            {"name": "example.com",
            "type": "A",
            "data": "192.0.2.17",
            "ttl": 86400}

        If 'subdomains' are supplied, they should be a list of dicts. Each
        subdomain dict should have the following format:

            {"name": "sub1.example.com",
             "comment": "1st sample subdomain",
             "emailAddress": "sample@rackspace.com"}
        """
        self.run_hooks("modify_body_for_create", body, **kwargs)
        resp, resp_body = self._async_call(uri, body=body, method="POST",
                error_class=exc.DomainCreationFailed)
        response_body = resp_body[self.response_key][0]
        return self.resource_class(self, response_body)


    def delete(self, domain, delete_subdomains=False):
        """
        Deletes the specified domain and all of its resource records. If the
        domain has subdomains, each subdomain will now become a root domain. If
        you wish to also delete any subdomains, pass True to 'delete_subdomains'.
        """
        uri = "/%s/%s" % (self.uri_base, utils.get_id(domain))
        if delete_subdomains:
            uri = "%s?deleteSubdomains=true" % uri
        resp, resp_body = self._async_call(uri, method="DELETE",
                error_class=exc.DomainDeletionFailed, has_response=False)


    def findall(self, **kwargs):
        """
        Finds all items with attributes matching ``**kwargs``.

        Normally this isn't very efficient, since the default action is to
        load the entire list and then filter on the Python side, but the DNS
        API provides a more efficient search option when filtering on name.
        So if the filter is on name, use that; otherwise, use the default.
        """
        if (len(kwargs) == 1) and ("name" in kwargs):
            # Filtering on name; use the more efficient method.
            nm = kwargs["name"].lower()
            uri = "/%s?name=%s" % (self.uri_base, nm)
            matches = self._list(uri, list_all=True)
            return [match for match in matches
                if match.name.lower() == nm]
        else:
            return super(CloudDNSManager, self).findall(**kwargs)


    def changes_since(self, domain, date_or_datetime):
        """
        Gets the changes for a domain since the specified date/datetime.
        The date can be one of:
            - a Python datetime object
            - a Python date object
            - a string in the format 'YYYY-MM-YY HH:MM:SS'
            - a string in the format 'YYYY-MM-YY'

        It returns a list of dicts, whose keys depend on the specific change
        that was made. A simple example of such a change dict:

            {u'accountId': 000000,
             u'action': u'update',
             u'changeDetails': [{u'field': u'serial_number',
               u'newValue': u'1354038941',
               u'originalValue': u'1354038940'},
              {u'field': u'updated_at',
               u'newValue': u'Tue Nov 27 17:55:41 UTC 2012',
               u'originalValue': u'Tue Nov 27 17:55:40 UTC 2012'}],
             u'domain': u'example.com',
             u'targetId': 00000000,
             u'targetType': u'Domain'}
        """
        domain_id = utils.get_id(domain)
        dt = utils.iso_time_string(date_or_datetime, show_tzinfo=True)
        uri = "/domains/%s/changes?since=%s" % (domain_id, dt)
        resp, body = self._retry_get(uri)
        return body.get("changes", [])


    def export_domain(self, domain):
        """
        Provides the BIND (Berkeley Internet Name Domain) 9 formatted contents
        of the requested domain. This call is for a single domain only, and as
        such, does not provide subdomain information.

        Sample export:
            {u'accountId': 000000,
             u'contentType': u'BIND_9',
             u'contents': u'example.com.\t3600\tIN\tSOA\tns.rackspace.com. '
                'foo@example.com. 1354202974 21600 3600 1814400 500'
                'example.com.\t3600\tIN\tNS\tdns1.stabletransit.com.'
                'example.com.\t3600\tIN\tNS\tdns2.stabletransit.com.',
             u'id': 1111111}
        """
        uri = "/domains/%s/export" % utils.get_id(domain)
        resp, resp_body = self._async_call(uri, method="GET",
                error_class=exc.NotFound)
        return resp_body.get("contents", "")


    def import_domain(self, domain_data):
        """
        Takes a string in the BIND 9 format and creates a new domain. See the
        'export_domain()' method for a description of the format.
        """
        uri = "/domains/import"
        body = {"domains": [{
                "contentType": "BIND_9",
                "contents": domain_data,
                }]}
        resp, resp_body = self._async_call(uri, method="POST", body=body,
                error_class=exc.DomainCreationFailed)
        return resp_body


    def update_domain(self, domain, emailAddress=None, ttl=None, comment=None):
        """
        Provides a way to modify the following attributes of a domain
        record:
            - email address
            - ttl setting
            - comment
        """
        if not any((emailAddress, ttl, comment)):
            raise exc.MissingDNSSettings(
                    "No settings provided to update_domain().")
        uri = "/domains/%s" % utils.get_id(domain)
        body = {"comment": comment,
                "ttl": ttl,
                "emailAddress": emailAddress,
                }
        none_keys = [key for key, val in body.items()
                if val is None]
        for none_key in none_keys:
            body.pop(none_key)
        resp, resp_body = self._async_call(uri, method="PUT", body=body,
                error_class=exc.DomainUpdateFailed, has_response=False)
        return resp_body


    def list_subdomains(self, domain, limit=None, offset=None):
        """
        Returns a list of all subdomains of the specified domain.
        """
        # The commented-out uri is the official API, but it is
        # horribly slow.
#        uri = "/domains/%s/subdomains" % utils.get_id(domain)
        uri = "/domains?name=%s" % domain.name
        page_qs = self._get_pagination_qs(limit, offset)
        if page_qs:
            uri = "%s&%s" % (uri, page_qs[1:])
        return self._list_subdomains(uri, domain.id)


    def _list_subdomains(self, uri, domain_id):
        resp, body = self._retry_get(uri)
        self._reset_paging("subdomain", body)
        subdomains = body.get("domains", [])
        return [CloudDNSDomain(self, subdomain, loaded=False)
                for subdomain in subdomains
                if subdomain["id"] != domain_id]


    def list_subdomains_previous_page(self):
        """
        When paging through subdomain results, this will return the previous
        page, using the same limit. If there are no more results, a
        NoMoreResults exception will be raised.
        """
        uri = self._paging.get("subdomain", {}).get("prev_uri")
        if uri is None:
            raise exc.NoMoreResults("There are no previous pages of subdomains "
                    "to list.")
        return self._list_subdomains(uri)


    def list_subdomains_next_page(self):
        """
        When paging through subdomain results, this will return the next page,
        using the same limit. If there are no more results, a NoMoreResults
        exception will be raised.
        """
        uri = self._paging.get("subdomain", {}).get("next_uri")
        if uri is None:
            raise exc.NoMoreResults("There are no more pages of subdomains "
                    "to list.")
        return self._list_subdomains(uri)


    def list_records(self, domain, limit=None, offset=None):
        """
        Returns a list of all records configured for the specified domain.
        """
        uri = "/domains/%s/records%s" % (utils.get_id(domain),
                self._get_pagination_qs(limit, offset))
        return self._list_records(uri)


    def _list_records(self, uri):
        resp, body = self._retry_get(uri)
        self._reset_paging("record", body)
        # The domain ID will be in the URL
        pat = "domains/([^/]+)/records"
        mtch = re.search(pat, uri)
        dom_id = mtch.groups()[0]
        records = body.get("records", [])
        for record in records:
            record["domain_id"] = dom_id
        return [CloudDNSRecord(self, record, loaded=False)
                for record in records if record]


    def list_records_previous_page(self):
        """
        When paging through record results, this will return the previous page,
        using the same limit. If there are no more results, a NoMoreResults
        exception will be raised.
        """
        uri = self._paging.get("record", {}).get("prev_uri")
        if uri is None:
            raise exc.NoMoreResults("There are no previous pages of records "
                    "to list.")
        return self._list_records(uri)


    def list_records_next_page(self):
        """
        When paging through record results, this will return the next page,
        using the same limit. If there are no more results, a NoMoreResults
        exception will be raised.
        """
        uri = self._paging.get("record", {}).get("next_uri")
        if uri is None:
            raise exc.NoMoreResults("There are no more pages of records to list.")
        return self._list_records(uri)


    def search_records(self, domain, record_type, name=None, data=None):
        """
        Returns a list of all records configured for the specified domain that
        match the supplied search criteria.
        """
        search_params = []
        if name:
            search_params.append("name=%s" % name)
        if data:
            search_params.append("data=%s" % data)
        query_string = "&".join(search_params)
        dom_id = utils.get_id(domain)
        uri = "/domains/%s/records?type=%s" % (dom_id, record_type)
        if query_string:
            uri = "%s&%s" % (uri, query_string)
        resp, body = self._retry_get(uri)
        records = body.get("records", [])
        self._reset_paging("record", body)
        rec_paging = self._paging.get("record", {})
        while rec_paging.get("next_uri"):
            resp, body = self._retry_get(rec_paging.get("next_uri"))
            self._reset_paging("record", body)
            records.extend(body.get("records", []))
        for record in records:
            record["domain_id"] = dom_id
        return [CloudDNSRecord(self, record, loaded=False)
                for record in records if record]


    def add_records(self, domain, records):
        """
        Adds the records to this domain. Each record should be a dict with the
        following keys:
            - type (required)
            - name (required)
            - data (required)
            - ttl (optional)
            - comment (optional)
            - priority (required for MX and SRV records; forbidden otherwise)
        """
        if isinstance(records, dict):
            # Single record passed
            records = [records]
        dom_id = utils.get_id(domain)
        uri = "/domains/%s/records" % dom_id
        body = {"records": records}
        resp, resp_body = self._async_call(uri, method="POST", body=body,
                error_class=exc.DomainRecordAdditionFailed, has_response=False)
        records = resp_body.get("response", {}).get("records", [])
        for record in records:
            record["domain_id"] = dom_id
        return [CloudDNSRecord(self, record, loaded=False)
                for record in records if record]


    def get_record(self, domain, record):
        """
        Gets the full information for an existing record for this domain.
        """
        rec_id = utils.get_id(record)
        domain_id = utils.get_id(domain)
        uri = "/domains/%s/records/%s" % (domain_id, rec_id)
        resp, resp_body = self._retry_get(uri)
        resp_body['domain_id'] = domain_id
        return CloudDNSRecord(self, resp_body, loaded=False)


    def update_record(self, domain, record, data=None, priority=None,
            ttl=None, comment=None):
        """
        Modifies an existing record for a domain.
        """
        rec_id = utils.get_id(record)
        uri = "/domains/%s/records/%s" % (utils.get_id(domain), rec_id)
        body = {"name": record.name}
        all_opts = (("data", data), ("priority", priority), ("ttl", ttl),
                ("comment", comment))
        opts = [(k, v) for k, v in all_opts if v is not None]
        body.update(dict(opts))
        resp, resp_body = self._async_call(uri, method="PUT", body=body,
                error_class=exc.DomainRecordUpdateFailed, has_response=False)
        return resp_body


    def delete_record(self, domain, record):
        """
        Deletes an existing record for a domain.
        """
        uri = "/domains/%s/records/%s" % (utils.get_id(domain),
                utils.get_id(record))
        resp, resp_body = self._async_call(uri, method="DELETE",
                error_class=exc.DomainRecordDeletionFailed, has_response=False)
        return resp_body


    def _get_ptr_details(self, device, device_type):
        """
        Takes a device and device type and returns the corresponding HREF link
        and service name for use with PTR record management.
        """
        if device_type.lower().startswith("load"):
            ep = pyrax._get_service_endpoint("load_balancer")
            svc = "loadbalancers"
            svc_name = "cloudLoadBalancers"
        else:
            ep = pyrax._get_service_endpoint("compute")
            svc = "servers"
            svc_name = "cloudServersOpenStack"
        href = "%s/%s/%s" % (ep, svc, utils.get_id(device))
        return (href, svc_name)


    def _resolve_device_type(self, device):
        """
        Given a device, determines if it is a CloudServer, a CloudLoadBalancer,
        or an invalid device.
        """
        try:
            from tests.unit import fakes
            server_types = (pyrax.CloudServer, fakes.FakeServer)
            lb_types = (CloudLoadBalancer, fakes.FakeLoadBalancer,
                    fakes.FakeDNSDevice)
        except ImportError:
            # Not running with tests
            server_types = (pyrax.CloudServer, )
            lb_types = (CloudLoadBalancer, )
        if isinstance(device, server_types):
            device_type = "server"
        elif isinstance(device, lb_types):
            device_type = "loadbalancer"
        else:
            raise exc.InvalidDeviceType("The device '%s' must be a CloudServer "
                    "or a CloudLoadBalancer." % device)
        return device_type


    def list_ptr_records(self, device):
        """
        Returns a list of all PTR records configured for this device.
        """
        device_type = self._resolve_device_type(device)
        href, svc_name = self._get_ptr_details(device, device_type)
        uri = "/rdns/%s?href=%s" % (svc_name, href)
        try:
            resp, resp_body = self._retry_get(uri)
        except exc.NotFound:
            return []
        records = [CloudDNSPTRRecord(rec, device)
                for rec in resp_body.get("records", [])]
        return records


    def add_ptr_records(self, device, records):
        """
        Adds one or more PTR records to the specified device.
        """
        device_type = self._resolve_device_type(device)
        href, svc_name = self._get_ptr_details(device, device_type)
        if not isinstance(records, (list, tuple)):
            records = [records]
        body = {"recordsList": {
                    "records": records},
                "link": {
                    "content": "",
                    "href": href,
                    "rel": svc_name,
                }}
        uri = "/rdns"
        # This is a necessary hack, so here's why: if you attempt to add
        # PTR records to device, and you don't have rights to either the device
        # or the IP address, the DNS API will return a 401 - Unauthorized.
        # Unfortunately, the pyrax client interprets this as a bad auth token,
        # and there is no way to distinguish this from an actual authentication
        # failure. The client will attempt to re-authenticate as a result, and
        # will fail, due to the DNS API not having regional endpoints. The net
        # result is that an EndpointNotFound exception will be raised, which
        # we catch here and then raise a more meaningful exception.
        # The Rackspace DNS team is working on changing this to return a 403
        # instead; when that happens this kludge can go away.
        try:
            resp, resp_body = self._async_call(uri, body=body, method="POST",
                    error_class=exc.PTRRecordCreationFailed)
        except exc.EndpointNotFound:
            raise exc.InvalidPTRRecord("The domain/IP address information is not "
                    "valid for this device.")
        return resp_body.get("records")
        records = [CloudDNSPTRRecord(rec, device)
                for rec in resp_body.get("records", [])]
        return records


    def update_ptr_record(self, device, record, domain_name, data=None,
            ttl=None, comment=None):
        """
        Updates a PTR record with the supplied values.
        """
        device_type = self._resolve_device_type(device)
        href, svc_name = self._get_ptr_details(device, device_type)
        try:
            rec_id = record.id
        except AttributeError:
            rec_id = record
        rec = {"name": domain_name,
              "id": rec_id,
              "type": "PTR",
              "data": data,
            }
        if ttl is not None:
            # Minimum TTL is 300 seconds
            rec["ttl"] = max(300, ttl)
        if comment is not None:
            # Maximum comment length is 160 chars
            rec["comment"] = comment[:160]
        body = {"recordsList": {
                    "records": [rec]},
                "link": {
                    "content": "",
                    "href": href,
                    "rel": svc_name,
                }}
        uri = "/rdns"
        try:
            resp, resp_body = self._async_call(uri, body=body, method="PUT",
                    has_response=False, error_class=exc.PTRRecordUpdateFailed)
        except exc.EndpointNotFound as e:
            raise exc.InvalidPTRRecord("The record domain/IP address "
                    "information is not valid for this device.")
        return resp_body.get("status") == "COMPLETED"


    def delete_ptr_records(self, device, ip_address=None):
        """
        Deletes the PTR records for the specified device. If 'ip_address' is
        supplied, only the PTR records with that IP address will be deleted.
        """
        device_type = self._resolve_device_type(device)
        href, svc_name = self._get_ptr_details(device, device_type)
        uri = "/rdns/%s?href=%s" % (svc_name, href)
        if ip_address:
            uri = "%s&ip=%s" % (uri, ip_address)
        resp, resp_body = self._async_call(uri, method="DELETE",
                has_response=False,
                error_class=exc.PTRRecordDeletionFailed)
        return resp_body.get("status") == "COMPLETED"



class CloudDNSClient(BaseClient):
    """
    This is the primary class for interacting with Cloud DNS.
    """
    name = "Cloud DNS"

    def _configure_manager(self):
        """
        Creates a manager to handle the instances, and another
        to handle flavors.
        """
        self._manager = CloudDNSManager(self, resource_class=CloudDNSDomain,
                response_key="domains", plural_response_key="domains",
                uri_base="domains")

    def method_get(self, uri, **kwargs):
        """
        Overload the method_get function in order to retry on empty body
        responses from the Cloud DNS API
        """
        for i in six.moves.range(3):
            resp, body = super(CloudDNSClient, self).method_get(uri, **kwargs)
            if body:
                return resp, body
        raise exc.ServiceResponseFailure("The Cloud DNS service failed to "
                "respond to the request.")


    def set_timeout(self, timeout):
        """
        Sets the amount of time that calls will wait for a response from
        the DNS system before timing out. Setting the timeout to zero will
        cause execution to wait indefinitely until the call completes.
        """
        self._manager._set_timeout(timeout)


    def set_delay(self, delay):
        """
        Changes the interval that the program will pause in between attempts to
        see if a request has completed.
        """
        self._manager._set_delay(delay)


    def list(self, limit=None, offset=None):
        """Returns a list of all resources."""
        return self._manager.list(limit=limit, offset=offset)


    def list_previous_page(self):
        """Returns the previous page of results."""
        return self._manager.list_previous_page()


    def list_next_page(self):
        """Returns the next page of results."""
        return self._manager.list_next_page()


    def get_domain_iterator(self):
        """
        Returns an iterator that will return each available domain. If there are
        more than the limit of 100 domains, the iterator will continue to fetch
        domains from the API until all domains have been returned.
        """
        return DomainResultsIterator(self._manager)


    @assure_domain
    def changes_since(self, domain, date_or_datetime):
        """
        Gets the changes for a domain since the specified date/datetime.
        The date can be one of:
            - a Python datetime object
            - a Python date object
            - a string in the format 'YYYY-MM-YY HH:MM:SS'
            - a string in the format 'YYYY-MM-YY'

        It returns a list of dicts, whose keys depend on the specific change
        that was made. A simple example of such a change dict:

            {u'accountId': 000000,
             u'action': u'update',
             u'changeDetails': [{u'field': u'serial_number',
               u'newValue': u'1354038941',
               u'originalValue': u'1354038940'},
              {u'field': u'updated_at',
               u'newValue': u'Tue Nov 27 17:55:41 UTC 2012',
               u'originalValue': u'Tue Nov 27 17:55:40 UTC 2012'}],
             u'domain': u'example.com',
             u'targetId': 00000000,
             u'targetType': u'Domain'}
        """
        return domain.changes_since(date_or_datetime)


    @assure_domain
    def export_domain(self, domain):
        """
        Provides the BIND (Berkeley Internet Name Domain) 9 formatted contents
        of the requested domain. This call is for a single domain only, and as
        such, does not provide subdomain information.

        Sample export:

            {u'accountId': 000000,
             u'contentType': u'BIND_9',
             u'contents': u'example.com.\t3600\tIN\tSOA\tns.rackspace.com. '
                'foo@example.com. 1354202974 21600 3600 1814400 500'
                'example.com.\t3600\tIN\tNS\tdns1.stabletransit.com.'
                'example.com.\t3600\tIN\tNS\tdns2.stabletransit.com.',
             u'id': 1111111}
        """
        return domain.export()


    def import_domain(self, domain_data):
        """
        Takes a string in the BIND 9 format and creates a new domain. See the
        'export_domain()' method for a description of the format.
        """
        return self._manager.import_domain(domain_data)


    @assure_domain
    def update_domain(self, domain, emailAddress=None, ttl=None, comment=None):
        """
        Provides a way to modify the following attributes of a domain
        record:
            - email address
            - ttl setting
            - comment
        """
        return domain.update(emailAddress=emailAddress,
                ttl=ttl, comment=comment)


    @assure_domain
    def delete(self, domain, delete_subdomains=False):
        """
        Deletes the specified domain and all of its resource records. If the
        domain has subdomains, each subdomain will now become a root domain. If
        you wish to also delete any subdomains, pass True to 'delete_subdomains'.
        """
        domain.delete(delete_subdomains=delete_subdomains)


    @assure_domain
    def list_subdomains(self, domain, limit=None, offset=None):
        """
        Returns a list of all subdomains for the specified domain.
        """
        return domain.list_subdomains(limit=limit, offset=offset)


    def get_subdomain_iterator(self, domain, limit=None, offset=None):
        """
        Returns an iterator that will return each available subdomain for the
        specified domain. If there are more than the limit of 100 subdomains,
        the iterator will continue to fetch subdomains from the API until all
        subdomains have been returned.
        """
        return SubdomainResultsIterator(self._manager, domain=domain)


    def list_subdomains_previous_page(self):
        """Returns the previous page of subdomain results."""
        return self._manager.list_subdomains_previous_page()


    def list_subdomains_next_page(self):
        """Returns the next page of subdomain results."""
        return self._manager.list_subdomains_next_page()


    @assure_domain
    def list_records(self, domain, limit=None, offset=None):
        """
        Returns a list of all records configured for the specified domain.
        """
        return domain.list_records(limit=limit, offset=offset)


    def get_record_iterator(self, domain):
        """
        Returns an iterator that will return each available DNS record for the
        specified domain. If there are more than the limit of 100 records, the
        iterator will continue to fetch records from the API until all records
        have been returned.
        """
        return RecordResultsIterator(self._manager, domain=domain)


    def list_records_previous_page(self):
        """Returns the previous page of record results."""
        return self._manager.list_records_previous_page()


    def list_records_next_page(self):
        """Returns the next page of record results."""
        return self._manager.list_records_next_page()


    @assure_domain
    def search_records(self, domain, record_type, name=None, data=None):
        """
        Returns a list of all records configured for the specified domain
        that match the supplied search criteria.
        """
        return domain.search_records(record_type=record_type,
                name=name, data=data)


    @assure_domain
    def find_record(self, domain, record_type, name=None, data=None):
        """
        Returns a single record for this domain that matches the supplied
        search criteria.

        If no record matches, a DomainRecordNotFound exception will be raised.
        If more than one matches, a DomainRecordNotUnique exception will
        be raised.
        """
        return domain.find_record(record_type=record_type,
                name=name, data=data)


    @assure_domain
    def add_records(self, domain, records):
        """
        Adds the records to this domain. Each record should be a dict with the
        following keys:
            - type (required)
            - name (required)
            - data (required)
            - ttl (optional)
            - comment (optional)
            - priority (required for MX and SRV records; forbidden otherwise)
        """
        return domain.add_records(records)

    # Create an alias, so that adding a single record is more intuitive
    add_record = add_records


    @assure_domain
    def get_record(self, domain, record):
        """
        Gets the full information for an existing record or record ID for the
        specified domain.
        """
        return domain.get_record(record)


    @assure_domain
    def update_record(self, domain, record, data=None, priority=None,
            ttl=None, comment=None):
        """
        Modifies an existing record for a domain.
        """
        return domain.update_record(record, data=data,
                priority=priority, ttl=ttl, comment=comment)


    @assure_domain
    def delete_record(self, domain, record):
        """
        Deletes an existing record for this domain.
        """
        return domain.delete_record(record)


    def list_ptr_records(self, device):
        """
        Returns a list of all PTR records configured for this device.
        """
        return self._manager.list_ptr_records(device)


    def add_ptr_records(self, device, records):
        """
        Adds one or more PTR records to the specified device.
        """
        return self._manager.add_ptr_records(device, records)


    def update_ptr_record(self, device, record, domain_name, data=None,
            ttl=None, comment=None):
        """
        Updates a PTR record with the supplied values.
        """
        return self._manager.update_ptr_record(device, record, domain_name,
                data=data, ttl=ttl, comment=comment)


    def delete_ptr_records(self, device, ip_address=None):
        """
        Deletes the PTR records for the specified device. If 'ip_address'
        is supplied, only the PTR records with that IP address will be deleted.
        """
        return self._manager.delete_ptr_records(device, ip_address=ip_address)


    def get_absolute_limits(self):
        """
        Returns a dict with the absolute limits for the current account.
        """
        resp, body = self.method_get("/limits")
        absolute_limits = body.get("limits", {}).get("absolute")
        return absolute_limits


    def get_rate_limits(self):
        """
        Returns a dict with the current rate limit information for domain
        and status requests.
        """
        resp, body = self.method_get("/limits")
        rate_limits = body.get("limits", {}).get("rate")
        ret = []
        for rate_limit in rate_limits:
            limits = rate_limit["limit"]
            uri_limits = {"uri": rate_limit["uri"],
                    "limits": limits}
            ret.append(uri_limits)
        return ret



class ResultsIterator(object):
    """
    This object will iterate over all the results for a given
    type of listing, no matter how many items exist.

    This is an abstract class; subclasses must define the
    _init_methods() method.
    """
    def __init__(self, manager, domain=None):
        self.manager = manager
        self.domain = domain
        self.domain_id = utils.get_id(domain) if domain else None
        self.results = []
        self.next_uri = ""
        self.extra_args = tuple()
        self._init_methods()


    def _init_methods(self):
        """
        Must be implemented in subclasses.
        """
        raise NotImplementedError()


    def __iter__(self):
        return self


    def next(self):
        """
        Return the next available item. If there are no more items in the
        local 'results' list, check if there is a 'next_uri' value. If so,
        use that to get the next page of results from the API, and return
        the first item from that query.
        """
        try:
            return self.results.pop(0)
        except IndexError:
            if self.next_uri is None:
                raise StopIteration()
            else:
                if not self.next_uri:
                    if self.domain:
                        self.results = self.list_method(self.domain)
                    else:
                        self.results = self.list_method()
                else:
                    args = self.extra_args
                    self.results = self._list_method(self.next_uri, *args)
                self.next_uri = self.manager._paging.get(
                        self.paging_service, {}).get("next_uri")
        # We should have more results.
        try:
            return self.results.pop(0)
        except IndexError:
            raise StopIteration()


class DomainResultsIterator(ResultsIterator):
    """
    ResultsIterator subclass for iterating over all domains.
    """
    def _init_methods(self):
        self.list_method = self.manager.list
        self._list_method = self.manager._list
        self.paging_service = "domain"


class SubdomainResultsIterator(ResultsIterator):
    """
    ResultsIterator subclass for iterating over all subdomains.
    """
    def _init_methods(self):
        self.list_method = self.manager.list_subdomains
        self._list_method = self.manager._list_subdomains
        self.extra_args = (self.domain_id, )
        self.paging_service = "subdomain"


class RecordResultsIterator(ResultsIterator):
    """
    ResultsIterator subclass for iterating over all domain records.
    """
    def _init_methods(self):
        self.list_method = self.manager.list_records
        self._list_method = self.manager._list_records
        self.paging_service = "record"

########NEW FILE########
__FILENAME__ = cloudloadbalancers
#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from functools import wraps

import six

import pyrax
from pyrax.client import BaseClient
import pyrax.exceptions as exc
from pyrax.manager import BaseManager
from pyrax.resource import BaseResource
import pyrax.utils as utils


def assure_parent(fnc):
    @wraps(fnc)
    def wrapped(self, *args, **kwargs):
        lb = self.parent
        if not lb:
            exc_class = {Node: exc.UnattachedNode,
                    VirtualIP: exc.UnattachedVirtualIP}[self.__class__]
            raise exc_class("No parent Load Balancer for this node could "
                    "be determined.")
        return fnc(self, *args, **kwargs)
    return wrapped


def assure_loadbalancer(fnc):
    @wraps(fnc)
    def _wrapped(self, loadbalancer, *args, **kwargs):
        if not isinstance(loadbalancer, CloudLoadBalancer):
            # Must be the ID
            loadbalancer = self._manager.get(loadbalancer)
        return fnc(self, loadbalancer, *args, **kwargs)
    return _wrapped



class CloudLoadBalancer(BaseResource):
    """Represents a Cloud Load Balancer instance."""
    def __init__(self, *args, **kwargs):
        self._connection_logging = None
        self._content_caching = None
        self._session_persistence = None
        self._non_display = ["nodes", "virtual_ips"]
        super(CloudLoadBalancer, self).__init__(*args, **kwargs)


    def add_nodes(self, nodes):
        """Adds the nodes to this load balancer."""
        return self.manager.add_nodes(self, nodes)


    def add_virtualip(self, vip):
        """Adds the virtual IP to this load balancer."""
        return self.manager.add_virtualip(self, vip)


    def get_usage(self, start=None, end=None):
        """
        Return the usage records for this load balancer. You may optionally
        include a start datetime or an end datetime, or both, which will limit
        the records to those on or after the start time, and those before or on
        the end time. These times should be Python datetime.datetime objects,
        Python datetime.date objects, or strings in the format:
        "YYYY-MM-DD HH:MM:SS" or "YYYY-MM-DD".
        """
        return self.manager.get_usage(self, start=start, end=end)


    def _add_details(self, info):
        """Override the base behavior to add Nodes, VirtualIPs, etc."""
        for (key, val) in info.iteritems():
            if key == "nodes":
                val = [Node(parent=self, **nd) for nd in val]
            elif key == "sessionPersistence":
                val = val['persistenceType']
            elif key == "cluster":
                val = val['name']
            elif key == "virtualIps":
                key = "virtual_ips"
                val = [VirtualIP(parent=self, **vip) for vip in val]
            setattr(self, key, val)


    def update(self, name=None, algorithm=None, protocol=None, halfClosed=None,
            port=None, timeout=None, httpsRedirect=None):
        """
        Provides a way to modify the following attributes of a load balancer:
            - name
            - algorithm
            - protocol
            - halfClosed
            - port
            - timeout
            - httpsRedirect
        """
        return self.manager.update(self, name=name, algorithm=algorithm,
                protocol=protocol, halfClosed=halfClosed, port=port,
                timeout=timeout, httpsRedirect=httpsRedirect)


    def delete_node(self, node):
        """Removes the node from the load balancer."""
        return self.manager.delete_node(self, node)


    def update_node(self, node, diff=None):
        """Updates the node's attributes."""
        return self.manager.update_node(node, diff=diff)


    def delete_virtualip(self, vip):
        """Deletes the VirtualIP from its load balancer."""
        return self.manager.delete_virtualip(self, vip)


    def get_access_list(self):
        """
        Returns the current access list for the load balancer.
        """
        return self.manager.get_access_list(self)


    def add_access_list(self, access_list):
        """
        Adds the access list provided to the load balancer.

        The 'access_list' should be a dict in the following format:

            {"accessList": [
                {"address": "192.0.43.10", "type": "DENY"},
                {"address": "192.0.43.11", "type": "ALLOW"},
                ...
                {"address": "192.0.43.99", "type": "DENY"},
                ]
            }

        If no access list exists, it is created. If an access list
        already exists, it is updated with the provided list.
        """
        return self.manager.add_access_list(self, access_list)


    def delete_access_list(self):
        """
        Removes the access list from this load balancer.
        """
        return self.manager.delete_access_list(self)


    def delete_access_list_items(self, item_ids):
        """
        Removes the item(s) from the load balancer's access list
        that match the provided IDs. 'item_ids' should be one or
        more access list item IDs.
        """
        return self.manager.delete_access_list_items(self, item_ids)


    def get_health_monitor(self):
        """
        Returns a dict representing the health monitor for the load
        balancer. If no monitor has been configured, returns an
        empty dict.
        """
        return self.manager.get_health_monitor(self)


    def add_health_monitor(self, type, delay=10, timeout=10,
            attemptsBeforeDeactivation=3, path="/", statusRegex=None,
            bodyRegex=None, hostHeader=None):
        """
        Adds a health monitor to the load balancer. If a monitor already
        exists, it is updated with the supplied settings.
        """
        abd = attemptsBeforeDeactivation
        return self.manager.add_health_monitor(self, type=type, delay=delay,
                timeout=timeout, attemptsBeforeDeactivation=abd,
                path=path, statusRegex=statusRegex, bodyRegex=bodyRegex,
                hostHeader=hostHeader)


    def delete_health_monitor(self):
        """
        Deletes the health monitor for the load balancer.
        """
        return self.manager.delete_health_monitor(self)


    def get_connection_throttle(self):
        """
        Returns a dict representing the connection throttling information
        for the load balancer. If no connection throttle has been configured,
        returns an empty dict.
        """
        return self.manager.get_connection_throttle(self)


    def add_connection_throttle(self, maxConnectionRate=None,
            maxConnections=None, minConnections=None, rateInterval=None):
        """
        Updates the connection throttling information for the load balancer with
        the supplied values. At least one of the parameters must be supplied.
        """
        if not any((maxConnectionRate, maxConnections, minConnections,
                rateInterval)):
            # Pointless call
            return
        return self.manager.add_connection_throttle(self,
                maxConnectionRate=maxConnectionRate, maxConnections=maxConnections,
                minConnections=minConnections, rateInterval=rateInterval)


    def delete_connection_throttle(self):
        """
        Deletes all connection throttling settings for the load balancer.
        """
        return self.manager.delete_connection_throttle(self)


    def get_ssl_termination(self):
        """
        Returns a dict representing the SSL termination configuration
        for the load balancer. If SSL termination has not been configured,
        returns an empty dict.
        """
        return self.manager.get_ssl_termination(self)


    def add_ssl_termination(self, securePort, privatekey, certificate,
            intermediateCertificate=None, enabled=True,
            secureTrafficOnly=False):
        """
        Adds SSL termination information to the load balancer. If SSL
        termination has already been configured, it is updated with the
        supplied settings.
        """
        return self.manager.add_ssl_termination(self, securePort=securePort,
                privatekey=privatekey, certificate=certificate,
                intermediateCertificate=intermediateCertificate,
                enabled=enabled, secureTrafficOnly=secureTrafficOnly)


    def update_ssl_termination(self, securePort=None, enabled=None,
            secureTrafficOnly=None):
        """
        Updates existing SSL termination information for the load balancer
        without affecting the existing certificates/keys.
        """
        return self.manager.update_ssl_termination(self, securePort=securePort,
                enabled=enabled, secureTrafficOnly=secureTrafficOnly)


    def delete_ssl_termination(self):
        """
        Removes SSL termination for the load balancer.
        """
        return self.manager.delete_ssl_termination(self)


    def get_metadata(self):
        """
        Returns the current metadata for the load balancer.
        """
        return self.manager.get_metadata(self)


    def set_metadata(self, metadata):
        """
        Sets the metadata for the load balancer to the supplied dictionary
        of values. Any existing metadata is cleared.
        """
        return self.manager.set_metadata(self, metadata)


    def update_metadata(self, metadata):
        """
        Updates the existing metadata for the load balancer with
        the supplied dictionary.
        """
        return self.manager.update_metadata(self, metadata)


    def delete_metadata(self, keys=None):
        """
        Deletes metadata items specified by the 'keys' parameter for
        this load balancer. If no value for 'keys' is provided, all
        metadata is deleted.
        """
        return self.manager.delete_metadata(self, keys=keys)


    def get_metadata_for_node(self, node):
        """
        Returns the current metadata for the specified node.
        """
        return self.manager.get_metadata(self, node=node)


    def set_metadata_for_node(self, node, metadata):
        """
        Sets the metadata for the specified node to the supplied dictionary
        of values. Any existing metadata is cleared.
        """
        return self.manager.set_metadata(self, metadata, node=node)


    def update_metadata_for_node(self, node, metadata):
        """
        Updates the existing metadata for the specified node with
        the supplied dictionary.
        """
        return self.manager.update_metadata(self, metadata, node=node)


    def delete_metadata_for_node(self, node, keys=None):
        """
        Deletes metadata items specified by the 'keys' parameter for
        the specified node. If no value for 'keys' is provided, all
        metadata is deleted.
        """
        return self.manager.delete_metadata(self, keys=keys, node=node)


    def get_error_page(self):
        """
        Returns the current error page for the load balancer.

        Load balancers all have a default error page that is shown to
        an end user who is attempting to access a load balancer node
        that is offline/unavailable.
        """
        return self.manager.get_error_page(self)


    def set_error_page(self, html):
        """
        Sets a custom error page for the load balancer.

        A single custom error page may be added per account load balancer
        with an HTTP protocol. Page updates will override existing content.
        If a custom error page is deleted, or the load balancer is changed
        to a non-HTTP protocol, the default error page will be restored.
        """
        return self.manager.set_error_page(self, html)


    def clear_error_page(self):
        """
        Resets the error page to the default.
        """
        return self.manager.clear_error_page(self)


    # BEGIN - property definitions ##
    def _get_connection_logging(self):
        if self._connection_logging is None:
            self._connection_logging = self.manager.get_connection_logging(self)
        return self._connection_logging

    def _set_connection_logging(self, val):
        self.manager.set_connection_logging(self, val)
        self._connection_logging = val


    def _get_content_caching(self):
        if self._content_caching is None:
            self._content_caching = self.manager.get_content_caching(self)
        return self._content_caching

    def _set_content_caching(self, val):
        self.manager.set_content_caching(self, val)
        self._content_caching = val


    def _get_session_persistence(self):
        if self._session_persistence is None:
            self._session_persistence = self.manager.get_session_persistence(self)
        return self._session_persistence

    def _set_session_persistence(self, val):
        if val:
            if not isinstance(val, six.string_types) or (val.upper() not in
                    ("HTTP_COOKIE", "SOURCE_IP")):
                raise exc.InvalidSessionPersistenceType("Session Persistence "
                        "must be one of 'HTTP_COOKIE' or 'SOURCE_IP'. '%s' is "
                        "not a valid setting." % val)
            self.manager.set_session_persistence(self, val)
            self._session_persistence = val.upper()
        else:
            self.manager.delete_session_persistence(self)
            self._session_persistence = ""


    connection_logging = property(_get_connection_logging,
            _set_connection_logging, None, "The current state of connection "
            "logging. Possible values are True or False.")
    content_caching = property(_get_content_caching, _set_content_caching,
            None, "The current state of content caching. Possible values are "
            "True or False.")
    session_persistence = property(_get_session_persistence,
            _set_session_persistence, None, "The current state of session "
            "persistence. Possible values are either 'HTTP_COOKIE' or "
            "'SOURCE_IP', depending on the type of load balancing.")
    # END - property definitions ##



class CloudLoadBalancerManager(BaseManager):
    def update(self, lb, name=None, algorithm=None, protocol=None,
            halfClosed=None, port=None, timeout=None, httpsRedirect=None):
        """
        Provides a way to modify the following attributes of a load balancer:
            - name
            - algorithm
            - protocol
            - halfClosed
            - port
            - timeout
            - httpsRedirect
        """
        body = {}
        if name is not None:
            body["name"] = name
        if algorithm is not None:
            body["algorithm"] = algorithm
        if protocol is not None:
            body["protocol"] = protocol
        if halfClosed is not None:
            body["halfClosed"] = halfClosed
        if port is not None:
            body["port"] = port
        if timeout is not None:
            body["timeout"] = timeout
        if httpsRedirect is not None:
            body["httpsRedirect"] = httpsRedirect
        if not body:
            # Nothing passed
            return
        body = {"loadBalancer": body}
        uri = "/loadbalancers/%s" % utils.get_id(lb)
        try:
            resp, resp_body = self.api.method_put(uri, body=body)
        except exc.ClientException as e:
            message = e.message
            details = e.details
            if message and details:
                errmsg = "%s - %s" % (message, details)
            else:
                errmsg = message
            raise exc.InvalidLoadBalancerParameters(errmsg)
        return resp, resp_body


    def _create_body(self, name, port=None, protocol=None, nodes=None,
            virtual_ips=None, algorithm=None, halfClosed=None, accessList=None,
            connectionLogging=None, connectionThrottle=None, healthMonitor=None,
            metadata=None, timeout=None, sessionPersistence=None,
            httpsRedirect=None):
        """
        Used to create the dict required to create a load balancer instance.
        """
        required = (virtual_ips, port, protocol)
        if not all(required):
            raise exc.MissingLoadBalancerParameters("Load Balancer creation "
                "requires at least one virtual IP, a protocol, and a port.")
        nodes = utils.coerce_string_to_list(nodes)
        virtual_ips = utils.coerce_string_to_list(virtual_ips)
        bad_conditions = [node.condition for node in nodes
                if node.condition.upper() not in ("ENABLED", "DISABLED")]
        if bad_conditions:
            raise exc.InvalidNodeCondition("Nodes for new load balancer must be "
                    "created in either 'ENABLED' or 'DISABLED' condition; "
                    "received the following invalid conditions: %s" %
                    ", ".join(set(bad_conditions)))
        node_dicts = [nd.to_dict() for nd in nodes]
        vip_dicts = [vip.to_dict() for vip in virtual_ips]
        body = {"loadBalancer": {
                "name": name,
                "port": port,
                "protocol": protocol,
                "nodes": node_dicts,
                "virtualIps": vip_dicts,
                "algorithm": algorithm or "RANDOM",
                "halfClosed": halfClosed,
                "accessList": accessList,
                "connectionLogging": connectionLogging,
                "connectionThrottle": connectionThrottle,
                "healthMonitor": healthMonitor,
                "metadata": metadata,
                "timeout": timeout,
                "sessionPersistence": sessionPersistence,
                "httpsRedirect": httpsRedirect,
                }}
        return body


    def add_nodes(self, lb, nodes):
        """Adds the list of nodes to the specified load balancer."""
        if not isinstance(nodes, (list, tuple)):
            nodes = [nodes]
        node_dicts = [nd.to_dict() for nd in nodes]
        resp, body = self.api.method_post("/loadbalancers/%s/nodes" % lb.id,
                body={"nodes": node_dicts})
        return resp, body


    def delete_node(self, loadbalancer, node):
        """Removes the node from its load balancer."""
        lb = node.parent
        if not lb:
            raise exc.UnattachedNode("No parent Load Balancer for this node "
                    "could be determined.")
        resp, body = self.api.method_delete("/loadbalancers/%s/nodes/%s" %
                (lb.id, node.id))
        return resp, body


    def update_node(self, node, diff=None):
        """Updates the node's attributes."""
        lb = node.parent
        if not lb:
            raise exc.UnattachedNode("No parent Load Balancer for this node "
                    "could be determined.")
        if diff is None:
            diff = node._diff()
        req_body = {"node": diff}
        resp, body = self.api.method_put("/loadbalancers/%s/nodes/%s" %
                (lb.id, node.id), body=req_body)
        return resp, body


    def add_virtualip(self, lb, vip):
        """Adds the VirtualIP to the specified load balancer."""
        resp, body = self.api.method_post("/loadbalancers/%s/virtualips" % lb.id,
                body=vip.to_dict())
        return resp, body


    def delete_virtualip(self, loadbalancer, vip):
        """Deletes the VirtualIP from its load balancer."""
        lb = vip.parent
        if not lb:
            raise exc.UnattachedVirtualIP("No parent Load Balancer for this "
                    "VirtualIP could be determined.")
        resp, body = self.api.method_delete("/loadbalancers/%s/virtualips/%s" %
                (lb.id, vip.id))
        return resp, body


    def get_access_list(self, loadbalancer):
        """
        Returns the current access list for the load balancer.
        """
        uri = "/loadbalancers/%s/accesslist" % utils.get_id(loadbalancer)
        resp, body = self.api.method_get(uri)
        return body.get("accessList")


    def add_access_list(self, loadbalancer, access_list):
        """
        Adds the access list provided to the load balancer.

        The 'access_list' should be a list of dicts in the following format:

            [{"address": "192.0.43.10", "type": "DENY"},
             {"address": "192.0.43.11", "type": "ALLOW"},
             ...
             {"address": "192.0.43.99", "type": "DENY"},
            ]

        If no access list exists, it is created. If an access list
        already exists, it is updated with the provided list.
        """
        req_body = {"accessList": access_list}
        uri = "/loadbalancers/%s/accesslist" % utils.get_id(loadbalancer)
        resp, body = self.api.method_post(uri, body=req_body)
        return body


    def delete_access_list(self, loadbalancer):
        """
        Removes the access list from this load balancer.
        """
        uri = "/loadbalancers/%s/accesslist" % utils.get_id(loadbalancer)
        resp, body = self.api.method_delete(uri)
        return body


    def delete_access_list_items(self, loadbalancer, item_ids):
        """
        Removes the item(s) from the load balancer's access list
        that match the provided IDs. 'item_ids' should be one or
        more access list item IDs.
        """
        if not isinstance(item_ids, (list, tuple)):
            item_ids = [item_ids]
        valid_ids = [itm["id"] for itm in self.get_access_list(loadbalancer)]
        bad_ids = [str(itm) for itm in item_ids if itm not in valid_ids]
        if bad_ids:
            raise exc.AccessListIDNotFound("The following ID(s) are not valid "
                    "Access List items: %s" % ", ".join(bad_ids))
        items = "&".join(["id=%s" % item_id for item_id in item_ids])
        uri = "/loadbalancers/%s/accesslist?%s" % (
                utils.get_id(loadbalancer), items)
        # TODO: add the item ids
        resp, body = self.api.method_delete(uri)
        return body


    def get_health_monitor(self, loadbalancer):
        """
        Returns a dict representing the health monitor for the load
        balancer. If no monitor has been configured, returns an
        empty dict.
        """
        uri = "/loadbalancers/%s/healthmonitor" % utils.get_id(loadbalancer)
        resp, body = self.api.method_get(uri)
        return body.get("healthMonitor", {})


    def add_health_monitor(self, loadbalancer, type, delay=10, timeout=10,
            attemptsBeforeDeactivation=3, path="/", statusRegex=None,
            bodyRegex=None, hostHeader=None):
        """
        Adds a health monitor to the load balancer. If a monitor already
        exists, it is updated with the supplied settings.
        """
        uri = "/loadbalancers/%s/healthmonitor" % utils.get_id(loadbalancer)
        req_body = {"healthMonitor": {
                "type": type,
                "delay": delay,
                "timeout": timeout,
                "attemptsBeforeDeactivation": attemptsBeforeDeactivation,
                }}
        uptype = type.upper()
        if uptype.startswith("HTTP"):
            lb = self._get_lb(loadbalancer)
            if uptype != lb.protocol:
                raise exc.ProtocolMismatch("Cannot set the Health Monitor type "
                        "to '%s' when the Load Balancer's protocol is '%s'." %
                        (type, lb.protocol))
            if not all((path, statusRegex, bodyRegex)):
                raise exc.MissingHealthMonitorSettings("When creating an HTTP(S) "
                        "monitor, you must provide the 'path', 'statusRegex' and "
                        "'bodyRegex' parameters.")
            body_hm = req_body["healthMonitor"]
            body_hm["path"] = path
            body_hm["statusRegex"] = statusRegex
            body_hm["bodyRegex"] = bodyRegex
            if hostHeader:
                body_hm["hostHeader"] = hostHeader
        resp, body = self.api.method_put(uri, body=req_body)
        return body


    def delete_health_monitor(self, loadbalancer):
        """
        Deletes the health monitor for the load balancer.
        """
        uri = "/loadbalancers/%s/healthmonitor" % utils.get_id(loadbalancer)
        resp, body = self.api.method_delete(uri)


    def get_connection_throttle(self, loadbalancer):
        """
        Returns a dict representing the connection throttling information
        for the load balancer. If no connection throttle has been configured,
        returns an empty dict.
        """
        uri = "/loadbalancers/%s/connectionthrottle" % utils.get_id(loadbalancer)
        resp, body = self.api.method_get(uri)
        return body.get("connectionThrottle", {})


    def add_connection_throttle(self, loadbalancer, maxConnectionRate=None,
            maxConnections=None, minConnections=None, rateInterval=None):
        """
        Creates or updates the connection throttling information for the load
        balancer. When first creating the connection throttle, all 4 parameters
        must be supplied. When updating an existing connection throttle, at
        least one of the parameters must be supplied.
        """
        settings = {}
        if maxConnectionRate:
            settings["maxConnectionRate"] = maxConnectionRate
        if maxConnections:
            settings["maxConnections"] = maxConnections
        if minConnections:
            settings["minConnections"] = minConnections
        if rateInterval:
            settings["rateInterval"] = rateInterval
        req_body = {"connectionThrottle": settings}
        uri = "/loadbalancers/%s/connectionthrottle" % utils.get_id(loadbalancer)
        resp, body = self.api.method_put(uri, body=req_body)
        return body


    def delete_connection_throttle(self, loadbalancer):
        """
        Deletes all connection throttling settings for the load balancer.
        """
        uri = "/loadbalancers/%s/connectionthrottle" % utils.get_id(loadbalancer)
        resp, body = self.api.method_delete(uri)


    def get_ssl_termination(self, loadbalancer):
        """
        Returns a dict representing the SSL termination configuration
        for the load balancer. If SSL termination has not been configured,
        returns an empty dict.
        """
        uri = "/loadbalancers/%s/ssltermination" % utils.get_id(loadbalancer)
        try:
            resp, body = self.api.method_get(uri)
        except exc.NotFound:
            # For some reason, instead of returning an empty dict like the
            # other API GET calls, this raises a 404.
            return {}
        return body.get("sslTermination", {})


    def add_ssl_termination(self, loadbalancer, securePort, privatekey, certificate,
            intermediateCertificate, enabled=True, secureTrafficOnly=False):
        """
        Adds SSL termination information to the load balancer. If SSL termination
        has already been configured, it is updated with the supplied settings.
        """
        uri = "/loadbalancers/%s/ssltermination" % utils.get_id(loadbalancer)
        req_body = {"sslTermination": {
                "certificate": certificate,
                "enabled": enabled,
                "secureTrafficOnly": secureTrafficOnly,
                "privatekey": privatekey,
                "intermediateCertificate": intermediateCertificate,
                "securePort": securePort,
                }}
        resp, body = self.api.method_put(uri, body=req_body)
        return body


    def update_ssl_termination(self, loadbalancer, securePort=None, enabled=None,
            secureTrafficOnly=None):
        """
        Updates existing SSL termination information for the load balancer
        without affecting the existing certificates/keys.
        """
        ssl_info = self.get_ssl_termination(loadbalancer)
        if not ssl_info:
            raise exc.NoSSLTerminationConfiguration("You must configure SSL "
                    "termination on this load balancer before attempting "
                    "to update it.")
        if securePort is None:
            securePort = ssl_info["securePort"]
        if enabled is None:
            enabled = ssl_info["enabled"]
        if secureTrafficOnly is None:
            secureTrafficOnly = ssl_info["secureTrafficOnly"]
        uri = "/loadbalancers/%s/ssltermination" % utils.get_id(loadbalancer)
        req_body = {"sslTermination": {
                "enabled": enabled,
                "secureTrafficOnly": secureTrafficOnly,
                "securePort": securePort,
                }}
        resp, body = self.api.method_put(uri, body=req_body)
        return body


    def delete_ssl_termination(self, loadbalancer):
        """
        Deletes the SSL Termination configuration for the load balancer.
        """
        uri = "/loadbalancers/%s/ssltermination" % utils.get_id(loadbalancer)
        resp, body = self.api.method_delete(uri)


    def get_metadata(self, loadbalancer, node=None, raw=False):
        """
        Returns the current metadata for the load balancer. If 'node' is
        provided, returns the current metadata for that node.
        """
        if node:
            uri = "/loadbalancers/%s/nodes/%s/metadata" % (
                    utils.get_id(loadbalancer), utils.get_id(node))
        else:
            uri = "/loadbalancers/%s/metadata" % utils.get_id(loadbalancer)
        resp, body = self.api.method_get(uri)
        meta = body.get("metadata", [])
        if raw:
            return meta
        ret = dict([(itm["key"], itm["value"]) for itm in meta])
        return ret


    def set_metadata(self, loadbalancer, metadata, node=None):
        """
        Sets the metadata for the load balancer to the supplied dictionary
        of values. Any existing metadata is cleared. If 'node' is provided,
        the metadata for that node is set instead of for the load balancer.
        """
        # Delete any existing metadata
        self.delete_metadata(loadbalancer, node=node)
        # Convert the metadata dict into the list format
        metadata_list = [{"key": key, "value": val}
                for key, val in metadata.items()]
        if node:
            uri = "/loadbalancers/%s/nodes/%s/metadata" % (
                    utils.get_id(loadbalancer), utils.get_id(node))
        else:
            uri = "/loadbalancers/%s/metadata" % utils.get_id(loadbalancer)
        req_body = {"metadata": metadata_list}
        resp, body = self.api.method_post(uri, body=req_body)
        return body


    def update_metadata(self, loadbalancer, metadata, node=None):
        """
        Updates the existing metadata with the supplied dictionary. If
        'node' is supplied, the metadata for that node is updated instead
        of for the load balancer.
        """
        # Get the existing metadata
        md = self.get_metadata(loadbalancer, raw=True)
        id_lookup = dict([(itm["key"], itm["id"]) for itm in md])
        metadata_list = []
        # Updates must be done individually
        for key, val in metadata.items():
            try:
                meta_id = id_lookup[key]
                if node:
                    uri = "/loadbalancers/%s/nodes/%s/metadata/%s" % (
                            utils.get_id(loadbalancer), utils.get_id(node),
                            meta_id)
                else:
                    uri = "/loadbalancers/%s/metadata" % utils.get_id(loadbalancer)
                req_body = {"meta": {"value": val}}
                resp, body = self.api.method_put(uri, body=req_body)
            except KeyError:
                # Not an existing key; add to metadata_list
                metadata_list.append({"key": key, "value": val})
        if metadata_list:
            # New items; POST them
            if node:
                uri = "/loadbalancers/%s/nodes/%s/metadata" % (
                        utils.get_id(loadbalancer), utils.get_id(node))
            else:
                uri = "/loadbalancers/%s/metadata" % utils.get_id(loadbalancer)
            req_body = {"metadata": metadata_list}
            resp, body = self.api.method_post(uri, body=req_body)


    def delete_metadata(self, loadbalancer, keys=None, node=None):
        """
        Deletes metadata items specified by the 'keys' parameter. If no value
        for 'keys' is provided, all metadata is deleted. If 'node' is supplied,
        the metadata for that node is deleted instead of the load balancer.
        """
        if keys and not isinstance(keys, (list, tuple)):
            keys = [keys]
        md = self.get_metadata(loadbalancer, node=node, raw=True)
        if keys:
            md = [dct for dct in md if dct["key"] in keys]
        if not md:
            # Nothing to do; log it? Raise an error?
            return
        id_list = "&".join(["id=%s" % itm["id"] for itm in md])
        if node:
            uri = "/loadbalancers/%s/nodes/%s/metadata?%s" % (
                    utils.get_id(loadbalancer), utils.get_id(node), id_list)
        else:
            uri = "/loadbalancers/%s/metadata?%s" % (
                    utils.get_id(loadbalancer), id_list)
        resp, body = self.api.method_delete(uri)
        return body


    def get_error_page(self, loadbalancer):
        """
        Load Balancers all have a default error page that is shown to
        an end user who is attempting to access a load balancer node
        that is offline/unavailable.
        """
        uri = "/loadbalancers/%s/errorpage" % utils.get_id(loadbalancer)
        resp, body = self.api.method_get(uri)
        return body


    def set_error_page(self, loadbalancer, html):
        """
        A single custom error page may be added per account load balancer
        with an HTTP protocol. Page updates will override existing content.
        If a custom error page is deleted, or the load balancer is changed
        to a non-HTTP protocol, the default error page will be restored.
        """
        uri = "/loadbalancers/%s/errorpage" % utils.get_id(loadbalancer)
        req_body = {"errorpage": {"content": html}}
        resp, body = self.api.method_put(uri, body=req_body)
        return body


    def clear_error_page(self, loadbalancer):
        """
        Resets the error page to the default.
        """
        uri = "/loadbalancers/%s/errorpage" % utils.get_id(loadbalancer)
        resp, body = self.api.method_delete(uri)
        return body


    def get_usage(self, loadbalancer=None, start=None, end=None):
        """
        Return the load balancer usage records for this account. If 'loadbalancer'
        is None, records for all load balancers are returned. You may optionally
        include a start datetime or an end datetime, or both, which will limit
        the records to those on or after the start time, and those before or on the
        end time. These times should be Python datetime.datetime objects, Python
        datetime.date objects, or strings in the format: "YYYY-MM-DD HH:MM:SS" or
        "YYYY-MM-DD".
        """
        if start is end is None:
            period = None
        else:
            parts = []
            startStr = utils.iso_time_string(start)
            if startStr:
                parts.append("startTime=%s" % startStr)
            endStr = utils.iso_time_string(end)
            if endStr:
                parts.append("endTime=%s" % endStr)
            period = "&".join(parts).strip("&")
        if loadbalancer is None:
            uri = "/loadbalancers/usage"
        else:
            uri = "/loadbalancers/%s/usage" % utils.get_id(loadbalancer)
        if period:
            uri = "%s?%s" % (uri, period)
        resp, body = self.api.method_get(uri)
        return body


    def get_stats(self, loadbalancer):
        """
        Returns statistics for the given load balancer.
        """
        uri = "/loadbalancers/%s/stats" % utils.get_id(loadbalancer)
        resp, body = self.api.method_get(uri)
        return body


    def get_session_persistence(self, loadbalancer):
        """
        Returns the session persistence setting for the given load balancer.
        """
        uri = "/loadbalancers/%s/sessionpersistence" % utils.get_id(loadbalancer)
        resp, body = self.api.method_get(uri)
        ret = body["sessionPersistence"].get("persistenceType", "")
        return ret


    def set_session_persistence(self, loadbalancer, val):
        """
        Sets the session persistence for the given load balancer.
        """
        val = val.upper()
        uri = "/loadbalancers/%s/sessionpersistence" % utils.get_id(loadbalancer)
        req_body = {"sessionPersistence": {
                "persistenceType": val,
                }}
        resp, body = self.api.method_put(uri, body=req_body)
        return body


    def delete_session_persistence(self, loadbalancer):
        """
        Removes the session persistence setting for the given load balancer.
        """
        uri = "/loadbalancers/%s/sessionpersistence" % utils.get_id(loadbalancer)
        resp, body = self.api.method_delete(uri)
        return body


    def get_connection_logging(self, loadbalancer):
        """
        Returns the connection logging setting for the given load balancer.
        """
        uri = "/loadbalancers/%s/connectionlogging" % utils.get_id(loadbalancer)
        resp, body = self.api.method_get(uri)
        ret = body.get("connectionLogging", {}).get("enabled", False)
        return ret


    def set_connection_logging(self, loadbalancer, val):
        """
        Sets the connection logging for the given load balancer.
        """
        uri = "/loadbalancers/%s/connectionlogging" % utils.get_id(loadbalancer)
        val = str(val).lower()
        req_body = {"connectionLogging": {
                "enabled": val,
                }}
        resp, body = self.api.method_put(uri, body=req_body)
        return body


    def get_content_caching(self, loadbalancer):
        """
        Returns the content caching setting for the given load balancer.
        """
        uri = "/loadbalancers/%s/contentcaching" % utils.get_id(loadbalancer)
        resp, body = self.api.method_get(uri)
        ret = body.get("contentCaching", {}).get("enabled", False)
        return ret


    def set_content_caching(self, loadbalancer, val):
        """
        Sets the content caching for the given load balancer.
        """
        uri = "/loadbalancers/%s/contentcaching" % utils.get_id(loadbalancer)
        val = str(val).lower()
        req_body = {"contentCaching": {
                "enabled": val,
                }}
        resp, body = self.api.method_put(uri, body=req_body)
        return body


    def _get_lb(self, lb_or_id):
        """
        Accepts either a loadbalancer or the ID of a loadbalancer, and returns
        the CloudLoadBalancer instance.
        """
        if isinstance(lb_or_id, CloudLoadBalancer):
            ret = lb_or_id
        else:
            ret = self.get(lb_or_id)
        return ret



class Node(object):
    """Represents a Node for a Load Balancer."""
    def __init__(self, address=None, port=None, condition=None, weight=None,
            status=None, parent=None, type=None, id=None):
        if condition is None:
            condition = "ENABLED"
        if not all((address, port)):
            raise exc.InvalidNodeParameters("You must include an address and a "
            "port when creating a node.")
        self.address = address
        self.port = port
        self.condition = condition
        if weight is None:
            weight = 1
        self.weight = weight
        self.status = status
        self.parent = parent
        self.type = type
        self.id = id
        self._original_state = self.to_dict()


    def __repr__(self):
        tmp = "<Node type=%s, condition=%s, id=%s, address=%s, port=%s weight=%s>"
        return tmp % (self.type, self.condition, self.id, self.address, self.port,
                self.weight)

    def __eq__(self, other):
        return (isinstance(other, self.__class__)
            and self.__dict__ == other.__dict__)

    def __ne__(self, other):
        return not self.__eq__(other)

    def to_dict(self):
        """Convert this Node to a dict representation for passing to the API."""
        return {"address": self.address,
                "port": self.port,
                "condition": self.condition,
                "type": self.type,
                "id": self.id,
                }


    def get_metadata(self):
        """
        Returns the current metadata for the node.
        """
        return self.manager.get_metadata(self, node=self)


    def set_metadata(self, metadata):
        """
        Sets the metadata for the node to the supplied dictionary
        of values. Any existing metadata is cleared.
        """
        return self.manager.set_metadata(self, metadata, node=self)


    def update_metadata(self, metadata):
        """
        Updates the existing metadata for the node with
        the supplied dictionary.
        """
        return self.manager.update_metadata(self, metadata, node=self)


    def delete_metadata(self, keys=None):
        """
        Deletes metadata items specified by the 'keys' parameter for
        this node. If no value for 'keys' is provided, all
        metadata is deleted.
        """
        return self.manager.delete_metadata(self, keys=keys, node=self)


    @assure_parent
    def delete(self):
        """Removes this Node from its Load Balancer."""
        self.parent.delete_node(self)


    def _diff(self):
        diff_dict = {}
        for att, val in self._original_state.items():
            curr = getattr(self, att)
            if curr != val:
                diff_dict[att] = curr
        return diff_dict


    @assure_parent
    def update(self):
        """
        Pushes any local changes to the object up to the actual load
        balancer node.
        """
        diff = self._diff()
        if not diff:
            # Nothing to do!
            return
        self.parent.update_node(self, diff)


    def get_device(self):
        """
        Returns a reference to the device that is represented by this node.
        Returns None if no such device can be determined.
        """
        addr = self.address
        servers = [server for server in pyrax.cloudservers.list()
                if addr in server.networks.get("private", "")]
        try:
            return servers[0]
        except IndexError:
            return None



class VirtualIP(object):
    """Represents a Virtual IP for a Load Balancer."""
    def __init__(self, type=None, address=None, ipVersion=None, id=None,
            parent=None):
        if type is None:
            type = "PUBLIC"
        if type.upper() not in ("PUBLIC", "SERVICENET"):
            raise exc.InvalidVirtualIPType("Virtual IPs must be one of "
                    "'PUBLIC' or 'SERVICENET' type; '%s' is not valid." % type)
        if not ipVersion:
            ipVersion = "IPV4"
        if not ipVersion.upper() in ("IPV4", "IPV6"):
            raise exc.InvalidVirtualIPVersion("Virtual IP versions must be one "
                    "of 'IPV4' or 'IPV6'; '%s' is not valid." % ipVersion)
        self.type = type
        self.address = address
        self.ip_version = ipVersion
        self.id = id
        self.parent = parent


    def __repr__(self):
        return "<VirtualIP type=%s, id=%s, address=%s version=%s>" % (
                self.type, self.id, self.address, self.ip_version)


    def to_dict(self):
        """
        Convert this VirtualIP to a dict representation for passing
        to the API.
        """
        if self.id:
            return {"id": self.id}
        return {"type": self.type, "ipVersion": self.ip_version}


    @assure_parent
    def delete(self):
        self.parent.delete_virtualip(self)



class CloudLoadBalancerClient(BaseClient):
    """
    This is the primary class for interacting with Cloud Load Balancers.
    """
    name = "Cloud Load Balancers"

    def __init__(self, *args, **kwargs):
        # Bring these two classes into the Client namespace
        self.Node = Node
        self.VirtualIP = VirtualIP
        self._algorithms = None
        self._protocols = None
        self._allowed_domains = None
        super(CloudLoadBalancerClient, self).__init__(*args, **kwargs)


    def _configure_manager(self):
        """
        Creates a manager to handle the instances, and another
        to handle flavors.
        """
        self._manager = CloudLoadBalancerManager(self,
                resource_class=CloudLoadBalancer,
                response_key="loadBalancer", uri_base="loadbalancers")


    def get_usage(self, loadbalancer=None, start=None, end=None):
        """
        Return the load balancer usage records for this account. If 'loadbalancer'
        is None, records for all load balancers are returned. You may optionally
        include a start datetime or an end datetime, or both, which will limit
        the records to those on or after the start time, and those before or on the
        end time. These times should be Python datetime.datetime objects, Python
        datetime.date objects, or strings in the format: "YYYY-MM-DD HH:MM:SS" or
        "YYYY-MM-DD".
        """
        return self._manager.get_usage(loadbalancer=loadbalancer, start=start,
                end=end)


    @property
    def allowed_domains(self):
        """
        This property lists the allowed domains for a load balancer.

        The allowed domains are restrictions set for the allowed domain names
        used for adding load balancer nodes. In order to submit a domain name
        as an address for the load balancer node to add, the user must verify
        that the domain is valid by using the List Allowed Domains call. Once
        verified, simply supply the domain name in place of the node's address
        in the add_nodes() call.
        """
        if self._allowed_domains is None:
            uri = "/loadbalancers/alloweddomains"
            resp, body = self.method_get(uri)
            dom_list = body["allowedDomains"]
            self._allowed_domains = [itm["allowedDomain"]["name"]
                    for itm in dom_list]
        return self._allowed_domains


    @property
    def algorithms(self):
        """
        Returns a list of available load balancing algorithms.
        """
        if self._algorithms is None:
            uri = "/loadbalancers/algorithms"
            resp, body = self.method_get(uri)
            self._algorithms = [alg["name"] for alg in body["algorithms"]]
        return self._algorithms


    @property
    def protocols(self):
        """
        Returns a list of available load balancing protocols.
        """
        if self._protocols is None:
            uri = "/loadbalancers/protocols"
            resp, body = self.method_get(uri)
            self._protocols = [proto["name"] for proto in body["protocols"]]
        return self._protocols


    @assure_loadbalancer
    def update(self, loadbalancer, name=None, algorithm=None, protocol=None,
            halfClosed=None, port=None, timeout=None, httpsRedirect=None):
        """
        Provides a way to modify the following attributes of a load balancer:
            - name
            - algorithm
            - protocol
            - halfClosed
            - port
            - timeout
            - httpsRedirect
        """
        return self._manager.update(loadbalancer, name=name,
                algorithm=algorithm, protocol=protocol, halfClosed=halfClosed,
                port=port, timeout=timeout, httpsRedirect=httpsRedirect)


    @assure_loadbalancer
    def add_nodes(self, loadbalancer, nodes):
        """Adds the nodes to this load balancer."""
        return loadbalancer.add_nodes(nodes)


    @assure_loadbalancer
    def add_virtualip(self, loadbalancer, vip):
        """Adds the virtual IP to this load balancer."""
        return loadbalancer.add_virtualip(vip)


    def delete_node(self, node):
        """Removes the node from its load balancer."""
        return node.delete()


    def update_node(self, node):
        """Updates the node's attributes."""
        return node.update()


    def delete_virtualip(self, vip):
        """Deletes the VirtualIP from its load balancer."""
        return vip.delete()


    @assure_loadbalancer
    def get_access_list(self, loadbalancer):
        """
        Returns the current access list for the load balancer.
        """
        return loadbalancer.get_access_list()


    @assure_loadbalancer
    def add_access_list(self, loadbalancer, access_list):
        """
        Adds the access list provided to the load balancer.

        The 'access_list' should be a dict in the following format:

            {"accessList": [
                {"address": "192.0.43.10", "type": "DENY"},
                {"address": "192.0.43.11", "type": "ALLOW"},
                ...
                {"address": "192.0.43.99", "type": "DENY"},
                ]
            }

        If no access list exists, it is created. If an access list
        already exists, it is updated with the provided list.
        """
        return loadbalancer.add_access_list(access_list)


    @assure_loadbalancer
    def delete_access_list(self, loadbalancer):
        """
        Removes the access list from this load balancer.
        """
        return loadbalancer.delete_access_list()


    @assure_loadbalancer
    def delete_access_list_items(self, loadbalancer, item_ids):
        """
        Removes the item(s) from the load balancer's access list
        that match the provided IDs. 'item_ids' should be one or
        more access list item IDs.
        """
        return loadbalancer.delete_access_list_items(item_ids)


    @assure_loadbalancer
    def get_health_monitor(self, loadbalancer):
        """
        Returns a dict representing the health monitor for the load
        balancer. If no monitor has been configured, returns an
        empty dict.
        """
        return loadbalancer.get_health_monitor()


    @assure_loadbalancer
    def add_health_monitor(self, loadbalancer, type, delay=10, timeout=10,
            attemptsBeforeDeactivation=3, path="/", statusRegex=None,
            bodyRegex=None, hostHeader=None):
        """
        Adds a health monitor to the load balancer. If a monitor already
        exists, it is updated with the supplied settings.
        """
        abd = attemptsBeforeDeactivation
        return loadbalancer.add_health_monitor(type=type, delay=delay,
                timeout=timeout, attemptsBeforeDeactivation=abd, path=path,
                statusRegex=statusRegex, bodyRegex=bodyRegex,
                hostHeader=hostHeader)


    @assure_loadbalancer
    def delete_health_monitor(self, loadbalancer):
        """
        Deletes the health monitor for the load balancer.
        """
        return loadbalancer.delete_health_monitor()


    @assure_loadbalancer
    def get_connection_throttle(self, loadbalancer):
        """
        Returns a dict representing the connection throttling information
        for the load balancer. If no connection throttle has been configured,
        returns an empty dict.
        """
        return loadbalancer.get_connection_throttle()


    @assure_loadbalancer
    def add_connection_throttle(self, loadbalancer, maxConnectionRate=None,
            maxConnections=None, minConnections=None, rateInterval=None):
        """
        Updates the connection throttling information for the load balancer with
        the supplied values. At least one of the parameters must be supplied.
        """
        return loadbalancer.add_connection_throttle(
                maxConnectionRate=maxConnectionRate, maxConnections=maxConnections,
                minConnections=minConnections, rateInterval=rateInterval)


    @assure_loadbalancer
    def delete_connection_throttle(self, loadbalancer):
        """
        Deletes all connection throttling settings for the load balancer.
        """
        return loadbalancer.delete_connection_throttle()


    @assure_loadbalancer
    def get_ssl_termination(self, loadbalancer):
        """
        Returns a dict representing the SSL termination configuration
        for the load balancer. If SSL termination has not been configured,
        returns an empty dict.
        """
        return loadbalancer.get_ssl_termination()


    @assure_loadbalancer
    def add_ssl_termination(self, loadbalancer, securePort, privatekey,
            certificate, intermediateCertificate, enabled=True,
            secureTrafficOnly=False):
        """
        Adds SSL termination information to the load balancer. If SSL termination
        has already been configured, it is updated with the supplied settings.
        """
        return loadbalancer.add_ssl_termination(securePort=securePort,
                privatekey=privatekey, certificate=certificate,
                intermediateCertificate=intermediateCertificate,
                enabled=enabled, secureTrafficOnly=secureTrafficOnly)


    @assure_loadbalancer
    def update_ssl_termination(self, loadbalancer, securePort=None, enabled=None,
            secureTrafficOnly=None):
        """
        Updates existing SSL termination information for the load balancer
        without affecting the existing certificates/keys.
        """
        return loadbalancer.update_ssl_termination(securePort=securePort,
                enabled=enabled, secureTrafficOnly=secureTrafficOnly)


    @assure_loadbalancer
    def delete_ssl_termination(self, loadbalancer):
        """
        Removes SSL termination for the load balancer.
        """
        return loadbalancer.delete_ssl_termination()


    @assure_loadbalancer
    def get_metadata(self, loadbalancer):
        """
        Returns the current metadata for the load balancer.
        """
        return loadbalancer.get_metadata()


    @assure_loadbalancer
    def set_metadata(self, loadbalancer, metadata):
        """
        Sets the metadata for the load balancer to the supplied dictionary
        of values. Any existing metadata is cleared.
        """
        return loadbalancer.set_metadata(metadata)


    @assure_loadbalancer
    def update_metadata(self, loadbalancer, metadata):
        """
        Updates the existing metadata for the load balancer with
        the supplied dictionary.
        """
        return loadbalancer.update_metadata(metadata)


    @assure_loadbalancer
    def delete_metadata(self, loadbalancer, keys=None):
        """
        Deletes metadata items specified by the 'keys' parameter for
        this load balancer. If no value for 'keys' is provided, all
        metadata is deleted.
        """
        return loadbalancer.delete_metadata(keys=keys)


    @assure_loadbalancer
    def get_metadata_for_node(self, loadbalancer, node):
        """
        Returns the current metadata for the specified node.
        """
        return loadbalancer.get_metadata_for_node(node)


    @assure_loadbalancer
    def set_metadata_for_node(self, loadbalancer, node, metadata):
        """
        Sets the metadata for the specified node to the supplied dictionary
        of values. Any existing metadata is cleared.
        """
        return loadbalancer.set_metadata_for_node(node, metadata)


    @assure_loadbalancer
    def update_metadata_for_node(self, loadbalancer, node, metadata):
        """
        Updates the existing metadata for the specified node with
        the supplied dictionary.
        """
        return loadbalancer.update_metadata_for_node(node, metadata)


    @assure_loadbalancer
    def delete_metadata_for_node(self, loadbalancer, node, keys=None):
        """
        Deletes metadata items specified by the 'keys' parameter for
        the specified node. If no value for 'keys' is provided, all
        metadata is deleted.
        """
        return loadbalancer.delete_metadata_for_node(node, keys=keys)


    @assure_loadbalancer
    def get_error_page(self, loadbalancer):
        """
        Load Balancers all have a default error page that is shown to
        an end user who is attempting to access a load balancer node
        that is offline/unavailable.
        """
        return loadbalancer.get_error_page()


    @assure_loadbalancer
    def set_error_page(self, loadbalancer, html):
        """
        A single custom error page may be added per account load balancer
        with an HTTP protocol. Page updates will override existing content.
        If a custom error page is deleted, or the load balancer is changed
        to a non-HTTP protocol, the default error page will be restored.
        """
        return loadbalancer.set_error_page(html)


    @assure_loadbalancer
    def clear_error_page(self, loadbalancer):
        """
        Resets the error page to the default.
        """
        return loadbalancer.clear_error_page()


    @assure_loadbalancer
    def get_connection_logging(self, loadbalancer):
        """
        Returns the current setting for connection logging for the load balancer.
        """
        return loadbalancer.connection_logging


    @assure_loadbalancer
    def set_connection_logging(self, loadbalancer, val):
        """
        Sets connection logging for the load balancer to either True
        or False.
        """
        loadbalancer.connection_logging = val


    @assure_loadbalancer
    def get_content_caching(self, loadbalancer):
        """
        Returns the current setting for content caching for the load balancer.
        """
        return loadbalancer.content_caching


    @assure_loadbalancer
    def set_content_caching(self, loadbalancer, val):
        """
        Sets content caching for the load balancer to either True
        or False.
        """
        loadbalancer.content_caching = val


    @assure_loadbalancer
    def get_session_persistence(self, loadbalancer):
        """
        Returns the current setting for session persistence for
        the load balancer.
        """
        return loadbalancer.session_persistence


    @assure_loadbalancer
    def set_session_persistence(self, loadbalancer, val):
        """
        Sets the type of session persistence for the load balancer. This
        must be one of either "HTTP_COOKIE" or "SOURCE_IP", depending
        on the type of load balancing.
        """
        loadbalancer.session_persistence = val

    # END pass-through methods ##

########NEW FILE########
__FILENAME__ = cloudmonitoring
#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Copyright 2013 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

import re

from pyrax.client import BaseClient
import pyrax.exceptions as exc
from pyrax.manager import BaseManager
from pyrax.resource import BaseResource
import pyrax.utils as utils


_invalid_key_pat = re.compile(r"Validation error for key '([^']+)'")


def _params_to_dict(params, dct, local_dict):
    for param in params:
        val = local_dict.get(param)
        if val is None:
            continue
        dct[param] = val
    return dct



class CloudMonitorEntity(BaseResource):
    def update(self, agent=None, metadata=None):
        """
        Only the agent_id and metadata are able to be updated via the API.
        """
        self.manager.update_entity(self, agent=agent, metadata=metadata)


    def list_checks(self):
        """
        Returns a list of all CloudMonitorChecks defined for this entity.
        """
        return self.manager.list_checks(self)


    def delete_check(self, check):
        """
        Deletes the specified check from this entity.
        """
        return self.manager.delete_check(self, check)


    def list_metrics(self, check):
        """
        Returns a list of all the metrics associated with the specified check.
        """
        return self.manager.list_metrics(self, check)


    def get_metric_data_points(self, check, metric, start, end, points=None,
            resolution=None, stats=None):
        """
        Returns the data points for a given metric for the given period. The
        'start' and 'end' times must be specified; they can be be either Python
        date/datetime values, or a Unix timestamp.

        The 'points' parameter represents the number of points to return. The
        'resolution' parameter represents the granularity of the data. You must
        specify either 'points' or 'resolution'. The allowed values for
        resolution are:
            FULL
            MIN5
            MIN20
            MIN60
            MIN240
            MIN1440

        Finally, the 'stats' parameter specifies the stats you want returned.
        By default only the 'average' is returned. You omit this parameter,
        pass in a single value, or pass in a list of values. The allowed values
        are:
            average
            variance
            min
            max
        """
        return self.manager.get_metric_data_points(self, check, metric, start,
                end, points=points, resolution=resolution, stats=stats)


    def create_alarm(self, check, notification_plan, criteria=None,
            disabled=False, label=None, name=None, metadata=None):
        """
        Creates an alarm that binds the check on this entity with a
        notification plan.
        """
        return self.manager.create_alarm(self, check, notification_plan,
                criteria=criteria, disabled=disabled, label=label, name=name,
                metadata=metadata)


    def update_alarm(self, alarm, criteria=None, disabled=False,
            label=None, name=None, metadata=None):
        """
        Updates an existing alarm on this entity.
        """
        return self.manager.update_alarm(self, alarm, criteria=criteria,
                disabled=disabled, label=label, name=name, metadata=metadata)


    def list_alarms(self):
        """
        Returns a list of all the alarms created on this entity.
        """
        return self.manager.list_alarms(self)


    def get_alarm(self, alarm):
        """
        Returns the alarm with the specified ID for this entity. If a
        CloudMonitorAlarm instance is passed, returns a new CloudMonitorAlarm
        object with the current state from the API.
        """
        return self.manager.get_alarm(self, alarm)


    def delete_alarm(self, alarm):
        """
        Deletes the specified alarm.
        """
        return self.manager.delete_alarm(self, alarm)


    @property
    def name(self):
        return self.label



class CloudMonitorNotificationManager(BaseManager):
    """
    Handles all of the requests dealing with notifications.
    """
    def create(self, notification_type, label=None, name=None, details=None):
        """
        Defines a notification for handling an alarm.
        """
        uri = "/%s" % self.uri_base
        body = {"label": label or name,
                "type": utils.get_id(notification_type),
                "details": details,
                }
        resp, resp_body = self.api.method_post(uri, body=body)
        return self.get(resp["x-object-id"])


    def test_notification(self, notification=None, notification_type=None,
            details=None):
        """
        This allows you to test either an existing notification, or a potential
        notification before creating it. The actual notification comes from the
        same server where the actual alert messages come from. This allow you
        to, among other things, verify that your firewall is configured
        properly.

        To test an existing notification, pass it as the 'notification'
        parameter and leave the other parameters empty. To pre-test a
        notification before creating it, leave 'notification' empty, but pass
        in the 'notification_type' and 'details'.
        """
        if notification:
            # Test an existing notification
            uri = "/%s/%s/test" % (self.uri_base, utils.get_id(notification))
            body = None
        else:
            uri = "/test-notification"
            body = {"type": utils.get_id(notification_type),
                    "details": details}
        resp, resp_body = self.api.method_post(uri, body=body)


    def update_notification(self, notification, details):
        """
        Updates the specified notification with the supplied details.
        """
        if isinstance(notification, CloudMonitorNotification):
            nid = notification.id
            ntyp = notification.type
        else:
            # Supplied an ID
            nfcn = self.get(notification)
            nid = notification
            ntyp = nfcn.type
        uri = "/%s/%s" % (self.uri_base, nid)
        body = {"type": ntyp,
                "details": details}
        resp, resp_body = self.api.method_put(uri, body=body)


    def list_types(self):
        """
        Returns a list of all available notification types.
        """
        uri = "/notification_types"
        resp, resp_body = self.api.method_get(uri)
        return [CloudMonitorNotificationType(self, info)
                for info in resp_body["values"]]


    def get_type(self, notification_type_id):
        """
        Returns a CloudMonitorNotificationType object for the given ID.
        """
        uri = "/notification_types/%s" % utils.get_id(notification_type_id)
        resp, resp_body = self.api.method_get(uri)
        return CloudMonitorNotificationType(self, resp_body)



class CloudMonitorNotificationPlanManager(BaseManager):
    """
    Handles all of the requests dealing with Notification Plans.
    """
    def create(self, label=None, name=None, critical_state=None, ok_state=None,
            warning_state=None):
        """
        Creates a notification plan to be executed when a monitoring check
        triggers an alarm. You can optionally label (or name) the plan.

        A plan consists of one or more notifications to be executed when an
        associated alarm is triggered. You can have different lists of actions
        for CRITICAL, WARNING or OK states.
        """
        uri = "/%s" % self.uri_base
        body = {"label": label or name}

        def make_list_of_ids(parameter):
            params = utils.coerce_string_to_list(parameter)
            return [utils.get_id(param) for param in params]

        if critical_state:
            critical_state = utils.coerce_string_to_list(critical_state)
            body["critical_state"] = make_list_of_ids(critical_state)
        if warning_state:
            warning_state = utils.coerce_string_to_list(warning_state)
            body["warning_state"] = make_list_of_ids(warning_state)
        if ok_state:
            ok_state = utils.coerce_string_to_list(ok_state)
            body["ok_state"] = make_list_of_ids(ok_state)
        resp, resp_body = self.api.method_post(uri, body=body)
        return self.get(resp["x-object-id"])


class CloudMonitorEntityManager(BaseManager):
    """
    Handles all of the entity-specific requests.
    """
    def _create_body(self, name, label=None, agent=None, ip_addresses=None,
            metadata=None):
        """
        Used to create the dict required to create various resources. Accepts
        either 'label' or 'name' as the keyword parameter for the label
        attribute for entities.
        """
        label = label or name
        if ip_addresses is not None:
            body = {"label": label}
            if ip_addresses:
                body["ip_addresses"] = ip_addresses
            if agent:
                body["agent_id"] = utils.get_id(agent)
            if metadata:
                body["metadata"] = metadata
        return body


    def update_entity(self, entity, agent=None, metadata=None):
        """
        Updates the specified entity's values with the supplied parameters.
        """
        body = {}
        if agent:
            body["agent_id"] = utils.get_id(agent)
        if metadata:
            body["metadata"] = metadata
        if body:
            uri = "/%s/%s" % (self.uri_base, utils.get_id(entity))
            resp, body = self.api.method_put(uri, body=body)


    def list_checks(self, entity):
        """
        Returns a list of all CloudMonitorChecks defined for this entity.
        """
        uri = "/%s/%s/checks" % (self.uri_base, utils.get_id(entity))
        resp, resp_body = self.api.method_get(uri)
        return [CloudMonitorCheck(self, val, entity)
                for val in resp_body["values"]]


    def create_check(self, entity, label=None, name=None, check_type=None,
            details=None, disabled=False, metadata=None,
            monitoring_zones_poll=None, timeout=None, period=None,
            target_alias=None, target_hostname=None, target_receiver=None,
            test_only=False, include_debug=False):
        """
        Creates a check on the entity with the specified attributes. The
        'details' parameter should be a dict with the keys as the option name,
        and the value as the desired setting.

        If the 'test_only' parameter is True, then the check is not created;
        instead, the check is run and the results of the test run returned. If
        'include_debug' is True, additional debug information is returned.
        According to the current Cloud Monitoring docs:
            "Currently debug information is only available for the
            remote.http check and includes the response body."
        """
        if details is None:
            raise exc.MissingMonitoringCheckDetails("The required 'details' "
                    "parameter was not passed to the create_check() method.")
        if not (target_alias or target_hostname):
            raise exc.MonitoringCheckTargetNotSpecified("You must specify "
                    "either the 'target_alias' or 'target_hostname' when "
                    "creating a check.")
        ctype = utils.get_id(check_type)
        is_remote = ctype.startswith("remote")
        monitoring_zones_poll = utils.coerce_string_to_list(
                monitoring_zones_poll)
        monitoring_zones_poll = [utils.get_id(mzp)
                for mzp in monitoring_zones_poll]
        if is_remote and not monitoring_zones_poll:
            raise exc.MonitoringZonesPollMissing("You must specify the "
                    "'monitoring_zones_poll' parameter for remote checks.")
        body = {"label": label or name,
                "details": details,
                "disabled": disabled,
                "type": utils.get_id(check_type),
                }
        params = ("monitoring_zones_poll", "timeout", "period",
                "target_alias", "target_hostname", "target_receiver")
        body = _params_to_dict(params, body, locals())
        if test_only:
            uri = "/%s/%s/test-check" % (self.uri_base, entity.id)
            if include_debug:
                uri = "%s?debug=true" % uri
        else:
            uri = "/%s/%s/checks" % (self.uri_base, entity.id)
        try:
            resp, resp_body = self.api.method_post(uri, body=body)
        except exc.BadRequest as e:
            msg = e.message
            dtls = e.details
            match = _invalid_key_pat.match(msg)
            if match:
                missing = match.groups()[0].replace("details.", "")
                if missing in details:
                    errcls = exc.InvalidMonitoringCheckDetails
                    errmsg = "".join(["The value passed for '%s' in the ",
                            "details parameter is not valid."]) % missing
                else:
                    errmsg = "".join(["The required value for the '%s' ",
                            "setting is missing from the 'details' ",
                            "parameter."]) % missing
                    utils.update_exc(e, errmsg)
                raise e
            else:
                if msg == "Validation error":
                    # Info is in the 'details'
                    raise exc.InvalidMonitoringCheckDetails("Validation "
                            "failed. Error: '%s'." % dtls)
        else:
            status = resp["status"]
            if status == "201":
                check_id = resp["x-object-id"]
                return self.get_check(entity, check_id)


    def find_all_checks(self, entity, **kwargs):
        """
        Finds all checks for a given entity with attributes matching
        ``**kwargs``.

        This isn't very efficient: it loads the entire list then filters on
        the Python side.
        """
        found = []
        searches = kwargs.items()
        for obj in self.list_checks(entity):
            try:
                if all(getattr(obj, attr) == value
                        for (attr, value) in searches):
                    found.append(obj)
            except AttributeError:
                continue
        return found


    def update_check(self, check, label=None, name=None, disabled=None,
            metadata=None, monitoring_zones_poll=None, timeout=None,
            period=None, target_alias=None, target_hostname=None,
            target_receiver=None):
        if monitoring_zones_poll:
            monitoring_zones_poll = utils.coerce_string_to_list(
                    monitoring_zones_poll)
            monitoring_zones_poll = [utils.get_id(mzp)
                    for mzp in monitoring_zones_poll]
        body = {}
        local_dict = locals()
        label = label or name
        params = ("label", "disabled", "metadata", "monitoring_zones_poll",
                "timeout", "period", "target_alias", "target_hostname",
                "target_receiver")
        body = _params_to_dict(params, body, locals())
        entity = check.entity
        uri = "/%s/%s/checks/%s" % (self.uri_base, utils.get_id(entity),
                utils.get_id(check))
        try:
            resp, resp_body = self.api.method_put(uri, body=body)
        except exc.BadRequest as e:
            msg = e.message
            dtls = e.details
            if msg.startswith("Validation error"):
                raise exc.InvalidMonitoringCheckUpdate("The update failed "
                        "validation: %s: %s" % (msg, dtls))
            else:
                # Some other issue.
                raise
        return resp_body


    def get_check(self, entity, check):
        """
        Returns the current version of the check for the entity.
        """
        uri = "/%s/%s/checks/%s" % (self.uri_base, utils.get_id(entity),
                utils.get_id(check))
        resp, resp_body = self.api.method_get(uri)
        return CloudMonitorCheck(self, resp_body, entity)


    def delete_check(self, entity, check):
        """
        Deletes the specified check from the entity.
        """
        uri = "/%s/%s/checks/%s" % (self.uri_base, utils.get_id(entity),
                utils.get_id(check))
        resp, resp_body = self.api.method_delete(uri)


    def list_metrics(self, entity, check):
        """
        Returns a list of all the metrics associated with the specified check.
        """
        uri = "/%s/%s/checks/%s/metrics" % (self.uri_base,
                utils.get_id(entity), utils.get_id(check))
        resp, resp_body = self.api.method_get(uri)
        metrics = [val["name"]
                for val in resp_body["values"]]
        return metrics


    def get_metric_data_points(self, entity, check, metric, start, end,
            points=None, resolution=None, stats=None):
        """
        Returns the data points for a given metric for the given period. The
        'start' and 'end' times must be specified; they can be be either Python
        date/datetime values, a string representing a date/datetime in either
        of 'YYYY-MM-DD HH:MM:SS' or 'YYYY-MM-DD' formats, or a Unix timestamp:

        The 'points' parameter represents the number of points to return. The
        'resolution' parameter represents the granularity of the data. You must
        specify either 'points' or 'resolution', but not both. The allowed
        values for resolution are: 'FULL', 'MIN5', 'MIN20', 'MIN60', 'MIN240',
        and 'MIN1440'.

        Finally, the 'stats' parameter specifies the stats you want returned.
        By default only the 'average' is returned. You omit this parameter,
        pass in a single value, or pass in a list of values. The allowed values
        are: 'average', 'variance', 'min', and 'max'
        """
        allowed_resolutions = ("FULL", "MIN5", "MIN20", "MIN60", "MIN240",
                "MIN1440")
        if not (points or resolution):
            raise exc.MissingMonitoringCheckGranularity("You must specify "
                    "either the 'points' or 'resolution' parameter when "
                    "fetching metrics.")
        if resolution:
            if resolution.upper() not in allowed_resolutions:
                raise exc.InvalidMonitoringMetricsResolution("The specified "
                        "resolution '%s' is not valid. The valid values are: "
                        "%s." % (resolution, str(allowed_resolutions)))
        start_tm = utils.to_timestamp(start)
        end_tm = utils.to_timestamp(end)
        # NOTE: For some odd reason, the timestamps required for this must be
        # in milliseconds, instead of the UNIX standard for timestamps, which
        # is in seconds. So the values here are multiplied by 1000 to make it
        # work. If the API is ever corrected, the next two lines should be
        # removed. GitHub #176.
        start_tm *= 1000
        end_tm *= 1000
        qparms = []
        # Timestamps with fractional seconds currently cause a 408 (timeout)
        qparms.append("from=%s" % int(start_tm))
        qparms.append("to=%s" % int(end_tm))
        if points:
            qparms.append("points=%s" % points)
        if resolution:
            qparms.append("resolution=%s" % resolution.upper())
        if stats:
            stats = utils.coerce_string_to_list(stats)
            for stat in stats:
                qparms.append("select=%s" % stat)
        qparm = "&".join(qparms)
        uri = "/%s/%s/checks/%s/metrics/%s/plot?%s" % (self.uri_base,
                utils.get_id(entity), utils.get_id(check), metric, qparm)
        try:
            resp, resp_body = self.api.method_get(uri)
        except exc.BadRequest as e:
            msg = e.message
            dtls = e.details
            if msg.startswith("Validation error"):
                raise exc.InvalidMonitoringMetricsRequest("Your request was "
                        "invalid: '%s'" % dtls)
            else:
                raise
        return resp_body["values"]


    def create_alarm(self, entity, check, notification_plan, criteria=None,
            disabled=False, label=None, name=None, metadata=None):
        """
        Creates an alarm that binds the check on the given entity with a
        notification plan.

        Note that the 'criteria' parameter, if supplied, should be a string
        representing the DSL for describing alerting conditions and their
        output states. Pyrax does not do any validation of these criteria
        statements; it is up to you as the developer to understand the language
        and correctly form the statement. This alarm language is documented
        online in the Cloud Monitoring section of http://docs.rackspace.com.
        """
        uri = "/%s/%s/alarms" % (self.uri_base, utils.get_id(entity))
        body = {"check_id": utils.get_id(check),
                "notification_plan_id": utils.get_id(notification_plan),
                }
        if criteria:
            body["criteria"] = criteria
        if disabled is not None:
            body["disabled"] = disabled
        label_name = label or name
        if label_name:
            body["label"] = label_name
        if metadata:
            body["metadata"] = metadata
        resp, resp_body = self.api.method_post(uri, body=body)

        status = resp["status"]
        if status == "201":
            alarm_id = resp["x-object-id"]
            return self.get_alarm(entity, alarm_id)

    def update_alarm(self, entity, alarm, criteria=None, disabled=False,
            label=None, name=None, metadata=None):
        """
        Updates an existing alarm on the given entity. See the comments on the
        'create_alarm()' regarding the criteria parameter.
        """
        uri = "/%s/%s/alarms/%s" % (self.uri_base, utils.get_id(entity),
                utils.get_id(alarm))
        body = {}
        if criteria:
            body["criteria"] = criteria
        if disabled is not None:
            body["disabled"] = disabled
        label_name = label or name
        if label_name:
            body["label"] = label_name
        if metadata:
            body["metadata"] = metadata
        resp, resp_body = self.api.method_put(uri, body=body)


    def list_alarms(self, entity):
        """
        Returns a list of all the alarms created on the specified entity.
        """
        uri = "/%s/%s/alarms" % (self.uri_base, utils.get_id(entity))
        resp, resp_body = self.api.method_get(uri)
        return [CloudMonitorAlarm(self, dct, entity)
                for dct in resp_body["values"]]


    def get_alarm(self, entity, alarm):
        """
        Returns the alarm with the specified ID for this entity. If a
        CloudMonitorAlarm instance is passed, returns a new CloudMonitorAlarm
        object with the current state from the API.
        """
        uri = "/%s/%s/alarms/%s" % (self.uri_base, utils.get_id(entity),
                utils.get_id(alarm))
        resp, resp_body = self.api.method_get(uri)
        return CloudMonitorAlarm(self, resp_body, entity)


    def delete_alarm(self, entity, alarm):
        """
        Deletes the specified alarm.
        """
        uri = "/%s/%s/alarms/%s" % (self.uri_base, utils.get_id(entity),
                utils.get_id(alarm))
        resp, resp_body = self.api.method_delete(uri)



class CloudMonitorChangelogManager(BaseManager):
    """
    Handles calls to retrieve changelogs.
    """
    def list(self, entity=None):
        """
        Returns a dictionary of changelog data, optionally filtered for a given
        entity.
        """
        uri = "/%s" % self.uri_base
        if entity:
            uri = "%s?entityId=%s" % (uri, utils.get_id(entity))
        resp, resp_body = self._list(uri, return_raw=True)
        return resp_body



class CloudMonitorOverviewManager(BaseManager):
    """
    Handles calls to retrieve overview information.
    """
    def list(self, entity=None):
        """
        Returns overview information, optionally filtered for a given entity.
        """
        uri = "/%s" % self.uri_base
        if entity:
            uri = "%s?entityId=%s" % (uri, utils.get_id(entity))
        resp, resp_body = self._list(uri, return_raw=True)
        return resp_body



class CloudMonitorCheck(BaseResource):
    """
    Represents a check defined for an entity.
    """
    def __init__(self, manager, info, entity, key=None, loaded=False):
        super(CloudMonitorCheck, self).__init__(manager, info, key=key,
                loaded=loaded)
        if not isinstance(entity, CloudMonitorEntity):
            entity = manager.get(entity)
        self.entity = entity


    @property
    def name(self):
        return self.label


    def get(self):
        """Reloads the check with its current values."""
        new = self.manager.get_check(self.entity, self)
        if new:
            self._add_details(new._info)

    reload = get


    def update(self, label=None, name=None, disabled=None, metadata=None,
            monitoring_zones_poll=None, timeout=None, period=None,
            target_alias=None, target_hostname=None, target_receiver=None):
        """
        Updates an existing check with any of the parameters.
        """
        self.manager.update_check(self, label=label, name=name,
                disabled=disabled, metadata=metadata,
                monitoring_zones_poll=monitoring_zones_poll, timeout=timeout,
                period=period, target_alias=target_alias,
                target_hostname=target_hostname,
                target_receiver=target_receiver)


    def delete(self):
        """Removes this check from its entity."""
        self.manager.delete_check(self.entity, self)


    def list_metrics(self):
        """
        Returns a list of all the metrics associated with this check.
        """
        return self.manager.list_metrics(self.entity, self)


    def get_metric_data_points(self, metric, start, end, points=None,
            resolution=None, stats=None):
        """
        Returns the data points for a given metric for the given period. The
        'start' and 'end' times must be specified; they can be be either Python
        date/datetime values, or a Unix timestamp.

        The 'points' parameter represents the number of points to return. The
        'resolution' parameter represents the granularity of the data. You must
        specify either 'points' or 'resolution'. The allowed values for
        resolution are:
            FULL
            MIN5
            MIN20
            MIN60
            MIN240
            MIN1440

        Finally, the 'stats' parameter specifies the stats you want returned.
        By default only the 'average' is returned. You omit this parameter,
        pass in a single value, or pass in a list of values. The allowed values
        are:
            average
            variance
            min
            max
        """
        return self.manager.get_metric_data_points(self.entity, self, metric,
                start, end, points=points, resolution=resolution, stats=stats)


    def create_alarm(self, notification_plan, criteria=None, disabled=False,
            label=None, name=None, metadata=None):
        """
        Creates an alarm that binds this check with a notification plan.
        """
        return self.manager.create_alarm(self.entity, self, notification_plan,
                criteria=criteria, disabled=disabled, label=label, name=name,
                metadata=metadata)



class CloudMonitorCheckType(BaseResource):
    """
    Represents the type of monitor check to be run. Each check type
    """
    @property
    def field_names(self):
        """
        Returns a list of all field names for this check type.
        """
        return [field["name"] for field in self.fields]


    @property
    def required_field_names(self):
        """
        Returns a list of the names of all required fields for this check type.
        """
        return [field["name"] for field in self.fields
                if not field["optional"]]


    @property
    def optional_field_names(self):
        """
        Returns a list of the names of all optional fields for this check type.
        """
        return [field["name"] for field in self.fields
                if field["optional"]]



class CloudMonitorZone(BaseResource):
    """
    Represents a location from which Cloud Monitoring collects data.
    """
    @property
    def name(self):
        return self.label



class CloudMonitorNotification(BaseResource):
    """
    Represents an action to take when an alarm is triggered.
    """
    @property
    def name(self):
        return self.label


    def update(self, details):
        """
        Updates this notification with the supplied details.
        """
        return self.manager.update_notification(self, details)



class CloudMonitorNotificationType(BaseResource):
    """
    Represents a class of action to take when an alarm is triggered.
    """
    @property
    def name(self):
        return self.label



class CloudMonitorNotificationPlan(BaseResource):
    """
    A Notification plan is a list of the notification actions to take when an
    alarm is triggered.
    """
    @property
    def name(self):
        return self.label



class CloudMonitorAlarm(BaseResource):
    """
    Alarms bind alerting rules, entities, and notification plans into a logical
    unit.
    """
    def __init__(self, manager, info, entity, key=None, loaded=False):
        super(CloudMonitorAlarm, self).__init__(manager, info, key=key,
                loaded=loaded)
        if not isinstance(entity, CloudMonitorEntity):
            entity = manager.get(entity)
        self.entity = entity


    def update(self, criteria=None, disabled=False, label=None, name=None,
            metadata=None):
        """
        Updates this alarm.
        """
        return self.entity.update_alarm(self, criteria=criteria,
                disabled=disabled, label=label, name=name, metadata=metadata)


    def get(self):
        """
        Fetches the current state of the alarm from the API and updates the
        object.
        """
        new_alarm = self.entity.get_alarm(self)
        if new_alarm:
            self._add_details(new_alarm._info)
    # Alias reload() to get()
    reload = get


    @property
    def name(self):
        return self.label



class CloudMonitorClient(BaseClient):
    """
    This is the base client for creating and managing Cloud Monitoring.
    """

    def __init__(self, *args, **kwargs):
        super(CloudMonitorClient, self).__init__(*args, **kwargs)
        self.name = "Cloud Monitoring"


    def _configure_manager(self):
        """
        Creates the Manager instances to handle monitoring.
        """
        self._entity_manager = CloudMonitorEntityManager(self,
                uri_base="entities", resource_class=CloudMonitorEntity,
                response_key=None, plural_response_key=None)
        self._check_type_manager = BaseManager(self,
                uri_base="check_types", resource_class=CloudMonitorCheckType,
                response_key=None, plural_response_key=None)
        self._monitoring_zone_manager = BaseManager(self,
                uri_base="monitoring_zones", resource_class=CloudMonitorZone,
                response_key=None, plural_response_key=None)
        self._notification_manager = CloudMonitorNotificationManager(self,
                uri_base="notifications",
                resource_class=CloudMonitorNotification,
                response_key=None, plural_response_key=None)
        self._notification_plan_manager = CloudMonitorNotificationPlanManager(
                self, uri_base="notification_plans",
                resource_class=CloudMonitorNotificationPlan,
                response_key=None, plural_response_key=None)
        self._changelog_manager = CloudMonitorChangelogManager(self,
                uri_base="changelogs/alarms", resource_class=None,
                response_key=None, plural_response_key=None)
        self._overview_manager = CloudMonitorOverviewManager(self,
                uri_base="views/overview", resource_class=None,
                response_key="value", plural_response_key=None)


    def get_account(self):
        """
        Returns a dict with the following keys: id, webhook_token, and metadata.
        """
        resp, resp_body = self.method_get("/account")
        return resp_body


    def get_audits(self):
        """
        Every write operation performed against the API (PUT, POST or DELETE)
        generates an audit record that is stored for 30 days. Audits record a
        variety of information about the request including the method, URL,
        headers, query string, transaction ID, the request body and the
        response code. They also store information about the action performed
        including a JSON list of the previous state of any modified objects.
        For example, if you perform an update on an entity, this will record
        the state of the entity before modification.
        """
        resp, resp_body = self.method_get("/audits")
        return resp_body["values"]


    def list_entities(self):
        return self._entity_manager.list()


    def get_entity(self, entity):
        return self._entity_manager.get(entity)


    def create_entity(self, label=None, name=None, agent=None,
            ip_addresses=None, metadata=None):
        # NOTE: passing a non-None value for ip_addresses is required so that
        # the _create_body() method can distinguish this as a request for a
        # body dict for entities.
        ip_addresses = ip_addresses or {}
        resp = self._entity_manager.create(label=label, name=name, agent=agent,
                ip_addresses=ip_addresses, metadata=metadata,
                return_response=True)
        status = resp["status"]
        if status == "201":
            ent_id = resp["x-object-id"]
            return self.get_entity(ent_id)


    def update_entity(self, entity, agent=None, metadata=None):
        """
        Only the agent_id and metadata are able to be updated via the API.
        """
        self._entity_manager.update_entity(entity, agent=agent,
                metadata=metadata)


    def delete_entity(self, entity):
        """Deletes the specified entity."""
        self._entity_manager.delete(entity)


    def list_check_types(self):
        return self._check_type_manager.list()


    def get_check_type(self, check_type):
        return self._check_type_manager.get(check_type)


    def list_checks(self, entity):
        return self._entity_manager.list_checks(entity)


    def create_check(self, entity, label=None, name=None, check_type=None,
            disabled=False, metadata=None, details=None,
            monitoring_zones_poll=None, timeout=None, period=None,
            target_alias=None, target_hostname=None, target_receiver=None,
            test_only=False, include_debug=False):
        """
        Creates a check on the entity with the specified attributes. The
        'details' parameter should be a dict with the keys as the option name,
        and the value as the desired setting.
        """
        return self._entity_manager.create_check(entity, label=label,
                name=name, check_type=check_type, disabled=disabled,
                metadata=metadata, details=details,
                monitoring_zones_poll=monitoring_zones_poll, timeout=timeout,
                period=period, target_alias=target_alias,
                target_hostname=target_hostname,
                target_receiver=target_receiver, test_only=test_only,
                include_debug=include_debug)


    def get_check(self, entity, check):
        """Returns the current check for the given entity."""
        return self._entity_manager.get_check(entity, check)


    def find_all_checks(self, entity, **kwargs):
        """
        Finds all checks for a given entity with attributes matching
        ``**kwargs``.

        This isn't very efficient: it loads the entire list then filters on
        the Python side.
        """
        return self._entity_manager.find_all_checks(entity, **kwargs)


    def update_check(self, entity, check, label=None, name=None, disabled=None,
            metadata=None, monitoring_zones_poll=None, timeout=None,
            period=None, target_alias=None, target_hostname=None,
            target_receiver=None):
        """
        Updates an existing check with any of the parameters.
        """
        self._entity_manager.update_check(entity, check, label=label,
                name=name, disabled=disabled, metadata=metadata,
                monitoring_zones_poll=monitoring_zones_poll, timeout=timeout,
                period=period, target_alias=target_alias,
                target_hostname=target_hostname,
                target_receiver=target_receiver)


    def delete_check(self, entity, check):
        """
        Deletes the specified check from the entity.
        """
        return self._entity_manager.delete_check(entity, check)


    def list_metrics(self, entity, check):
        """
        Returns a list of all the metrics associated with the specified check.
        """
        return self._entity_manager.list_metrics(entity, check)


    def get_metric_data_points(self, entity, check, metric, start, end,
            points=None, resolution=None, stats=None):
        """
        Returns the data points for a given metric for the given period. The
        'start' and 'end' times must be specified; they can be be either Python
        date/datetime values, or a Unix timestamp.

        The 'points' parameter represents the number of points to return. The
        'resolution' parameter represents the granularity of the data. You must
        specify either 'points' or 'resolution'. The allowed values for
        resolution are:
            FULL
            MIN5
            MIN20
            MIN60
            MIN240
            MIN1440

        Finally, the 'stats' parameter specifies the stats you want returned.
        By default only the 'average' is returned. You omit this parameter,
        pass in a single value, or pass in a list of values. The allowed values
        are:
            average
            variance
            min
            max
        """
        return self._entity_manager.get_metric_data_points(entity, check,
                metric, start, end, points=points, resolution=resolution,
                stats=stats)


    def list_notifications(self):
        """Returns a list of all defined notifications."""
        return self._notification_manager.list()


    def get_notification(self, notification_id):
        """
        Returns the CloudMonitorNotification object for the specified ID.
        """
        return self._notification_manager.get(notification_id)


    def test_notification(self, notification=None, notification_type=None,
            details=None):
        """
        This allows you to test either an existing notification, or a potential
        notification before creating it. The actual notification comes from the
        same server where the actual alert messages come from. This allow you
        to, among other things, verify that your firewall is configured
        properly.

        To test an existing notification, pass it as the 'notification'
        parameter and leave the other parameters empty. To pre-test a
        notification before creating it, leave 'notification' empty, but pass
        in the 'notification_type' and 'details'.
        """
        return self._notification_manager.test_notification(
                notification=notification, notification_type=notification_type,
                details=details)


    def create_notification(self, notification_type, label=None, name=None,
            details=None):
        """
        Defines a notification for handling an alarm.
        """
        return self._notification_manager.create(notification_type,
                label=label, name=name, details=details)


    def update_notification(self, notification, details):
        """
        Updates the specified notification with the supplied details.
        """
        return self._notification_manager.update_notification(notification,
                details)


    def delete_notification(self, notification):
        """
        Deletes the specified notification.
        """
        return self._notification_manager.delete(notification)


    def create_notification_plan(self, label=None, name=None,
            critical_state=None, ok_state=None, warning_state=None):
        """
        Creates a notification plan to be executed when a monitoring check
        triggers an alarm.
        """
        return self._notification_plan_manager.create(label=label, name=name,
                critical_state=critical_state, ok_state=ok_state,
                warning_state=warning_state)


    def list_notification_plans(self):
        """
        Returns a list of all defined notification plans.
        """
        return self._notification_plan_manager.list()


    def get_notification_plan(self, notification_plan_id):
        """
        Returns the CloudMonitorNotificationPlan object for the specified ID.
        """
        return self._notification_plan_manager.get(notification_plan_id)


    def delete_notification_plan(self, notification_plan):
        """
        Deletes the specified notification plan.
        """
        return self._notification_plan_manager.delete(notification_plan)


    def create_alarm(self, entity, check, notification_plan, criteria=None,
            disabled=False, label=None, name=None, metadata=None):
        """
        Creates an alarm that binds the check on the given entity with a
        notification plan.
        """
        return self._entity_manager.create_alarm(entity, check,
            notification_plan, criteria=criteria, disabled=disabled,
            label=label, name=name, metadata=metadata)


    def update_alarm(self, entity, alarm, criteria=None, disabled=False,
            label=None, name=None, metadata=None):
        """
        Updates an existing alarm on the given entity.
        """
        return self._entity_manager.update_alarm(entity, alarm,
                criteria=criteria, disabled=disabled, label=label, name=name,
                metadata=metadata)


    def list_alarms(self, entity):
        """
        Returns a list of all the alarms created on the specified entity.
        """
        return self._entity_manager.list_alarms(entity)


    def get_alarm(self, entity, alarm_id):
        """
        Returns the alarm with the specified ID for the entity.
        """
        return self._entity_manager.get_alarm(entity, alarm_id)


    def delete_alarm(self, entity, alarm):
        """
        Deletes the specified alarm.
        """
        return self._entity_manager.delete_alarm(entity, alarm)


    def list_notification_types(self):
        return self._notification_manager.list_types()


    def get_notification_type(self, nt_id):
        return self._notification_manager.get_type(nt_id)


    def list_monitoring_zones(self):
        """
        Returns a list of all available monitoring zones.
        """
        return self._monitoring_zone_manager.list()


    def get_monitoring_zone(self, mz_id):
        """
        Returns the monitoring zone for the given ID.
        """
        return self._monitoring_zone_manager.get(mz_id)


    def get_changelogs(self, entity=None):
        """
        Returns a dictionary containing the changelogs. The monitoring service
        records changelogs for alarm statuses.

        You may supply an entity to filter the results to show only the alarms
        for the specified entity.
        """
        return self._changelog_manager.list(entity=entity)


    def get_overview(self, entity=None):
        """
        Returns a dictionary containing the overview information.

        Views contain a combination of data that usually includes multiple,
        different objects. The primary purpose of a view is to save API calls
        and make data retrieval more efficient. Instead of doing multiple API
        calls and then combining the result yourself, you can perform a single
        API call against the view endpoint.

        You may supply an entity to filter the results to show only the data
        for the specified entity.
        """
        return self._overview_manager.list(entity=entity)


    #################################################################
    # The following methods are defined in the generic client class,
    # but don't have meaning in monitoring, as there is not a single
    # resource that defines this module.
    #################################################################
    def list(self, limit=None, marker=None):
        """Not applicable in Cloud Monitoring."""
        raise NotImplementedError

    def get(self, item):
        """Not applicable in Cloud Monitoring."""
        raise NotImplementedError

    def create(self, *args, **kwargs):
        """Not applicable in Cloud Monitoring."""
        raise NotImplementedError

    def delete(self, item):
        """Not applicable in Cloud Monitoring."""
        raise NotImplementedError

    def find(self, **kwargs):
        """Not applicable in Cloud Monitoring."""
        raise NotImplementedError

    def findall(self, **kwargs):
        """Not applicable in Cloud Monitoring."""
        raise NotImplementedError
    #################################################################

########NEW FILE########
__FILENAME__ = cloudnetworks
#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Copyright 2013 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from pyrax.client import BaseClient
import pyrax.exceptions as exc
from pyrax.manager import BaseManager
from pyrax.resource import BaseResource
import pyrax.utils as utils

# Constants to represent the 'special' network IDs.
PUBLIC_NET_ID = "00000000-0000-0000-0000-000000000000"
SERVICE_NET_ID = "11111111-1111-1111-1111-111111111111"
PSEUDO_NETWORKS = (PUBLIC_NET_ID, SERVICE_NET_ID)


def _get_server_networks(network, public=False, private=False):
    net_id = utils.get_id(network)
    ret = [{"net-id": net_id}]
    if public:
        ret.append({"net-id": PUBLIC_NET_ID})
    if private:
        ret.append({"net-id": SERVICE_NET_ID})
    return ret



class CloudNetwork(BaseResource):
    """
    This represents a network in the cloud. It can be either an isolated
    network, the public network, or the ServiceNet network.

    While resources generally use 'name' as the text identifier, the Cloud
    Networks API uses 'label' instead. This module aliases the attributes andi
    methods so that you can use either in your code.
    """
    id = None
    cidr = None
    label = None


    def _get_name(self):
        return self.label

    def _set_name(self, name):
        self.label = name

    name = property(_get_name, _set_name)


    @property
    def is_isolated(self):
        """Returns True if this is a user-defined network."""
        return self.id not in PSEUDO_NETWORKS


    def get(self):
        if not self.is_isolated:
            # These are placeholders, not actual networks
            return
        return super(CloudNetwork, self).get()


    def delete(self):
        """
        Wraps the standard delete() method to catch expected exceptions and
        raise the appropriate pyrax exceptions.
        """
        try:
            return super(CloudNetwork, self).delete()
        except exc.Forbidden as e:
            # Network is in use
            raise exc.NetworkInUse("Cannot delete a network in use by a server.")


    def get_server_networks(self, public=False, private=False):
        """
        Creates the dict of network UUIDs required by Cloud Servers when
        creating a new server with isolated networks.

        By default only this network is included. If you wish to create a
        server that has either the public (internet) or private (ServiceNet)
        networks, you have to pass those parameters in with values of True.
        """
        return _get_server_networks(self, public=public, private=private)



class CloudNetworkManager(BaseManager):
    """
    Does nothing special, but is used in testing.
    """
    def _create_body(self, name, label=None, cidr=None):
        """
        Used to create the dict required to create a network. Accepts either
        'label' or 'name' as the keyword parameter for the label attribute.
        """
        label = label or name
        body = {"network": {
                "label": label,
                "cidr": cidr,
                }}
        return body



class CloudNetworkClient(BaseClient):
    """
    This is the base client for creating and managing Cloud Networks.
    """

    def __init__(self, *args, **kwargs):
        super(CloudNetworkClient, self).__init__(*args, **kwargs)
        self.name = "Cloud Networks"
        # Constants to represent the 'special' network IDs.
        self.PUBLIC_NET_ID = PUBLIC_NET_ID
        self.SERVICE_NET_ID = SERVICE_NET_ID
        self.PSEUDO_NETWORKS = PSEUDO_NETWORKS


    def _configure_manager(self):
        """
        Creates the Manager instance to handle networks.
        """
        self._manager = CloudNetworkManager(self, resource_class=CloudNetwork,
                response_key="network", uri_base="os-networksv2")


    def create(self, label=None, name=None, cidr=None):
        """
        Wraps the basic create() call to handle specific failures.
        """
        try:
            return super(CloudNetworkClient, self).create(label=label,
                    name=name, cidr=cidr)
        except exc.BadRequest as e:
            msg = e.message
            if "too many networks" in msg:
                raise exc.NetworkCountExceeded("Cannot create network; the "
                        "maximum number of isolated networks already exist.")
            elif "does not contain enough" in msg:
                raise exc.NetworkCIDRInvalid("Networks must contain two or "
                        "more hosts; the CIDR '%s' is too restrictive." % cidr)
            elif "CIDR is malformed" in msg:
                raise exc.NetworkCIDRMalformed("The CIDR '%s' is not valid." % cidr)
            else:
                # Something unexpected
                raise


    def delete(self, network):
        """
        Wraps the standard delete() method to catch expected exceptions and
        raise the appropriate pyrax exceptions.
        """
        try:
            return super(CloudNetworkClient, self).delete(network)
        except exc.Forbidden as e:
            # Network is in use
            raise exc.NetworkInUse("Cannot delete a network in use by a server.")


    def find_network_by_label(self, label):
        """
        This is inefficient; it gets all the networks and then filters on
        the client side to find the matching name.
        """
        networks = self.list()
        match = [network for network in networks
                if network.label == label]
        if not match:
            raise exc.NetworkNotFound("No network with the label '%s' exists" %
                    label)
        elif len(match) > 1:
            raise exc.NetworkLabelNotUnique("There were %s matches for the label "
                    "'%s'." % (len(match), label))
        return match[0]
    # Create an alias using 'name'
    find_network_by_name = find_network_by_label


    def get_server_networks(self, network, public=False, private=False):
        """
        Creates the dict of network UUIDs required by Cloud Servers when
        creating a new server with isolated networks.

        By default only the specified network is included. If you wish to
        create a server that has either the public (internet) or private
        (ServiceNet) networks, you have to pass those parameters in with
        values of True.
        """
        return _get_server_networks(network, public=public, private=private)

########NEW FILE########
__FILENAME__ = exceptions
#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

# Since we use the novaclient package, we need to expose its exception
# classes here.
from novaclient import exceptions as _nova_exceptions
ServerNotFound = _nova_exceptions.NotFound
ServerClientException = _nova_exceptions.ClientException

class PyraxException(Exception):
    pass

class AccessListIDNotFound(PyraxException):
    pass

class AuthenticationFailed(PyraxException):
    pass

class AuthorizationFailure(PyraxException):
    pass

class AuthSystemNotFound(PyraxException):
    pass

class CDNFailed(PyraxException):
    pass

class DBUpdateUnchanged(PyraxException):
    pass

class DNSCallTimedOut(PyraxException):
    pass

class DomainCreationFailed(PyraxException):
    pass

class DomainDeletionFailed(PyraxException):
    pass

class DomainRecordAdditionFailed(PyraxException):
    pass

class DomainRecordDeletionFailed(PyraxException):
    pass

class DomainRecordNotFound(PyraxException):
    pass

class DomainRecordNotUnique(PyraxException):
    pass

class DomainRecordUpdateFailed(PyraxException):
    pass

class DomainUpdateFailed(PyraxException):
    pass

class DuplicateQueue(PyraxException):
    pass

class DuplicateUser(PyraxException):
    pass

class EndpointNotDefined(PyraxException):
    pass

class EndpointNotFound(PyraxException):
    pass

class EnvironmentNotFound(PyraxException):
    pass

class FlavorNotFound(PyraxException):
    pass

class FileNotFound(PyraxException):
    pass

class FolderNotFound(PyraxException):
    pass

class KeyringModuleNotInstalled(PyraxException):
    pass

class KeyringPasswordNotFound(PyraxException):
    pass

class KeyringUsernameMissing(PyraxException):
    pass

class IdentityClassNotDefined(PyraxException):
    pass

class InternalServerError(PyraxException):
    pass

class InvalidCDNMetadata(PyraxException):
    pass

class InvalidConfigurationFile(PyraxException):
    pass

class InvalidCredentialFile(PyraxException):
    pass

class InvalidDateTimeString(PyraxException):
    pass

class InvalidDeviceType(PyraxException):
    pass

class InvalidEmail(PyraxException):
    pass

class InvalidImageMember(PyraxException):
    pass

class InvalidImageMemberStatus(PyraxException):
    pass

class InvalidLoadBalancer(PyraxException):
    pass

class InvalidLoadBalancerParameters(PyraxException):
    pass

class InvalidImageMemberStatus(PyraxException):
    pass

class InvalidMonitoringCheckDetails(PyraxException):
    pass

class InvalidMonitoringCheckUpdate(PyraxException):
    pass

class InvalidMonitoringMetricsRequest(PyraxException):
    pass

class InvalidMonitoringMetricsResolution(PyraxException):
    pass

class InvalidNodeCondition(PyraxException):
    pass

class InvalidNodeParameters(PyraxException):
    pass

class InvalidPTRRecord(PyraxException):
    pass

class InvalidQueueName(PyraxException):
    pass

class InvalidSessionPersistenceType(PyraxException):
    pass

class InvalidSetting(PyraxException):
    pass

class InvalidSize(PyraxException):
    pass

class InvalidTemporaryURLMethod(PyraxException):
    pass

class InvalidUploadID(PyraxException):
    pass

class InvalidVirtualIPType(PyraxException):
    pass

class InvalidVirtualIPVersion(PyraxException):
    pass

class InvalidVolumeResize(PyraxException):
    pass

class MissingAuthSettings(PyraxException):
    pass

class MissingClaimParameters(PyraxException):
    pass

class MissingDBUserParameters(PyraxException):
    pass

class MissingDNSSettings(PyraxException):
    pass

class MissingHealthMonitorSettings(PyraxException):
    pass

class MissingLoadBalancerParameters(PyraxException):
    pass

class MissingMonitoringCheckDetails(PyraxException):
    pass

class MissingMonitoringCheckGranularity(PyraxException):
    pass

class MissingName(PyraxException):
    pass

class MissingTemporaryURLKey(PyraxException):
    pass

class MonitoringCheckTargetNotSpecified(PyraxException):
    pass

class MonitoringZonesPollMissing(PyraxException):
    pass

class NetworkCIDRInvalid(PyraxException):
    pass

class NetworkCIDRMalformed(PyraxException):
    pass

class NetworkCountExceeded(PyraxException):
    pass

class NetworkInUse(PyraxException):
    pass

class NetworkNotFound(PyraxException):
    pass

class NetworkLabelNotUnique(PyraxException):
    pass

class NoClientForService(PyraxException):
    pass

class NoEndpointForRegion(PyraxException):
    pass

class NoEndpointForService(PyraxException):
    pass

class NoMoreResults(PyraxException):
    pass

class NoReloadError(PyraxException):
    pass

class NoSSLTerminationConfiguration(PyraxException):
    pass

class NoSuchClient(PyraxException):
    pass

class NoSuchContainer(PyraxException):
    pass

class NoSuchDatabase(PyraxException):
    pass

class NoSuchDatabaseUser(PyraxException):
    pass

class NoSuchObject(PyraxException):
    pass

class NotAuthenticated(PyraxException):
    pass

class NotCDNEnabled(PyraxException):
    pass

class NoTokenLookupException(PyraxException):
    pass

class PasswordChangeFailed(PyraxException):
    pass

class ProtocolMismatch(PyraxException):
    pass

class PTRRecordCreationFailed(PyraxException):
    pass

class PTRRecordDeletionFailed(PyraxException):
    pass

class PTRRecordUpdateFailed(PyraxException):
    pass

class QueueClientIDNotDefined(PyraxException):
    pass

class ServiceNotAvailable(PyraxException):
    pass

class ServiceResponseFailure(PyraxException):
    pass

class SnapshotNotAvailable(PyraxException):
    pass

class TenantNotFound(PyraxException):
    pass

class UnattachedNode(PyraxException):
    pass

class UnattachedVirtualIP(PyraxException):
    pass

class UnicodePathError(PyraxException):
    pass

class UnsharableImage(PyraxException):
    pass

class UploadFailed(PyraxException):
    pass

class UserNotFound(PyraxException):
    pass

class VolumeAttachmentFailed(PyraxException):
    pass

class VolumeCloneTooSmall(PyraxException):
    pass

class VolumeDetachmentFailed(PyraxException):
    pass

class VolumeNotAvailable(PyraxException):
    pass


class AmbiguousEndpoints(PyraxException):
    """Found more than one matching endpoint in Service Catalog."""
    def __init__(self, endpoints=None):
        self.endpoints = endpoints

    def __str__(self):
        return "AmbiguousEndpoints: %s" % repr(self.endpoints)


class ClientException(PyraxException):
    """
    The base exception class for all exceptions this library raises.
    """
    def __init__(self, code, message=None, details=None, request_id=None):
        self.code = code
        self.message = message or "-no error message returned-"
        self.details = details
        self.request_id = request_id

    def __str__(self):
        formatted_string = "%s (HTTP %s)" % (self.message, self.code)
        if self.request_id:
            formatted_string += " (Request-ID: %s)" % self.request_id
        return formatted_string


class BadRequest(ClientException):
    """
    HTTP 400 - Bad request: you sent some malformed data.
    """
    http_status = 400
    message = "Bad request"


class Unauthorized(ClientException):
    """
    HTTP 401 - Unauthorized: bad credentials.
    """
    http_status = 401
    message = "Unauthorized"


class Forbidden(ClientException):
    """
    HTTP 403 - Forbidden: your credentials don't give you access to this
    resource.
    """
    http_status = 403
    message = "Forbidden"


class NotFound(ClientException):
    """
    HTTP 404 - Not found
    """
    http_status = 404
    message = "Not found"


class NoUniqueMatch(ClientException):
    """
    HTTP 400 - Bad Request
    """
    http_status = 400
    message = "Not Unique"


class OverLimit(ClientException):
    """
    HTTP 413 - Over limit: you're over the API limits for this time period.
    """
    http_status = 413
    message = "Over limit"


# NotImplemented is a python keyword.
class HTTPNotImplemented(ClientException):
    """
    HTTP 501 - Not Implemented: the server does not support this operation.
    """
    http_status = 501
    message = "Not Implemented"



# In Python 2.4 Exception is old-style and thus doesn't have a __subclasses__()
# so we can do this:
#     _code_map = dict((c.http_status, c)
#                      for c in ClientException.__subclasses__())
#
# Instead, we have to hardcode it:
_code_map = dict((c.http_status, c) for c in [BadRequest, Unauthorized,
        Forbidden, NotFound, OverLimit, HTTPNotImplemented])


def from_response(response, body):
    """
    Return an instance of a ClientException or subclass
    based on an httplib2 response.

    Usage::

        resp, body = http.request(...)
        if resp.status_code != 200:
            raise exception_from_response(resp, body)
    """
    if isinstance(response, dict):
        status = response.get("status_code")
    else:
        status = response.status_code
    cls = _code_map.get(int(status), ClientException)

#    import pyrax
#    pyrax.utils.trace()

    request_id = response.headers.get("x-compute-request-id")
    if body:
        message = "n/a"
        details = "n/a"
        if isinstance(body, dict):
            message = body.get("message")
            details = body.get("details")
            if message is details is None:
                error = body[body.keys()[0]]
                if isinstance(error, dict):
                    message = error.get("message", None)
                    details = error.get("details", None)
                else:
                    message = error
                    details = None
        return cls(code=status, message=message, details=details,
                   request_id=request_id)
    else:
        return cls(code=status, request_id=request_id)

########NEW FILE########
__FILENAME__ = fakes
#!/usr/bin/env python
# -*- coding: utf-8 -*-
import json
import os
import random
import time
import uuid

import pyrax
from pyrax.autoscale import AutoScaleClient
from pyrax.autoscale import AutoScalePolicy
from pyrax.autoscale import AutoScaleWebhook
from pyrax.autoscale import ScalingGroup
from pyrax.autoscale import ScalingGroupManager
from pyrax.cf_wrapper.client import BulkDeleter
from pyrax.cf_wrapper.client import FolderUploader
from pyrax.cf_wrapper.container import Container
from pyrax.cf_wrapper.storage_object import StorageObject
from pyrax.client import BaseClient
from pyrax.clouddatabases import CloudDatabaseClient
from pyrax.clouddatabases import CloudDatabaseDatabaseManager
from pyrax.clouddatabases import CloudDatabaseInstance
from pyrax.clouddatabases import CloudDatabaseManager
from pyrax.clouddatabases import CloudDatabaseUser
from pyrax.clouddatabases import CloudDatabaseUserManager
from pyrax.clouddatabases import CloudDatabaseVolume
from pyrax.cloudblockstorage import CloudBlockStorageClient
from pyrax.cloudblockstorage import CloudBlockStorageManager
from pyrax.cloudblockstorage import CloudBlockStorageSnapshot
from pyrax.cloudblockstorage import CloudBlockStorageVolume
from pyrax.cloudloadbalancers import CloudLoadBalancer
from pyrax.cloudloadbalancers import CloudLoadBalancerManager
from pyrax.cloudloadbalancers import CloudLoadBalancerClient
from pyrax.cloudloadbalancers import Node
from pyrax.cloudloadbalancers import VirtualIP
from pyrax.clouddns import CloudDNSClient
from pyrax.clouddns import CloudDNSDomain
from pyrax.clouddns import CloudDNSManager
from pyrax.clouddns import CloudDNSRecord
from pyrax.clouddns import CloudDNSPTRRecord
from pyrax.cloudnetworks import CloudNetwork
from pyrax.cloudnetworks import CloudNetworkClient
from pyrax.cloudmonitoring import CloudMonitorClient
from pyrax.cloudmonitoring import CloudMonitorEntity
from pyrax.cloudmonitoring import CloudMonitorCheck
from pyrax.cloudmonitoring import CloudMonitorNotification
from pyrax.image import Image
from pyrax.image import ImageClient
from pyrax.image import ImageManager
from pyrax.image import ImageMemberManager
from pyrax.image import ImageTagManager
from pyrax.queueing import Queue
from pyrax.queueing import QueueClaim
from pyrax.queueing import QueueMessage
from pyrax.queueing import QueueClient
from pyrax.queueing import QueueManager

import pyrax.exceptions as exc
from pyrax.base_identity import BaseIdentity
from pyrax.base_identity import Endpoint
from pyrax.base_identity import Service
from pyrax.identity.rax_identity import RaxIdentity
from pyrax.identity.keystone_identity import KeystoneIdentity
import pyrax.utils as utils


example_uri = "http://example.com"


class FakeResponse(object):
    headers = {}
    body = ""
    status_code = 200
    reason = "Oops"
    content = "Oops"

    @property
    def status(self):
        # TEMPORARY - until the cf_wrapper code is removed.
        return self.status_code

    @status.setter
    def status(self, val):
        # TEMPORARY - until the cf_wrapper code is removed.
        self.status_code = val

    def getheaders(self):
        return self.headers

    def read(self):
        return "Line1\nLine2"

    def get(self, arg):
        pass

    def json(self):
        return self.content


class FakeClient(object):
    user_agent = "Fake"
    USER_AGENT = "Fake"

    def __init__(self, *args, **kwargs):
        super(FakeClient, self).__init__(*args, **kwargs)
        self.identity = FakeIdentity()


class FakeContainer(Container):
    def _fetch_cdn_data(self):
        self._cdn_uri = None
        self._cdn_ttl = self.client.default_cdn_ttl
        self._cdn_ssl_uri = None
        self._cdn_streaming_uri = None
        self._cdn_ios_uri = None
        self._cdn_log_retention = False


class FakeStorageObject(StorageObject):
    def __init__(self, client, container, name=None, total_bytes=None,
            content_type=None, last_modified=None, etag=None, attdict=None):
        """
        The object can either be initialized with individual params, or by
        passing the dict that is returned by swiftclient.
        """
        self.client = client
        self.container = container
        self.name = name
        self.total_bytes = total_bytes
        self.content_type = content_type
        self.last_modified = last_modified
        self.etag = etag
        if attdict:
            self._read_attdict(attdict)


fake_attdict = {"name": "fake",
        "content-length": 42,
        "content-type": "text/html",
        "etag": "ABC",
        "last-modified": "Tue, 01 Jan 2013 01:02:03 GMT",
        }


class FakeServer(object):
    id = utils.random_unicode()


class FakeService(object):
    user_agent = "FakeService"
    USER_AGENT = "FakeService"

    def __init__(self, *args, **kwargs):
        self.client = FakeClient()
        self.Node = FakeNode
        self.VirtualIP = FakeVirtualIP
        self.loadbalancers = FakeLoadBalancer()
        self.id = utils.random_unicode()

    def authenticate(self):
        pass

    def get_protocols(self):
        return ["HTTP"]

    def get_algorithms(self):
        return ["RANDOM"]

    def get_usage(self):
        pass


class FakeCSClient(FakeService):
    def __init__(self, *args, **kwargs):
        ident = FakeIdentity()
        super(FakeCSClient, self).__init__(ident, *args, **kwargs)

        def dummy(self):
            pass

        self.servers = FakeService()
        utils.add_method(self.servers, dummy, "list")
        self.images = FakeService()
        utils.add_method(self.images, dummy, "list")
        self.flavors = FakeService()
        utils.add_method(self.flavors, dummy, "list")


class FakeFolderUploader(FolderUploader):
    def __init__(self, *args, **kwargs):
        super(FakeFolderUploader, self).__init__(*args, **kwargs)
        # Useful for when we mock out the run() method.
        self.actual_run = self.run
        self.run = self.fake_run

    def fake_run(self):
        pass


class FakeBulkDeleter(BulkDeleter):
    def __init__(self, *args, **kwargs):
        super(FakeBulkDeleter, self).__init__(*args, **kwargs)
        # Useful for when we mock out the run() method.
        self.actual_run = self.run
        self.run = self.fake_run

    def fake_run(self):
        time.sleep(0.0001)
        self.results = {}
        self.completed = True


class FakeManager(object):
    def __init__(self, *args, **kwargs):
        super(FakeManager, self).__init__(*args, **kwargs)
        self.api = FakeClient()

    def list(self):
        pass

    def get(self, item):
        pass

    def delete(self, item):
        pass

    def create(self, *args, **kwargs):
        pass

    def find(self, *args, **kwargs):
        pass

    def action(self, item, action_type, body={}):
        pass


class FakeException(BaseException):
    pass


class FakeKeyring(object):
    password_set = False

    def get_password(self, *args, **kwargs):
        return "FAKE_TOKEN|FAKE_URL"

    def set_password(self, *args, **kwargs):
        self.password_set = True


class FakeEntity(object):
    def __init__(self, *args, **kwargs):
        self.id = utils.random_unicode()

    def get(self, *args, **kwargs):
        pass

    def list(self, *args, **kwargs):
        pass


class FakeDatabaseUser(CloudDatabaseUser):
    pass


class FakeDatabaseVolume(CloudDatabaseVolume):
    def __init__(self, instance, *args, **kwargs):
        self.instance = instance
        self.size = 1
        self.used = 0.2


class FakeDatabaseInstance(CloudDatabaseInstance):
    def __init__(self, *args, **kwargs):
        self.id = utils.random_unicode()
        self.manager = FakeDatabaseManager()
        self.manager.api = FakeDatabaseClient()
        self._database_manager = CloudDatabaseDatabaseManager(
                FakeDatabaseClient())
        self._user_manager = CloudDatabaseUserManager(FakeDatabaseClient())
        self.volume = FakeDatabaseVolume(self)


class FakeDatabaseManager(CloudDatabaseManager):
    def __init__(self, api=None, *args, **kwargs):
        if api is None:
            api = FakeDatabaseClient()
        super(FakeDatabaseManager, self).__init__(api, *args, **kwargs)
        self.uri_base = "instances"


class FakeDatabaseClient(CloudDatabaseClient):
    def __init__(self, *args, **kwargs):
        self._manager = FakeDatabaseManager(self)
        self._flavor_manager = FakeManager()
        ident = FakeIdentity()
        super(FakeDatabaseClient, self).__init__(ident, "fakeuser",
                "fakepassword", *args, **kwargs)


class FakeNovaVolumeClient(BaseClient):
    def __init__(self, *args, **kwargs):
        pass


class FakeBlockStorageManager(CloudBlockStorageManager):
    def __init__(self, api=None, *args, **kwargs):
        ident = FakeIdentity()
        if api is None:
            api = FakeBlockStorageClient(ident)
        super(FakeBlockStorageManager, self).__init__(api, *args, **kwargs)


class FakeBlockStorageVolume(CloudBlockStorageVolume):
    def __init__(self, *args, **kwargs):
        volname = utils.random_unicode(8)
        self.id = utils.random_unicode()
        self.manager = FakeBlockStorageManager()
        self._nova_volumes = FakeNovaVolumeClient()


class FakeBlockStorageSnapshot(CloudBlockStorageSnapshot):
    def __init__(self, *args, **kwargs):
        self.id = utils.random_unicode()
        self.manager = FakeManager()
        self.status = "available"


class FakeBlockStorageClient(CloudBlockStorageClient):
    def __init__(self, *args, **kwargs):
        self._types_manager = FakeManager()
        self._snapshot_manager = FakeManager()
        ident = FakeIdentity()
        super(FakeBlockStorageClient, self).__init__(ident, "fakeuser",
                "fakepassword", *args, **kwargs)


class FakeLoadBalancerClient(CloudLoadBalancerClient):
    def __init__(self, *args, **kwargs):
        ident = FakeIdentity()
        super(FakeLoadBalancerClient, self).__init__(ident, "fakeuser",
                "fakepassword", *args, **kwargs)


class FakeLoadBalancerManager(CloudLoadBalancerManager):
    def __init__(self, api=None, *args, **kwargs):
        if api is None:
            api = FakeLoadBalancerClient()
        super(FakeLoadBalancerManager, self).__init__(api, *args, **kwargs)


class FakeLoadBalancer(CloudLoadBalancer):
    def __init__(self, name=None, info=None, *args, **kwargs):
        name = name or utils.random_ascii()
        info = info or {"fake": "fake"}
        super(FakeLoadBalancer, self).__init__(name, info, *args, **kwargs)
        self.id = utils.random_ascii()
        self.port = random.randint(1, 256)
        self.manager = FakeLoadBalancerManager()


class FakeNode(Node):
    def __init__(self, address=None, port=None, condition=None, weight=None,
            status=None, parent=None, type=None, id=None):
        if address is None:
            address = "0.0.0.0"
        if port is None:
            port = 80
        if id is None:
            id = utils.random_unicode()
        super(FakeNode, self).__init__(address=address, port=port,
                condition=condition, weight=weight, status=status,
                parent=parent, type=type, id=id)


class FakeVirtualIP(VirtualIP):
    pass


class FakeStatusChanger(object):
    check_count = 0
    id = utils.random_unicode()

    @property
    def status(self):
        if self.check_count < 2:
            self.check_count += 1
            return "changing"
        return "ready"


class FakeDNSClient(CloudDNSClient):
    def __init__(self, *args, **kwargs):
        ident = FakeIdentity()
        super(FakeDNSClient, self).__init__(ident, "fakeuser",
                "fakepassword", *args, **kwargs)


class FakeDNSManager(CloudDNSManager):
    def __init__(self, api=None, *args, **kwargs):
        if api is None:
            api = FakeDNSClient()
        super(FakeDNSManager, self).__init__(api, *args, **kwargs)
        self.resource_class = FakeDNSDomain
        self.response_key = "domain"
        self.plural_response_key = "domains"
        self.uri_base = "domains"


class FakeDNSDomain(CloudDNSDomain):
    def __init__(self, *args, **kwargs):
        self.id = utils.random_ascii()
        self.name = utils.random_unicode()
        self.manager = FakeDNSManager()


class FakeDNSRecord(CloudDNSRecord):
    def __init__(self, mgr, info, *args, **kwargs):
        super(FakeDNSRecord, self).__init__(mgr, info, *args, **kwargs)


class FakeDNSPTRRecord(CloudDNSPTRRecord):
    pass


class FakeDNSDevice(FakeLoadBalancer):
    def __init__(self, *args, **kwargs):
        self.id = utils.random_unicode()


class FakeCloudNetworkClient(CloudNetworkClient):
    def __init__(self, *args, **kwargs):
        ident = FakeIdentity()
        super(FakeCloudNetworkClient, self).__init__(ident, "fakeuser",
                "fakepassword", *args, **kwargs)


class FakeCloudNetwork(CloudNetwork):
    def __init__(self, *args, **kwargs):
        info = kwargs.pop("info", {"fake": "fake"})
        label = kwargs.pop("label", kwargs.pop("name", utils.random_unicode()))
        info["label"] = label
        super(FakeCloudNetwork, self).__init__(manager=None, info=info, *args,
                **kwargs)
        self.id = uuid.uuid4()


class FakeAutoScaleClient(AutoScaleClient):
    def __init__(self, *args, **kwargs):
        ident = FakeIdentity()
        self._manager = FakeManager()
        super(FakeAutoScaleClient, self).__init__(ident, *args, **kwargs)


class FakeAutoScalePolicy(AutoScalePolicy):
    def __init__(self, *args, **kwargs):
        super(FakeAutoScalePolicy, self).__init__(*args, **kwargs)
        self.id = utils.random_ascii()


class FakeAutoScaleWebhook(AutoScaleWebhook):
    def __init__(self, *args, **kwargs):
        super(FakeAutoScaleWebhook, self).__init__(*args, **kwargs)
        self.id = utils.random_ascii()


class FakeScalingGroupManager(ScalingGroupManager):
    def __init__(self, api=None, *args, **kwargs):
        if api is None:
            api = FakeAutoScaleClient()
        super(FakeScalingGroupManager, self).__init__(api, *args, **kwargs)
        self.id = utils.random_ascii()


class FakeScalingGroup(ScalingGroup):
    def __init__(self, name=None, info=None, *args, **kwargs):
        name = name or utils.random_ascii()
        info = info or {"fake": "fake", "scalingPolicies": []}
        self.groupConfiguration = {}
        super(FakeScalingGroup, self).__init__(name, info, *args, **kwargs)
        self.id = utils.random_ascii()
        self.name = name
        self.manager = FakeScalingGroupManager()


class FakeCloudMonitorClient(CloudMonitorClient):
    def __init__(self, *args, **kwargs):
        ident = FakeIdentity()
        super(FakeCloudMonitorClient, self).__init__(ident, "fakeuser",
                "fakepassword", *args, **kwargs)


class FakeCloudMonitorEntity(CloudMonitorEntity):
    def __init__(self, *args, **kwargs):
        info = kwargs.pop("info", {"fake": "fake"})
        super(FakeCloudMonitorEntity, self).__init__(FakeManager(), info=info,
                *args, **kwargs)
        self.manager.api = FakeCloudMonitorClient()
        self.id = utils.random_unicode()


class FakeCloudMonitorCheck(CloudMonitorCheck):
    def __init__(self, *args, **kwargs):
        info = kwargs.pop("info", {"fake": "fake"})
        entity = kwargs.pop("entity", FakeCloudMonitorEntity())
        super(FakeCloudMonitorCheck, self).__init__(None, info, entity,
                *args, **kwargs)
        self.id = uuid.uuid4()


class FakeCloudMonitorNotification(CloudMonitorNotification):
    def __init__(self, *args, **kwargs):
        info = kwargs.pop("info", {"fake": "fake"})
        super(FakeCloudMonitorNotification, self).__init__(manager=None,
                info=info, *args, **kwargs)
        self.id = uuid.uuid4()


class FakeQueue(Queue):
    def __init__(self, *args, **kwargs):
        info = kwargs.pop("info", {"fake": "fake"})
        info["name"] = utils.random_unicode()
        mgr = kwargs.pop("manager", FakeQueueManager())
        super(FakeQueue, self).__init__(manager=mgr, info=info, *args, **kwargs)


class FakeQueueClaim(QueueClaim):
    def __init__(self, *args, **kwargs):
        info = kwargs.pop("info", {"fake": "fake"})
        info["name"] = utils.random_unicode()
        mgr = kwargs.pop("manager", FakeQueueManager())
        super(FakeQueueClaim, self).__init__(manager=mgr, info=info, *args,
                **kwargs)


class FakeQueueClient(QueueClient):
    def __init__(self, *args, **kwargs):
        ident = FakeIdentity()
        super(FakeQueueClient, self).__init__(ident, "fakeuser",
                "fakepassword", *args, **kwargs)


class FakeQueueManager(QueueManager):
    def __init__(self, api=None, *args, **kwargs):
        if api is None:
            api = FakeQueueClient()
        super(FakeQueueManager, self).__init__(api, *args, **kwargs)
        self.id = utils.random_ascii()


class FakeImage(Image):
    def __init__(self, *args, **kwargs):
        info = kwargs.pop("info", {"fake": "fake"})
        info["name"] = utils.random_unicode()
        info["id"] = utils.random_unicode()
        mgr = kwargs.pop("manager", FakeImageManager())
        kwargs["member_manager_class"] = FakeImageMemberManager
        kwargs["tag_manager_class"] = FakeImageTagManager
        super(FakeImage, self).__init__(mgr, info, *args, **kwargs)


class FakeImageClient(ImageClient):
    def __init__(self, identity=None, *args, **kwargs):
        if identity is None:
            identity = FakeIdentity()
        super(FakeImageClient, self).__init__(identity, "fakeuser",
                "fakepassword", *args, **kwargs)


class FakeImageMemberManager(ImageMemberManager):
    def __init__(self, api=None, *args, **kwargs):
        if api is None:
            api = FakeImageClient()
        super(FakeImageMemberManager, self).__init__(api, *args, **kwargs)
        self.id = utils.random_ascii()


class FakeImageTagManager(ImageTagManager):
    def __init__(self, api=None, *args, **kwargs):
        if api is None:
            api = FakeImageClient()
        super(FakeImageTagManager, self).__init__(api, *args, **kwargs)
        self.id = utils.random_ascii()


class FakeImageManager(ImageManager):
    def __init__(self, api=None, *args, **kwargs):
        if api is None:
            api = FakeImageClient()
        super(FakeImageManager, self).__init__(api, *args, **kwargs)
        self.plural_response_key = "images"
        self.resource_class = FakeImage
        self.id = utils.random_ascii()


class FakeIdentityService(Service):
    def __init__(self, identity=None, *args, **kwargs):
        self.identity = identity or FakeIdentity()
        self.name = "fake"
        self.prefix = ""
        self.service_type = "fake"
        self.clients = {}
        self.endpoints = utils.DotDict()


class FakeEndpoint(Endpoint):
    pass


class FakeRaxIdentity(RaxIdentity):
    pass


class FakeIdentity(BaseIdentity):
    """Class that returns canned authentication responses."""
    def __init__(self, *args, **kwargs):
        super(FakeIdentity, self).__init__(*args, **kwargs)
        self._good_username = "fakeuser"
        self._good_password = "fakeapikey"
        self._default_region = random.choice(("DFW", "ORD"))
        self.services = {"fake": FakeIdentityService(self)}

    def authenticate(self):
        if ((self.username == self._good_username) and
                (self.password == self._good_password)):
            self._parse_response(self.fake_response())
            self.authenticated = True
        else:
            self.authenticated = False
            raise exc.AuthenticationFailed("No match for '%s'/'%s' "
                    "username/password" % (self.username, self.password))

    def auth_with_token(self, token, tenant_id=None, tenant_name=None):
        self.token = token
        self.tenant_id = tenant_id
        self.tenant_name = tenant_name
        self.authenticated = True

    def get_token(self, force=False):
        return self.token

    def fake_response(self):
        return fake_identity_response


fake_config_file = """[settings]
identity_type = rackspace
keyring_username =
region = FAKE
custom_user_agent = FAKE
http_debug =
"""

# This will handle both singular and plural responses.
fake_identity_user_response = {
        "users": [{"name": "fake", "id": "fake"},
            {"name": "faker", "id": "faker"}],
        "user": {"name": "fake", "id": "fake"},
        "roles": [{u'description': 'User Admin Role.',
                'id': '3',
                'name': 'identity:user-admin'}],
        }

fake_identity_tenant_response = {"name": "fake", "id": "fake",
        "description": "fake", "enabled": True}

fake_identity_tenants_response = {
    "tenants": [
        {"name": "fake", "id": "fake", "description": "fake",
        "enabled": True},
        {"name": "faker", "id": "faker", "description": "faker",
        "enabled": True},
        ]}

fake_identity_tokens_response = {"access":
        {'metadata': {u'is_admin': 0,
            'roles': [u'asdfgh',
                'sdfghj',
                'dfghjk']},
        'serviceCatalog': [{u'endpoints': [
            {u'adminURL': 'http://10.0.0.0:8774/v2/qweqweqwe',
            'id': 'dddddddddd',
            'publicURL': 'http://10.0.0.0:8774/v2/qweqweqwe',
            'internalURL': 'http://10.0.0.0:8774/v2/qweqweqwe',
            'region': 'some_region'}],
            'endpoints_links': [],
            'name': 'nova',
            'type': 'compute'},
            {u'endpoints': [{u'adminURL': 'http://10.0.0.0:35357/v2.0',
            'id': 'qweqweqwe',
            'internalURL': 'http://10.0.0.0:5000/v2.0',
            'publicURL': 'http://10.0.0.0:5000/v2.0',
            'region': 'some_region'}],
            'endpoints_links': [],
            'name': 'keystone',
            'type': 'identity'}],
        'token': {u'expires': '1999-05-04T16:45:05Z',
            'id': 'qweqweqwe',
            'tenant': {u'description': 'admin Tenant',
                'enabled': True,
                'id': 'qweqweqwe',
                'name': 'admin'}},
        'user': {u'id': 'qweqweqwe',
            'name': 'admin',
            'roles': [{u'id': 'qweqweqwe', 'name': 'admin'},
                {u'id': 'qweqweqwe', 'name': 'KeystoneAdmin'},
                {u'id': 'qweqweqwe',
                'name': 'KeystoneServiceAdmin'}],
            'roles_links': [],
            'username': 'admin'}}}

fake_identity_endpoints_response = {"access": {
        "endpoints": ["fake", "faker", "fakest"]}}

fake_identity_response = {u'access':
    {u'serviceCatalog': [
        {u'endpoints': [{u'publicURL':
            'https://ord.loadbalancers.api.rackspacecloud.com/v1.0/000000',
            'region': 'ORD',
            'tenantId': '000000'},
            {u'publicURL':
            'https://dfw.loadbalancers.api.rackspacecloud.com/v1.0/000000',
            'region': 'DFW',
            'tenantId': '000000'},
            {u'publicURL':
            'https://syd.loadbalancers.api.rackspacecloud.com/v1.0/000000',
            'region': 'SYD',
            'tenantId': '000000'}],
        'name': 'cloudLoadBalancers',
        'type': 'rax:load-balancer'},
        {u'endpoints': [{u'internalURL':
            'https://snet-aa.fake1.clouddrive.com/v1/MossoCloudFS_abc',
            'publicURL': 'https://aa.fake1.clouddrive.com/v1/MossoCloudFS_abc',
            'region': 'FAKE',
            'tenantId': 'MossoCloudFS_abc'},
            {u'internalURL':
            'https://snet-aa.dfw1.clouddrive.com/v1/MossoCloudFS_abc',
            'publicURL': 'https://aa.dfw1.clouddrive.com/v1/MossoCloudFS_abc',
            'region': 'DFW',
            'tenantId': 'MossoCloudFS_abc'},
            {u'internalURL':
            'https://snet-aa.ord1.clouddrive.com/v1/MossoCloudFS_abc',
            'publicURL': 'https://aa.ord1.clouddrive.com/v1/MossoCloudFS_abc',
            'region': 'ORD',
            'tenantId': 'MossoCloudFS_abc'},
            {u'internalURL':
            'https://snet-aa.syd1.clouddrive.com/v1/MossoCloudFS_abc',
            'publicURL': 'https://aa.ord1.clouddrive.com/v1/MossoCloudFS_abc',
            'region': 'SYD',
            'tenantId': 'MossoCloudFS_abc'}],
        'name': 'cloudFiles',
        'type': 'object-store'},
        {u'endpoints': [{u'publicURL':
            'https://dfw.servers.api.rackspacecloud.com/v2/000000',
            'region': 'DFW',
            'tenantId': '000000',
            'versionId': '2',
            'versionInfo': 'https://dfw.servers.api.rackspacecloud.com/v2',
            'versionList': 'https://dfw.servers.api.rackspacecloud.com/'},
            {u'publicURL':
            'https://ord.servers.api.rackspacecloud.com/v2/000000',
            'region': 'ORD',
            'tenantId': '000000',
            'versionId': '2',
            'versionInfo': 'https://ord.servers.api.rackspacecloud.com/v2',
            'versionList': 'https://ord.servers.api.rackspacecloud.com/'},
            {u'publicURL':
            'https://syd.servers.api.rackspacecloud.com/v2/000000',
            'region': 'SYD',
            'tenantId': '000000',
            'versionId': '2',
            'versionInfo': 'https://syd.servers.api.rackspacecloud.com/v2',
            'versionList': 'https://syd.servers.api.rackspacecloud.com/'}],
        'name': 'cloudServersOpenStack',
        'type': 'compute'},
        {u'endpoints': [{u'publicURL':
        'https://dns.api.rackspacecloud.com/v1.0/000000',
        'tenantId': '000000'}],
        'name': 'cloudDNS',
        'type': 'rax:dns'},
        {u'endpoints': [{u'publicURL':
            'https://dfw.databases.api.rackspacecloud.com/v1.0/000000',
            'region': 'DFW',
            'tenantId': '000000'},
            {u'publicURL':
            'https://syd.databases.api.rackspacecloud.com/v1.0/000000',
            'region': 'SYD',
            'tenantId': '000000'},
            {u'publicURL':
            'https://ord.databases.api.rackspacecloud.com/v1.0/000000',
            'region': 'ORD',
            'tenantId': '000000'}],
        'name': 'cloudDatabases',
        'type': 'rax:database'},
        {u'endpoints': [{u'publicURL':
        'https://servers.api.rackspacecloud.com/v1.0/000000',
        'tenantId': '000000',
        'versionId': '1.0',
        'versionInfo': 'https://servers.api.rackspacecloud.com/v1.0',
        'versionList': 'https://servers.api.rackspacecloud.com/'}],
        'name': 'cloudServers',
        'type': 'compute'},
        {u'endpoints': [{u'publicURL':
            'https://cdn1.clouddrive.com/v1/MossoCloudFS_abc',
            'region': 'DFW',
            'tenantId': 'MossoCloudFS_abc'},
            {u'publicURL': 'https://cdn1.clouddrive.com/v1/MossoCloudFS_abc',
            'region': 'SYD',
            'tenantId': 'MossoCloudFS_abc'},
            {u'publicURL': 'https://cdn2.clouddrive.com/v1/MossoCloudFS_abc',
            'region': 'ORD',
            'tenantId': 'MossoCloudFS_abc'}],
        'name': 'cloudFilesCDN',
        'type': 'rax:object-cdn'},
        {u'endpoints': [{u'publicURL':
            'https://monitoring.api.rackspacecloud.com/v1.0/000000',
            'tenantId': '000000'}],
        'name': 'cloudMonitoring',
        'type': 'rax:monitor'}],
    u'token': {u'expires': '2222-02-22T22:22:22.000-02:00',
    'id': 'xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx',
    'tenant': {u'id': '000000', 'name': '000000'}},
    u'user': {u'id': '123456',
    'name': 'fakeuser',
    'RAX-AUTH:defaultRegion': 'DFW',
    'roles': [{u'description': 'User Admin Role.',
    'id': '3',
    'name': 'identity:user-admin'}],
    }}}



class FakeIdentityResponse(FakeResponse):
    status_code = 200
    response_type = "auth"
    responses = {"auth": fake_identity_response,
            "users": fake_identity_user_response,
            "tenant": fake_identity_tenant_response,
            "tenants": fake_identity_tenants_response,
            "tokens": fake_identity_tokens_response,
            "endpoints": fake_identity_endpoints_response,
            }

    @property
    def content(self):
        return self.responses.get(self.response_type)

    def json(self):
        return self.content

    def read(self):
        return json.dumps(self.content)


def get_png_content():
    _module_pth = os.path.dirname(pyrax.__file__)
    _img_path = os.path.join(_module_pth, "..", "tests", "unit",
            "python-logo.png")
    png_content = None
    with open(_img_path, "rb") as pfile:
        png_content = pfile.read()
    return png_content

########NEW FILE########
__FILENAME__ = http
# Copyright 2014 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.
"""
Wrapper around the requests library. Used for making all HTTP calls.
"""

import logging
import json
import requests

import pyrax
import pyrax.exceptions as exc


req_methods = {
    "HEAD": requests.head,
    "GET": requests.get,
    "POST": requests.post,
    "PUT": requests.put,
    "DELETE": requests.delete,
    "PATCH": requests.patch,
    }

# NOTE: FIX THIS!!!
verify_ssl = False


def request(method, uri, *args, **kwargs):
    """
    Handles all the common functionality required for API calls. Returns
    the resulting response object.

    Formats the request into a dict representing the headers
    and body that will be used to make the API call.
    """
    req_method = req_methods[method.upper()]
    raise_exception = kwargs.pop("raise_exception", True)
    kwargs["headers"] = kwargs.get("headers", {})
    http_log_req(method, uri, args, kwargs)
    data = None
    if "data" in kwargs:
        # The 'data' kwarg is used when you don't want json encoding.
        data = kwargs.pop("data")
    elif "body" in kwargs:
        if "Content-Type" not in kwargs["headers"]:
            kwargs["headers"]["Content-Type"] = "application/json"
        data = json.dumps(kwargs.pop("body"))
    if data:
        resp = req_method(uri, data=data, **kwargs)
    else:
        resp = req_method(uri, **kwargs)
    try:
        body = resp.json()
    except ValueError:
        # No JSON in response
        body = resp.content
    http_log_resp(resp, body)
    if resp.status_code >= 400 and raise_exception:
        raise exc.from_response(resp, body)
    return resp, body


def http_log_req(method, uri, args, kwargs):
    """
    When pyrax.get_http_debug() is True, outputs the equivalent `curl`
    command for the API request being made.
    """
    if not pyrax.get_http_debug():
        return
    string_parts = ["curl -i -X %s" % method]
    for element in args:
        string_parts.append("%s" % element)
    for element in kwargs["headers"]:
        header = "-H '%s: %s'" % (element, kwargs["headers"][element])
        string_parts.append(header)
    string_parts.append(uri)
    log = logging.getLogger("pyrax")
    log.debug("\nREQ: %s\n" % " ".join(string_parts))
    if "body" in kwargs:
        pyrax._logger.debug("REQ BODY: %s\n" % (kwargs["body"]))


def http_log_resp(resp, body):
    """
    When pyrax.get_http_debug() is True, outputs the response received
    from the API request.
    """
    if not pyrax.get_http_debug():
        return
    log = logging.getLogger("pyrax")
    log.debug("RESP: %s %s\n", resp, body)

########NEW FILE########
__FILENAME__ = keystone_identity
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from __future__ import absolute_import

import pyrax
from ..base_identity import BaseIdentity
from .. import exceptions as exc


class KeystoneIdentity(BaseIdentity):
    """
    Implements the Keystone-specific behaviors for Identity. In most
    cases you will want to create specific subclasses to implement the
    _get_auth_endpoint() method if you want to use something other
    than the config file to control your auth endpoint.
    """

    _default_region = "RegionOne"

    def _get_auth_endpoint(self):
        ep = pyrax.get_setting("auth_endpoint")
        if ep is None:
            raise exc.EndpointNotDefined("No auth endpoint has been specified.")
        return ep

########NEW FILE########
__FILENAME__ = rax_identity
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from __future__ import absolute_import

from six.moves import configparser as ConfigParser

import pyrax
from ..base_identity import BaseIdentity
from ..base_identity import User
from .. import exceptions as exc
from .. import utils as utils

AUTH_ENDPOINT = "https://identity.api.rackspacecloud.com/v2.0/"


class RaxIdentity(BaseIdentity):
    """
    This class handles all of the authentication requirements for working
    with the Rackspace Cloud.
    """
    _auth_endpoint = None
    _creds_style = "apikey"


    def _get_auth_endpoint(self):
        return self._auth_endpoint or AUTH_ENDPOINT


    def _read_credential_file(self, cfg):
        """
        Parses the credential file with Rackspace-specific labels.
        """
        self.username = cfg.get("rackspace_cloud", "username")
        try:
            self.password = cfg.get("rackspace_cloud", "api_key", raw=True)
        except ConfigParser.NoOptionError as e:
            # Allow either the use of either 'api_key' or 'password'.
            self.password = cfg.get("rackspace_cloud", "password", raw=True)


    def _format_credentials(self):
        """
        Returns the current credentials in the format expected by the
        authentication service. Note that by default Rackspace credentials
        expect 'api_key' instead of 'password'. However, if authentication
        fails, return the creds in standard password format, in case they are
        using a username / password combination.
        """
        if self._creds_style == "apikey":
            return {"auth": {"RAX-KSKEY:apiKeyCredentials":
                    {"username": "%s" % self.username,
                    "apiKey": "%s" % self.api_key}}}
        else:
            # Return in the default password-style
            return super(RaxIdentity, self)._format_credentials()


    def authenticate(self, username=None, password=None, api_key=None,
            tenant_id=None):
        """
        If the user's credentials include an API key, the default behavior will
        work. But if they are using a password, the initial attempt will fail,
        so try again, but this time using the standard password format.
        """
        try:
            super(RaxIdentity, self).authenticate(username=username,
                    password=password, api_key=api_key, tenant_id=tenant_id)
        except exc.AuthenticationFailed:
            self._creds_style = "password"
            super(RaxIdentity, self).authenticate(username=username,
                    password=password, api_key=api_key, tenant_id=tenant_id)


    def auth_with_token(self, token, tenant_id=None, tenant_name=None):
        """
        If a valid token is already known, this call will use it to generate
        the service catalog.
        """
        # Implementation note:
        # Rackspace auth uses one tenant ID for the object_store services and
        # another for everything else. The one that the user would know is the
        # 'everything else' ID, so we need to extract the object_store tenant
        # ID from the initial response, and call the superclass
        # auth_with_token() method a second time with that tenant ID to get the
        # object_store endpoints. We can then add these to the initial
        # endpoints returned by the primary tenant ID, and then continue with
        # the auth process.
        main_resp, main_body = self._call_token_auth(token, tenant_id,
                tenant_name)
        # Get the swift tenant ID
        roles = main_body["access"]["user"]["roles"]
        ostore = [role for role in roles
                if role["name"] == "object-store:default"]
        if ostore:
            ostore_tenant_id = ostore[0]["tenantId"]
            ostore_resp, ostore_body = self._call_token_auth(token,
                    ostore_tenant_id, None)
            ostore_cat = ostore_body["access"]["serviceCatalog"]
            main_cat = main_body["access"]["serviceCatalog"]
            main_cat.extend(ostore_cat)
        self._parse_response(main_body)
        self.authenticated = True


    def _parse_response(self, resp):
        """Gets the authentication information from the returned JSON."""
        super(RaxIdentity, self)._parse_response(resp)
        user = resp["access"]["user"]
        defreg = user.get("RAX-AUTH:defaultRegion")
        if defreg:
            self._default_region = defreg


    def find_user_by_name(self, name):
        """
        Returns a User object by searching for the supplied user name. Returns
        None if there is no match for the given name.
        """
        return self.get_user(username=name)


    def find_user_by_email(self, email):
        """
        Returns a User object by searching for the supplied user's email
        address. Returns None if there is no match for the given ID.
        """
        return self.get_user(email=email)


    def find_user_by_id(self, uid):
        """
        Returns a User object by searching for the supplied user ID. Returns
        None if there is no match for the given ID.
        """
        return self.get_user(user_id=uid)


    def get_user(self, user_id=None, username=None, email=None):
        """
        Returns the user specified by either ID, username or email.

        Since more than user can have the same email address, searching by that
        term will return a list of 1 or more User objects. Searching by
        username or ID will return a single User.

        If a user_id that doesn't belong to the current account is searched
        for, a Forbidden exception is raised. When searching by username or
        email, a NotFound exception is raised if there is no matching user.
        """
        if user_id:
            uri = "/users/%s" % user_id
        elif username:
            uri = "/users?name=%s" % username
        elif email:
            uri = "/users?email=%s" % email
        else:
            raise ValueError("You must include one of 'user_id', "
                    "'username', or 'email' when calling get_user().")
        resp, resp_body = self.method_get(uri)
        if resp.status_code == 404:
            raise exc.NotFound("No such user exists.")
        users = resp_body.get("users", [])
        if users:
            return [User(self, user) for user in users]
        else:
            user = resp_body.get("user", {})
            if user:
                return User(self, user)
            else:
                raise exc.NotFound("No such user exists.")


    def update_user(self, user, email=None, username=None,
            uid=None, defaultRegion=None, enabled=None):
        """
        Allows you to update settings for a given user.
        """
        user_id = utils.get_id(user)
        uri = "users/%s" % user_id
        upd = {"id": user_id}
        if email is not None:
            upd["email"] = email
        if defaultRegion is not None:
            upd["RAX-AUTH:defaultRegion"] = defaultRegion
        if username is not None:
            upd["username"] = username
        if enabled is not None:
            upd["enabled"] = enabled
        data = {"user": upd}
        resp, resp_body = self.method_put(uri, data=data)
        if resp.status_code in (401, 403, 404):
            raise exc.AuthorizationFailure("You are not authorized to update "
                    "users.")
        return User(self, resp_body)


    def reset_api_key(self, user=None):
        """
        Resets the API key for the specified user, or if no user is specified,
        for the current user. Returns the newly-created API key.

        Resetting an API key does not invalidate any authenticated sessions,
        nor does it revoke any tokens.
        """
        if user is None:
            user_id = utils.get_id(self)
        else:
            user_id = utils.get_id(user)
        uri = "users/%s/OS-KSADM/credentials/" % user_id
        uri += "RAX-KSKEY:apiKeyCredentials/RAX-AUTH/reset"
        resp, resp_body = self.method_post(uri)
        return resp_body.get("RAX-KSKEY:apiKeyCredentials", {}).get("apiKey")

########NEW FILE########
__FILENAME__ = image
#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Copyright 2014 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from functools import wraps

import pyrax
from pyrax.client import BaseClient
import pyrax.exceptions as exc
from pyrax.manager import BaseManager
from pyrax.resource import BaseResource
import pyrax.utils as utils


DEFAULT_FORMAT = "vhd"


def assure_image(fnc):
    """
    Converts a image ID passed as the 'image' parameter to a image object.
    """
    @wraps(fnc)
    def _wrapped(self, img, *args, **kwargs):
        if not isinstance(img, Image):
            # Must be the ID
            img = self._manager.get(img)
        return fnc(self, img, *args, **kwargs)
    return _wrapped



class Image(BaseResource):
    """
    This class represents an Image.
    """
    def __init__(self, manager, info, key=None, loaded=False,
            member_manager_class=None, tag_manager_class=None):
        super(Image, self).__init__(manager, info, key=key, loaded=loaded)
        member_manager_class = member_manager_class or ImageMemberManager
        tag_manager_class = tag_manager_class or ImageTagManager
        self._member_manager = member_manager_class(self.manager.api,
                resource_class=ImageMember, response_key="",
                plural_response_key="members", uri_base="images/%s/members" %
                self.id)
        self._tag_manager = tag_manager_class(self.manager.api,
                resource_class=ImageTag, response_key="",
                plural_response_key="tags", uri_base="images/%s/tags" %
                self.id)
        self._non_display = [
                "com.rackspace__1__build_core",
                "com.rackspace__1__build_managed",
                "com.rackspace__1__build_rackconnect",
                "com.rackspace__1__options",
                "com.rackspace__1__platform_target",
                "com.rackspace__1__release_build_date",
                "com.rackspace__1__release_id",
                "com.rackspace__1__release_version",
                "com.rackspace__1__source",
                "com.rackspace__1__visible_core",
                "com.rackspace__1__visible_managed",
                "com.rackspace__1__visible_rackconnect",
                "file",
                "instance_type_ephemeral_gb",
                "instance_type_flavorid",
                "instance_type_id",
                "instance_type_memory_mb",
                "instance_type_name",
                "instance_type_root_gb",
                "instance_type_rxtx_factor",
                "instance_type_swap",
                "instance_type_vcpu_weight",
                "instance_type_vcpus",
                "instance_uuid",
                "org.openstack__1__architecture",
                "org.openstack__1__os_distro",
                "org.openstack__1__os_version",
                "rax_activation_profile",
                "rax_managed",
                "rax_options",
                "schema",
                "self",
                ]


    def update(self, value_dict):
        """
        Accepts a and dictionary of key/value pairs, where the key is an
        attribute of the image, and the value is the desired new value for that
        image.
        """
        return self.manager.update(self, value_dict)


    def change_name(self, newname):
        """
        Image name can be changed via the update() method. This is simply a
        convenience method.
        """
        return self.update({"name": newname})


    def list_members(self):
        """
        Returns a list of all Members for this image.
        """
        return self._member_manager.list()


    def get_member(self, member):
        """
        Returns the ImageMember object representing the specified member
        """
        return self._member_manager.get(member)


    def add_member(self, project_id):
        """
        Adds the project (tenant) represented by the project_id as a member of
        this image.
        """
        return self._member_manager.create(name=None, project_id=project_id)


    def delete_member(self, project_id):
        """
        Removes the project (tenant) represented by the project_id as a member
        of this image.
        """
        return self._member_manager.delete(project_id)


    def add_tag(self, tag):
        """
        Adds the tag to this image.
        """
        return self._tag_manager.add(tag)


    def delete_tag(self, tag):
        """
        Deletes the tag from this image.
        """
        return self._tag_manager.delete(tag)



class ImageMember(BaseResource):
    """
    This class represents a member (user) of an Image.
    """
    @property
    def id(self):
        return self.member_id



class ImageTag(BaseResource):
    """
    This class represents a tag for an Image.
    """
    pass



class ImageTask(BaseResource):
    """
    This class represents a ImageTask.
    """
    pass



class ImageManager(BaseManager):
    """
    Manager class for an Image.
    """
    def _create_body(self, name, metadata=None):
        """
        Used to create the dict required to create a new queue
        """
        if metadata is None:
            body = {}
        else:
            body = {"metadata": metadata}
        return body


    def list(self, limit=None, marker=None, name=None, visibility=None,
            member_status=None, owner=None, tag=None, status=None,
            size_min=None, size_max=None, sort_key=None, sort_dir=None,
            return_raw=False):
        """
        Returns a list of resource objects. Pagination is supported through the
        optional 'marker' and 'limit' parameters. Filtering the returned value
        is possible by specifying values for any of the other parameters.
        """
        uri = "/%s" % self.uri_base
        qs = utils.dict_to_qs(dict(limit=limit, marker=marker, name=name,
                visibility=visibility, member_status=member_status,
                owner=owner, tag=tag, status=status, size_min=size_min,
                size_max=size_max, sort_key=sort_key, sort_dir=sort_dir))
        if qs:
            uri = "%s?%s" % (uri, qs)
        return self._list(uri, return_raw=return_raw)


    def list_all(self, name=None, visibility=None, member_status=None,
            owner=None, tag=None, status=None, size_min=None, size_max=None,
            sort_key=None, sort_dir=None):
        """
        Returns all of the images in one call, rather than in paginated batches.
        """

        def strip_version(uri):
            """
            The 'next' uri contains a redundant version number. We need to
            strip it to use in the method_get() call.
            """
            pos = uri.find("/images")
            return uri[pos:]

        obj_class = self.resource_class
        resp, resp_body = self.list(name=name, visibility=visibility,
                member_status=member_status, owner=owner, tag=tag,
                status=status, size_min=size_min, size_max=size_max,
                sort_key=sort_key, sort_dir=sort_dir, return_raw=True)
        data = resp_body.get(self.plural_response_key, resp_body)
        next_uri = strip_version(resp_body.get("next", ""))
        ret = [obj_class(manager=self, info=res) for res in data if res]
        while next_uri:
            resp, resp_body = self.api.method_get(next_uri)
            data = resp_body.get(self.plural_response_key, resp_body)
            next_uri = strip_version(resp_body.get("next", ""))
            ret.extend([obj_class(manager=self, info=res)
                    for res in data if res])
        return ret


    def update(self, img, value_dict):
        """
        Accepts an image reference (object or ID) and  dictionary of key/value
        pairs, where the key is an attribute of the image, and the value is the
        desired new value for that image.

        NOTE: There is a bug in Glance where the 'add' operation returns a 409
        if the property already exists, which conflicts with the spec. So to
        get around this a fresh copy of the image must be retrieved, and the
        value of 'op' must be determined based on whether this attribute exists
        or not.
        """
        img = self.get(img)
        uri = "/%s/%s" % (self.uri_base, utils.get_id(img))
        body = []
        for key, val in value_dict.items():
            op = "replace" if key in img.__dict__ else "add"
            body.append({"op": op,
                    "path": "/%s" % key,
                    "value": val})
        headers = {"Content-Type":
                "application/openstack-images-v2.1-json-patch"}
        resp, resp_body = self.api.method_patch(uri, body=body, headers=headers)


    def update_image_member(self, img_id, status):
        """
        Updates the image whose ID is given with the status specified. This
        must be called by the user whose project_id is in the members for the
        image. If called by the owner of the image, an InvalidImageMember
        exception will be raised.

        Valid values for 'status' include:
            pending
            accepted
            rejected
        Any other value will result in an InvalidImageMemberStatus exception
        being raised.
        """
        if status not in ("pending", "accepted", "rejected"):
            raise exc.InvalidImageMemberStatus("The status value must be one "
                    "of 'accepted', 'rejected', or 'pending'. Received: '%s'" %
                    status)
        api = self.api
        project_id = api.identity.tenant_id
        uri = "/%s/%s/members/%s" % (self.uri_base, img_id, project_id)
        body = {"status": status}
        try:
            resp, resp_body = self.api.method_put(uri, body=body)
        except exc.NotFound as e:
            raise exc.InvalidImageMember("The update member request could not "
                    "be completed. No member request for that image was found.")



class ImageMemberManager(BaseManager):
    """
    Manager class for members (users) of an Image.
    """
    def _create_body(self, name, project_id):
        """
        Used to create the dict required to add a member to this image.
        """
        body = {"member": project_id}
        return body


    def create(self, name, *args, **kwargs):
        """
        Need to wrap the default call to handle exceptions.
        """
        try:
            return super(ImageMemberManager, self).create(name, *args, **kwargs)
        except Exception as e:
            if e.http_status == 403:
                raise exc.UnsharableImage("You cannot share a public image.")
            else:
                raise



class ImageTagManager(BaseManager):
    """
    Manager class for Image tags.
    """
    def _create_body(self, name):
        """
        Not used; the add() method is used with a PUT request.
        """
        return {}


    def add(self, tag):
        """
        """
        uri = "/%s/%s" % (self.uri_base, tag)
        resp, resp_body = self.api.method_put(uri)



class ImageTasksManager(BaseManager):
    """
    Manager class for ImageTasks.
    """
    def _create_body(self, name, img=None, cont=None, img_format=None,
            img_name=None):
        """
        Used to create a new task. Since tasks don't have names, the required
        'name' parameter is used for the type of task: 'import' or 'export'.
        """
        img = utils.get_id(img)
        cont = utils.get_name(cont)
        body = {"type": name}
        if name == "export":
            body["input"] = {
                    "image_uuid": img,
                    "receiving_swift_container": cont}
        else:
            nm = "%s/%s" % (cont, utils.get_name(img))
            body["input"] = {
                    "image_properties": {"name": img_name or img},
                    "import_from": nm,
                    "import_from_format": img_format or DEFAULT_FORMAT}
        return body


    def create(self, name, *args, **kwargs):
        """
        Standard task creation, but first check for the existence of the
        containers, and raise an exception if they don't exist.
        """
        cont = kwargs.get("cont")
        if cont:
            # Verify that it exists. If it doesn't, a NoSuchContainer exception
            # will be raised.
            api = self.api
            rgn = api.region_name
            cf = api.identity.object_store[rgn].client
            cf.get_container(cont)
        return super(ImageTasksManager, self).create(name, *args, **kwargs)



class JSONSchemaManager(BaseManager):
    """
    Manager class for retrieving JSON schemas.
    """
    def _create_body(self, name):
        """
        Not used.
        """
        pass


    def images(self):
        """
        Returns a json-schema document that represents an image members entity,
        which is a container of image member entities.
        """
        uri = "/%s/images" % self.uri_base
        resp, resp_body = self.api.method_get(uri)
        return resp_body


    def image(self):
        """
        Returns a json-schema document that represents a single image entity.
        """
        uri = "/%s/image" % self.uri_base
        resp, resp_body = self.api.method_get(uri)
        return resp_body


    def image_members(self):
        """
        Returns a json-schema document that represents an image members entity
        (a container of member entities).
        """
        uri = "/%s/members" % self.uri_base
        resp, resp_body = self.api.method_get(uri)
        return resp_body


    def image_member(self):
        """
        Returns a json-schema document that represents an image member entity.
        (a container of member entities).
        """
        uri = "/%s/member" % self.uri_base
        resp, resp_body = self.api.method_get(uri)
        return resp_body


    def image_tasks(self):
        """
        Returns a json-schema document that represents a container of tasks
        entities.
        """
        uri = "/%s/tasks" % self.uri_base
        resp, resp_body = self.api.method_get(uri)
        return resp_body


    def image_task(self):
        """
        Returns a json-schema document that represents an task entity.
        """
        uri = "/%s/task" % self.uri_base
        resp, resp_body = self.api.method_get(uri)
        return resp_body



class ImageClient(BaseClient):
    """
    This is the primary class for interacting with Images.
    """
    name = "Images"


    def _configure_manager(self):
        """
        Create the manager to handle queues.
        """
        self._manager = ImageManager(self, resource_class=Image,
                response_key="", plural_response_key="images",
                uri_base="images")
        self._tasks_manager = ImageTasksManager(self, resource_class=ImageTask,
                response_key="", plural_response_key="tasks",
                uri_base="tasks")
        self._schema_manager = JSONSchemaManager(self, resource_class=None,
                response_key="", plural_response_key="", uri_base="schemas")


    def list(self, limit=None, marker=None, name=None, visibility=None,
            member_status=None, owner=None, tag=None, status=None,
            size_min=None, size_max=None, sort_key=None, sort_dir=None):
        """
        Returns a list of resource objects. Pagination is supported through the
        optional 'marker' and 'limit' parameters. Filtering the returned value
        is possible by specifying values for any of the other parameters.
        """
        return self._manager.list(limit=limit, marker=marker, name=name,
                visibility=visibility, member_status=member_status,
                owner=owner, tag=tag, status=status, size_min=size_min,
                size_max=size_max, sort_key=sort_key, sort_dir=sort_dir)


    def list_all(self, name=None, visibility=None, member_status=None,
            owner=None, tag=None, status=None, size_min=None, size_max=None,
            sort_key=None, sort_dir=None):
        """
        Returns all of the images in one call, rather than in paginated batches.
        The same filtering options available in list() apply here, with the
        obvious exception of limit and marker.
        """
        return self._manager.list_all(name=name, visibility=visibility,
                member_status=member_status, owner=owner, tag=tag,
                status=status, size_min=size_min, size_max=size_max,
                sort_key=sort_key, sort_dir=sort_dir)


    def update(self, img, value_dict):
        """
        Accepts an image reference (object or ID) and  dictionary of key/value
        pairs, where the key is an attribute of the image, and the value is the
        desired new value for that image.
        """
        return self._manager.update(img, value_dict)


    def change_image_name(self, img, newname):
        """
        Image name can be changed via the update() method. This is simply a
        convenience method.
        """
        return self.update(img, {"name": newname})


    @assure_image
    def list_image_members(self, img):
        """
        Returns a list of members (users) of the specified image.
        """
        return img.list_members()


    @assure_image
    def get_image_member(self, img, member):
        """
        Returns the ImageMember object representing the specified member for the
        specified image.
        """
        return img.get_member(member)


    @assure_image
    def add_image_member(self, img, project_id):
        """
        Adds the project (tenant) represented by the project_id as a member of
        the specified image.
        """
        return img.add_member(project_id)


    @assure_image
    def delete_image_member(self, img, project_id):
        """
        Removes the project (tenant) represented by the project_id as a member
        of the specified image.
        """
        return img.delete_member(project_id)


    def update_image_member(self, img_id, status):
        """
        Updates the image whose ID is given with the status specified. This
        must be called by the user whose project_id is in the members for the
        image; that is, the user with whom the image is being shared. If called
        by the owner of the image, an `InvalidImageMember` exception will be
        raised.

        Valid values for 'status' include:
            pending
            accepted
            rejected

        Any other value will result in an `InvalidImageMemberStatus` exception
        being raised.
        """
        return self._manager.update_image_member(img_id, status)


    @assure_image
    def add_image_tag(self, img, tag):
        """
        Adds the tag to the specified image.
        """
        return img.add_tag(tag)


    @assure_image
    def delete_image_tag(self, img, tag):
        """
        Deletes the tag from the specified image.
        """
        return img.delete_tag(tag)


    def list_tasks(self):
        """
        Returns a list of all tasks.
        """
        return self._tasks_manager.list()


    def get_task(self, task):
        """
        Returns the ImageTask object for the supplied ID.
        """
        return self._tasks_manager.get(task)


    def export_task(self, img, cont):
        """
        Creates a task to export the specified image to the swift container
        named in the 'cont' parameter. If the container does not exist, a
        NoSuchContainer exception is raised.

        The 'img' parameter can be either an Image object or the ID of an
        image. If these do not correspond to a valid image, a NotFound
        exception is raised.
        """
        return self._tasks_manager.create("export", img=img, cont=cont)


    def import_task(self, img, cont, img_format=None, img_name=None):
        """
        Creates a task to import the specified image from the swift container
        named in the 'cont' parameter. The new image will be named the same as
        the object in the container unless you specify a value for the
        'img_name' parameter.

        By default it is assumed that the image is in 'vhd' format; if it is
        another format, you must specify that in the 'img_format' parameter.
        """
        return self._tasks_manager.create("import", img=img, cont=cont,
                img_format=img_format, img_name=img_name)


    def get_images_schema(self):
        """
        Returns a json-schema document that represents an image members entity,
        which is a container of image member entities.
        """
        return self._schema_manager.images()


    def get_image_schema(self):
        """
        Returns a json-schema document that represents a single image entity.
        """
        return self._schema_manager.image()


    def get_image_members_schema(self):
        """
        Returns a json-schema document that represents an image members entity
        (a container of member entities).
        """
        return self._schema_manager.image_members()


    def get_image_member_schema(self):
        """
        Returns a json-schema document that represents an image member entity.
        (a container of member entities).
        """
        return self._schema_manager.image_member()


    def get_image_tasks_schema(self):
        """
        Returns a json-schema document that represents a container of tasks
        entities.
        """
        return self._schema_manager.image_tasks()


    def get_image_task_schema(self):
        """
        Returns a json-schema document that represents an task entity.
        """
        return self._schema_manager.image_task()

########NEW FILE########
__FILENAME__ = manager
# Copyright 2010 Jacob Kaplan-Moss

# Copyright 2011 OpenStack LLC.
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

"""
Base utilities to build API operation managers and objects on top of.
"""

import pyrax.exceptions as exc
import pyrax.utils as utils


# Python 2.4 compat
try:
    all
except NameError:
    def all(iterable):
        return True not in (not x for x in iterable)



class BaseManager(object):
    """
    Managers interact with a particular type of API (servers, databases, dns,
    etc.) and provide CRUD operations for them.
    """
    resource_class = None
    response_key = None
    plural_response_key = None
    uri_base = None
    _hooks_map = {}


    def __init__(self, api, resource_class=None, response_key=None,
            plural_response_key=None, uri_base=None):
        self.api = api
        self.resource_class = resource_class
        self.response_key = response_key
        self.plural_response_key = plural_response_key
        if plural_response_key is None and response_key is not None:
            # Default to adding 's'
            self.plural_response_key = "%ss" % response_key
        self.uri_base = uri_base


    def list(self, limit=None, marker=None, return_raw=False):
        """
        Returns a list of resource objects. Pagination is supported through the
        optional 'marker' and 'limit' parameters.

        Some APIs do not follow the typical pattern in their responses, and the
        BaseManager subclasses will have to parse the raw response to get the
        desired information. For those cases, pass 'return_raw=True', and the
        response and response_body will be returned unprocessed.
        """
        uri = "/%s" % self.uri_base
        pagination_items = []
        if limit is not None:
            pagination_items.append("limit=%s" % limit)
        if marker is not None:
            pagination_items.append("marker=%s" % marker)
        pagination = "&".join(pagination_items)
        if pagination:
            uri = "%s?%s" % (uri, pagination)
        return self._list(uri, return_raw=return_raw)


    def head(self, item):
        """Makes a HEAD request on a specific item."""
        uri = "/%s/%s" % (self.uri_base, utils.get_id(item))
        return self._head(uri)


    def get(self, item):
        """Gets a specific item."""
        uri = "/%s/%s" % (self.uri_base, utils.get_id(item))
        return self._get(uri)


    def create(self, name, *args, **kwargs):
        """
        Subclasses need to implement the _create_body() method to return a dict
        that will be used for the API request body.

        For cases where no response is returned from the API on creation, pass
        `return_none=True` so that the _create method doesn't expect one.

        For cases where you do not want the _create method to attempt to parse
        the response, but instead have it returned directly, pass
        `return_raw=True`.

        For cases where the API returns information in the response and not the
        response_body, pass `return_response=True`.
        """
        return_none = kwargs.pop("return_none", False)
        return_raw = kwargs.pop("return_raw", False)
        return_response = kwargs.pop("return_response", False)
        body = self._create_body(name, *args, **kwargs)
        return self._create("/%s" % self.uri_base, body,
                return_none=return_none, return_raw=return_raw,
                return_response=return_response)


    def _create_body(self, name, *args, **kwargs):
        """
        Creates the dictionary that is passed in the POST call to create a new
        resource. Must be defined in each subclass.
        """
        raise NotImplementedError("Managers must define their _create_body() "
                "method.")


    def delete(self, item):
        """Deletes the specified item."""
        uri = "/%s/%s" % (self.uri_base, utils.get_id(item))
        return self._delete(uri)


    def _list(self, uri, obj_class=None, body=None, return_raw=False):
        """
        Handles the communication with the API when getting
        a full listing of the resources managed by this class.
        """
        if body:
            resp, resp_body = self.api.method_post(uri, body=body)
        else:
            resp, resp_body = self.api.method_get(uri)
        if return_raw:
            return (resp, resp_body)
        if obj_class is None:
            obj_class = self.resource_class

        data = self._data_from_response(resp_body)
        return [obj_class(self, res, loaded=False)
                for res in data if res]


    def _data_from_response(self, resp_body):
        """
        This works for most API responses, but some don't structure their
        listing responses the same way, so overriding this method allows
        subclasses to handle extraction for those outliers.
        """
        data = resp_body.get(self.plural_response_key, resp_body)
        # NOTE(ja): keystone returns values as list as {"values": [ ... ]}
        #           unlike other services which just return the list...
        if isinstance(data, dict):
            try:
                data = data["values"]
            except KeyError:
                pass
        return data


    def _head(self, uri):
        """
        Handles the communication with the API when performing a HEAD request
        on a specific resource managed by this class. Returns the headers
        contained in the response.
        """
        resp, resp_body = self.api.method_head(uri)
        return resp


    def _get(self, uri):
        """
        Handles the communication with the API when getting
        a specific resource managed by this class.
        """
        resp, resp_body = self.api.method_get(uri)
        return self.resource_class(self, resp_body, self.response_key,
                loaded=True)


    def _create(self, uri, body, return_none=False, return_raw=False,
            return_response=None, **kwargs):
        """
        Handles the communication with the API when creating a new
        resource managed by this class.
        """
        self.run_hooks("modify_body_for_create", body, **kwargs)
        resp, resp_body = self.api.method_post(uri, body=body)
        if return_none:
            # No response body
            return
        elif return_response:
            return resp
        elif return_raw:
            if self.response_key:
                return resp_body[self.response_key]
            else:
                return resp_body
        return self.resource_class(self, resp_body, self.response_key)


    def _delete(self, uri):
        """
        Handles the communication with the API when deleting
        a specific resource managed by this class.
        """
        _resp, _body = self.api.method_delete(uri)


    def _update(self, uri, body, **kwargs):
        """
        Handles the communication with the API when updating
        a specific resource managed by this class.
        """
        self.run_hooks("modify_body_for_update", body, **kwargs)
        resp, resp_body = self.api.method_put(uri, body=body)
        return resp_body


    def action(self, item, action_type, body={}):
        """
        Several API calls are lumped under the 'action' API. This
        is the generic handler for such calls.
        """
        uri = "/%s/%s/action" % (self.uri_base, utils.get_id(item))
        action_body = {action_type: body}
        return self.api.method_post(uri, body=action_body)


    def find(self, **kwargs):
        """
        Finds a single item with attributes matching ``**kwargs``.

        This isn't very efficient: it loads the entire list then filters on
        the Python side.
        """
        matches = self.findall(**kwargs)
        num_matches = len(matches)
        if not num_matches:
            msg = "No %s matching: %s." % (self.resource_class.__name__, kwargs)
            raise exc.NotFound(404, msg)
        if num_matches > 1:
            msg = "More than one %s matching: %s." % (
                    self.resource_class.__name__, kwargs)
            raise exc.NoUniqueMatch(400, msg)
        else:
            return matches[0]


    def findall(self, **kwargs):
        """
        Finds all items with attributes matching ``**kwargs``.

        This isn't very efficient: it loads the entire list then filters on
        the Python side.
        """
        found = []
        searches = kwargs.items()

        for obj in self.list():
            try:
                if all(getattr(obj, attr) == value
                        for (attr, value) in searches):
                    found.append(obj)
            except AttributeError:
                continue
        return found


    @classmethod
    def add_hook(cls, hook_type, hook_func):
        if hook_type not in cls._hooks_map:
            cls._hooks_map[hook_type] = []

        cls._hooks_map[hook_type].append(hook_func)


    @classmethod
    def run_hooks(cls, hook_type, *args, **kwargs):
        hook_funcs = cls._hooks_map.get(hook_type) or []
        for hook_func in hook_funcs:
            hook_func(*args, **kwargs)

########NEW FILE########
__FILENAME__ = queueing
#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from functools import wraps
import json
import os
import re
import urlparse

import pyrax
from pyrax.client import BaseClient
import pyrax.exceptions as exc
from pyrax.manager import BaseManager
from pyrax.resource import BaseResource
import pyrax.utils as utils

# The hard-coded maximum number of messages returned in a single call.
MSG_LIMIT = 10
# Pattern for extracting the marker value from an href link.
marker_pat = re.compile(r".+\bmarker=(\d+).*")


def _parse_marker(body):
    marker = None
    links = body.get("links", [])
    next_links = [link for link in links if link.get("rel") == "next"]
    try:
        next_link = next_links[0]["href"]
    except IndexError:
        next_link = ""
    mtch = marker_pat.match(next_link)
    if mtch:
        marker = mtch.groups()[0]
    return marker


def assure_queue(fnc):
    """
    Converts a queue ID or name passed as the 'queue' parameter to a Queue
    object.
    """
    @wraps(fnc)
    def _wrapped(self, queue, *args, **kwargs):
        if not isinstance(queue, Queue):
            # Must be the ID
            queue = self._manager.get(queue)
        return fnc(self, queue, *args, **kwargs)
    return _wrapped



class BaseQueueManager(BaseManager):
    """
    This class attempts to add in all the common deviations from the API
    standards that the regular base classes are based on.
    """
    def _list(self, uri, obj_class=None, body=None, return_raw=False):
        try:
            return super(BaseQueueManager, self)._list(uri, obj_class=None,
                    body=None, return_raw=return_raw)
        except (exc.NotFound, AttributeError):
            return []



class Queue(BaseResource):
    """
    This class represents a Queue.
    """
    def __init__(self, manager, info, key=None, loaded=False):
        # Queues are often returned with no info
        info = info or {"queue": {}}
        super(Queue, self).__init__(manager, info, key=key, loaded=loaded)
        self._repr_properties = ["id"]
        self._message_manager = QueueMessageManager(self.manager.api,
                resource_class=QueueMessage, response_key="",
                plural_response_key="messages",
                uri_base="queues/%s/messages" % self.id)
        self._claim_manager = QueueClaimManager(self.manager.api,
                resource_class=QueueClaim, response_key="",
                plural_response_key="claims",
                uri_base="queues/%s/claims" % self.id)
        self._claim_manager._message_manager = self._message_manager


    def get_message(self, msg_id):
        """
        Returns the message whose ID matches the supplied msg_id from this
        queue.
        """
        return self._message_manager.get(msg_id)


    def delete_message(self, msg_id, claim_id=None):
        """
        Deletes the message whose ID matches the supplied msg_id from the
        specified queue. If the message has been claimed, the ID of that claim
        must be passed as the 'claim_id' parameter.
        """
        return self._message_manager.delete(msg_id, claim_id=claim_id)


    def list(self, include_claimed=False, echo=False, marker=None, limit=None):
        """
        Returns a list of messages for this queue.

        By default only unclaimed messages are returned; if you want claimed
        messages included, pass `include_claimed=True`. Also, the requester's
        own messages are not returned by default; if you want them included,
        pass `echo=True`.

        The 'marker' and 'limit' parameters are used to control pagination of
        results. 'Marker' is the ID of the last message returned, while 'limit'
        controls the number of messages returned per reuqest (default=20).
        """
        return self._message_manager.list(include_claimed=include_claimed,
                echo=echo, marker=marker, limit=limit)


    def list_by_ids(self, ids):
        """
        If you wish to retrieve a list of messages from this queue and know the
        IDs of those messages, you can pass in a list of those IDs, and only
        the matching messages will be returned. This avoids pulling down all
        the messages in a queue and filtering on the client side.
        """
        return self._message_manager.list_by_ids(ids)


    def delete_by_ids(self, ids):
        """
        Deletes the messages whose IDs are passed in from this queue.
        """
        return self._message_manager.delete_by_ids(ids)


    def list_by_claim(self, claim):
        """
        Returns a list of all the messages from this queue that have been
        claimed by the specified claim. The claim can be either a claim ID or a
        QueueClaim object.
        """
        if not isinstance(claim, QueueClaim):
            claim = self._claim_manager.get(claim)
        return claim.messages


    def post_message(self, body, ttl):
        """
        Create a message in this queue. The value of ttl must be between 60 and
        1209600 seconds (14 days).
        """
        return self._message_manager.create(body, ttl)


    def claim_messages(self, ttl, grace, count=None):
        """
        Claims up to `count` unclaimed messages from this queue. If count is
        not specified, the default is to claim 10 messages.

        The `ttl` parameter specifies how long the server should wait before
        releasing the claim. The ttl value MUST be between 60 and 43200 seconds.

        The `grace` parameter is the message grace period in seconds. The value
        of grace MUST be between 60 and 43200 seconds. The server extends the
        lifetime of claimed messages to be at least as long as the lifetime of
        the claim itself, plus a specified grace period to deal with crashed
        workers (up to 1209600 or 14 days including claim lifetime). If a
        claimed message would normally live longer than the grace period, its
        expiration will not be adjusted.

        Returns a QueueClaim object, whose 'messages' attribute contains the
        list of QueueMessage objects representing the claimed messages.
        """
        return self._claim_manager.claim(ttl, grace, count=count)


    def get_claim(self, claim):
        """
        Returns a QueueClaim object with information about the specified claim.
        If no such claim exists, a NotFound exception is raised.
        """
        return self._claim_manager.get(claim)


    def update_claim(self, claim, ttl=None, grace=None):
        """
        Updates the specified claim with either a new TTL or grace period, or
        both.
        """
        return self._claim_manager.update(claim, ttl=ttl, grace=grace)


    def release_claim(self, claim):
        """
        Releases the specified claim and makes any messages previously claimed
        by this claim as available for processing by other workers.
        """
        return self._claim_manager.delete(claim)


    @property
    def id(self):
        return self.name

    @id.setter
    def id(self, val):
        self.name = val



class QueueMessage(BaseResource):
    """
    This class represents a Message posted to a Queue.
    """
    def __init__(self, *args, **kwargs):
        self.id = None
        self.age = None
        self.body = None
        self.href = None
        self.ttl = None
        self.claim_id = None
        super(QueueMessage, self).__init__(*args, **kwargs)


    def _add_details(self, info):
        """
        The 'id' and 'claim_id' attributes are not supplied directly, but
        included as part of the 'href' value.
        """
        super(QueueMessage, self)._add_details(info)
        if self.href is None:
            return
        parsed = urlparse.urlparse(self.href)
        self.id = parsed.path.rsplit("/", 1)[-1]
        query = parsed.query
        if query:
            self.claim_id = query.split("claim_id=")[-1]


    def delete(self, claim_id=None):
        """
        Deletes this message from its queue. If the message has been claimed,
        the ID of that claim must be passed as the 'claim_id' parameter.
        """
        return self.manager.delete(self, claim_id=claim_id)



class QueueClaim(BaseResource):
    """
    This class represents a Claim for a Message posted by a consumer.
    """
    id = None
    messages = None
    href = ""

    def _add_details(self, info):
        """
        The 'id' attribute is not supplied directly, but included as part of
        the 'href' value. Also, convert the dicts for messages into
        QueueMessage objects.
        """
        msg_dicts = info.pop("messages", [])
        super(QueueClaim, self)._add_details(info)
        parsed = urlparse.urlparse(self.href)
        self.id = parsed.path.rsplit("/", 1)[-1]
        self.messages = [QueueMessage(self.manager._message_manager, item)
                for item in msg_dicts]



class QueueMessageManager(BaseQueueManager):
    """
    Manager class for a Queue Message.
    """
    def _create_body(self, msg, ttl):
        """
        Used to create the dict required to create a new message.
        """
        body = [{
                "body": msg,
                "ttl": ttl,
                }]
        return body


    def list(self, include_claimed=False, echo=False, marker=None, limit=None):
        """
        Need to form the URI differently, so we can't use the default list().
        """
        return self._iterate_list(include_claimed=include_claimed, echo=echo,
                marker=marker, limit=limit)


    def _iterate_list(self, include_claimed, echo, marker, limit):
        """
        Recursive method to work around the hard limit of 10 items per call.
        """
        ret = []
        if limit is None:
            this_limit = MSG_LIMIT
        else:
            this_limit = min(MSG_LIMIT, limit)
            limit = limit - this_limit
        uri = "/%s?include_claimed=%s&echo=%s" % (self.uri_base,
                json.dumps(include_claimed), json.dumps(echo))
        qs_parts = []
        if marker is not None:
            qs_parts.append("marker=%s" % marker)
        if this_limit is not None:
            qs_parts.append("limit=%s" % this_limit)
        if qs_parts:
            uri = "%s&%s" % (uri, "&".join(qs_parts))
        resp, resp_body = self._list(uri, return_raw=True)
        if not resp_body:
            return ret
        messages = resp_body.get(self.plural_response_key, [])
        ret = [QueueMessage(manager=self, info=item) for item in messages]
        marker = _parse_marker(resp_body)

        loop = 0
        if ((limit is None) or limit > 0) and marker:
            loop += 1
            ret.extend(self._iterate_list(include_claimed, echo, marker, limit))
        return ret


    def delete(self, msg, claim_id=None):
        """
        Deletes the specified message from its queue. If the message has been
        claimed, the ID of that claim must be passed as the 'claim_id'
        parameter.
        """
        msg_id = utils.get_id(msg)
        if claim_id:
            uri = "/%s/%s?claim_id=%s" % (self.uri_base, msg_id, claim_id)
        else:
            uri = "/%s/%s" % (self.uri_base, msg_id)
        return self._delete(uri)


    def list_by_ids(self, ids):
        """
        If you wish to retrieve a list of messages from this queue and know the
        IDs of those messages, you can pass in a list of those IDs, and only
        the matching messages will be returned. This avoids pulling down all
        the messages in a queue and filtering on the client side.
        """
        ids = utils.coerce_string_to_list(ids)
        uri = "/%s?ids=%s" % (self.uri_base, ",".join(ids))
        # The API is not consistent in how it returns message lists, so this
        # workaround is needed.
        curr_prkey = self.plural_response_key
        self.plural_response_key = ""
        # BROKEN: API returns a list, not a dict.
        ret = self._list(uri)
        self.plural_response_key = curr_prkey
        return ret


    def delete_by_ids(self, ids):
        """
        Deletes the messages whose IDs are passed in from this queue.
        """
        ids = utils.coerce_string_to_list(ids)
        uri = "/%s?ids=%s" % (self.uri_base, ",".join(ids))
        return self.api.method_delete(uri)



class QueueClaimManager(BaseQueueManager):
    """
    Manager class for a Queue Claims.
    """
    def claim(self, ttl, grace, count=None):
        """
        Claims up to `count` unclaimed messages from this queue. If count is
        not specified, the default is to claim 10 messages.

        The `ttl` parameter specifies how long the server should wait before
        releasing the claim. The ttl value MUST be between 60 and 43200 seconds.

        The `grace` parameter is the message grace period in seconds. The value
        of grace MUST be between 60 and 43200 seconds. The server extends the
        lifetime of claimed messages to be at least as long as the lifetime of
        the claim itself, plus a specified grace period to deal with crashed
        workers (up to 1209600 or 14 days including claim lifetime). If a
        claimed message would normally live longer than the grace period, its
        expiration will not be adjusted.

        bReturns a QueueClaim object, whose 'messages' attribute contains the
        list of QueueMessage objects representing the claimed messages.
        """
        if count is None:
            qs = ""
        else:
            qs = "?limit=%s" % count
        uri = "/%s%s" % (self.uri_base, qs)
        body = {"ttl": ttl,
                "grace": grace,
                }
        resp, resp_body = self.api.method_post(uri, body=body)
        if resp.status_code == 204:
            # Nothing available to claim
            return None
        # Get the claim ID from the first message in the list.
        href = resp_body[0]["href"]
        claim_id = href.split("claim_id=")[-1]
        return self.get(claim_id)


    def update(self, claim, ttl=None, grace=None):
        """
        Updates the specified claim with either a new TTL or grace period, or
        both.
        """
        body = {}
        if ttl is not None:
            body["ttl"] = ttl
        if grace is not None:
            body["grace"] = grace
        if not body:
            raise exc.MissingClaimParameters("You must supply a value for "
                    "'ttl' or 'grace' when calling 'update()'")
        uri = "/%s/%s" % (self.uri_base, utils.get_id(claim))
        resp, resp_body = self.api.method_patch(uri, body=body)



class QueueManager(BaseQueueManager):
    """
    Manager class for a Queue.
    """
    def _create_body(self, name, metadata=None):
        """
        Used to create the dict required to create a new queue
        """
        if metadata is None:
            body = {}
        else:
            body = {"metadata": metadata}
        return body


    def get(self, id_):
        """
        Need to customize, since Queues are not returned with normal response
        bodies.
        """
        if self.api.queue_exists(id_):
            return Queue(self, {"queue": {"name": id_, "id_": id_}}, key="queue")
        raise exc.NotFound("The queue '%s' does not exist." % id_)


    def create(self, name):
        uri = "/%s/%s" % (self.uri_base, name)
        resp, resp_body = self.api.method_put(uri)
        if resp.status_code == 201:
            return Queue(self, {"name": name})
        elif resp.status_code == 400:
            # Most likely an invalid name
            raise exc.InvalidQueueName("Queue names must not exceed 64 bytes "
                    "in length, and are limited to US-ASCII letters, digits, "
                    "underscores, and hyphens. Submitted: '%s'." % name)


    def get_stats(self, queue):
        """
        Returns the message stats for the specified queue.
        """
        uri = "/%s/%s/stats" % (self.uri_base, utils.get_id(queue))
        resp, resp_body = self.api.method_get(uri)
        return resp_body.get("messages")


    def get_metadata(self, queue):
        """
        Returns the metadata for the specified queue.
        """
        uri = "/%s/%s/metadata" % (self.uri_base, utils.get_id(queue))
        resp, resp_body = self.api.method_get(uri)
        return resp_body


    def set_metadata(self, queue, metadata, clear=False):
        """
        Accepts a dictionary and adds that to the specified queue's metadata.
        If the 'clear' argument is passed as True, any existing metadata is
        replaced with the new metadata.
        """
        uri = "/%s/%s/metadata" % (self.uri_base, utils.get_id(queue))
        if clear:
            curr = {}
        else:
            curr = self.get_metadata(queue)
        curr.update(metadata)
        resp, resp_body = self.api.method_put(uri, body=curr)



class QueueClient(BaseClient):
    """
    This is the primary class for interacting with Cloud Queues.
    """
    name = "Cloud Queues"
    client_id = None


    def _configure_manager(self):
        """
        Create the manager to handle queues.
        """
        self._manager = QueueManager(self,
                resource_class=Queue, response_key="queue",
                uri_base="queues")


    def _add_custom_headers(self, dct):
        """
        Add the Client-ID header required by Cloud Queues
        """
        if self.client_id is None:
            self.client_id = os.environ.get("CLOUD_QUEUES_ID")
        if self.client_id:
            dct["Client-ID"] = self.client_id


    def _api_request(self, uri, method, **kwargs):
        """
        Any request that involves messages must define the client ID. This
        handles all failures due to lack of client ID and raises the
        appropriate exception.
        """
        try:
            return super(QueueClient, self)._api_request(uri, method, **kwargs)
        except exc.BadRequest as e:
            if ((e.code == "400") and
                    (e.message == 'The "Client-ID" header is required.')):
                raise exc.QueueClientIDNotDefined("You must supply a client ID "
                        "to work with Queue messages.")
            else:
                raise


    def get_home_document(self):
        """
        You should never need to use this method; it is included for
        completeness. It is meant to be used for API clients that need to
        explore the API with no prior knowledge. This knowledge is already
        included in the SDK, so it should never be necessary to work at this
        basic a level, as all the functionality is exposed through normal
        Python methods in the client.

        If you are curious about the 'Home Document' concept, here is the
        explanation from the Cloud Queues documentation:

        The entire API is discoverable from a single starting point - the home
        document. You do not need to know any more than this one URI in order
        to explore the entire API. This document is cacheable.

        The home document lets you write clients using a "follow-your-nose"
        style so clients do not have to construct their own URLs. You can click
        through and view the JSON doc in your browser.

        For more information about home documents, see
        http://tools.ietf.org/html/draft-nottingham-json-home-02.
        """
        uri = self.management_url.rsplit("/", 1)[0]
        return self.method_get(uri)


    def queue_exists(self, name):
        """
        Returns True or False, depending on the existence of the named queue.
        """
        try:
            queue = self._manager.head(name)
            return True
        except exc.NotFound:
            return False


    def create(self, name):
        """
        Cloud Queues works differently, in that they use the name as the ID for
        the resource. So for create(), we need to check if a queue by that name
        exists already, and raise an exception if it does. If not, create the
        queue and return a reference object for it.
        """
        if self.queue_exists(name):
            raise exc.DuplicateQueue("The queue '%s' already exists." % name)
        return self._manager.create(name)


    def get_stats(self, queue):
        """
        Returns the message stats for the specified queue.
        """
        return self._manager.get_stats(queue)


    def get_metadata(self, queue):
        """
        Returns the metadata for the specified queue.
        """
        return self._manager.get_metadata(queue)


    def set_metadata(self, queue, metadata, clear=False):
        """
        Accepts a dictionary and adds that to the specified queue's metadata.
        If the 'clear' argument is passed as True, any existing metadata is
        replaced with the new metadata.
        """
        return self._manager.set_metadata(queue, metadata, clear=clear)


    @assure_queue
    def get_message(self, queue, msg_id):
        """
        Returns the message whose ID matches the supplied msg_id from the
        specified queue.
        """
        return queue.get_message(msg_id)


    @assure_queue
    def delete_message(self, queue, msg_id, claim_id=None):
        """
        Deletes the message whose ID matches the supplied msg_id from the
        specified queue. If the message has been claimed, the ID of that claim
        must be passed as the 'claim_id' parameter.
        """
        return queue.delete_message(msg_id, claim_id=claim_id)


    @assure_queue
    def list_messages(self, queue, include_claimed=False, echo=False,
            marker=None, limit=None):
        """
        Returns a list of messages for the specified queue.

        By default only unclaimed messages are returned; if you want claimed
        messages included, pass `include_claimed=True`. Also, the requester's
        own messages are not returned by default; if you want them included,
        pass `echo=True`.

        The 'marker' and 'limit' parameters are used to control pagination of
        results. 'Marker' is the ID of the last message returned, while 'limit'
        controls the number of messages returned per reuqest (default=20).
        """
        return queue.list(include_claimed=include_claimed, echo=echo,
                marker=marker, limit=limit)


    @assure_queue
    def list_messages_by_ids(self, queue, ids):
        """
        If you wish to retrieve a list of messages from a queue and know the
        IDs of those messages, you can pass in a list of those IDs, and only
        the matching messages will be returned. This avoids pulling down all
        the messages in a queue and filtering on the client side.
        """
        return queue.list_by_ids(ids)


    @assure_queue
    def delete_messages_by_ids(self, queue, ids):
        """
        Deletes the messages whose IDs are passed in from the specified queue.
        """
        return queue.delete_by_ids(ids)


    @assure_queue
    def list_messages_by_claim(self, queue, claim):
        """
        Returns a list of all the messages from the specified queue that have
        been claimed by the specified claim. The claim can be either a claim ID
        or a QueueClaim object.
        """
        return queue.list_by_claim(claim)


    @assure_queue
    def post_message(self, queue, body, ttl):
        """
        Create a message in the specified queue. The value of ttl must be
        between 60 and 1209600 seconds (14 days).
        """
        return queue.post_message(body, ttl)


    @assure_queue
    def claim_messages(self, queue, ttl, grace, count=None):
        """
        Claims up to `count` unclaimed messages from the specified queue. If
        count is not specified, the default is to claim 10 messages.

        The `ttl` parameter specifies how long the server should wait before
        releasing the claim. The ttl value MUST be between 60 and 43200 seconds.

        The `grace` parameter is the message grace period in seconds. The value
        of grace MUST be between 60 and 43200 seconds. The server extends the
        lifetime of claimed messages to be at least as long as the lifetime of
        the claim itself, plus a specified grace period to deal with crashed
        workers (up to 1209600 or 14 days including claim lifetime). If a
        claimed message would normally live longer than the grace period, its
        expiration will not be adjusted.

        Returns a QueueClaim object, whose 'messages' attribute contains the
        list of QueueMessage objects representing the claimed messages.
        """
        return queue.claim_messages(ttl, grace, count=count)


    @assure_queue
    def get_claim(self, queue, claim):
        """
        Returns a QueueClaim object with information about the specified claim.
        If no such claim exists, a NotFound exception is raised.
        """
        return queue.get_claim(claim)


    @assure_queue
    def update_claim(self, queue, claim, ttl=None, grace=None):
        """
        Updates the specified claim with either a new TTL or grace period, or
        both.
        """
        return queue.update_claim(claim, ttl=ttl, grace=grace)


    @assure_queue
    def release_claim(self, queue, claim):
        """
        Releases the specified claim and makes any messages previously claimed
        by this claim as available for processing by other workers.
        """
        return queue.release_claim(claim)

########NEW FILE########
__FILENAME__ = resource
# Copyright 2010 Jacob Kaplan-Moss

# Copyright 2011 OpenStack LLC.
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

"""
Base utilities to build API operation managers and objects on top of.
"""

import six

import pyrax
import pyrax.utils as utils


class BaseResource(object):
    """
    A resource represents a particular instance of an object (server, flavor,
    etc). This is pretty much just a bag for attributes.
    """
    HUMAN_ID = False
    NAME_ATTR = "name"
    # Some resource do not have any additional details to lazy load,
    # so skip the unneeded API call by setting this to False.
    get_details = True
    # Atts not to display when showing the __repr__()
    _non_display = []
    # Properties to add to the __repr__() display
    _repr_properties = []


    def __init__(self, manager, info, key=None, loaded=False):
        self._loaded = loaded
        self.manager = manager
        if key:
            info = info[key]
        self._info = info
        self._add_details(info)


    @property
    def human_id(self):
        """Subclasses may override this to provide a pretty ID which can be used
        for bash completion.
        """
        if self.NAME_ATTR in self.__dict__ and self.HUMAN_ID:
            return utils.slugify(getattr(self, self.NAME_ATTR))
        return None


    def _add_details(self, info):
        """
        Takes the dict returned by the API call and sets the
        corresponding attributes on the object.
        """
        for (key, val) in info.iteritems():
            if isinstance(key, six.text_type):
                key = key.encode(pyrax.get_encoding())
            setattr(self, key, val)


    def __getattr__(self, key):
        """
        Many objects are lazy-loaded: only their most basic details
        are initially returned. The first time any of the other attributes
        are referenced, a GET is made to get the full details for the
        object.
        """
        if not self.loaded:
            self.get()
        # Attribute should be set; if not, it's not valid
        try:
            return self.__dict__[key]
        except KeyError:
            raise AttributeError("'%s' object has no attribute "
                    "'%s'." % (self.__class__, key))


    def __repr__(self):
        reprkeys = sorted(key for key in self.__dict__.keys()
                if (key[0] != "_")
                and (key not in ("manager", "created", "updated"))
                and (key not in self._non_display))
        reprkeys += self._repr_properties
        info = ", ".join("%s=%s" % (key, getattr(self, key))
                for key in reprkeys)
        return "<%s %s>" % (self.__class__.__name__, info)


    def get(self):
        """Gets the details for the object."""
        # set 'loaded' first ... so if we have to bail, we know we tried.
        self.loaded = True
        if not hasattr(self.manager, "get"):
            return
        if not self.get_details:
            return
        new = self.manager.get(self)
        if new:
            self._add_details(new._info)
    # This alias is used to make its purpose clearer.
    reload = get


    def delete(self):
        """Deletes the object."""
        # set 'loaded' first ... so if we have to bail, we know we tried.
        self.loaded = True
        if not hasattr(self.manager, "delete"):
            return
        self.manager.delete(self)


    def __eq__(self, other):
        """
        Two resource objects that represent the same entity in the cloud
        should be considered equal if they have the same ID. If they
        don't have IDs, but their attribute info matches, they are equal.
        """
        if not isinstance(other, self.__class__):
            return False
        if hasattr(self, "id") and hasattr(other, "id"):
            return self.id == other.id
        return self._info == other._info


    def _get_loaded(self):
        return self._loaded

    def _set_loaded(self, val):
        self._loaded = val

    loaded = property(_get_loaded, _set_loaded)

########NEW FILE########
__FILENAME__ = service_catalog
# Copyright 2011 OpenStack LLC.
# Copyright 2011, Piston Cloud Computing, Inc.
# Copyright 2012, Rackspace
#
# All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import pyrax.exceptions as exc


class ServiceCatalog(object):
    """Helper methods for dealing with a Keystone Service Catalog."""

    def __init__(self, resource_dict):
        self.catalog = resource_dict

    def get_token(self):
        """Extracts and returns the authentication token."""
        return self.catalog["access"]["token"]["id"]

    def url_for(self, attr=None, filter_value=None,
            service_type=None, endpoint_type="publicURL",
            service_name=None, volume_service_name=None):
        """Fetches the public URL from the given service for
        a particular endpoint attribute. If none given, returns
        the first. See tests for sample service catalog."""
        matching_endpoints = []
        # We don't always get a service catalog back ...
        if "serviceCatalog" not in self.catalog["access"]:
            return None

        # Full catalog ...
        catalog = self.catalog["access"]["serviceCatalog"]
        for service in catalog:
            if service.get("type") != service_type:
                continue
            endpoints = service["endpoints"]
            for endpoint in endpoints:
                if not filter_value or endpoint.get(attr) == filter_value:
                    endpoint["serviceName"] = service.get("name")
                    matching_endpoints.append(endpoint)

        if not matching_endpoints:
            raise exc.EndpointNotFound()
        elif len(matching_endpoints) > 1:
            raise exc.AmbiguousEndpoints(endpoints=matching_endpoints)
        else:
            return matching_endpoints[0][endpoint_type]

########NEW FILE########
__FILENAME__ = utils
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from __future__ import print_function

import datetime
import email.utils
import fnmatch
import hashlib
import numbers
import os
import random
import re
import shutil
import string
from subprocess import Popen, PIPE
import sys
import tempfile
import threading
import time
import types

try:
    import pudb
except ImportError:
    import pdb as pudb
trace = pudb.set_trace

import six

import pyrax
import pyrax.exceptions as exc


def runproc(cmd):
    """
    Convenience method for executing operating system commands.

    Accepts a single string that would be the command as executed on the
    command line.

    Returns a 2-tuple consisting of the output of (STDOUT, STDERR). In your
    code you should check for an empty STDERR output to determine if your
    command completed successfully.
    """
    proc = Popen([cmd], shell=True, stdin=PIPE, stdout=PIPE, stderr=PIPE,
            close_fds=True)
    stdoutdata, stderrdata = proc.communicate()
    return (stdoutdata, stderrdata)


class SelfDeletingTempfile(object):
    """
    Convenience class for dealing with temporary files.

    The temp file is created in a secure fashion, and is
    automatically deleted when the context manager exits.

    Usage:

    \code
    with SelfDeletingTempfile() as tmp:
        tmp.write( ... )
        some_func(tmp)
    # More code
    # At this point, the tempfile has been erased.
    \endcode
    """
    name = None

    def __enter__(self):
        fd, self.name = tempfile.mkstemp()
        os.close(fd)
        return self.name

    def __exit__(self, type, value, traceback):
        os.unlink(self.name)


class SelfDeletingTempDirectory(object):
    """
    Convenience class for dealing with temporary folders and the
    files within them.

    The temp folder is created in a secure fashion, and is
    automatically deleted when the context manager exits, along
    with any files that may be contained within. When you
    instantiate this class, you receive the full path to the
    temporary directory.

    Usage:

    \code
    with SelfDeletingTempDirectory() as tmpdir:
        f1 = open(os.path.join(tmpdir, "my_file.txt", "w")
        f1.write("blah...")
        f1.close()
        some_func(tmpdir)
    # More code
    # At this point, the directory 'tmpdir' has been deleted,
    # as well as the file 'f1' within it.
    \endcode
    """
    name = None

    def __enter__(self):
        self.name = tempfile.mkdtemp()
        return self.name

    def __exit__(self, type, value, traceback):
        shutil.rmtree(self.name)



class DotDict(dict):
    """
    Dictionary subclass that allows accessing keys via dot notation.

    If the key is not present, an AttributeError is raised.
    """
    _att_mapper = {}
    _fail = object()

    def __init__(self, *args, **kwargs):
        super(DotDict, self).__init__(*args, **kwargs)

    def __getattr__(self, att):
        att = self._att_mapper.get(att, att)
        ret = self.get(att, self._fail)
        if ret is self._fail:
            raise AttributeError("'%s' object has no attribute '%s'" %
                    (self.__class__.__name__, att))
        return ret

    __setattr__ = dict.__setitem__
    __delattr__ = dict.__delitem__



def get_checksum(content, encoding="utf8", block_size=8192):
    """
    Returns the MD5 checksum in hex for the given content. If 'content'
    is a file-like object, the content will be obtained from its read()
    method. If 'content' is a file path, that file is read and its
    contents used. Otherwise, 'content' is assumed to be the string whose
    checksum is desired. If the content is unicode, it will be encoded
    using the specified encoding.

    To conserve memory, files and file-like objects will be read in blocks,
    with the default block size of 8192 bytes, which is 64 * the digest block
    size of md5 (128). This is optimal for most cases, but you can change this
    by passing in a different value for `block_size`.
    """
    md = hashlib.md5()

    def safe_update(txt):
        try:
            md.update(txt)
        except UnicodeEncodeError:
            md.update(txt.encode(encoding))

    try:
        isfile = os.path.isfile(content)
    except TypeError:
        # Will happen with binary content.
        isfile = False
    if isfile:
        with open(content, "rb") as ff:
            txt = ff.read(block_size)
            while txt:
                safe_update(txt)
                txt = ff.read(block_size)
    elif hasattr(content, "read"):
        pos = content.tell()
        content.seek(0)
        txt = content.read(block_size)
        while txt:
            safe_update(txt)
            txt = content.read(block_size)
        content.seek(pos)
    else:
        safe_update(content)
    return md.hexdigest()


def _join_chars(chars, length):
    """
    Used by the random character functions.
    """
    mult = (length / len(chars)) + 1
    mult_chars = chars * mult
    return "".join(random.sample(mult_chars, length))


def random_unicode(length=20):
    """
    Generates a random name; useful for testing.

    Returns an encoded string of the specified length containing unicode values
    up to code point 1000.
    """
    def get_char():
        return unichr(random.randint(32, 1000))
    chars = u"".join([get_char() for ii in six.moves.range(length)])
    return _join_chars(chars, length)


def random_ascii(length=20, ascii_only=False):
    """
    Generates a random name; useful for testing.

    Returns a string of the specified length containing only ASCII characters.
    """
    return _join_chars(string.ascii_letters, length)


def coerce_string_to_list(val):
    """
    For parameters that can take either a single string or a list of strings,
    this function will ensure that the result is a list containing the passed
    values.
    """
    if val:
        if not isinstance(val, (list, tuple)):
            val = [val]
    else:
        val = []
    return val


def folder_size(pth, ignore=None):
    """
    Returns the total bytes for the specified path, optionally ignoring
    any files which match the 'ignore' parameter. 'ignore' can either be
    a single string pattern, or a list of such patterns.
    """
    if not os.path.isdir(pth):
        raise exc.FolderNotFound

    ignore = coerce_string_to_list(ignore)

    def get_size(total, root, names):
        paths = [os.path.realpath(os.path.join(root, nm)) for nm in names]
        for pth in paths[::-1]:
            if not os.path.exists(pth):
                paths.remove(pth)
            elif os.path.isdir(pth):
                # Don't count folder stat sizes
                paths.remove(pth)
            elif match_pattern(pth, ignore):
                paths.remove(pth)
        total[0] += sum(os.stat(pth).st_size for pth in paths)

    # Need a mutable to pass
    total = [0]
    os.path.walk(pth, get_size, total)
    return total[0]


def add_method(obj, func, name=None):
    """Adds an instance method to an object."""
    if name is None:
        name = func.func_name
    method = types.MethodType(func, obj, obj.__class__)
    setattr(obj, name, method)


class _WaitThread(threading.Thread):
    """
    Threading class to wait for object status in the background. Note that
    verbose will always be False for a background thread.
    """
    def __init__(self, obj, att, desired, callback, interval, attempts,
            verbose, verbose_atts):
        self.obj = obj
        self.att = att
        self.desired = desired
        self.callback = callback
        self.interval = interval
        self.attempts = attempts
        self.verbose = verbose
        threading.Thread.__init__(self)

    def run(self):
        """Starts the thread."""
        resp = _wait_until(obj=self.obj, att=self.att,
                desired=self.desired, callback=None,
                interval=self.interval, attempts=self.attempts,
                verbose=False, verbose_atts=None)
        self.callback(resp)


def wait_until(obj, att, desired, callback=None, interval=5, attempts=0,
        verbose=False, verbose_atts=None):
    """
    When changing the state of an object, it will commonly be in a transitional
    state until the change is complete. This will reload the object every
    `interval` seconds, and check its `att` attribute until the `desired` value
    is reached, or until the maximum number of attempts is reached. The updated
    object is returned. It is up to the calling program to check the returned
    object to make sure that it successfully reached the desired state.

    Once the desired value of the attribute is reached, the method returns. If
    not, it will re-try until the attribute's value matches one of the
    `desired` values. By default (attempts=0) it will loop infinitely until the
    attribute reaches the desired value. You can optionally limit the number of
    times that the object is reloaded by passing a positive value to
    `attempts`. If the attribute has not reached the desired value by then, the
    method will exit.

    If `verbose` is True, each attempt will print out the current value of the
    watched attribute and the time that has elapsed since the original request.
    Also, if `verbose_atts` is specified, the values of those attributes will
    also be output. If `verbose` is False, then `verbose_atts` has no effect.

    Note that `desired` can be a list of values; if the attribute becomes equal
    to any of those values, this will succeed. For example, when creating a new
    cloud server, it will initially have a status of 'BUILD', and you can't
    work with it until its status is 'ACTIVE'. However, there might be a
    problem with the build process, and the server will change to a status of
    'ERROR'. So for this case you need to set the `desired` parameter to
    `['ACTIVE', 'ERROR']`. If you simply pass 'ACTIVE' as the desired state,
    this will loop indefinitely if a build fails, as the server will never
    reach a status of 'ACTIVE'.

    Since this process of waiting can take a potentially long time, and will
    block your program's execution until the desired state of the object is
    reached, you may specify a callback function. The callback can be any
    callable that accepts a single parameter; the parameter it receives will be
    either the updated object (success), or None (failure). If a callback is
    specified, the program will return immediately after spawning the wait
    process in a separate thread.
    """
    if callback:
        waiter = _WaitThread(obj=obj, att=att, desired=desired, callback=callback,
                interval=interval, attempts=attempts, verbose=verbose,
                verbose_atts=verbose_atts)
        waiter.start()
        return waiter
    else:
        return _wait_until(obj=obj, att=att, desired=desired, callback=None,
                interval=interval, attempts=attempts, verbose=verbose,
                verbose_atts=verbose_atts)


def _wait_until(obj, att, desired, callback, interval, attempts, verbose,
        verbose_atts):
    """
    Loops until either the desired value of the attribute is reached, or the
    number of attempts is exceeded.
    """
    if not isinstance(desired, (list, tuple)):
        desired = [desired]
    if verbose_atts is None:
        verbose_atts = []
    if not isinstance(verbose_atts, (list, tuple)):
        verbose_atts = [verbose_atts]
    infinite = (attempts == 0)
    attempt = 0
    start = time.time()
    while infinite or (attempt < attempts):
        try:
            # For servers:
            obj.get()
        except AttributeError:
            try:
                # For other objects that don't support .get()
                obj = obj.manager.get(obj.id)
            except AttributeError:
                # punt
                raise exc.NoReloadError("The 'wait_until' method is not "
                        "supported for '%s' objects." % obj.__class__)
        attval = getattr(obj, att)
        if verbose:
            elapsed = time.time() - start
            msgs = ["Current value of %s: %s (elapsed: %4.1f seconds)" % (
                    att, attval, elapsed)]
            for vatt in verbose_atts:
                vattval = getattr(obj, vatt, None)
                msgs.append("%s=%s" % (vatt, vattval))
            print(" ".join(msgs))
        if attval in desired:
            return obj
        time.sleep(interval)
        attempt += 1
    return obj



def wait_for_build(obj, att=None, desired=None, callback=None, interval=None,
        attempts=None, verbose=None, verbose_atts=None):
    """
    Designed to handle the most common use case for wait_until: an object whose
    'status' attribute will end up in either 'ACTIVE' or 'ERROR' state. Since
    builds don't happen very quickly, the interval will default to 20 seconds
    to avoid excess polling.
    """
    att = att or "status"
    desired = desired or ["ACTIVE", "ERROR", "available", "COMPLETED"]
    interval = interval or 20
    attempts = attempts or 0
    verbose_atts = verbose_atts or "progress"
    return wait_until(obj, att, desired, callback=callback, interval=interval,
            attempts=attempts, verbose=verbose, verbose_atts=verbose_atts)


def _parse_datetime_string(val):
    """
    Attempts to parse a string representation of a date or datetime value, and
    returns a datetime if successful. If not, a InvalidDateTimeString exception
    will be raised.
    """
    dt = None
    lenval = len(val)
    fmt = {19: "%Y-%m-%d %H:%M:%S", 10: "%Y-%m-%d"}.get(lenval)
    if fmt is None:
        # Invalid date
        raise exc.InvalidDateTimeString("The supplied value '%s' does not "
              "match either of the formats 'YYYY-MM-DD HH:MM:SS' or "
              "'YYYY-MM-DD'." % val)
    return datetime.datetime.strptime(val, fmt)


def iso_time_string(val, show_tzinfo=False):
    """
    Takes either a date, datetime or a string, and returns the standard ISO
    formatted string for that date/time, with any fractional second portion
    removed.
    """
    if not val:
        return ""
    if isinstance(val, six.string_types):
        dt = _parse_datetime_string(val)
    else:
        dt = val
    if not isinstance(dt, datetime.datetime):
        dt = datetime.datetime.fromordinal(dt.toordinal())
    has_tz = (dt.tzinfo is not None)
    if show_tzinfo and has_tz:
        # Need to remove the colon in the TZ portion
        ret = "".join(dt.isoformat().rsplit(":", 1))
    elif show_tzinfo and not has_tz:
        ret = "%s+0000" % dt.isoformat().split(".")[0]
    elif not show_tzinfo and has_tz:
        ret = dt.isoformat()[:-6]
    elif not show_tzinfo and not has_tz:
        ret = dt.isoformat().split(".")[0]
    return ret


def rfc2822_format(val):
    """
    Takes either a date, a datetime, or a string, and returns a string that
    represents the value in RFC 2822 format. If a string is passed it is
    returned unchanged.
    """
    if isinstance(val, six.string_types):
        return val
    elif isinstance(val, (datetime.datetime, datetime.date)):
        # Convert to a timestamp
        val = time.mktime(val.timetuple())
    if isinstance(val, numbers.Number):
        return email.utils.formatdate(val)
    else:
        # Bail
        return val


def to_timestamp(val):
    """
    Takes a value that is either a Python date, datetime, or a string
    representation of a date/datetime value. Returns a standard Unix timestamp
    corresponding to that value.
    """
    # If we're given a number, give it right back - it's already a timestamp.
    if isinstance(val, numbers.Number):
        return val
    elif isinstance(val, six.string_types):
        dt = _parse_datetime_string(val)
    else:
        dt = val
    return time.mktime(dt.timetuple())


def get_id(id_or_obj):
    """
    Returns the 'id' attribute of 'id_or_obj' if present; if not,
    returns 'id_or_obj'.
    """
    if isinstance(id_or_obj, six.string_types + (int,)):
        # It's an ID
        return id_or_obj
    try:
        return id_or_obj.id
    except AttributeError:
        return id_or_obj


def get_name(name_or_obj):
    """
    Returns the 'name' attribute of 'name_or_obj' if present; if not,
    returns 'name_or_obj'.
    """
    if isinstance(name_or_obj, six.string_types):
        # It's a name
        return name_or_obj
    try:
        return name_or_obj.name
    except AttributeError:
        raise exc.MissingName(name_or_obj)


def params_to_dict(params, dct, local_dict):
    """
    Given a set of optional parameter names, constructs a dictionary with the
    parameter name as the key, and the value for that key in the local_dict as
    the value, for all non-None values.
    """
    for param in params:
        val = local_dict.get(param)
        if val is None:
            continue
        dct[param] = val
    return dct


def dict_to_qs(dct):
    """
    Takes a dictionary and uses it to create a query string.
    """
    itms = ["%s=%s" % (key, val) for key, val in list(dct.items())
            if val is not None]
    return "&".join(itms)


def match_pattern(nm, patterns):
    """
    Compares `nm` with the supplied patterns, and returns True if it matches
    at least one.

    Patterns are standard file-name wildcard strings, as defined in the
    `fnmatch` module. For example, the pattern "*.py" will match the names
    of all Python scripts.
    """
    patterns = coerce_string_to_list(patterns)
    for pat in patterns:
        if fnmatch.fnmatch(nm, pat):
            return True
    return False


def update_exc(exc, msg, before=True, separator="\n"):
    """
    Adds additional text to an exception's error message.

    The new text will be added before the existing text by default; to append
    it after the original text, pass False to the `before` parameter.

    By default the old and new text will be separated by a newline. If you wish
    to use a different separator, pass that as the `separator` parameter.
    """
    emsg = exc.message
    if before:
        parts = (msg, separator, emsg)
    else:
        parts = (emsg, separator, msg)
    new_msg = "%s%s%s" % parts
    new_args = (new_msg, ) + exc.args[1:]
    exc.message = new_msg
    exc.args = new_args
    return exc


def case_insensitive_update(dct1, dct2):
    """
    Given two dicts, updates the first one with the second, but considers keys
    that are identical except for case to be the same.

    No return value; this function modified dct1 similar to the update() method.
    """
    lowkeys = dict([(key.lower(), key) for key in dct1])
    for key, val in dct2.items():
        d1_key = lowkeys.get(key.lower(), key)
        dct1[d1_key] = val


def env(*args, **kwargs):
    """
    Returns the first environment variable set
    if none are non-empty, defaults to "" or keyword arg default
    """
    for arg in args:
        value = os.environ.get(arg, None)
        if value:
            return value
    return kwargs.get("default", "")


def unauthenticated(fnc):
    """
    Adds 'unauthenticated' attribute to decorated function.
    Usage:
        @unauthenticated
        def mymethod(fnc):
            ...
    """
    fnc.unauthenticated = True
    return fnc


def isunauthenticated(fnc):
    """
    Checks to see if the function is marked as not requiring authentication
    with the @unauthenticated decorator. Returns True if decorator is
    set to True, False otherwise.
    """
    return getattr(fnc, "unauthenticated", False)


def safe_issubclass(*args):
    """Like issubclass, but will just return False if not a class."""
    try:
        if issubclass(*args):
            return True
    except TypeError:
        pass
    return False


def import_class(import_str):
    """Returns a class from a string including module and class."""
    mod_str, _sep, class_str = import_str.rpartition(".")
    __import__(mod_str)
    return getattr(sys.modules[mod_str], class_str)


# http://code.activestate.com/recipes/
#   577257-slugify-make-a-string-usable-in-a-url-or-filename/
def slugify(value):
    """
    Normalizes string, converts to lowercase, removes non-alpha characters,
    and converts spaces to hyphens.

    From Django's "django/template/defaultfilters.py".
    """
    import unicodedata
    _slugify_strip_re = re.compile(r"[^\w\s-]")
    _slugify_hyphenate_re = re.compile(r"[-\s]+")
    if not isinstance(value, six.text_type):
        value = six.text_type(value)
    value = unicodedata.normalize("NFKD", value).encode("ascii", "ignore")
    value = six.text_type(_slugify_strip_re.sub("", value).strip().lower())
    return _slugify_hyphenate_re.sub("-", value)

########NEW FILE########
__FILENAME__ = version
#!/usr/bin/env python
# -*- coding: utf-8 -*-

version = "1.8.1"

########NEW FILE########
__FILENAME__ = auth_creds_file
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os

import pyrax
import pyrax.exceptions as exc

pyrax.set_setting("identity_type", "rackspace")

# Use a credential file in the format:
#     [rackspace_cloud]
#     username = myusername
#     api_key = 01234567890abcdef
print()
print("Using credentials file")
# Note: you can name this file whatever you like.
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
try:
    pyrax.set_credential_file(creds_file)
except exc.AuthenticationFailed:
    print("Did you remember to replace the credential file with your actual",
        end=' ')
    print("username and api_key?")
print("authenticated =", pyrax.identity.authenticated)
print()

########NEW FILE########
__FILENAME__ = auth_direct
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os

import pyrax
import pyrax.exceptions as exc

pyrax.set_setting("identity_type", "rackspace")

# Pass credentials directly (replace with your credentials)
print("Pass directly:")
try:
    pyrax.set_credentials("real_username", "real_api_key")
except exc.AuthenticationFailed:
    print("Did you remember to replace the credentials with your actual", end=' ')
    print("username and api_key?")
print("authenticated =", pyrax.identity.authenticated)
print()

########NEW FILE########
__FILENAME__ = add_policy
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
au = pyrax.autoscale

def safe_int(val, allow_zero=True):
    """
    This function converts the raw_input values to integers. It handles invalid
    entries, and optionally forbids values of zero.
    """
    try:
        ret = int(val)
    except ValueError:
        print("Sorry, '%s' is not a valid integer." % val)
        return False
    if not allow_zero and ret == 0:
        print("Please enter a non-zero integer.")
        return False
    return ret

# Get the current scaling groups
sgs = au.list()
if not sgs:
    print("There are no scaling groups defined. Please run the "
        "'create_scaling_group.py' script first.")
    exit()

print()
print("Available Scaling Groups:")
for pos, sg in enumerate(sgs):
    print("%s - %s" % (pos, sg.name))
answer = raw_input("Enter the number of the scaling group you wish to add a "
        "policy to: ")
if not answer:
    print("Nothing entered; exiting.")
    exit()
intanswer = safe_int(answer)
if not 0 <= intanswer < len(sgs):
    print("The number '%s' does not correspond to any scaling group." % answer)
    exit()
sg = sgs[intanswer]

pname = ""
while not pname:
    pname = raw_input("Enter a name for this policy: ")

cooldown = 0
while not cooldown:
    cooldown = safe_int(raw_input("Enter a cooldown period in seconds: "), False)

change = 0
while not change:
    change = safe_int(raw_input("Enter the change increment: "), False)

answer = raw_input("Is that a percentage change? [y/N]: ")
is_percent = "y" in answer.lower()

policy = au.add_policy(sg, pname, "webhook", cooldown, change, is_percent)

print("Policy added: %s" % policy)

########NEW FILE########
__FILENAME__ = add_webhook
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
au = pyrax.autoscale

def safe_int(val, allow_zero=True):
    """
    This function converts the raw_input values to integers. It handles invalid
    entries, and optionally forbids values of zero.
    """
    try:
        ret = int(val)
    except ValueError:
        print("Sorry, '%s' is not a valid integer." % val)
        return False
    if not allow_zero and ret == 0:
        print("Please enter a non-zero integer.")
        return False
    return ret

# Get the current scaling groups
sgs = au.list()
if not sgs:
    print("There are no scaling groups defined.")
    exit()

print()
print("Available Scaling Groups:")
for pos, sg in enumerate(sgs):
    print("%s - %s" % (pos, sg.name))
intanswer = -1
while intanswer < 0:
    answer = raw_input("Enter the number of the scaling group: ")
    if not answer:
        print("Nothing entered; exiting.")
        exit()
    intanswer = safe_int(answer)
    if intanswer is False:
        intanswer = -1
        continue
    if not 0 <= intanswer < len(sgs):
        print("The number '%s' does not correspond to any scaling group." % answer)
        intanswer = -1

policies = sg.list_policies()
if not policies:
    print("There are no policies defined for this scaling group. You can only "
        "add webhooks to existing policies.")
    exit()
for pos, policy in enumerate(policies):
    print("%s - %s" % (pos, policy.name))
answer = raw_input("Enter the number of the policy: ")
if not answer:
    print("Nothing entered; exiting.")
    exit()
intanswer = safe_int(answer)
if not 0 <= intanswer < len(policies):
    print("The number '%s' does not correspond to any policy." % answer)
    exit()
policy = policies[intanswer]

name = ""
while not name:
    name = raw_input("Enter a name for this webhook: ")

metadata = {}
while True:
    key = raw_input("Enter a metadata key, or press Enter to end metadata "
            "entry: ")
    if not key:
        break
    val = raw_input("Enter the value for the key '%s': " % key)
    metadata[key] = val

hook = policy.add_webhook(name, metadata=metadata)

print()
print()
print("Webhook added: %s" % hook)

########NEW FILE########
__FILENAME__ = create_scaling_group
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
au = pyrax.autoscale
cs = pyrax.cloudservers
clb = pyrax.cloud_loadbalancers


def safe_int(val, allow_zero=True):
    """
    This function converts the raw_input values to integers. It handles invalid
    entries, and optionally forbids values of zero.
    """
    try:
        ret = int(val)
    except ValueError:
        print("Sorry, '%s' is not a valid integer." % val)
        return False
    if not allow_zero and ret == 0:
        print("Please enter a non-zero integer.")
        return False
    return ret


def get_yn(prompt):
    answer = yn = None
    while not answer:
        answer = raw_input("%s (y/n) " % prompt)
        yn = answer[0].lower()
        if yn not in "yn":
            print("Please answer 'y' or 'n', not '%s'." % answer)
            answer = None
            continue
    return (yn == "y")


def select_lbs():
    print("Getting a list of your load balancers...")
    lbs = clb.list()
    for pos, lb in enumerate(lbs):
        print("%s - %s (port %s)" % (pos, lb.name, lb.port))
    chosen = raw_input("Enter the number(s) of the load balancer to use, "
            "separated by commas: ")
    lb_ints = [safe_int(num) for num in chosen.split(",")]
    lb_pos = [lb_int for lb_int in lb_ints
        if lb_int
        and lb_int < len(lbs)]
    selected = []
    for pos in lb_pos:
        selected.append(lbs[pos])
    return selected


# Give the scaling group a name
sg_name = ""
while not sg_name:
    sg_name = raw_input("Enter a name for the scaling group: ")

cooldown = 0
while not cooldown:
    str_secs = raw_input("Enter a cooldown period in seconds: ")
    cooldown = safe_int(str_secs, False)

# We want a minimum of 2 servers, and a max of 20.
min_entities = max_entities = None
min_entities = safe_int(raw_input("Enter the minimum entities (0-1000): "),
        False)
max_entities = min_entities
while max_entities <= min_entities:
    max_entities = safe_int(raw_input("Enter the maximum entities: (%s-1000)"
            % min_entities), False)
    if max_entities and (max_entities < min_entities):
        print("The value for max_entities must be greater than min_entities.")

# Configure the server launch settings.
server_name = ""
while not server_name:
    server_name = raw_input("Enter the name base for the servers in this "
            "scaling group: ")

print("Getting a list of images...")
imgs = cs.list_images()
for pos, img in enumerate(imgs):
    print("%s - %s" % (pos, img.name))
answer = -1
while answer < 0:
    answer = safe_int(raw_input("Enter the number of the image to use: "))
    if answer is False:
        # safe_int() returns False for invalid values.
        answer = -1
        continue
    if not 0 <= answer < len(imgs):
        print("The number '%s' does not correspond to any image." % answer)
        answer = -1
image = imgs[answer]
print("You selected: %s." % image.name)

# Use a small flavor
flavor = "performance1-1"
# Set the disk configuration to 'MANUAL'
disk_config = "MANUAL"
# Let's give the servers some metadata
metadata = {"created_by": "autoscale sample script"}

load_balancers = []
add_lb = get_yn("Do you want to add one or more load balancers to this "
        "scaling group?")
while add_lb:
    lbs = select_lbs()
    if not lbs:
        print("No valid load balancers were entered.")
        add_lb = get_yn("Do you want to try again?")
        continue
    add_lb = False
    load_balancers = [(lb.id, lb.port) for lb in lbs]

sg = au.create(sg_name, cooldown, min_entities, max_entities, "launch_server",
        server_name, image, flavor, load_balancers=load_balancers,
        disk_config=disk_config, metadata=metadata)

print()
print()
print("Scaling Group:", sg.name)
print("ID:", sg.id)
print("State:", sg.get_state())

########NEW FILE########
__FILENAME__ = delete_policy
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
au = pyrax.autoscale

def safe_int(val, allow_zero=True):
    """
    This function converts the raw_input values to integers. It handles invalid
    entries, and optionally forbids values of zero.
    """
    try:
        ret = int(val)
    except ValueError:
        print("Sorry, '%s' is not a valid integer." % val)
        return False
    if not allow_zero and ret == 0:
        print("Please enter a non-zero integer.")
        return False
    return ret

# Get the current scaling groups
sgs = au.list()
if not sgs:
    print("There are no scaling groups defined.")
    exit()

print()
print("Available Scaling Groups:")
for pos, sg in enumerate(sgs):
    print("%s - %s" % (pos, sg.name))
intanswer = -1
while intanswer < 0:
    answer = raw_input("Enter the number of the scaling group: ")
    if not answer:
        print("Nothing entered; exiting.")
        exit()
    intanswer = safe_int(answer)
    if intanswer is False:
        intanswer = -1
        continue
    if not 0 <= intanswer < len(sgs):
        print("The number '%s' does not correspond to any scaling group." % answer)
        intanswer = -1

policies = sg.list_policies()
if not policies:
    print("There are no policies defined for this scaling group.")
    exit()
for pos, policy in enumerate(policies):
    print("%s - %s" % (pos, policy.name))
answer = raw_input("Enter the number of the policy to delete: ")
if not answer:
    print("Nothing entered; exiting.")
    exit()
intanswer = safe_int(answer)
if not 0 <= intanswer < len(policies):
    print("The number '%s' does not correspond to any policy." % answer)
    exit()
policy = policies[intanswer]
policy.delete()
print("Policy '%s' has been deleted." % policy.name)

########NEW FILE########
__FILENAME__ = delete_scaling_group
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
au = pyrax.autoscale
cs = pyrax.cloudservers

# Get the current scaling groups
sgs = au.list()
if not sgs:
    print("There are no scaling groups defined.")
    exit()

print()
print("Available Scaling Groups:")
for pos, sg in enumerate(sgs):
    print("%s - %s" % (pos, sg.name))
answer = raw_input("Enter the number of the scaling group to delete: ")
if not answer:
    print("Nothing entered; exiting.")
    exit()
try:
    intanswer = int(answer)
except ValueError:
    print("'%s' is not a valid number; exiting." % answer)
    exit()
if not 0 <= intanswer < len(sgs):
    print("The number '%s' does not correspond to any scaling group." % answer)
    exit()

sg_del = sgs[intanswer]
sg_del.update(min_entities=0, max_entities=0)
sg_del.delete()
print("Scaling group '%s' has been deleted." % sg_del.name)

########NEW FILE########
__FILENAME__ = delete_webhook
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
au = pyrax.autoscale

def safe_int(val, allow_zero=True):
    """
    This function converts the raw_input values to integers. It handles invalid
    entries, and optionally forbids values of zero.
    """
    try:
        ret = int(val)
    except ValueError:
        print("Sorry, '%s' is not a valid integer." % val)
        return False
    if not allow_zero and ret == 0:
        print("Please enter a non-zero integer.")
        return False
    return ret

# Get the current scaling groups
sgs = au.list()
if not sgs:
    print("There are no scaling groups defined.")
    exit()

print()
print("Available Scaling Groups:")
for pos, sg in enumerate(sgs):
    print("%s - %s" % (pos, sg.name))
intanswer = -1
while intanswer < 0:
    answer = raw_input("Enter the number of the scaling group: ")
    if not answer:
        print("Nothing entered; exiting.")
        exit()
    intanswer = safe_int(answer)
    if intanswer is False:
        intanswer = -1
        continue
    if not 0 <= intanswer < len(sgs):
        print("The number '%s' does not correspond to any scaling group." % answer)
        intanswer = -1

policies = sg.list_policies()
if not policies:
    print("There are no policies defined for this scaling group. You can only "
        "add webhooks to existing policies.")
    exit()
for pos, policy in enumerate(policies):
    print("%s - %s" % (pos, policy.name))
answer = raw_input("Enter the number of the policy: ")
if not answer:
    print("Nothing entered; exiting.")
    exit()
intanswer = safe_int(answer)
if not 0 <= intanswer < len(policies):
    print("The number '%s' does not correspond to any policy." % answer)
    exit()
policy = policies[intanswer]

webhooks = policy.list_webhooks()
if not webhooks:
    print("There are no webhooks defined for this policy.")
    exit()
for pos, webhook in enumerate(webhooks):
    print("%s - %s" % (pos, webhook.name))
answer = raw_input("Enter the number of the webhook: ")
if not answer:
    print("Nothing entered; exiting.")
    exit()
intanswer = safe_int(answer)
if not 0 <= intanswer < len(webhooks):
    print("The number '%s' does not correspond to any webhook." % answer)
    exit()
webhook = webhooks[intanswer]
webhook.delete()
print()
print("Webhook '%s' has been deleted." % webhook.name)

########NEW FILE########
__FILENAME__ = container_cdn
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cf = pyrax.cloudfiles

cont_name = pyrax.utils.random_ascii()
cont = cf.create_container(cont_name)
print("Container:", cont)
print("Before Making Public")
print("cdn_enabled", cont.cdn_enabled)
print("cdn_ttl", cont.cdn_ttl)
print("cdn_log_retention", cont.cdn_log_retention)
print("cdn_uri", cont.cdn_uri)
print("cdn_ssl_uri", cont.cdn_ssl_uri)
print("cdn_streaming_uri", cont.cdn_streaming_uri)
print("cdn_ios_uri", cont.cdn_ios_uri
)
# Make it public
cont.make_public(ttl=1200)

# Now re-check the container's attributes
cont = cf.get_container(cont_name)
print()
print("After Making Public")
print("cdn_enabled", cont.cdn_enabled)
print("cdn_ttl", cont.cdn_ttl)
print("cdn_log_retention", cont.cdn_log_retention)
print("cdn_uri", cont.cdn_uri)
print("cdn_ssl_uri", cont.cdn_ssl_uri)
print("cdn_streaming_uri", cont.cdn_streaming_uri)
print("cdn_ios_uri", cont.cdn_ios_uri
)
# clean up
cont.delete()

########NEW FILE########
__FILENAME__ = container_metadata
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import time

import pyrax
import pyrax.exceptions as exc

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cf = pyrax.cloudfiles

cont_name = pyrax.utils.random_ascii()
cont = cf.create_container(cont_name)
print("Container:", cont
)
# Get the existing metadata, if any
meta = cf.get_container_metadata(cont)
print("Initial metadata:", meta
)
# Create a dict of metadata. Make one key with the required prefix,
# and the other without, to illustrate how pyrax will 'massage'
# the keys to include the require prefix.
new_meta = {"X-Container-Meta-City": "Springfield",
        "Famous_Family": "Simpsons"}
print()
print("Setting container metadata to:", new_meta)
cf.set_container_metadata(cont, new_meta)

# Verify that the new metadata has been set for both keys.
meta = cf.get_container_metadata(cont)
print("Updated metadata:", meta
)
# Now remove the city key
print()
print("Removing meta key for 'city'")
cf.remove_container_metadata_key(cont, "city")

# Verify that the key has been removed.
meta = cf.get_container_metadata(cont)
print("After removing key:", meta
)
# Clean up
cont.delete(True)

########NEW FILE########
__FILENAME__ = create_container
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cf = pyrax.cloudfiles

cont_name = pyrax.utils.random_ascii(8)
print("Creating container with random name:", cont_name)
cont = cf.create_container(cont_name)
print("New Container")
print("Name:", cont.name)
print("# of objects:", cont.object_count)
print()
print("All Containers")
print("list_containers:", cf.list_containers())
print("get_all_containers:", cf.get_all_containers()
)
# Clean up
cont.delete()

########NEW FILE########
__FILENAME__ = delete_objects
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import time

import pyrax
import pyrax.exceptions as exc

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cf = pyrax.cloudfiles

cont_name = pyrax.utils.random_ascii(8)
cont = cf.create_container(cont_name)
fname = "soon_to_vanish.txt"
text = "X" * 2056

# Create a file in the container
cont.store_object(fname, text)

# Verify that it's there.
obj = cont.get_object(fname)
print("Object present, size =", obj.total_bytes
)
# Delete it!
obj.delete()
start = time.time()

# See if it's still there; if not, this should raise an exception
# Generally this happens quickly, but an object may appear to remain
# in a container for a short period of time after calling delete().
while obj:
    try:
        obj = cont.get_object(fname)
        print("...still there...")
        time.sleep(0.5)
    except exc.NoSuchObject:
        obj = None
        print("Object '%s' has been deleted" % fname)
        print("It took %4.2f seconds to appear as deleted." % (time.time() - start)
)
# Clean up
cont.delete(True)

########NEW FILE########
__FILENAME__ = fetch_objects
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cf = pyrax.cloudfiles

cont_name = pyrax.utils.random_ascii(8)
cont = cf.create_container(cont_name)
obj_name = pyrax.utils.random_ascii(8)

text = "This is some text containing unicode characters like Ã©, Ã¼ and ËÂ¬âÃ§" * 100
obj = cf.store_object(cont, obj_name, text)

# Make sure that the content stored is identical
print("Using obj.get()")
stored_text = obj.get()
if stored_text == text:
    print("Stored text is identical")
else:
    print("Difference detected!")
    print("Original:", text)
    print("Stored:", stored_text
)
# Let's look at the metadata for the stored object
meta, stored_text = obj.get(include_meta=True)
print()
print("Metadata:", meta
)
# Demonstrate chunked retrieval
print()
print("Using chunked retrieval")
obj_generator = obj.get(chunk_size=256)
joined_text = "".join(obj_generator)
if joined_text == text:
    print("Joined text is identical")
else:
    print("Difference detected!")
    print("Original:", text)
    print("Joined:", joined_text
)
# Clean up
cont.delete(True)

########NEW FILE########
__FILENAME__ = get_objects
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os

import six

import pyrax
import pyrax.exceptions as exc

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cf = pyrax.cloudfiles

cont_name = pyrax.utils.random_ascii(8)
cont = cf.create_container(cont_name)
text = "File Content"

# Create 5 files with a similar name
for i in six.moves.range(5):
    nm = "series_%s" % i
    cont.store_object(nm, text)

# Create 5 files in a "folder", with repeated single-letter names
start = ord("a")
end = start + 5
for i in six.moves.range(start, end):
    chars = chr(i) * 4
    nm = "stuff/%s" % chars
    cont.store_object(nm, text)

# Verify
objs = cont.get_objects()
print()
print("Created the following objects:")
for obj in objs:
    print("  ", obj.name)
print()

# Limit and marker
limit = 4
marker = ""
objs = cont.get_objects(limit=limit, marker=marker)
print("Paging 4 objects at a time")
print("Paged Objects:", [obj.name for obj in objs])
marker = objs[-1].name
while True:
    objs = cont.get_objects(limit=limit, marker=marker)
    if not objs:
        break
    print("Paged Objects:", [obj.name for obj in objs])
    marker = objs[-1].name
print()

# Prefix
objs = cont.get_objects(prefix="stuff")
print("Objects Prefixed with 'stuff':", [obj.name for obj in objs])
print()

# Delimiter
objs = cont.get_objects(delimiter="/")
print("Objects Delimited with '/':", [obj.name for obj in objs]
)
# Clean up
cont.delete(True)

########NEW FILE########
__FILENAME__ = object_metadata
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import time

import pyrax
import pyrax.exceptions as exc

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cf = pyrax.cloudfiles

cont_name = pyrax.utils.random_ascii(8)
cont = cf.create_container(cont_name)
oname = pyrax.utils.random_ascii(8)
obj = cont.store_object(oname, "some text")

# Get the existing metadata, if any
meta = cf.get_object_metadata(cont, obj)
print("Initial metadata:", meta
)
# Create a dict of metadata. Make one key with the required prefix,
# and the other without, to illustrate how pyrax will 'massage'
# the keys to include the require prefix.
new_meta = {"X-Object-Meta-City": "Springfield",
        "Famous_Family": "Simpsons"}
print()
print("Adding metadata:", new_meta)
cf.set_object_metadata(cont, obj, new_meta)

# Verify that the new metadata has been set for both keys.
meta = cf.get_object_metadata(cont, obj)
print("Updated metadata:", meta
)
# Now remove the city key
print()
print("Removing meta key for 'city'")
cf.remove_object_metadata_key(cont, obj, "city")

# Verify that the key has been removed.
meta = cf.get_object_metadata(cont, obj)
print("After removing key:", meta
)
# Clean up
cont.delete(True)

########NEW FILE########
__FILENAME__ = store_object
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cf = pyrax.cloudfiles

cont_name = pyrax.utils.random_ascii(8)
cont = cf.create_container(cont_name)
obj_name = pyrax.utils.random_ascii(8)

text = "This is some text containing unicode like Ã©, Ã¼ and ËÂ¬âÃ§"
obj = cf.store_object(cont, obj_name, text)

# Verify that the object is there
print("Stored Object Name:", obj.name)
print("Size:", obj.total_bytes
)
# Make sure that the content stored is identical
stored_text = obj.get()
print("Original text:", text)
print("  Stored text:", stored_text)
if stored_text == text:
    print("Stored text is identical")
else:
    print("Difference detected!")
    print("Original:", text)
    print("Stored:", stored_text
)
# Clean up
cont.delete(True)

########NEW FILE########
__FILENAME__ = store_with_etag
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cf = pyrax.cloudfiles

cont_name = pyrax.utils.random_ascii(8)
obj_name = pyrax.utils.random_ascii(8)
cont = cf.create_container(cont_name)

content = "This is a random collection of words."
chksum = pyrax.utils.get_checksum(content)
obj = cf.store_object(cont, obj_name, content, etag=chksum)
print("Calculated checksum:", chksum)
print(" Stored object etag:", obj.etag
)
# Clean up
cont.delete(True)

########NEW FILE########
__FILENAME__ = temporary_url
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import requests
import time

import pyrax
import pyrax.exceptions as exc

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cf = pyrax.cloudfiles

cont_name = pyrax.utils.random_ascii(8)
cont = cf.create_container(cont_name)
oname = pyrax.utils.random_ascii(8)
ipsum = """Import integration functools test dunder object explicit. Method
integration mercurial unit import. Future integration decorator pypy method
tuple unit pycon. Django raspberrypi mercurial 2to3 cython scipy. Cython
raspberrypi exception pypy object. Cython integration functools 2to3 object.
Future raspberrypi exception 2to3. Dunder integration community goat import
jinja exception science. Kwargs integration diversity 2to3 dunder future
functools. Import integration itertools 2to3 cython pycon unit tuple."""
print("Creating an object...")
obj = cont.store_object(oname, ipsum)

print("Getting the TempURL...")
# Get the existing TempURL key
curr_key = cf.get_temp_url_key()
if not curr_key:
    # Create one.
    cf.set_temp_url_key()

# Create the Temporary URL
temp_url = obj.get_temp_url(seconds=60)
print("Temporary URL")
print(temp_url)
print()

# Now try downloading it
print("Downloading the TempURL...")
resp = requests.get(temp_url)
content = resp.content
print("Downloaded content == stored content: ", content == ipsum
)
# Clean up
cf.set_temp_url_key(curr_key)
cont.delete(True)

########NEW FILE########
__FILENAME__ = upload_file
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os

import pyrax
import pyrax.exceptions as exc
import pyrax.utils as utils

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cf = pyrax.cloudfiles

cont_name = pyrax.utils.random_ascii(8)
cont = cf.create_container(cont_name)

text = """First Line
    Indented Second Line
Last Line"""
# pyrax has a utility for creating temporary local files that clean themselves up.
with utils.SelfDeletingTempfile() as tmpname:
    print("Creating text file with the following content:")
    print("-" * 44)
    print(text)
    print("-" * 44)
    with open(tmpname, "w") as tmp:
        tmp.write(text)
    nm = os.path.basename(tmpname)
    print()
    print("Uploading file: %s" % nm)
    cf.upload_file(cont, tmpname, content_type="text/text")
# Let's verify that the file is there
obj = cont.get_object(nm)
print()
print("Stored Object:", obj)
print("Retrieved Content:")
print("-" * 44)
# Get the contents
print(obj.get())
print("-" * 44
)
# Clean up
cont.delete(True)

########NEW FILE########
__FILENAME__ = upload_folder
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import time

import six

import pyrax
import pyrax.exceptions as exc
import pyrax.utils as utils

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cf = pyrax.cloudfiles

cont_name = pyrax.utils.random_ascii(8)
cont = cf.create_container(cont_name)

# pyrax has a utility for creating temporary local directories that clean
# themselves up.
with utils.SelfDeletingTempDirectory() as tmpfolder:
    # Create a bunch of files
    for idx in six.moves.range(13):
        fname = "file_%s" % idx
        pth = os.path.join(tmpfolder, fname)
        with open(pth, "w") as tmp:
            tmp.write("This is some text")
    # Create a subfolder. It will be deleted automatically as part of
    # the cleanup of SelfDeletingTempDirectory.
    subfolder_path = os.path.join(tmpfolder, "subfolder")
    os.mkdir(subfolder_path)
    # Create some files in the subfolder, too.
    for idx in six.moves.range(7):
        fname = "subfile_%s" % idx
        pth = os.path.join(subfolder_path, fname)
        with open(pth, "w") as tmp:
            tmp.write("This is some text. " * 100)

    # OK, we've created our local file system. Now upload it to a container
    # named 'upfolder'. We'll have it skip all files ending in the digits
    # '2', '6' or '0'.
    ignore = ["*2", "*6", "*0"]
    print("Beginning Folder Uplaod")
    upload_key, total_bytes = cf.upload_folder(tmpfolder, cont, ignore=ignore)
    # Since upload_folder happens in the background, we need to stay in this
    # block until the upload is complete, or the SelfDeletingTempDirectory
    # will be deleted, and the upload won't find the files it needs.
    print("Total bytes to upload:", total_bytes)
    uploaded = 0
    while uploaded < total_bytes:
        uploaded = cf.get_uploaded(upload_key)
        print("Progress: %4.2f%%" % ((uploaded * 100.0) / total_bytes))
        time.sleep(1)

# OK, the upload is complete. Let's verify what's in 'upfolder'.
folder_name = os.path.basename(tmpfolder)
print()
print("Temp folder name:", folder_name)
nms = cf.get_container_object_names(cont, prefix=folder_name)
print("Number of files in container:", len(nms))
print("\n".join(nms)
)
# Clean up
cont.delete(True)

########NEW FILE########
__FILENAME__ = create_image
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cs = pyrax.cloudservers
servers = cs.servers.list()
srv_dict = {}
print("Select a server from which an image will be created.")
for pos, srv in enumerate(servers):
    print("%s: %s" % (pos, srv.name))
    srv_dict[str(pos)] = srv.id
selection = None
while selection not in srv_dict:
    if selection is not None:
        print("   -- Invalid choice")
    selection = raw_input("Enter the number for your choice: ")

server_id = srv_dict[selection]
print()
nm = raw_input("Enter a name for the image: ")

img_id = cs.servers.create_image(server_id, nm)

print("Image '%s' is being created. Its ID is: %s" % (nm, img_id))

########NEW FILE########
__FILENAME__ = create_server
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cs = pyrax.cloudservers
server_name = pyrax.utils.random_ascii(8)

ubu_image = [img for img in cs.images.list()
        if "14.04" in img.name
        and "PVHVM" in img.name][0]
print("Ubuntu Image:", ubu_image)
flavor_1GB = [flavor for flavor in cs.flavors.list()
        if flavor.ram == 1024][0]
print("1024 Flavor:", flavor_1GB)
server = cs.servers.create(server_name, ubu_image.id, flavor_1GB.id)
print("Name:", server.name)
print("ID:", server.id)
print("Status:", server.status)
print("Admin Password:", server.adminPass)
print("Networks:", server.networks)

########NEW FILE########
__FILENAME__ = create_with_meta_and_files
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cs = pyrax.cloudservers

ubu_image = [img for img in cs.images.list()
        if "12.04" in img.name][0]
flavor_1GB = [flavor for flavor in cs.flavors.list()
        if flavor.ram == 1024][0]

meta = {"test_key": "test_value",
        "meaning_of_life": "42",
        }

content = """This is the contents of the text file.
It has several lines of text.

And it even has a blank line."""

files = {"/root/testfile": content}

server = cs.servers.create("meta_server", ubu_image.id, flavor_1GB.id,
        meta=meta, files=files)
print("Name:", server.name)
print("ID:", server.id)
print("Admin Password:", server.adminPass)
print("Metadata:", server.metadata)
print()
print("When the server becomes active, shell in as root with the admin password.")
print("Verify that the file '/root/testfile' exists, and contains the exact "
    "content")
print("that was defined above.")
print()

########NEW FILE########
__FILENAME__ = delete_image
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cs = pyrax.cloudservers
all_images = cs.images.list()
images = [img for img in all_images if hasattr(img, "server")]
if not images:
    print("There are no images to delete. Create one, and then re-run this script.")
    print()
    sys.exit()
img_dict = {}
print("Select an image to delete:")
for pos, img in enumerate(images):
    print("%s: %s" % (pos, img.name))
    img_dict[str(pos)] = img
selection = None
while selection not in img_dict:
    if selection is not None:
        print("   -- Invalid choice")
    selection = raw_input("Enter the number for your choice: ")

image = img_dict.get(selection)
cs.images.delete(image.id)
print("Image '%s' has been deleted." % image.name)

########NEW FILE########
__FILENAME__ = delete_server
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys
import time

import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cs = pyrax.cloudservers

def create_server():
    print("Creating the sacrificial server...")
    img = cs.list_images()[0]
    flv = cs.list_flavors()[0]
    srv = cs.servers.create("sacrifice", img.id, flv.id)
    print("Server '%s' created; ID=%s" % (srv.name, srv.id))
    return srv

print()
print("Looking for a server named 'sacrifice' to delete...")
try:
    sacrifice = cs.servers.find(name="sacrifice")
    print("Found server named 'sacrifice'.")
except Exception as e:
    print("No server named 'sacrifice' exists, so for safety reasons this")
    print("script will not do anything potentially destructive.")
    print()
    answer = raw_input("Do you want to create that server now? [y/n] ")
    if answer.strip().lower()[0] == "y":
        sacrifice = create_server()
    else:
        print("The server will not be created.")
        sys.exit()

if sacrifice.status != "ACTIVE":
    print("Please wait until the 'sacrifice' server is in ACTIVE status.")
    print("Current status:", sacrifice.status)
    raw_answer = raw_input("Do you want this script to cycle every 10 seconds "
            "to check? [y/n] ")
    answer = raw_answer[0].lower()
    if answer != "y":
        sys.exit()
    print("Waiting...  (press CTRL-C to stop)")
    while sacrifice.status != "ACTIVE":
        time.sleep(10)
        sacrifice = cs.servers.get(sacrifice.id)
        print("Status is '%s' at %s" % (sacrifice.status, time.ctime()))
    print()
    print("The server is now active. You may re-run this script to delete it.")
    sys.exit()

print("Deleting 'sacrifice' server...", end=' ')
sacrifice.delete()
print("  Done!")

########NEW FILE########
__FILENAME__ = list_flavors
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cs = pyrax.cloudservers

flvs = cs.list_flavors()
for flv in flvs:
    print("Name:", flv.name)
    print("  ID:", flv.id)
    print("  RAM:", flv.ram)
    print("  Disk:", flv.disk)
    print("  VCPUs:", flv.vcpus)
    print()

########NEW FILE########
__FILENAME__ = list_images
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cs = pyrax.cloudservers

imgs = cs.images.list()
for img in imgs:
    print("Name: %s\n    ID: %s" % (img.name, img.id))

########NEW FILE########
__FILENAME__ = reboot
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cs = pyrax.cloudservers

servers = cs.servers.list()
# Find the first 'ACTIVE' server
try:
    active = [server for server in servers
            if server.status == "ACTIVE"][0]
except IndexError:
    print("There are no active servers in your account.")
    print("Please create one before running this script.")
    sys.exit()
# Display server info
print("Server Name:", active.name)
print("Server ID:", active.id)
print("Server Status:", active.status)
print()
answer = raw_input("Do you wish to reboot this server? [y/n] ")
if answer.strip().lower()[0] == "y":
    print()
    print("A 'soft' reboot attempts a graceful shutdown and restart of your "
        "server.")
    print("A 'hard' reboot power cycles your server.")
    answer = raw_input("Which type of reboot do you want to do? [s/h] ")
    answer = answer.strip().lower()[0]
    reboot_type = {"s": "soft", "h": "hard"}[answer]
    active.reboot(reboot_type)
    # Reload the server
    after_reboot = cs.servers.get(active.id)
    print()
    print("After reboot command")
    print("Server Status =", after_reboot.status)

########NEW FILE########
__FILENAME__ = attach_detach_volume
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cs = pyrax.cloudservers
cbs = pyrax.cloud_blockstorage

try:
    server = cs.servers.find(name="sample_server")
except cs.exceptions.NotFound as e:
    print()
    print("Before running this sample, create a server named 'sample_server' ")
    print("and wait for it to be in an ACTIVE state.")
    answer = raw_input("Do you wish to have this server created for you? [y/N]")
    if answer.lower().startswith("y"):
        ubu_image = [img for img in cs.images.list()
                if "Ubuntu" in img.name][0]
        flavor_1GB = [flavor for flavor in cs.flavors.list()
                if flavor.ram == 1024][0]
        print("Creating the server...")
        server = cs.servers.create("sample_server", ubu_image.id, flavor_1GB.id)
        print("Server created; waiting for it to become active...")
        pyrax.utils.wait_until(server, "status", "ACTIVE", attempts=0,
                verbose=True)
    else:
        sys.exit()

# Create a 100GB SATA volume, and attach it to the server
vol = cbs.create(name="sample_volume", size=100, volume_type="SATA")
print("New volume:", vol.name)
print("Attaching to:", server)
print("It may take several seconds for the attachment to complete.")
vol.attach_to_instance(server, mountpoint="/dev/xvdd")
pyrax.utils.wait_until(vol, "status", "in-use", interval=3, attempts=0,
        verbose=True)
print("Volume attachments:", vol.attachments)

# Now detach the volume
print()
print("Detaching the volume...")
vol.detach()
pyrax.utils.wait_until(vol, "status", "available", interval=3, attempts=0,
        verbose=True)
print("Attachments:", vol.attachments)

# Delete the volume
vol.delete()
print("Deleted")

########NEW FILE########
__FILENAME__ = create_snapshot
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax
import pyrax.exceptions as exc

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cbs = pyrax.cloud_blockstorage
vol_name = pyrax.utils.random_ascii(length=8)
vol = cbs.create(name="sample_volume", size=500, volume_type="SATA")

snap = vol.create_snapshot("sample_snap")

print("Volume:", vol)
print("Snapshot:", snap)
print()
print("You have to wait until the snapshot finishes being created before")
print("it can be deleted. Press Ctrl-C to interrupt.")
try:
    pyrax.utils.wait_until(snap, "status", "available", attempts=0, verbose=True)
except KeyboardInterrupt:
    print()
    print("Process interrupted.")
    print("Be sure to manually delete this snapshot when it completes.")
    sys.exit(0)
print()
print("Deleting snapshot...")
snap.delete()
try:
    vol.delete()
except exc.VolumeNotAvailable:
    print("Could not delete volume; snapshot deletion has not completed yet.")
    print("Please be sure to delete the volume manually.")
    print()
print("Done.")

########NEW FILE########
__FILENAME__ = create_volume
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cbs = pyrax.cloud_blockstorage
vol_name = pyrax.utils.random_ascii(length=8)

sata_vol = cbs.create(name="my_standard_volume", size=500, volume_type="SATA")
ssd_vol = cbs.create(name="my_fast_volume", size=500, volume_type="SSD")

print("SATA:", sata_vol)
print()
print("SSD:", ssd_vol)
print()
print("To delete these volumes, run 'delete_volume.py'")
print()

########NEW FILE########
__FILENAME__ = delete_volume
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cbs = pyrax.cloud_blockstorage

# This assumes that you have are deleting the volumes named 'my_fast_volume'
# and 'my_standard_volume' that were created in create_volume.py.
for nm in ("my_fast_volume", "my_standard_volume"):
    try:
        vol = cbs.findall(name=nm)[0]
    except IndexError:
        print("There is no volume named '%s'. Skipping..." % nm)
        vol = None
    if vol:
        print("Deleting", vol)
        vol.delete()
print()
print("Done.")
print()

########NEW FILE########
__FILENAME__ = add_database
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cdb = pyrax.cloud_databases

instances = cdb.list()
if not instances:
    print("There are no cloud database instances.")
    print("Please create one and re-run this script.")
    sys.exit()

print()
print("Available Instances:")
for pos, inst in enumerate(instances):
    print("%s: %s (%s, RAM=%s, volume=%s) Status=%s" % (pos, inst.name,
            inst.flavor.name, inst.flavor.ram, inst.volume.size, inst.status))
try:
    sel = int(raw_input("Enter the number of the instance to which you want to "
            "add a database: "))
except ValueError:
    print()
    print("Invalid (non-numeric) entry.")
    print()
    sys.exit()
try:
    inst = instances[sel]
except IndexError:
    print()
    print("Invalid selection.")
    print()
    sys.exit()

nm = raw_input("Enter the name of the new database to create in this instance: ")
db = inst.create_database(nm)

dbs = inst.list_databases()
print()
print("Database %s has been created." % nm)
print("Current databases for instance '%s':" % inst.name)
for db in dbs:
    print(db.name)
print()

########NEW FILE########
__FILENAME__ = add_user
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import getpass
import os
import sys

import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cdb = pyrax.cloud_databases

instances = cdb.list()
if not instances:
    print("There are no cloud database instances.")
    print("Please create one and re-run this script.")
    sys.exit()

print()
print("Available Instances:")
for pos, inst in enumerate(instances):
    print("%s: %s (%s, RAM=%s, volume=%s) Status=%s" % (pos, inst.name,
            inst.flavor.name, inst.flavor.ram, inst.volume.size, inst.status))
try:
    sel = int(raw_input("Enter the number of the instance to which you want to "
            "add a user: "))
except ValueError:
    print()
    print("Invalid (non-numeric) entry.")
    print()
    sys.exit()
try:
    inst = instances[sel]
except IndexError:
    print()
    print("Invalid selection.")
    print()
    sys.exit()

print()
nm = raw_input("Enter the user name: ")
pw = getpass.getpass("Enter the password for this user: ")
print()
print("Available Databases:")
dbs = inst.list_databases()
for pos, db in enumerate(dbs):
    print("%s: %s" % (pos, db.name))
print("Enter the numbers of the databases which the user can access,", end=' ')
print("separated by spaces: ", end=' ')
selected = raw_input()
selnums = [int(val) for val in selected.split()]
sel_dbs = [db.name for pos, db in enumerate(dbs)
        if pos in selnums]

user = inst.create_user(nm, pw, database_names=sel_dbs)

print()
print("User '%s' has been created on instance '%s'." % (nm, inst.name))
print()

########NEW FILE########
__FILENAME__ = create_instance
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cdb = pyrax.cloud_databases
instance_name = pyrax.utils.random_ascii(8)

flavors = cdb.list_flavors()
nm = raw_input("Enter a name for your new instance: ")
print()
print("Available Flavors:")
for pos, flavor in enumerate(flavors):
    print("%s: %s, %s" % (pos, flavor.name, flavor.ram))

flav = int(raw_input("Select a Flavor for your new instance: "))
try:
    selected = flavors[flav]
except IndexError:
    print("Invalid selection; exiting.")
    sys.exit()

print()
sz = int(raw_input("Enter the volume size in GB (1-50): "))

instance = cdb.create(nm, flavor=selected, volume=sz)
print("Name:", instance.name)
print("ID:", instance.id)
print("Status:", instance.status)
print("Flavor:", instance.flavor.name)

########NEW FILE########
__FILENAME__ = delete_instance
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cdb = pyrax.cloud_databases

instances = cdb.list()
if not instances:
    print("There are no cloud database instances to delete.")
    sys.exit()

print()
print("Available Instances:")
for pos, inst in enumerate(instances):
    print("%s: %s (%s, RAM=%s, volume=%s) Status=%s" % (pos, inst.name,
            inst.flavor.name, inst.flavor.ram, inst.volume.size, inst.status))
try:
    sel = int(raw_input("Enter the number of the instance to delete: "))
except ValueError:
    print()
    print("Invalid (non-numeric) entry.")
    print()
    sys.exit()
try:
    del_inst = instances[sel]
except IndexError:
    print()
    print("Invalid selection.")
    print()
    sys.exit()

del_inst.delete()
print()
print("Instance %s has been deleted." % del_inst.name)
print()

########NEW FILE########
__FILENAME__ = list_flavors
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cdb = pyrax.cloud_databases

flavors = cdb.list_flavors()
print()
print("Available Flavors:")
for flavor in flavors:
    print("Name: %s; RAM: %s, ID: %s" % (flavor.name, flavor.ram, flavor.id))
print()

########NEW FILE########
__FILENAME__ = add_ptr_records
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax
import pyrax.exceptions as exc


pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
dns = pyrax.cloud_dns
cs = pyrax.cloudservers

# Substitute an actual server ID here
server_id = "00000000-0000-0000-0000-000000000000"
server = cs.servers.get(server_id)

# Substitute your actual domain name and IP addresses here
domain_name = "abc.example.edu"
ipv4_rec = {"name": domain_name,
        "type": "PTR",
        "data": "1.2.3.4",
        "ttl": 7200}
ipv6_rec = {"name": domain_name,
        "type": "PTR",
        "data": "2001:000::0",
        "ttl": 7200}

recs = dns.add_ptr_records(server, [ipv4_rec, ipv6_rec])
print(recs)
print()

########NEW FILE########
__FILENAME__ = add_records
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax
import pyrax.exceptions as exc


pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
dns = pyrax.cloud_dns

domain_name = "abc.example.edu"

try:
    dom = dns.find(name=domain_name)
except exc.NotFound:
    answer = raw_input("The domain '%s' was not found. Do you want to create "
            "it? [y/n]" % domain_name)
    if not answer.lower().startswith("y"):
        sys.exit()
    try:
        dom = dns.create(name=domain_name, emailAddress="sample@example.edu",
                ttl=900, comment="sample domain")
    except exc.DomainCreationFailed as e:
        print("Domain creation failed:", e)
    print("Domain created:", dom)
    print()

# Substitute your actual domain name and IP addresses here
a_rec = {"type": "A",
        "name": domain_name,
        "data": "1.2.3.4",
        "ttl": 6000}
mx_rec = {"type": "MX",
        "name": domain_name,
        "data": "mail.example.edu",
        "priority": 50,
        "comment": "Backup mail server"}
recs = dom.add_records([a_rec, mx_rec])
print(recs)
print()

########NEW FILE########
__FILENAME__ = create_domain
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os

import pyrax
import pyrax.exceptions as exc


pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
dns = pyrax.cloud_dns

domain_name = "abc.example.edu"
try:
    dom = dns.create(name=domain_name, emailAddress="sample@example.edu",
            ttl=900, comment="sample domain")
except exc.DomainCreationFailed as e:
    print("Domain creation failed:", e)
print("Domain created:", dom)

########NEW FILE########
__FILENAME__ = create_subdomain
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax
import pyrax.exceptions as exc


pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
dns = pyrax.cloud_dns

domain_name = "abc.example.edu"
try:
    dom = dns.find(name=domain_name)
except exc.DomainCreationFailed as e:
    answer = raw_input("The domain '%s' was not found. Do you want to create "
            "it? [y/n]" % domain_name)
    if not answer.lower().startswith("y"):
        sys.exit()
    try:
        dom = dns.create(name=domain_name, emailAddress="sample@example.edu",
                ttl=900, comment="sample domain")
    except exc.DomainCreationFailed as e:
        print("Domain creation failed:", e)
        print()
        sys.exit()
    print("Domain created:", dom)
    print()

sub_name = "sub.%s" % domain_name
try:
    sub = dns.create(name=sub_name, emailAddress="sample@example.edu", ttl=900,
            comment="sample subdomain")
except exc.DomainCreationFailed as e:
    print("Could not create '%s': %s" % (sub_name, e))
    print()
    sys.exit()

print("Subdomain '%s' successfully created." % sub_name)
print(sub)
print()

########NEW FILE########
__FILENAME__ = delete_all_ptr_records
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax
import pyrax.exceptions as exc


pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
dns = pyrax.cloud_dns
cs = pyrax.cloudservers

# Be sure to substitute an actual server ID here
server_id = "00000000-0000-0000-0000-000000000000"
server = cs.servers.get(server_id)

ret = dns.delete_ptr_records(server)
print()
print(ret)
print()

########NEW FILE########
__FILENAME__ = delete_all_records
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax
import pyrax.exceptions as exc


pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
dns = pyrax.cloud_dns

domain_name = "abc.example.edu"
count = 0
try:
    dom = dns.find(name=domain_name)
except exc.NotFound:
    print("There is no DNS information for the domain '%s'." % domain_name)
    sys.exit()

sub_iter = dns.get_record_iterator(dom)
for sub in sub_iter:
    if sub.type == "NS":
        # Don't delete these; they are required
        continue
    sub.delete()
    count += 1

if not count:
    print("There were no non-NS records to delete.")
else:
    if count == 1:
        print("The one non-NS record for '%s' has been deleted." % domain_name)
    else:
        print("All %s non-NS records for '%s' have been deleted." % (count,
                domain_name))
print()

########NEW FILE########
__FILENAME__ = delete_all_subdomains
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax
import pyrax.exceptions as exc


pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
dns = pyrax.cloud_dns

domain_name = "abc.example.edu"
count = 0
try:
    dom = dns.find(name=domain_name)
except exc.NotFound:
    print("There is no DNS information for the domain '%s'." % domain_name)
    sys.exit()

sub_iter = dns.get_subdomain_iterator(dom)
for sub in sub_iter:
    sub.delete()
    count += 1

if not count:
    print("There were no subdomains to delete.")
else:
    if count == 1:
        print("The one subdomain of '%s' has been deleted." % domain_name)
    else:
        print("All %s subdomains of '%s' have been deleted." % (count, domain_name))
print()

########NEW FILE########
__FILENAME__ = delete_domain
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax
import pyrax.exceptions as exc


pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
dns = pyrax.cloud_dns

domain_name = "abc.example.edu"
try:
    dom = dns.find(name=domain_name)
except exc.NotFound:
    print("There is no DNS information for the domain '%s'." % domain_name)
    sys.exit()

dom.delete()
print("The domain '%s' was successfully deleted." % domain_name)

########NEW FILE########
__FILENAME__ = iterate_domains
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os

import pyrax
import pyrax.exceptions as exc


pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
dns = pyrax.cloud_dns

def print_domain(domain):
    print("Domain:", domain.name)
    print("  email:", domain.emailAddress)
    print("  created:", domain.created)
    print()

count = 0

iterator = dns.get_domain_iterator()
for domain in iterator:
    count += 1
    print_domain(domain)

print("There were a total of %s domain(s)." % count)

########NEW FILE########
__FILENAME__ = list_domains
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os

import pyrax
import pyrax.exceptions as exc


pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
dns = pyrax.cloud_dns

PAGE_SIZE = 10
count = 0

def print_domains(domains):
    for domain in domains:
        print("Domain:", domain.name)
        print("  email:", domain.emailAddress)
        print("  created:", domain.created)
        print()

domains = dns.list(limit=PAGE_SIZE)
count += len(domains)
print_domains(domains)

# Loop until all domains are printed
while True:
    try:
        domains = dns.list_next_page()
        count += len(domains)
    except exc.NoMoreResults:
        break
    print_domains(domains)

print("There were a total of %s domain(s)." % count)

########NEW FILE########
__FILENAME__ = list_ptr_records
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax
import pyrax.exceptions as exc


pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
dns = pyrax.cloud_dns
cs = pyrax.cloudservers

# Be sure to substitute an actual server ID here
server_id = "00000000-0000-0000-0000-000000000000"
server = cs.servers.get(server_id)

ptr_records = dns.list_ptr_records(server)
if ptr_records:
    for ptr_record in ptr_records:
        print("PTR Record:")
        print("  ID:", ptr_record.id)
        print("  name:", ptr_record.name)
        print("  data:", ptr_record.data)
        print("  TTL:", ptr_record.ttl)
        print("  comment:", ptr_record.comment)
else:
    print("There are no PTR records for device '%s'." % server)
print()

########NEW FILE########
__FILENAME__ = list_records
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax
import pyrax.exceptions as exc


pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
dns = pyrax.cloud_dns

PAGE_SIZE = 10
count = 0
domain_name = "abc.example.edu"

def print_records(records):
    for record in records:
        print("Record:", record.type)
        print("  ID:", record.id)
        print("  data:", record.data)
        print("  TTL:", record.ttl)
        print("  comment:", record.comment)
        print()

try:
    dom = dns.find(name=domain_name)
except exc.NotFound:
    answer = raw_input("The domain '%s' was not found. Do you want to create "
            "it? [y/n]" % domain_name)
    if not answer.lower().startswith("y"):
        sys.exit()
    try:
        dom = dns.create(name=domain_name, emailAddress="sample@example.edu",
                ttl=900, comment="sample domain")
    except exc.DomainCreationFailed as e:
        print("Domain creation failed:", e)
    print("Domain created:", dom)
    print()

records = dom.list_records(limit=PAGE_SIZE)
count += len(records)
print_records(records)

# Loop until all records are printed
while True:
    try:
        records = dns.list_records_next_page()
        count += len(records)
    except exc.NoMoreResults:
        break
    print_records(records)

print("There were a total of %s record(s)." % count)
print()

########NEW FILE########
__FILENAME__ = list_subdomains
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax
import pyrax.exceptions as exc


pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
dns = pyrax.cloud_dns

PAGE_SIZE = 10
count = 0
domain_name = "abc.example.edu"

def print_domains(domains):
    for domain in domains:
        print("Domain:", domain.name)
        print("  email:", domain.emailAddress)
        print("  created:", domain.created)
        print()

try:
    dom = dns.find(name=domain_name)
except exc.NotFound:
    answer = raw_input("The domain '%s' was not found. Do you want to create "
            "it? [y/n]" % domain_name)
    if not answer.lower().startswith("y"):
        sys.exit()
    try:
        dom = dns.create(name=domain_name, emailAddress="sample@example.edu",
                ttl=900, comment="sample domain")
    except exc.DomainCreationFailed as e:
        print("Domain creation failed:", e)
    print("Domain created:", dom)
    print()

subdomains = dom.list_subdomains(limit=PAGE_SIZE)
count += len(subdomains)
print_domains(subdomains)

# Loop until all subdomains are printed
while True:
    try:
        subdomains = dns.list_subdomains_next_page()
        count += len(subdomains)
    except exc.NoMoreResults:
        break
    print_domains(subdomains)

print("There were a total of %s subdomain(s)." % count)
subs = dom.list_subdomains()
print(subs)

########NEW FILE########
__FILENAME__ = update_domain
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax
import pyrax.exceptions as exc


pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
dns = pyrax.cloud_dns

domain_name = "abc.example.edu"
try:
    dom = dns.find(name=domain_name)
except exc.NotFound:
    print("There is no DNS information for the domain '%s'." % domain_name)
    sys.exit()

print("Original TTL for '%s': %s" % (domain_name, dom.ttl))
# Add 10 minutes
new_ttl = dom.ttl + 600
dom.update(ttl=new_ttl)
dom.reload()
print("New TTL: %s" % dom.ttl)

########NEW FILE########
__FILENAME__ = update_ptr_record
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax
import pyrax.exceptions as exc


pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
dns = pyrax.cloud_dns
cs = pyrax.cloudservers

# Be sure to substitute an actual server ID here
server_id = "00000000-0000-0000-0000-000000000000"
server = cs.servers.get(server_id)

domain_name = "abc.example.edu"
records = dns.list_ptr_records(server)
if not records:
    print("There are no PTR records for device '%s' to update." % server)
    sys.exit()
rec = records[0]
orig_ttl = rec.ttl
orig_data = rec.data
# Add 5 minutes
new_ttl = orig_ttl + 300
resp = dns.update_ptr_record(server, rec, domain_name, ttl=new_ttl,
        data=orig_data, comment="TTL has been increased")

if resp:
    print("Original TTL:", orig_ttl)
    print("New TTL:", new_ttl)
else:
    print("Update failed.")
print()

########NEW FILE########
__FILENAME__ = add_remove_node
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import time

import pyrax


pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
clb = pyrax.cloud_loadbalancers

lb = clb.list()[0]
print()
print("Load Balancer:", lb)
print()
print("Current nodes:", lb.nodes
)
# You may have to adjust the address of the node to something on
# the same internal network as your load balancer.
new_node = clb.Node(address="10.177.1.2", port=80, condition="ENABLED")
lb.add_nodes([new_node])
pyrax.utils.wait_until(lb, "status", "ACTIVE", interval=1, attempts=30,
        verbose=True)

print()
print("After adding node:", lb.nodes
)
# Now remove that node. Note that we can't use the original node instance,
# as it was created independently, and doesn't have the link to its load
# balancer. Instead, we'll get the last node from the load balancer.
added_node = [node for node in lb.nodes
        if node.address == new_node.address][0]
print()
print("Added Node:", added_node)
added_node.delete()
pyrax.utils.wait_until(lb, "status", "ACTIVE", interval=1, attempts=30,
        verbose=True)
print()
print("After removing node:", lb.nodes)

########NEW FILE########
__FILENAME__ = content_caching
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
clb = pyrax.cloud_loadbalancers

try:
    lb = clb.list()[0]
except IndexError:
    print("You do not have any load balancers yet.")
    print("Please create one and then re-run this script.")
    sys.exit()

print("Load Balancer:", lb)
orig = lb.content_caching
print("Current setting of content caching:", orig)
print()
if orig:
    print("Turning off...")
else:
    print("Turning on...")
lb.content_caching = not orig
print("New setting of content caching:", lb.content_caching)

########NEW FILE########
__FILENAME__ = create_lb
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
clb = pyrax.cloud_loadbalancers
lb_name = pyrax.utils.random_ascii(length=8)

# You may have to adjust the address of the node to something on
# the same internal network as your load balancer.
node = clb.Node(address="10.177.1.1", port=80, condition="ENABLED")
vip = clb.VirtualIP(type="PUBLIC")
lb = clb.create(lb_name, port=80, protocol="HTTP", nodes=[node], virtual_ips=[vip])

print("Node:", node.to_dict())
print("Virtual IP:", vip.to_dict())
print()
print("Load Balancer:", lb)

########NEW FILE########
__FILENAME__ = create_node
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
clb = pyrax.cloud_loadbalancers

# You need to specify an address, port and condition
node = clb.Node(address="10.1.1.1", port=80, condition="DISABLED")
print("Node:", node
)
# Actually, 'condition' is optional; it will default to 'ENABLED'.
node_default = clb.Node(address="10.1.1.2", port=80)
print("Node(using default condition):", node_default)

########NEW FILE########
__FILENAME__ = create_vip
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
clb = pyrax.cloud_loadbalancers

# You can specify a type, address, IP version, and ID
# None are required; defaults are:
#    type: PUBLIC
#    address: None
#    ip_version: IPV4
#    id: None

vip = clb.VirtualIP()
print("Virtual IP (using defaults):", vip
)
vip = clb.VirtualIP(type="SERVICENET", address="1.2.3.4", ipVersion="IPV4", id=999)
print("Virtual IP (using supplied values):", vip)

########NEW FILE########
__FILENAME__ = get_lb_attributes
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
clb = pyrax.cloud_loadbalancers

try:
    lb = clb.list()[0]
except IndexError:
    print("You do not have any load balancers yet.")
    print("Please create one and then re-run this script.")
    sys.exit()

print("Load Balancer:", lb)
print("Name:", lb.name)
print("ID:", lb.id)
print("Status:", lb.status)
print("Nodes:", lb.nodes)
print("Virtual IPs:", lb.virtual_ips)
print("Algorithm:", lb.algorithm)
print("Protocol:", lb.protocol)

########NEW FILE########
__FILENAME__ = get_usage
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import datetime
import os

import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
clb = pyrax.cloud_loadbalancers

# Get load balancer usage
usage = clb.get_usage()
print("Usage for Account:", usage["accountId"])
print()
print("Account Usage Records")
print("-" * 30)
au_recs = usage["accountUsage"]
for rec_key in au_recs.keys()[:5]:
    recs = au_recs[rec_key]
    if len(recs) > 5:
        print("(only the first 5 records...)")
    print(recs[:5])
    print()
print("Load Balancer Usage Records")
print("-" * 30)
lb_recs = usage["loadBalancerUsages"]
if len(lb_recs) > 5:
    print("(only the first 5 records...)")
for rec in lb_recs[:5]:
    print(rec)
    print()

########NEW FILE########
__FILENAME__ = list_algorithms
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
clb = pyrax.cloud_loadbalancers

# Get available algorithms
print("Algorithms:", clb.algorithms)

########NEW FILE########
__FILENAME__ = list_protocols
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
clb = pyrax.cloud_loadbalancers

# Get available protocols
print("Protocols:", clb.protocols)

########NEW FILE########
__FILENAME__ = metadata
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
clb = pyrax.cloud_loadbalancers

lb = clb.list()[0]
orig_meta = lb.get_metadata()
print("Initial metadata:", orig_meta)
lb.set_metadata({"a": "one", "b": "two", "c": "three"})
print("New metadata:", lb.get_metadata())
lb.update_metadata({"d": "four"})
print("Updated metadata:", lb.get_metadata())
lb.set_metadata({"e": "five"})
print("After set_metadata:", lb.get_metadata())
lb.delete_metadata()
print("After delete_metadata:", lb.get_metadata())
if orig_meta:
    lb.set_metadata(orig_meta)
    print("After restoring original metadata:", lb.get_metadata())

########NEW FILE########
__FILENAME__ = node_condition
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
clb = pyrax.cloud_loadbalancers

lb = clb.list()[0]
# Initial state
print("Initial:", [(node.id, node.condition) for node in lb.nodes]
)
# Toggle the first node's condition between ENABLED and DISABLED
node = lb.nodes[0]
node.condition = "DISABLED" if node.condition == "ENABLED" else "ENABLED"
node.update()

# After toggling
print("Toggled:", [(node.id, node.condition) for node in lb.nodes])

########NEW FILE########
__FILENAME__ = session_persistence
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
clb = pyrax.cloud_loadbalancers

try:
    lb = clb.list()[0]
except IndexError:
    print("You do not have any load balancers yet.")
    print("Please create one and then re-run this script.")
    sys.exit()

print("Load Balancer:", lb)
orig = lb.session_persistence
print("Current setting of session persistence:", orig or '""')
print()
if orig:
    print("Clearing...")
    lb.session_persistence = ""
else:
    print("Setting persistence to HTTP_COOKIE...")
    lb.session_persistence = "HTTP_COOKIE"
print("New setting of session persistence:", lb.session_persistence or '""')

########NEW FILE########
__FILENAME__ = ssl_termination
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2012 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
clb = pyrax.cloud_loadbalancers

try:
    lb = clb.list()[0]
except IndexError:
    print("You do not have any load balancers yet.")
    print("Please create one and then re-run this script.")
    sys.exit()

orig = lb.get_ssl_termination()
print("Current setting of SSL Termination:", orig)
print()

if orig:
    print("Updating SSL Termination info...")
    curr_enabled = orig["enabled"]
    new_enabled = not curr_enabled
    lb.update_ssl_termination(enabled=new_enabled)
else:
    print("Adding SSL Termination info...")
    lb.add_ssl_termination(securePort=443, secureTrafficOnly=False,
            certificate="dummy_certificate", privatekey="dummy_private_key")
print()
print("New setting of SSL Termination:", lb.get_ssl_termination())

########NEW FILE########
__FILENAME__ = create_alarm
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2013 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

sys.path.insert(0, os.path.abspath(os.pardir))

import pyrax

from util import option_chooser

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cm = pyrax.cloud_monitoring

# We need the IP address of the entity for this check
ents = cm.list_entities()
if not ents:
    print("You must create an entity before you can create a notification.")
    sys.exit()
print("Select the entity on which you wish to create the notification:")
ent = option_chooser(ents, attr="name")
entity = ents[ent]
print(entity
)
checks = entity.list_checks()
print("Select a check to notify about:")
check_num = option_chooser(checks, attr="label")
check = checks[check_num]

plans = cm.list_notification_plans()
plan_num = option_chooser(plans, attr="label")
plan = plans[plan_num]

# Create an alarm which causes your notification plan's `warning` to be
# notified whenever the average ping time goes over 5 seconds. Otherwise,
# the status will be `ok`.
alarm = cm.create_alarm(entity, check, plan,
    ("if (rate(metric['average']) > 5) { return new AlarmStatus(WARNING); } "
     "return new AlarmStatus(OK);"), label="sample alarm")

print("Created Alarm %s" % alarm.id)

########NEW FILE########
__FILENAME__ = create_check
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2013 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

sys.path.insert(0, os.path.abspath(os.pardir))

import pyrax

from util import option_chooser

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cm = pyrax.cloud_monitoring

# We need the IP address of the entity for this check
ents = cm.list_entities()
if not ents:
    print("You must create an entity before you can create a notification.")
    sys.exit()
print("Select the entity on which you wish to create the notification:")
ent = option_chooser(ents, attr="name")
entity = ents[ent]
print(entity
)
aliases = entity.ip_addresses.items()
print("Select an IP address to check")
interface = option_chooser(aliases)
alias = aliases[interface][0]

# cm.list_check_types() would provide all available check types.
# However, this sample will use the most basic type: remote.ping

# List the available Monitoring Zones
zones = cm.list_monitoring_zones()
print("Select a Monitoring Zone:")
zone_choice = option_chooser(zones, attr="label")
zone = zones[zone_choice]

# Create the check
chk = cm.create_check(entity, label="sample_check", check_type="remote.ping",
        details={"count": 5}, monitoring_zones_poll=[zone],
        period=60, timeout=20, target_alias=alias)

print("Name:", chk.name)
print("ID:", chk.id)

########NEW FILE########
__FILENAME__ = create_entity
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2013 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cm = pyrax.cloud_monitoring
cs = pyrax.cloudservers

# Create an entity based on an existing server
servers = cs.servers.list()
if not servers:
    print("You must have at least one server to run this sample code.")
    exit()
server = servers[0]
ip = server.accessIPv4
ent = cm.create_entity(name="sample_entity", ip_addresses={"main": ip},
        metadata={"note": "Sample enitity for server '%s'" % server.name})

print("Name:", ent.name)
print("ID:", ent.id)
print("IPs:", ent.ip_addresses)
print("Meta:", ent.metadata)

########NEW FILE########
__FILENAME__ = create_notification
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2013 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import sys

sys.path.insert(0, os.path.abspath(os.pardir))

import pyrax

from util import option_chooser

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cm = pyrax.cloud_monitoring

# We need the IP address of the entity for this check
ents = cm.list_entities()
if not ents:
    print("You must create an entity before you can create a notification.")
    sys.exit()
print("Select the entity on which you wish to create the notification:")
ent = option_chooser(ents, attr="name")
entity = ents[ent]
print(entity
)
checks = entity.list_checks()
print("Select a check to notify about:")
check_num = option_chooser(checks, attr="label")
check = checks[check_num]

# cm.list_notification_types() would provide all available check types.
# However, this sample will use the most basic type: email

email = raw_input("Enter the email address to be notified at: ")

# Create the notification
notif = cm.create_notification("email", label="sample email",
        details={"address": email})

# You may want to set different notifications to different states.
# This sample just sets the same for all as a simple example.
np = cm.create_notification_plan(label="sample notification plan",
        ok_state=notif, warning_state=notif, critical_state=notif)

print("Created Notification %s" % notif.id)
print("Added %s to Notification Plan %s" % (notif.id, np.id))

########NEW FILE########
__FILENAME__ = util
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2013 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import sys

def option_chooser(options, attr=None):
    """Given an iterable, enumerate its contents for a user to choose from.
    If the optional `attr` is not None, that attribute in each iterated
    object will be printed.

    This function will exit the program if the user chooses the escape option.
    """
    for num, option in enumerate(options):
        if attr:
            print("%s: %s" % (num, getattr(option, attr)))
        else:
            print("%s: %s" % (num, option))
    # Add an escape option
    escape_opt = num + 1
    print("%s: I want to exit!" % escape_opt)
    choice = raw_input("Selection: ")
    try:
        ichoice = int(choice)
        if ichoice > escape_opt:
            raise ValueError
    except ValueError:
        print("Valid entries are the numbers 0-%s. Received '%s'." % (escape_opt,
                choice))
        sys.exit()

    if ichoice == escape_opt:
        print("Bye!")
        sys.exit()

    return ichoice

########NEW FILE########
__FILENAME__ = create_bastion
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2013 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

from pprint import pprint
import os

import pyrax
from pyrax import utils


pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cs = pyrax.cloudservers
cnw = pyrax.cloud_networks
new_network_name = "SAMPLE_NETWORK"
new_network_cidr = "192.168.0.0/24"

# These are the IDs for the image and flavor to be used
img_id = "5cebb13a-f783-4f8c-8058-c4182c724ccd"
flavor_id = "performance1-1"

# Create the new network
new_net = cnw.create(new_network_name, cidr=new_network_cidr)
print("New network:", new_net
)
# Create the bastion server
networks = new_net.get_server_networks(public=True, private=True)
bastion = cs.servers.create("bastion", img_id, flavor_id,
        nics=networks)
print("Bastion server:", bastion.name, bastion.id
)
# Create an isolated server
networks = new_net.get_server_networks(public=False, private=False)
isolated = cs.servers.create("isolated", img_id, flavor_id,
        nics=networks)
print("Isolated server:", isolated.name, isolated.id
)
print()
print("The networks will not be visible until the servers have finished building.")
print("Do you want to wait until then to see the results? It might take several")
answer = raw_input("minutes to complete. [y/N]")
if answer not in "yY":
    exit()

bas_id = bastion.id
iso_id = isolated.id
pyrax.utils.wait_until(bastion, "status", ("ERROR", "ACTIVE"), attempts=0,
        interval=10, verbose=True)
pyrax.utils.wait_until(isolated, "status", ("ERROR", "ACTIVE"), attempts=0,
        interval=10, verbose=True)
# Refresh the objects with the latest values of the servers.
bastion = cs.servers.get(bas_id)
isolated = cs.servers.get(iso_id)
if "ERROR" in (bastion.status, isolated.status):
    print("There was an error building the servers. Please try again.")
    exit()

print("Bastion server networks:")
pprint(bastion.networks)
print()
print("Isolated server networks:")
pprint(isolated.networks)

########NEW FILE########
__FILENAME__ = create_network
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2013 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax
from pyrax import utils

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
cnw = pyrax.cloud_networks
new_network_name = "SAMPLE_NETWORK"
new_network_cidr = "192.168.0.0/24"

# List initial status
nets = cnw.list()
for net in nets:
    print("Network: %s; cidr=%s; id=%s" % (net.label, net.cidr, net.id))
print()

# Add the new network
new_net = cnw.create(new_network_name, cidr=new_network_cidr)
print("NEW NET", new_net)

########NEW FILE########
__FILENAME__ = delete_network
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2013 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax
from pyrax import exc
from pyrax import utils

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)

pyrax.set_http_debug(True)

cnw = pyrax.cloud_networks
network_name = "SAMPLE_NETWORK"

# Get the network created in the create_network sample script
try:
    net = cnw.find_network_by_label(network_name)
except exc.NetworkNotFound:
    msg = ("The sample network was not found. Please run the 'create_network' "
            "script before running this script.")
    print(msg)
    exit()

print("Sample network:")
print(net)
print()
net.delete()
print("The network has been deleted.")

########NEW FILE########
__FILENAME__ = accept_images
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2014 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
imgs = pyrax.images
imgs.http_log_debug = True

print("Listing images with pending status...")
images = imgs.list(visibility="shared", member_status="pending")

if not images:
    print("No pending images found")
    exit()

for pos, image in enumerate(images):
    new_status = None
    print("[%s] - %s" % (pos, image.name))
    choice = raw_input("Would you like to accept, reject or skip? "
            "('a', 'r', or 's'): ")
    if choice == 'a':
        new_status = 'accepted'
    elif choice == 'r':
        new_status = 'rejected'

    if new_status is not None:
        print("[%s] - %s : Updating status to %s" % (pos, image.name, new_status))
        imgs.update_image_member(image.id, new_status)
        print("[%s] - %s : has been updated" % (pos, image.name))
    else:
        print("[%s] - %s : Skipping update" % (pos, image.name))

########NEW FILE########
__FILENAME__ = add_image_member
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2014 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
imgs = pyrax.images

print("You will need a valid project_id for the member you wish to add.")
images = imgs.list(visibility="private")

if len(images) == 1:
    image = images[0]
    print("Only one image available; using '%s'." % image.name)
else:
    print("Images:")
    for pos, image in enumerate(images):
        print("[%s] - %s" % (pos, image.name))
    snum = raw_input("Enter the number of the image you want to share: ")
    if not snum:
        exit()
    try:
        num = int(snum)
    except ValueError:
        print("'%s' is not a valid number." % snum)
        exit()
    if not 0 <= num < len(images):
        print("'%s' is not a valid image number." % snum)
        exit()
    image = images[num]

project_id = raw_input("Enter the project ID of the member you wish to share "
        "this image with: ")
if not project_id:
    print("No project ID entered; exiting.")
    exit()
imgs.http_log_debug = True
member = imgs.add_image_member(image, project_id)
print("The following member was added:")
print("   ID: %s" % member.id)
print("   Status: %s" % member.status)
print("   Created at: %s" % member.created_at)

########NEW FILE########
__FILENAME__ = delete_image_member
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2014 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
imgs = pyrax.images


print("You will be able to remove members from an image (that is, unshare it)")
images = imgs.list(visibility="private")

images_with_members = []
for image in images:
    members = image.list_members()
    if not members:
        continue
    images_with_members.append((image, members))

if not images_with_members:
    print("You have no images that are shared with other members.")
    exit()

member_index = 0
to_delete = []
for image, members in images_with_members:
    print("Image: %s" % image.name)
    for member in members:
        print("  [%s] - %s (%s)" % (member_index, member.id, member.status))
        to_delete.append(member)
        member_index += 1
snum = raw_input("Enter the number of the member you wish to delete: ")
if not snum:
    exit()
try:
    num = int(snum)
except ValueError:
    print("'%s' is not a valid number." % snum)
    exit()
if not 0 <= num < member_index:
    print("'%s' is not a valid member number." % snum)
    exit()
member = to_delete[num]

imgs.http_log_debug = True
res = imgs.delete_image_member(member.image_id, member.id)

print("RES", res)
# print("The following member was added:")
# print("   ID: %s" % member.id)
# print("   Status: %s" % member.status)
# print("   Created at: %s" % member.created_at)

########NEW FILE########
__FILENAME__ = export_task
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2014 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
imgs = pyrax.images
cf = pyrax.cloudfiles

print("You will need to select an image to export, and a Container into which "
        "the exported image will be placed.")
images = imgs.list(visibility="private")
print()
print("Select an image to export:")
for pos, image in enumerate(images):
    print("[%s] %s" % (pos, image.name))
snum = raw_input("Enter the number of the image you want to share: ")
if not snum:
    exit()
try:
    num = int(snum)
except ValueError:
    print("'%s' is not a valid number." % snum)
    exit()
if not 0 <= num < len(images):
    print("'%s' is not a valid image number." % snum)
    exit()
image = images[num]

conts = cf.list()
print()
print("Select the target container to place the exported image:")
for pos, cont in enumerate(conts):
    print("[%s] %s" % (pos, cont.name))
snum = raw_input("Enter the number of the container: ")
if not snum:
    exit()
try:
    num = int(snum)
except ValueError:
    print("'%s' is not a valid number." % snum)
    exit()
if not 0 <= num < len(conts):
    print("'%s' is not a valid container number." % snum)
    exit()
cont = conts[num]

task = imgs.export_task(image, cont)
print("Task ID=%s" % task.id)
print()
answer = raw_input("Do you want to track the task until completion? This may "
        "take several minutes. [y/N]: ")
if answer and answer[0].lower() == "y":
    pyrax.utils.wait_until(task, "status", ["success", "failure"],
            verbose=True, interval=30)

########NEW FILE########
__FILENAME__ = import_task
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2014 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
imgs = pyrax.images
cf = pyrax.cloudfiles

print("You will need an image file stored in a Cloud Files container.")
conts = cf.list()
print()
print("Select the container containing the image to import:")
for pos, cont in enumerate(conts):
    print("[%s] %s" % (pos, cont.name))
snum = raw_input("Enter the number of the container: ")
if not snum:
    exit()
try:
    num = int(snum)
except ValueError:
    print("'%s' is not a valid number." % snum)
    exit()
if not 0 <= num < len(conts):
    print("'%s' is not a valid container number." % snum)
    exit()
cont = conts[num]

print()
print("Select the image object:")
objs = cont.get_objects()
for pos, obj in enumerate(objs):
    print("[%s] %s" % (pos, obj.name))
snum = raw_input("Enter the number of the image object: ")
if not snum:
    exit()
try:
    num = int(snum)
except ValueError:
    print("'%s' is not a valid number." % snum)
    exit()
if not 0 <= num < len(conts):
    print("'%s' is not a valid object number." % snum)
    exit()
obj = objs[num]

fmt = raw_input("Enter the format of the image [VHD]: ")
fmt = fmt or "VHD"
base_name = os.path.splitext(os.path.basename(obj.name))[0]
obj_name = raw_input("Enter a name for the imported image ['%s']: " % base_name)
obj_name = obj_name or base_name

task = imgs.import_task(obj, cont, img_format=fmt, img_name=obj_name)
print("Task ID=%s" % task.id)
print()
answer = raw_input("Do you want to track the task until completion? This may "
        "take several minutes. [y/N]: ")
if answer and answer[0].lower() == "y":
    pyrax.utils.wait_until(task, "status", ["success", "failure"],
            verbose=True, interval=30)
    print()
    if task.status == "success":
        print("Success!")
        print("Your new image:")
        new_img = imgs.find(name=obj_name)
        print(" ID: %s" % new_img.id)
        print(" Name: %s" % new_img.name)
        print(" Status: %s" % new_img.status)
        print(" Size: %s" % new_img.size)
        print(" Tags: %s" % new_img.tags)
    else:
        print("Image import failed!")
        print("Reason: %s" % task.message)

########NEW FILE########
__FILENAME__ = list_images
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2014 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
imgs = pyrax.images

images = imgs.list()

if not images:
    print("No images exist.")
    exit()
print("There are %s images:" % len(images))
for image in images:
    print("  (%s) %s (ID=%s)" % (image.visibility, image.name, image.id))

########NEW FILE########
__FILENAME__ = list_images_filtered
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2014 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
imgs = pyrax.images

print("Filtering on visibility='private'")
images = imgs.list(visibility="private")
if not images:
    print("No images exist.")
    exit()
print("There are %s images with visibility='private':" % len(images))
for image in images:
    print("  (%s) %s (ID=%s)" % (image.visibility, image.name, image.id))

print("-" * 66)
print("Filtering on name='Ubuntu 13.10 (Saucy Salamander)'")
images = imgs.list(name="Ubuntu 13.10 (Saucy Salamander)")
if not images:
    print("No images exist.")
    exit()
print("There are %s images with name=Ubuntu 13.10 (Saucy Salamander):" %
        len(images))
for image in images:
    print("  (%s) %s (ID=%s)" % (image.visibility, image.name, image.id))

print("-" * 66)
print("Filtering on size_min > 1000000000")
images = imgs.list(size_min=1000000000)
if not images:
    print("No images exist.")
    exit()
print("There are %s images with size_min > 1000000000:" % len(images))
for image in images:
    print("  (%s) %s (ID=%s)" % (image.size, image.name, image.id))

########NEW FILE########
__FILENAME__ = list_image_members
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2014 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
imgs = pyrax.images

print("This will loop through all your private images and list the members for "
        "each.")
images = imgs.list(visibility="private")
if not images:
    print("No images exist.")
    exit()
for image in images:
    members = imgs.list_image_members(image)
    if not members:
        print("Image %s: no members" % image.id)
    else:
        print("Image %s:" % image.id)
        for member in members:
            print("  %s (%s)" % (member.id, member.status))

########NEW FILE########
__FILENAME__ = list_tasks
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2014 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
imgs = pyrax.images

print("This will loop through all current tasks.")
tasks = imgs.list_tasks()
for task in tasks:
    print()
    print("Task ID=%s" % task.id)
    print("  Type: %s" % task.type)
    print("  Status: %s" % task.status)
    print("  Message: %s" % task.message)
    print("  Created: %s" % task.created_at)
    print("  Expires: %s" % task.expires_at)

########NEW FILE########
__FILENAME__ = claim_messages
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2013 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax
import pyrax.exceptions as exc

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
pq = pyrax.queues

queues = pq.list()
if not queues:
    print("There are no queues to post to. Please create one before proceeding.")
    exit()

if len(queues) == 1:
    queue = queues[0]
    print("Only one queue available; using '%s'." % queue.name)
else:
    print("Queues:")
    for pos, queue in enumerate(queues):
        print("%s - %s" % (pos, queue.name))
    snum = raw_input("Enter the number of the queue you wish to post a message "
            "to: ")
    if not snum:
        exit()
    try:
        num = int(snum)
    except ValueError:
        print("'%s' is not a valid number." % snum)
        exit()
    if not 0 <= num < len(queues):
        print("'%s' is not a valid queue number." % snum)
        exit()
    queue = queues[num]

sttl = raw_input("Enter a TTL for the claim: ")
if not sttl:
    print("A TTL value is required.")
    exit()
else:
    try:
        ttl = int(sttl)
        if not 60 <= ttl <= 43200:
            old_ttl = ttl
            ttl = max(min(ttl, 43200), 60)
            print("TTL values must be between 60 and 43200 seconds; changing "
                "it to '%s'." % ttl)
    except ValueError:
        print("'%s' is not a valid number." % sttl)
        exit()

sgrace = raw_input("Enter a grace period for the claim: ")
if not sgrace:
    print("A value for the grace period is required.")
    exit()
else:
    try:
        grace = int(sgrace)
        if not 60 <= grace <= 43200:
            old_grace = grace
            grace = max(min(grace, 43200), 60)
            print("Grace values must be between 60 and 43200 seconds; changing "
                "it to '%s'." % grace)
    except ValueError:
        print("'%s' is not a valid number." % sgrace)
        exit()

scount = raw_input("Enter the number of messages to claim (max=20), or press "
        "Enter for the default of 10: ")
if not scount:
    count = None
else:
    try:
        count = int(scount)
    except ValueError:
        print("'%s' is not a valid number." % scount)
        exit()

claim = pq.claim_messages(queue, ttl, grace, count=count)
if not claim:
    print("There were no messages available to claim.")
    exit()
num_msgs = len(claim.messages)
print()
print("You have successfully claimed %s messages." % num_msgs)
print("Claim ID:", claim.id)
for msg in claim.messages:
    print("Age:", msg.age)
    print("Body:", msg.body)
    print()

########NEW FILE########
__FILENAME__ = create_queue
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2013 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax
import pyrax.exceptions as exc

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
pq = pyrax.queues

name = raw_input("Enter the name for your queue: ")
if not name:
    exit()

try:
    queue = pq.create(name)
    msg = "The queue '%s' has been created." % queue.name
except exc.DuplicateQueue:
    msg = "A queue with the name '%s' already exists." % name
print(msg)

########NEW FILE########
__FILENAME__ = delete_message
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2013 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax
import pyrax.exceptions as exc

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
pq = pyrax.queues

queues = pq.list()
if not queues:
    print("There are no queues to post to. Please create one before proceeding.")
    exit()

if len(queues) == 1:
    queue = queues[0]
    print("Only one queue available; using '%s'." % queue.name)
else:
    print("Queues:")
    for pos, queue in enumerate(queues):
        print("%s - %s" % (pos, queue.name))
    snum = raw_input("Enter the number of the queue you wish to list messages "
            "from: ")
    if not snum:
        exit()
    try:
        num = int(snum)
    except ValueError:
        print("'%s' is not a valid number." % snum)
        exit()
    if not 0 <= num < len(queues):
        print("'%s' is not a valid queue number." % snum)
        exit()
    queue = queues[num]
echo = claimed = True
msgs = pq.list_messages(queue, echo=echo, include_claimed=claimed)
if not msgs:
    print("There are no messages available in this queue.")
    exit()
for pos, msg in enumerate(msgs):
    msg.get()
    print(pos, "- ID:", msg.id, msg.claim_id, "Body='%s'" % msg.body[:80])
snum = raw_input("Enter the number of the message you wish to delete: ")
if not snum:
    print("No message selected; exiting.")
    exit()
try:
    num = int(snum)
except ValueError:
    print("'%s' is not a valid number." % snum)
    exit()
if not 0 <= num < len(msgs):
    print("'%s' is not a valid message number." % snum)
    exit()
msg_to_delete = msgs[num]
msg_to_delete.delete()
print()
print("The message has been deleted.")

########NEW FILE########
__FILENAME__ = delete_messages
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2013 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax
import pyrax.exceptions as exc

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
pq = pyrax.queues

queues = pq.list()
if not queues:
    print("There are no queues to post to. Please create one before proceeding.")
    exit()

if len(queues) == 1:
    queue = queues[0]
    print("Only one queue available; using '%s'." % queue.name)
else:
    print("Queues:")
    for pos, queue in enumerate(queues):
        print("%s - %s" % (pos, queue.name))
    snum = raw_input("Enter the number of the queue you wish to list messages "
            "from: ")
    if not snum:
        exit()
    try:
        num = int(snum)
    except ValueError:
        print("'%s' is not a valid number." % snum)
        exit()
    if not 0 <= num < len(queues):
        print("'%s' is not a valid queue number." % snum)
        exit()
    queue = queues[num]
echo = claimed = True
msgs = pq.list_messages(queue, echo=echo, include_claimed=claimed)
if not msgs:
    print("There are no messages available in this queue.")
    exit()
for pos, msg in enumerate(msgs):
    msg.get()
    print(pos, "- ID:", msg.id, msg.claim_id, "Body='%s'" % msg.body[:80])
snums = raw_input("Enter one or more numbers of the messages you wish to "
        "delete, separated by spaces: ")
if not snums:
    print("No messages selected; exiting.")
    exit()
nums = [int(num) for num in snums.split()]
ids = [msg.id for msg in msgs if msgs.index(msg) in nums]
if not ids:
    print("No messages match your selections; exiting.")
    exit()
print("DEL", pq.delete_messages_by_ids(queue, ids))
del_msgs = [msg for msg in msgs if msg.id in ids]

print()
print("The following messages were deleted:")
for del_msg in del_msgs:
    print(del_msg.id, "Body='%s'" % del_msg.body)

########NEW FILE########
__FILENAME__ = delete_queue
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2013 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax
import pyrax.exceptions as exc

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
pq = pyrax.queues

queues = pq.list()
if not queues:
    print("There are no queues to delete.")
    exit()

print("Queues:")
for pos, queue in enumerate(queues):
    print("%s - %s" % (pos, queue.name))
snum = raw_input("Enter the number of the queue to delete: ")
if not snum:
    exit()
try:
    num = int(snum)
except ValueError:
    print("'%s' is not a valid number." % snum)
    exit()
if not 0 <= num < len(queues):
    print("'%s' is not a valid queue number." % snum)
    exit()
pq.delete(queues[num])
print("Queue '%s' has been deleted." % queue.name)

########NEW FILE########
__FILENAME__ = list_claims
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2013 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax
import pyrax.exceptions as exc


print("Sorry, this hasn't been implemented yet.")
exit()

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
pq = pyrax.queues

queues = pq.list()
if not queues:
    print("There are no queues to post to. Please create one before proceeding.")
    exit()

if len(queues) == 1:
    queue = queues[0]
    print("Only one queue available; using '%s'." % queue.name)
else:
    print("Queues:")
    for pos, queue in enumerate(queues):
        print("%s - %s" % (pos, queue.name))
    snum = raw_input("Enter the number of the queue you wish to list messages "
            "from: ")
    if not snum:
        exit()
    try:
        num = int(snum)
    except ValueError:
        print("'%s' is not a valid number." % snum)
        exit()
    if not 0 <= num < len(queues):
        print("'%s' is not a valid queue number." % snum)
        exit()
    queue = queues[num]
claims = pq.list_claims(queue)
if not claims:
    print("There are no claims available in this queue.")
    exit()
for claim in claims:
    print("ID:", claim.id)
    print(claim)
    print()

########NEW FILE########
__FILENAME__ = list_messages
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2013 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax
import pyrax.exceptions as exc

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
pq = pyrax.queues

queues = pq.list()
if not queues:
    print("There are no queues to post to. Please create one before proceeding.")
    exit()

if len(queues) == 1:
    queue = queues[0]
    print("Only one queue available; using '%s'." % queue.name)
else:
    print("Queues:")
    for pos, queue in enumerate(queues):
        print("%s - %s" % (pos, queue.name))
    snum = raw_input("Enter the number of the queue you wish to list messages "
            "from: ")
    if not snum:
        exit()
    try:
        num = int(snum)
    except ValueError:
        print("'%s' is not a valid number." % snum)
        exit()
    if not 0 <= num < len(queues):
        print("'%s' is not a valid queue number." % snum)
        exit()
    queue = queues[num]
echo = claimed = False
secho = raw_input("Do you want to include your own messages? [y/N]")
if secho:
    echo = secho in ("Yy")
sclaimed = raw_input("Do you want to include claimed messages? [y/N]")
if sclaimed:
    claimed = sclaimed in ("Yy")

msgs = pq.list_messages(queue, echo=echo, include_claimed=claimed)
if not msgs:
    print("There are no messages available in this queue.")
    exit()
for msg in msgs:
    print("ID:", msg.id)
    print("Age:", msg.age)
    print("TTL:", msg.ttl)
    print("Claim ID:", msg.claim_id)
    print("Body:", msg.body)
    print()

########NEW FILE########
__FILENAME__ = list_queues
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2013 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
pq = pyrax.queues

queues = pq.list()
if not queues:
    print("No queues have been created.")
    exit()
num_queues = len(queues)
if num_queues == 1:
    print("There is one queue defined:")
else:
    print("There are %s queueis defined:" % num_queues)
for queue in queues:
    print("  %s" % queue.name)

########NEW FILE########
__FILENAME__ = post_message
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright 2013 Rackspace

# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

from __future__ import print_function

import os
import pyrax
import pyrax.exceptions as exc

pyrax.set_setting("identity_type", "rackspace")
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")
pyrax.set_credential_file(creds_file)
pq = pyrax.queues

queues = pq.list()
if not queues:
    print("There are no queues to post to. Please create one before proceeding.")
    exit()

if len(queues) == 1:
    queue = queues[0]
    print("Only one queue available; using '%s'." % queue.nam)
else:
    print("Queues:")
    for pos, queue in enumerate(queues):
        print("%s - %s" % (pos, queue.name))
    snum = raw_input("Enter the number of the queue you wish to post a message "
            "to: ")
    if not snum:
        exit()
    try:
        num = int(snum)
    except ValueError:
        print("'%s' is not a valid number." % snu)
        exit()
    if not 0 <= num < len(queues):
        print("'%s' is not a valid queue number." % snu)
        exit()
    queue = queues[num]
msg = raw_input("Enter the message to post: ")
sttl = raw_input("Enter a TTL for the message, or just press Enter for the "
        "default of 14 days: ")
if not sttl:
    ttl = None
else:
    try:
        ttl = int(sttl)
    except ValueError:
        print("'%s' is not a valid number." % stt)
        exit()
pq.post_message(queue, msg, ttl=ttl)
print("Your message has been posted.")

########NEW FILE########
__FILENAME__ = smoketest
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from __future__ import print_function

try:
    import eventlet
    eventlet.patcher.monkey_patch(all=False, socket=True, time=True,
            thread=True)
except ImportError:
    pass

import argparse
import os
import sys
import time
import unittest

import pyrax
import pyrax.exceptions as exc


class SmokeTester(object):
    def __init__(self, region):
        self.failures = []
        self.cleanup_items = []
        self.auth(region)
        self.cs = pyrax.cloudservers
        self.cf = pyrax.cloudfiles
        self.cbs = pyrax.cloud_blockstorage
        self.cdb = pyrax.cloud_databases
        self.clb = pyrax.cloud_loadbalancers
        self.dns = pyrax.cloud_dns
        self.cnw = pyrax.cloud_networks
        self.cmn = pyrax.cloud_monitoring
        self.au = pyrax.autoscale
        self.pq = pyrax.queues
        self.services = ({"service": self.cs, "name": "Cloud Servers"},
                {"service": self.cf, "name": "Cloud Files"},
                {"service": self.cbs, "name": "Cloud Block Storage"},
                {"service": self.cdb, "name": "Cloud Databases"},
                {"service": self.clb, "name": "Cloud Load Balancers"},
                {"service": self.dns, "name": "Cloud DNS"},
                {"service": self.cnw, "name": "Cloud Networks"},
                {"service": self.cmn, "name": "Cloud Monitoring"},
                {"service": self.au, "name": "Auto Scale"},
                {"service": self.pq, "name": "Cloud Queues"},
                )

    def auth(self, region):
        # Make sure that keyring has been set up with the account credentials.
        print("Authenticating for region '%s'..." % region)
        try:
            pyrax.keyring_auth(region=region)
            print("Success!")
        except Exception as e:
            print("FAIL!", e)
            self.failures.append("AUTHENTICATION")
        print()

    def check_services(self):
        for service in self.services:
            print("SERVICE:", service["name"], end=' ')
            if service["service"]:
                print("Success!")
            else:
                print("FAIL!")
                self.failures.append("Service=%s" % service["name"])
        print()

    def run_tests(self):
        if self.cs:
            print("Running 'compute' tests...")
            self.cs_list_flavors()
            self.cs_list_images()
            self.cs_create_server()
            self.cs_reboot_server()
            self.cs_list_servers()

        if self.cnw:
            print("Running 'network' tests...")
            try:
                self.cnw_create_network()
                self.cnw_list_networks()
            except exc.NotFound:
                # Networking not supported
                print(" - Networking not supported.")
            except exc.NetworkCountExceeded:
                print(" - Too many networks already exist.")

        if self.cdb:
            print("Running 'database' tests...")
            self.cdb_list_flavors()
            self.cdb_create_instance()
            self.cdb_create_db()
            self.cdb_create_user()

        if self.cf:
            print("Running 'object_store' tests...")
            self.cf_create_container()
            self.cf_list_containers()
            self.cf_make_container_public()
            self.cf_make_container_private()
            self.cf_upload_file()

        if self.clb:
            print("Running 'load_balancer' tests...")
            self.lb_list()
            self.lb_create()

        if self.dns:
            print("Running 'DNS' tests...")
            self.dns_list()
            self.dns_create_domain()
            self.dns_create_record()

        if self.cmn:
            if not self.smoke_server:
                print("Server not available; skipping Monitoring tests.")
                return
            self.cmn_create_entity()
            self.cmn_list_check_types()
            self.cmn_list_monitoring_zones()
            self.cmn_create_check()
            self.cmn_create_notification()
            self.cmn_create_notification_plan()
            self.cmn_create_alarm()


    # Specific tests start here ##
    def cs_list_flavors(self):
        print("Listing Flavors:", end=' ')
        self.cs_flavors = self.cs.list_flavors()
        if self.cs_flavors:
            print()
            for flavor in self.cs_flavors:
                print(" -", flavor)
        else:
            print("FAIL!")
            self.failures.append("FLAVORS")
        print()

    def cs_list_images(self):
        print("Listing Images:", end=' ')
        self.cs_images = self.cs.list_base_images()
        if self.cs_images:
            print()
            for image in self.cs_images:
                print(" -", image)
        else:
            print("FAIL!")
            self.failures.append("IMAGES")
        print()

    def cnw_create_network(self):
        print("Creating network...")
        new_network_name = "SMOKETEST_NW"
        new_network_cidr = "192.168.0.0/24"
        print("CREATE NETWORK:", end=' ')
        self.smoke_network = self.cnw.create(new_network_name,
                cidr=new_network_cidr)
        self.cleanup_items.append(self.smoke_network)
        if self.smoke_network:
            print("Success!")
        else:
            print("FAIL!")
            self.failures.append("CREATE NETWORK")
        print()

    def cnw_list_networks(self):
        print("Listing networks...")
        try:
            networks = self.cnw.list()
        except exc.NotFound:
            # Many non-rax system do no support networking.
            print("Networking not available")
            return
        for network in networks:
            print(" - %s: %s (%s)" % (network.id, network.name, network.cidr))
        if not networks:
            self.failures.append("LIST NETWORKS")
        print()

    def cs_create_server(self):
        print("Creating server...")
        img = [img for img in self.cs_images
                if "12.04" in img.name][0]
        flavor = self.cs_flavors[0]
        self.smoke_server = self.cs.servers.create("SMOKETEST_SERVER",
                img.id, flavor.id)
        self.cleanup_items.append(self.smoke_server)
        self.smoke_server = pyrax.utils.wait_until(self.smoke_server, "status",
                ["ACTIVE", "ERROR"], interval=10, verbose=True,
                verbose_atts="progress")
        if self.smoke_server.status == "ERROR":
            print("Server creation failed!")
            self.failures.append("SERVER CREATION")
        else:
            print("Success!")
        print()

    def cs_reboot_server(self):
        print("Rebooting server...")
        self.smoke_server.reboot()
        self.smoke_server = pyrax.utils.wait_until(self.smoke_server, "status",
                ["ACTIVE", "ERROR"], interval=10, verbose=True,
                verbose_atts="progress")
        if self.smoke_server.status == "ERROR":
            print("Server reboot failed!")
            self.failures.append("SERVER REBOOT")
        else:
            print("Success!")
        print()

    def cs_list_servers(self):
        print("Listing servers...")
        servers = self.cs.servers.list()
        if not servers:
            print("Server listing failed!")
            self.failures.append("SERVER LISTING")
        else:
            for server in servers:
                print(" -", server.id, server.name)
        print()

    def cdb_list_flavors(self):
        print("Listing Database Flavors:", end=' ')
        try:
            self.cdb_flavors = self.cdb.list_flavors()
        except Exception as e:
            self.cdb_flavors = None
        if self.cdb_flavors:
            print()
            for flavor in self.cdb_flavors:
                print(" -", flavor)
        else:
            print("FAIL!")
            self.failures.append("DB FLAVORS")
        print()

    def cdb_create_instance(self):
        if not self.cdb_flavors:
            # Skip this test
            print("Skipping database instance creation...")
            self.smoke_instance = None
            return
        print("Creating database instance...")
        self.smoke_instance = self.cdb.create("SMOKETEST_DB_INSTANCE",
                flavor=self.cdb_flavors[0], volume=1)
        self.cleanup_items.append(self.smoke_instance)
        self.smoke_instance = pyrax.utils.wait_until(self.smoke_instance,
                "status", ["ACTIVE", "ERROR"], interval=10, verbose=True,
                verbose_atts="progress")
        if self.smoke_instance.status == "ACTIVE":
            print("Success!")
        else:
            print("FAIL!")
            self.failures.append("DB INSTANCE CREATION")
        print()

    def cdb_create_db(self):
        if not self.smoke_instance:
            # Skip this test
            print("Skipping database creation...")
            return
        print("Creating database...")
        self.smoke_db = self.smoke_instance.create_database("SMOKETEST_DB")
        self.cleanup_items.append(self.smoke_db)
        dbs = self.smoke_instance.list_databases()
        if self.smoke_db in dbs:
            print("Success!")
        else:
            print("FAIL!")
            self.failures.append("DB DATABASE CREATION")
        print()

    def cdb_create_user(self):
        if not self.smoke_instance:
            # Skip this test
            print("Skipping database user creation...")
            return
        print("Creating database user...")
        self.smoke_user = self.smoke_instance.create_user("SMOKETEST_USER",
                "SMOKETEST_PW", database_names=[self.smoke_db])
        self.cleanup_items.append(self.smoke_user)
        users = self.smoke_instance.list_users()
        if self.smoke_user in users:
            print("Success!")
        else:
            print("FAIL!")
            self.failures.append("DB USER CREATION")
        print()

    def cf_create_container(self):
        print("Creating a Cloud Files Container...")
        self.smoke_cont = self.cf.create_container("SMOKETEST_CONTAINER")
        self.cleanup_items.append(self.smoke_cont)
        if self.smoke_cont:
            print("Success!")
        else:
            print("FAIL!")
            self.failures.append("CONTAINER CREATION")
        print()

    def cf_list_containers(self):
        print("Listing the Cloud Files Containers...")
        conts = self.cf.get_all_containers()
        if conts:
            for cont in conts:
                print("%s - %s files, %s bytes" % (cont.name,
                        cont.object_count, cont.total_bytes))
        else:
            print("FAIL!")
            self.failures.append("CONTAINER LISTING")
        print()

    def cf_make_container_public(self):
        print("Publishing the Cloud Files Container to CDN...")
        self.smoke_cont.make_public()
        uri = self.smoke_cont.cdn_uri
        if uri:
            print("Success!")
        else:
            print("FAIL!")
            self.failures.append("PUBLISHING CDN")
        print()

    def cf_make_container_private(self):
        print("Removing the Cloud Files Container from CDN...")
        try:
            self.smoke_cont.make_private()
            print("Success!")
        except Exception as e:
            print("FAIL!")
            self.failures.append("UNPUBLISHING CDN")
        print()

    def cf_upload_file(self):
        print("Uploading a Cloud Files object...")
        cont = self.smoke_cont
        text = pyrax.utils.random_unicode(1024)
        obj = cont.store_object("SMOKETEST_OBJECT", text)
        # Make sure it is deleted before the container
        self.cleanup_items.insert(0, obj)
        all_objs = cont.get_object_names()
        if obj.name in all_objs:
            print("Success!")
        else:
            print("FAIL!")
            self.failures.append("UPLOAD FILE")
        print()

    def lb_list(self):
        print("Listing Load Balancers...")
        lbs = self.clb.list()
        if not lbs:
            print(" - No load balancers to list!")
        else:
            for lb in lbs:
                print(" -", lb.name)

    def lb_create(self):
        print("Creating a Load Balancer...")
        node = self.clb.Node(address="10.177.1.1", port=80, condition="ENABLED")
        vip = self.clb.VirtualIP(type="PUBLIC")
        lb = self.clb.create("SMOKETEST_LB", port=80, protocol="HTTP",
                nodes=[node], virtual_ips=[vip])
        self.cleanup_items.append(lb)
        pyrax.utils.wait_until(lb, "status", ["ACTIVE", "ERROR"], interval=10,
                verbose=True)
        if lb:
            print("Success!")
        else:
            print("FAIL!")
            self.failures.append("LOAD_BALANCERS")

    def dns_list(self):
        print("Listing DNS Domains...")
        doms = self.dns.list()
        if not doms:
            print(" - No domains to list!")
        else:
            for dns in doms:
                print(" -", dns.name)

    def dns_create_domain(self):
        print("Creating a DNS Domain...")
        domain_name = "SMOKETEST.example.edu"
        try:
            dom = self.dns.create(name=domain_name,
                    emailAddress="sample@example.edu", ttl=900,
                    comment="SMOKETEST sample domain")
            print("Success!")
            self.cleanup_items.append(dom)
        except exc.DomainCreationFailed:
            print("FAIL!")
            self.failures.append("DNS DOMAIN CREATION")

    def dns_create_record(self):
        print("Creating a DNS Record...")
        domain_name = "SMOKETEST.example.edu"
        try:
            dom = self.dns.find(name=domain_name)
        except exc.NotFound:
            print("Smoketest domain not found; skipping record test.")
            self.failures.append("DNS RECORD CREATION")
            return
        a_rec = {"type": "A",
                "name": domain_name,
                "data": "1.2.3.4",
                "ttl": 6000}
        try:
            recs = dom.add_records(a_rec)
            print("Success!")
            # No need to cleanup, since domain deletion also deletes the recs.
            # self.cleanup_items.extend(recs)
        except exc.DomainRecordAdditionFailed:
            print("FAIL!")
            self.failures.append("DNS RECORD CREATION")

    def cmn_list_check_types(self):
        print("Listing Monitoring Check Types...")
        cts = self.cmn.list_check_types()
        for ct in cts:
            print(" -", ct.id, ct.type)
        print()

    def cmn_list_monitoring_zones(self):
        print("Listing Monitoring Zones...")
        zones = self.cmn.list_monitoring_zones()
        for zone in zones:
            print(" -", zone.id, zone.name)
        print()

    def cmn_create_entity(self):
        print("Creating a Monitoring Entity...")
        srv = self.smoke_server
        ip = srv.networks["public"][0]
        try:
            self.smoke_entity = self.cmn.create_entity(name="SMOKETEST_entity",
                    ip_addresses={"main": ip})
            self.cleanup_items.append(self.smoke_entity)
            print("Success!")
        except Exception:
            print("FAIL!")
            self.smoke_entity = None
            self.failures.append("MONITORING CREATE ENTITY")
        print()

    def cmn_create_check(self):
        print("Creating a Monitoring Check...")
        ent = self.smoke_entity
        alias = ent.ip_addresses.keys()[0]
        try:
            self.smoke_check = self.cmn.create_check(ent,
                    label="SMOKETEST_check", check_type="remote.ping",
                    details={"count": 5}, monitoring_zones_poll=["mzdfw"],
                    period=60, timeout=20, target_alias=alias)
            print("Success!")
            self.cleanup_items.append(self.smoke_check)
        except Exception:
            print("FAIL!")
            self.smoke_check = None
            self.failures.append("MONITORING CREATE CHECK")
        print()

    def cmn_create_notification(self):
        print("Creating a Monitoring Notification...")
        email = "smoketest@example.com"
        try:
            self.smoke_notification = self.cmn.create_notification("email",
                    label="smoketest", details={"address": email})
            print("Success!")
            self.cleanup_items.append(self.smoke_notification)
        except Exception:
            print("FAIL!")
            self.smoke_notification = None
            self.failures.append("MONITORING CREATE NOTIFICATION")
        print()

    def cmn_create_notification_plan(self):
        if not self.smoke_notification:
            print("No monitoring notification found; skipping notification "
                    "creation...")
            return
        print("Creating a Monitoring Notification Plan...")
        try:
            self.smoke_notification_plan = self.cmn.create_notification_plan(
                    label="smoketest plan", ok_state=self.smoke_notification)
            print("Success!")
            self.cleanup_items.append(self.smoke_notification_plan)
        except Exception as e:
            print("FAIL!", e)
            self.smoke_notification_plan = None
            self.failures.append("MONITORING CREATE NOTIFICATION PLAN")
        print()

    def cmn_create_alarm(self):
        if not self.smoke_notification_plan:
            print("No monitoring plan found; skipping alarm creation...")
            return
        print("Creating a Monitoring Alarm...")
        try:
            self.smoke_alarm = self.cmn.create_alarm(self.smoke_entity,
                    self.smoke_check, self.smoke_notification_plan,
                    label="smoke alarm")
            print("Success!")
            self.cleanup_items.append(self.smoke_alarm)
        except Exception:
            print("FAIL!")
            self.failures.append("MONITORING CREATE ALARM")
        print()


    def cleanup(self):
        print("Cleaning up...")
        for item in self.cleanup_items:
            try:
                item.delete()
                print(" - Deleting:", end=' ')
                try:
                    print(item.name)
                except AttributeError:
                    print(item)
            except exc.NotFound:
                # Some items are deleted along with others (e.g., DNS records
                # when a domain is deleted), so don't complain.
                pass
            except Exception as e:
                print("Could not delete '%s': %s" % (item, e))



if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Run the smoke tests!")
    parser.add_argument("--regions", "-r", action="append",
            help="""Regions to run tests against. Can be specified multiple
            times. If not specified, the default of pyrax.regions will be
            used.""")
    parser.add_argument("--env", "-e", help="""Configuration environment to
            use for the test. If not specified, the `default` environment is
            used.""")
    args = parser.parse_args()
    regions = args.regions
    if not regions:
        pyrax.keyring_auth()
        regions = pyrax.regions
    env = args.env
    if env:
        pyrax.set_environment(env)

    start = time.time()
    pyrax.keyring_auth()
    for region in regions:
        print()
        print("=" * 77)
        print("Starting test for region: %s" % region)
        print("=" * 77)
        smoke_tester = SmokeTester(region)
        try:
            smoke_tester.run_tests()

        finally:
            smoke_tester.cleanup()

        print()
        print("=" * 88)
        if smoke_tester.failures:
            print("The following tests failed:")
            for failure in smoke_tester.failures:
                print(" -", failure)
        else:
            print("All tests passed!")
    end = time.time()
    print()
    print("Running the smoketests took %6.1f seconds." % (end - start))
    print()

########NEW FILE########
__FILENAME__ = test_module
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import unittest

import pyrax


# This file needs to contain the actual credentials for a
# valid Rackspace Cloud account.
creds_file = os.path.expanduser("~/.rackspace_cloud_credentials")


class TestCase(unittest.TestCase):
    def setUp(self):
        pyrax.set_credential_file(creds_file)

    def tearDown(self):
        pyrax.clear_credentials()

    def test_cloudservers_images(self):
        imgs = pyrax.cloudservers.images.list()
        self.assert_(isinstance(imgs, list))

    def test_cloudfiles_base_container(self):
        conts = pyrax.cloudfiles.get_all_containers()
        self.assert_(isinstance(conts, list))

    def test_cloud_loadbalancers(self):
        lbs = pyrax.cloud_loadbalancers.list()
        self.assert_(isinstance(lbs, list))

    def test_cloud_db(self):
        flavors = pyrax.cloud_databases.list_flavors()
        self.assert_(isinstance(flavors, list))


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = base_test
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import json
import time
import unittest


TIMING_FILE = ".testtimes.json"


class BaseTest(unittest.TestCase):
    def __init__(self, *args, **kwargs):
        super(BaseTest, self).__init__(*args, **kwargs)
        self.timing = False
        # Create the output file if it doesn't exist
        with open(TIMING_FILE, "a") as jj:
            pass

    def setUp(self):
        if self.timing:
            self.begun = time.time()
        super(BaseTest, self).setUp()

    def tearDown(self):
        if self.timing:
            elapsed = time.time() - self.begun
            with open(TIMING_FILE, "r") as jj:
                try:
                    times = json.load(jj)
                except ValueError:
                    times = []
                times.append((elapsed, self._testMethodName))
            with open(TIMING_FILE, "w") as jj:
                json.dump(times, jj)
        super(BaseTest, self).tearDown()

########NEW FILE########
__FILENAME__ = test_autoscale
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import random
import unittest

from mock import patch
from mock import MagicMock as Mock

import pyrax
import pyrax.autoscale
from pyrax.autoscale import AutoScaleClient
from pyrax.autoscale import AutoScalePolicy
from pyrax.autoscale import AutoScaleWebhook
from pyrax.autoscale import ScalingGroup
from pyrax.autoscale import ScalingGroupManager
import pyrax.exceptions as exc
import pyrax.utils as utils

from pyrax import fakes



class AutoscaleTest(unittest.TestCase):
    def __init__(self, *args, **kwargs):
        super(AutoscaleTest, self).__init__(*args, **kwargs)

    def setUp(self):
        self.identity = fakes.FakeIdentity()
        self.scaling_group = fakes.FakeScalingGroup(self.identity)

    def tearDown(self):
        pass

    def test_make_policies(self):
        sg = self.scaling_group
        p1 = utils.random_unicode()
        p2 = utils.random_unicode()
        sg.scalingPolicies = [{"name": p1}, {"name": p2}]
        sg._make_policies()
        self.assertEqual(len(sg.policies), 2)
        polnames = [pol.name for pol in sg.policies]
        self.assert_(p1 in polnames)
        self.assert_(p2 in polnames)

    def test_get_state(self):
        sg = self.scaling_group
        mgr = sg.manager
        mgr.get_state = Mock()
        sg.get_state()
        mgr.get_state.assert_called_once_with(sg)

    def test_pause(self):
        sg = self.scaling_group
        mgr = sg.manager
        mgr.pause = Mock()
        sg.pause()
        mgr.pause.assert_called_once_with(sg)

    def test_resume(self):
        sg = self.scaling_group
        mgr = sg.manager
        mgr.resume = Mock()
        sg.resume()
        mgr.resume.assert_called_once_with(sg)

    def test_update(self):
        sg = self.scaling_group
        mgr = sg.manager
        mgr.update = Mock()
        name = utils.random_unicode()
        cooldown = utils.random_unicode()
        min_entities = utils.random_unicode()
        max_entities = utils.random_unicode()
        metadata = utils.random_unicode()
        sg.update(name=name, cooldown=cooldown, min_entities=min_entities,
                max_entities=max_entities, metadata=metadata)
        mgr.update.assert_called_once_with(sg, name=name, cooldown=cooldown,
                min_entities=min_entities, max_entities=max_entities,
                metadata=metadata)

    def test_update_metadata(self):
        sg = self.scaling_group
        mgr = sg.manager
        mgr.update_metadata = Mock()
        metadata = utils.random_unicode()
        sg.update_metadata(metadata)
        mgr.update_metadata.assert_called_once_with(sg, metadata=metadata)

    def test_get_configuration(self):
        sg = self.scaling_group
        mgr = sg.manager
        mgr.get_configuration = Mock()
        sg.get_configuration()
        mgr.get_configuration.assert_called_once_with(sg)

    def test_get_launch_config(self):
        sg = self.scaling_group
        mgr = sg.manager
        mgr.get_launch_config = Mock()
        sg.get_launch_config()
        mgr.get_launch_config.assert_called_once_with(sg)

    def test_update_launch_config(self):
        sg = self.scaling_group
        mgr = sg.manager
        mgr.update_launch_config = Mock()
        server_name = utils.random_unicode()
        flavor = utils.random_unicode()
        image = utils.random_unicode()
        disk_config = utils.random_unicode()
        metadata = utils.random_unicode()
        personality = utils.random_unicode()
        networks = utils.random_unicode()
        load_balancers = utils.random_unicode()
        key_name = utils.random_unicode()
        sg.update_launch_config(server_name=server_name, flavor=flavor,
                image=image, disk_config=disk_config, metadata=metadata,
                personality=personality, networks=networks,
                load_balancers=load_balancers, key_name=key_name)
        mgr.update_launch_config.assert_called_once_with(sg,
                server_name=server_name, flavor=flavor, image=image,
                disk_config=disk_config, metadata=metadata,
                personality=personality, networks=networks,
                load_balancers=load_balancers, key_name=key_name)

    def test_update_launch_metadata(self):
        sg = self.scaling_group
        mgr = sg.manager
        mgr.update_launch_metadata = Mock()
        metadata = utils.random_unicode()
        sg.update_launch_metadata(metadata)
        mgr.update_launch_metadata.assert_called_once_with(sg, metadata)

    def test_add_policy(self):
        sg = self.scaling_group
        mgr = sg.manager
        name = utils.random_unicode()
        policy_type = utils.random_unicode()
        cooldown = utils.random_unicode()
        change = utils.random_unicode()
        is_percent = utils.random_unicode()
        desired_capacity = utils.random_unicode()
        args = utils.random_unicode()
        mgr.add_policy = Mock()
        sg.add_policy(name, policy_type, cooldown, change,
                is_percent=is_percent, desired_capacity=desired_capacity,
                args=args)
        mgr.add_policy.assert_called_once_with(sg, name, policy_type, cooldown,
                change=change, is_percent=is_percent,
                desired_capacity=desired_capacity, args=args)

    def test_list_policies(self):
        sg = self.scaling_group
        mgr = sg.manager
        mgr.list_policies = Mock()
        sg.list_policies()
        mgr.list_policies.assert_called_once_with(sg)

    def test_get_policy(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = utils.random_unicode()
        mgr.get_policy = Mock()
        sg.get_policy(pol)
        mgr.get_policy.assert_called_once_with(sg, pol)

    def test_update_policy(self):
        sg = self.scaling_group
        mgr = sg.manager
        policy = utils.random_unicode()
        name = utils.random_unicode()
        policy_type = utils.random_unicode()
        cooldown = utils.random_unicode()
        change = utils.random_unicode()
        desired_capacity = utils.random_unicode()
        is_percent = utils.random_unicode()
        args = utils.random_unicode()
        mgr.update_policy = Mock()
        sg.update_policy(policy, name=name, policy_type=policy_type,
                cooldown=cooldown, change=change, is_percent=is_percent,
                desired_capacity=desired_capacity, args=args)
        mgr.update_policy.assert_called_once_with(scaling_group=sg,
                policy=policy, name=name, policy_type=policy_type,
                cooldown=cooldown, change=change, is_percent=is_percent,
                desired_capacity=desired_capacity, args=args)

    def test_execute_policy(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = utils.random_unicode()
        mgr.execute_policy = Mock()
        sg.execute_policy(pol)
        mgr.execute_policy.assert_called_once_with(scaling_group=sg,
                policy=pol)

    def test_delete_policy(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = utils.random_unicode()
        mgr.delete_policy = Mock()
        sg.delete_policy(pol)
        mgr.delete_policy.assert_called_once_with(scaling_group=sg,
                policy=pol)

    def test_add_webhook(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = utils.random_unicode()
        name = utils.random_unicode()
        metadata = utils.random_unicode()
        mgr.add_webhook = Mock()
        sg.add_webhook(pol, name, metadata=metadata)
        mgr.add_webhook.assert_called_once_with(sg, pol, name,
                metadata=metadata)

    def test_list_webhooks(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = utils.random_unicode()
        mgr.list_webhooks = Mock()
        sg.list_webhooks(pol)
        mgr.list_webhooks.assert_called_once_with(sg, pol)

    def test_update_webhook(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = utils.random_unicode()
        hook = utils.random_unicode()
        name = utils.random_unicode()
        metadata = utils.random_unicode()
        mgr.update_webhook = Mock()
        sg.update_webhook(pol, hook, name=name, metadata=metadata)
        mgr.update_webhook.assert_called_once_with(scaling_group=sg, policy=pol,
                webhook=hook, name=name, metadata=metadata)

    def test_update_webhook_metadata(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = utils.random_unicode()
        hook = utils.random_unicode()
        metadata = utils.random_unicode()
        mgr.update_webhook_metadata = Mock()
        sg.update_webhook_metadata(pol, hook, metadata=metadata)
        mgr.update_webhook_metadata.assert_called_once_with(sg, pol, hook,
                metadata)

    def test_delete_webhook(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = utils.random_unicode()
        hook = utils.random_unicode()
        mgr.delete_webhook = Mock()
        sg.delete_webhook(pol, hook)
        mgr.delete_webhook.assert_called_once_with(sg, pol, hook)


    def test_policy_count(self):
        sg = self.scaling_group
        num = random.randint(1, 100)
        sg.policies = ["x"] * num
        self.assertEqual(sg.policy_count, num)

    def test_name(self):
        sg = self.scaling_group
        name = utils.random_unicode()
        newname = utils.random_unicode()
        sg.groupConfiguration = {"name": name}
        self.assertEqual(sg.name, name)
        sg.name = newname
        self.assertEqual(sg.name, newname)

    def test_cooldown(self):
        sg = self.scaling_group
        cooldown = utils.random_unicode()
        newcooldown = utils.random_unicode()
        sg.groupConfiguration = {"cooldown": cooldown}
        self.assertEqual(sg.cooldown, cooldown)
        sg.cooldown = newcooldown
        self.assertEqual(sg.cooldown, newcooldown)

    def test_metadata(self):
        sg = self.scaling_group
        metadata = utils.random_unicode()
        newmetadata = utils.random_unicode()
        sg.groupConfiguration = {"metadata": metadata}
        self.assertEqual(sg.metadata, metadata)
        sg.metadata = newmetadata
        self.assertEqual(sg.metadata, newmetadata)

    def test_min_entities(self):
        sg = self.scaling_group
        min_entities = utils.random_unicode()
        newmin_entities = utils.random_unicode()
        sg.groupConfiguration = {"minEntities": min_entities}
        self.assertEqual(sg.min_entities, min_entities)
        sg.min_entities = newmin_entities
        self.assertEqual(sg.min_entities, newmin_entities)

    def test_max_entities(self):
        sg = self.scaling_group
        max_entities = utils.random_unicode()
        newmax_entities = utils.random_unicode()
        sg.groupConfiguration = {"maxEntities": max_entities}
        self.assertEqual(sg.max_entities, max_entities)
        sg.max_entities = newmax_entities
        self.assertEqual(sg.max_entities, newmax_entities)

    def test_mgr_get_state(self):
        sg = self.scaling_group
        mgr = sg.manager
        id1 = utils.random_unicode()
        id2 = utils.random_unicode()
        ac = utils.random_unicode()
        dc = utils.random_unicode()
        pc = utils.random_unicode()
        paused = utils.random_unicode()
        statedict = {"group": {
                "active": [{"id": id1}, {"id": id2}],
                "activeCapacity": ac,
                "desiredCapacity": dc,
                "pendingCapacity": pc,
                "paused": paused,
                }}
        expected = {
                "active": [id1, id2],
                "active_capacity": ac,
                "desired_capacity": dc,
                "pending_capacity": pc,
                "paused": paused,
                }
        mgr.api.method_get = Mock(return_value=(None, statedict))
        ret = mgr.get_state(sg)
        self.assertEqual(ret, expected)

    def test_mgr_pause(self):
        sg = self.scaling_group
        mgr = sg.manager
        uri = "/%s/%s/pause" % (mgr.uri_base, sg.id)
        mgr.api.method_post = Mock(return_value=(None, None))
        mgr.pause(sg)
        mgr.api.method_post.assert_called_once_with(uri)

    def test_mgr_resume(self):
        sg = self.scaling_group
        mgr = sg.manager
        uri = "/%s/%s/resume" % (mgr.uri_base, sg.id)
        mgr.api.method_post = Mock(return_value=(None, None))
        mgr.resume(sg)
        mgr.api.method_post.assert_called_once_with(uri)

    def test_mgr_get_configuration(self):
        sg = self.scaling_group
        mgr = sg.manager
        uri = "/%s/%s/config" % (mgr.uri_base, sg.id)
        conf = utils.random_unicode()
        resp_body = {"groupConfiguration": conf}
        mgr.api.method_get = Mock(return_value=(None, resp_body))
        ret = mgr.get_configuration(sg)
        mgr.api.method_get.assert_called_once_with(uri)
        self.assertEqual(ret, conf)

    def test_mgr_update(self):
        sg = self.scaling_group
        mgr = sg.manager
        mgr.get = Mock(return_value=sg)
        uri = "/%s/%s/config" % (mgr.uri_base, sg.id)
        sg.name = utils.random_unicode()
        sg.cooldown = utils.random_unicode()
        sg.min_entities = utils.random_unicode()
        sg.max_entities = utils.random_unicode()
        metadata = utils.random_unicode()
        mgr.api.method_put = Mock(return_value=(None, None))
        expected_body = {"name": sg.name,
                "cooldown": sg.cooldown,
                "minEntities": sg.min_entities,
                "maxEntities": sg.max_entities,
                "metadata": metadata,
                }
        mgr.update(sg.id, metadata=metadata)
        mgr.api.method_put.assert_called_once_with(uri, body=expected_body)

    def test_mgr_replace(self):
        sg = self.scaling_group
        mgr = sg.manager
        mgr.get = Mock(return_value=sg)
        uri = "/%s/%s/config" % (mgr.uri_base, sg.id)
        sg.name = utils.random_unicode()
        sg.cooldown = utils.random_unicode()
        sg.min_entities = utils.random_unicode()
        sg.max_entities = utils.random_unicode()
        metadata = utils.random_unicode()

        new_name = utils.random_unicode()
        new_cooldown = utils.random_unicode()
        new_min = utils.random_unicode()
        new_max = utils.random_unicode()
        mgr.api.method_put = Mock(return_value=(None, None))
        expected_body = {
                "name": new_name,
                "cooldown": new_cooldown,
                "minEntities": new_min,
                "maxEntities": new_max,
                "metadata": {}
                }
        mgr.replace(sg.id, new_name, new_cooldown, new_min, new_max)
        mgr.api.method_put.assert_called_once_with(uri, body=expected_body)

    def test_mgr_update_metadata(self):
        sg = self.scaling_group
        mgr = sg.manager
        mgr.get = Mock(return_value=sg)
        sg.metadata = {"orig": "orig"}
        metadata = {"new": "new"}
        expected = sg.metadata.copy()
        expected.update(metadata)
        mgr.update = Mock()
        mgr.update_metadata(sg.id, metadata)
        mgr.update.assert_called_once_with(sg, metadata=expected)

    def test_mgr_get_launch_config(self):
        sg = self.scaling_group
        mgr = sg.manager
        typ = utils.random_unicode()
        lbs = utils.random_unicode()
        name = utils.random_unicode()
        flv = utils.random_unicode()
        img = utils.random_unicode()
        dconfig = utils.random_unicode()
        metadata = utils.random_unicode()
        personality = utils.random_unicode()
        networks = utils.random_unicode()
        key_name = utils.random_unicode()
        launchdict = {"launchConfiguration":
                {"type": typ,
                "args": {
                    "loadBalancers": lbs,
                    "server": {
                        "name": name,
                        "flavorRef": flv,
                        "imageRef": img,
                        "OS-DCF:diskConfig": dconfig,
                        "metadata": metadata,
                        "personality": personality,
                        "networks": networks,
                        "key_name": key_name,
                        },
                    },
                },
            }
        expected = {
                "type": typ,
                "load_balancers": lbs,
                "name": name,
                "flavor": flv,
                "image": img,
                "disk_config": dconfig,
                "metadata": metadata,
                "personality": personality,
                "networks": networks,
                "key_name": key_name,
                }
        mgr.api.method_get = Mock(return_value=(None, launchdict))
        uri = "/%s/%s/launch" % (mgr.uri_base, sg.id)
        ret = mgr.get_launch_config(sg)
        mgr.api.method_get.assert_called_once_with(uri)
        self.assertEqual(ret, expected)

    def test_mgr_update_launch_config(self):
        sg = self.scaling_group
        mgr = sg.manager
        mgr.get = Mock(return_value=sg)
        typ = utils.random_unicode()
        lbs = utils.random_unicode()
        name = utils.random_unicode()
        flv = utils.random_unicode()
        img = utils.random_unicode()
        dconfig = utils.random_unicode()
        metadata = utils.random_unicode()
        personality = utils.random_unicode()
        networks = utils.random_unicode()
        sg.launchConfiguration = {}
        body = {"type": "launch_server",
                "args": {
                    "server": {
                        "name": name,
                        "imageRef": img,
                        "flavorRef": flv,
                        "OS-DCF:diskConfig": dconfig,
                        "personality": personality,
                        "networks": networks,
                        "metadata": metadata,
                    },
                    "loadBalancers": lbs,
                },
            }
        mgr.api.method_put = Mock(return_value=(None, None))
        uri = "/%s/%s/launch" % (mgr.uri_base, sg.id)
        mgr.update_launch_config(sg.id, server_name=name, flavor=flv, image=img,
                disk_config=dconfig, metadata=metadata,
                personality=personality, networks=networks, load_balancers=lbs)
        mgr.api.method_put.assert_called_once_with(uri, body=body)

    def test_mgr_update_launch_config_key_name(self):
        sg = self.scaling_group
        mgr = sg.manager
        mgr.get = Mock(return_value=sg)
        typ = utils.random_unicode()
        lbs = utils.random_unicode()
        name = utils.random_unicode()
        flv = utils.random_unicode()
        img = utils.random_unicode()
        dconfig = utils.random_unicode()
        metadata = utils.random_unicode()
        personality = utils.random_unicode()
        networks = utils.random_unicode()
        key_name = utils.random_unicode()
        sg.launchConfiguration = {}
        body = {"type": "launch_server",
                "args": {
                    "server": key_name,
                    "loadBalancers": lbs,
                },
            }
        mgr.api.method_put = Mock(return_value=(None, None))
        uri = "/%s/%s/launch" % (mgr.uri_base, sg.id)
        mgr.update_launch_config(sg.id, server_name=name, flavor=flv, image=img,
                disk_config=dconfig, metadata=metadata,
                personality=personality, networks=networks, load_balancers=lbs,
                key_name=key_name)
        mgr.api.method_put.assert_called_once_with(uri, body=body)

    def test_mgr_replace_launch_config(self):
        sg = self.scaling_group
        mgr = sg.manager
        mgr.get = Mock(return_value=sg)
        typ = utils.random_unicode()
        lbs = utils.random_unicode()
        name = utils.random_unicode()
        flv = utils.random_unicode()
        img = utils.random_unicode()
        dconfig = utils.random_unicode()
        metadata = utils.random_unicode()
        personality = utils.random_unicode()
        networks = utils.random_unicode()

        sg.launchConfiguration = {
                "type": typ,
                "args": {
                    "server": {
                        "name": name,
                        "imageRef": img,
                        "flavorRef": flv,
                        "OS-DCF:diskConfig": dconfig,
                        "personality": personality,
                        "networks": networks,
                        "metadata": metadata,
                        },
                    "loadBalancers": lbs,
                    },
                }
        new_typ = utils.random_unicode()
        new_name = utils.random_unicode()
        new_flv = utils.random_unicode()
        new_img = utils.random_unicode()

        expected = {
                "type": new_typ,
                "args": {
                    "server": {
                        "name": new_name,
                        "imageRef": new_img,
                        "flavorRef": new_flv,
                        },
                    "loadBalancers": []
                    }
                }

        mgr.api.method_put = Mock(return_value=(None, None))
        uri = "/%s/%s/launch" % (mgr.uri_base, sg.id)

        mgr.replace_launch_config(sg.id, launch_config_type=new_typ,
                server_name=new_name, flavor=new_flv, image=new_img)
        mgr.api.method_put.assert_called_once_with(uri, body=expected)

    def test_mgr_update_launch_metadata(self):
        sg = self.scaling_group
        mgr = sg.manager
        mgr.get = Mock(return_value=sg)
        orig_meta = {"orig": "orig"}
        new_meta = {"new": "new"}
        sg.launchConfiguration = {"args": {"server": {"metadata": orig_meta}}}
        expected = orig_meta.copy()
        expected.update(new_meta)
        mgr.update_launch_config = Mock()
        mgr.update_launch_metadata(sg.id, new_meta)
        mgr.update_launch_config.assert_called_once_with(sg, metadata=expected)

    def test_mgr_add_policy(self):
        sg = self.scaling_group
        mgr = sg.manager
        ret_body = {"policies": [{}]}
        mgr.api.method_post = Mock(return_value=(None, ret_body))
        uri = "/%s/%s/policies" % (mgr.uri_base, sg.id)
        name = utils.random_unicode()
        ptype = utils.random_unicode()
        cooldown = utils.random_unicode()
        change = utils.random_unicode()
        for is_percent in (True, False):
            post_body = {"name": name, "cooldown": cooldown, "type": ptype}
            if is_percent:
                post_body["changePercent"] = change
            else:
                post_body["change"] = change
            ret = mgr.add_policy(sg, name, ptype, cooldown, change,
                    is_percent=is_percent)
            mgr.api.method_post.assert_called_with(uri, body=[post_body])
            self.assert_(isinstance(ret, AutoScalePolicy))

    def test_mgr_create_policy_body(self):
        sg = self.scaling_group
        mgr = sg.manager
        name = utils.random_unicode()
        ptype = utils.random_unicode()
        cooldown = utils.random_unicode()
        desired_capacity = utils.random_unicode()
        args = utils.random_unicode()
        change = utils.random_unicode()
        expected_pct = {"name": name,
                "cooldown": cooldown,
                "type": ptype,
                "desiredCapacity": desired_capacity,
                "args": args
                }
        expected_nopct = expected_pct.copy()
        expected_pct["changePercent"] = change
        expected_nopct["change"] = change
        ret_pct = mgr._create_policy_body(name, ptype, cooldown, change=change,
                is_percent=True, desired_capacity=desired_capacity, args=args)
        ret_nopct = mgr._create_policy_body(name, ptype, cooldown,
                change=change, is_percent=False,
                desired_capacity=desired_capacity, args=args)
        self.assertEqual(ret_nopct, expected_nopct)
        self.assertEqual(ret_pct, expected_pct)

    def test_mgr_add_policy_desired_capacity(self):
        sg = self.scaling_group
        mgr = sg.manager
        ret_body = {"policies": [{}]}
        mgr.api.method_post = Mock(return_value=(None, ret_body))
        uri = "/%s/%s/policies" % (mgr.uri_base, sg.id)
        name = utils.random_unicode()
        ptype = utils.random_unicode()
        cooldown = utils.random_unicode()
        desired_capacity = utils.random_unicode()
        post_body = {
                "name": name,
                "cooldown": cooldown,
                "type": ptype,
                "desiredCapacity": desired_capacity,
                }
        ret = mgr.add_policy(sg, name, ptype, cooldown,
                desired_capacity=desired_capacity)
        mgr.api.method_post.assert_called_with(uri, body=[post_body])
        self.assert_(isinstance(ret, AutoScalePolicy))

    def test_mgr_list_policies(self):
        sg = self.scaling_group
        mgr = sg.manager
        ret_body = {"policies": [{}]}
        mgr.api.method_get = Mock(return_value=(None, ret_body))
        uri = "/%s/%s/policies" % (mgr.uri_base, sg.id)
        ret = mgr.list_policies(sg)
        mgr.api.method_get.assert_called_once_with(uri)

    def test_mgr_get_policy(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = utils.random_unicode()
        ret_body = {"policy": {}}
        uri = "/%s/%s/policies/%s" % (mgr.uri_base, sg.id, pol)
        mgr.api.method_get = Mock(return_value=(None, ret_body))
        ret = mgr.get_policy(sg, pol)
        self.assert_(isinstance(ret, AutoScalePolicy))
        mgr.api.method_get.assert_called_once_with(uri)

    def test_mgr_replace_policy(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol_id = utils.random_unicode()
        info = {
                "name": utils.random_unicode(),
                "type": utils.random_unicode(),
                "cooldown": utils.random_unicode(),
                "change": utils.random_unicode(),
                "args": utils.random_unicode(),
                }
        policy = fakes.FakeAutoScalePolicy(mgr, info, sg)
        mgr.get_policy = Mock(return_value=policy)

        new_name = utils.random_unicode()
        new_type = utils.random_unicode()
        new_cooldown = utils.random_unicode()
        new_change_percent = utils.random_unicode()

        mgr.api.method_put = Mock(return_value=(None, None))
        uri = "/%s/%s/policies/%s" % (mgr.uri_base, sg.id, pol_id)
        expected = {
                "name": new_name,
                "type": new_type,
                "cooldown": new_cooldown,
                "changePercent": new_change_percent,
                }
        ret = mgr.replace_policy(sg, pol_id, name=new_name,
                policy_type=new_type, cooldown=new_cooldown,
                change=new_change_percent, is_percent=True)
        mgr.api.method_put.assert_called_with(uri, body=expected)

    def test_mgr_update_policy(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = utils.random_unicode()
        name = utils.random_unicode()
        ptype = utils.random_unicode()
        cooldown = utils.random_unicode()
        change = utils.random_unicode()
        args = utils.random_unicode()
        mgr.get_policy = Mock(return_value=fakes.FakeAutoScalePolicy(mgr, {},
                sg))
        mgr.api.method_put = Mock(return_value=(None, None))
        uri = "/%s/%s/policies/%s" % (mgr.uri_base, sg.id, pol)
        for is_percent in (True, False):
            put_body = {"name": name, "cooldown": cooldown, "type": ptype,
                    "args": args}
            if is_percent:
                put_body["changePercent"] = change
            else:
                put_body["change"] = change
            ret = mgr.update_policy(sg, pol, name=name, policy_type=ptype,
                    cooldown=cooldown, change=change, is_percent=is_percent,
                    args=args)
            mgr.api.method_put.assert_called_with(uri, body=put_body)

    def test_mgr_update_policy_desired_to_desired(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = utils.random_unicode()
        name = utils.random_unicode()
        ptype = utils.random_unicode()
        cooldown = utils.random_unicode()
        change = utils.random_unicode()
        args = utils.random_unicode()
        new_desired_capacity = 10
        old_info = {"desiredCapacity": 0}
        mgr.get_policy = Mock(
                return_value=fakes.FakeAutoScalePolicy(mgr, old_info, sg))
        mgr.api.method_put = Mock(return_value=(None, None))
        uri = "/%s/%s/policies/%s" % (mgr.uri_base, sg.id, pol)
        put_body = {"name": name, "cooldown": cooldown, "type": ptype,
                "desiredCapacity": new_desired_capacity}
        ret = mgr.update_policy(sg, pol, name=name, policy_type=ptype,
                cooldown=cooldown, desired_capacity=new_desired_capacity)
        mgr.api.method_put.assert_called_with(uri, body=put_body)

    def test_mgr_update_policy_change_to_desired(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = utils.random_unicode()
        name = utils.random_unicode()
        ptype = utils.random_unicode()
        cooldown = utils.random_unicode()
        change = utils.random_unicode()
        args = utils.random_unicode()
        new_desired_capacity = 10
        old_info = {"change": -1}
        mgr.get_policy = Mock(
                return_value=fakes.FakeAutoScalePolicy(mgr, old_info, sg))
        mgr.api.method_put = Mock(return_value=(None, None))
        uri = "/%s/%s/policies/%s" % (mgr.uri_base, sg.id, pol)
        put_body = {"name": name, "cooldown": cooldown, "type": ptype,
                "desiredCapacity": new_desired_capacity}
        ret = mgr.update_policy(sg, pol, name=name, policy_type=ptype,
                cooldown=cooldown, desired_capacity=new_desired_capacity)
        mgr.api.method_put.assert_called_with(uri, body=put_body)

    def test_mgr_update_policy_desired_to_change(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = utils.random_unicode()
        name = utils.random_unicode()
        ptype = utils.random_unicode()
        cooldown = utils.random_unicode()
        change = utils.random_unicode()
        args = utils.random_unicode()
        new_change = 1
        old_info = {"desiredCapacity": 0}
        mgr.get_policy = Mock(
                return_value=fakes.FakeAutoScalePolicy(mgr, old_info, sg))
        mgr.api.method_put = Mock(return_value=(None, None))
        uri = "/%s/%s/policies/%s" % (mgr.uri_base, sg.id, pol)
        put_body = {"name": name, "cooldown": cooldown, "type": ptype,
                "change": new_change}
        ret = mgr.update_policy(sg, pol, name=name, policy_type=ptype,
                cooldown=cooldown, change=new_change)
        mgr.api.method_put.assert_called_with(uri, body=put_body)

    def test_mgr_update_policy_maintain_desired_capacity(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = utils.random_unicode()
        name = utils.random_unicode()
        ptype = utils.random_unicode()
        cooldown = utils.random_unicode()
        change = utils.random_unicode()
        args = utils.random_unicode()
        new_name = utils.random_unicode()
        old_capacity = 0
        old_info = {
                "type": ptype,
                "desiredCapacity": old_capacity,
                "cooldown": cooldown,
                }
        mgr.get_policy = Mock(
                return_value=fakes.FakeAutoScalePolicy(mgr, old_info, sg))
        mgr.api.method_put = Mock(return_value=(None, None))
        uri = "/%s/%s/policies/%s" % (mgr.uri_base, sg.id, pol)
        put_body = {"name": new_name, "cooldown": cooldown, "type": ptype,
                "desiredCapacity": old_capacity}
        ret = mgr.update_policy(sg, pol, name=new_name)
        mgr.api.method_put.assert_called_with(uri, body=put_body)

    def test_mgr_update_policy_maintain_is_percent(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = utils.random_unicode()
        name = utils.random_unicode()
        ptype = utils.random_unicode()
        cooldown = utils.random_unicode()
        new_name = utils.random_unicode()
        old_percent = 10
        old_info = {
                "type": ptype,
                "changePercent": old_percent,
                "cooldown": cooldown,
                }
        mgr.get_policy = Mock(
                return_value=fakes.FakeAutoScalePolicy(mgr, old_info, sg))
        mgr.api.method_put = Mock(return_value=(None, None))
        uri = "/%s/%s/policies/%s" % (mgr.uri_base, sg.id, pol)
        put_body = {"name": new_name, "cooldown": cooldown, "type": ptype,
                "changePercent": old_percent}
        ret = mgr.update_policy(sg, pol, name=new_name)
        mgr.api.method_put.assert_called_with(uri, body=put_body)

    def test_mgr_update_policy_maintain_is_absolute(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = utils.random_unicode()
        name = utils.random_unicode()
        ptype = utils.random_unicode()
        cooldown = utils.random_unicode()
        change = utils.random_unicode()
        new_name = utils.random_unicode()
        old_change = 10
        old_info = {
                "type": ptype,
                "change": old_change,
                "cooldown": cooldown,
                }
        mgr.get_policy = Mock(
                return_value=fakes.FakeAutoScalePolicy(mgr, old_info, sg))
        mgr.api.method_put = Mock(return_value=(None, None))
        uri = "/%s/%s/policies/%s" % (mgr.uri_base, sg.id, pol)
        put_body = {"name": new_name, "cooldown": cooldown, "type": ptype,
                "change": old_change}
        ret = mgr.update_policy(sg, pol, name=new_name)
        mgr.api.method_put.assert_called_with(uri, body=put_body)

    def test_mgr_execute_policy(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = utils.random_unicode()
        uri = "/%s/%s/policies/%s/execute" % (mgr.uri_base, sg.id, pol)
        mgr.api.method_post = Mock(return_value=(None, None))
        mgr.execute_policy(sg, pol)
        mgr.api.method_post.assert_called_once_with(uri)

    def test_mgr_delete_policy(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = utils.random_unicode()
        uri = "/%s/%s/policies/%s" % (mgr.uri_base, sg.id, pol)
        mgr.api.method_delete = Mock(return_value=(None, None))
        mgr.delete_policy(sg, pol)
        mgr.api.method_delete.assert_called_once_with(uri)

    def test_mgr_add_webhook(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = utils.random_unicode()
        ret_body = {"webhooks": [{}]}
        mgr.api.method_post = Mock(return_value=(None, ret_body))
        uri = "/%s/%s/policies/%s/webhooks" % (mgr.uri_base, sg.id, pol)
        mgr.get_policy = Mock(return_value=fakes.FakeAutoScalePolicy(mgr, {},
                sg))
        name = utils.random_unicode()
        metadata = utils.random_unicode()
        post_body = {"name": name, "metadata": metadata}
        ret = mgr.add_webhook(sg, pol, name, metadata=metadata)
        mgr.api.method_post.assert_called_with(uri, body=[post_body])
        self.assert_(isinstance(ret, AutoScaleWebhook))

    def test_mgr_list_webhooks(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = fakes.FakeAutoScalePolicy(mgr, {}, sg)
        ret_body = {"webhooks": [{}]}
        mgr.api.method_get = Mock(return_value=(None, ret_body))
        mgr.get_policy = Mock(return_value=fakes.FakeAutoScalePolicy(mgr, {},
                sg))
        uri = "/%s/%s/policies/%s/webhooks" % (mgr.uri_base, sg.id, pol.id)
        ret = mgr.list_webhooks(sg, pol)
        mgr.api.method_get.assert_called_once_with(uri)

    def test_mgr_get_webhook(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = fakes.FakeAutoScalePolicy(mgr, {}, sg)
        hook = utils.random_unicode()
        ret_body = {"webhook": {}}
        uri = "/%s/%s/policies/%s/webhooks/%s" % (mgr.uri_base, sg.id, pol.id,
                hook)
        mgr.api.method_get = Mock(return_value=(None, ret_body))
        ret = mgr.get_webhook(sg, pol, hook)
        self.assert_(isinstance(ret, AutoScaleWebhook))
        mgr.api.method_get.assert_called_once_with(uri)

    def test_mgr_replace_webhook(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = fakes.FakeAutoScalePolicy(mgr, {}, sg)
        hook = utils.random_unicode()
        info = {"name": utils.random_unicode(),
                "metadata": utils.random_unicode()}
        hook_obj = fakes.FakeAutoScaleWebhook(mgr, info, pol, sg)
        new_name = utils.random_unicode()
        new_metadata = utils.random_unicode()
        mgr.get_webhook = Mock(return_value=hook_obj)
        mgr.api.method_put = Mock(return_value=(None, None))
        uri = "/%s/%s/policies/%s/webhooks/%s" % (mgr.uri_base, sg.id, pol.id,
                hook)
        expected = {"name": new_name, "metadata": {}}
        ret = mgr.replace_webhook(sg, pol, hook, name=new_name)
        mgr.api.method_put.assert_called_with(uri, body=expected)

    def test_mgr_update_webhook(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = fakes.FakeAutoScalePolicy(mgr, {}, sg)
        hook = utils.random_unicode()
        hook_obj = fakes.FakeAutoScaleWebhook(mgr, {}, pol, sg)
        name = utils.random_unicode()
        metadata = utils.random_unicode()
        mgr.get_webhook = Mock(return_value=hook_obj)
        mgr.api.method_put = Mock(return_value=(None, None))
        uri = "/%s/%s/policies/%s/webhooks/%s" % (mgr.uri_base, sg.id, pol.id,
                hook)
        put_body = {"name": name, "metadata": metadata}
        ret = mgr.update_webhook(sg, pol, hook, name=name, metadata=metadata)
        mgr.api.method_put.assert_called_with(uri, body=put_body)

    def test_mgr_update_webhook_metadata(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = fakes.FakeAutoScalePolicy(mgr, {}, sg)
        hook = utils.random_unicode()
        hook_obj = fakes.FakeAutoScaleWebhook(mgr, {}, pol, sg)
        hook_obj.metadata = {"orig": "orig"}
        metadata = {"new": "new"}
        expected = hook_obj.metadata.copy()
        expected.update(metadata)
        uri = "/%s/%s/policies/%s/webhooks/%s" % (mgr.uri_base, sg.id, pol.id,
                hook)
        mgr.update_webhook = Mock()
        mgr.get_webhook = Mock(return_value=hook_obj)
        mgr.update_webhook_metadata(sg, pol, hook, metadata)
        mgr.update_webhook.assert_called_once_with(sg, pol, hook_obj,
                metadata=expected)

    def test_mgr_delete_webhook(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = fakes.FakeAutoScalePolicy(mgr, {}, sg)
        hook = utils.random_unicode()
        hook_obj = fakes.FakeAutoScaleWebhook(mgr, {}, pol, sg)
        uri = "/%s/%s/policies/%s/webhooks/%s" % (mgr.uri_base, sg.id, pol.id,
                hook)
        mgr.api.method_delete = Mock(return_value=(None, None))
        mgr.get_webhook = Mock(return_value=hook_obj)
        mgr.delete_webhook(sg, pol, hook)
        mgr.api.method_delete.assert_called_once_with(uri)

    def test_mgr_resolve_lbs_dict(self):
        sg = self.scaling_group
        mgr = sg.manager
        key = utils.random_unicode()
        val = utils.random_unicode()
        lb_dict = {key: val}
        ret = mgr._resolve_lbs(lb_dict)
        self.assertEqual(ret, [lb_dict])

    def test_mgr_resolve_lbs_clb(self):
        sg = self.scaling_group
        mgr = sg.manager
        clb = fakes.FakeLoadBalancer(None, {})
        ret = mgr._resolve_lbs(clb)
        expected = {"loadBalancerId": clb.id, "port": clb.port}
        self.assertEqual(ret, [expected])

    def test_mgr_resolve_lbs_tuple(self):
        sg = self.scaling_group
        mgr = sg.manager
        fake_id = utils.random_unicode()
        fake_port = utils.random_unicode()
        lbs = (fake_id, fake_port)
        ret = mgr._resolve_lbs(lbs)
        expected = {"loadBalancerId": fake_id, "port": fake_port}
        self.assertEqual(ret, [expected])

    def test_mgr_resolve_lbs_id(self):
        sg = self.scaling_group
        mgr = sg.manager
        clb = fakes.FakeLoadBalancer(None, {})
        sav = pyrax.cloud_loadbalancers

        class PyrCLB(object):
            def get(self, *args, **kwargs):
                return clb

        pyrax.cloud_loadbalancers = PyrCLB()
        ret = mgr._resolve_lbs("fakeid")
        expected = {"loadBalancerId": clb.id, "port": clb.port}
        self.assertEqual(ret, [expected])
        pyrax.cloud_loadbalancers = sav

    def test_mgr_resolve_lbs_id_fail(self):
        sg = self.scaling_group
        mgr = sg.manager
        pyclb = pyrax.cloudloadbalancers
        pyclb.get = Mock(side_effect=Exception())
        self.assertRaises(exc.InvalidLoadBalancer, mgr._resolve_lbs, "bogus")

    def test_mgr_create_body(self):
        sg = self.scaling_group
        mgr = sg.manager
        name = utils.random_unicode()
        cooldown = utils.random_unicode()
        min_entities = utils.random_unicode()
        max_entities = utils.random_unicode()
        launch_config_type = utils.random_unicode()
        flavor = utils.random_unicode()
        disk_config = None
        metadata = None
        personality = None
        scaling_policies = None
        networks = utils.random_unicode()
        lb = fakes.FakeLoadBalancer()
        load_balancers = (lb.id, lb.port)
        server_name = utils.random_unicode()
        image = utils.random_unicode()
        group_metadata = utils.random_unicode()
        key_name = utils.random_unicode()
        expected = {
                "groupConfiguration": {
                    "cooldown": cooldown,
                    "maxEntities": max_entities,
                    "minEntities": min_entities,
                    "name": name,
                    "metadata": group_metadata},
                "launchConfiguration": {
                    "args": {
                        "loadBalancers": [{"loadBalancerId": lb.id,
                            "port": lb.port}],
                        "server": {
                            "flavorRef": flavor,
                            "imageRef": image,
                            "metadata": {},
                            "name": server_name,
                            "personality": [],
                            "networks": networks,
                            "key_name": key_name}
                        },
                    "type": launch_config_type},
                "scalingPolicies": []}

        self.maxDiff = 1000000
        ret = mgr._create_body(name, cooldown, min_entities, max_entities,
                launch_config_type, server_name, image, flavor,
                disk_config=disk_config, metadata=metadata,
                personality=personality, networks=networks,
                load_balancers=load_balancers,
                scaling_policies=scaling_policies,
                group_metadata=group_metadata, key_name=key_name)
        self.assertEqual(ret, expected)

    def test_mgr_create_body_disk_config(self):
        sg = self.scaling_group
        mgr = sg.manager
        name = utils.random_unicode()
        cooldown = utils.random_unicode()
        min_entities = utils.random_unicode()
        max_entities = utils.random_unicode()
        launch_config_type = utils.random_unicode()
        flavor = utils.random_unicode()
        disk_config = utils.random_unicode()
        metadata = None
        personality = None
        scaling_policies = None
        networks = utils.random_unicode()
        lb = fakes.FakeLoadBalancer()
        load_balancers = (lb.id, lb.port)
        server_name = utils.random_unicode()
        image = utils.random_unicode()
        group_metadata = utils.random_unicode()
        key_name = utils.random_unicode()
        expected = {
                "groupConfiguration": {
                    "cooldown": cooldown,
                    "maxEntities": max_entities,
                    "minEntities": min_entities,
                    "name": name,
                    "metadata": group_metadata},
                "launchConfiguration": {
                    "args": {
                        "loadBalancers": [{"loadBalancerId": lb.id,
                            "port": lb.port}],
                        "server": {
                            "OS-DCF:diskConfig": disk_config,
                            "flavorRef": flavor,
                            "imageRef": image,
                            "metadata": {},
                            "name": server_name,
                            "personality": [],
                            "networks": networks,
                            "key_name": key_name}
                        },
                    "type": launch_config_type},
                "scalingPolicies": []}

        self.maxDiff = 1000000
        ret = mgr._create_body(name, cooldown, min_entities, max_entities,
                launch_config_type, server_name, image, flavor,
                disk_config=disk_config, metadata=metadata,
                personality=personality, networks=networks,
                load_balancers=load_balancers,
                scaling_policies=scaling_policies,
                group_metadata=group_metadata, key_name=key_name)
        self.assertEqual(ret, expected)

    def test_policy_init(self):
        sg = self.scaling_group
        mgr = sg.manager
        mgr.get = Mock(return_value=sg)
        pol = fakes.FakeAutoScalePolicy(mgr, {}, sg.id)
        self.assert_(pol.scaling_group is sg)

    def test_policy_get(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = fakes.FakeAutoScalePolicy(mgr, {}, sg)
        mgr.get_policy = Mock(return_value=pol)
        pol.get()
        mgr.get_policy.assert_called_once_with(sg, pol)

    def test_policy_delete(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = fakes.FakeAutoScalePolicy(mgr, {}, sg)
        mgr.delete_policy = Mock()
        pol.delete()
        mgr.delete_policy.assert_called_once_with(sg, pol)

    def test_policy_update(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = fakes.FakeAutoScalePolicy(mgr, {}, sg)
        name = utils.random_unicode()
        policy_type = utils.random_unicode()
        cooldown = utils.random_unicode()
        change = utils.random_unicode()
        is_percent = utils.random_unicode()
        desired_capacity = utils.random_unicode()
        args = utils.random_unicode()
        mgr.update_policy = Mock()
        pol.update(name=name, policy_type=policy_type, cooldown=cooldown,
                change=change, is_percent=is_percent,
                desired_capacity=desired_capacity, args=args)
        mgr.update_policy.assert_called_once_with(scaling_group=sg,
                policy=pol, name=name, policy_type=policy_type,
                cooldown=cooldown, change=change, is_percent=is_percent,
                desired_capacity=desired_capacity, args=args)

    def test_policy_execute(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = fakes.FakeAutoScalePolicy(mgr, {}, sg)
        mgr.execute_policy = Mock()
        pol.execute()
        mgr.execute_policy.assert_called_once_with(sg, pol)

    def test_policy_add_webhook(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = fakes.FakeAutoScalePolicy(mgr, {}, sg)
        mgr.add_webhook = Mock()
        name = utils.random_unicode()
        metadata = utils.random_unicode()
        pol.add_webhook(name, metadata=metadata)
        mgr.add_webhook.assert_called_once_with(sg, pol, name,
                metadata=metadata)

    def test_policy_list_webhooks(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = fakes.FakeAutoScalePolicy(mgr, {}, sg)
        mgr.list_webhooks = Mock()
        pol.list_webhooks()
        mgr.list_webhooks.assert_called_once_with(sg, pol)

    def test_policy_get_webhook(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = fakes.FakeAutoScalePolicy(mgr, {}, sg)
        hook = utils.random_unicode()
        mgr.get_webhook = Mock()
        pol.get_webhook(hook)
        mgr.get_webhook.assert_called_once_with(sg, pol, hook)

    def test_policy_update_webhook(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = fakes.FakeAutoScalePolicy(mgr, {}, sg)
        hook = utils.random_unicode()
        name = utils.random_unicode()
        metadata = utils.random_unicode()
        mgr.update_webhook = Mock()
        pol.update_webhook(hook, name=name, metadata=metadata)
        mgr.update_webhook.assert_called_once_with(sg, policy=pol, webhook=hook,
                name=name, metadata=metadata)

    def test_policy_update_webhook_metadata(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = fakes.FakeAutoScalePolicy(mgr, {}, sg)
        hook = utils.random_unicode()
        metadata = utils.random_unicode()
        mgr.update_webhook_metadata = Mock()
        pol.update_webhook_metadata(hook, metadata=metadata)
        mgr.update_webhook_metadata.assert_called_once_with(sg, pol, hook,
                metadata)

    def test_policy_delete_webhook(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = fakes.FakeAutoScalePolicy(mgr, {}, sg)
        hook = utils.random_unicode()
        mgr.delete_webhook = Mock()
        pol.delete_webhook(hook)
        mgr.delete_webhook.assert_called_once_with(sg, pol, hook)

    def test_webhook_get(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = fakes.FakeAutoScalePolicy(mgr, {}, sg)
        hook = fakes.FakeAutoScaleWebhook(mgr, {}, pol, sg)
        pol.get_webhook = Mock()
        hook.get()
        pol.get_webhook.assert_called_once_with(hook)

    def test_webhook_update(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = fakes.FakeAutoScalePolicy(mgr, {}, sg)
        hook = fakes.FakeAutoScaleWebhook(mgr, {}, pol, sg)
        name = utils.random_unicode()
        metadata = utils.random_unicode()
        pol.update_webhook = Mock()
        hook.update(name=name, metadata=metadata)
        pol.update_webhook.assert_called_once_with(hook, name=name,
                metadata=metadata)

    def test_webhook_update_metadata(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = fakes.FakeAutoScalePolicy(mgr, {}, sg)
        hook = fakes.FakeAutoScaleWebhook(mgr, {}, pol, sg)
        metadata = utils.random_unicode()
        pol.update_webhook_metadata = Mock()
        hook.update_metadata(metadata=metadata)
        pol.update_webhook_metadata.assert_called_once_with(hook,
                metadata)

    def test_webhook_delete(self):
        sg = self.scaling_group
        mgr = sg.manager
        pol = fakes.FakeAutoScalePolicy(mgr, {}, sg)
        hook = fakes.FakeAutoScaleWebhook(mgr, {}, pol, sg)
        pol.delete_webhook = Mock()
        hook.delete()
        pol.delete_webhook.assert_called_once_with(hook)

    def test_clt_get_state(self):
        clt = fakes.FakeAutoScaleClient()
        sg = self.scaling_group
        mgr = clt._manager
        mgr.get_state = Mock()
        clt.get_state(sg)
        mgr.get_state.assert_called_once_with(sg)

    def test_clt_pause(self):
        clt = fakes.FakeAutoScaleClient()
        sg = self.scaling_group
        mgr = clt._manager
        mgr.pause = Mock()
        clt.pause(sg)
        mgr.pause.assert_called_once_with(sg)

    def test_clt_resume(self):
        clt = fakes.FakeAutoScaleClient()
        mgr = clt._manager
        sg = self.scaling_group
        mgr.resume = Mock()
        clt.resume(sg)
        mgr.resume.assert_called_once_with(sg)

    def test_clt_replace(self):
        clt = fakes.FakeAutoScaleClient()
        mgr = clt._manager
        sg = self.scaling_group
        name = utils.random_unicode()
        cooldown = utils.random_unicode()
        min_entities = utils.random_unicode()
        max_entities = utils.random_unicode()
        metadata = utils.random_unicode()
        mgr.replace = Mock()
        clt.replace(sg, name, cooldown, min_entities, max_entities,
                metadata=metadata)
        mgr.replace.assert_called_once_with(sg, name, cooldown, min_entities,
                max_entities, metadata=metadata)

    def test_clt_update(self):
        clt = fakes.FakeAutoScaleClient()
        mgr = clt._manager
        sg = self.scaling_group
        name = utils.random_unicode()
        cooldown = utils.random_unicode()
        min_entities = utils.random_unicode()
        max_entities = utils.random_unicode()
        metadata = utils.random_unicode()
        mgr.update = Mock()
        clt.update(sg, name=name, cooldown=cooldown, min_entities=min_entities,
                max_entities=max_entities, metadata=metadata)
        mgr.update.assert_called_once_with(sg, name=name, cooldown=cooldown,
                min_entities=min_entities, max_entities=max_entities,
                metadata=metadata)

    def test_clt_update_metadata(self):
        clt = fakes.FakeAutoScaleClient()
        mgr = clt._manager
        sg = self.scaling_group
        metadata = utils.random_unicode()
        mgr.update_metadata = Mock()
        clt.update_metadata(sg, metadata)
        mgr.update_metadata.assert_called_once_with(sg, metadata)

    def test_clt_get_configuration(self):
        clt = fakes.FakeAutoScaleClient()
        mgr = clt._manager
        sg = self.scaling_group
        mgr.get_configuration = Mock()
        clt.get_configuration(sg)
        mgr.get_configuration.assert_called_once_with(sg)

    def test_clt_get_launch_config(self):
        clt = fakes.FakeAutoScaleClient()
        mgr = clt._manager
        sg = self.scaling_group
        mgr.get_launch_config = Mock()
        clt.get_launch_config(sg)
        mgr.get_launch_config.assert_called_once_with(sg)

    def test_clt_replace_launch_config(self):
        clt = fakes.FakeAutoScaleClient()
        mgr = clt._manager
        sg = self.scaling_group
        mgr.replace_launch_config = Mock()
        launch_config_type = utils.random_unicode()
        server_name = utils.random_unicode()
        image = utils.random_unicode()
        flavor = utils.random_unicode()
        disk_config = utils.random_unicode()
        metadata = utils.random_unicode()
        personality = utils.random_unicode()
        networks = utils.random_unicode()
        load_balancers = utils.random_unicode()
        key_name = utils.random_unicode()
        clt.replace_launch_config(sg, launch_config_type, server_name, image,
                flavor, disk_config=disk_config, metadata=metadata,
                personality=personality, networks=networks,
                load_balancers=load_balancers, key_name=key_name)
        mgr.replace_launch_config.assert_called_once_with(sg,
                launch_config_type, server_name, image, flavor,
                disk_config=disk_config, metadata=metadata,
                personality=personality, networks=networks,
                load_balancers=load_balancers, key_name=key_name)

    def test_clt_update_launch_config(self):
        clt = fakes.FakeAutoScaleClient()
        mgr = clt._manager
        sg = self.scaling_group
        mgr.update_launch_config = Mock()
        server_name = utils.random_unicode()
        flavor = utils.random_unicode()
        image = utils.random_unicode()
        disk_config = utils.random_unicode()
        metadata = utils.random_unicode()
        personality = utils.random_unicode()
        networks = utils.random_unicode()
        load_balancers = utils.random_unicode()
        key_name = utils.random_unicode()
        clt.update_launch_config(sg, server_name=server_name, flavor=flavor,
                image=image, disk_config=disk_config, metadata=metadata,
                personality=personality, networks=networks,
                load_balancers=load_balancers, key_name=key_name)
        mgr.update_launch_config.assert_called_once_with(sg,
                server_name=server_name, flavor=flavor, image=image,
                disk_config=disk_config, metadata=metadata,
                personality=personality, networks=networks,
                load_balancers=load_balancers, key_name=key_name)

    def test_clt_update_launch_metadata(self):
        clt = fakes.FakeAutoScaleClient()
        mgr = clt._manager
        sg = self.scaling_group
        mgr.update_launch_metadata = Mock()
        metadata = utils.random_unicode()
        clt.update_launch_metadata(sg, metadata)
        mgr.update_launch_metadata.assert_called_once_with(sg, metadata)

    def test_clt_add_policy(self):
        clt = fakes.FakeAutoScaleClient()
        mgr = clt._manager
        sg = self.scaling_group
        name = utils.random_unicode()
        policy_type = utils.random_unicode()
        cooldown = utils.random_unicode()
        change = utils.random_unicode()
        is_percent = utils.random_unicode()
        desired_capacity = utils.random_unicode()
        args = utils.random_unicode()
        mgr.add_policy = Mock()
        clt.add_policy(sg, name, policy_type, cooldown, change,
                is_percent=is_percent, desired_capacity=desired_capacity,
                args=args)
        mgr.add_policy.assert_called_once_with(sg, name, policy_type, cooldown,
                change=change, is_percent=is_percent,
                desired_capacity=desired_capacity, args=args)

    def test_clt_list_policies(self):
        clt = fakes.FakeAutoScaleClient()
        mgr = clt._manager
        sg = self.scaling_group
        mgr.list_policies = Mock()
        clt.list_policies(sg)
        mgr.list_policies.assert_called_once_with(sg)

    def test_clt_get_policy(self):
        clt = fakes.FakeAutoScaleClient()
        mgr = clt._manager
        sg = self.scaling_group
        pol = utils.random_unicode()
        mgr.get_policy = Mock()
        clt.get_policy(sg, pol)
        mgr.get_policy.assert_called_once_with(sg, pol)

    def test_clt_replace_policy(self):
        clt = fakes.FakeAutoScaleClient()
        mgr = clt._manager
        sg = self.scaling_group
        pol = utils.random_unicode()
        name = utils.random_unicode()
        policy_type = utils.random_unicode()
        cooldown = utils.random_unicode()
        change = utils.random_unicode()
        is_percent = utils.random_unicode()
        desired_capacity = utils.random_unicode()
        args = utils.random_unicode()
        mgr.replace_policy = Mock()
        clt.replace_policy(sg, pol, name, policy_type, cooldown, change=change,
                is_percent=is_percent, desired_capacity=desired_capacity,
                args=args)
        mgr.replace_policy.assert_called_once_with(sg, pol, name, policy_type,
                cooldown, change=change, is_percent=is_percent,
                desired_capacity=desired_capacity, args=args)

    def test_clt_update_policy(self):
        clt = fakes.FakeAutoScaleClient()
        mgr = clt._manager
        sg = self.scaling_group
        pol = utils.random_unicode()
        name = utils.random_unicode()
        policy_type = utils.random_unicode()
        cooldown = utils.random_unicode()
        change = utils.random_unicode()
        is_percent = utils.random_unicode()
        desired_capacity = utils.random_unicode()
        args = utils.random_unicode()
        mgr.update_policy = Mock()
        clt.update_policy(sg, pol, name=name, policy_type=policy_type,
                cooldown=cooldown, change=change, is_percent=is_percent,
                desired_capacity=desired_capacity, args=args)
        mgr.update_policy.assert_called_once_with(sg, pol, name=name,
                policy_type=policy_type, cooldown=cooldown, change=change,
                is_percent=is_percent, desired_capacity=desired_capacity,
                args=args)

    def test_clt_execute_policy(self):
        clt = fakes.FakeAutoScaleClient()
        mgr = clt._manager
        sg = self.scaling_group
        pol = utils.random_unicode()
        mgr.execute_policy = Mock()
        clt.execute_policy(sg, pol)
        mgr.execute_policy.assert_called_once_with(scaling_group=sg, policy=pol)

    def test_clt_delete_policy(self):
        clt = fakes.FakeAutoScaleClient()
        mgr = clt._manager
        sg = self.scaling_group
        pol = utils.random_unicode()
        mgr.delete_policy = Mock()
        clt.delete_policy(sg, pol)
        mgr.delete_policy.assert_called_once_with(scaling_group=sg, policy=pol)

    def test_clt_add_webhook(self):
        clt = fakes.FakeAutoScaleClient()
        mgr = clt._manager
        sg = self.scaling_group
        pol = utils.random_unicode()
        name = utils.random_unicode()
        metadata = utils.random_unicode()
        mgr.add_webhook = Mock()
        clt.add_webhook(sg, pol, name, metadata=metadata)
        mgr.add_webhook.assert_called_once_with(sg, pol, name,
                metadata=metadata)

    def test_clt_list_webhooks(self):
        clt = fakes.FakeAutoScaleClient()
        mgr = clt._manager
        sg = self.scaling_group
        pol = utils.random_unicode()
        mgr.list_webhooks = Mock()
        clt.list_webhooks(sg, pol)
        mgr.list_webhooks.assert_called_once_with(sg, pol)

    def test_clt_get_webhook(self):
        clt = fakes.FakeAutoScaleClient()
        mgr = clt._manager
        sg = self.scaling_group
        pol = utils.random_unicode()
        hook = utils.random_unicode()
        mgr.get_webhook = Mock()
        clt.get_webhook(sg, pol, hook)
        mgr.get_webhook.assert_called_once_with(sg, pol, hook)

    def test_clt_replace_webhook(self):
        clt = fakes.FakeAutoScaleClient()
        mgr = clt._manager
        sg = self.scaling_group
        pol = utils.random_unicode()
        hook = utils.random_unicode()
        name = utils.random_unicode()
        metadata = utils.random_unicode()
        mgr.replace_webhook = Mock()
        clt.replace_webhook(sg, pol, hook, name, metadata=metadata)
        mgr.replace_webhook.assert_called_once_with(sg, pol, hook, name,
                metadata=metadata)

    def test_clt_update_webhook(self):
        clt = fakes.FakeAutoScaleClient()
        mgr = clt._manager
        sg = self.scaling_group
        pol = utils.random_unicode()
        hook = utils.random_unicode()
        name = utils.random_unicode()
        metadata = utils.random_unicode()
        mgr.update_webhook = Mock()
        clt.update_webhook(sg, pol, hook, name=name, metadata=metadata)
        mgr.update_webhook.assert_called_once_with(scaling_group=sg, policy=pol,
                webhook=hook, name=name, metadata=metadata)

    def test_clt_update_webhook_metadata(self):
        clt = fakes.FakeAutoScaleClient()
        mgr = clt._manager
        sg = self.scaling_group
        pol = utils.random_unicode()
        hook = utils.random_unicode()
        metadata = utils.random_unicode()
        mgr.update_webhook_metadata = Mock()
        clt.update_webhook_metadata(sg, pol, hook, metadata)
        mgr.update_webhook_metadata.assert_called_once_with(sg, pol, hook,
                metadata)

    def test_clt_delete_webhook(self):
        clt = fakes.FakeAutoScaleClient()
        mgr = clt._manager
        sg = self.scaling_group
        pol = utils.random_unicode()
        hook = utils.random_unicode()
        mgr.delete_webhook = Mock()
        clt.delete_webhook(sg, pol, hook)
        mgr.delete_webhook.assert_called_once_with(sg, pol, hook)




if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_cf_client
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import locale
import os
import random
import unittest
import uuid

import six

from mock import ANY, call, patch
from mock import MagicMock as Mock

import pyrax
from pyrax.cf_wrapper.client import _swift_client, \
    _convert_head_object_last_modified_to_local, \
    _convert_list_last_modified_to_local
from pyrax.cf_wrapper.container import Container
import pyrax.utils as utils
import pyrax.exceptions as exc

from pyrax.fakes import fake_attdict
from pyrax.fakes import FakeBulkDeleter
from pyrax.fakes import FakeContainer
from pyrax.fakes import FakeFolderUploader
from pyrax.fakes import FakeIdentity
from pyrax.fakes import FakeResponse
from pyrax.fakes import FakeStorageObject


class CF_ClientTest(unittest.TestCase):
    def __init__(self, *args, **kwargs):
        reload(pyrax)
        self.orig_connect_to_cloudservers = pyrax.connect_to_cloudservers
        self.orig_connect_to_cloud_databases = pyrax.connect_to_cloud_databases
        ctclb = pyrax.connect_to_cloud_loadbalancers
        self.orig_connect_to_cloud_loadbalancers = ctclb
        ctcbs = pyrax.connect_to_cloud_blockstorage
        self.orig_connect_to_cloud_blockstorage = ctcbs
        super(CF_ClientTest, self).__init__(*args, **kwargs)

    def setUp(self):
        pyrax.connect_to_cloudservers = Mock()
        pyrax.connect_to_cloud_loadbalancers = Mock()
        pyrax.connect_to_cloud_databases = Mock()
        pyrax.connect_to_cloud_blockstorage = Mock()
        pyrax.identity = FakeIdentity()
        pyrax.set_credentials("fakeuser", "fakeapikey", region="FAKE")
        pyrax.connect_to_cloudfiles(region="FAKE")
        self.client = pyrax.cloudfiles
        self.client._container_cache = {}
        self.cont_name = utils.random_ascii()
        self.obj_name = utils.random_ascii()
        self.fake_object = FakeStorageObject(self.client, self.cont_name,
                self.obj_name)

    def tearDown(self):
        self.client = None
        pyrax.connect_to_cloudservers = self.orig_connect_to_cloudservers
        pyrax.connect_to_cloud_databases = self.orig_connect_to_cloud_databases
        octclb = self.orig_connect_to_cloud_loadbalancers
        pyrax.connect_to_cloud_loadbalancers = octclb
        octcbs = self.orig_connect_to_cloud_blockstorage
        pyrax.connect_to_cloud_blockstorage = octcbs

    def test_account_metadata(self):
        client = self.client
        client.connection.head_account = Mock()
        client.connection.head_account.return_value = {"X-Account-Meta-Foo":
                "yes", "Some-Other-Key": "no"}
        meta = client.get_account_metadata()
        self.assert_(len(meta) == 1)
        self.assert_("X-Account-Meta-Foo" in meta)

    def test_set_account_metadata(self):
        client = self.client
        client.connection.head_account = Mock()
        client.connection.head_account.return_value = {
                "X-Account-Meta-foo": "yes", "some-other-key": "no"}
        client.connection.post_account = Mock()
        client.set_account_metadata({"newkey": "newval"})
        client.connection.post_account.assert_called_with(
                {"X-Account-Meta-newkey": "newval"}, response_dict=None)

    def test_set_account_metadata_prefix(self):
        client = self.client
        client.connection.post_account = Mock()
        prefix = utils.random_unicode()
        client.set_account_metadata({"newkey": "newval"}, prefix=prefix)
        client.connection.post_account.assert_called_with(
                {"%snewkey" % prefix: "newval"}, response_dict=None)

    def test_set_account_metadata_clear(self):
        client = self.client
        client.connection.head_account = Mock()
        client.connection.head_account.return_value = {
                "X-Account-Meta-foo": "yes", "some-other-key": "no"}
        client.connection.post_account = Mock()
        client.set_account_metadata({"newkey": "newval"}, clear=True)
        client.connection.post_account.assert_called_with(
                {"X-Account-Meta-foo": "", "X-Account-Meta-newkey": "newval"},
                response_dict=None)

    def test_set_account_metadata_response(self):
        client = self.client
        client.connection.head_account = Mock()
        client.connection.head_account.return_value = {
                "X-Account-Meta-foo": "yes", "some-other-key": "no"}
        client.connection.post_account = Mock()
        response = {}
        client.set_account_metadata({"newkey": "newval"}, clear=True,
                extra_info=response)
        client.connection.post_account.assert_called_with(
                {"X-Account-Meta-foo": "", "X-Account-Meta-newkey": "newval"},
                response_dict=response)

    def test_set_temp_url_key(self):
        client = self.client
        sav = client.set_account_metadata
        client.set_account_metadata = Mock()
        key = utils.random_unicode()
        exp = {"Temp-Url-Key": key}
        client.set_temp_url_key(key)
        client.set_account_metadata.assert_called_once_with(exp)
        client.set_account_metadata = sav

    def test_set_temp_url_key_generated(self):
        client = self.client
        sav = client.set_account_metadata
        client.set_account_metadata = Mock()
        key = utils.random_ascii()
        sav_uu = uuid.uuid4

        class FakeUUID(object):
            hex = key

        uuid.uuid4 = Mock(return_value=FakeUUID())
        exp = {"Temp-Url-Key": key}
        client.set_temp_url_key()
        client.set_account_metadata.assert_called_once_with(exp)
        client.set_account_metadata = sav
        uuid.uuid4 = sav_uu

    def test_get_temp_url_key(self):
        client = self.client
        client.connection.head_account = Mock()
        client.connection.head_account.return_value = {
                "x-account-meta-foo": "yes", "some-other-key": "no"}
        meta = client.get_temp_url_key()
        self.assertIsNone(meta)
        nm = utils.random_unicode()
        client.connection.head_account.return_value = {
                "x-account-meta-temp-url-key": nm, "some-other-key": "no"}
        meta = client.get_temp_url_key()
        self.assertEqual(meta, nm)

    def test_get_temp_url_key_cached(self):
        client = self.client
        key = utils.random_unicode()
        client._cached_temp_url_key = key
        meta = client.get_temp_url_key()
        self.assertEqual(meta, key)

    def test_get_temp_url(self):
        client = self.client
        nm = utils.random_ascii()
        cname = utils.random_ascii()
        oname = utils.random_ascii()
        client.connection.head_account = Mock()
        client.connection.head_account.return_value = {
                "x-account-meta-temp-url-key": nm, "some-other-key": "no"}
        ret = client.get_temp_url(cname, oname, seconds=120, method="GET")
        self.assert_(cname in ret)
        self.assert_(oname in ret)
        self.assert_("?temp_url_sig=" in ret)
        self.assert_("&temp_url_expires=" in ret)

    def test_get_temp_url_bad_method(self):
        client = self.client
        nm = utils.random_ascii()
        cname = utils.random_ascii()
        oname = utils.random_ascii()
        self.assertRaises(exc.InvalidTemporaryURLMethod, client.get_temp_url,
                cname, oname, seconds=120, method="INVALID")

    def test_get_temp_url_windows(self):
        client = self.client
        nm = "%s\\" % utils.random_ascii()
        cname = "\\%s\\" % utils.random_ascii()
        oname = utils.random_ascii()
        client.connection.head_account = Mock()
        client.connection.head_account.return_value = {
                "x-account-meta-temp-url-key": nm, "some-other-key": "no"}
        ret = client.get_temp_url(cname, oname, seconds=120, method="GET")
        self.assertFalse("\\" in ret)

    def test_get_temp_url_unicode(self):
        client = self.client
        nm = utils.random_unicode()
        cname = utils.random_ascii()
        oname = utils.random_ascii()
        client.connection.head_account = Mock()
        client.connection.head_account.return_value = {
                "x-account-meta-temp-url-key": nm, "some-other-key": "no"}
        client.post_account = Mock()
        self.assertRaises(exc.UnicodePathError, client.get_temp_url, cname,
                oname, seconds=120, method="GET")

    def test_get_temp_url_missing_key(self):
        client = self.client
        cname = utils.random_ascii()
        oname = utils.random_ascii()
        client.connection.head_account = Mock()
        client.connection.head_account.return_value = {"some-other-key": "no"}
        self.assertRaises(exc.MissingTemporaryURLKey, client.get_temp_url,
                cname, oname, seconds=120, method="GET")

    def test_container_metadata(self):
        client = self.client
        client.connection.head_container = Mock()
        client.connection.head_container.return_value = {
                "X-Container-Meta-Foo": "yes", "Some-Other-Key": "no"}
        meta = client.get_container_metadata(self.cont_name)
        self.assert_(len(meta) == 1)
        self.assert_("X-Container-Meta-Foo" in meta)

    def test_object_metadata(self):
        client = self.client
        client.connection.head_object = Mock()
        client.connection.head_object.return_value = {
                "X-Object-Meta-Foo": "yes", "Some-Other-Key": "no"}
        meta = client.get_object_metadata(self.cont_name, self.obj_name)
        self.assert_(len(meta) == 1)
        self.assert_("X-Object-Meta-Foo" in meta)

    def test_set_container_metadata(self):
        client = self.client
        client.connection.post_container = Mock()
        client.set_container_metadata(self.cont_name, {"newkey": "newval"})
        client.connection.post_container.assert_called_with(self.cont_name,
                {"X-Container-Meta-newkey": "newval"}, response_dict=None)

    def test_set_container_metadata_prefix(self):
        client = self.client
        client.connection.post_container = Mock()
        prefix = utils.random_unicode()
        client.set_container_metadata(self.cont_name, {"newkey": "newval"},
                prefix=prefix)
        client.connection.post_container.assert_called_with(self.cont_name,
                {"%snewkey" % prefix: "newval"}, response_dict=None)

    def test_set_container_metadata_clear(self):
        client = self.client
        client.connection.head_container = Mock()
        client.connection.head_container.return_value = {
                "X-Container-Meta-Foo": "yes", "Some-Other-Key": "no"}
        client.connection.post_container = Mock()
        client.set_container_metadata(self.cont_name, {"newkey": "newval"},
                clear=True)
        client.connection.post_container.assert_called_with(self.cont_name,
                {"X-Container-Meta-Foo": "",
                "X-Container-Meta-newkey": "newval"}, response_dict=None)

    def test_set_container_metadata_response(self):
        client = self.client
        client.connection.head_container = Mock()
        client.connection.head_container.return_value = {
                "X-Container-Meta-Foo": "yes", "Some-Other-Key": "no"}
        client.connection.post_container = Mock()
        response = {}
        client.set_container_metadata(self.cont_name, {"newkey": "newval"},
                clear=True, extra_info=response)
        client.connection.post_container.assert_called_with(self.cont_name,
                {"X-Container-Meta-Foo": "",
                "X-Container-Meta-newkey": "newval"}, response_dict=response)

    def test_set_object_metadata(self):
        client = self.client
        client.connection.head_object = Mock()
        client.connection.head_object.return_value = {
                "X-Object-Meta-Foo": "yes", "Some-Other-Key": "no"}
        client.connection.post_object = Mock()
        client.set_object_metadata(self.cont_name, self.obj_name,
                {"newkey": "newval", "emptykey": ""})
        client.connection.post_object.assert_called_with(self.cont_name,
                self.obj_name, {"X-Object-Meta-newkey": "newval",
                "X-Object-Meta-Foo": "yes"}, response_dict=None)
        response = {}
        client.set_object_metadata(self.cont_name, self.obj_name,
                {"newkey": "newval", "emptykey": ""}, extra_info=response)
        client.connection.post_object.assert_called_with(ANY, ANY, ANY,
                response_dict=response)

    def test_set_object_metadata_prefix(self):
        client = self.client
        client.connection.head_object = Mock()
        client.connection.head_object.return_value = {
                "x-object-meta-foo": "yes", "some-other-key": "no"}
        client.connection.post_object = Mock()
        prefix = utils.random_unicode()
        client.set_object_metadata(self.cont_name, self.obj_name,
                {"newkey": "newval", "emptykey": ""}, prefix=prefix)
        client.connection.post_object.assert_called_with(self.cont_name,
                self.obj_name, {"%snewkey" % prefix: "newval"},
                response_dict=None)

    def test_remove_object_metadata_key(self):
        client = self.client
        client.connection.head_object = Mock()
        client.connection.head_object.return_value = {
                "X-Object-Meta-Foo": "foo", "X-Container-Meta-Bar": "bar"}
        client.connection.post_object = Mock()
        client.remove_object_metadata_key(self.cont_name, self.obj_name, "Bar")
        client.connection.post_object.assert_called_with(self.cont_name,
                self.obj_name, {"X-Object-Meta-Foo": "foo"},
                response_dict=None)

    def test_remove_container_metadata_key(self):
        client = self.client
        client.connection.head_container = Mock()
        client.connection.head_container.return_value = {
                "X-Container-Meta-Foo": "foo", "X-Container-Meta-Bar": "bar"}
        client.connection.post_container = Mock()
        client.remove_container_metadata_key(self.cont_name, "Bar")
        client.connection.post_container.assert_called_with(self.cont_name,
                {"x-container-meta-Bar": ""}, response_dict=None)

    def test_massage_metakeys(self):
        prefix = "ABC-"
        orig = {"ABC-yyy": "ok", "zzz": "change"}
        expected = {"ABC-yyy": "ok", "ABC-zzz": "change"}
        fixed = self.client._massage_metakeys(orig, prefix)
        self.assertEqual(fixed, expected)

    def test_prefix_read_only(self):
        client = self.client
        val = utils.random_unicode()

        def set_prefix(val):
            client.account_meta_prefix = val

        self.assertRaises(AttributeError, set_prefix, val)

    def test_resolve_name(self):
        class Foo(object):
            name = "BAR"
        client = self.client
        foo = Foo()
        objval = client._resolve_name(foo)
        strval = client._resolve_name(foo.name)
        self.assertEqual(objval, strval)

    def test_get_container_cdn_metadata(self):
        client = self.client
        client.connection.cdn_request = Mock()
        client.connection.cdn_connection = "fake"
        resp = FakeResponse()
        resp.headers = [("a", "b"), ("c", "d")]
        client.connection.cdn_request.return_value = resp
        returned = client.get_container_cdn_metadata(self.cont_name)
        expected = {"a": "b", "c": "d"}
        self.assertEqual(expected, returned)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_set_container_cdn_metadata(self):
        client = self.client
        client.connection.put_container = Mock()
        client.connection.head_container = Mock()
        client.connection.cdn_connection = "fake"
        meta = {"X-TTL": "9999", "X-NotAllowed": "0"}
        self.assertRaises(exc.InvalidCDNMetadata,
                client.set_container_cdn_metadata, self.cont_name, meta)
        meta = {"X-TTL": "9999"}
        client.connection.cdn_request = Mock()
        client.set_container_cdn_metadata(self.cont_name, meta)
        client.connection.cdn_request.assert_called_with("POST",
                [self.cont_name], hdrs=meta)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_create_container(self):
        client = self.client
        client.connection.put_container = Mock()
        client.connection.head_container = Mock()
        ret = client.create_container(self.cont_name)
        self.assert_(isinstance(ret, FakeContainer))
        self.assertEqual(ret.name, self.cont_name)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_create_container_response(self):
        client = self.client
        client.connection.put_container = Mock()
        client.connection.head_container = Mock()
        response = {}
        ret = client.create_container(self.cont_name, extra_info=response)
        client.connection.put_container.assert_called_with(self.cont_name,
                response_dict=response)

    def test_delete_container(self):
        client = self.client
        client.connection.delete_container = Mock()
        client.get_container_object_names = Mock()
        onames = ["o1", "o2", "o3"]
        client.get_container_object_names.return_value = onames
        client.delete_object = Mock()
        client.bulk_delete = Mock()
        client.delete_container(self.cont_name)
        self.assertEqual(client.get_container_object_names.call_count, 0)
        client.connection.delete_container.assert_called_with(self.cont_name,
                response_dict=None)
        # Now call with del_objects=True
        client.delete_container(self.cont_name, del_objects=True)
        self.assertEqual(client.get_container_object_names.call_count, 1)
        client.bulk_delete.assert_called_once_with(self.cont_name, onames,
                async=False)
        client.connection.delete_container.assert_called_with(self.cont_name,
                response_dict=None)
        response = {}
        # Now call with extra_info
        client.delete_container(self.cont_name, True, response)
        client.connection.delete_container.assert_called_with(self.cont_name,
                response_dict=response)

    def test_remove_object_from_cache(self):
        client = self.client
        client.connection.head_container = Mock()
        nm = utils.random_unicode()
        client._container_cache = {nm: object()}
        client.remove_container_from_cache(nm)
        self.assertEqual(client._container_cache, {})

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_delete_object(self):
        client = self.client
        client.connection.head_container = Mock()
        client.connection.delete_object = Mock()
        client.delete_object(self.cont_name, self.obj_name)
        client.connection.delete_object.assert_called_with(self.cont_name,
                self.obj_name, response_dict=None)
        response = {}
        client.delete_object(self.cont_name, self.obj_name, extra_info=response)
        client.connection.delete_object.assert_called_with(ANY, ANY,
                response_dict=response)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_purge_cdn_object(self):
        client = self.client
        client.connection.head_container = Mock()
        client.connection.cdn_connection = "fake"
        self.assertRaises(exc.NotCDNEnabled, client.purge_cdn_object,
                self.cont_name, self.obj_name)
        client.get_container(self.cont_name).cdn_uri = "http://example.com"
        client.connection.cdn_request = Mock()
        emls = ["foo@example.com", "bar@example.com"]
        client.purge_cdn_object(self.cont_name, self.obj_name, emls)
        client.connection.cdn_request.assert_called_with("DELETE",
                [self.cont_name, self.obj_name],
                hdrs={"X-Purge-Email": "foo@example.com, bar@example.com"})

    @patch('pyrax.cf_wrapper.client.BulkDeleter', new=FakeBulkDeleter)
    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_bulk_delete(self):
        client = self.client
        sav = client.bulk_delete_interval
        client.bulk_delete_interval = 0.001
        container = self.cont_name
        obj_names = [utils.random_unicode()]
        ret = client.bulk_delete(container, obj_names, async=False)
        self.assertTrue(isinstance(ret, dict))
        client.bulk_delete_interval = sav

    @patch('pyrax.cf_wrapper.client.BulkDeleter', new=FakeBulkDeleter)
    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_bulk_delete_async(self):
        client = self.client
        container = self.cont_name
        obj_names = [utils.random_unicode()]
        ret = client.bulk_delete(container, obj_names, async=True)
        self.assertTrue(isinstance(ret, FakeBulkDeleter))

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_get_object(self):
        client = self.client
        client.connection.head_container = Mock()
        client.connection.head_object = Mock(return_value=fake_attdict)
        cont = client.get_container(self.cont_name)
        cont.client.connection.get_container = Mock()
        cont.client.connection.get_container.return_value = ({},
                [{"name": "o1"}, {"name": "o2"}])
        obj = client.get_object(self.cont_name, "o1")
        self.assertEqual(obj.name, "o1")

    def random_non_us_locale(self):
        nonUS_locales = ("de_DE", "fr_FR", "hu_HU", "ja_JP", "nl_NL", "pl_PL",
                         "pt_BR", "pt_PT", "ro_RO", "ru_RU", "zh_CN", "zh_HK",
                         "zh_TW")
        return random.choice(nonUS_locales)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_get_object_locale(self):
        client = self.client
        orig_locale = locale.getlocale(locale.LC_TIME)
        new_locale = self.random_non_us_locale()
        try:
            locale.setlocale(locale.LC_TIME, new_locale)
        except Exception:
            # Travis CI seems to have a problem with setting locale, so
            # just skip this.
            self.skipTest("Could not set locale to %s" % new_locale)
        client.connection.head_container = Mock()
        client.connection.head_object = Mock(return_value=fake_attdict)
        obj = client.get_object(self.cont_name, "fake")
        self.assertEqual(obj.last_modified, "2013-01-01T01:02:03")
        locale.setlocale(locale.LC_TIME, orig_locale)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_store_object(self):
        client = self.client
        client.connection.head_container = Mock()
        client.connection.put_object = Mock()
        gobj = client.get_object
        client.get_object = Mock(return_value=self.fake_object)
        content = u"something with Ã¼â Æ-8"
        etag = utils.get_checksum(content)
        obj = client.store_object(self.cont_name, self.obj_name, content,
                content_type="test/test", etag=etag,
                content_encoding="gzip")
        self.assertEqual(client.connection.put_object.call_count, 1)
        # Add extra_info
        response = {}
        obj = client.store_object(self.cont_name, self.obj_name, content,
                content_type="test/test", etag=etag,
                content_encoding="gzip", extra_info=response)
        client.connection.put_object.assert_called_with(ANY, ANY,
                contents=ANY, content_type=ANY, chunk_size=ANY, etag=ANY,
                headers=ANY, response_dict=response)

        client.get_object = gobj

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_upload_file(self):
        client = self.client
        client.connection.head_container = Mock()
        client.connection.put_object = Mock()
        gobj = client.get_object
        client.get_object = Mock(return_value=self.fake_object)
        cont = client.get_container(self.cont_name)
        with utils.SelfDeletingTempfile() as tmpname:
            small_file_contents = "Test Value " * 25
            client.max_file_size = len(small_file_contents) + 1
            with open(tmpname, "wb") as tmp:
                tmp.write(small_file_contents)
            fname = os.path.basename(tmpname)
            fake_type = "test/test"
            client.upload_file(cont, tmpname, content_type=fake_type)
            self.assertEqual(client.connection.put_object.call_count, 1)
        client.get_object = gobj


    def test_upload_large_file(self):
        def call_upload_file(client, cont, tmpname, content_type_type):
            client.upload_file(cont, tmpname, content_type=content_type_type)

        self._test_upload_large_file(call_upload_file)

    def test_upload_large_file_from_file_object(self):
        def call_upload_file(client, cont, tmpname, content_type_type):
            with open(tmpname, "rb") as tmp:
                client.upload_file(cont, tmp, content_type=content_type_type)

        self._test_upload_large_file(call_upload_file)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def _test_upload_large_file(self, call_upload_file):
        client = self.client
        client.connection.head_container = Mock()
        client.connection.put_object = Mock()
        cont = client.get_container(self.cont_name)
        gobj = client.get_object
        client.get_object = Mock(return_value=self.fake_object)
        with utils.SelfDeletingTempfile() as tmpname:
            small_file_contents = "Test Value " * 25
            client.max_file_size = len(small_file_contents) - 1
            with open(tmpname, "wb") as tmp:
                tmp.write(small_file_contents)
            fname = os.path.basename(tmpname)
            fake_type = "test/test"
            call_upload_file(client, cont, tmpname, fake_type)
            # Large files require 1 call for manifest, plus one for each
            # segment. This should be a 2-segment file upload.
            self.assertEqual(client.connection.put_object.call_count, 3)
            put_calls = client.connection.put_object.mock_calls
            self.assertEqual(put_calls[0][1][1], '%s.1' % fname)
            self.assertEqual(put_calls[1][1][1], '%s.2' % fname)
            self.assertEqual(put_calls[2][1][1], fname)

            # get_object() should be called with the same name that was passed
            # to the final put_object() call (to get the object to return)
            client.get_object.assert_called_once_with(cont, fname)
        client.get_object = gobj

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_upload_large_file_from_file_object_with_obj_name(self):
        client = self.client
        client.connection.head_container = Mock()
        client.connection.put_object = Mock()
        cont = client.get_container(self.cont_name)
        gobj = client.get_object
        client.get_object = Mock(return_value=self.fake_object)
        with utils.SelfDeletingTempfile() as tmpname:
            small_file_contents = "Test Value " * 25
            client.max_file_size = len(small_file_contents) - 1
            with open(tmpname, "wb") as tmp:
                tmp.write(small_file_contents)
            fname = os.path.basename(tmpname)
            fake_type = "test/test"
            obj_name = 'not the same as filename'
            with open(tmpname, "rb") as tmp:
                client.upload_file(cont, tmp,
                        obj_name=obj_name, content_type=fake_type)
            # Large files require 1 call for manifest, plus one for each
            # segment. This should be a 2-segment file upload.
            self.assertEqual(client.connection.put_object.call_count, 3)
            put_calls = client.connection.put_object.mock_calls
            self.assertEqual(put_calls[0][1][1], '%s.1' % obj_name)
            self.assertEqual(put_calls[1][1][1], '%s.2' % obj_name)
            self.assertEqual(put_calls[2][1][1], obj_name)
            self.assertEqual(put_calls[2][2]["headers"]["X-Object-Manifest"],
                             self.cont_name + "/" + obj_name + ".")

            # get_object() should be called with the same name that was passed
            # to the final put_object() call (to get the object to return)
            client.get_object.assert_called_once_with(cont, obj_name)
        client.get_object = gobj

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_upload_folder_bad_folder(self):
        self.assertRaises(exc.FolderNotFound, self.client.upload_folder,
                "/doesnt_exist")

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_upload_folder_ignore_patterns(self):
        client = self.client
        bg = client._upload_folder_in_background
        client._upload_folder_in_background = Mock()
        opi = os.path.isdir
        os.path.isdir = Mock(return_value=True)
        test_folder = "testfolder"
        # Test string and list of ignores
        pat1 = "*.foo"
        pat2 = "*.bar"
        upload_key, total_bytes = client.upload_folder(test_folder,
                ignore=pat1)
        client._upload_folder_in_background.assert_called_with(test_folder,
                None, [pat1], upload_key, None)
        upload_key, total_bytes = client.upload_folder(test_folder,
                ignore=[pat1, pat2])
        client._upload_folder_in_background.assert_called_with(test_folder,
                None, [pat1, pat2], upload_key, None)
        client._upload_folder_in_background = bg
        os.path.isdir = opi

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_upload_folder_initial_progress(self):
        client = self.client
        bg = client._upload_folder_in_background
        client._upload_folder_in_background = Mock()
        opi = os.path.isdir
        os.path.isdir = Mock(return_value=True)
        ufs = utils.folder_size
        fake_size = 1234
        utils.folder_size = Mock(return_value=fake_size)
        test_folder = "testfolder"
        key, total_bytes = client.upload_folder(test_folder)
        self.assertEqual(total_bytes, fake_size)
        client._upload_folder_in_background = bg
        utils.folder_size = ufs
        os.path.isdir = opi

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    @patch('pyrax.cf_wrapper.client.FolderUploader', new=FakeFolderUploader)
    def test_upload_folder_in_backgroud(self):
        client = self.client
        start = FakeFolderUploader.start
        FakeFolderUploader.start = Mock()
        client.connection.put_container = Mock()
        client.connection.head_container = Mock()
        fake_upload_key = "abcd"
        client._upload_folder_in_background("folder/path", "cont_name", [],
                fake_upload_key)
        FakeFolderUploader.start.assert_called_with()
        FakeFolderUploader.start = start

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_folder_name_from_path(self):
        self.client.connection.put_container = Mock()
        self.client.connection.head_container = Mock()
        fake_upload_key = "abcd"
        uploader = FakeFolderUploader("root", "cont", None, fake_upload_key,
                self.client)
        path1 = "/foo/bar/baz"
        path2 = "/foo/bar/baz"
        nm1 = uploader.folder_name_from_path(path1)
        nm2 = uploader.folder_name_from_path(path2)
        self.assertEqual(nm1, "baz")
        self.assertEqual(nm2, "baz")

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_uploader_bad_dirname(self):
        self.client.connection.put_container = Mock()
        self.client.connection.head_container = Mock()
        fake_upload_key = "abcd"
        uploader = FakeFolderUploader("root", "cont", "*.bad", fake_upload_key,
                self.client)
        ret = uploader.upload_files_in_folder(None, "folder.bad", ["a", "b"])
        self.assertFalse(ret)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_upload_folder_with_files(self):
        client = self.client
        up = client.upload_file
        client.upload_file = Mock()
        client.connection.head_container = Mock()
        client.connection.put_container = Mock()
        cont_name = utils.random_unicode()
        cont = client.create_container(cont_name)
        gobj = client.get_object
        client.get_object = Mock(return_value=self.fake_object)
        safu = client._should_abort_folder_upload
        client._should_abort_folder_upload = Mock(return_value=False)
        upprog = client._update_progress
        client._update_progress = Mock()
        num_files = 10
        fake_upload_key = "abcd"
        with utils.SelfDeletingTempDirectory() as tmpdir:
            for idx in six.moves.range(num_files):
                nm = "file%s" % idx
                pth = os.path.join(tmpdir, nm)
                open(pth, "w").write("test")
            uploader = FakeFolderUploader(tmpdir, cont, "", fake_upload_key,
                    client)
            # Note that the fake moved the actual run() code to a
            # different method
            uploader.actual_run()
            self.assertEqual(client.upload_file.call_count, num_files)
        client.get_object = gobj
        client.upload_file = up
        client._should_abort_folder_upload = safu
        client._update_progress = upprog

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_valid_upload_key(self):
        clt = self.client
        clt.folder_upload_status = {"good": {"uploaded": 0}}
        self.assertIsNone(clt._update_progress("good", 1))
        self.assertRaises(exc.InvalidUploadID, clt._update_progress, "bad", 1)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_sync_folder_to_container(self):
        clt = self.client
        up = clt.upload_file
        clt.upload_file = Mock()
        clt.connection.head_container = Mock()
        clt.connection.put_container = Mock()
        clt.connection.head_object = Mock(return_value=fake_attdict)
        clt.get_container_objects = Mock(return_value=[])
        cont_name = utils.random_unicode(8)
        cont = clt.create_container(cont_name)
        num_files = 7
        with utils.SelfDeletingTempDirectory() as tmpdir:
            for idx in six.moves.range(num_files):
                nm = "file%s" % idx
                pth = os.path.join(tmpdir, nm)
                open(pth, "w").write("test")
            clt.sync_folder_to_container(tmpdir, cont)
            self.assertEqual(clt.upload_file.call_count, num_files)
        clt.upload_file = up

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_sync_folder_to_container_hidden(self):
        clt = self.client
        up = clt.upload_file
        clt.upload_file = Mock()
        clt.connection.head_container = Mock()
        clt.connection.put_container = Mock()
        clt.connection.head_object = Mock(return_value=fake_attdict)
        clt.get_container_objects = Mock(return_value=[])
        cont_name = utils.random_unicode(8)
        cont = clt.create_container(cont_name)
        num_vis_files = 4
        num_hid_files = 4
        num_all_files = num_vis_files + num_hid_files
        with utils.SelfDeletingTempDirectory() as tmpdir:
            for idx in six.moves.range(num_vis_files):
                nm = "file%s" % idx
                pth = os.path.join(tmpdir, nm)
                open(pth, "w").write("test")
            for idx in six.moves.range(num_hid_files):
                nm = ".file%s" % idx
                pth = os.path.join(tmpdir, nm)
                open(pth, "w").write("test")
            clt.sync_folder_to_container(tmpdir, cont, include_hidden=True)
            self.assertEqual(clt.upload_file.call_count, num_all_files)
        clt.upload_file = up

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_sync_folder_to_container_nested(self):
        clt = self.client
        up = clt.upload_file
        clt.upload_file = Mock()
        clt.connection.head_container = Mock()
        clt.connection.put_container = Mock()
        clt.connection.head_object = Mock(return_value=fake_attdict)
        clt.get_container_objects = Mock(return_value=[])
        cont_name = utils.random_unicode(8)
        cont = clt.create_container(cont_name)
        num_files = 3
        num_nested_files = 6
        num_all_files = num_files + num_nested_files
        with utils.SelfDeletingTempDirectory() as tmpdir:
            for idx in six.moves.range(num_files):
                nm = "file%s" % idx
                pth = os.path.join(tmpdir, nm)
                open(pth, "w").write("test")
            nested_folder = os.path.join(tmpdir, "nested")
            os.mkdir(nested_folder)
            for idx in six.moves.range(num_nested_files):
                nm = "file%s" % idx
                pth = os.path.join(nested_folder, nm)
                open(pth, "w").write("test")
            clt.sync_folder_to_container(tmpdir, cont)
            self.assertEqual(clt.upload_file.call_count, num_all_files)
        clt.upload_file = up

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_delete_objects_not_in_list(self):
        client = self.client
        client.connection.head_container = Mock()
        client.connection.get_container = Mock()
        cont = client.get_container(self.cont_name)
        cont.get_object_names = Mock(return_value=["First", "Second"])
        good_names = ["First", "Third"]
        client._local_files = good_names
        client.bulk_delete = Mock()
        client._delete_objects_not_in_list(cont)
        client.bulk_delete.assert_called_with(cont, ["Second"], async=True)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_copy_object(self):
        client = self.client
        client.connection.head_container = Mock()
        client.connection.head_object = Mock(return_value=fake_attdict)
        cont = client.get_container(self.cont_name)
        client.connection.put_object = Mock()
        cont.client.connection.get_container = Mock()
        cont.client.connection.get_container.return_value = ({},
                [{"name": "o1"}, {"name": "o2"}])
        client.copy_object(self.cont_name, "o1", "newcont")
        client.connection.put_object.assert_called_with("newcont", "o1",
                contents=None, headers={"X-Copy-From": "/%s/o1" %
                self.cont_name}, response_dict=None)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_move_object(self):
        client = self.client
        client.connection.head_container = Mock()
        client.connection.head_object = Mock(return_value=fake_attdict)
        cont = client.get_container(self.cont_name)
        client.connection.put_object = Mock(return_value="0000")
        cont.client.connection.get_container = Mock()
        cont.client.connection.get_container.return_value = ({},
                [{"name": "o1"}, {"name": "o2"}])
        client.delete_object = Mock()
        client.move_object(self.cont_name, "o1", "newcont")
        client.connection.put_object.assert_called_with("newcont", "o1",
                contents=None, headers={"X-Copy-From": "/%s/o1" %
                self.cont_name}, response_dict=None)
        client.delete_object.assert_called_with(self.cont_name, "o1")

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_change_object_content_type(self):
        client = self.client
        client.connection.head_container = Mock()
        client.connection.head_object = Mock(return_value=fake_attdict)
        cont = client.get_container(self.cont_name)
        client.connection.put_object = Mock(return_value="0000")
        cont.client.connection.get_container = Mock()
        cont.client.connection.get_container.return_value = ({},
                [{"name": "o1"}, {"name": "o2"}])
        client.change_object_content_type(self.cont_name, "o1",
                "something/else")
        client.connection.put_object.assert_called_with(self.cont_name, "o1",
                contents=None, headers={"X-Copy-From": "/%s/o1" %
                self.cont_name}, content_type="something/else",
                response_dict=None)

    def test_fetch_object(self):
        client = self.client
        text = "file_contents"
        client.connection.get_object = Mock(return_value=({}, text))
        resp = client.fetch_object(self.cont_name, self.obj_name,
                include_meta=True)
        self.assertEqual(len(resp), 2)
        self.assertEqual(resp[1], text)

        # Try with extra_info dict
        patch("client._resolve_name", lambda arg: arg)
        response = {}
        resp = client.fetch_object(self.cont_name, self.obj_name,
                include_meta=True, extra_info=response)
        client.connection.get_object.assert_called_with(ANY, ANY,
                resp_chunk_size=ANY, response_dict=response)

    def test_fetch_partial(self):
        client = self.client
        cont = utils.random_unicode()
        obj = utils.random_unicode()
        size = random.randint(1, 1000)
        client.fetch_object = Mock()
        client.fetch_partial(cont, obj, size)
        client.fetch_object.assert_called_once_with(cont, obj, chunk_size=size)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_download_object(self):
        client = self.client
        sav_fetch = client.fetch_object
        client.fetch_object = Mock(return_value=utils.random_ascii())
        sav_isdir = os.path.isdir
        os.path.isdir = Mock(return_value=True)
        nm = "one/two/three/four.txt"
        with utils.SelfDeletingTempDirectory() as tmpdir:
            fullpath = os.path.join(tmpdir, nm)
            client.download_object("fake", nm, tmpdir, structure=True)
            self.assertTrue(os.path.exists(fullpath))
        with utils.SelfDeletingTempDirectory() as tmpdir:
            fullpath = os.path.join(tmpdir, os.path.basename(nm))
            client.download_object("fake", nm, tmpdir, structure=False)
            self.assertTrue(os.path.exists(fullpath))
        client.fetch_object = sav_fetch
        os.path.isdir = sav_isdir

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_get_all_containers(self):
        client = self.client
        client.connection.head_container = Mock()
        cont_list = [{"name": self.cont_name, "count": "2", "bytes": "12345"},
                {"name": "anothercont", "count": "1", "bytes": "67890"}]
        client.connection.get_container = Mock()
        client.connection.get_container.return_value = ({}, cont_list)
        conts = client.get_all_containers()
        client.connection.get_container.assert_called_with("", limit=None,
                marker=None)
        self.assertEqual(len(conts), 2)
        cont_names = [ct.name for ct in conts]
        cont_names.sort()
        expected_names = [self.cont_name, "anothercont"]
        expected_names.sort()
        self.assertEqual(cont_names, expected_names)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_get_container(self):
        client = self.client
        client.connection.head_container = Mock()
        client.connection.head_container.return_value = {
                "x-container-object-count": 3, "x-container-bytes-used": 1234}
        self.assertRaises(exc.MissingName, client.get_container, "")
        cont = client.get_container(self.cont_name)
        self.assertEqual(cont.name, self.cont_name)
        self.assertEqual(cont.object_count, 3)
        self.assertEqual(cont.total_bytes, 1234)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_get_container_from_cache(self):
        client = self.client
        client.connection.head_container = Mock()
        client.connection.head_container.return_value = {
                "x-container-object-count": 3, "x-container-bytes-used": 1234}
        cnt = random.randint(2, 6)
        for ii in range(cnt):
            cont = client.get_container(self.cont_name)
        self.assertEqual(client.connection.head_container.call_count, 1)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_get_container_no_cache(self):
        client = self.client
        client.connection.head_container = Mock()
        client.connection.head_container.return_value = {
                "x-container-object-count": 3, "x-container-bytes-used": 1234}
        cnt = random.randint(2, 6)
        for ii in range(cnt):
            cont = client.get_container(self.cont_name, cached=False)
        self.assertEqual(client.connection.head_container.call_count, cnt)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_get_container_objects(self):
        client = self.client
        client.connection.head_container = Mock()
        dct = [{"name": "o1", "bytes": 111}, {"name": "o2", "bytes": 2222}]
        client.connection.get_container = Mock(return_value=({}, dct))
        objs = client.get_container_objects(self.cont_name)
        self.assertEqual(len(objs), 2)
        self.assertEqual(objs[0].container.name, self.cont_name)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_get_container_objects_last_modified(self):
        client = self.client
        client.connection.head_container = Mock()
        dct = [
            {
                "name": "o1",
                "bytes": 111,
                "last_modified": "2013-01-01T01:02:03.123456",
            },
            {
                "name": "o2",
                "bytes": 2222,
                "last_modified": "2013-10-21T01:02:03.123456",
            },
        ]
        client.connection.get_container = Mock(return_value=({}, dct))
        objs = client.get_container_objects(self.cont_name)
        self.assertEqual(len(objs), 2)
        self.assertEqual(objs[0].container.name, self.cont_name)
        self.assertEqual(objs[0].name, "o1")
        self.assertEqual(objs[0].last_modified, "2013-01-01T01:02:04")
        self.assertEqual(objs[1].name, "o2")

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_get_container_object_names(self):
        client = self.client
        client.connection.head_container = Mock()
        dct = [{"name": "o1", "bytes": 111}, {"name": "o2", "bytes": 2222}]
        client.connection.get_container = Mock(return_value=({}, dct))
        obj_names = client.get_container_object_names(self.cont_name)
        self.assertEqual(len(obj_names), 2)
        self.assert_("o1" in obj_names)
        self.assert_("o2" in obj_names)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_list_container_subdirs(self):
        client = self.client
        client.connection.head_container = Mock()
        objs = [{"name": "subdir1", "content_type": "application/directory"},
                {"name": "file1", "content_type": "text/plain"},
                {"name": "subdir2", "content_type": "application/directory"},
                {"name": "file2", "content_type": "text/plain"}]
        client.connection.get_container = Mock(return_value=(None, objs))
        ret = client.list_container_subdirs("fake")
        self.assertEqual(len(ret), 2)
        obj_names = [obj.name for obj in ret]
        self.assert_("subdir1" in obj_names)
        self.assert_("subdir2" in obj_names)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_get_info(self):
        client = self.client
        dct = {"x-account-container-count": 2, "x-account-bytes-used": 1234}
        client.connection.head_container = Mock(return_value=dct)
        resp = client.get_info()
        self.assertEqual(len(resp), 2)
        self.assertEqual(resp[0], 2)
        self.assertEqual(resp[1], 1234)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_get_container_streaming_uri(self):
        client = self.client
        client.connection.head_container = Mock()
        example_uri = "http://example.com"
        client.get_container(self.cont_name).cdn_streaming_uri = example_uri
        uri = client.get_container_streaming_uri(self.cont_name)
        self.assertEqual(uri, example_uri)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_get_container_ios_uri(self):
        client = self.client
        client.connection.head_container = Mock()
        example_uri = "http://example.com"
        client.get_container(self.cont_name).cdn_ios_uri = example_uri
        uri = client.get_container_ios_uri(self.cont_name)
        self.assertEqual(uri, example_uri)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_list(self):
        client = self.client
        client.connection.head_container = Mock()
        client.connection.get_container = Mock()
        cont_list = [{"name": self.cont_name, "count": "2", "bytes": "12345"},
                {"name": "anothercont", "count": "1", "bytes": "67890"}]
        client.connection.get_container = Mock()
        client.connection.get_container.return_value = ({}, cont_list)
        resp = client.list()
        self.assertEqual(len(resp), 2)
        self.assert_(all([isinstance(cont, Container) for cont in resp]))

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_list_containers(self):
        client = self.client
        client.connection.get_container = Mock()
        cont_list = [{"name": self.cont_name, "count": "2", "bytes": "12345"},
                {"name": "anothercont", "count": "1", "bytes": "67890"}]
        client.connection.get_container = Mock()
        client.connection.get_container.return_value = ({}, cont_list)
        resp = client.list_containers()
        self.assertEqual(len(resp), 2)
        self.assert_(self.cont_name in resp)
        self.assert_("anothercont" in resp)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_list_containers_info(self):
        client = self.client
        client.connection.get_container = Mock()
        cont_list = [{"name": self.cont_name, "count": "2", "bytes": "12345"},
                {"name": "anothercont", "count": "1", "bytes": "67890"}]
        client.connection.get_container = Mock()
        client.connection.get_container.return_value = ({}, cont_list)
        resp = client.list_containers_info()
        self.assertEqual(len(resp), 2)
        r0 = resp[0]
        self.assert_(isinstance(r0, dict))
        self.assertEqual(len(r0), 3)
        self.assert_("name" in r0)
        self.assert_("count" in r0)
        self.assert_("bytes" in r0)

    def test_list_public_containers(self):
        client = self.client
        client.connection.cdn_request = Mock()
        client.connection.cdn_connection = "fake"
        resp = FakeResponse()
        resp.headers = [("a", "b"), ("c", "d")]
        resp.status = 500
        client.connection.cdn_request.return_value = resp
        self.assertRaises(exc.CDNFailed, client.list_public_containers)
        resp.status = 200
        conts = client.list_public_containers()
        client.connection.cdn_request.assert_called_with("GET", [""])
        self.assertEqual(len(conts), 2)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_make_container_public(self):
        client = self.client
        client.connection.head_container = Mock()
        client.connection.cdn_connection = "fake"
        cont = client.get_container(self.cont_name)
        cont.cdn_uri = None
        client.connection.cdn_request = Mock()
        example = "http://example.com"
        resp = FakeResponse()
        resp.headers = [("x-cdn-uri", example), ("c", "d")]
        resp.status = 500
        client.connection.cdn_request.return_value = resp
        self.assertRaises(exc.CDNFailed, client.make_container_public,
                self.cont_name)
        resp.status = 204
        client.make_container_public(self.cont_name, ttl=6666)
        client.connection.cdn_request.assert_called_with("PUT",
                [self.cont_name], hdrs={"X-TTL": "6666",
                "X-CDN-Enabled": "True"})

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_make_container_private(self):
        client = self.client
        client.connection.head_container = Mock()
        client.connection.cdn_connection = "fake"
        cont = client.get_container(self.cont_name)
        cont.cdn_uri = None
        client.connection.cdn_request = Mock()
        example = "http://example.com"
        resp = FakeResponse()
        resp.headers = [("x-cdn-uri", example), ("c", "d")]
        resp.status = 500
        client.connection.cdn_request.return_value = resp
        self.assertRaises(exc.CDNFailed, client.make_container_public,
                self.cont_name)
        resp.status = 204
        client.make_container_private(self.cont_name)
        client.connection.cdn_request.assert_called_with("PUT",
                [self.cont_name], hdrs={"X-CDN-Enabled": "False"})


    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_set_cdn_log_retention(self):
        client = self.client
        client.connection.head_container = Mock()
        client.connection.cdn_connection = "fake"
        cont = client.get_container(self.cont_name)
        client.connection.cdn_request = Mock()
        resp = FakeResponse()
        client.connection.cdn_request.return_value = resp
        resp.status = 500
        self.assertRaises(exc.CDNFailed, client.set_cdn_log_retention, cont,
                True)
        resp.status = 204
        client.set_cdn_log_retention(cont, True)
        self.assert_(cont.cdn_log_retention)
        client.set_cdn_log_retention(cont, False)
        self.assertFalse(cont.cdn_log_retention)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_set_container_web_index_page(self):
        client = self.client
        client.connection.head_container = Mock()
        cont = client.get_container(self.cont_name)
        client.connection.post_container = Mock()
        pg = "index.html"
        client.set_container_web_index_page(cont, pg)
        client.connection.post_container.assert_called_with(self.cont_name,
                {"X-Container-Meta-Web-Index": pg}, response_dict=None)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_set_container_web_error_page(self):
        client = self.client
        client.connection.head_container = Mock()
        cont = client.get_container(self.cont_name)
        client.connection.post_container = Mock()
        pg = "error.html"
        client.set_container_web_error_page(cont, pg)
        client.connection.post_container.assert_called_with(self.cont_name,
                {"X-Container-Meta-Web-Error": pg}, response_dict=None)

    def test_cdn_request(self):
        client = self.client
        conn = client.connection
        conn._make_cdn_connection(cdn_url="http://example.com")
        if conn.cdn_connection is not None:
            conn.cdn_connection.request = Mock()
            conn.cdn_connection.getresponse = Mock()
            conn.cdn_request("GET", path=["A", "B"])
            call_args = conn.cdn_connection.request.call_args_list[0][0]
            self.assertEqual(call_args[0], "GET")
            self.assert_(call_args[1].endswith("A/B"))
            hdrs = call_args[-1]
            self.assert_("pyrax" in hdrs["User-Agent"])

    def test_handle_swiftclient_exception_container(self):
        client = self.client
        gc = client.get_container
        client.get_container = Mock()
        side_effect = _swift_client.ClientException("Container GET failed: "
                "https://example.com/some_container 404")
        side_effect.http_status = 404
        client.get_container.side_effect = side_effect
        # Note: we're using delete_object because its first call
        # is get_container()
        self.assertRaises(exc.NoSuchContainer, client.delete_object,
                "some_container", "some_object")
        client.get_container = gc

    def test_handle_swiftclient_exception_object(self):
        client = self.client
        gc = client.get_container
        client.get_container = Mock()
        go = client.get_object
        bad = _swift_client.ClientException("Object GET failed: "
                "https://example.com/cont/some_object 404", http_status=404)
        client.get_object = Mock(side_effect=bad)
        # Note: we're using copy_object because it calls get_object().
        self.assertRaises(exc.NoSuchObject, client.copy_object,
                "some_container", "some_object", "fake")
        client.get_object = go
        client.get_container = gc

    def test_handle_swiftclient_exception_upload(self):
        client = self.client
        gc = client.get_container
        client.get_container = Mock()
        client.get_container.side_effect = _swift_client.ClientException(
                "Object PUT failed: foo/bar/baz 422 Unprocessable Entity")
        # Note: we're using delete_object because its first call
        # is get_container()
        self.assertRaises(exc.UploadFailed, client.delete_object,
                "some_container", "some_object")
        client.get_container = gc

    def test_handle_swiftclient_exception_others(self):
        client = self.client
        gc = client.get_container
        client.get_container = Mock()
        client.get_container.side_effect = _swift_client.ClientException(
                "Some other sort of error message")
        # Note: we're using delete_object because its first call
        # is get_container()
        self.assertRaises(_swift_client.ClientException, client.delete_object,
                "some_container", "some_object")
        client.get_container = gc

    def test_bulk_deleter(self):
        client = self.client
        container = self.cont_name
        object_names = utils.random_unicode()
        bd = FakeBulkDeleter(client, container, object_names)
        self.assertEqual(bd.client, client)
        self.assertEqual(bd.container, container)
        self.assertEqual(bd.object_names, object_names)

    def test_bulk_deleter_run(self):
        client = self.client
        container = self.cont_name
        object_names = utils.random_unicode()
        bd = FakeBulkDeleter(client, container, object_names)

        class FakeConn(object):
            pass

        class FakePath(object):
            path = utils.random_unicode()

        class FakeResp(object):
            status = utils.random_unicode()
            reason = utils.random_unicode()

        fpath = FakePath()
        conn = FakeConn()
        resp = FakeResp()
        # Need to make these ASCII, since some characters will confuse the
        # splitlines() call.
        num_del = random.randint(0, 100)
        num_not_found = random.randint(0, 100)
        status = utils.random_ascii()
        errors = utils.random_ascii()
        useless = utils.random_ascii()
        fake_read = """Number Deleted: %s
Number Not Found: %s
Response Status: %s
Errors: %s

Useless Line: %s
""" % (num_del, num_not_found, status, errors, useless)
        resp.read = Mock(return_value=fake_read)
        client.connection.http_connection = Mock(return_value=(fpath, conn))
        conn.request = Mock()
        conn.getresponse = Mock(return_value=resp)
        self.assertFalse(bd.completed)
        bd.actual_run()
        self.assertTrue(bd.completed)
        results = bd.results
        self.assertEqual(results.get("deleted"), num_del)
        self.assertEqual(results.get("not_found"), num_not_found)
        self.assertEqual(results.get("status"), status)
        self.assertEqual(results.get("errors"), errors)
        self.assertTrue(useless not in results.values())

    def test_converted_last_modified_times_head_and_list_match(self):
        head_last_modified_string = "Mon, 7 Apr 2014 17:34:25 UTC"
        list_last_modified_string = "2014-04-07T17:34:24.112333"
        converted_head_datetime = _convert_head_object_last_modified_to_local(
                head_last_modified_string)
        attdict = {"last_modified": list_last_modified_string}
        converted_list_attributes = _convert_list_last_modified_to_local(
                attdict=attdict)
        converted_list_date = converted_list_attributes["last_modified"]
        self.assertEqual(converted_head_datetime, converted_list_date)

    def test_list_last_mod_does_not_round_up_for_zero_microseconds(self):
        list_last_modified_string = "2014-04-07T17:34:24.000000"
        attdict = {"last_modified": list_last_modified_string}
        converted_list_attributes = _convert_list_last_modified_to_local(
                attdict=attdict)
        converted_list_date = converted_list_attributes["last_modified"]
        self.assertTrue(converted_list_date.endswith(":24"))


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_cf_container
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import random
import unittest

from mock import patch
from mock import MagicMock as Mock

import pyrax
from pyrax.cf_wrapper.client import _swift_client
from pyrax.cf_wrapper.container import Container
from pyrax.cf_wrapper.container import Fault
import pyrax.utils as utils
import pyrax.exceptions as exc
from pyrax.fakes import example_uri
from pyrax.fakes import fake_attdict
from pyrax.fakes import FakeContainer
from pyrax.fakes import FakeIdentity
from pyrax.fakes import FakeResponse
from pyrax.fakes import FakeStorageObject



class CF_ContainerTest(unittest.TestCase):
    def __init__(self, *args, **kwargs):
        reload(pyrax)
        self.orig_connect_to_cloudservers = pyrax.connect_to_cloudservers
        self.orig_connect_to_cloud_databases = pyrax.connect_to_cloud_databases
        ctclb = pyrax.connect_to_cloud_loadbalancers
        self.orig_connect_to_cloud_loadbalancers = ctclb
        ctcbs = pyrax.connect_to_cloud_blockstorage
        self.orig_connect_to_cloud_blockstorage = ctcbs
        super(CF_ContainerTest, self).__init__(*args, **kwargs)
        pyrax.identity = FakeIdentity()
        pyrax.connect_to_cloudservers = Mock()
        pyrax.connect_to_cloud_loadbalancers = Mock()
        pyrax.connect_to_cloud_databases = Mock()
        pyrax.connect_to_cloud_blockstorage = Mock()
        pyrax.set_credentials("fakeuser", "fakeapikey")

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def setUp(self):
        pyrax.connect_to_cloudservers = Mock()
        pyrax.connect_to_cloud_loadbalancers = Mock()
        pyrax.connect_to_cloud_databases = Mock()
        pyrax.connect_to_cloud_blockstorage = Mock()
        pyrax.connect_to_cloudfiles()
        self.client = pyrax.cloudfiles
        self.client.connection.head_container = Mock()
        self.cont_name = utils.random_ascii()
        self.container = self.client.get_container(self.cont_name)
        self.obj_name = utils.random_ascii()
        self.fake_object = FakeStorageObject(self.client, self.cont_name,
                self.obj_name)
        self.client._container_cache = {}
        self.container.object_cache = {}

    def tearDown(self):
        self.client = None
        self.container = None
        pyrax.connect_to_cloudservers = self.orig_connect_to_cloudservers
        pyrax.connect_to_cloud_databases = self.orig_connect_to_cloud_databases
        octclb = self.orig_connect_to_cloud_loadbalancers
        pyrax.connect_to_cloud_loadbalancers = octclb
        octcbs = self.orig_connect_to_cloud_blockstorage
        pyrax.connect_to_cloud_blockstorage = octcbs

    def test_fault(self):
        fault = Fault()
        self.assertFalse(fault)

    def test_fetch_cdn(self):
        self.client.connection.cdn_request = Mock()
        self.client.connection.cdn_connection = "fake"
        resp = FakeResponse()
        resp.status = 204
        resp.getheaders = Mock()
        test_uri = "http://example.com"
        test_ttl = "6666"
        test_ssl_uri = "http://ssl.example.com"
        test_streaming_uri = "http://streaming.example.com"
        test_ios_uri = "http://ios.example.com"
        test_log_retention = True
        resp.getheaders.return_value = [("x-cdn-uri", test_uri),
                ("x-ttl", test_ttl), ("x-cdn-ssl-uri", test_ssl_uri),
                ("x-cdn-streaming-uri", test_streaming_uri),
                ("x-cdn-ios-uri", test_ios_uri),
                ("x-log-retention", test_log_retention)]
        self.client.connection.cdn_request.return_value = resp
        # We need an actual container
        cont = Container(self.client, "realcontainer", 0, 0)
        self.assertEqual(cont.cdn_uri, test_uri)

    def test_fetch_cdn_not_found(self):
        self.client.connection.cdn_request = Mock()
        self.client.connection.cdn_connection = "fake"
        resp = FakeResponse()
        resp.status = 404
        resp.getheaders = Mock()
        test_uri = "http://example.com"
        test_ttl = "6666"
        test_ssl_uri = "http://ssl.example.com"
        test_streaming_uri = "http://streaming.example.com"
        test_ios_uri = "http://ios.example.com"
        test_log_retention = True
        resp.getheaders.return_value = []
        self.client.connection.cdn_request.return_value = resp
        # We need an actual container
        cont = Container(self.client, "realcontainer", 0, 0)
        self.assertIsNone(cont.cdn_uri)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_get_object_names(self):
        cont = self.container
        cont.client.get_container_object_names = Mock(return_value=["o1", "o2"])
        nms = cont.get_object_names()
        self.assertEqual(len(nms), 2)
        self.assert_("o1" in nms)
        self.assert_("o2" in nms)
        self.assert_("o3" not in nms)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_get_objects(self):
        cont = self.container
        cont.client.connection.get_container = Mock()
        cont.client.connection.get_container.return_value = ({},
                [{"name": "o1"}, {"name": "o2"}])
        objs = cont.get_objects()
        self.assertEqual(len(objs), 2)
        self.assert_("o1" in [objs[0].name, objs[1].name])

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_get_object(self):
        cont = self.container
        cont.client.connection.get_container = Mock()
        cont.client.connection.head_object = Mock(return_value=fake_attdict)
        obj = cont.get_object("fake")
        self.assertEqual(obj.name, "fake")

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_get_object_from_cache(self):
        cont = self.container
        cont.client.connection.get_container = Mock()
        cont.client.connection.head_object = Mock(return_value=fake_attdict)
        cnt = random.randint(2, 6)
        for ii in range(cnt):
            obj = cont.get_object("fake")
        self.assertEqual(cont.client.connection.head_object.call_count, 1)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_get_object_no_cache(self):
        cont = self.container
        cont.client.connection.get_container = Mock()
        cont.client.connection.head_object = Mock(return_value=fake_attdict)
        cnt = random.randint(2, 6)
        for ii in range(cnt):
            obj = cont.get_object("fake", cached=False)
        self.assertEqual(cont.client.connection.head_object.call_count, cnt)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_get_object_missing(self):
        cont = self.container
        cont.client.connection.get_container = Mock()
        side_effect = _swift_client.ClientException(
                "Object GET failed: https://example.com/cont/some_object 404")
        side_effect.http_status = 404
        cont.client.connection.head_object = Mock(side_effect=side_effect)
        self.assertRaises(exc.NoSuchObject, cont.get_object, "missing")

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_list_subdirs(self):
        cont = self.container
        clt = cont.client
        clt.list_container_subdirs = Mock()
        marker = utils.random_unicode()
        limit = utils.random_unicode()
        prefix = utils.random_unicode()
        delimiter = utils.random_unicode()
        full_listing = utils.random_unicode()
        cont.list_subdirs(marker=marker, limit=limit, prefix=prefix,
                delimiter=delimiter, full_listing=full_listing)
        clt.list_container_subdirs.assert_called_once_with(cont.name,
                marker=marker, limit=limit, prefix=prefix, delimiter=delimiter,
                full_listing=full_listing)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_store_object(self):
        cont = self.container
        cont.client.connection.head_container = Mock()
        cont.client.connection.put_object = Mock()
        gobj = cont.client.get_object
        cont.client.get_object = Mock(return_value=self.fake_object)
        content = "something"
        etag = utils.get_checksum(content)
        obj = cont.store_object(self.obj_name, content,
                content_type="test/test", etag=etag,
                content_encoding="gzip")
        self.assertEqual(cont.client.connection.put_object.call_count, 1)
        cont.client.get_object = gobj

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_upload_file(self):
        cont = self.container
        cont.client.connection.head_container = Mock()
        cont.client.connection.put_object = Mock()
        gobj = cont.client.get_object
        cont.client.get_object = Mock(return_value=self.fake_object)
        with utils.SelfDeletingTempfile() as tmpname:
            small_file_contents = "Test Value " * 25
            cont.client.max_file_size = len(small_file_contents) + 1
            with open(tmpname, "wb") as tmp:
                tmp.write(small_file_contents)
            fname = os.path.basename(tmpname)
            fake_type = "test/test"
            cont.upload_file(tmpname, content_type=fake_type)
            self.assertEqual(cont.client.connection.put_object.call_count, 1)
        cont.client.get_object = gobj

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_delete_object(self):
        cont = self.container
        client = cont.client
        cont.client.connection.head_container = Mock()
        cont.client.connection.delete_object = Mock()
        cont.delete_object(self.obj_name)
        cont.client.connection.delete_object.assert_called_with(self.cont_name,
                self.obj_name, response_dict=None)

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def test_delete_all_objects(self):
        cont = self.container
        client = cont.client
        cont.client.connection.head_container = Mock()
        cont.client.bulk_delete = Mock()
        cont.client.get_container_object_names = Mock(
                return_value=[self.obj_name])
        cont.delete_all_objects()
        cont.client.bulk_delete.assert_called_once_with(cont, [self.obj_name],
                async=False)

    def test_delete(self):
        cont = self.container
        cont.client.connection.delete_container = Mock()
        cont.delete()
        cont.client.connection.delete_container.assert_called_with(
                self.cont_name, response_dict=None)

    def test_fetch_object(self):
        cont = self.container
        cont.client.fetch_object = Mock()
        oname = utils.random_ascii()
        incmeta = random.choice((True, False))
        csize = random.randint(0, 1000)
        cont.fetch_object(oname, include_meta=incmeta, chunk_size=csize)
        cont.client.fetch_object.assert_called_once_with(cont, oname,
                include_meta=incmeta, chunk_size=csize)

    def test_download_object(self):
        cont = self.container
        cont.client.download_object = Mock()
        oname = utils.random_ascii()
        dname = utils.random_ascii()
        stru = random.choice((True, False))
        cont.download_object(oname, dname, structure=stru)
        cont.client.download_object.assert_called_once_with(cont, oname,
                dname, structure=stru)

    def test_get_metadata(self):
        cont = self.container
        cont.client.connection.head_container = Mock()
        cont.client.connection.head_container.return_value = {
                "X-Container-Meta-Foo": "yes", "Some-Other-Key": "no"}
        meta = cont.get_metadata()
        self.assert_(len(meta) == 1)
        self.assert_("X-Container-Meta-Foo" in meta)

    def test_set_metadata(self):
        cont = self.container
        cont.client.connection.post_container = Mock()
        cont.set_metadata({"newkey": "newval"})
        cont.client.connection.post_container.assert_called_with(cont.name,
                {"X-Container-Meta-newkey": "newval"}, response_dict=None)

    def test_set_metadata_prefix(self):
        cont = self.container
        cont.client.connection.post_container = Mock()
        prefix = utils.random_unicode()
        cont.set_metadata({"newkey": "newval"}, prefix=prefix)
        cont.client.connection.post_container.assert_called_with(cont.name,
                {"%snewkey" % prefix: "newval"}, response_dict=None)

    def test_remove_metadata_key(self):
        cont = self.container
        cont.client.remove_container_metadata_key = Mock()
        key = utils.random_unicode()
        prefix = utils.random_unicode()
        cont.remove_metadata_key(key, prefix=prefix)
        cont.client.remove_container_metadata_key.assert_called_once_with(cont,
                key, prefix=prefix)

    def test_set_web_index_page(self):
        cont = self.container
        page = "test_index.html"
        cont.client.connection.post_container = Mock()
        cont.set_web_index_page(page)
        cont.client.connection.post_container.assert_called_with(cont.name,
                {"X-Container-Meta-Web-Index": page}, response_dict=None)

    def test_set_web_error_page(self):
        cont = self.container
        page = "test_error.html"
        cont.client.connection.post_container = Mock()
        cont.set_web_error_page(page)
        cont.client.connection.post_container.assert_called_with(cont.name,
                {"X-Container-Meta-Web-Error": page}, response_dict=None)

    def test_make_public(self, ttl=None):
        cont = self.container
        cont.cdn_uri = ""
        cont.client.connection.cdn_request = Mock()
        cont.client.connection.cdn_connection = "fake"
        example = "http://example.com"
        ttl = 6666
        resp = FakeResponse()
        resp.headers = [("x-cdn-uri", example), ("c", "d")]
        cont.client.connection.cdn_request.return_value = resp
        cont.client.connection.cdn_connection = "fake"
        cont.make_public(ttl)
        cont.client.connection.cdn_request.assert_called_with("PUT",
                [cont.name], hdrs={"X-TTL": str(ttl), "X-CDN-Enabled": "True"})

    def test_make_private(self):
        cont = self.container
        cont.client.connection.cdn_request = Mock()
        cont.client.connection.cdn_connection = "fake"
        example = "http://example.com"
        cont.cdn_uri = example
        resp = FakeResponse()
        resp.headers = [("c", "d")]
        cont.client.connection.cdn_request.return_value = resp
        cont.client.connection.cdn_connection = "fake"
        cont.make_private()
        cont.client.connection.cdn_request.assert_called_with("PUT",
                [cont.name], hdrs={"X-CDN-Enabled": "False"})

    def test_copy_object(self):
        cont = self.container
        cont.client.copy_object = Mock()
        obj = utils.random_unicode()
        new_cont = utils.random_unicode()
        new_name = utils.random_unicode()
        extra_info = utils.random_unicode()
        cont.copy_object(obj, new_cont, new_obj_name=new_name,
                extra_info=extra_info)
        cont.client.copy_object.assert_called_once_with(cont, obj, new_cont,
                new_obj_name=new_name, extra_info=extra_info)

    def test_move_object(self):
        cont = self.container
        cont.client.move_object = Mock()
        obj = utils.random_unicode()
        new_cont = utils.random_unicode()
        new_name = utils.random_unicode()
        extra_info = utils.random_unicode()
        cont.move_object(obj, new_cont, new_obj_name=new_name,
                extra_info=extra_info)
        cont.client.move_object.assert_called_once_with(cont, obj, new_cont,
                new_obj_name=new_name, extra_info=extra_info)

    def test_change_object_content_type(self):
        cont = self.container
        cont.client.change_object_content_type = Mock()
        cont.change_object_content_type("fakeobj", "foo")
        cont.client.change_object_content_type.assert_called_once_with(cont,
                "fakeobj", new_ctype="foo", guess=False)

    def test_get_temp_url(self):
        cont = self.container
        nm = utils.random_ascii()
        sav = cont.name
        cont.name = utils.random_ascii()
        cont.client.get_temp_url = Mock()
        secs = random.randint(1, 1000)
        cont.get_temp_url(nm, seconds=secs)
        cont.client.get_temp_url.assert_called_with(cont, nm, seconds=secs,
                method="GET")
        cont.name = sav

    def test_delete_object_in_seconds(self):
        cont = self.container
        cont.client.delete_object_in_seconds = Mock()
        secs = random.randint(1, 1000)
        obj_name = utils.random_ascii()
        cont.delete_object_in_seconds(obj_name, secs)
        cont.client.delete_object_in_seconds.assert_called_once_with(cont,
                obj_name, secs)

        nm = utils.random_ascii()
        sav = cont.name
        cont.name = utils.random_ascii()
        cont.client.get_temp_url = Mock()
        secs = random.randint(1, 1000)
        cont.get_temp_url(nm, seconds=secs)
        cont.client.get_temp_url.assert_called_with(cont, nm, seconds=secs,
                method="GET")
        cont.name = sav

    def test_cdn_enabled(self):
        cont = self.container
        cont.cdn_uri = None
        self.assertFalse(cont.cdn_enabled)
        cont.cdn_uri = "http://example.com"
        self.assert_(cont.cdn_enabled)

    def test_cdn_ttl(self):
        cont = self.container
        ret = cont.cdn_ttl
        self.assertEqual(ret, self.client.default_cdn_ttl)

    def test_cdn_ssl_uri(self):
        cont = self.container
        ret = cont.cdn_ssl_uri
        self.assertIsNone(ret)


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_cf_storage_object
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import random
import unittest

from mock import patch
from mock import MagicMock as Mock

import pyrax
from pyrax.cf_wrapper.storage_object import StorageObject
import pyrax.exceptions as exc
import pyrax.utils as utils
from pyrax.fakes import fake_attdict
from pyrax.fakes import FakeContainer
from pyrax.fakes import FakeIdentity
from pyrax.fakes import FakeResponse



class CF_StorageObjectTest(unittest.TestCase):
    def __init__(self, *args, **kwargs):
        reload(pyrax)
        self.orig_connect_to_cloudservers = pyrax.connect_to_cloudservers
        self.orig_connect_to_cloudfiles = pyrax.connect_to_cloudfiles
        self.orig_connect_to_cloud_databases = pyrax.connect_to_cloud_databases
        ctclb = pyrax.connect_to_cloud_loadbalancers
        self.orig_connect_to_cloud_loadbalancers = ctclb
        ctcbs = pyrax.connect_to_cloud_blockstorage
        self.orig_connect_to_cloud_blockstorage = ctcbs
        super(CF_StorageObjectTest, self).__init__(*args, **kwargs)
        self.obj_name = "testobj"
        self.container_name = "testcont"
        pyrax.connect_to_cloudservers = Mock()
        pyrax.connect_to_cloud_loadbalancers = Mock()
        pyrax.connect_to_cloud_databases = Mock()
        pyrax.connect_to_cloud_blockstorage = Mock()

    @patch('pyrax.cf_wrapper.client.Container', new=FakeContainer)
    def setUp(self):
        pyrax.connect_to_cloudservers = Mock()
        pyrax.connect_to_cloud_loadbalancers = Mock()
        pyrax.connect_to_cloud_databases = Mock()
        pyrax.connect_to_cloud_blockstorage = Mock()
        pyrax.clear_credentials()
        pyrax.identity = FakeIdentity()
        pyrax.set_setting("region", None)
        pyrax.set_credentials("fakeuser", "fakeapikey")
        pyrax.connect_to_cloudfiles()
        self.client = pyrax.cloudfiles
        self.container = FakeContainer(self.client, self.container_name, 0, 0)
        self.container.name = self.container_name
        self.client.get_container = Mock(return_value=self.container)
        self.client.connection.get_container = Mock()
        self.client.connection.head_object = Mock(return_value=fake_attdict)
        self.storage_object = self.client.get_object(self.container, "testobj")
        self.client._container_cache = {}
        self.container.object_cache = {}

    def tearDown(self):
        self.client = None
        self.container = None
        self.storage_object = None
        pyrax.connect_to_cloudservers = self.orig_connect_to_cloudservers
        pyrax.connect_to_cloudfiles = self.orig_connect_to_cloudfiles
        pyrax.connect_to_cloud_databases = self.orig_connect_to_cloud_databases
        octclb = self.orig_connect_to_cloud_loadbalancers
        pyrax.connect_to_cloud_loadbalancers = octclb
        octcbs = self.orig_connect_to_cloud_blockstorage
        pyrax.connect_to_cloud_blockstorage = octcbs

    def test_init(self):
        cname = utils.random_unicode()
        oname = utils.random_unicode()
        ctype = utils.random_unicode()
        etag = utils.random_unicode()
        tbytes = random.randint(0, 1000)
        lmod = random.randint(0, 1000)
        cont = FakeContainer(self.client, cname, 0, 0)
        # Using container
        obj = StorageObject(self.client, cont, name=oname, total_bytes=tbytes,
                content_type=ctype, last_modified=lmod, etag=etag)
        self.assertEqual(obj.name, oname)
        self.assertEqual(obj.container, cont)
        self.assertEqual(obj.container.name, cname)
        self.assertEqual(obj.total_bytes, tbytes)
        self.assertEqual(obj.content_type, ctype)
        self.assertEqual(obj.last_modified, lmod)
        self.assertEqual(obj.etag, etag)
        # Using container name
        obj = StorageObject(self.client, cname, name=oname, total_bytes=tbytes,
                content_type=ctype, last_modified=lmod, etag=etag)
        # This will default to using the container defined in setUp().
        self.assertEqual(obj.container.name, self.container.name)

    def test_read_attdict(self):
        tname = "something"
        ttype = "foo/bar"
        tbytes = 12345
        tlastmodified = "2222-02-22T22:22:22.222222"
        tetag = "123123123"
        dct = {"name": tname, "content_type": ttype, "bytes": tbytes,
                "last_modified": tlastmodified, "hash": tetag}
        obj = self.storage_object
        obj._read_attdict(dct)
        self.assertEqual(obj.name, tname)
        self.assertEqual(obj.content_type, ttype)
        self.assertEqual(obj.total_bytes, tbytes)
        self.assertEqual(obj.last_modified, tlastmodified)
        self.assertEqual(obj.etag, tetag)

    def test_subdir(self):
        tname = "something"
        dct = {"subdir": tname}
        obj = self.storage_object
        obj._read_attdict(dct)
        self.assertEqual(obj.name, tname)

    def test_get(self):
        obj = self.storage_object
        obj.client.connection.get_object = Mock()
        meta = {"a": "b"}
        data = "This is the contents of the file"
        obj.client.connection.get_object.return_value = (meta, data)
        ret = obj.fetch()
        self.assertEqual(ret, data)
        ret = obj.fetch(include_meta=True)
        self.assertEqual(ret, (meta, data))

    def test_download(self):
        obj = self.storage_object
        obj.client.download_object = Mock()
        dname = utils.random_unicode()
        stru = random.choice((True, False))
        obj.download(dname, structure=stru)
        obj.client.download_object.assert_called_once_with(obj.container, obj,
                dname, structure=stru)

    def test_delete(self):
        obj = self.storage_object
        obj.client.connection.delete_object = Mock()
        obj.delete()
        obj.client.connection.delete_object.assert_called_with(
                obj.container.name, obj.name, response_dict=None)

    def test_purge(self):
        obj = self.storage_object
        cont = obj.container
        cont.cdn_uri = None
        self.assertRaises(exc.NotCDNEnabled, obj.purge)
        cont.cdn_uri = "http://example.com"
        obj.client.connection.cdn_request = Mock()
        obj.purge()
        obj.client.connection.cdn_request.assert_called_with("DELETE",
                [cont.name, obj.name], hdrs={})

    def test_get_metadata(self):
        obj = self.storage_object
        obj.client.connection.head_object = Mock()
        obj.client.connection.head_object.return_value = {
                "X-Object-Meta-Foo": "yes",
                "Some-Other-Key": "no"}
        meta = obj.get_metadata()
        self.assertEqual(meta, {"X-Object-Meta-Foo": "yes"})

    def test_set_metadata(self):
        obj = self.storage_object
        obj.client.connection.post_object = Mock()
        obj.client.connection.head_object = Mock(return_value={})
        obj.set_metadata({"newkey": "newval"})
        obj.client.connection.post_object.assert_called_with(obj.container.name,
                obj.name, {"X-Object-Meta-newkey": "newval"},
                response_dict=None)

    def test_set_metadata_prefix(self):
        obj = self.storage_object
        obj.client.connection.post_object = Mock()
        obj.client.connection.head_object = Mock(return_value={})
        prefix = utils.random_unicode()
        obj.set_metadata({"newkey": "newval"}, prefix=prefix)
        obj.client.connection.post_object.assert_called_with(obj.container.name,
                obj.name, {"%snewkey" % prefix: "newval"},
                response_dict=None)

    def test_remove_metadata_key(self):
        obj = self.storage_object
        obj.client.connection.post_object = Mock()
        obj.client.connection.head_object = Mock(return_value={})
        obj.remove_metadata_key("newkey")
        obj.client.connection.post_object.assert_called_with(obj.container.name,
                obj.name, {}, response_dict=None)

    def test_copy(self):
        obj = self.storage_object
        cont = obj.container
        cont.copy_object = Mock()
        new_cont = utils.random_unicode()
        new_name = utils.random_unicode()
        extra_info = utils.random_unicode()
        obj.copy(new_cont, new_obj_name=new_name, extra_info=extra_info)
        cont.copy_object.assert_called_once_with(obj, new_cont,
                new_obj_name=new_name, extra_info=extra_info)

    def test_move(self):
        obj = self.storage_object
        cont = obj.container
        cont.move_object = Mock()
        new_cont = utils.random_unicode()
        new_name = utils.random_unicode()
        extra_info = utils.random_unicode()
        obj.move(new_cont, new_obj_name=new_name, extra_info=extra_info)
        cont.move_object.assert_called_once_with(obj, new_cont,
                new_obj_name=new_name, extra_info=extra_info)

    def test_change_content_type(self):
        obj = self.storage_object
        obj.client.change_object_content_type = Mock()
        obj.change_content_type("foo")
        obj.client.change_object_content_type.assert_called_once_with(
                obj.container, obj, new_ctype="foo", guess=False)

    def test_get_temp_url(self):
        obj = self.storage_object
        obj.client.get_temp_url = Mock()
        secs = random.randint(1, 1000)
        obj.get_temp_url(seconds=secs)
        obj.client.get_temp_url.assert_called_with(obj.container, obj,
                seconds=secs, method="GET")

    def test_delete_in_seconds(self):
        obj = self.storage_object
        obj.client.connection.post_object = Mock()
        secs = random.randint(1, 1000)
        obj.delete_in_seconds(seconds=secs)
        obj.client.connection.post_object.assert_called_with(obj.container.name,
                obj.name, {'X-Delete-After': "%s" % secs}, response_dict=None)

    def test_repr(self):
        obj = self.storage_object
        rep = obj.__repr__()
        self.assert_("<Object " in rep)
        self.assert_(obj.name in rep)
        self.assert_(obj.content_type in rep)


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_client
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import datetime
import json
import os
import pkg_resources
import requests
import unittest
from urllib import quote

from mock import patch
from mock import MagicMock as Mock

import pyrax
import pyrax.utils as utils
import pyrax.exceptions as exc
from pyrax import client

from pyrax import fakes

DUMMY_URL = "http://example.com"
ID_CLS = pyrax.settings.get("identity_class") or pyrax.rax_identity.RaxIdentity


class ClientTest(unittest.TestCase):
    def __init__(self, *args, **kwargs):
        super(ClientTest, self).__init__(*args, **kwargs)

    def setUp(self):
        save_conf = client.BaseClient._configure_manager
        client.BaseClient._configure_manager = Mock()
        self.identity = pyrax.identity = ID_CLS()
        self.client = client.BaseClient(self.identity)
        client.BaseClient._configure_manager = save_conf
        self.client._manager = fakes.FakeManager()

    def tearDown(self):
        self.client = None

    def test_base_client(self):
        tenant_id = "faketenantid"
        auth_url = "fakeauthurl"
        region_name = "fakeregion"
        endpoint_type = "fakeenpointtype"
        management_url = "fakemanagementurl"
        auth_token = "fakeauthtoken"
        service_name = "fakeservicename"
        timings = "faketimings"
        no_cache = "fakenocache"
        http_log_debug = "fakehttplogdebug"
        timeout = "faketimeout"
        auth_system = "fakeauthsystem"

        save_conf = client.BaseClient._configure_manager
        client.BaseClient._configure_manager = Mock()
        bc = client.BaseClient(identity=self.identity, region_name=region_name,
                endpoint_type=endpoint_type, management_url=management_url,
                service_name=service_name, timings=timings,
                http_log_debug=http_log_debug, timeout=timeout,)

        self.assertEqual(bc.region_name, region_name)
        self.assertEqual(bc.endpoint_type, endpoint_type)
        self.assertEqual(bc.management_url, management_url)
        self.assertEqual(bc.service_name, service_name)
        self.assertEqual(bc.timings, timings)
        self.assertEqual(bc.http_log_debug, http_log_debug)
        self.assertEqual(bc.timeout, timeout)
        client.BaseClient._configure_manager = save_conf

    def test_configure_manager(self):
        self.assertRaises(NotImplementedError, client.BaseClient, self.identity)

    def test_list(self):
        mgr = self.client._manager
        sav = mgr.list
        mgr.list = Mock()
        self.client.list()
        mgr.list.assert_called_once_with(limit=None, marker=None)
        mgr.list = sav

    def test_list_limit(self):
        mgr = self.client._manager
        sav = mgr.list
        mgr.list = Mock()
        self.client.list(limit=10, marker="abc")
        mgr.list.assert_called_once_with(limit=10, marker="abc")
        mgr.list = sav

    def test_get(self):
        mgr = self.client._manager
        sav = mgr.get
        mgr.get = Mock()
        self.client.get("val")
        mgr.get.assert_called_once_with("val")
        mgr.get = sav

    def test_delete(self):
        mgr = self.client._manager
        sav = mgr.delete
        mgr.delete = Mock()
        self.client.delete("val")
        mgr.delete.assert_called_once_with("val")
        mgr.delete = sav

    def test_create(self):
        mgr = self.client._manager
        sav = mgr.create
        mgr.create = Mock()
        self.client.create("val")
        mgr.create.assert_called_once_with("val")
        mgr.create = sav

    def test_find(self):
        mgr = self.client._manager
        mgr.find = Mock()
        prop = utils.random_unicode()
        val = utils.random_unicode()
        self.client.find(prop=val)
        mgr.find.assert_called_once_with(prop=val)

    def test_findall(self):
        mgr = self.client._manager
        mgr.findall = Mock()
        prop = utils.random_unicode()
        val = utils.random_unicode()
        self.client.findall(prop=val)
        mgr.findall.assert_called_once_with(prop=val)

    def test_unauthenticate(self):
        clt = self.client
        id_svc = clt.identity
        clt.unauthenticate()
        self.assertEqual(id_svc.token, "")

    def test_get_timings(self):
        clt = self.client
        clt.times = expected = [1, 2, 3]
        self.assertEqual(clt.get_timings(), expected)

    def test_reset_timings(self):
        clt = self.client
        clt.times = [1, 2, 3]
        clt.reset_timings()
        self.assertEqual(clt.get_timings(), [])

    def test_get_limits(self):
        clt = self.client
        data = utils.random_unicode()
        clt.method_get = Mock(return_value=(None, data))
        ret = clt.get_limits()
        self.assertEqual(ret, data)

    def test_request_ok(self):
        clt = self.client
        clt.http_log_debug = False
        clt.timeout = utils.random_unicode()
        fakeresp = fakes.FakeResponse()
        fakeresp.status_code = 200
        body_content = {"one": 2, "three": 4}
        fake_uri = utils.random_unicode()
        fake_method = utils.random_unicode()
        sav = pyrax.http.request
        pyrax.http.request = Mock(return_value=(fakeresp, body_content))
        resp, body = clt.request(fake_uri, fake_method, body="text")
        self.assertTrue(isinstance(resp, fakes.FakeResponse))
        self.assertEqual(resp.status_code, 200)
        self.assertEqual(body, body_content)
        pyrax.http.request = sav

    def test_request_400(self):
        clt = self.client
        clt.http_log_debug = False
        fakeresp = fakes.FakeResponse()
        fakeresp.status_code = 400
        body_content = {"one": 2, "three": 4}
        fakebody = json.dumps(body_content)
        fake_uri = utils.random_unicode()
        fake_method = utils.random_unicode()
        sav = pyrax.http.request
        pyrax.http.request = Mock(return_value=(fakeresp, fakebody))
        savexc = exc.from_response
        exc.from_response = Mock(side_effect=fakes.FakeException)
        self.assertRaises(fakes.FakeException, clt.request, fake_uri,
                fake_method)
        exc.from_response = savexc
        pyrax.http.request = sav

    def test_request_no_json_resp(self):
        clt = self.client
        clt.http_log_debug = False
        fakeresp = fakes.FakeResponse()
        fakeresp.status_code = 400
        body_content = {"one": 2, "three": 4}
        fakebody = json.dumps(body_content)
        sav = pyrax.http.request
        # Test non-json response
        fakebody = "{{{{{{"
        fake_uri = utils.random_unicode()
        fake_method = utils.random_unicode()
        pyrax.http.request = Mock(return_value=(fakeresp, fakebody))
        savexc = exc.from_response
        exc.from_response = Mock(side_effect=fakes.FakeException)
        self.assertRaises(fakes.FakeException, clt.request, fake_uri,
                fake_method)
        exc.from_response = savexc
        pyrax.http.request = sav

    def test_request_empty_body(self):
        clt = self.client
        clt.http_log_debug = False
        fakeresp = fakes.FakeResponse()
        fakeresp.status_code = 400
        body_content = {"one": 2, "three": 4}
        fakebody = json.dumps(body_content)
        sav = pyrax.http.request
        fakebody = ""
        fake_uri = utils.random_unicode()
        fake_method = utils.random_unicode()
        pyrax.http.request = Mock(return_value=(fakeresp, fakebody))
        savexc = exc.from_response
        exc.from_response = Mock(side_effect=fakes.FakeException)
        self.assertRaises(fakes.FakeException, clt.request, fake_uri,
                fake_method)
        exc.from_response.assert_called_once_with(fakeresp, "")
        exc.from_response = savexc
        pyrax.http.request = sav

    def test_time_request(self):
        clt = self.client
        sav = clt.request
        clt.request = Mock()
        url = DUMMY_URL
        method = "PUT"
        clt.request(url, method)
        clt.request.assert_called_once_with(url, method)
        clt.request = sav

    def test_api_request_expired(self):
        clt = self.client
        id_svc = clt.identity
        sav_auth = id_svc.authenticate
        returns = [exc.Unauthorized(""), (fakes.FakeIdentityResponse(),
                fakes.fake_identity_response)]

        def auth_resp(*args, **kwargs):
            result = returns.pop(0)
            if isinstance(result, Exception):
                raise result
            return result

        id_svc.authenticate = Mock()
        sav_req = clt.request
        clt.request = Mock(side_effect=auth_resp)
        url = DUMMY_URL
        method = "PUT"
        clt.unauthenticate()
        clt.management_url = url
        id_svc.token = ""
        id_svc.tenant_id = utils.random_unicode()
        clt._api_request(url, method)
        self.assertEqual(id_svc.authenticate.call_count, 2)
        clt.request = sav_req
        id_svc.authenticate = sav_auth

    def test_api_request_not_authed(self):
        clt = self.client
        id_svc = clt.identity
        sav_auth = id_svc.authenticate
        id_svc.authenticate = Mock()
        sav_req = clt.request
        clt.request = Mock(return_value=(1, 1))
        url = DUMMY_URL
        method = "PUT"
        clt.unauthenticate()
        clt.management_url = url
        id_svc.token = ""
        id_svc.tenant_id = utils.random_unicode()
        clt._api_request(url, method)
        id_svc.authenticate.assert_called_once_with()
        clt.request = sav_req
        id_svc.authenticate = sav_auth

    def test_api_request_auth_failed(self):
        clt = self.client
        id_svc = clt.identity
        sav_auth = id_svc.authenticate
        id_svc.authenticate = Mock()
        sav_req = clt.request
        clt.request = Mock(return_value=(1, 1))
        url = DUMMY_URL
        method = "PUT"
        clt.request = Mock(side_effect=exc.Unauthorized(""))
        clt.management_url = clt.auth_token = "test"
        self.assertRaises(exc.Unauthorized, clt._api_request, url, method)
        clt.request = sav_req
        clt.authenticate = sav_auth

    def test_api_request_service_unavailable(self):
        clt = self.client
        id_svc = clt.identity
        sav_auth = id_svc.authenticate
        id_svc.authenticate = Mock()
        sav_req = clt.request
        clt.request = Mock(return_value=(1, 1))
        url = DUMMY_URL
        method = "GET"
        clt.request = Mock(side_effect=exc.Unauthorized(""))
        clt.management_url = ""
        self.assertRaises(exc.ServiceNotAvailable, clt._api_request, url,
                method)
        clt.request = sav_req
        id_svc.authenticate = sav_auth

    def test_api_request_url_quoting(self):
        clt = self.client
        id_svc = clt.identity
        sav_mgt = clt.management_url
        clt.management_url = "/FAKE"
        sav_auth = id_svc.authenticate
        id_svc.authenticate = Mock()
        sav_req = clt._time_request
        clt._time_request = Mock(return_value=((None, None)))
        uri = "/abc/def?fake@fake.com"
        expected = "%s%s" % (clt.management_url, quote(uri, safe="/.?="))
        clt._api_request(uri, "GET")
        clt._time_request.assert_called_once_with(expected, 'GET',
                headers={'X-Auth-Token': None})
        id_svc.authenticate = sav_auth
        clt._time_request = sav_req
        clt.management_url = sav_mgt

    def test_api_request_url_safe_quoting(self):
        clt = self.client
        id_svc = clt.identity
        sav_mgt = clt.management_url
        clt.management_url = "/FAKE"
        sav_auth = id_svc.authenticate
        id_svc.authenticate = Mock()
        sav_req = clt._time_request
        clt._time_request = Mock(return_value=((None, None)))
        uri = "/abc/def"
        expected = "%s%s" % (clt.management_url, quote(uri, safe="/.?="))
        clt._api_request(uri, "GET")
        clt._time_request.assert_called_once_with(expected, 'GET',
                headers={'X-Auth-Token': None})
        id_svc.authenticate = sav_auth
        clt._time_request = sav_req
        clt.management_url = sav_mgt

    def test_method_head(self):
        clt = self.client
        sav = clt._api_request
        clt._api_request = Mock()
        url = DUMMY_URL
        clt.method_head(url)
        clt._api_request.assert_called_once_with(url, "HEAD")
        clt._api_request = sav

    def test_method_get(self):
        clt = self.client
        sav = clt._api_request
        clt._api_request = Mock()
        url = DUMMY_URL
        clt.method_get(url)
        clt._api_request.assert_called_once_with(url, "GET")
        clt._api_request = sav

    def test_method_post(self):
        clt = self.client
        sav = clt._api_request
        clt._api_request = Mock()
        url = DUMMY_URL
        clt.method_post(url)
        clt._api_request.assert_called_once_with(url, "POST")
        clt._api_request = sav

    def test_method_put(self):
        clt = self.client
        sav = clt._api_request
        clt._api_request = Mock()
        url = DUMMY_URL
        clt.method_put(url)
        clt._api_request.assert_called_once_with(url, "PUT")
        clt._api_request = sav

    def test_method_delete(self):
        clt = self.client
        sav = clt._api_request
        clt._api_request = Mock()
        url = DUMMY_URL
        clt.method_delete(url)
        clt._api_request.assert_called_once_with(url, "DELETE")
        clt._api_request = sav

    def test_method_patch(self):
        clt = self.client
        sav = clt._api_request
        clt._api_request = Mock()
        url = DUMMY_URL
        clt.method_patch(url)
        clt._api_request.assert_called_once_with(url, "PATCH")
        clt._api_request = sav

    def test_authenticate(self):
        clt = self.client
        sav_auth = clt.identity.authenticate
        clt.identity.authenticate = Mock()
        ret = clt.authenticate()
        clt.identity.authenticate.assert_called_once_with()
        clt.identity.authenticate = sav_auth

    def test_project_id(self):
        clt = self.client
        id_svc = clt.identity
        id_svc.tenant_id = "FAKE"
        self.assertEqual(clt.projectid, "FAKE")


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_cloud_blockstorage
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import random
import unittest

from mock import patch
from mock import MagicMock as Mock

import pyrax.cloudblockstorage
from pyrax.cloudblockstorage import CloudBlockStorageClient
from pyrax.cloudblockstorage import CloudBlockStorageVolume
from pyrax.cloudblockstorage import CloudBlockStorageVolumeType
from pyrax.cloudblockstorage import CloudBlockStorageSnapshot
from pyrax.cloudblockstorage import CloudBlockStorageSnapshotManager
from pyrax.cloudblockstorage import _resolve_id
from pyrax.cloudblockstorage import _resolve_name
from pyrax.cloudblockstorage import assure_volume
from pyrax.cloudblockstorage import assure_snapshot
from pyrax.cloudblockstorage import MIN_SIZE
from pyrax.cloudblockstorage import MAX_SIZE
import pyrax.exceptions as exc
from pyrax.manager import BaseManager
import pyrax.utils as utils

from pyrax import fakes

example_uri = "http://example.com"


class CloudBlockStorageTest(unittest.TestCase):
    def __init__(self, *args, **kwargs):
        super(CloudBlockStorageTest, self).__init__(*args, **kwargs)

    def setUp(self):
        self.client = fakes.FakeBlockStorageClient()
        self.volume = fakes.FakeBlockStorageVolume()
        self.snapshot = fakes.FakeBlockStorageSnapshot()

    def tearDown(self):
        pass

    def test_resolve_id(self):
        target = "test_id"

        class Obj_with_id(object):
            id = target

        obj = Obj_with_id()
        self.assertEqual(_resolve_id(obj), target)
        self.assertEqual(_resolve_id(obj), target)
        self.assertEqual(_resolve_id(obj.id), target)

    def test_resolve_name(self):
        target = "test_name"

        class Obj_with_name(object):
            name = target

        obj = Obj_with_name()
        self.assertEqual(_resolve_name(obj), target)
        self.assertEqual(_resolve_name(obj), target)
        self.assertEqual(_resolve_name(obj.name), target)

    def test_assure_volume(self):
        class TestClient(object):
            _manager = fakes.FakeManager()

            @assure_volume
            def test_method(self, volume):
                return volume

        client = TestClient()
        client._manager.get = Mock(return_value=self.volume)
        # Pass the volume
        ret = client.test_method(self.volume)
        self.assertTrue(ret is self.volume)
        # Pass the ID
        ret = client.test_method(self.volume.id)
        self.assertTrue(ret is self.volume)

    def test_assure_snapshot(self):
        class TestClient(object):
            _snapshot_manager = fakes.FakeManager()

            @assure_snapshot
            def test_method(self, snapshot):
                return snapshot

        client = TestClient()
        client._snapshot_manager.get = Mock(return_value=self.snapshot)
        # Pass the snapshot
        ret = client.test_method(self.snapshot)
        self.assertTrue(ret is self.snapshot)
        # Pass the ID
        ret = client.test_method(self.snapshot.id)
        self.assertTrue(ret is self.snapshot)

    def test_create_volume(self):
        mgr = fakes.FakeManager()
        mgr.api.region_name = "FAKE"
        sav = pyrax.connect_to_cloudservers
        fakenovavol = utils.random_unicode()

        class FakeVol(object):
            def __init__(self, *args, **kwargs):
                self.volumes = fakenovavol

        pyrax.connect_to_cloudservers = Mock(return_value=FakeVol())
        vol = CloudBlockStorageVolume(mgr, {})
        self.assertTrue(isinstance(vol, CloudBlockStorageVolume))
        self.assertEqual(vol._nova_volumes, fakenovavol)
        pyrax.connect_to_cloudservers = sav

    def test_attach_to_instance(self):
        vol = self.volume
        inst = fakes.FakeServer()
        mp = utils.random_unicode()
        vol._nova_volumes.create_server_volume = Mock(return_value=vol)
        vol.attach_to_instance(inst, mp)
        vol._nova_volumes.create_server_volume.assert_called_once_with(inst.id,
                vol.id, mp)

    def test_attach_to_instance_fail(self):
        vol = self.volume
        inst = fakes.FakeServer()
        mp = utils.random_unicode()
        vol._nova_volumes.create_server_volume = Mock(
                side_effect=Exception("test"))
        self.assertRaises(exc.VolumeAttachmentFailed, vol.attach_to_instance,
                inst, mp)

    def test_detach_from_instance(self):
        vol = self.volume
        srv_id = utils.random_unicode()
        att_id = utils.random_unicode()
        vol.attachments = [{"server_id": srv_id, "id": att_id}]
        vol._nova_volumes.delete_server_volume = Mock()
        vol.detach()
        vol._nova_volumes.delete_server_volume.assert_called_once_with(srv_id,
                att_id)

    def test_detach_from_instance_fail(self):
        vol = self.volume
        srv_id = utils.random_unicode()
        att_id = utils.random_unicode()
        vol.attachments = [{"server_id": srv_id, "id": att_id}]
        vol._nova_volumes.delete_server_volume = Mock(
                side_effect=Exception("test"))
        self.assertRaises(exc.VolumeDetachmentFailed, vol.detach)

    def test_detach_from_instance_no_attachment(self):
        vol = self.volume
        srv_id = utils.random_unicode()
        att_id = utils.random_unicode()
        vol.attachments = []
        vol._nova_volumes.delete_server_volume = Mock()
        ret = vol.detach()
        self.assertTrue(ret is None)
        self.assertFalse(vol._nova_volumes.delete_server_volume.called)

    def test_create_snapshot(self):
        vol = self.volume
        vol.manager.create_snapshot = Mock()
        name = utils.random_unicode()
        desc = utils.random_unicode()
        vol.create_snapshot(name=name, description=desc, force=False)
        vol.manager.create_snapshot.assert_called_once_with(volume=vol,
                name=name, description=desc, force=False)

    def test_create_snapshot_bad_request(self):
        vol = self.volume
        sav = BaseManager.create
        BaseManager.create = Mock(side_effect=exc.BadRequest(
                "Invalid volume: must be available"))
        name = utils.random_unicode()
        desc = utils.random_unicode()
        self.assertRaises(exc.VolumeNotAvailable, vol.create_snapshot,
                name=name, description=desc, force=False)
        BaseManager.create = sav

    def test_create_snapshot_bad_request_other(self):
        vol = self.volume
        sav = BaseManager.create
        BaseManager.create = Mock(side_effect=exc.BadRequest("FAKE"))
        name = utils.random_unicode()
        desc = utils.random_unicode()
        self.assertRaises(exc.BadRequest, vol.create_snapshot,
                name=name, description=desc, force=False)
        BaseManager.create = sav

    def test_update_volume(self):
        clt = self.client
        vol = self.volume
        mgr = clt._manager
        mgr.api.method_put = Mock(return_value=(None, None))
        name = utils.random_unicode()
        desc = utils.random_unicode()
        exp_uri = "/%s/%s" % (mgr.uri_base, vol.id)
        exp_body = {"volume": {"display_name": name,
                "display_description": desc}}
        mgr.update(vol, display_name=name, display_description=desc)
        mgr.api.method_put.assert_called_once_with(exp_uri, body=exp_body)

    def test_update_volume_empty(self):
        clt = self.client
        vol = self.volume
        mgr = clt._manager
        mgr.api.method_put = Mock(return_value=(None, None))
        mgr.update(vol)
        self.assertEqual(mgr.api.method_put.call_count, 0)

    def test_list_types(self):
        clt = self.client
        clt._types_manager.list = Mock()
        clt.list_types()
        clt._types_manager.list.assert_called_once_with()

    def test_list_snapshots(self):
        clt = self.client
        clt._snapshot_manager.list = Mock()
        clt.list_snapshots()
        clt._snapshot_manager.list.assert_called_once_with()

    def test_vol_list_snapshots(self):
        vol = self.volume
        vol.manager.list_snapshots = Mock()
        vol.list_snapshots()
        vol.manager.list_snapshots.assert_called_once_with()

    def test_vol_mgr_list_snapshots(self):
        vol = self.volume
        mgr = vol.manager
        mgr.api.list_snapshots = Mock()
        mgr.list_snapshots()
        mgr.api.list_snapshots.assert_called_once_with()

    def test_create_body_volume_bad_size(self):
        mgr = self.client._manager
        self.assertRaises(exc.InvalidSize, mgr._create_body, "name",
                size=MIN_SIZE - 1)
        self.assertRaises(exc.InvalidSize, mgr._create_body, "name",
                size=MAX_SIZE + 1)

    def test_create_volume_bad_clone_size(self):
        mgr = self.client._manager
        mgr._create = Mock(side_effect=exc.BadRequest(400,
                "Clones currently must be >= original volume size"))
        self.assertRaises(exc.VolumeCloneTooSmall, mgr.create, "name",
                size=MIN_SIZE, clone_id=utils.random_unicode())

    def test_create_volume_fail_other(self):
        mgr = self.client._manager
        mgr._create = Mock(side_effect=exc.BadRequest(400, "FAKE"))
        self.assertRaises(exc.BadRequest, mgr.create, "name",
                size=MIN_SIZE, clone_id=utils.random_unicode())

    def test_create_body_volume(self):
        mgr = self.client._manager
        size = random.randint(MIN_SIZE, MAX_SIZE)
        name = utils.random_unicode()
        snapshot_id = utils.random_unicode()
        clone_id = utils.random_unicode()
        display_description = None
        volume_type = None
        metadata = None
        availability_zone = utils.random_unicode()
        fake_body = {"volume": {
                "size": size,
                "snapshot_id": snapshot_id,
                "source_volid": clone_id,
                "display_name": name,
                "display_description": "",
                "volume_type": "SATA",
                "metadata": {},
                "availability_zone": availability_zone,
                }}
        ret = mgr._create_body(name=name, size=size, volume_type=volume_type,
                description=display_description, metadata=metadata,
                snapshot_id=snapshot_id, clone_id=clone_id,
                availability_zone=availability_zone)
        self.assertEqual(ret, fake_body)

    def test_create_body_volume_defaults(self):
        mgr = self.client._manager
        size = random.randint(MIN_SIZE, MAX_SIZE)
        name = utils.random_unicode()
        snapshot_id = utils.random_unicode()
        clone_id = utils.random_unicode()
        display_description = utils.random_unicode()
        volume_type = utils.random_unicode()
        metadata = {}
        availability_zone = utils.random_unicode()
        fake_body = {"volume": {
                "size": size,
                "snapshot_id": snapshot_id,
                "source_volid": clone_id,
                "display_name": name,
                "display_description": display_description,
                "volume_type": volume_type,
                "metadata": metadata,
                "availability_zone": availability_zone,
                }}
        ret = mgr._create_body(name=name, size=size, volume_type=volume_type,
                description=display_description, metadata=metadata,
                snapshot_id=snapshot_id, clone_id=clone_id,
                availability_zone=availability_zone)
        self.assertEqual(ret, fake_body)

    def test_create_body_snapshot(self):
        mgr = self.client._snapshot_manager
        vol = self.volume
        name = utils.random_unicode()
        display_description = utils.random_unicode()
        force = True
        fake_body = {"snapshot": {
                "display_name": name,
                "display_description": display_description,
                "volume_id": vol.id,
                "force": str(force).lower(),
                }}
        ret = mgr._create_body(name=name, description=display_description,
                volume=vol, force=force)
        self.assertEqual(ret, fake_body)

    def test_client_attach_to_instance(self):
        clt = self.client
        vol = self.volume
        inst = fakes.FakeServer()
        mp = utils.random_unicode()
        vol.attach_to_instance = Mock()
        clt.attach_to_instance(vol, inst, mp)
        vol.attach_to_instance.assert_called_once_with(inst, mp)

    def test_client_detach(self):
        clt = self.client
        vol = self.volume
        vol.detach = Mock()
        clt.detach(vol)
        vol.detach.assert_called_once_with()

    def test_client_delete_volume(self):
        clt = self.client
        vol = self.volume
        vol.delete = Mock()
        clt.delete_volume(vol)
        vol.delete.assert_called_once_with(force=False)

    def test_client_delete_volume_not_available(self):
        clt = self.client
        vol = self.volume
        vol.manager.delete = Mock(side_effect=exc.VolumeNotAvailable(""))
        self.assertRaises(exc.VolumeNotAvailable, clt.delete_volume, vol)

    def test_client_delete_volume_force(self):
        clt = self.client
        vol = self.volume
        vol.manager.delete = Mock()
        vol.detach = Mock()
        vol.delete_all_snapshots = Mock()
        clt.delete_volume(vol, force=True)
        vol.manager.delete.assert_called_once_with(vol)
        vol.detach.assert_called_once_with()
        vol.delete_all_snapshots.assert_called_once_with()

    def test_volume_delete_all_snapshots(self):
        vol = self.volume
        snap = fakes.FakeBlockStorageSnapshot()
        snap.delete = Mock()
        vol.list_snapshots = Mock(return_value=[snap])
        vol.delete_all_snapshots()
        snap.delete.assert_called_once_with()

    def test_client_snap_mgr_create_snapshot(self):
        clt = self.client
        vol = self.volume
        name = utils.random_ascii()
        description = utils.random_ascii()
        mgr = clt._snapshot_manager
        snap = fakes.FakeBlockStorageSnapshot()
        mgr._create = Mock(return_value=snap)
        ret = mgr.create(name, vol, description=description, force=True)
        self.assertTrue(isinstance(ret, CloudBlockStorageSnapshot))

    def test_client_create_snapshot(self):
        clt = self.client
        vol = self.volume
        name = utils.random_unicode()
        description = utils.random_unicode()
        clt._snapshot_manager.create = Mock()
        clt.create_snapshot(vol, name=name, description=description,
                force=True)
        clt._snapshot_manager.create.assert_called_once_with(volume=vol,
                name=name, description=description, force=True)

    def test_client_create_snapshot_not_available(self):
        clt = self.client
        vol = self.volume
        name = utils.random_unicode()
        description = utils.random_unicode()
        cli_exc = exc.ClientException(409, "Request conflicts with in-progress")
        sav = BaseManager.create
        BaseManager.create = Mock(side_effect=cli_exc)
        self.assertRaises(exc.VolumeNotAvailable, clt.create_snapshot, vol,
                name=name, description=description)
        BaseManager.create = sav

    def test_client_create_snapshot_409_other(self):
        clt = self.client
        vol = self.volume
        name = utils.random_unicode()
        description = utils.random_unicode()
        cli_exc = exc.ClientException(409, "FAKE")
        sav = BaseManager.create
        BaseManager.create = Mock(side_effect=cli_exc)
        self.assertRaises(exc.ClientException, clt.create_snapshot, vol,
                name=name, description=description)
        BaseManager.create = sav

    def test_client_create_snapshot_not_409(self):
        clt = self.client
        vol = self.volume
        name = utils.random_unicode()
        description = utils.random_unicode()
        cli_exc = exc.ClientException(420, "FAKE")
        sav = BaseManager.create
        BaseManager.create = Mock(side_effect=cli_exc)
        self.assertRaises(exc.ClientException, clt.create_snapshot, vol,
                name=name, description=description)
        BaseManager.create = sav

    def test_client_delete_snapshot(self):
        clt = self.client
        snap = fakes.FakeBlockStorageSnapshot()
        snap.delete = Mock()
        clt.delete_snapshot(snap)
        snap.delete.assert_called_once_with()

    def test_snapshot_delete(self):
        snap = self.snapshot
        snap.manager.delete = Mock()
        snap.delete()
        snap.manager.delete.assert_called_once_with(snap)

    def test_snapshot_delete_unavailable(self):
        snap = self.snapshot
        snap.status = "busy"
        self.assertRaises(exc.SnapshotNotAvailable, snap.delete)

    def test_snapshot_delete_retry(self):
        snap = self.snapshot
        snap.manager.delete = Mock(side_effect=exc.ClientException(
                "Request conflicts with in-progress 'DELETE"))
        pyrax.cloudblockstorage.RETRY_INTERVAL = 0.1
        self.assertRaises(exc.ClientException, snap.delete)

    def test_volume_name_property(self):
        vol = self.volume
        nm = utils.random_unicode()
        vol.display_name = nm
        self.assertEqual(vol.name, vol.display_name)
        nm = utils.random_unicode()
        vol.name = nm
        self.assertEqual(vol.name, vol.display_name)

    def test_volume_description_property(self):
        vol = self.volume
        nm = utils.random_unicode()
        vol.display_description = nm
        self.assertEqual(vol.description, vol.display_description)
        nm = utils.random_unicode()
        vol.description = nm
        self.assertEqual(vol.description, vol.display_description)

    def test_snapshot_name_property(self):
        snap = self.snapshot
        nm = utils.random_unicode()
        snap.display_name = nm
        self.assertEqual(snap.name, snap.display_name)
        nm = utils.random_unicode()
        snap.name = nm
        self.assertEqual(snap.name, snap.display_name)

    def test_snapshot_description_property(self):
        snap = self.snapshot
        nm = utils.random_unicode()
        snap.display_description = nm
        self.assertEqual(snap.description, snap.display_description)
        nm = utils.random_unicode()
        snap.description = nm
        self.assertEqual(snap.description, snap.display_description)

    def test_update_snapshot(self):
        clt = self.client
        snap = self.snapshot
        mgr = clt._snapshot_manager
        mgr.api.method_put = Mock(return_value=(None, None))
        name = utils.random_unicode()
        desc = utils.random_unicode()
        exp_uri = "/%s/%s" % (mgr.uri_base, snap.id)
        exp_body = {"snapshot": {"display_name": name,
                "display_description": desc}}
        mgr.update(snap, display_name=name, display_description=desc)
        mgr.api.method_put.assert_called_once_with(exp_uri, body=exp_body)

    def test_update_snapshot_empty(self):
        clt = self.client
        snap = self.snapshot
        mgr = clt._snapshot_manager
        mgr.api.method_put = Mock(return_value=(None, None))
        mgr.update(snap)
        self.assertEqual(mgr.api.method_put.call_count, 0)

    def test_clt_update_volume(self):
        clt = self.client
        vol = self.volume
        name = utils.random_unicode()
        desc = utils.random_unicode()
        clt._manager.update = Mock()
        clt.update(vol, display_name=name, display_description=desc)
        clt._manager.update.assert_called_once_with(vol, display_name=name,
                display_description=desc)

    def test_clt_update_snapshot(self):
        clt = self.client
        snap = self.snapshot
        name = utils.random_unicode()
        desc = utils.random_unicode()
        clt._snapshot_manager.update = Mock()
        clt.update_snapshot(snap, display_name=name, display_description=desc)
        clt._snapshot_manager.update.assert_called_once_with(snap,
                display_name=name, display_description=desc)

    def test_get_snapshot(self):
        clt = self.client
        mgr = clt._snapshot_manager
        mgr.get = Mock()
        snap = utils.random_unicode()
        clt.get_snapshot(snap)
        mgr.get.assert_called_once_with(snap)


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_cloud_databases
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import unittest

from mock import patch
from mock import MagicMock as Mock

from pyrax.clouddatabases import CloudDatabaseBackupManager
from pyrax.clouddatabases import CloudDatabaseDatabase
from pyrax.clouddatabases import CloudDatabaseFlavor
from pyrax.clouddatabases import CloudDatabaseInstance
from pyrax.clouddatabases import CloudDatabaseUser
from pyrax.clouddatabases import CloudDatabaseVolume
from pyrax.clouddatabases import assure_instance
import pyrax.exceptions as exc
from pyrax.resource import BaseResource
import pyrax.utils as utils

from pyrax import fakes

example_uri = "http://example.com"


class CloudDatabasesTest(unittest.TestCase):
    def __init__(self, *args, **kwargs):
        super(CloudDatabasesTest, self).__init__(*args, **kwargs)

    def setUp(self):
        self.instance = fakes.FakeDatabaseInstance()
        self.client = fakes.FakeDatabaseClient()

    def tearDown(self):
        pass

    def test_assure_instance(self):
        class TestClient(object):
            _manager = fakes.FakeManager()

            @assure_instance
            def test_method(self, instance):
                return instance

        client = TestClient()
        client._manager.get = Mock(return_value=self.instance)
        # Pass the instance
        ret = client.test_method(self.instance)
        self.assertTrue(ret is self.instance)
        # Pass the ID
        ret = client.test_method(self.instance.id)
        self.assertTrue(ret is self.instance)

    @patch("pyrax.manager.BaseManager", new=fakes.FakeManager)
    def test_instantiate_instance(self):
        inst = CloudDatabaseInstance(fakes.FakeManager(), {"id": 42,
                "volume": {"size": 1, "used": 0.2}})
        self.assertTrue(isinstance(inst, CloudDatabaseInstance))
        self.assertTrue(isinstance(inst.volume, CloudDatabaseVolume))

    def test_list_databases(self):
        inst = self.instance
        inst._database_manager.list = Mock()
        limit = utils.random_unicode()
        marker = utils.random_unicode()
        inst.list_databases(limit=limit, marker=marker)
        inst._database_manager.list.assert_called_once_with(limit=limit,
                marker=marker)

    def test_list_users(self):
        inst = self.instance
        inst._user_manager.list = Mock()
        limit = utils.random_unicode()
        marker = utils.random_unicode()
        inst.list_users(limit=limit, marker=marker)
        inst._user_manager.list.assert_called_once_with(limit=limit,
                marker=marker)

    def test_get_database(self):
        inst = self.instance
        db1 = fakes.FakeEntity()
        db1.name = "a"
        db2 = fakes.FakeEntity()
        db2.name = "b"
        inst.list_databases = Mock(return_value=[db1, db2])
        ret = inst.get_database("a")
        self.assertEqual(ret, db1)

    def test_get_database_bad(self):
        inst = self.instance
        db1 = fakes.FakeEntity()
        db1.name = "a"
        db2 = fakes.FakeEntity()
        db2.name = "b"
        inst.list_databases = Mock(return_value=[db1, db2])
        self.assertRaises(exc.NoSuchDatabase, inst.get_database, "z")

    def test_dbmgr_get(self):
        mgr = fakes.FakeDatabaseManager()
        rsrc = fakes.FakeDatabaseInstance()
        rsrc.volume = {}
        mgr._get = Mock(return_value=rsrc)
        ret = mgr.get("fake")
        self.assertTrue(isinstance(ret, CloudDatabaseInstance))
        self.assertTrue(isinstance(ret.volume, CloudDatabaseVolume))

    def test_dbmgr_create_backup(self):
        inst = self.instance
        mgr = inst.manager
        name = utils.random_unicode()
        description = utils.random_unicode()
        mgr.api.method_post = Mock(return_value=(None, {"backup": {}}))
        expected_uri = "/backups"
        expected_body = {"backup": {"instance": inst.id, "name": name,
                "description": description}}
        mgr.create_backup(inst, name, description=description)
        mgr.api.method_post.assert_called_once_with(expected_uri,
                body=expected_body)

    @patch('pyrax.clouddatabases.CloudDatabaseInstance',
            new=fakes.FakeDatabaseInstance)
    def test_mgr_restore_backup(self):
        inst = self.instance
        mgr = inst.manager
        name = utils.random_unicode()
        flavor = utils.random_unicode()
        fref = utils.random_unicode()
        volume = utils.random_unicode()
        backup = utils.random_unicode()
        mgr.api.method_post = Mock(return_value=(None, {"instance": {}}))
        mgr.api._get_flavor_ref = Mock(return_value=fref)
        expected_uri = "/%s" % mgr.uri_base
        expected_body = {"instance": {"name": name, "flavorRef": fref,
                "volume": {"size": volume}, "restorePoint":
                {"backupRef": backup}}}
        mgr.restore_backup(backup, name, flavor, volume)
        mgr.api.method_post.assert_called_once_with(expected_uri,
                body=expected_body)

    def test_mgr_list_backups(self):
        inst = self.instance
        mgr = inst.manager
        mgr.api._backup_manager.list = Mock(return_value=(None, None))
        mgr.list_backups(inst)
        mgr.api._backup_manager.list.assert_called_once_with(instance=inst)

    def test_mgr_list_backups_for_instance(self):
        inst = self.instance
        mgr = inst.manager
        mgr.api.method_get = Mock(return_value=(None, {"backups": []}))
        expected_uri = "/%s/%s/backups" % (mgr.uri_base, inst.id)
        mgr._list_backups_for_instance(inst)
        mgr.api.method_get.assert_called_once_with(expected_uri)

    def test_create_database(self):
        inst = self.instance
        inst._database_manager.create = Mock()
        inst._database_manager.find = Mock()
        db = inst.create_database(name="test")
        inst._database_manager.create.assert_called_once_with(name="test",
                character_set="utf8", collate="utf8_general_ci",
                return_none=True)

    def test_create_user(self):
        inst = self.instance
        inst._user_manager.create = Mock()
        inst._user_manager.find = Mock()
        name = utils.random_unicode()
        password = utils.random_unicode()
        database_names = utils.random_unicode()
        host = utils.random_unicode()
        inst.create_user(name=name, password=password,
                database_names=database_names, host=host)
        inst._user_manager.create.assert_called_once_with(name=name,
                password=password, database_names=[database_names], host=host,
                return_none=True)

    def test_delete_database(self):
        inst = self.instance
        inst._database_manager.delete = Mock()
        inst.delete_database("dbname")
        inst._database_manager.delete.assert_called_once_with("dbname")

    def test_delete_user(self):
        inst = self.instance
        inst._user_manager.delete = Mock()
        inst.delete_user("username")
        inst._user_manager.delete.assert_called_once_with("username")

    def test_delete_database_direct(self):
        inst = self.instance
        mgr = inst.manager
        name = utils.random_unicode()
        db = CloudDatabaseDatabase(mgr, info={"name": name})
        mgr.delete = Mock()
        db.delete()
        mgr.delete.assert_called_once_with(name)

    def test_delete_user_direct(self):
        inst = self.instance
        mgr = inst.manager
        name = utils.random_unicode()
        user = CloudDatabaseUser(mgr, info={"name": name})
        mgr.delete = Mock()
        user.delete()
        mgr.delete.assert_called_once_with(name)

    def test_enable_root_user(self):
        inst = self.instance
        pw = utils.random_unicode()
        fake_body = {"user": {"password": pw}}
        inst.manager.api.method_post = Mock(return_value=(None, fake_body))
        ret = inst.enable_root_user()
        call_uri = "/instances/%s/root" % inst.id
        inst.manager.api.method_post.assert_called_once_with(call_uri)
        self.assertEqual(ret, pw)

    def test_root_user_status(self):
        inst = self.instance
        fake_body = {"rootEnabled": True}
        inst.manager.api.method_get = Mock(return_value=(None, fake_body))
        ret = inst.root_user_status()
        call_uri = "/instances/%s/root" % inst.id
        inst.manager.api.method_get.assert_called_once_with(call_uri)
        self.assertTrue(ret)

    def test_restart(self):
        inst = self.instance
        inst.manager.action = Mock()
        ret = inst.restart()
        inst.manager.action.assert_called_once_with(inst, "restart")

    def test_resize(self):
        inst = self.instance
        flavor_ref = utils.random_unicode()
        inst.manager.api._get_flavor_ref = Mock(return_value=flavor_ref)
        fake_body = {"flavorRef": flavor_ref}
        inst.manager.action = Mock()
        ret = inst.resize(42)
        call_uri = "/instances/%s/action" % inst.id
        inst.manager.action.assert_called_once_with(inst, "resize",
                body=fake_body)

    def test_resize_volume_too_small(self):
        inst = self.instance
        inst.volume.get = Mock(return_value=2)
        self.assertRaises(exc.InvalidVolumeResize, inst.resize_volume, 1)

    def test_resize_volume(self):
        inst = self.instance
        fake_body = {"volume": {"size": 2}}
        inst.manager.action = Mock()
        ret = inst.resize_volume(2)
        inst.manager.action.assert_called_once_with(inst, "resize",
                body=fake_body)

    def test_resize_volume_direct(self):
        inst = self.instance
        vol = inst.volume
        fake_body = {"volume": {"size": 2}}
        inst.manager.action = Mock()
        ret = vol.resize(2)
        inst.manager.action.assert_called_once_with(inst, "resize",
                body=fake_body)

    def test_volume_get(self):
        inst = self.instance
        vol = inst.volume
        att = vol.size
        using_get = vol.get("size")
        self.assertEqual(att, using_get)

    def test_volume_get_fail(self):
        inst = self.instance
        vol = inst.volume
        self.assertRaises(AttributeError, vol.get, "fake")

    def test_inst_list_backups(self):
        inst = self.instance
        mgr = inst.manager
        mgr._list_backups_for_instance = Mock()
        inst.list_backups()
        mgr._list_backups_for_instance.assert_called_once_with(inst)

    def test_inst_create_backup(self):
        inst = self.instance
        mgr = inst.manager
        name = utils.random_unicode()
        description = utils.random_unicode()
        mgr.create_backup = Mock()
        inst.create_backup(name, description=description)
        mgr.create_backup.assert_called_once_with(inst, name,
                description=description)

    def test_get_flavor_property(self):
        inst = self.instance
        inst._loaded = True
        flavor = inst.flavor
        self.assertTrue(isinstance(flavor, CloudDatabaseFlavor))

    def test_set_flavor_property_dict(self):
        inst = self.instance
        inst._loaded = True
        inst.flavor = {"name": "test"}
        self.assertTrue(isinstance(inst.flavor, CloudDatabaseFlavor))

    def test_set_flavor_property_instance(self):
        inst = self.instance
        inst._loaded = True
        flavor = CloudDatabaseFlavor(inst.manager, {"name": "test"})
        inst.flavor = flavor
        self.assertTrue(isinstance(inst.flavor, CloudDatabaseFlavor))

    @patch("pyrax.manager.BaseManager", new=fakes.FakeManager)
    def test_list_databases_for_instance(self):
        clt = self.client
        inst = self.instance
        limit = utils.random_unicode()
        marker = utils.random_unicode()
        inst.list_databases = Mock(return_value=["db"])
        ret = clt.list_databases(inst, limit=limit, marker=marker)
        self.assertEqual(ret, ["db"])
        inst.list_databases.assert_called_once_with(limit=limit, marker=marker)

    @patch("pyrax.manager.BaseManager", new=fakes.FakeManager)
    def test_create_database_for_instance(self):
        clt = self.client
        inst = self.instance
        inst.create_database = Mock(return_value=["db"])
        nm = utils.random_unicode()
        ret = clt.create_database(inst, nm)
        self.assertEqual(ret, ["db"])
        inst.create_database.assert_called_once_with(nm,
                character_set=None, collate=None)

    def test_clt_get_database(self):
        clt = self.client
        inst = self.instance
        inst.get_database = Mock()
        nm = utils.random_unicode()
        clt.get_database(inst, nm)
        inst.get_database.assert_called_once_with(nm)

    @patch("pyrax.manager.BaseManager", new=fakes.FakeManager)
    def test_delete_database_for_instance(self):
        clt = self.client
        inst = self.instance
        inst.delete_database = Mock()
        nm = utils.random_unicode()
        clt.delete_database(inst, nm)
        inst.delete_database.assert_called_once_with(nm)

    @patch("pyrax.manager.BaseManager", new=fakes.FakeManager)
    def test_list_users_for_instance(self):
        clt = self.client
        inst = self.instance
        limit = utils.random_unicode()
        marker = utils.random_unicode()
        inst.list_users = Mock(return_value=["user"])
        ret = clt.list_users(inst, limit=limit, marker=marker)
        self.assertEqual(ret, ["user"])
        inst.list_users.assert_called_once_with(limit=limit, marker=marker)

    def test_create_user_for_instance(self):
        clt = self.client
        inst = self.instance
        inst.create_user = Mock()
        nm = utils.random_unicode()
        pw = utils.random_unicode()
        host = utils.random_unicode()
        ret = clt.create_user(inst, nm, pw, ["db"], host=host)
        inst.create_user.assert_called_once_with(name=nm, password=pw,
                database_names=["db"], host=host)

    @patch("pyrax.manager.BaseManager", new=fakes.FakeManager)
    def test_delete_user_for_instance(self):
        clt = self.client
        inst = self.instance
        inst.delete_user = Mock()
        nm = utils.random_unicode()
        clt.delete_user(inst, nm)
        inst.delete_user.assert_called_once_with(nm)

    @patch("pyrax.manager.BaseManager", new=fakes.FakeManager)
    def test_enable_root_user_for_instance(self):
        clt = self.client
        inst = self.instance
        inst.enable_root_user = Mock()
        clt.enable_root_user(inst)
        inst.enable_root_user.assert_called_once_with()

    @patch("pyrax.manager.BaseManager", new=fakes.FakeManager)
    def test_root_user_status_for_instance(self):
        clt = self.client
        inst = self.instance
        inst.root_user_status = Mock()
        clt.root_user_status(inst)
        inst.root_user_status.assert_called_once_with()

    @patch("pyrax.manager.BaseManager", new=fakes.FakeManager)
    def test_get_user_by_client(self):
        clt = self.client
        inst = self.instance
        inst.get_user = Mock()
        fakeuser = utils.random_unicode()
        clt.get_user(inst, fakeuser)
        inst.get_user.assert_called_once_with(fakeuser)

    def test_get_user(self):
        inst = self.instance
        good_name = utils.random_unicode()
        user = fakes.FakeDatabaseUser(manager=None, info={"name": good_name})
        inst._user_manager.get = Mock(return_value=user)
        returned = inst.get_user(good_name)
        self.assertEqual(returned, user)

    def test_get_user_fail(self):
        inst = self.instance
        bad_name = utils.random_unicode()
        inst._user_manager.get = Mock(side_effect=exc.NotFound(""))
        self.assertRaises(exc.NoSuchDatabaseUser, inst.get_user, bad_name)

    def test_get_db_names(self):
        inst = self.instance
        mgr = inst._user_manager
        mgr.instance = inst
        dbname1 = utils.random_ascii()
        dbname2 = utils.random_ascii()
        inst.list_databases = Mock(return_value=((dbname1, dbname2)))
        resp = mgr._get_db_names(dbname1)
        self.assertEqual(resp, [dbname1])

    def test_get_db_names_not_strict(self):
        inst = self.instance
        mgr = inst._user_manager
        mgr.instance = inst
        dbname1 = utils.random_ascii()
        dbname2 = utils.random_ascii()
        inst.list_databases = Mock(return_value=((dbname1, dbname2)))
        resp = mgr._get_db_names("BAD", strict=False)
        self.assertEqual(resp, ["BAD"])

    def test_get_db_names_fail(self):
        inst = self.instance
        mgr = inst._user_manager
        mgr.instance = inst
        dbname1 = utils.random_ascii()
        dbname2 = utils.random_ascii()
        inst.list_databases = Mock(return_value=((dbname1, dbname2)))
        self.assertRaises(exc.NoSuchDatabase, mgr._get_db_names, "BAD")

    def test_change_user_password(self):
        inst = self.instance
        fakename = utils.random_ascii()
        newpass = utils.random_ascii()
        resp = fakes.FakeResponse()
        resp.status_code = 202
        inst._user_manager.api.method_put = Mock(return_value=(resp, {}))
        fakeuser = fakes.FakeDatabaseUser(inst._user_manager, {"name": fakename})
        inst._user_manager.get = Mock(return_value=fakeuser)
        inst.change_user_password(fakename, newpass)
        inst._user_manager.api.method_put.assert_called_once_with(
                "/None/%s" % fakename, body={"user": {"password": newpass}})

    def test_update_user(self):
        inst = self.instance
        mgr = inst._user_manager
        user = utils.random_unicode()
        name = utils.random_unicode()
        password = utils.random_unicode()
        host = utils.random_unicode()
        mgr.update = Mock()
        inst.update_user(user, name=name, password=password, host=host)
        mgr.update.assert_called_once_with(user, name=name, password=password,
                host=host)

    def test_user_manager_update(self):
        inst = self.instance
        mgr = inst._user_manager
        username = utils.random_unicode()
        user = fakes.FakeDatabaseUser(mgr, info={"name": username})
        name = utils.random_unicode()
        host = utils.random_unicode()
        password = utils.random_unicode()
        mgr.api.method_put = Mock(return_value=(None, None))
        expected_uri = "/%s/%s" % (mgr.uri_base, username)
        expected_body = {"user": {"name": name, "host": host,
                "password": password}}
        mgr.update(user, name=name, host=host, password=password)
        mgr.api.method_put.assert_called_once_with(expected_uri,
                body=expected_body)

    def test_user_manager_update_missing(self):
        inst = self.instance
        mgr = inst._user_manager
        username = utils.random_unicode()
        user = fakes.FakeDatabaseUser(mgr, info={"name": username})
        self.assertRaises(exc.MissingDBUserParameters, mgr.update, user)

    def test_user_manager_update_unchanged(self):
        inst = self.instance
        mgr = inst._user_manager
        username = utils.random_unicode()
        user = fakes.FakeDatabaseUser(mgr, info={"name": username})
        self.assertRaises(exc.DBUpdateUnchanged, mgr.update, user,
                name=username)

    def test_list_user_access(self):
        inst = self.instance
        dbname1 = utils.random_ascii()
        dbname2 = utils.random_ascii()
        acc = {"databases": [{"name": dbname1}, {"name": dbname2}]}
        inst._user_manager.api.method_get = Mock(return_value=(None, acc))
        db_list = inst.list_user_access("fakeuser")
        self.assertEqual(len(db_list), 2)
        self.assertTrue(db_list[0].name in (dbname1, dbname2))

    def test_list_user_access_not_found(self):
        inst = self.instance
        mgr = inst._user_manager
        mgr.api.method_get = Mock(side_effect=exc.NotFound(""))
        username = utils.random_unicode()
        user = fakes.FakeDatabaseUser(mgr, info={"name": username})
        self.assertRaises(exc.NoSuchDatabaseUser, mgr.list_user_access, user)

    def test_grant_user_access(self):
        inst = self.instance
        fakeuser = utils.random_ascii()
        dbname1 = utils.random_ascii()
        inst._user_manager.api.method_put = Mock(return_value=(None, None))
        inst.grant_user_access(fakeuser, dbname1, strict=False)
        inst._user_manager.api.method_put.assert_called_once_with(
                "/None/%s/databases" % fakeuser, body={"databases": [{"name":
                dbname1}]})

    def test_grant_user_access_not_found(self):
        inst = self.instance
        mgr = inst._user_manager
        mgr.api.method_put = Mock(side_effect=exc.NotFound(""))
        username = utils.random_unicode()
        user = fakes.FakeDatabaseUser(mgr, info={"name": username})
        db_names = utils.random_unicode()
        mgr._get_db_names = Mock(return_value=[])
        self.assertRaises(exc.NoSuchDatabaseUser, mgr.grant_user_access, user,
                db_names)

    def test_revoke_user_access(self):
        inst = self.instance
        fakeuser = utils.random_ascii()
        dbname1 = utils.random_ascii()
        inst._user_manager.api.method_delete = Mock(return_value=(None, None))
        inst.revoke_user_access(fakeuser, dbname1, strict=False)
        inst._user_manager.api.method_delete.assert_called_once_with(
                "/None/%s/databases/%s" % (fakeuser, dbname1))

    def test_backup_mgr_create_body(self):
        inst = self.instance
        mgr = inst.manager
        bu_mgr = mgr.api._backup_manager
        name = utils.random_unicode()
        description = utils.random_unicode()
        expected_body = {"backup": {"instance": inst.id, "name": name,
                "description": description}}
        ret = bu_mgr._create_body(name, inst, description=description)
        self.assertEqual(ret, expected_body)

    def test_backup_mgr_list(self):
        inst = self.instance
        mgr = inst.manager
        bu_mgr = mgr.api._backup_manager
        fake_val = utils.random_unicode()
        bu_mgr._list = Mock(return_value=fake_val)
        ret = bu_mgr.list()
        self.assertEqual(ret, fake_val)

    def test_backup_mgr_list_instance(self):
        inst = self.instance
        mgr = inst.manager
        bu_mgr = mgr.api._backup_manager
        db_mgr = mgr.api._manager
        db_mgr._list_backups_for_instance = Mock()
        bu_mgr.list(instance=inst)
        db_mgr._list_backups_for_instance.assert_called_once_with(inst)

    def test_clt_change_user_password(self):
        clt = self.client
        inst = self.instance
        inst.change_user_password = Mock()
        user = utils.random_unicode()
        pw = utils.random_unicode()
        clt.change_user_password(inst, user, pw)
        inst.change_user_password.assert_called_once_with(user, pw)

    def test_user_change_password(self):
        inst = self.instance
        mgr = inst.manager
        password = utils.random_unicode()
        user = CloudDatabaseUser(mgr, info={"name": "fake"})
        mgr.change_user_password = Mock()
        user.change_password(password)
        mgr.change_user_password.assert_called_once_with(user, password)

    def test_clt_update_user(self):
        clt = self.client
        inst = self.instance
        inst.update_user = Mock()
        user = utils.random_unicode()
        name = utils.random_unicode()
        password = utils.random_unicode()
        host = utils.random_unicode()
        clt.update_user(inst, user, name=name, password=password, host=host)
        inst.update_user.assert_called_once_with(user, name=name,
                password=password, host=host)

    def test_user_update(self):
        inst = self.instance
        mgr = inst.manager
        name = utils.random_unicode()
        password = utils.random_unicode()
        host = utils.random_unicode()
        user = CloudDatabaseUser(mgr, info={"name": "fake"})
        mgr.update = Mock()
        user.update(name=name, password=password, host=host)
        mgr.update.assert_called_once_with(user, name=name, password=password,
                host=host)

    def test_clt_list_user_access(self):
        clt = self.client
        inst = self.instance
        inst.list_user_access = Mock()
        user = utils.random_unicode()
        clt.list_user_access(inst, user)
        inst.list_user_access.assert_called_once_with(user)

    def test_user_list_user_access(self):
        inst = self.instance
        mgr = inst.manager
        user = CloudDatabaseUser(mgr, info={"name": "fake"})
        mgr.list_user_access = Mock()
        user.list_user_access()
        mgr.list_user_access.assert_called_once_with(user)

    def test_clt_grant_user_access(self):
        clt = self.client
        inst = self.instance
        inst.grant_user_access = Mock()
        user = utils.random_unicode()
        db_names = utils.random_unicode()
        clt.grant_user_access(inst, user, db_names)
        inst.grant_user_access.assert_called_once_with(user, db_names,
                strict=True)

    def test_user_grant_user_access(self):
        inst = self.instance
        mgr = inst.manager
        user = CloudDatabaseUser(mgr, info={"name": "fake"})
        db_names = utils.random_unicode()
        strict = utils.random_unicode()
        mgr.grant_user_access = Mock()
        user.grant_user_access(db_names, strict=strict)
        mgr.grant_user_access.assert_called_once_with(user, db_names,
                strict=strict)

    def test_clt_revoke_user_access(self):
        clt = self.client
        inst = self.instance
        inst.revoke_user_access = Mock()
        user = utils.random_unicode()
        db_names = utils.random_unicode()
        clt.revoke_user_access(inst, user, db_names)
        inst.revoke_user_access.assert_called_once_with(user, db_names,
                strict=True)

    def test_user_revoke_user_access(self):
        inst = self.instance
        mgr = inst.manager
        user = CloudDatabaseUser(mgr, info={"name": "fake"})
        db_names = utils.random_unicode()
        strict = utils.random_unicode()
        mgr.revoke_user_access = Mock()
        user.revoke_user_access(db_names, strict=strict)
        mgr.revoke_user_access.assert_called_once_with(user, db_names,
                strict=strict)

    def test_clt_restart(self):
        clt = self.client
        inst = self.instance
        inst.restart = Mock()
        clt.restart(inst)
        inst.restart.assert_called_once_with()

    @patch("pyrax.manager.BaseManager", new=fakes.FakeManager)
    def test_inst_resize(self):
        clt = self.client
        inst = self.instance
        inst.resize = Mock()
        clt.resize(inst, "flavor")
        inst.resize.assert_called_once_with("flavor")

    def test_get_limits(self):
        self.assertRaises(NotImplementedError, self.client.get_limits)

    @patch("pyrax.manager.BaseManager", new=fakes.FakeManager)
    def test_list_flavors(self):
        clt = self.client
        clt._flavor_manager.list = Mock()
        limit = utils.random_unicode()
        marker = utils.random_unicode()
        clt.list_flavors(limit=limit, marker=marker)
        clt._flavor_manager.list.assert_called_once_with(limit=limit,
                marker=marker)

    @patch("pyrax.manager.BaseManager", new=fakes.FakeManager)
    def test_get_flavor(self):
        clt = self.client
        clt._flavor_manager.get = Mock()
        clt.get_flavor("flavorid")
        clt._flavor_manager.get.assert_called_once_with("flavorid")

    @patch("pyrax.manager.BaseManager", new=fakes.FakeManager)
    def test_get_flavor_ref_for_obj(self):
        clt = self.client
        info = {"id": 1,
                "name": "test_flavor",
                "ram": 42,
                "links": [{
                    "href": example_uri,
                    "rel": "self"}]}
        flavor_obj = CloudDatabaseFlavor(clt._manager, info)
        ret = clt._get_flavor_ref(flavor_obj)
        self.assertEqual(ret, example_uri)

    @patch("pyrax.manager.BaseManager", new=fakes.FakeManager)
    def test_get_flavor_ref_for_id(self):
        clt = self.client
        info = {"id": 1,
                "name": "test_flavor",
                "ram": 42,
                "links": [{
                    "href": example_uri,
                    "rel": "self"}]}
        flavor_obj = CloudDatabaseFlavor(clt._manager, info)
        clt.get_flavor = Mock(return_value=flavor_obj)
        ret = clt._get_flavor_ref(1)
        self.assertEqual(ret, example_uri)

    @patch("pyrax.manager.BaseManager", new=fakes.FakeManager)
    def test_get_flavor_ref_for_name(self):
        clt = self.client
        info = {"id": 1,
                "name": "test_flavor",
                "ram": 42,
                "links": [{
                    "href": example_uri,
                    "rel": "self"}]}
        flavor_obj = CloudDatabaseFlavor(clt._manager, info)
        clt.get_flavor = Mock(side_effect=exc.NotFound(""))
        clt.list_flavors = Mock(return_value=[flavor_obj])
        ret = clt._get_flavor_ref("test_flavor")
        self.assertEqual(ret, example_uri)

    @patch("pyrax.manager.BaseManager", new=fakes.FakeManager)
    def test_get_flavor_ref_for_ram(self):
        clt = self.client
        info = {"id": 1,
                "name": "test_flavor",
                "ram": 42,
                "links": [{
                    "href": example_uri,
                    "rel": "self"}]}
        flavor_obj = CloudDatabaseFlavor(clt._manager, info)
        clt.get_flavor = Mock(side_effect=exc.NotFound(""))
        clt.list_flavors = Mock(return_value=[flavor_obj])
        ret = clt._get_flavor_ref(42)
        self.assertEqual(ret, example_uri)

    @patch("pyrax.manager.BaseManager", new=fakes.FakeManager)
    def test_get_flavor_ref_not_found(self):
        clt = self.client
        info = {"id": 1,
                "name": "test_flavor",
                "ram": 42,
                "links": [{
                    "href": example_uri,
                    "rel": "self"}]}
        flavor_obj = CloudDatabaseFlavor(clt._manager, info)
        clt.get_flavor = Mock(side_effect=exc.NotFound(""))
        clt.list_flavors = Mock(return_value=[flavor_obj])
        self.assertRaises(exc.FlavorNotFound, clt._get_flavor_ref, "nonsense")

    def test_clt_list_backups(self):
        clt = self.client
        mgr = clt._backup_manager
        mgr.list = Mock()
        clt.list_backups()
        mgr.list.assert_called_once_with(instance=None)

    def test_clt_list_backups_for_instance(self):
        clt = self.client
        mgr = clt._backup_manager
        mgr.list = Mock()
        inst = utils.random_unicode()
        clt.list_backups(instance=inst)
        mgr.list.assert_called_once_with(instance=inst)

    def test_clt_get_backup(self):
        clt = self.client
        mgr = clt._backup_manager
        mgr.get = Mock()
        backup = utils.random_unicode()
        clt.get_backup(backup)
        mgr.get.assert_called_once_with(backup)

    def test_clt_delete_backup(self):
        clt = self.client
        mgr = clt._backup_manager
        mgr.delete = Mock()
        backup = utils.random_unicode()
        clt.delete_backup(backup)
        mgr.delete.assert_called_once_with(backup)

    def test_clt_create_backup(self):
        clt = self.client
        inst = self.instance
        name = utils.random_unicode()
        description = utils.random_unicode()
        inst.create_backup = Mock()
        clt.create_backup(inst, name, description=description)
        inst.create_backup.assert_called_once_with(name,
                description=description)

    def test_clt_restore_backup(self):
        clt = self.client
        mgr = clt._manager
        backup = utils.random_unicode()
        name = utils.random_unicode()
        flavor = utils.random_unicode()
        volume = utils.random_unicode()
        mgr.restore_backup = Mock()
        clt.restore_backup(backup, name, flavor, volume)
        mgr.restore_backup.assert_called_once_with(backup, name, flavor, volume)

    @patch("pyrax.manager.BaseManager", new=fakes.FakeManager)
    def test_create_body_db(self):
        mgr = self.instance._database_manager
        nm = utils.random_unicode()
        ret = mgr._create_body(nm, character_set="CS", collate="CO")
        expected = {"databases": [
                {"name": nm,
                "character_set": "CS",
                "collate": "CO"}]}
        self.assertEqual(ret, expected)

    @patch("pyrax.manager.BaseManager", new=fakes.FakeManager)
    def test_create_body_user(self):
        inst = self.instance
        mgr = inst._user_manager
        nm = utils.random_unicode()
        pw = utils.random_unicode()
        dbnames = [utils.random_unicode(), utils.random_unicode()]
        ret = mgr._create_body(nm, password=pw, database_names=dbnames)
        expected = {"users": [
                {"name": nm,
                "password": pw,
                "databases": [{"name": dbnames[0]}, {"name": dbnames[1]}]}]}
        self.assertEqual(ret, expected)

    @patch("pyrax.manager.BaseManager", new=fakes.FakeManager)
    def test_create_body_user_host(self):
        inst = self.instance
        mgr = inst._user_manager
        nm = utils.random_unicode()
        host = utils.random_unicode()
        pw = utils.random_unicode()
        dbnames = [utils.random_unicode(), utils.random_unicode()]
        ret = mgr._create_body(nm, host=host, password=pw,
                database_names=dbnames)
        expected = {"users": [
                {"name": nm,
                "password": pw,
                "host": host,
                "databases": [{"name": dbnames[0]}, {"name": dbnames[1]}]}]}
        self.assertEqual(ret, expected)

    @patch("pyrax.manager.BaseManager", new=fakes.FakeManager)
    def test_create_body_flavor(self):
        clt = self.client
        nm = utils.random_unicode()
        clt._get_flavor_ref = Mock(return_value=example_uri)
        ret = clt._manager._create_body(nm)
        expected = {"instance": {
                "name": nm,
                "flavorRef": example_uri,
                "volume": {"size": 1},
                "databases": [],
                "users": []}}
        self.assertEqual(ret, expected)


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_cloud_dns
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import random
import time
import unittest

from mock import call
from mock import patch
from mock import MagicMock as Mock

import pyrax
from pyrax.manager import BaseManager
from pyrax.clouddns import assure_domain
from pyrax.clouddns import CloudDNSClient
from pyrax.clouddns import CloudDNSDomain
from pyrax.clouddns import CloudDNSManager
from pyrax.clouddns import CloudDNSRecord
from pyrax.clouddns import ResultsIterator
from pyrax.clouddns import DomainResultsIterator
from pyrax.clouddns import SubdomainResultsIterator
from pyrax.clouddns import RecordResultsIterator
import pyrax.exceptions as exc
import pyrax.utils as utils

from pyrax import fakes

example_uri = "http://example.com"


class CloudDNSTest(unittest.TestCase):
    def __init__(self, *args, **kwargs):
        super(CloudDNSTest, self).__init__(*args, **kwargs)

    def setUp(self):
        super(CloudDNSTest, self).setUp()
        self.client = fakes.FakeDNSClient()
        self.client._manager = fakes.FakeDNSManager(self.client)
        self.client._manager._set_delay(0.000001)
        self.domain = fakes.FakeDNSDomain()
        self.domain.manager = self.client._manager

    def tearDown(self):
        super(CloudDNSTest, self).tearDown()
        self.client = None
        self.domain = None

    def test_assure_domain(self):
        @assure_domain
        def test(self, domain):
            return domain
        clt = self.client
        dom = self.domain
        d1 = test(clt, dom)
        self.assertEqual(d1, dom)
        self.assertTrue(isinstance(d1, CloudDNSDomain))

    def test_assure_domain_id(self):
        @assure_domain
        def test(self, domain):
            return domain
        clt = self.client
        dom = self.domain
        clt._manager._get = Mock(return_value=dom)
        d2 = test(clt, dom.id)
        self.assertEqual(d2, dom)
        self.assertTrue(isinstance(d2, CloudDNSDomain))

    def test_assure_domain_name(self):
        @assure_domain
        def test(self, domain):
            return domain
        clt = self.client
        dom = self.domain
        clt._manager._get = Mock(side_effect=exc.NotFound(""))
        clt._manager._list = Mock(return_value=[dom])
        d3 = test(clt, dom.name)
        self.assertEqual(d3, dom)
        self.assertTrue(isinstance(d3, CloudDNSDomain))

    def test_set_timeout(self):
        clt = self.client
        mgr = clt._manager
        new_timeout = random.randint(0, 99)
        clt.set_timeout(new_timeout)
        self.assertEqual(mgr._timeout, new_timeout)

    def test_set_delay(self):
        clt = self.client
        mgr = clt._manager
        new_delay = random.randint(0, 99)
        clt.set_delay(new_delay)
        self.assertEqual(mgr._delay, new_delay)

    def test_reset_paging_all(self):
        clt = self.client
        mgr = clt._manager
        mgr._paging["domain"]["total_entries"] = 99
        mgr._paging["record"]["next_uri"] = example_uri
        mgr._reset_paging("all")
        self.assertIsNone(mgr._paging["domain"]["total_entries"])
        self.assertIsNone(mgr._paging["record"]["next_uri"])

    def test_reset_paging_body(self):
        clt = self.client
        mgr = clt._manager
        mgr._paging["domain"]["total_entries"] = 99
        mgr._paging["domain"]["next_uri"] = "FAKE"
        exp_entries = random.randint(100, 200)
        uri_string_next = utils.random_unicode()
        next_uri = "%s/domains/%s" % (example_uri, uri_string_next)
        uri_string_prev = utils.random_unicode()
        prev_uri = "%s/domains/%s" % (example_uri, uri_string_prev)
        body = {"totalEntries": exp_entries,
                "links": [
                    {"href": next_uri,
                    "rel": "next"},
                    {"href": prev_uri,
                    "rel": "previous"}]}
        mgr._reset_paging("domain", body=body)
        self.assertEqual(mgr._paging["domain"]["total_entries"], exp_entries)
        self.assertEqual(mgr._paging["domain"]["next_uri"], "/domains/%s" %
                uri_string_next)
        self.assertEqual(mgr._paging["domain"]["prev_uri"], "/domains/%s" %
                uri_string_prev)

    def test_get_pagination_qs(self):
        clt = self.client
        mgr = clt._manager
        test_limit = random.randint(1, 100)
        test_offset = random.randint(1, 100)
        qs = mgr._get_pagination_qs(test_limit, test_offset)
        self.assertEqual(qs, "?limit=%s&offset=%s" % (test_limit, test_offset))

    def test_manager_list(self):
        clt = self.client
        mgr = clt._manager
        fake_name = utils.random_unicode()
        ret_body = {"domains": [{"name": fake_name}]}
        clt.method_get = Mock(return_value=({}, ret_body))
        ret = clt.list()
        self.assertEqual(len(ret), 1)

    def test_manager_list_all(self):
        clt = self.client
        mgr = clt._manager
        fake_name = utils.random_unicode()
        ret_body = {"domains": [{"name": fake_name}]}
        uri_string_next = utils.random_unicode()
        next_uri = "%s/domains/%s" % (example_uri, uri_string_next)
        mgr.count = 0

        def mock_get(uri):
            if mgr.count:
                return ({}, ret_body)
            mgr.count += 1
            ret = {"totalEntries": 2,
                    "links": [
                        {"href": next_uri,
                         "rel": "next"}]}
            ret.update(ret_body)
            return ({}, ret)

        clt.method_get = Mock(wraps=mock_get)
        ret = mgr._list(example_uri, list_all=True)
        self.assertEqual(len(ret), 2)

    def test_list_previous_page(self):
        clt = self.client
        mgr = clt._manager
        mgr._paging["domain"]["prev_uri"] = example_uri
        mgr._list = Mock()
        clt.list_previous_page()
        mgr._list.assert_called_once_with(example_uri)

    def test_list_previous_page_fail(self):
        clt = self.client
        mgr = clt._manager
        self.assertRaises(exc.NoMoreResults, clt.list_previous_page)

    def test_list_next_page(self):
        clt = self.client
        mgr = clt._manager
        mgr._paging["domain"]["next_uri"] = example_uri
        mgr._list = Mock()
        clt.list_next_page()
        mgr._list.assert_called_once_with(example_uri)

    def test_list_next_page_fail(self):
        clt = self.client
        mgr = clt._manager
        self.assertRaises(exc.NoMoreResults, clt.list_next_page)

    def test_list_subdomains_previous_page(self):
        clt = self.client
        mgr = clt._manager
        mgr._paging["subdomain"]["prev_uri"] = example_uri
        mgr._list_subdomains = Mock()
        clt.list_subdomains_previous_page()
        mgr._list_subdomains.assert_called_once_with(example_uri)

    def test_list_subdomains_previous_page_fail(self):
        clt = self.client
        mgr = clt._manager
        self.assertRaises(exc.NoMoreResults, clt.list_subdomains_previous_page)

    def test_list_subdomains_next_page(self):
        clt = self.client
        mgr = clt._manager
        mgr._paging["subdomain"]["next_uri"] = example_uri
        mgr._list_subdomains = Mock()
        clt.list_subdomains_next_page()
        mgr._list_subdomains.assert_called_once_with(example_uri)

    def test_list_subdomains_next_page_fail(self):
        clt = self.client
        mgr = clt._manager
        self.assertRaises(exc.NoMoreResults, clt.list_subdomains_next_page)

    def test_list_records_previous_page(self):
        clt = self.client
        mgr = clt._manager
        mgr._paging["record"]["prev_uri"] = example_uri
        mgr._list_records = Mock()
        clt.list_records_previous_page()
        mgr._list_records.assert_called_once_with(example_uri)

    def test_list_records_previous_page_fail(self):
        clt = self.client
        mgr = clt._manager
        self.assertRaises(exc.NoMoreResults, clt.list_records_previous_page)

    def test_list_records_next_page(self):
        clt = self.client
        mgr = clt._manager
        mgr._paging["record"]["next_uri"] = example_uri
        mgr._list_records = Mock()
        clt.list_records_next_page()
        mgr._list_records.assert_called_once_with(example_uri)

    def test_list_records_next_page_fail(self):
        clt = self.client
        mgr = clt._manager
        self.assertRaises(exc.NoMoreResults, clt.list_records_next_page)

    def test_manager_get(self):
        ret_body = {"recordsList": {
                "records": [{
                    "accountId": "728829",
                    "created": "2012-09-21T21:32:27.000+0000",
                    "emailAddress": "me@example.com",
                    "id": "3448214",
                    "name": "example.com",
                    "updated": "2012-09-21T21:35:45.000+0000"
                }]}}
        mgr = self.client._manager
        mgr.api.method_get = Mock(return_value=(None, ret_body))
        dom = mgr._get("fake")
        self.assertTrue(isinstance(dom, CloudDNSDomain))

    def test_manager_create(self):
        clt = self.client
        mgr = clt._manager
        ret_body = {"callbackUrl": example_uri,
                "status": "RUNNING"}
        mgr.api.method_post = Mock(return_value=(None, ret_body))
        stat_body = {"status": "complete",
                "response": {mgr.response_key: [{
                    "accountId": "728829",
                    "created": "2012-09-21T21:32:27.000+0000",
                    "emailAddress": "me@example.com",
                    "id": "3448214",
                    "name": "example.com",
                    "updated": "2012-09-21T21:35:45.000+0000"
                }]}}
        mgr.api.method_get = Mock(return_value=(None, stat_body))
        dom = mgr._create("fake", {})
        self.assertTrue(isinstance(dom, CloudDNSDomain))

    def test_manager_create_error(self):
        clt = self.client
        mgr = clt._manager
        ret_body = {"callbackUrl": example_uri,
                "status": "RUNNING"}
        mgr.api.method_post = Mock(return_value=(None, ret_body))
        stat_body = {"status": "ERROR",
                "error": {
                    "details": "fail",
                    "code": 666}}
        mgr.api.method_get = Mock(return_value=(None, stat_body))
        self.assertRaises(exc.DomainCreationFailed, mgr._create, "fake", {})

    def test_manager_findall(self):
        clt = self.client
        mgr = clt._manager
        mgr._list = Mock()
        mgr.findall(name="fake")
        mgr._list.assert_called_once_with("/domains?name=fake", list_all=True)

    def test_manager_findall_default(self):
        clt = self.client
        mgr = clt._manager
        sav = BaseManager.findall
        BaseManager.findall = Mock()
        mgr.findall(foo="bar")
        BaseManager.findall.assert_called_once_with(foo="bar")
        BaseManager.findall = sav

    def test_manager_empty_get_body_error(self):
        clt = self.client
        mgr = clt._manager
        mgr.api.method_get = Mock(return_value=(None, None))
        self.assertRaises(exc.ServiceResponseFailure, mgr.list)

    def test_create_body(self):
        mgr = self.client._manager
        fake_name = utils.random_unicode()
        body = mgr._create_body(fake_name, "fake@fake.com")
        self.assertEqual(body["domains"][0]["name"], fake_name)

    def test_async_call_body(self):
        clt = self.client
        mgr = clt._manager
        body = {"fake": "fake"}
        uri = "http://example.com"
        callback_uri = "https://fake.example.com/status/fake"
        massaged_uri = "/status/fake?showDetails=true"
        put_resp = {"callbackUrl": callback_uri,
                "status": "RUNNING"}
        get_resp = {"response": {"result": "fake"},
                "status": "COMPLETE"}
        method = "PUT"
        clt.method_put = Mock(return_value=({}, put_resp))
        clt.method_get = Mock(return_value=({}, get_resp))
        ret = mgr._async_call(uri, body=body, method=method)
        clt.method_put.assert_called_once_with(uri, body=body)
        clt.method_get.assert_called_once_with(massaged_uri)
        self.assertEqual(ret, ({}, get_resp["response"]))

    def test_async_call_no_body(self):
        clt = self.client
        mgr = clt._manager
        uri = "http://example.com"
        callback_uri = "https://fake.example.com/status/fake"
        massaged_uri = "/status/fake?showDetails=true"
        put_resp = {"callbackUrl": callback_uri,
                "status": "RUNNING"}
        get_resp = {"response": {"result": "fake"},
                "status": "COMPLETE"}
        method = "DELETE"
        clt.method_delete = Mock(return_value=({}, put_resp))
        clt.method_get = Mock(return_value=({}, get_resp))
        ret = mgr._async_call(uri, method=method)
        clt.method_delete.assert_called_once_with(uri)
        clt.method_get.assert_called_once_with(massaged_uri)
        self.assertEqual(ret, ({}, get_resp["response"]))

    def test_async_call_no_response(self):
        clt = self.client
        mgr = clt._manager
        uri = "http://example.com"
        callback_uri = "https://fake.example.com/status/fake"
        massaged_uri = "/status/fake?showDetails=true"
        put_resp = {"callbackUrl": callback_uri,
                "status": "RUNNING"}
        get_resp = {"status": "COMPLETE"}
        method = "DELETE"
        clt.method_delete = Mock(return_value=({}, put_resp))
        clt.method_get = Mock(return_value=({}, get_resp))
        ret = mgr._async_call(uri, method=method, has_response=False)
        clt.method_delete.assert_called_once_with(uri)
        clt.method_get.assert_called_once_with(massaged_uri)
        self.assertEqual(ret, ({}, get_resp))

    def test_async_call_timeout(self):
        clt = self.client
        mgr = clt._manager
        uri = "http://example.com"
        callback_uri = "https://fake.example.com/status/fake"
        clt.set_timeout(0.000001)
        clt.method_get = Mock(return_value=({}, {"callbackUrl": callback_uri,
                "status": "RUNNING"}))
        self.assertRaises(exc.DNSCallTimedOut, mgr._async_call, uri,
                method="GET")

    def test_async_call_error(self):
        clt = self.client
        mgr = clt._manager
        uri = "http://example.com"
        callback_uri = "https://fake.example.com/status/fake"
        massaged_uri = "/status/fake?showDetails=true"
        put_resp = {"callbackUrl": callback_uri,
                "status": "RUNNING"}
        get_resp = {"response": {"result": "fake"},
                "status": "ERROR"}
        method = "DELETE"
        clt.method_delete = Mock(return_value=({}, put_resp))
        clt.method_get = Mock(return_value=({}, get_resp))
        err_class = exc.DomainRecordDeletionFailed
        err = err_class("oops")
        mgr._process_async_error = Mock(side_effect=err)
        self.assertRaises(err_class,
                mgr._async_call, uri, method=method, error_class=err_class)
        clt.method_delete.assert_called_once_with(uri)
        clt.method_get.assert_called_once_with(massaged_uri)
        mgr._process_async_error.assert_called_once_with(get_resp, err_class)

    def test_process_async_error(self):
        clt = self.client
        mgr = clt._manager
        err = {"error": {"message": "fake", "details": "", "code": 400}}
        err_class = exc.DomainRecordDeletionFailed
        self.assertRaises(err_class, mgr._process_async_error, err, err_class)

    def test_process_async_error_nested(self):
        clt = self.client
        mgr = clt._manager
        err = {"error": {
                "failedItems": {"faults": [
                    {"message": "fake1", "details": "", "code": 400},
                    {"message": "fake2", "details": "", "code": 400},
                    ]}}}
        err_class = exc.DomainRecordDeletionFailed
        self.assertRaises(err_class, mgr._process_async_error, err, err_class)

    def test_changes_since(self):
        clt = self.client
        dom = self.domain
        clt.method_get = Mock(return_value=({}, {"changes": ["fake"]}))
        dt = "2012-01-01"
        ret = clt.changes_since(dom, dt)
        uri = "/domains/%s/changes?since=2012-01-01T00:00:00+0000" % dom.id
        clt.method_get.assert_called_once_with(uri)
        self.assertEqual(ret, ["fake"])

    def test_export_domain(self):
        clt = self.client
        dom = self.domain
        export = utils.random_unicode()
        clt._manager._async_call = Mock(return_value=({}, {"contents": export}))
        ret = clt.export_domain(dom)
        uri = "/domains/%s/export" % dom.id
        clt._manager._async_call.assert_called_once_with(uri,
                error_class=exc.NotFound, method="GET")
        self.assertEqual(ret, export)

    def test_import_domain(self):
        clt = self.client
        mgr = clt._manager
        data = utils.random_unicode()
        mgr._async_call = Mock(return_value=({}, "fake"))
        req_body = {"domains": [{
                "contentType": "BIND_9",
                "contents": data,
                }]}
        ret = clt.import_domain(data)
        mgr._async_call.assert_called_once_with("/domains/import",
                method="POST", body=req_body,
                error_class=exc.DomainCreationFailed)

    def test_update_domain_empty(self):
        self.assertRaises(exc.MissingDNSSettings, self.client.update_domain,
                self.domain)

    def test_update_domain(self):
        clt = self.client
        dom = self.domain
        mgr = clt._manager
        emailAddress = None
        comment = utils.random_unicode()
        ttl = 666
        mgr._async_call = Mock(return_value=({}, "fake"))
        uri = "/domains/%s" % utils.get_id(dom)
        req_body = {"comment": comment,
                "ttl": ttl,
                }
        ret = clt.update_domain(dom, emailAddress, ttl, comment)
        mgr._async_call.assert_called_once_with(uri, method="PUT",
                body=req_body, error_class=exc.DomainUpdateFailed,
                has_response=False)

    def test_delete(self):
        clt = self.client
        mgr = clt._manager
        dom = self.domain
        mgr._async_call = Mock(return_value=({}, {}))
        uri = "/domains/%s" % utils.get_id(dom)
        clt.delete(dom)
        mgr._async_call.assert_called_once_with(uri, method="DELETE",
                error_class=exc.DomainDeletionFailed, has_response=False)

    def test_delete_subdomains(self):
        clt = self.client
        mgr = clt._manager
        dom = self.domain
        mgr._async_call = Mock(return_value=({}, {}))
        uri = "/domains/%s?deleteSubdomains=true" % utils.get_id(dom)
        clt.delete(dom, delete_subdomains=True)
        mgr._async_call.assert_called_once_with(uri, method="DELETE",
                error_class=exc.DomainDeletionFailed, has_response=False)

    def test_list_subdomains(self):
        clt = self.client
        mgr = clt._manager
        dom = self.domain
        resp_body = {'Something': 'here'}
        clt.method_get = Mock(return_value=({}, resp_body))
#        uri = "/domains/%s/subdomains" % utils.get_id(dom)
        uri = "/domains?name=%s&limit=5" % dom.name
        clt.list_subdomains(dom, limit=5)
        clt.method_get.assert_called_once_with(uri)

    def test_list_records(self):
        clt = self.client
        mgr = clt._manager
        dom = self.domain
        resp_body = {'Something': 'here'}
        clt.method_get = Mock(return_value=({}, resp_body))
        uri = "/domains/%s/records" % utils.get_id(dom)
        clt.list_records(dom)
        clt.method_get.assert_called_once_with(uri)

    def test_search_records(self):
        clt = self.client
        mgr = clt._manager
        dom = self.domain
        typ = "A"
        uri = "/domains/%s/records?type=%s" % (utils.get_id(dom), typ)
        ret_body = {"records": [{"type": typ}]}
        mgr.count = 0

        def mock_get(uri):
            if mgr.count:
                return ({}, ret_body)
            mgr.count += 1
            ret = {"totalEntries": 2,
                    "links": [
                        {"href": uri,
                         "rel": "next"}]}
            ret.update(ret_body)
            return ({}, ret)

        clt.method_get = Mock(wraps=mock_get)
        clt.search_records(dom, typ)
        calls = [call(uri), call(uri)]
        clt.method_get.assert_has_calls(calls)

    def test_search_records_params(self):
        clt = self.client
        mgr = clt._manager
        dom = self.domain
        typ = "A"
        nm = utils.random_unicode()
        data = "0.0.0.0"
        resp_body = {"Something": "here"}
        clt.method_get = Mock(return_value=({}, resp_body))
        uri = "/domains/%s/records?type=%s&name=%s&data=%s" % (
                utils.get_id(dom), typ, nm, data)
        clt.search_records(dom, typ, name=nm, data=data)
        clt.method_get.assert_called_once_with(uri)

    def test_find_record(self):
        clt = self.client
        mgr = clt._manager
        dom = self.domain
        typ = "A"
        nm = utils.random_unicode()
        data = "0.0.0.0"
        ret_body = {"records": [{
                "accountId": "728829",
                "created": "2012-09-21T21:32:27.000+0000",
                "emailAddress": "me@example.com",
                "id": "3448214",
                "name": "example.com",
                "updated": "2012-09-21T21:35:45.000+0000"
                }]}
        clt.method_get = Mock(return_value=({}, ret_body))
        uri = "/domains/%s/records?type=%s&name=%s&data=%s" % (
                utils.get_id(dom), typ, nm, data)
        clt.find_record(dom, typ, name=nm, data=data)
        clt.method_get.assert_called_once_with(uri)

    def test_find_record_not_found(self):
        clt = self.client
        mgr = clt._manager
        dom = self.domain
        typ = "A"
        nm = utils.random_unicode()
        data = "0.0.0.0"
        ret_body = {"records": []}
        clt.method_get = Mock(return_value=({}, ret_body))
        uri = "/domains/%s/records?type=%s&name=%s&data=%s" % (
                utils.get_id(dom), typ, nm, data)
        self.assertRaises(exc.DomainRecordNotFound, clt.find_record, dom, typ,
                name=nm, data=data)

    def test_find_record_not_unique(self):
        clt = self.client
        mgr = clt._manager
        dom = self.domain
        typ = "A"
        nm = utils.random_unicode()
        data = "0.0.0.0"
        ret_body = {"records": [{
                "accountId": "728829",
                "created": "2012-09-21T21:32:27.000+0000",
                "emailAddress": "me@example.com",
                "id": "3448214",
                "name": "example.com",
                "updated": "2012-09-21T21:35:45.000+0000"
                }, {"accountId": "728829",
                "created": "2012-09-21T21:32:27.000+0000",
                "emailAddress": "me@example.com",
                "id": "3448214",
                "name": "example.com",
                "updated": "2012-09-21T21:35:45.000+0000"
                }]}
        clt.method_get = Mock(return_value=({}, ret_body))
        uri = "/domains/%s/records?type=%s&name=%s&data=%s" % (
                utils.get_id(dom), typ, nm, data)
        self.assertRaises(exc.DomainRecordNotUnique, clt.find_record, dom, typ,
                name=nm, data=data)

    def test_add_records(self):
        clt = self.client
        mgr = clt._manager
        dom = self.domain
        rec = {"type": "A", "name": "example.com", "data": "0.0.0.0"}
        mgr._async_call = Mock(return_value=({}, {}))
        uri = "/domains/%s/records" % utils.get_id(dom)
        clt.add_records(dom, rec)
        mgr._async_call.assert_called_once_with(uri, method="POST",
                body={"records": [rec]},
                error_class=exc.DomainRecordAdditionFailed,
                has_response=False)

    def test_get_record(self):
        clt = self.client
        mgr = clt._manager
        dom = self.domain
        nm = utils.random_unicode()
        rec_id = utils.random_unicode()
        rec_dict = {"id": rec_id, "name": nm}
        mgr.api.method_get = Mock(return_value=(None, rec_dict))
        ret = clt.get_record(dom, rec_id)
        mgr.api.method_get.assert_called_once_with("/%s/%s/records/%s" %
                (mgr.uri_base, dom.id, rec_id))

    def test_update_record(self):
        clt = self.client
        mgr = clt._manager
        dom = self.domain
        nm = utils.random_unicode()
        rec = fakes.FakeDNSRecord(mgr, {"id": utils.random_unicode(),
                "name": nm})
        ttl = 9999
        data = "0.0.0.0"
        mgr._async_call = Mock(return_value=({}, {}))
        uri = "/domains/%s/records/%s" % (utils.get_id(dom), utils.get_id(rec))
        req_body = {"name": nm, "data": data, "ttl": ttl}
        clt.update_record(dom, rec, data=data, ttl=ttl)
        mgr._async_call.assert_called_once_with(uri, method="PUT",
                body=req_body, error_class=exc.DomainRecordUpdateFailed,
                has_response=False)

    def test_delete_record(self):
        clt = self.client
        mgr = clt._manager
        dom = self.domain
        rec = CloudDNSRecord(mgr, {"id": utils.random_unicode()})
        mgr._async_call = Mock(return_value=({}, {}))
        uri = "/domains/%s/records/%s" % (utils.get_id(dom), utils.get_id(rec))
        clt.delete_record(dom, rec)
        mgr._async_call.assert_called_once_with(uri, method="DELETE",
                error_class=exc.DomainRecordDeletionFailed,
                has_response=False)

    def test_resolve_device_type(self):
        clt = self.client
        mgr = clt._manager
        device = fakes.FakeDNSDevice()
        typ = mgr._resolve_device_type(device)
        self.assertEqual(typ, "loadbalancer")
        device = fakes.FakeLoadBalancer()
        typ = mgr._resolve_device_type(device)
        self.assertEqual(typ, "loadbalancer")

    def test_resolve_device_type_invalid(self):
        clt = self.client
        mgr = clt._manager
        device = object()
        self.assertRaises(exc.InvalidDeviceType, mgr._resolve_device_type,
                device)

    def test_get_ptr_details_lb(self):
        clt = self.client
        mgr = clt._manager
        dvc = fakes.FakeDNSDevice()
        dvc_type = "loadbalancer"
        sav = pyrax._get_service_endpoint
        pyrax._get_service_endpoint = Mock(return_value=example_uri)
        expected_href = "%s/loadbalancers/%s" % (example_uri, dvc.id)
        href, svc_name = mgr._get_ptr_details(dvc, dvc_type)
        self.assertEqual(svc_name, "cloudLoadBalancers")
        self.assertEqual(href, expected_href)
        pyrax._get_service_endpoint = sav

    def test_list_ptr_records(self):
        clt = self.client
        mgr = clt._manager
        dvc = fakes.FakeDNSDevice()
        href = "%s/%s" % (example_uri, dvc.id)
        svc_name = "cloudServersOpenStack"
        uri = "/rdns/%s?href=%s" % (svc_name, href)
        mgr._get_ptr_details = Mock(return_value=(href, svc_name))
        clt.method_get = Mock(return_value=({}, {"records": []}))
        ret = clt.list_ptr_records(dvc)
        clt.method_get.assert_called_once_with(uri)
        self.assertEqual(ret, [])

    def test_list_ptr_records_not_found(self):
        clt = self.client
        mgr = clt._manager
        dvc = fakes.FakeDNSDevice()
        href = "%s/%s" % (example_uri, dvc.id)
        svc_name = "cloudServersOpenStack"
        uri = "/rdns/%s?href=%s" % (svc_name, href)
        mgr._get_ptr_details = Mock(return_value=(href, svc_name))
        clt.method_get = Mock(side_effect=exc.NotFound(""))
        ret = clt.list_ptr_records(dvc)
        clt.method_get.assert_called_once_with(uri)
        self.assertEqual(ret, [])

    def test_add_ptr_records(self):
        clt = self.client
        mgr = clt._manager
        dvc = fakes.FakeDNSDevice()
        href = "%s/%s" % (example_uri, dvc.id)
        svc_name = "cloudServersOpenStack"
        rec = {"foo": "bar"}
        body = {"recordsList": {"records": [rec]},
                "link": {"content": "", "href": href, "rel": svc_name}}
        uri = "/rdns"
        mgr._get_ptr_details = Mock(return_value=(href, svc_name))
        mgr._async_call = Mock(return_value=({}, {"records": []}))
        clt.add_ptr_records(dvc, rec)
        mgr._async_call.assert_called_once_with(uri, body=body,
                error_class=exc.PTRRecordCreationFailed, method="POST")

    def test_update_ptr_record(self):
        clt = self.client
        mgr = clt._manager
        dvc = fakes.FakeDNSDevice()
        href = "%s/%s" % (example_uri, dvc.id)
        svc_name = "cloudServersOpenStack"
        ptr_record = fakes.FakeDNSPTRRecord({"id": utils.random_unicode()})
        ttl = 9999
        data = "0.0.0.0"
        long_comment = "x" * 200
        trim_comment = long_comment[:160]
        nm = "example.com"
        rec = {"name": nm, "id": ptr_record.id, "type": "PTR", "data": data,
                "ttl": ttl, "comment": trim_comment}
        uri = "/rdns"
        body = {"recordsList": {"records": [rec]}, "link": {"content": "",
                "href": href, "rel": svc_name}}
        mgr._get_ptr_details = Mock(return_value=(href, svc_name))
        mgr._async_call = Mock(return_value=({}, {"records": []}))
        clt.update_ptr_record(dvc, ptr_record, domain_name=nm, data=data,
                ttl=ttl, comment=long_comment)
        mgr._async_call.assert_called_once_with(uri, body=body,
                error_class=exc.PTRRecordUpdateFailed, method="PUT",
                has_response=False)

    def test_delete_ptr_records(self):
        clt = self.client
        mgr = clt._manager
        dvc = fakes.FakeDNSDevice()
        href = "%s/%s" % (example_uri, dvc.id)
        svc_name = "cloudServersOpenStack"
        ip_address = "0.0.0.0"
        uri = "/rdns/%s?href=%s&ip=%s" % (svc_name, href, ip_address)
        mgr._get_ptr_details = Mock(return_value=(href, svc_name))
        mgr._async_call = Mock(return_value=({}, {"records": []}))
        ret = clt.delete_ptr_records(dvc, ip_address=ip_address)
        mgr._async_call.assert_called_once_with(uri,
                error_class=exc.PTRRecordDeletionFailed,
                method="DELETE", has_response=False)

    def test_get_absolute_limits(self):
        clt = self.client
        rand_limit = utils.random_unicode()
        resp = {"limits": {"absolute": rand_limit}}
        clt.method_get = Mock(return_value=({}, resp))
        ret = clt.get_absolute_limits()
        self.assertEqual(ret, rand_limit)

    def test_get_rate_limits(self):
        clt = self.client
        limits = [{"uri": "fake1", "limit": 1},
                {"uri": "fake2", "limit": 2}]
        resp = {"limits": {"rate": limits}}
        resp_limits = [{"uri": "fake1", "limits": 1},
                {"uri": "fake2", "limits": 2}]
        clt.method_get = Mock(return_value=({}, resp))
        ret = clt.get_rate_limits()
        self.assertEqual(ret, resp_limits)

    def test_results_iterator(self):
        clt = self.client
        mgr = clt._manager
        self.assertRaises(NotImplementedError, ResultsIterator, mgr)

    def test_iter(self):
        clt = self.client
        mgr = clt._manager
        res_iter = DomainResultsIterator(mgr)
        ret = res_iter.__iter__()
        self.assertTrue(ret is res_iter)

    def test_iter_next(self):
        clt = self.client
        mgr = clt._manager
        res_iter = DomainResultsIterator(mgr)
        clt.method_get = Mock(return_value=({}, {"domains": []}))
        self.assertRaises(StopIteration, res_iter.next)

    def test_iter_items_first_fetch(self):
        clt = self.client
        mgr = clt._manager
        fake_name = utils.random_unicode()
        ret_body = {"domains": [{"name": fake_name}]}
        clt.method_get = Mock(return_value=({}, ret_body))
        res_iter = DomainResultsIterator(mgr)
        ret = res_iter.next()
        self.assertTrue(isinstance(ret, CloudDNSDomain))
        clt.method_get.assert_called_once_with("/domains")

    def test_iter_items_next_fetch(self):
        clt = self.client
        mgr = clt._manager
        fake_name = utils.random_unicode()
        ret_body = {"domains": [{"name": fake_name}]}
        clt.method_get = Mock(return_value=({}, ret_body))
        res_iter = DomainResultsIterator(mgr)
        res_iter.next_uri = example_uri
        ret = res_iter.next()
        self.assertTrue(isinstance(ret, CloudDNSDomain))

    def test_iter_items_next_stop(self):
        clt = self.client
        mgr = clt._manager
        res_iter = DomainResultsIterator(mgr)
        res_iter.next_uri = None
        self.assertRaises(StopIteration, res_iter.next)

    def test_subdomain_iter(self):
        clt = self.client
        mgr = clt._manager
        res_iter = SubdomainResultsIterator(mgr)
        self.assertEqual(res_iter.paging_service, "subdomain")

    def test_record_iter(self):
        clt = self.client
        mgr = clt._manager
        res_iter = RecordResultsIterator(mgr)
        self.assertEqual(res_iter.paging_service, "record")

    # patch BaseClients method_get to make it always return an empty
    # body. client method_get uses super to get at BaseClient's
    # method_get.
    @patch.object(pyrax.client.BaseClient, "method_get",
            new=lambda x, y: (None, None))
    def test_client_empty_get_body_error(self):
        clt = self.client
        self.assertRaises(exc.ServiceResponseFailure, clt.get_absolute_limits)


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_cloud_loadbalancers
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import random
import unittest

from mock import patch
from mock import MagicMock as Mock

from pyrax.cloudloadbalancers import CloudLoadBalancerClient
from pyrax.cloudloadbalancers import CloudLoadBalancer
from pyrax.cloudloadbalancers import Node
from pyrax.cloudloadbalancers import VirtualIP
from pyrax.cloudloadbalancers import assure_parent
from pyrax.cloudloadbalancers import assure_loadbalancer
import pyrax.exceptions as exc
import pyrax.utils as utils

from pyrax import fakes

example_uri = "http://example.com"


class CloudLoadBalancerTest(unittest.TestCase):
    def __init__(self, *args, **kwargs):
        super(CloudLoadBalancerTest, self).__init__(*args, **kwargs)

    def setUp(self):
        self.loadbalancer = fakes.FakeLoadBalancer()
        self.client = fakes.FakeLoadBalancerClient()

    def tearDown(self):
        self.loadbalancer = None
        self.client = None

    def test_assure_parent_fail(self):
        orphan_node = Node(address="fake", port="fake")
        self.assertRaises(exc.UnattachedNode, orphan_node.update)

    def test_assure_parent_succeed(self):
        adopted_node = Node(address="fake", port="fake",
                parent=fakes.FakeLoadBalancer())
        diff = "DIFF"
        adopted_node._diff = Mock(return_value=diff)
        adopted_node.parent.update_node = Mock()
        adopted_node.update()
        adopted_node.parent.update_node.assert_called_once_with(adopted_node,
                diff)

    def test_assure_loadbalancer(self):

        class TestClient(object):
            _manager = fakes.FakeManager()

            @assure_loadbalancer
            def test_method(self, loadbalancer):
                return loadbalancer

        client = TestClient()
        client._manager.get = Mock(return_value=self.loadbalancer)
        # Pass the loadbalancer
        ret = client.test_method(self.loadbalancer)
        self.assertTrue(ret is self.loadbalancer)
        # Pass the ID
        ret = client.test_method(self.loadbalancer.id)
        self.assertTrue(ret is self.loadbalancer)

    def test_add_nodes_client(self):
        clt = self.client
        lb = self.loadbalancer
        nd = fakes.FakeNode()
        lb.manager.add_nodes = Mock()
        clt.add_nodes(lb, nd)
        lb.manager.add_nodes.assert_called_once_with(lb, nd)

    def test_node_equality(self):
        node1 = Node(address="192.168.1.1", port=80)
        node2 = Node(address="192.168.1.2", port=80)
        node3 = Node(address="192.168.1.1", port=80)

        self.assertFalse(node1 == node2)
        self.assertFalse(node2 == node1)
        self.assertTrue(node1 != node2)
        self.assertTrue(node2 != node1)
        self.assertTrue(node2 != node3)
        self.assertTrue(node3 != node2)
        self.assertTrue(node1 == node3)
        self.assertTrue(node3 == node1)

    def test_add_virtualip_client(self):
        clt = self.client
        lb = self.loadbalancer
        vip = fakes.FakeVirtualIP()
        lb.manager.add_virtualip = Mock()
        clt.add_virtualip(lb, vip)
        lb.manager.add_virtualip.assert_called_once_with(lb, vip)

    def test_get_usage(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.get_usage = Mock()
        lb.get_usage()
        mgr.get_usage.assert_called_once_with(lb, start=None, end=None)

    def test_add_details_nodes(self):
        fake_node_info = {"address": "0.0.0.0", "id": 1, "type": "PRIMARY",
                "port": 80, "status": "OFFLINE", "condition": "ENABLED"}
        info = {"nodes": [fake_node_info]}
        lb = fakes.FakeLoadBalancer(name="fake", info=info)
        node = lb.nodes[0]
        self.assertEqual(node.address, fake_node_info["address"])

    def test_add_details_virtualips(self):
        fake_vip_info = {"address": "0.0.0.0", "id": 1, "type": "PUBLIC",
                "ipVersion": "IPV4"}
        info = {"virtualIps": [fake_vip_info]}
        lb = fakes.FakeLoadBalancer(name="fake", info=info)
        vip = lb.virtual_ips[0]
        self.assertEqual(vip.address, fake_vip_info["address"])

    def test_add_details_session_persistence(self):
        info = {"sessionPersistence": {"persistenceType": "fake"}}
        lb = fakes.FakeLoadBalancer(name="fake", info=info)
        self.assertEqual(lb.sessionPersistence,
                info["sessionPersistence"]["persistenceType"])

    def test_add_details_cluster(self):
        info = {"cluster": {"name": "fake"}}
        lb = fakes.FakeLoadBalancer(name="fake", info=info)
        self.assertEqual(lb.cluster, info["cluster"]["name"])

    def test_client_update_lb(self):
        clt = self.client
        lb = self.loadbalancer
        mgr = clt._manager
        mgr.update = Mock()
        name = utils.random_unicode()
        algorithm = utils.random_unicode()
        timeout = utils.random_unicode()
        httpsRedirect = utils.random_unicode()
        clt.update(lb, name=name, algorithm=algorithm, timeout=timeout,
                httpsRedirect=httpsRedirect)
        mgr.update.assert_called_once_with(lb, name=name, algorithm=algorithm,
                protocol=None, halfClosed=None, port=None, timeout=timeout,
                httpsRedirect=httpsRedirect)

    def test_lb_update_lb(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.update = Mock()
        name = utils.random_unicode()
        algorithm = utils.random_unicode()
        timeout = utils.random_unicode()
        httpsRedirect = utils.random_unicode()
        lb.update(name=name, algorithm=algorithm, timeout=timeout,
                httpsRedirect=httpsRedirect)
        mgr.update.assert_called_once_with(lb, name=name, algorithm=algorithm,
                protocol=None, halfClosed=None, port=None, timeout=timeout,
                httpsRedirect=httpsRedirect)

    def test_mgr_update_lb(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_put = Mock(return_value=(None, None))
        name = utils.random_unicode()
        algorithm = utils.random_unicode()
        timeout = utils.random_unicode()
        mgr.update(lb, name=name, algorithm=algorithm, timeout=timeout)
        exp_uri = "/loadbalancers/%s" % lb.id
        exp_body = {"loadBalancer": {"name": name, "algorithm": algorithm,
                "timeout": timeout}}
        mgr.api.method_put.assert_called_once_with(exp_uri, body=exp_body)

    def test_client_delete_node(self):
        clt = self.client
        lb = self.loadbalancer
        nd = fakes.FakeNode()
        nd.parent = lb
        lb.manager.delete_node = Mock()
        clt.delete_node(nd)
        lb.manager.delete_node.assert_called_once_with(lb, nd)

    def test_client_update_node(self):
        clt = self.client
        lb = self.loadbalancer
        nd = fakes.FakeNode()
        nd.parent = lb
        diff = "DIFF"
        nd._diff = Mock(return_value=diff)
        lb.manager.update_node = Mock()
        clt.update_node(nd)
        lb.manager.update_node.assert_called_once_with(nd, diff=diff)

    def test_client_delete_virtualip(self):
        clt = self.client
        lb = self.loadbalancer
        vip = fakes.FakeVirtualIP()
        vip.parent = lb
        lb.manager.delete_virtualip = Mock()
        clt.delete_virtualip(vip)
        lb.manager.delete_virtualip.assert_called_once_with(lb, vip)

    def test_client_get_access_list(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.get_access_list = Mock()
        clt.get_access_list(lb)
        lb.manager.get_access_list.assert_called_once_with(lb)

    def test_client_add_access_list(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.add_access_list = Mock()
        alist = {"fake": "fake"}
        clt.add_access_list(lb, alist)
        lb.manager.add_access_list.assert_called_once_with(lb, alist)

    def test_client_delete_access_list(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.delete_access_list = Mock()
        clt.delete_access_list(lb)
        lb.manager.delete_access_list.assert_called_once_with(lb)

    def test_client_delete_access_list_items(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.delete_access_list_items = Mock()
        fake_ids = [1, 2, 3]
        clt.delete_access_list_items(lb, fake_ids)
        lb.manager.delete_access_list_items.assert_called_once_with(lb,
                fake_ids)

    def test_client_get_health_monitor(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.get_health_monitor = Mock()
        clt.get_health_monitor(lb)
        lb.manager.get_health_monitor.assert_called_once_with(lb)

    def test_client_add_health_monitor(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.add_health_monitor = Mock()
        fake_type = "fake"
        fake_delay = 99
        fake_timeout = 99
        fake_attemptsBeforeDeactivation = 99
        fake_path = "/fake"
        fake_statusRegex = ".*fake.*"
        fake_bodyRegex = ".*fake.*"
        fake_hostHeader = "fake"
        clt.add_health_monitor(lb, type=fake_type, delay=fake_delay,
                timeout=fake_timeout,
                attemptsBeforeDeactivation=fake_attemptsBeforeDeactivation,
                path=fake_path, statusRegex=fake_statusRegex,
                bodyRegex=fake_bodyRegex, hostHeader=fake_hostHeader)
        lb.manager.add_health_monitor.assert_called_once_with(lb,
                type=fake_type, delay=fake_delay, timeout=fake_timeout,
                attemptsBeforeDeactivation=fake_attemptsBeforeDeactivation,
                path=fake_path, statusRegex=fake_statusRegex,
                bodyRegex=fake_bodyRegex, hostHeader=fake_hostHeader)

    def test_client_delete_health_monitor(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.delete_health_monitor = Mock()
        clt.delete_health_monitor(lb)
        lb.manager.delete_health_monitor.assert_called_once_with(lb)

    def test_client_get_connection_throttle(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.get_connection_throttle = Mock()
        clt.get_connection_throttle(lb)
        lb.manager.get_connection_throttle.assert_called_once_with(lb)

    def test_client_add_connection_throttle(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.add_connection_throttle = Mock()
        fake_maxConnectionRate = 99
        fake_maxConnections = 99
        fake_minConnections = 99
        fake_rateInterval = 99
        clt.add_connection_throttle(lb)
        self.assertEqual(lb.manager.add_connection_throttle.call_count, 0)
        clt.add_connection_throttle(lb,
                maxConnectionRate=fake_maxConnectionRate,
                maxConnections=fake_minConnections,
                minConnections=fake_minConnections,
                rateInterval=fake_rateInterval)
        lb.manager.add_connection_throttle.assert_called_once_with(lb,
                maxConnectionRate=fake_maxConnectionRate,
                maxConnections=fake_minConnections,
                minConnections=fake_minConnections,
                rateInterval=fake_rateInterval)

    def test_client_delete_connection_throttle(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.delete_connection_throttle = Mock()
        clt.delete_connection_throttle(lb)
        lb.manager.delete_connection_throttle.assert_called_once_with(lb)

    def test_client_get_ssl_termination(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.get_ssl_termination = Mock()
        clt.get_ssl_termination(lb)
        lb.manager.get_ssl_termination.assert_called_once_with(lb)

    def test_client_add_ssl_termination(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.add_ssl_termination = Mock()
        fake_securePort = 99
        fake_privatekey = "fake"
        fake_certificate = "fake"
        fake_intermediateCertificate = "fake"
        fake_enabled = True
        fake_secureTrafficOnly = False
        clt.add_ssl_termination(lb, securePort=fake_securePort,
                privatekey=fake_privatekey, certificate=fake_certificate,
                intermediateCertificate=fake_intermediateCertificate,
                enabled=fake_enabled, secureTrafficOnly=fake_secureTrafficOnly)
        lb.manager.add_ssl_termination.assert_called_once_with(lb,
                securePort=fake_securePort, privatekey=fake_privatekey,
                certificate=fake_certificate,
                intermediateCertificate=fake_intermediateCertificate,
                enabled=fake_enabled, secureTrafficOnly=fake_secureTrafficOnly)

    def test_client_update_ssl_termination(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.update_ssl_termination = Mock()
        fake_securePort = 99
        fake_enabled = True
        fake_secureTrafficOnly = False
        clt.update_ssl_termination(lb, securePort=fake_securePort,
                enabled=fake_enabled, secureTrafficOnly=fake_secureTrafficOnly)
        lb.manager.update_ssl_termination.assert_called_once_with(lb,
                securePort=fake_securePort, enabled=fake_enabled,
                secureTrafficOnly=fake_secureTrafficOnly)

    def test_client_delete_ssl_termination(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.delete_ssl_termination = Mock()
        clt.delete_ssl_termination(lb)
        lb.manager.delete_ssl_termination.assert_called_once_with(lb)

    def test_client_get_metadata(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.get_metadata = Mock()
        clt.get_metadata(lb)
        lb.manager.get_metadata.assert_called_once_with(lb)

    def test_client_set_metadata(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.set_metadata = Mock()
        meta = {"fake": "fake"}
        clt.set_metadata(lb, meta)
        lb.manager.set_metadata.assert_called_once_with(lb, meta)

    def test_client_update_metadata(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.update_metadata = Mock()
        meta = {"fake": "fake"}
        clt.update_metadata(lb, meta)
        lb.manager.update_metadata.assert_called_once_with(lb, meta)

    def test_client_delete_metadata(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.delete_metadata = Mock()
        keys = [1, 2, 3]
        clt.delete_metadata(lb, keys=keys)
        lb.manager.delete_metadata.assert_called_once_with(lb, keys=keys)

    def test_client_get_metadata_for_node(self):
        clt = self.client
        lb = self.loadbalancer
        nd = fakes.FakeNode()
        lb.manager.get_metadata = Mock()
        clt.get_metadata_for_node(lb, nd)
        lb.manager.get_metadata.assert_called_once_with(lb, node=nd)

    def test_client_set_metadata_for_node(self):
        clt = self.client
        lb = self.loadbalancer
        nd = fakes.FakeNode()
        lb.manager.set_metadata = Mock()
        meta = {"fake": "fake"}
        clt.set_metadata_for_node(lb, nd, meta)
        lb.manager.set_metadata.assert_called_once_with(lb, meta, node=nd)

    def test_client_update_metadata_for_node(self):
        clt = self.client
        lb = self.loadbalancer
        nd = fakes.FakeNode()
        lb.manager.update_metadata = Mock()
        meta = {"fake": "fake"}
        clt.update_metadata_for_node(lb, nd, meta)
        lb.manager.update_metadata.assert_called_once_with(lb, meta, node=nd)

    def test_client_delete_metadata_for_node(self):
        clt = self.client
        lb = self.loadbalancer
        nd = fakes.FakeNode()
        lb.manager.delete_metadata = Mock()
        keys = [1, 2, 3]
        clt.delete_metadata_for_node(lb, nd, keys=keys)
        lb.manager.delete_metadata.assert_called_once_with(lb, node=nd,
                keys=keys)

    def test_client_get_error_page(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.get_error_page = Mock()
        clt.get_error_page(lb)
        lb.manager.get_error_page.assert_called_once_with(lb)

    def test_client_set_error_page(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.set_error_page = Mock()
        ep = "<fake>"
        clt.set_error_page(lb, ep)
        lb.manager.set_error_page.assert_called_once_with(lb, ep)

    def test_client_clear_error_page(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.clear_error_page = Mock()
        clt.clear_error_page(lb)
        lb.manager.clear_error_page.assert_called_once_with(lb)

    def test_client_get_connection_logging(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.get_connection_logging = Mock()
        clt.get_connection_logging(lb)
        lb.manager.get_connection_logging.assert_called_once_with(lb)

    def test_client_set_connection_logging(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.set_connection_logging = Mock()
        clt.set_connection_logging(lb, True)
        lb.manager.set_connection_logging.assert_called_once_with(lb, True)

    def test_client_get_content_caching(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.get_content_caching = Mock()
        clt.get_content_caching(lb)
        lb.manager.get_content_caching.assert_called_once_with(lb)

    def test_client_set_content_caching(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.set_content_caching = Mock()
        clt.set_content_caching(lb, True)
        lb.manager.set_content_caching.assert_called_once_with(lb, True)

    def test_client_get_session_persistence(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.get_session_persistence = Mock()
        clt.get_session_persistence(lb)
        lb.manager.get_session_persistence.assert_called_once_with(lb)

    def test_client_set_session_persistence_bad(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.set_session_persistence = Mock()
        self.assertRaises(exc.InvalidSessionPersistenceType,
                clt.set_session_persistence, lb, "BAD")

    def test_client_set_session_persistence(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.set_session_persistence = Mock()
        clt.set_session_persistence(lb, "HTTP_COOKIE")
        lb.manager.set_session_persistence.assert_called_once_with(lb,
                "HTTP_COOKIE")

    def test_client_clear_session_persistence(self):
        clt = self.client
        lb = self.loadbalancer
        lb.manager.delete_session_persistence = Mock()
        clt.set_session_persistence(lb, "")
        lb.manager.delete_session_persistence.assert_called_once_with(lb)

    def test_mgr_add_nodes(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_post = Mock(return_value=({}, {}))
        nd = fakes.FakeNode()
        mgr.add_nodes(lb, nd)
        uri = "/loadbalancers/%s/nodes" % lb.id
        ndict = nd.to_dict()
        mgr.api.method_post.assert_called_once_with(uri,
                body={"nodes": [ndict]})

    def test_mgr_delete_node(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_delete = Mock(return_value=({}, {}))
        nd = fakes.FakeNode()
        nd.parent = lb
        uri = "/loadbalancers/%s/nodes/%s" % (lb.id, nd.id)
        mgr.delete_node(lb, nd)
        mgr.api.method_delete.assert_called_once_with(uri)

    def test_mgr_delete_unattached_node(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_delete = Mock(return_value=({}, {}))
        nd = fakes.FakeNode()
        self.assertRaises(exc.UnattachedNode, mgr.delete_node, lb, nd)

    def test_mgr_update_node(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_put = Mock(return_value=({}, {}))
        nd = fakes.FakeNode()
        nd.parent = lb
        uri = "/loadbalancers/%s/nodes/%s" % (lb.id, nd.id)
        mgr.update_node(nd)
        mgr.api.method_put.assert_called_once_with(uri, body={"node": {}})

    def test_mgr_update_unattached_node(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_put = Mock(return_value=({}, {}))
        nd = fakes.FakeNode()
        self.assertRaises(exc.UnattachedNode, mgr.update_node, nd)

    def test_mgr_add_virtualip(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_post = Mock(return_value=({}, {}))
        vip = fakes.FakeVirtualIP()
        mgr.add_virtualip(lb, vip)
        uri = "/loadbalancers/%s/virtualips" % lb.id
        mgr.api.method_post.assert_called_once_with(uri, body=vip.to_dict())

    def test_mgr_delete_virtualip(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_delete = Mock(return_value=({}, {}))
        vip = fakes.FakeVirtualIP()
        vip.parent = lb
        uri = "/loadbalancers/%s/virtualips/%s" % (lb.id, vip.id)
        mgr.delete_virtualip(lb, vip)
        mgr.api.method_delete.assert_called_once_with(uri)

    def test_mgr_delete_unattached_virtualip(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_put = Mock(return_value=({}, {}))
        vip = fakes.FakeVirtualIP()
        self.assertRaises(exc.UnattachedVirtualIP, mgr.delete_virtualip, lb,
                vip)

    def test_mgr_get_access_list(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_get = Mock(return_value=({}, {}))
        mgr.get_access_list(lb)
        uri = "/loadbalancers/%s/accesslist" % lb.id
        mgr.api.method_get.assert_called_once_with(uri)

    def test_mgr_add_access_list(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_post = Mock(return_value=({}, {}))
        alist = {"fake": "fake"}
        mgr.add_access_list(lb, alist)
        uri = "/loadbalancers/%s/accesslist" % lb.id
        req_body = {"accessList": alist}
        mgr.api.method_post.assert_called_once_with(uri, body=req_body)

    def test_mgr_delete_access_list(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_delete = Mock(return_value=({}, {}))
        uri = "/loadbalancers/%s/accesslist" % lb.id
        mgr.delete_access_list(lb)
        mgr.api.method_delete.assert_called_once_with(uri)

    def test_mgr_delete_access_list_items(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_delete = Mock(return_value=({}, {}))
        fake_id = 3
        acc_ids = [{"id": 1}, {"id": 2}, {"id": 3}]
        mgr.get_access_list = Mock(return_value=acc_ids)
        uri = "/loadbalancers/%s/accesslist?id=3" % lb.id
        mgr.delete_access_list_items(lb, fake_id)
        mgr.api.method_delete.assert_called_once_with(uri)

    def test_mgr_delete_access_list_items_invalid(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_delete = Mock(return_value=({}, {}))
        ids = [1, 2, 99]
        acc_ids = [{"id": 1}, {"id": 2}, {"id": 3}]
        mgr.get_access_list = Mock(return_value=acc_ids)
        self.assertRaises(exc.AccessListIDNotFound,
                mgr.delete_access_list_items, lb, ids)

    def test_mgr_get_health_monitor(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_get = Mock(return_value=({}, {}))
        mgr.get_health_monitor(lb)
        uri = "/loadbalancers/%s/healthmonitor" % lb.id
        mgr.api.method_get.assert_called_once_with(uri)

    def test_mgr_add_health_monitor(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_put = Mock(return_value=({}, {}))
        fake_type = "HTTP"
        fake_delay = 99
        fake_timeout = 99
        fake_attemptsBeforeDeactivation = 99
        fake_path = "/fake"
        fake_statusRegex = ".*fake.*"
        fake_bodyRegex = ".*fake.*"
        fake_hostHeader = "fake"
        lb.protocol = fake_type
        mgr.add_health_monitor(lb, type=fake_type, delay=fake_delay,
                timeout=fake_timeout,
                attemptsBeforeDeactivation=fake_attemptsBeforeDeactivation,
                path=fake_path, statusRegex=fake_statusRegex,
                bodyRegex=fake_bodyRegex, hostHeader=fake_hostHeader)
        uri = "/loadbalancers/%s/healthmonitor" % lb.id
        req_body = {"healthMonitor": {
                "type": fake_type,
                "delay": fake_delay,
                "timeout": fake_timeout,
                "attemptsBeforeDeactivation": fake_attemptsBeforeDeactivation,
                "path": fake_path,
                "statusRegex": fake_statusRegex,
                "bodyRegex": fake_bodyRegex,
                "hostHeader": fake_hostHeader,
                }}
        mgr.api.method_put.assert_called_once_with(uri, body=req_body)

    def test_mgr_add_health_monitor_bad_protocol(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_put = Mock(return_value=({}, {}))
        fake_type = "HTTP"
        fake_delay = 99
        fake_timeout = 99
        fake_attemptsBeforeDeactivation = 99
        fake_path = "/fake"
        fake_statusRegex = ".*fake.*"
        fake_bodyRegex = ".*fake.*"
        fake_hostHeader = "fake"
        lb.protocol = "BAD"
        self.assertRaises(exc.ProtocolMismatch, mgr.add_health_monitor, lb,
                type=fake_type, delay=fake_delay, timeout=fake_timeout,
                attemptsBeforeDeactivation=fake_attemptsBeforeDeactivation,
                path=fake_path, statusRegex=fake_statusRegex,
                bodyRegex=fake_bodyRegex, hostHeader=fake_hostHeader)

    def test_mgr_add_health_monitor_missing_cert(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_put = Mock(return_value=({}, {}))
        fake_type = "HTTP"
        fake_delay = 99
        fake_timeout = 99
        fake_attemptsBeforeDeactivation = 99
        fake_path = "/fake"
        fake_statusRegex = None
        fake_bodyRegex = None
        fake_hostHeader = "fake"
        lb.protocol = fake_type
        self.assertRaises(exc.MissingHealthMonitorSettings,
                mgr.add_health_monitor, lb, type=fake_type, delay=fake_delay,
                timeout=fake_timeout,
                attemptsBeforeDeactivation=fake_attemptsBeforeDeactivation,
                path=fake_path, statusRegex=fake_statusRegex,
                bodyRegex=fake_bodyRegex, hostHeader=fake_hostHeader)

    def test_mgr_delete_health_monitor(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_delete = Mock(return_value=({}, {}))
        uri = "/loadbalancers/%s/healthmonitor" % lb.id
        mgr.delete_health_monitor(lb)
        mgr.api.method_delete.assert_called_once_with(uri)

    def test_mgr_get_connection_throttle(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_get = Mock(return_value=({}, {}))
        mgr.get_connection_throttle(lb)
        uri = "/loadbalancers/%s/connectionthrottle" % lb.id
        mgr.api.method_get.assert_called_once_with(uri)

    def test_mgr_add_connection_throttle(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_put = Mock(return_value=({}, {}))
        fake_maxConnectionRate = 99
        fake_maxConnections = 99
        fake_minConnections = 99
        fake_rateInterval = 99
        mgr.add_connection_throttle(lb,
                maxConnectionRate=fake_maxConnectionRate,
                maxConnections=fake_minConnections,
                minConnections=fake_minConnections,
                rateInterval=fake_rateInterval)
        uri = "/loadbalancers/%s/connectionthrottle" % lb.id
        req_body = {"connectionThrottle": {
                "maxConnectionRate": fake_maxConnectionRate,
                "maxConnections": fake_minConnections,
                "minConnections": fake_minConnections,
                "rateInterval": fake_rateInterval,
                }}
        mgr.api.method_put.assert_called_once_with(uri, body=req_body)

    def test_mgr_delete_connection_throttle(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_delete = Mock(return_value=({}, {}))
        uri = "/loadbalancers/%s/connectionthrottle" % lb.id
        mgr.delete_connection_throttle(lb)
        mgr.api.method_delete.assert_called_once_with(uri)

    def test_mgr_get_ssl_termination(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_get = Mock(return_value=({}, {}))
        mgr.get_ssl_termination(lb)
        uri = "/loadbalancers/%s/ssltermination" % lb.id
        mgr.api.method_get.assert_called_once_with(uri)

    def test_mgr_get_ssl_termination_missing(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_get = Mock(side_effect=exc.NotFound("fake"))
        ret = mgr.get_ssl_termination(lb)
        self.assertEqual(ret, {})

    def test_mgr_add_ssl_termination(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_put = Mock(return_value=({}, {}))
        fake_securePort = 99
        fake_privatekey = "fake"
        fake_certificate = "fake"
        fake_intermediateCertificate = "fake"
        fake_enabled = True
        fake_secureTrafficOnly = False
        mgr.add_ssl_termination(lb, securePort=fake_securePort,
                privatekey=fake_privatekey, certificate=fake_certificate,
                intermediateCertificate=fake_intermediateCertificate,
                enabled=fake_enabled, secureTrafficOnly=fake_secureTrafficOnly)
        uri = "/loadbalancers/%s/ssltermination" % lb.id
        req_body = {"sslTermination": {
                "certificate": fake_certificate,
                "enabled": fake_enabled,
                "secureTrafficOnly": fake_secureTrafficOnly,
                "privatekey": fake_privatekey,
                "intermediateCertificate": fake_intermediateCertificate,
                "securePort": fake_securePort
                }}
        mgr.api.method_put.assert_called_once_with(uri, body=req_body)

    def test_mgr_update_ssl_termination_no_config(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.get_ssl_termination = Mock(return_value=None)
        self.assertRaises(exc.NoSSLTerminationConfiguration,
                mgr.update_ssl_termination, lb)

    def test_mgr_update_ssl_termination(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_put = Mock(return_value=({}, {}))
        fake_securePort = 99
        fake_enabled = True
        fake_secureTrafficOnly = False
        fake_config = {"securePort": fake_securePort,
                "enabled": fake_enabled,
                "secureTrafficOnly": fake_secureTrafficOnly}
        mgr.get_ssl_termination = Mock(return_value=fake_config)

        mgr.update_ssl_termination(lb)
        uri = "/loadbalancers/%s/ssltermination" % lb.id
        req_body = {"sslTermination": {
                "enabled": fake_enabled,
                "secureTrafficOnly": fake_secureTrafficOnly,
                "securePort": fake_securePort
                }}
        mgr.api.method_put.assert_called_once_with(uri, body=req_body)

    def test_mgr_delete_ssl_termination(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_delete = Mock(return_value=({}, {}))
        uri = "/loadbalancers/%s/ssltermination" % lb.id
        mgr.delete_ssl_termination(lb)
        mgr.api.method_delete.assert_called_once_with(uri)

    def test_mgr_get_metadata(self):
        lb = self.loadbalancer
        mgr = lb.manager
        fake_meta = {"fakekey": "fakeval"}
        fake_screwy_meta = [{"key": "fakekey", "value": "fakeval", "id": 1}]
        mgr.api.method_get = Mock(return_value=({},
                {"metadata": fake_screwy_meta}))
        ret = mgr.get_metadata(lb)
        uri = "/loadbalancers/%s/metadata" % lb.id
        mgr.api.method_get.assert_called_once_with(uri)
        self.assertEqual(ret, fake_meta)

    def test_mgr_get_node_metadata(self):
        lb = self.loadbalancer
        mgr = lb.manager
        fake_meta = {"fakekey": "fakeval"}
        fake_screwy_meta = [{"key": "fakekey", "value": "fakeval", "id": 1}]
        mgr.api.method_get = Mock(return_value=({},
                {"metadata": fake_screwy_meta}))
        nd = fakes.FakeNode()
        ret = mgr.get_metadata(lb, node=nd)
        uri = "/loadbalancers/%s/nodes/%s/metadata" % (lb.id, nd.id)
        mgr.api.method_get.assert_called_once_with(uri)
        self.assertEqual(ret, fake_meta)

    def test_mgr_get_metadata_raw(self):
        lb = self.loadbalancer
        mgr = lb.manager
        fake_meta = {"fakekey": "fakeval"}
        fake_screwy_meta = [{"key": "fakekey", "value": "fakeval", "id": 1}]
        mgr.api.method_get = Mock(return_value=({},
                {"metadata": fake_screwy_meta}))
        ret = mgr.get_metadata(lb, raw=True)
        uri = "/loadbalancers/%s/metadata" % lb.id
        mgr.api.method_get.assert_called_once_with(uri)
        self.assertEqual(ret, fake_screwy_meta)

    def test_mgr_set_metadata(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.delete_metadata = Mock()
        fake_meta = {"fakekey": "fakeval"}
        fake_screwy_meta = [{"key": "fakekey", "value": "fakeval"}]
        mgr.api.method_post = Mock(return_value=({},
                {"metadata": fake_screwy_meta}))
        mgr.set_metadata(lb, fake_meta)
        uri = "/loadbalancers/%s/metadata" % lb.id
        req_body = {"metadata": fake_screwy_meta}
        mgr.api.method_post.assert_called_once_with(uri, body=req_body)

    def test_mgr_set_node_metadata(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.delete_metadata = Mock()
        fake_meta = {"fakekey": "fakeval"}
        fake_screwy_meta = [{"key": "fakekey", "value": "fakeval"}]
        mgr.api.method_post = Mock(return_value=({},
                {"metadata": fake_screwy_meta}))
        nd = fakes.FakeNode()
        mgr.set_metadata(lb, fake_meta, node=nd)
        uri = "/loadbalancers/%s/nodes/%s/metadata" % (lb.id, nd.id)
        req_body = {"metadata": fake_screwy_meta}
        mgr.api.method_post.assert_called_once_with(uri, body=req_body)

    def test_mgr_update_metadata(self):
        lb = self.loadbalancer
        mgr = lb.manager
        fake_meta = {"fakekey": "fakeval"}
        fake_screwy_meta = [{"key": "fakekey", "value": "fakeval", "id": 1}]
        fake_new_meta = {"fakekey": "updated", "fakeNEWkey": "fakeNEWval"}
        fake_screwy_upd_meta = [{"key": "fakekey", "value": "updated"}]
        fake_screwy_new_meta = [{"key": "fakeNEWkey", "value": "fakeNEWval"}]
        mgr.get_metadata = Mock(return_value=fake_screwy_meta)
        mgr.api.method_post = Mock(return_value=({}, {}))
        mgr.api.method_put = Mock(return_value=({}, {}))
        mgr.update_metadata(lb, fake_new_meta)
        uri = "/loadbalancers/%s/metadata" % lb.id
        req_body = {"metadata": fake_screwy_new_meta}
        upd_req_body = {"meta": {"value": "updated"}}
        mgr.api.method_post.assert_called_once_with(uri, body=req_body)
        mgr.api.method_put.assert_called_once_with(uri, body=upd_req_body)

    def test_mgr_update_node_metadata(self):
        lb = self.loadbalancer
        mgr = lb.manager
        nd = fakes.FakeNode()
        fake_meta = {"fakekey": "fakeval"}
        fake_screwy_meta = [{"key": "fakekey", "value": "fakeval", "id": 1}]
        fake_new_meta = {"fakekey": "updated", "fakeNEWkey": "fakeNEWval"}
        fake_screwy_upd_meta = [{"key": "fakekey", "value": "updated"}]
        fake_screwy_new_meta = [{"key": "fakeNEWkey", "value": "fakeNEWval"}]
        mgr.get_metadata = Mock(return_value=fake_screwy_meta)
        mgr.api.method_post = Mock(return_value=({}, {}))
        mgr.api.method_put = Mock(return_value=({}, {}))
        mgr.update_metadata(lb, fake_new_meta, node=nd)
        put_uri = "/loadbalancers/%s/nodes/%s/metadata/1" % (lb.id, nd.id)
        post_uri = "/loadbalancers/%s/nodes/%s/metadata" % (lb.id, nd.id)
        req_body = {"metadata": fake_screwy_new_meta}
        upd_req_body = {"meta": {"value": "updated"}}
        mgr.api.method_post.assert_called_once_with(post_uri, body=req_body)
        mgr.api.method_put.assert_called_once_with(put_uri, body=upd_req_body)

    def test_mgr_delete_metadata(self):
        lb = self.loadbalancer
        mgr = lb.manager
        fake_meta = {"fakekey": "fakeval"}
        fake_screwy_meta = [{"key": "fakekey", "value": "fakeval", "id": 1}]
        fake_meta_key = fake_screwy_meta[0]["key"]
        fake_meta_id = fake_screwy_meta[0]["id"]
        mgr.get_metadata = Mock(return_value=fake_screwy_meta)
        mgr.api.method_delete = Mock(return_value=({}, {}))
        # No match, should be a noop
        mgr.delete_metadata(lb, keys="BAD")
        self.assertEqual(mgr.api.method_delete.call_count, 0)
        mgr.delete_metadata(lb, keys=fake_meta_key)
        uri = "/loadbalancers/%s/metadata?id=%s" % (lb.id, fake_meta_id)
        mgr.api.method_delete.assert_called_once_with(uri)

    def test_mgr_delete_node_metadata(self):
        lb = self.loadbalancer
        mgr = lb.manager
        nd = fakes.FakeNode()
        fake_meta = {"fakekey": "fakeval"}
        fake_screwy_meta = [{"key": "fakekey", "value": "fakeval", "id": 1}]
        fake_meta_key = fake_screwy_meta[0]["key"]
        fake_meta_id = fake_screwy_meta[0]["id"]
        mgr.get_metadata = Mock(return_value=fake_screwy_meta)
        mgr.api.method_delete = Mock(return_value=({}, {}))
        # No match, should be a noop
        mgr.delete_metadata(lb, keys="BAD", node=nd)
        self.assertEqual(mgr.api.method_delete.call_count, 0)
        mgr.delete_metadata(lb, keys=fake_meta_key, node=nd)
        uri = "/loadbalancers/%s/nodes/%s/metadata?id=%s" % (lb.id, nd.id,
                fake_meta_id)
        mgr.api.method_delete.assert_called_once_with(uri)

    def test_mgr_get_error_page(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_get = Mock(return_value=({}, {}))
        mgr.get_error_page(lb)
        uri = "/loadbalancers/%s/errorpage" % lb.id
        mgr.api.method_get.assert_called_once_with(uri)

    def test_mgr_set_error_page(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_put = Mock(return_value=({}, {}))
        ep = "<fake>"
        mgr.set_error_page(lb, ep)
        uri = "/loadbalancers/%s/errorpage" % lb.id
        req_body = {"errorpage": {"content": ep}}
        mgr.api.method_put.assert_called_once_with(uri, body=req_body)

    def test_mgr_clear_error_page(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_delete = Mock(return_value=({}, {}))
        uri = "/loadbalancers/%s/errorpage" % lb.id
        mgr.clear_error_page(lb)
        mgr.api.method_delete.assert_called_once_with(uri)

    def test_mgr_get_usage_all(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_get = Mock(return_value=({}, {}))
        mgr.get_usage()
        uri = "/loadbalancers/usage"
        mgr.api.method_get.assert_called_once_with(uri)

    def test_mgr_get_usage_for_lb(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_get = Mock(return_value=({}, {}))
        mgr.get_usage(loadbalancer=lb)
        uri = "/loadbalancers/%s/usage" % lb.id
        mgr.api.method_get.assert_called_once_with(uri)

    def test_mgr_get_usage_period(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_get = Mock(return_value=({}, {}))
        start = "1999-12-31"
        end = "2000-01-01"
        start_iso = "1999-12-31T00:00:00"
        end_iso = "2000-01-01T00:00:00"
        mgr.get_usage(start=start, end=end)
        uri = "/loadbalancers/usage?startTime=%s&endTime=%s" % (start_iso,
                end_iso)
        mgr.api.method_get.assert_called_once_with(uri)

    def test_mgr_get_stats(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_get = Mock(return_value=({}, {}))
        mgr.get_stats(lb)
        uri = "/loadbalancers/%s/stats" % lb.id
        mgr.api.method_get.assert_called_once_with(uri)

    def test_mgr_get_session_persistence(self):
        lb = self.loadbalancer
        mgr = lb.manager
        fake_type = "FAKE"
        body = {"sessionPersistence": {"persistenceType": fake_type}}
        mgr.api.method_get = Mock(return_value=({}, body))
        mgr.get_session_persistence(lb)
        uri = "/loadbalancers/%s/sessionpersistence" % lb.id
        mgr.api.method_get.assert_called_once_with(uri)

    def test_mgr_set_session_persistence(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_put = Mock(return_value=({}, {}))
        fake_type = "FAKE"
        mgr.set_session_persistence(lb, fake_type)
        uri = "/loadbalancers/%s/sessionpersistence" % lb.id
        req_body = {"sessionPersistence": {"persistenceType": fake_type}}
        mgr.api.method_put.assert_called_once_with(uri, body=req_body)

    def test_mgr_delete_session_persistence(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_delete = Mock(return_value=({}, {}))
        mgr.delete_session_persistence(lb)
        uri = "/loadbalancers/%s/sessionpersistence" % lb.id
        mgr.api.method_delete.assert_called_once_with(uri)

    def test_mgr_get_connection_logging(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_get = Mock(return_value=({}, {}))
        mgr.get_connection_logging(lb)
        uri = "/loadbalancers/%s/connectionlogging" % lb.id
        mgr.api.method_get.assert_called_once_with(uri)

    def test_mgr_set_connection_logging(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_put = Mock(return_value=({}, {}))
        mgr.set_connection_logging(lb, True)
        uri = "/loadbalancers/%s/connectionlogging" % lb.id
        req_body = {"connectionLogging": {"enabled": "true"}}
        mgr.api.method_put.assert_called_once_with(uri, body=req_body)

    def test_mgr_get_content_caching(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_get = Mock(return_value=({}, {}))
        mgr.get_content_caching(lb)
        uri = "/loadbalancers/%s/contentcaching" % lb.id
        mgr.api.method_get.assert_called_once_with(uri)

    def test_mgr_set_content_caching(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.api.method_put = Mock(return_value=({}, {}))
        mgr.set_content_caching(lb, True)
        uri = "/loadbalancers/%s/contentcaching" % lb.id
        req_body = {"contentCaching": {"enabled": "true"}}
        mgr.api.method_put.assert_called_once_with(uri, body=req_body)

    def test_get_lb(self):
        lb = self.loadbalancer
        mgr = lb.manager
        mgr.get = Mock(return_value=({}, {}))
        mgr._get_lb(lb)
        self.assertEqual(mgr.get.call_count, 0)
        mgr._get_lb(lb.id)
        mgr.get.assert_called_once_with(lb.id)

    def test_bad_node_parameters(self):
        # Can't use FakeNode, since it supplies all valid params.
        self.assertRaises(exc.InvalidNodeParameters, Node)

    def test_node_repr(self):
        nd = fakes.FakeNode(port=12345)
        nd_repr = "%s" % nd
        self.assertTrue("port=12345" in nd_repr)

    def test_node_to_dict(self):
        nd = fakes.FakeNode()
        expected = {"address": nd.address,
                "port": nd.port,
                "condition": nd.condition,
                "type": nd.type,
                "id": nd.id,
                }
        self.assertEqual(nd.to_dict(), expected)

    def test_node_delete(self):
        lb = self.loadbalancer
        nd = fakes.FakeNode(parent=lb)
        lb.delete_node = Mock()
        nd.delete()
        lb.delete_node.assert_called_once_with(nd)

    def test_node_diff(self):
        nd = fakes.FakeNode()
        new_port = nd.port + 1
        nd.port = new_port
        expected = {"port": new_port}
        self.assertEqual(nd._diff(), expected)

    def test_node_update(self):
        lb = self.loadbalancer
        nd = fakes.FakeNode(parent=lb)
        lb.update_node = Mock()
        nd.update()
        self.assertEqual(lb.update_node.call_count, 0)
        nd.port += 1
        nd.update()
        lb.update_node.assert_called_once_with(nd, {"port": nd.port})

    def test_vip_bad_type(self):
        self.assertRaises(exc.InvalidVirtualIPType, VirtualIP, type="FAKE")

    def test_vip_bad_ip_version(self):
        self.assertRaises(exc.InvalidVirtualIPVersion, VirtualIP,
                ipVersion="FAKE")

    def test_vip_repr(self):
        vip = fakes.FakeVirtualIP(address="1.2.3.4")
        vip_repr = "%s" % vip
        self.assertTrue("address=1.2.3.4" in vip_repr)

    def test_vip_to_dict(self):
        vip = fakes.FakeVirtualIP(id="fake_id")
        self.assertEqual(vip.to_dict(), {"id": "fake_id"})

    def test_vip_to_dict(self):
        vip = fakes.FakeVirtualIP()
        expected = {"type": vip.type,
                "ipVersion": vip.ip_version}
        self.assertEqual(vip.to_dict(), expected)

    def test_vip_delete(self):
        lb = self.loadbalancer
        vip = fakes.FakeVirtualIP(parent=lb)
        lb.delete_virtualip = Mock()
        vip.delete()
        lb.delete_virtualip.assert_called_once_with(vip)

    def test_client_create_body(self):
        mgr = self.client._manager
        nd = fakes.FakeNode()
        vip = fakes.FakeVirtualIP()
        fake_name = "FAKE"
        fake_port = 999
        fake_protocol = "FAKE"
        fake_nodes = [nd]
        fake_virtual_ips = [vip]
        fake_algorithm = "FAKE"
        fake_accessList = ["FAKE"]
        fake_halfClosed = False
        fake_connectionLogging = True
        fake_connectionThrottle = True
        fake_healthMonitor = object()
        fake_metadata = {"fake": utils.random_unicode()}
        fake_timeout = 42
        fake_sessionPersistence = True
        fake_httpsRedirect = True
        expected = {"loadBalancer": {
                "name": fake_name,
                "port": fake_port,
                "protocol": fake_protocol,
                "nodes": [nd.to_dict()],
                "virtualIps": [vip.to_dict()],
                "algorithm": fake_algorithm,
                "accessList": fake_accessList,
                "halfClosed": fake_halfClosed,
                "connectionLogging": fake_connectionLogging,
                "connectionThrottle": fake_connectionThrottle,
                "healthMonitor": fake_healthMonitor,
                "metadata": fake_metadata,
                "timeout": fake_timeout,
                "sessionPersistence": fake_sessionPersistence,
                "httpsRedirect": fake_httpsRedirect,
                }}
        ret = mgr._create_body(fake_name, port=fake_port,
                protocol=fake_protocol, nodes=fake_nodes,
                virtual_ips=fake_virtual_ips, algorithm=fake_algorithm,
                accessList=fake_accessList,
                connectionLogging=fake_connectionLogging,
                halfClosed=fake_halfClosed,
                connectionThrottle=fake_connectionThrottle,
                healthMonitor=fake_healthMonitor, metadata=fake_metadata,
                timeout=fake_timeout,
                sessionPersistence=fake_sessionPersistence,
                httpsRedirect=fake_httpsRedirect)
        self.assertEqual(ret, expected)

    def test_bad_node_condition(self):
        mgr = self.client._manager
        nd = fakes.FakeNode()
        nd.condition = "DRAINING"
        vip = fakes.FakeVirtualIP()
        fake_name = "FAKE"
        fake_port = 999
        fake_protocol = "FAKE"
        fake_nodes = [nd]
        fake_virtual_ips = [vip]
        fake_algorithm = "FAKE"
        fake_accessList = ["FAKE"]
        fake_halfClosed = False
        fake_connectionLogging = True
        fake_connectionThrottle = True
        fake_healthMonitor = object()
        fake_metadata = {"fake": utils.random_unicode()}
        fake_timeout = 42
        fake_sessionPersistence = True
        fake_httpsRedirect = True
        self.assertRaises(exc.InvalidNodeCondition, mgr._create_body,
                fake_name, port=fake_port, protocol=fake_protocol,
                nodes=fake_nodes, virtual_ips=fake_virtual_ips,
                algorithm=fake_algorithm, accessList=fake_accessList,
                connectionLogging=fake_connectionLogging,
                halfClosed=fake_halfClosed,
                connectionThrottle=fake_connectionThrottle,
                healthMonitor=fake_healthMonitor, metadata=fake_metadata,
                timeout=fake_timeout,
                sessionPersistence=fake_sessionPersistence,
                httpsRedirect=fake_httpsRedirect)

    def test_missing_lb_parameters(self):
        mgr = self.client._manager
        nd = fakes.FakeNode()
        vip = fakes.FakeVirtualIP()
        fake_name = "FAKE"
        fake_port = 999
        fake_protocol = "FAKE"
        fake_nodes = [nd]
        fake_virtual_ips = []
        fake_algorithm = "FAKE"
        fake_accessList = ["FAKE"]
        fake_halfClosed = False
        fake_connectionLogging = True
        fake_connectionThrottle = True
        fake_healthMonitor = object()
        fake_metadata = {"fake": utils.random_unicode()}
        fake_timeout = 42
        fake_sessionPersistence = True
        fake_httpsRedirect = True
        self.assertRaises(exc.MissingLoadBalancerParameters, mgr._create_body,
                fake_name, port=fake_port, protocol=fake_protocol,
                nodes=fake_nodes, virtual_ips=fake_virtual_ips,
                algorithm=fake_algorithm, accessList=fake_accessList,
                connectionLogging=fake_connectionLogging,
                halfClosed=fake_halfClosed,
                connectionThrottle=fake_connectionThrottle,
                healthMonitor=fake_healthMonitor, metadata=fake_metadata,
                timeout=fake_timeout,
                sessionPersistence=fake_sessionPersistence,
                httpsRedirect=fake_httpsRedirect)

    def test_client_get_usage(self):
        clt = self.client
        lb = self.loadbalancer
        clt._manager.get_usage = Mock()
        clt.get_usage(lb)
        clt._manager.get_usage.assert_called_once_with(loadbalancer=lb,
                start=None, end=None)

    def test_client_allowed_domains(self):
        clt = self.client
        fake_name = utils.random_unicode()
        fake_body = {"allowedDomains": [{"allowedDomain":
                {"name": fake_name}}]}
        clt.method_get = Mock(return_value=({}, fake_body))
        ret = clt.allowed_domains
        self.assertEqual(ret, [fake_name])
        self.assertEqual(clt.method_get.call_count, 1)
        # Retry; should not re-call the GET
        ret = clt.allowed_domains
        self.assertEqual(ret, [fake_name])
        self.assertEqual(clt.method_get.call_count, 1)

    def test_client_algorithms(self):
        clt = self.client
        fake_name = utils.random_unicode()
        fake_body = {"algorithms": [{"name": fake_name}]}
        clt.method_get = Mock(return_value=({}, fake_body))
        ret = clt.algorithms
        self.assertEqual(ret, [fake_name])
        self.assertEqual(clt.method_get.call_count, 1)
        # Retry; should not re-call the GET
        ret = clt.algorithms
        self.assertEqual(ret, [fake_name])
        self.assertEqual(clt.method_get.call_count, 1)

    def test_client_protocols(self):
        clt = self.client
        fake_name = utils.random_unicode()
        fake_body = {"protocols": [{"name": fake_name}]}
        clt.method_get = Mock(return_value=({}, fake_body))
        ret = clt.protocols
        self.assertEqual(ret, [fake_name])
        self.assertEqual(clt.method_get.call_count, 1)
        # Retry; should not re-call the GET
        ret = clt.protocols
        self.assertEqual(ret, [fake_name])
        self.assertEqual(clt.method_get.call_count, 1)


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_cloud_monitoring
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import datetime
import random
import unittest

from mock import patch
from mock import MagicMock as Mock

import pyrax.cloudnetworks
from pyrax.cloudmonitoring import CloudMonitorAlarm
from pyrax.cloudmonitoring import CloudMonitorCheck
from pyrax.cloudmonitoring import CloudMonitorCheckType
from pyrax.cloudmonitoring import CloudMonitorNotification
from pyrax.cloudmonitoring import CloudMonitorNotificationPlan
from pyrax.cloudmonitoring import CloudMonitorNotificationType
from pyrax.cloudmonitoring import CloudMonitorZone
from pyrax.cloudmonitoring import _params_to_dict

import pyrax.exceptions as exc
import pyrax.utils as utils

from pyrax import fakes



class CloudMonitoringTest(unittest.TestCase):
    def __init__(self, *args, **kwargs):
        super(CloudMonitoringTest, self).__init__(*args, **kwargs)

    def setUp(self):
        self.client = fakes.FakeCloudMonitorClient()
        self.entity = fakes.FakeCloudMonitorEntity()

    def tearDown(self):
        self.client = None

    def test_params_to_dict(self):
        val = utils.random_unicode()
        local = {"foo": val, "bar": None, "baz": True}
        params = ("foo", "bar")
        expected = {"foo": val}
        ret = _params_to_dict(params, {}, local)
        self.assertEqual(ret, expected)

    def test_entity_update(self):
        ent = self.entity
        ent.manager.update_entity = Mock()
        agent = utils.random_unicode()
        metadata = {"fake": utils.random_unicode()}
        ent.update(agent=agent, metadata=metadata)
        ent.manager.update_entity.assert_called_once_with(ent, agent=agent,
                metadata=metadata)

    def test_entity_list_checks(self):
        ent = self.entity
        ent.manager.list_checks = Mock()
        ent.list_checks()
        ent.manager.list_checks.assert_called_once_with(ent)

    def test_entity_delete_check(self):
        ent = self.entity
        ent.manager.delete_check = Mock()
        check = utils.random_unicode()
        ent.delete_check(check)
        ent.manager.delete_check.assert_called_once_with(ent, check)

    def test_entity_list_metrics(self):
        ent = self.entity
        ent.manager.list_metrics = Mock()
        check = utils.random_unicode()
        ent.list_metrics(check)
        ent.manager.list_metrics.assert_called_once_with(ent, check)

    def test_entity_get_metric_data_points(self):
        ent = self.entity
        ent.manager.get_metric_data_points = Mock()
        check = utils.random_unicode()
        metric = utils.random_unicode()
        start = utils.random_unicode()
        end = utils.random_unicode()
        points = utils.random_unicode()
        resolution = utils.random_unicode()
        stats = utils.random_unicode()
        ent.get_metric_data_points(check, metric, start, end, points=points,
                resolution=resolution, stats=stats)
        ent.manager.get_metric_data_points.assert_called_once_with(ent, check,
                metric, start, end, points=points, resolution=resolution,
                stats=stats)

    def test_entity_create_alarm(self):
        ent = self.entity
        ent.manager.create_alarm = Mock()
        check = utils.random_unicode()
        np = utils.random_unicode()
        criteria = utils.random_unicode()
        disabled = random.choice((True, False))
        label = utils.random_unicode()
        name = utils.random_unicode()
        metadata = utils.random_unicode()
        ent.create_alarm(check, np, criteria=criteria, disabled=disabled,
                label=label, name=name, metadata=metadata)
        ent.manager.create_alarm.assert_called_once_with(ent, check, np,
                criteria=criteria, disabled=disabled, label=label, name=name,
                metadata=metadata)

    def test_entity_update_alarm(self):
        ent = self.entity
        ent.manager.update_alarm = Mock()
        alarm = utils.random_unicode()
        criteria = utils.random_unicode()
        disabled = random.choice((True, False))
        label = utils.random_unicode()
        name = utils.random_unicode()
        metadata = utils.random_unicode()
        ent.update_alarm(alarm, criteria=criteria, disabled=disabled,
                label=label, name=name, metadata=metadata)
        ent.manager.update_alarm.assert_called_once_with(ent, alarm,
                criteria=criteria, disabled=disabled, label=label, name=name,
                metadata=metadata)

    def test_entity_list_alarms(self):
        ent = self.entity
        ent.manager.list_alarms = Mock()
        ent.list_alarms()
        ent.manager.list_alarms.assert_called_once_with(ent)

    def test_entity_get_alarm(self):
        ent = self.entity
        ent.manager.get_alarm = Mock()
        alarm = utils.random_unicode()
        ent.get_alarm(alarm)
        ent.manager.get_alarm.assert_called_once_with(ent, alarm)

    def test_entity_delete_alarm(self):
        ent = self.entity
        ent.manager.delete_alarm = Mock()
        alarm = utils.random_unicode()
        ent.delete_alarm(alarm)
        ent.manager.delete_alarm.assert_called_once_with(ent, alarm)

    def test_entity_name(self):
        ent = self.entity
        ent.label = utils.random_unicode()
        self.assertEqual(ent.label, ent.name)

    def test_notif_manager_create(self):
        clt = self.client
        mgr = clt._notification_manager
        clt.method_post = Mock(
                return_value=({"x-object-id": utils.random_unicode()}, None))
        mgr.get = Mock()
        ntyp = utils.random_unicode()
        label = utils.random_unicode()
        name = utils.random_unicode()
        details = utils.random_unicode()
        exp_uri = "/%s" % mgr.uri_base
        exp_body = {"label": label or name, "type": ntyp, "details": details}
        mgr.create(ntyp, label=label, name=name, details=details)
        clt.method_post.assert_called_once_with(exp_uri, body=exp_body)

    def test_notif_manager_test_notification_existing(self):
        clt = self.client
        mgr = clt._notification_manager
        clt.method_post = Mock(return_value=(None, None))
        ntf = utils.random_unicode()
        details = utils.random_unicode()
        exp_uri = "/%s/%s/test" % (mgr.uri_base, ntf)
        exp_body = None
        mgr.test_notification(notification=ntf, details=details)
        clt.method_post.assert_called_once_with(exp_uri, body=exp_body)

    def test_notif_manager_test_notification(self):
        clt = self.client
        mgr = clt._notification_manager
        clt.method_post = Mock(return_value=(None, None))
        ntyp = utils.random_unicode()
        details = utils.random_unicode()
        exp_uri = "/test-notification"
        exp_body = {"type": ntyp, "details": details}
        mgr.test_notification(notification_type=ntyp, details=details)
        clt.method_post.assert_called_once_with(exp_uri, body=exp_body)

    def test_notif_manager_update_notification(self):
        clt = self.client
        mgr = clt._notification_manager
        clt.method_put = Mock(return_value=(None, None))
        ntf = fakes.FakeCloudMonitorNotification()
        ntf.type = utils.random_unicode()
        details = utils.random_unicode()
        exp_uri = "/%s/%s" % (mgr.uri_base, ntf.id)
        exp_body = {"type": ntf.type, "details": details}
        mgr.update_notification(ntf, details)
        clt.method_put.assert_called_once_with(exp_uri, body=exp_body)

    def test_notif_manager_update_notification_id(self):
        clt = self.client
        mgr = clt._notification_manager
        clt.method_put = Mock(return_value=(None, None))
        ntf = fakes.FakeCloudMonitorNotification()
        ntf.type = utils.random_unicode()
        details = utils.random_unicode()
        mgr.get = Mock(return_value=ntf)
        exp_uri = "/%s/%s" % (mgr.uri_base, ntf.id)
        exp_body = {"type": ntf.type, "details": details}
        mgr.update_notification(ntf.id, details)
        clt.method_put.assert_called_once_with(exp_uri, body=exp_body)

    def test_notif_manager_list_types(self):
        clt = self.client
        mgr = clt._notification_manager
        id_ = utils.random_unicode()
        ret_body = {"values": [{"id": id_}]}
        clt.method_get = Mock(return_value=(None, ret_body))
        ret = mgr.list_types()
        clt.method_get.assert_called_once_with("/notification_types")
        self.assertEqual(len(ret), 1)
        inst = ret[0]
        self.assertTrue(isinstance(inst, CloudMonitorNotificationType))
        self.assertEqual(inst.id, id_)

    def test_notif_manager_get_type(self):
        clt = self.client
        mgr = clt._notification_manager
        id_ = utils.random_unicode()
        ret_body = {"id": id_}
        clt.method_get = Mock(return_value=(None, ret_body))
        ret = mgr.get_type(id_)
        exp_uri = "/notification_types/%s" % id_
        clt.method_get.assert_called_once_with(exp_uri)
        self.assertTrue(isinstance(ret, CloudMonitorNotificationType))
        self.assertEqual(ret.id, id_)

    def test_notif_plan_manager_create(self):
        clt = self.client
        mgr = clt._notification_plan_manager
        clt.method_post = Mock(
                return_value=({"x-object-id": utils.random_unicode()}, None))
        mgr.get = Mock()
        label = utils.random_unicode()
        name = utils.random_unicode()
        crit = utils.random_unicode()
        # Make the OK an object rather than a straight ID.
        ok = fakes.FakeEntity()
        ok_id = ok.id = utils.random_unicode()
        warn = utils.random_unicode()
        exp_uri = "/%s" % mgr.uri_base
        exp_body = {"label": label or name, "critical_state": [crit],
                "ok_state": [ok.id], "warning_state": [warn]}
        mgr.create(label=label, name=name, critical_state=crit, ok_state=ok,
                warning_state=warn)
        clt.method_post.assert_called_once_with(exp_uri, body=exp_body)

    def test_entity_mgr_update_entity(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        clt.method_put = Mock(return_value=(None, None))
        agent = utils.random_unicode()
        metadata = utils.random_unicode()
        exp_uri = "/%s/%s" % (mgr.uri_base, ent.id)
        exp_body = {"agent_id": agent, "metadata": metadata}
        mgr.update_entity(ent, agent, metadata)
        clt.method_put.assert_called_once_with(exp_uri, body=exp_body)

    def test_entity_mgr_list_checks(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        ret_body = {"values": [{"id": id_}]}
        clt.method_get = Mock(return_value=(None, ret_body))
        ret = mgr.list_checks(ent)
        exp_uri = "/%s/%s/checks" % (mgr.uri_base, ent.id)
        clt.method_get.assert_called_once_with(exp_uri)
        self.assertEqual(len(ret), 1)
        inst = ret[0]
        self.assertTrue(isinstance(inst, CloudMonitorCheck))
        self.assertEqual(inst.id, id_)

    # The following tests need to mock CloudMonitorCheck, as we're mocking out
    # the entity manager's method_post, which is what CloudMonitorCheck is
    # created from. It's probably easier than making a more complicated
    # method_post mock.
    @patch("pyrax.cloudmonitoring.CloudMonitorCheck")
    def test_entity_mgr_create_check_test_debug(self, cmc):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        label = utils.random_unicode()
        name = utils.random_unicode()
        check_type = utils.random_unicode()
        details = utils.random_unicode()
        disabled = utils.random_unicode()
        metadata = utils.random_unicode()
        monitoring_zones_poll = utils.random_unicode()
        timeout = utils.random_unicode()
        period = utils.random_unicode()
        target_alias = utils.random_unicode()
        target_hostname = utils.random_unicode()
        target_receiver = utils.random_unicode()
        test_only = True
        include_debug = True
        fake_resp = {"x-object-id": {}, "status": "201"}
        clt.method_post = Mock(return_value=(fake_resp, None))
        mgr.get_check = Mock()
        mgr.get = Mock(return_value=fakes.FakeEntity)
        exp_uri = "/%s/%s/test-check?debug=true" % (mgr.uri_base, ent.id)
        exp_body = {"label": label or name, "details": details,
                "disabled": disabled, "type": check_type,
                "monitoring_zones_poll": [monitoring_zones_poll], "timeout":
                timeout, "period": period, "target_alias": target_alias,
                "target_hostname": target_hostname, "target_receiver":
                target_receiver}
        mgr.create_check(ent, label=label, name=name, check_type=check_type,
                details=details, disabled=disabled, metadata=metadata,
                monitoring_zones_poll=monitoring_zones_poll, timeout=timeout,
                period=period, target_alias=target_alias,
                target_hostname=target_hostname,
                target_receiver=target_receiver, test_only=test_only,
                include_debug=include_debug)
        clt.method_post.assert_called_once_with(exp_uri, body=exp_body)

    @patch("pyrax.cloudmonitoring.CloudMonitorCheck")
    def test_entity_mgr_create_check_test_no_debug(self, cmc):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        label = utils.random_unicode()
        name = utils.random_unicode()
        check_type = utils.random_unicode()
        details = utils.random_unicode()
        disabled = utils.random_unicode()
        metadata = utils.random_unicode()
        monitoring_zones_poll = utils.random_unicode()
        timeout = utils.random_unicode()
        period = utils.random_unicode()
        target_alias = utils.random_unicode()
        target_hostname = utils.random_unicode()
        target_receiver = utils.random_unicode()
        test_only = True
        include_debug = False
        fake_resp = {"x-object-id": {}, "status": "201"}
        clt.method_post = Mock(return_value=(fake_resp, None))
        mgr.get_check = Mock()
        mgr.get = Mock(return_value=fakes.FakeEntity)
        exp_uri = "/%s/%s/test-check" % (mgr.uri_base, ent.id)
        exp_body = {"label": label or name, "details": details,
                "disabled": disabled, "type": check_type,
                "monitoring_zones_poll": [monitoring_zones_poll], "timeout":
                timeout, "period": period, "target_alias": target_alias,
                "target_hostname": target_hostname, "target_receiver":
                target_receiver}
        mgr.create_check(ent, label=label, name=name, check_type=check_type,
                details=details, disabled=disabled, metadata=metadata,
                monitoring_zones_poll=monitoring_zones_poll, timeout=timeout,
                period=period, target_alias=target_alias,
                target_hostname=target_hostname,
                target_receiver=target_receiver, test_only=test_only,
                include_debug=include_debug)
        clt.method_post.assert_called_once_with(exp_uri, body=exp_body)

    @patch("pyrax.cloudmonitoring.CloudMonitorCheck")
    def test_entity_mgr_create_check(self, cmc):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        label = utils.random_unicode()
        name = utils.random_unicode()
        check_type = utils.random_unicode()
        details = utils.random_unicode()
        disabled = utils.random_unicode()
        metadata = utils.random_unicode()
        monitoring_zones_poll = utils.random_unicode()
        timeout = utils.random_unicode()
        period = utils.random_unicode()
        target_alias = utils.random_unicode()
        target_hostname = utils.random_unicode()
        target_receiver = utils.random_unicode()
        test_only = False
        include_debug = False
        fake_resp = {"x-object-id": {}, "status": "201"}
        clt.method_post = Mock(return_value=(fake_resp, None))
        mgr.get_check = Mock()
        mgr.get = Mock(return_value=fakes.FakeEntity)
        exp_uri = "/%s/%s/checks" % (mgr.uri_base, ent.id)
        exp_body = {"label": label or name, "details": details,
                "disabled": disabled, "type": check_type,
                "monitoring_zones_poll": [monitoring_zones_poll], "timeout":
                timeout, "period": period, "target_alias": target_alias,
                "target_hostname": target_hostname, "target_receiver":
                target_receiver}
        mgr.create_check(ent, label=label, name=name, check_type=check_type,
                details=details, disabled=disabled, metadata=metadata,
                monitoring_zones_poll=monitoring_zones_poll, timeout=timeout,
                period=period, target_alias=target_alias,
                target_hostname=target_hostname,
                target_receiver=target_receiver, test_only=test_only,
                include_debug=include_debug)
        clt.method_post.assert_called_once_with(exp_uri, body=exp_body)

    def test_entity_mgr_create_check_no_details(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        self.assertRaises(exc.MissingMonitoringCheckDetails, mgr.create_check,
                ent)

    def test_entity_mgr_create_check_no_target(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        self.assertRaises(exc.MonitoringCheckTargetNotSpecified,
                mgr.create_check, ent, details="fake")

    def test_entity_mgr_create_check_no_mz_poll(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        self.assertRaises(exc.MonitoringZonesPollMissing, mgr.create_check,
                ent, details="fake", target_alias="fake",
                check_type="remote.fake")

    def test_entity_mgr_create_check_invalid_details(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        err = exc.BadRequest(400)
        err.message = "Validation error for key 'fake'"
        err.details = "Validation failed for 'fake'"
        clt.method_post = Mock(side_effect=err)
        self.assertRaises(exc.BadRequest, mgr.create_check,
                ent, details="fake", target_alias="fake",
                check_type="remote.fake", monitoring_zones_poll="fake")

    def test_entity_mgr_create_check_missing_details(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        err = exc.BadRequest(400)
        err.message = "Validation error for key 'something'"
        err.details = "Validation failed for 'something'"
        clt.method_post = Mock(side_effect=err)
        self.assertRaises(exc.BadRequest, mgr.create_check,
                ent, details="fake", target_alias="fake",
                check_type="remote.fake", monitoring_zones_poll="fake")

    def test_entity_mgr_create_check_failed_validation(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        err = exc.BadRequest(400)
        err.message = "Validation error"
        err.details = "Some details"
        clt.method_post = Mock(side_effect=err)
        self.assertRaises(exc.InvalidMonitoringCheckDetails, mgr.create_check,
                ent, details="fake", target_alias="fake",
                check_type="remote.fake", monitoring_zones_poll="fake")

    def test_entity_mgr_find_all_checks(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        c1 = fakes.FakeCloudMonitorCheck(entity=ent, info={"foo": "fake",
                "bar": "fake"})
        c2 = fakes.FakeCloudMonitorCheck(entity=ent, info={"foo": "fake"})
        c3 = fakes.FakeCloudMonitorCheck(entity=ent, info={"foo": "fake",
                "bar": "real"})
        mgr.list_checks = Mock(return_value=[c1, c2, c3])
        found = mgr.find_all_checks(ent, foo="fake", bar="fake")
        self.assertEqual(len(found), 1)
        self.assertTrue(c1 in found)
        self.assertTrue(c2 not in found)
        self.assertTrue(c3 not in found)

    def test_entity_mgr_update_check(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        chk = fakes.FakeCloudMonitorCheck(entity=ent)
        label = utils.random_unicode()
        name = utils.random_unicode()
        check_type = utils.random_unicode()
        details = utils.random_unicode()
        disabled = utils.random_unicode()
        metadata = utils.random_unicode()
        monitoring_zones_poll = utils.random_unicode()
        timeout = utils.random_unicode()
        period = utils.random_unicode()
        target_alias = utils.random_unicode()
        target_hostname = utils.random_unicode()
        target_receiver = utils.random_unicode()
        test_only = False
        include_debug = False
        clt.method_put = Mock(return_value=(None, None))
        exp_uri = "/%s/%s/checks/%s" % (mgr.uri_base, ent.id, chk.id)
        exp_body = {"label": label or name, "metadata": metadata, "disabled":
            disabled, "monitoring_zones_poll": [monitoring_zones_poll],
            "timeout": timeout, "period": period, "target_alias": target_alias,
            "target_hostname": target_hostname, "target_receiver":
            target_receiver}
        mgr.update_check(chk, label=label, name=name, disabled=disabled,
                metadata=metadata, monitoring_zones_poll=monitoring_zones_poll,
                timeout=timeout, period=period, target_alias=target_alias,
                target_hostname=target_hostname,
                target_receiver=target_receiver)
        clt.method_put.assert_called_once_with(exp_uri, body=exp_body)

    def test_entity_mgr_update_check_failed_validation(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        chk = fakes.FakeCloudMonitorCheck(info={"id": id_}, entity=ent)
        err = exc.BadRequest(400)
        err.message = "Validation error"
        err.details = "Some details"
        clt.method_put = Mock(side_effect=err)
        self.assertRaises(exc.InvalidMonitoringCheckUpdate, mgr.update_check,
                chk, target_alias="fake", monitoring_zones_poll="fake")

    def test_entity_mgr_update_check_failed_validation_other(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        chk = fakes.FakeCloudMonitorCheck(info={"id": id_}, entity=ent)
        err = exc.BadRequest(400)
        err.message = "Another error"
        err.details = "Some details"
        clt.method_put = Mock(side_effect=err)
        self.assertRaises(exc.BadRequest, mgr.update_check, chk,
                target_alias="fake", monitoring_zones_poll="fake")

    def test_entity_mgr_get_check(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        ret_body = {"id": id_}
        clt.method_get = Mock(return_value=(None, ret_body))
        ret = mgr.get_check(ent, id_)
        exp_uri = "/%s/%s/checks/%s" % (mgr.uri_base, ent.id, id_)
        clt.method_get.assert_called_once_with(exp_uri)
        self.assertTrue(isinstance(ret, CloudMonitorCheck))
        self.assertEqual(ret.id, id_)

    def test_entity_mgr_delete_check(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        clt.method_delete = Mock(return_value=(None, None))
        ret = mgr.delete_check(ent, id_)
        exp_uri = "/%s/%s/checks/%s" % (mgr.uri_base, ent.id, id_)
        clt.method_delete.assert_called_once_with(exp_uri)

    def test_entity_mgr_list_metrics(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        met1 = utils.random_unicode()
        met2 = utils.random_unicode()
        ret_body = {"values": [{"name": met1}, {"name": met2}]}
        clt.method_get = Mock(return_value=(None, ret_body))
        ret = mgr.list_metrics(ent, id_)
        exp_uri = "/%s/%s/checks/%s/metrics" % (mgr.uri_base, ent.id, id_)
        clt.method_get.assert_called_once_with(exp_uri)
        self.assertEqual(len(ret), 2)
        self.assertTrue(met1 in ret)
        self.assertTrue(met2 in ret)

    def test_entity_mgr_get_metric_data_points_no_granularity(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        self.assertRaises(exc.MissingMonitoringCheckGranularity,
                mgr.get_metric_data_points, None, None, None, None, None)

    def test_entity_mgr_get_metric_data_points_invalid_resolution(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        self.assertRaises(exc.InvalidMonitoringMetricsResolution,
                mgr.get_metric_data_points, None, None, None, None, None,
                resolution="INVALID")

    def test_entity_mgr_get_metric_data_points(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        chk_id = utils.random_unicode()
        metric = utils.random_unicode()
        points = utils.random_unicode()
        resolution = "FULL"
        end = datetime.datetime.now()
        start = end - datetime.timedelta(days=7)
        start_stamp = int(utils.to_timestamp(start))
        end_stamp = int(utils.to_timestamp(end))
        # NOTE: For some odd reason, the timestamps required for this must be
        # in milliseconds, instead of the UNIX standard for timestamps, which
        # is in seconds. So the values here are multiplied by 1000 to make it
        # work. If the API is ever corrected, the next two lines should be
        # removed. GitHub #176.
        start_stamp *= 1000
        end_stamp *= 1000
        stats = ["foo", "bar"]
        exp_qp = "from=%s&to=%s&points=%s&resolution=%s&select=%s&select=%s" % (
                start_stamp, end_stamp, points, resolution, stats[0], stats[1])
        exp_uri = "/%s/%s/checks/%s/metrics/%s/plot?%s" % (mgr.uri_base, ent.id,
                chk_id, metric, exp_qp)
        vals = utils.random_unicode()
        ret_body = {"values": vals}
        clt.method_get = Mock(return_value=(None, ret_body))
        ret = mgr.get_metric_data_points(ent, chk_id, metric, start, end,
                points=points, resolution=resolution, stats=stats)
        clt.method_get.assert_called_once_with(exp_uri)
        self.assertEqual(ret, vals)

    def test_entity_mgr_get_metric_data_points_invalid_request(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        chk_id = utils.random_unicode()
        metric = utils.random_unicode()
        points = utils.random_unicode()
        resolution = "FULL"
        end = datetime.datetime.now()
        start = end - datetime.timedelta(days=7)
        stats = ["foo", "bar"]
        err = exc.BadRequest(400)
        err.message = "Validation error: foo"
        clt.method_get = Mock(side_effect=err)
        self.assertRaises(exc.InvalidMonitoringMetricsRequest,
                mgr.get_metric_data_points, ent, chk_id, metric, start, end,
                points=points, resolution=resolution, stats=stats)

    def test_entity_mgr_get_metric_data_points_invalid_request_other(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        chk_id = utils.random_unicode()
        metric = utils.random_unicode()
        points = utils.random_unicode()
        resolution = "FULL"
        end = datetime.datetime.now()
        start = end - datetime.timedelta(days=7)
        stats = ["foo", "bar"]
        err = exc.BadRequest(400)
        err.message = "Some other error: foo"
        clt.method_get = Mock(side_effect=err)
        self.assertRaises(exc.BadRequest, mgr.get_metric_data_points, ent,
                chk_id, metric, start, end, points=points,
                resolution=resolution, stats=stats)

    def test_entity_mgr_create_alarm(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        check = utils.random_unicode()
        np = utils.random_unicode()
        criteria = utils.random_unicode()
        disabled = random.choice((True, False))
        label = utils.random_unicode()
        name = utils.random_unicode()
        metadata = utils.random_unicode()
        obj_id = utils.random_unicode()
        resp = ({"status": "201", "x-object-id": {}}, None)
        clt.method_post = Mock(return_value=resp)
        mgr.get_alarm = Mock()
        exp_uri = "/%s/%s/alarms" % (mgr.uri_base, ent.id)
        exp_body = {"check_id": check, "notification_plan_id": np, "criteria":
                criteria, "disabled": disabled, "label": label,
                "metadata": metadata}
        mgr.create_alarm(ent, check, np, criteria=criteria, disabled=disabled,
                label=label, name=name, metadata=metadata)
        clt.method_post.assert_called_once_with(exp_uri, body=exp_body)

    def test_entity_mgr_update_alarm(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        clt.method_put = Mock(return_value=(None, None))
        alarm = utils.random_unicode()
        criteria = utils.random_unicode()
        disabled = random.choice((True, False))
        label = utils.random_unicode()
        name = utils.random_unicode()
        metadata = utils.random_unicode()
        exp_uri = "/%s/%s/alarms/%s" % (mgr.uri_base, ent.id, alarm)
        exp_body = {"criteria": criteria, "disabled": disabled, "label": label,
                "metadata": metadata}
        mgr.update_alarm(ent, alarm, criteria=criteria, disabled=disabled,
                label=label, name=name, metadata=metadata)
        clt.method_put.assert_called_once_with(exp_uri, body=exp_body)

    def test_entity_mgr_list_alarms(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        ret_body = {"values": [{"id": id_}]}
        clt.method_get = Mock(return_value=(None, ret_body))
        exp_uri = "/%s/%s/alarms" % (mgr.uri_base, ent.id)
        ret = mgr.list_alarms(ent)
        clt.method_get.assert_called_once_with(exp_uri)
        self.assertEqual(len(ret), 1)
        self.assertTrue(isinstance(ret[0], CloudMonitorAlarm))
        self.assertEqual(ret[0].id, id_)

    def test_entity_mgr_get_alarm(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        ret_body = {"id": id_}
        clt.method_get = Mock(return_value=(None, ret_body))
        ret = mgr.get_alarm(ent, id_)
        exp_uri = "/%s/%s/alarms/%s" % (mgr.uri_base, ent.id, id_)
        clt.method_get.assert_called_once_with(exp_uri)
        self.assertTrue(isinstance(ret, CloudMonitorAlarm))
        self.assertEqual(ret.id, id_)

    def test_entity_mgr_delete_alarm(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        clt.method_delete = Mock(return_value=(None, None))
        ret = mgr.delete_alarm(ent, id_)
        exp_uri = "/%s/%s/alarms/%s" % (mgr.uri_base, ent.id, id_)
        clt.method_delete.assert_called_once_with(exp_uri)

    def test_changelog_mgr_list(self):
        clt = self.client
        mgr = clt._changelog_manager
        mgr._list = Mock(return_value=(None, None))
        entity = utils.random_unicode()
        mgr.list(entity=entity)
        expected_uri = "/%s?entityId=%s" % (mgr.uri_base, entity)
        mgr._list.assert_called_once_with(expected_uri, return_raw=True)

    def test_overview_mgr_list(self):
        clt = self.client
        mgr = clt._overview_manager
        mgr._list = Mock(return_value=(None, None))
        entity = utils.random_unicode()
        mgr.list(entity=entity)
        expected_uri = "/%s?entityId=%s" % (mgr.uri_base, entity)
        mgr._list.assert_called_once_with(expected_uri, return_raw=True)

    def test_check(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        mgr.get = Mock(return_value=ent)
        id_ = utils.random_unicode()
        chk = CloudMonitorCheck(mgr, info={"id": id_}, entity="fake")
        self.assertEqual(chk.manager, mgr)
        self.assertEqual(chk.id, id_)
        self.assertEqual(chk.entity, ent)

    def test_check_name(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        chk = CloudMonitorCheck(mgr, info={"id": id_}, entity=ent)
        nm = utils.random_unicode()
        chk.label = nm
        self.assertEqual(chk.name, nm)

    def test_check_get_reload(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        chk = CloudMonitorCheck(mgr, info={"id": id_}, entity=ent)
        info = chk._info
        mgr.get_check = Mock(return_value=chk)
        chk.reload()
        self.assertEqual(chk._info, info)

    def test_check_update(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        chk = CloudMonitorCheck(mgr, info={"id": id_}, entity=ent)
        mgr.update_check = Mock()
        label = utils.random_unicode()
        name = utils.random_unicode()
        check_type = utils.random_unicode()
        disabled = utils.random_unicode()
        metadata = utils.random_unicode()
        monitoring_zones_poll = utils.random_unicode()
        timeout = utils.random_unicode()
        period = utils.random_unicode()
        target_alias = utils.random_unicode()
        target_hostname = utils.random_unicode()
        target_receiver = utils.random_unicode()
        chk.update(label=label, name=name, disabled=disabled,
                metadata=metadata, monitoring_zones_poll=monitoring_zones_poll,
                timeout=timeout, period=period, target_alias=target_alias,
                target_hostname=target_hostname,
                target_receiver=target_receiver)
        mgr.update_check.assert_called_once_with(chk, label=label, name=name,
                disabled=disabled, metadata=metadata,
                monitoring_zones_poll=monitoring_zones_poll, timeout=timeout,
                period=period, target_alias=target_alias,
                target_hostname=target_hostname,
                target_receiver=target_receiver)

    def test_check_delete(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        chk = CloudMonitorCheck(mgr, info={"id": id_}, entity=ent)
        mgr.delete_check = Mock()
        chk.delete()
        mgr.delete_check.assert_called_once_with(ent, chk)

    def test_check_list_metrics(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        chk = CloudMonitorCheck(mgr, info={"id": id_}, entity=ent)
        mgr.list_metrics = Mock()
        chk.list_metrics()
        mgr.list_metrics.assert_called_once_with(ent, chk)

    def test_check_get_metric_data_points(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        chk = CloudMonitorCheck(mgr, info={"id": id_}, entity=ent)
        mgr.get_metric_data_points = Mock()
        metric = utils.random_unicode()
        start = utils.random_unicode()
        end = utils.random_unicode()
        points = utils.random_unicode()
        resolution = utils.random_unicode()
        stats = utils.random_unicode()
        chk.get_metric_data_points(metric, start, end, points=points,
                resolution=resolution, stats=stats)
        mgr.get_metric_data_points.assert_called_once_with(ent, chk, metric,
                start, end, points=points, resolution=resolution, stats=stats)

    def test_check_create_alarm(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        chk = CloudMonitorCheck(mgr, info={"id": id_}, entity=ent)
        mgr.create_alarm = Mock()
        notification_plan = utils.random_unicode()
        criteria = utils.random_unicode()
        disabled = utils.random_unicode()
        label = utils.random_unicode()
        name = utils.random_unicode()
        metadata = utils.random_unicode()
        chk.create_alarm(notification_plan, criteria=criteria,
                disabled=disabled, label=label, name=name, metadata=metadata)
        mgr.create_alarm.assert_called_once_with(ent, chk, notification_plan,
                criteria=criteria, disabled=disabled, label=label, name=name,
                metadata=metadata)

    def test_checktype_field_names(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        flds = [{"optional": True, "name": "fake_opt",
                "description": "Optional Field"},
                {"optional": False, "name": "fake_req",
                "description": "Required Field"}]
        ctyp = CloudMonitorCheckType(mgr, info={"id": id_, "fields": flds})
        self.assertEqual(ctyp.field_names, ["fake_opt", "fake_req"])
        self.assertEqual(ctyp.required_field_names, ["fake_req"])
        self.assertEqual(ctyp.optional_field_names, ["fake_opt"])

    def test_zone_name(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        nm = utils.random_unicode()
        cmz = CloudMonitorZone(mgr, info={"id": id_, "label": nm})
        self.assertEqual(cmz.label, nm)
        self.assertEqual(cmz.name, nm)

    def test_notification_name(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        nm = utils.random_unicode()
        cnot = CloudMonitorNotification(mgr, info={"id": id_, "label": nm})
        self.assertEqual(cnot.label, nm)
        self.assertEqual(cnot.name, nm)

    def test_notification_update(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        nm = utils.random_unicode()
        details = utils.random_unicode()
        cnot = CloudMonitorNotification(mgr, info={"id": id_, "label": nm})
        mgr.update_notification = Mock()
        cnot.update(details)
        mgr.update_notification.assert_called_once_with(cnot, details)

    def test_notification_type_name(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        nm = utils.random_unicode()
        cntyp = CloudMonitorNotificationType(mgr, info={"id": id_, "label": nm})
        self.assertEqual(cntyp.label, nm)
        self.assertEqual(cntyp.name, nm)

    def test_notification_plan_name(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        nm = utils.random_unicode()
        cpln = CloudMonitorNotificationPlan(mgr, info={"id": id_, "label": nm})
        self.assertEqual(cpln.label, nm)
        self.assertEqual(cpln.name, nm)

    def test_alarm(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        nm = utils.random_unicode()
        mgr.get = Mock(return_value=ent)
        alm = CloudMonitorAlarm(mgr, info={"id": id_, "label": nm},
                entity="fake")
        self.assertEqual(alm.entity, ent)

    def test_alarm_name(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        nm = utils.random_unicode()
        alm = CloudMonitorAlarm(mgr, info={"id": id_, "label": nm},
                entity=ent)
        self.assertEqual(alm.label, nm)
        self.assertEqual(alm.name, nm)

    def test_alarm_update(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        nm = utils.random_unicode()
        alm = CloudMonitorAlarm(mgr, info={"id": id_, "label": nm},
                entity=ent)
        criteria = utils.random_unicode()
        disabled = utils.random_unicode()
        label = utils.random_unicode()
        name = utils.random_unicode()
        metadata = utils.random_unicode()
        ent.update_alarm = Mock()
        alm.update(criteria=criteria, disabled=disabled, label=label,
                name=name, metadata=metadata)
        ent.update_alarm.assert_called_once_with(alm, criteria=criteria,
                disabled=disabled, label=label, name=name, metadata=metadata)

    def test_alarm_get_reload(self):
        ent = self.entity
        clt = self.client
        mgr = clt._entity_manager
        id_ = utils.random_unicode()
        nm = utils.random_unicode()
        alm = CloudMonitorAlarm(mgr, info={"id": id_, "label": nm},
                entity=ent)
        info = alm._info
        ent.get_alarm = Mock(return_value=alm)
        alm.reload()
        self.assertEqual(alm._info, info)

    def test_clt_get_account(self):
        clt = self.client
        rsp = utils.random_unicode()
        rb = utils.random_unicode()
        clt.method_get = Mock(return_value=((rsp, rb)))
        ret = clt.get_account()
        clt.method_get.assert_called_once_with("/account")
        self.assertEqual(ret, rb)

    def test_clt_get_limits(self):
        clt = self.client
        rsp = utils.random_unicode()
        rb = utils.random_unicode()
        clt.method_get = Mock(return_value=((rsp, rb)))
        ret = clt.get_limits()
        clt.method_get.assert_called_once_with("/limits")
        self.assertEqual(ret, rb)

    def test_clt_get_audits(self):
        clt = self.client
        rsp = utils.random_unicode()
        rb = utils.random_unicode()
        clt.method_get = Mock(return_value=((rsp, {"values": rb})))
        ret = clt.get_audits()
        clt.method_get.assert_called_once_with("/audits")
        self.assertEqual(ret, rb)

    def test_clt_list_entities(self):
        clt = self.client
        ents = utils.random_unicode()
        clt._entity_manager.list = Mock(return_value=ents)
        ret = clt.list_entities()
        clt._entity_manager.list.assert_called_once_with()
        self.assertEqual(ret, ents)

    def test_clt_get_entity(self):
        clt = self.client
        ent = self.entity
        clt._entity_manager.get = Mock(return_value=ent)
        ret = clt.get_entity(ent)
        clt._entity_manager.get.assert_called_once_with(ent)
        self.assertEqual(ret, ent)

    def test_clt_create_entity(self):
        clt = self.client
        ent = self.entity
        mgr = clt._entity_manager
        obj_id = utils.random_unicode()
        resp = {"status": "201", "x-object-id": obj_id}
        mgr.create = Mock(return_value=resp)
        clt.get_entity = Mock(return_value=ent)
        label = utils.random_unicode()
        name = utils.random_unicode()
        agent = utils.random_unicode()
        ip_addresses = utils.random_unicode()
        metadata = utils.random_unicode()
        ret = clt.create_entity(label=label, name=name, agent=agent,
                ip_addresses=ip_addresses, metadata=metadata)
        mgr.create.assert_called_once_with(label=label, name=name, agent=agent,
                ip_addresses=ip_addresses, metadata=metadata,
                return_response=True)
        clt.get_entity.assert_called_once_with(obj_id)
        self.assertEqual(ret, ent)

    def test_clt_update_entity(self):
        clt = self.client
        ent = self.entity
        mgr = clt._entity_manager
        obj_id = utils.random_unicode()
        mgr.update_entity = Mock()
        agent = utils.random_unicode()
        metadata = utils.random_unicode()
        clt.update_entity(ent, agent=agent, metadata=metadata)
        mgr.update_entity.assert_called_once_with(ent, agent=agent,
                metadata=metadata)

    def test_clt_delete_entity(self):
        clt = self.client
        ent = self.entity
        mgr = clt._entity_manager
        mgr.delete = Mock()
        clt.delete_entity(ent)
        mgr.delete.assert_called_once_with(ent)

    def test_clt_list_check_types(self):
        clt = self.client
        ent = self.entity
        mgr = clt._check_type_manager
        cts = utils.random_unicode()
        mgr.list = Mock(return_value=cts)
        ret = clt.list_check_types()
        mgr.list.assert_called_once_with()
        self.assertEqual(ret, cts)

    def test_clt_get_check_type(self):
        clt = self.client
        ent = self.entity
        mgr = clt._check_type_manager
        ct = utils.random_unicode()
        mgr.get = Mock(return_value=ct)
        ret = clt.get_check_type("fake")
        mgr.get.assert_called_once_with("fake")
        self.assertEqual(ret, ct)

    def test_clt_list_checks(self):
        clt = self.client
        ent = self.entity
        mgr = clt._entity_manager
        chks = utils.random_unicode()
        mgr.list_checks = Mock(return_value=chks)
        ret = clt.list_checks(ent)
        mgr.list_checks.assert_called_once_with(ent)
        self.assertEqual(ret, chks)

    def test_clt_create_check(self):
        clt = self.client
        ent = self.entity
        mgr = clt._entity_manager
        label = utils.random_unicode()
        name = utils.random_unicode()
        check_type = utils.random_unicode()
        disabled = utils.random_unicode()
        metadata = utils.random_unicode()
        details = utils.random_unicode()
        monitoring_zones_poll = utils.random_unicode()
        timeout = utils.random_unicode()
        period = utils.random_unicode()
        target_alias = utils.random_unicode()
        target_hostname = utils.random_unicode()
        target_receiver = utils.random_unicode()
        rand_bool = random.choice((True, False))
        answer = utils.random_unicode()
        mgr.create_check = Mock(return_value=answer)
        ret = clt.create_check(ent, label=label, name=name,
                check_type=check_type, disabled=disabled, metadata=metadata,
                details=details, monitoring_zones_poll=monitoring_zones_poll,
                timeout=timeout, period=period, target_alias=target_alias,
                target_hostname=target_hostname,
                target_receiver=target_receiver, test_only=rand_bool,
                include_debug=rand_bool)
        mgr.create_check.assert_called_once_with(ent, label=label, name=name,
                check_type=check_type, disabled=disabled, metadata=metadata,
                details=details, monitoring_zones_poll=monitoring_zones_poll,
                timeout=timeout, period=period, target_alias=target_alias,
                target_hostname=target_hostname,
                target_receiver=target_receiver, test_only=rand_bool,
                include_debug=rand_bool)
        self.assertEqual(ret, answer)

    def test_clt_get_check(self):
        clt = self.client
        ent = self.entity
        mgr = clt._entity_manager
        answer = utils.random_unicode()
        chk = utils.random_unicode()
        mgr.get_check = Mock(return_value=answer)
        ret = clt.get_check(ent, chk)
        mgr.get_check.assert_called_once_with(ent, chk)
        self.assertEqual(ret, answer)

    def test_clt_find_all_checks(self):
        clt = self.client
        ent = self.entity
        mgr = clt._entity_manager
        answer = utils.random_unicode()
        mgr.find_all_checks = Mock(return_value=answer)
        ret = clt.find_all_checks(ent, foo="fake", bar="fake")
        mgr.find_all_checks.assert_called_once_with(ent, foo="fake", bar="fake")
        self.assertEqual(ret, answer)

    def test_clt_update_check(self):
        clt = self.client
        ent = self.entity
        mgr = clt._entity_manager
        chk = utils.random_unicode()
        label = utils.random_unicode()
        name = utils.random_unicode()
        disabled = utils.random_unicode()
        metadata = utils.random_unicode()
        monitoring_zones_poll = utils.random_unicode()
        timeout = utils.random_unicode()
        period = utils.random_unicode()
        target_alias = utils.random_unicode()
        target_hostname = utils.random_unicode()
        target_receiver = utils.random_unicode()
        mgr.update_check = Mock()
        clt.update_check(ent, chk, label=label, name=name, disabled=disabled,
                metadata=metadata, monitoring_zones_poll=monitoring_zones_poll,
                timeout=timeout, period=period, target_alias=target_alias,
                target_hostname=target_hostname,
                target_receiver=target_receiver)
        mgr.update_check.assert_called_once_with(ent, chk, label=label,
                name=name, disabled=disabled, metadata=metadata,
                monitoring_zones_poll=monitoring_zones_poll, timeout=timeout,
                period=period, target_alias=target_alias,
                target_hostname=target_hostname,
                target_receiver=target_receiver)

    def test_clt_delete_check(self):
        clt = self.client
        ent = self.entity
        mgr = clt._entity_manager
        chk = utils.random_unicode()
        mgr.delete_check = Mock()
        clt.delete_check(ent, chk)
        mgr.delete_check.assert_called_once_with(ent, chk)

    def test_clt_list_metrics(self):
        clt = self.client
        ent = self.entity
        mgr = clt._entity_manager
        chk = utils.random_unicode()
        answer = utils.random_unicode()
        mgr.list_metrics = Mock(return_value=answer)
        ret = clt.list_metrics(ent, chk)
        mgr.list_metrics.assert_called_once_with(ent, chk)
        self.assertEqual(ret, answer)

    def test_clt_get_metric_data_points(self):
        clt = self.client
        ent = self.entity
        mgr = clt._entity_manager
        chk = utils.random_unicode()
        answer = utils.random_unicode()
        mgr.get_metric_data_points = Mock(return_value=answer)
        metric = utils.random_unicode()
        start = utils.random_unicode()
        end = utils.random_unicode()
        points = utils.random_unicode()
        resolution = utils.random_unicode()
        stats = utils.random_unicode()
        ret = clt.get_metric_data_points(ent, chk, metric, start, end,
                points=points, resolution=resolution, stats=stats)
        mgr.get_metric_data_points.assert_called_once_with(ent, chk, metric,
                start, end, points=points, resolution=resolution, stats=stats)
        self.assertEqual(ret, answer)

    def test_clt_list_notifications(self):
        clt = self.client
        ent = self.entity
        mgr = clt._notification_manager
        answer = utils.random_unicode()
        mgr.list = Mock(return_value=answer)
        ret = clt.list_notifications()
        mgr.list.assert_called_once_with()
        self.assertEqual(ret, answer)

    def test_clt_get_notification(self):
        clt = self.client
        ent = self.entity
        mgr = clt._notification_manager
        answer = utils.random_unicode()
        notif_id = utils.random_unicode()
        mgr.get = Mock(return_value=answer)
        ret = clt.get_notification(notif_id)
        mgr.get.assert_called_once_with(notif_id)
        self.assertEqual(ret, answer)

    def test_clt_test_notification(self):
        clt = self.client
        ent = self.entity
        mgr = clt._notification_manager
        answer = utils.random_unicode()
        mgr.test_notification = Mock(return_value=answer)
        notification = utils.random_unicode()
        ntyp = utils.random_unicode()
        details = utils.random_unicode()
        ret = clt.test_notification(notification=notification,
                notification_type=ntyp, details=details)
        mgr.test_notification.assert_called_once_with(notification=notification,
                notification_type=ntyp, details=details)
        self.assertEqual(ret, answer)

    def test_clt_create_notification(self):
        clt = self.client
        ent = self.entity
        mgr = clt._notification_manager
        answer = utils.random_unicode()
        mgr.create = Mock(return_value=answer)
        ntyp = utils.random_unicode()
        label = utils.random_unicode()
        name = utils.random_unicode()
        details = utils.random_unicode()
        ret = clt.create_notification(ntyp, label=label, name=name,
                details=details)
        mgr.create.assert_called_once_with(ntyp, label=label, name=name,
                details=details)
        self.assertEqual(ret, answer)

    def test_clt_update_notification(self):
        clt = self.client
        ent = self.entity
        mgr = clt._notification_manager
        answer = utils.random_unicode()
        mgr.update_notification = Mock(return_value=answer)
        notification = utils.random_unicode()
        details = utils.random_unicode()
        ret = clt.update_notification(notification, details)
        mgr.update_notification.assert_called_once_with(notification, details)
        self.assertEqual(ret, answer)

    def test_clt_delete_notification(self):
        clt = self.client
        ent = self.entity
        mgr = clt._notification_manager
        answer = utils.random_unicode()
        mgr.delete = Mock(return_value=answer)
        notification = utils.random_unicode()
        ret = clt.delete_notification(notification)
        mgr.delete.assert_called_once_with(notification)
        self.assertEqual(ret, answer)

    def test_clt_create_notification_plan(self):
        clt = self.client
        ent = self.entity
        mgr = clt._notification_plan_manager
        answer = utils.random_unicode()
        mgr.create = Mock(return_value=answer)
        label = utils.random_unicode()
        name = utils.random_unicode()
        critical_state = utils.random_unicode()
        ok_state = utils.random_unicode()
        warning_state = utils.random_unicode()
        ret = clt.create_notification_plan(label=label, name=name,
                critical_state=critical_state, ok_state=ok_state,
                warning_state=warning_state)
        mgr.create.assert_called_once_with(label=label, name=name,
                critical_state=critical_state, ok_state=ok_state,
                warning_state=warning_state)
        self.assertEqual(ret, answer)

    def test_clt_list_notification_plans(self):
        clt = self.client
        ent = self.entity
        mgr = clt._notification_plan_manager
        answer = utils.random_unicode()
        mgr.list = Mock(return_value=answer)
        ret = clt.list_notification_plans()
        mgr.list.assert_called_once_with()
        self.assertEqual(ret, answer)

    def test_clt_get_notification_plan(self):
        clt = self.client
        ent = self.entity
        mgr = clt._notification_plan_manager
        answer = utils.random_unicode()
        nplan_id = utils.random_unicode()
        mgr.get = Mock(return_value=answer)
        ret = clt.get_notification_plan(nplan_id)
        mgr.get.assert_called_once_with(nplan_id)
        self.assertEqual(ret, answer)

    def test_clt_delete_notification_plan(self):
        clt = self.client
        ent = self.entity
        mgr = clt._notification_plan_manager
        answer = utils.random_unicode()
        mgr.delete = Mock(return_value=answer)
        notification_plan = utils.random_unicode()
        ret = clt.delete_notification_plan(notification_plan)
        mgr.delete.assert_called_once_with(notification_plan)
        self.assertEqual(ret, answer)

    def test_clt_list_alarms(self):
        clt = self.client
        ent = self.entity
        mgr = clt._entity_manager
        alms = utils.random_unicode()
        mgr.list_alarms = Mock(return_value=alms)
        ret = clt.list_alarms(ent)
        mgr.list_alarms.assert_called_once_with(ent)
        self.assertEqual(ret, alms)

    def test_clt_get_alarm(self):
        clt = self.client
        ent = self.entity
        mgr = clt._entity_manager
        answer = utils.random_unicode()
        alm = utils.random_unicode()
        mgr.get_alarm = Mock(return_value=answer)
        ret = clt.get_alarm(ent, alm)
        mgr.get_alarm.assert_called_once_with(ent, alm)
        self.assertEqual(ret, answer)

    def test_clt_create_alarm(self):
        clt = self.client
        ent = self.entity
        mgr = clt._entity_manager
        chk = utils.random_unicode()
        nplan = utils.random_unicode()
        criteria = utils.random_unicode()
        disabled = utils.random_unicode()
        label = utils.random_unicode()
        name = utils.random_unicode()
        metadata = utils.random_unicode()
        answer = utils.random_unicode()
        mgr.create_alarm = Mock(return_value=answer)
        ret = clt.create_alarm(ent, chk, nplan, criteria=criteria,
                disabled=disabled, label=label, name=name, metadata=metadata)
        mgr.create_alarm.assert_called_once_with(ent, chk, nplan,
                criteria=criteria, disabled=disabled, label=label, name=name,
                metadata=metadata)
        self.assertEqual(ret, answer)

    def test_clt_update_alarm(self):
        clt = self.client
        ent = self.entity
        mgr = clt._entity_manager
        alm = utils.random_unicode()
        criteria = utils.random_unicode()
        disabled = utils.random_unicode()
        label = utils.random_unicode()
        name = utils.random_unicode()
        metadata = utils.random_unicode()
        answer = utils.random_unicode()
        mgr.update_alarm = Mock(return_value=answer)
        ret = clt.update_alarm(ent, alm, criteria=criteria, disabled=disabled,
                label=label, name=name, metadata=metadata)
        mgr.update_alarm.assert_called_once_with(ent, alm, criteria=criteria,
                disabled=disabled, label=label, name=name, metadata=metadata)
        self.assertEqual(ret, answer)

    def test_clt_delete_alarm(self):
        clt = self.client
        ent = self.entity
        mgr = clt._entity_manager
        alm = utils.random_unicode()
        mgr.delete_alarm = Mock()
        clt.delete_alarm(ent, alm)
        mgr.delete_alarm.assert_called_once_with(ent, alm)

    def test_clt_list_notification_types(self):
        clt = self.client
        ent = self.entity
        mgr = clt._notification_manager
        typs = utils.random_unicode()
        mgr.list_types = Mock(return_value=typs)
        ret = clt.list_notification_types()
        mgr.list_types.assert_called_once_with()
        self.assertEqual(ret, typs)

    def test_clt_get_notification_type(self):
        clt = self.client
        ent = self.entity
        mgr = clt._notification_manager
        answer = utils.random_unicode()
        nt_id = utils.random_unicode()
        mgr.get_type = Mock(return_value=answer)
        ret = clt.get_notification_type(nt_id)
        mgr.get_type.assert_called_once_with(nt_id)
        self.assertEqual(ret, answer)

    def test_clt_list_monitoring_zones(self):
        clt = self.client
        ent = self.entity
        mgr = clt._monitoring_zone_manager
        typs = utils.random_unicode()
        mgr.list = Mock(return_value=typs)
        ret = clt.list_monitoring_zones()
        mgr.list.assert_called_once_with()
        self.assertEqual(ret, typs)

    def test_clt_get_monitoring_zone(self):
        clt = self.client
        ent = self.entity
        mgr = clt._monitoring_zone_manager
        answer = utils.random_unicode()
        mz_id = utils.random_unicode()
        mgr.get = Mock(return_value=answer)
        ret = clt.get_monitoring_zone(mz_id)
        mgr.get.assert_called_once_with(mz_id)
        self.assertEqual(ret, answer)

    def test_clt_get_changelogs(self):
        clt = self.client
        mgr = clt._changelog_manager
        entity = utils.random_unicode()
        mgr.list = Mock()
        clt.get_changelogs(entity=entity)
        mgr.list.assert_called_once_with(entity=entity)

    def test_clt_get_overview(self):
        clt = self.client
        mgr = clt._overview_manager
        entity = utils.random_unicode()
        mgr.list = Mock()
        clt.get_overview(entity=entity)
        mgr.list.assert_called_once_with(entity=entity)

    def test_clt_list(self):
        clt = self.client
        self.assertRaises(NotImplementedError, clt.list)

    def test_clt_get(self):
        clt = self.client
        self.assertRaises(NotImplementedError, clt.get, "fake")

    def test_clt_create(self):
        clt = self.client
        self.assertRaises(NotImplementedError, clt.create)

    def test_clt_delete(self):
        clt = self.client
        self.assertRaises(NotImplementedError, clt.delete, "fake")

    def test_clt_find(self):
        clt = self.client
        self.assertRaises(NotImplementedError, clt.find)

    def test_clt_findall(self):
        clt = self.client
        self.assertRaises(NotImplementedError, clt.findall)

    def test_clt_create_body(self):
        mgr = self.client._entity_manager
        label = utils.random_unicode()
        name = utils.random_unicode()
        agent = utils.random_unicode()
        ip_addresses = utils.random_unicode()
        metadata = utils.random_unicode()
        expected = {"label": label, "ip_addresses": ip_addresses,
                "agent_id": agent, "metadata": metadata}
        ret = mgr._create_body(name, label=label, agent=agent,
                ip_addresses=ip_addresses, metadata=metadata)
        self.assertEqual(ret, expected)



if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_cloud_networks
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import random
import unittest

from mock import patch
from mock import MagicMock as Mock

import pyrax.cloudnetworks
from pyrax.cloudnetworks import CloudNetwork
from pyrax.cloudnetworks import CloudNetworkManager
from pyrax.cloudnetworks import CloudNetworkClient
from pyrax.cloudnetworks import _get_server_networks

import pyrax.exceptions as exc
import pyrax.utils as utils

from pyrax import fakes

example_cidr = "1.1.1.0/8"
example_uri = "http://example.com"


class CloudNetworksTest(unittest.TestCase):
    def __init__(self, *args, **kwargs):
        super(CloudNetworksTest, self).__init__(*args, **kwargs)

    def setUp(self):
        self.client = fakes.FakeCloudNetworkClient()

    def tearDown(self):
        self.client = None

    def test_get_types(self):
        iso_network = fakes.FakeCloudNetwork()
        svc_network = fakes.FakeCloudNetwork()
        svc_network.id = pyrax.cloudnetworks.SERVICE_NET_ID
        sav_get = pyrax.resource.BaseResource.get
        pyrax.resource.BaseResource.get = Mock()
        iso_network.get()
        pyrax.resource.BaseResource.get.assert_called_once_with()
        svc_network.get()
        pyrax.resource.BaseResource.get.assert_called_once_with()
        pyrax.resource.BaseResource.get = sav_get

    def test_get_server_networks(self):
        clt = self.client
        iso_network = fakes.FakeCloudNetwork()
        iso_id = iso_network.id
        exp = [{"net-id": iso_id}, {"net-id": clt.PUBLIC_NET_ID},
                {"net-id": clt.SERVICE_NET_ID}]
        ret = _get_server_networks(iso_network, public=True, private=True)
        self.assertEqual(ret, exp)

    def test_get_server_networks_by_client(self):
        clt = self.client
        iso_network = fakes.FakeCloudNetwork()
        iso_id = iso_network.id
        ret = clt.get_server_networks(iso_network)
        self.assertEqual(ret, [{"net-id": iso_id}])
        ret = clt.get_server_networks(iso_network, private=True)
        self.assertEqual(ret, [{"net-id": iso_id},
                {"net-id": clt.SERVICE_NET_ID}])

    def test_get_server_networks_by_network(self):
        clt = self.client
        iso_network = fakes.FakeCloudNetwork()
        iso_id = iso_network.id
        ret = iso_network.get_server_networks()
        self.assertEqual(ret, [{"net-id": iso_id}])
        ret = iso_network.get_server_networks(private=True)
        self.assertEqual(ret, [{"net-id": iso_id},
                {"net-id": clt.SERVICE_NET_ID}])

    def test_create_manager(self):
        clt = self.client
        self.assertTrue(isinstance(clt._manager, CloudNetworkManager))

    def test_create_body(self):
        mgr = self.client._manager
        nm = utils.random_unicode()
        expected = {"network": {"label": nm, "cidr": example_cidr}}
        returned = mgr._create_body(name=nm, cidr=example_cidr)
        self.assertEqual(expected, returned)

    def test_create(self):
        clt = self.client
        clt._manager.create = Mock(return_value=fakes.FakeCloudNetwork())
        nm = utils.random_unicode()
        new = clt.create(label=nm, cidr=example_cidr)
        clt._manager.create.assert_called_once_with(label=nm, name=None,
                cidr=example_cidr)

    def test_create_fail_count(self):
        clt = self.client
        err = exc.BadRequest(400)
        err.message = "Request failed: too many networks."
        clt._manager.create = Mock(side_effect=err)
        nm = utils.random_unicode()
        self.assertRaises(exc.NetworkCountExceeded, clt.create, label=nm,
                cidr=example_cidr)

    def test_create_fail_cidr(self):
        clt = self.client
        err = exc.BadRequest(400)
        err.message = "CIDR does not contain enough addresses."
        clt._manager.create = Mock(side_effect=err)
        nm = utils.random_unicode()
        self.assertRaises(exc.NetworkCIDRInvalid, clt.create, label=nm,
                cidr=example_cidr)

    def test_create_fail_cidr_malformed(self):
        clt = self.client
        err = exc.BadRequest(400)
        err.message = "CIDR is malformed."
        clt._manager.create = Mock(side_effect=err)
        nm = utils.random_unicode()
        self.assertRaises(exc.NetworkCIDRMalformed, clt.create, label=nm,
                cidr=example_cidr)

    def test_create_fail_other(self):
        clt = self.client
        err = exc.BadRequest(400)
        err.message = "Something strange happened."
        clt._manager.create = Mock(side_effect=err)
        nm = utils.random_unicode()
        self.assertRaises(exc.BadRequest, clt.create, label=nm,
                cidr=example_cidr)

    def test_find_network_by_label(self):
        clt = self.client
        net1 = fakes.FakeCloudNetwork(name="First")
        net2 = fakes.FakeCloudNetwork(name="Second")
        net3 = fakes.FakeCloudNetwork(name="Third")
        clt.list = Mock(return_value=[net1, net2, net3])
        found = clt.find_network_by_label("Third")
        self.assertEqual(found, net3)

    def test_find_network_by_label_missing(self):
        clt = self.client
        net1 = fakes.FakeCloudNetwork(name="First")
        net2 = fakes.FakeCloudNetwork(name="Second")
        net3 = fakes.FakeCloudNetwork(name="Third")
        clt.list = Mock(return_value=[net1, net2, net3])
        self.assertRaises(exc.NetworkNotFound, clt.find_network_by_label,
                "Fourth")

    def test_find_network_by_label_multiple(self):
        clt = self.client
        net1 = fakes.FakeCloudNetwork(name="First")
        net2 = fakes.FakeCloudNetwork(name="Third")
        net3 = fakes.FakeCloudNetwork(name="Third")
        clt.list = Mock(return_value=[net1, net2, net3])
        self.assertRaises(exc.NetworkLabelNotUnique, clt.find_network_by_label,
                "Third")

    def test_network_name(self):
        clt = self.client
        nm = "fake"
        net = fakes.FakeCloudNetwork(name=nm)
        self.assertEqual(net.label, nm)
        self.assertEqual(net.name, nm)
        net.name = "faker"
        self.assertEqual(net.name, net.label)

    def test_delete_network(self):
        clt = self.client
        nm = "fake"
        net = fakes.FakeCloudNetwork(name=nm)
        net.manager = fakes.FakeManager()
        net.manager.delete = Mock()
        net.delete()
        net.manager.delete.assert_called_once_with(net)

    def test_delete_network_by_client(self):
        clt = self.client
        nm = "fake"
        net = fakes.FakeCloudNetwork(name=nm)
        clt.method_delete = Mock(return_value=(None, None))
        clt.delete(net)
        clt.method_delete.assert_called_once_with("/os-networksv2/%s" % net.id)

    def test_delete_network_fail(self):
        clt = self.client
        nm = "fake"
        net = fakes.FakeCloudNetwork(name=nm)
        net.manager = fakes.FakeManager()
        err = exc.Forbidden(403)
        net.manager.delete = Mock(side_effect=err)
        self.assertRaises(exc.NetworkInUse, net.delete)

    def test_delete_network_by_client_fail(self):
        clt = self.client
        nm = "fake"
        net = fakes.FakeCloudNetwork(name=nm)
        err = exc.Forbidden(403)
        clt.method_delete = Mock(side_effect=err)
        self.assertRaises(exc.NetworkInUse, clt.delete, net)


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_exceptions
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import unittest

from mock import MagicMock as Mock

import pyrax.utils as utils
import pyrax.exceptions as exc

from pyrax import fakes

fake_url = "http://example.com"


class ExceptionsTest(unittest.TestCase):
    def __init__(self, *args, **kwargs):
        super(ExceptionsTest, self).__init__(*args, **kwargs)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_from_response_no_body(self):
        fake_resp = fakes.FakeResponse()
        fake_resp.status_code = 666
        ret = exc.from_response(fake_resp, None)
        self.assertTrue(isinstance(ret, exc.ClientException))
        self.assertEqual(ret.code, fake_resp.status_code)

    def test_from_response_with_body(self):
        fake_resp = fakes.FakeResponse()
        fake_resp.status_code = 666
        fake_body = {"error": {
                "message": "fake_message",
                "details": "fake_details"}}
        ret = exc.from_response(fake_resp, fake_body)
        self.assertTrue(isinstance(ret, exc.ClientException))
        self.assertEqual(ret.code, fake_resp.status_code)
        self.assertEqual(ret.message, "fake_message")
        self.assertEqual(ret.details, "fake_details")
        self.assertTrue("HTTP 666" in str(ret))



if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_http
#!/usr/bin/env python
# -*- coding: utf-8 -*-
import json
import random
import unittest

from mock import patch
from mock import MagicMock as Mock

import pyrax
import pyrax.utils as utils
import pyrax.exceptions as exc
from pyrax import client

from pyrax import fakes



class HttpTest(unittest.TestCase):
    def __init__(self, *args, **kwargs):
        super(HttpTest, self).__init__(*args, **kwargs)
        self.http = pyrax.http

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_request(self):
        mthd = random.choice(self.http.req_methods.keys())
        sav_method = self.http.req_methods[mthd]
        resp = fakes.FakeResponse()
        self.http.req_methods[mthd] = Mock(return_value=resp)
        uri = utils.random_unicode()
        hk = utils.random_unicode()
        hv = utils.random_unicode()
        headers = {hk: hv}
        self.http.request(mthd, uri, headers=headers)
        self.http.req_methods[mthd].assert_called_once_with(uri,
                headers=headers)
        self.http.req_methods[mthd] = sav_method

    def test_request_no_json(self):
        mthd = random.choice(self.http.req_methods.keys())
        sav_method = self.http.req_methods[mthd]
        resp = fakes.FakeResponse()
        resp.json = Mock(side_effect=ValueError(""))
        self.http.req_methods[mthd] = Mock(return_value=resp)
        uri = utils.random_unicode()
        hk = utils.random_unicode()
        hv = utils.random_unicode()
        headers = {hk: hv}
        self.http.request(mthd, uri, headers=headers)
        self.http.req_methods[mthd].assert_called_once_with(uri,
                headers=headers)
        self.http.req_methods[mthd] = sav_method

    def test_request_exception(self):
        mthd = random.choice(self.http.req_methods.keys())
        sav_method = self.http.req_methods[mthd]
        resp = fakes.FakeResponse()
        resp.status_code = 404
        self.http.req_methods[mthd] = Mock(return_value=resp)
        uri = utils.random_unicode()
        hk = utils.random_unicode()
        hv = utils.random_unicode()
        headers = {hk: hv}
        self.assertRaises(exc.NotFound, self.http.request, mthd, uri,
                headers=headers)

    def test_request_data(self):
        mthd = random.choice(self.http.req_methods.keys())
        sav_method = self.http.req_methods[mthd]
        resp = fakes.FakeResponse()
        self.http.req_methods[mthd] = Mock(return_value=resp)
        uri = utils.random_unicode()
        hk = utils.random_unicode()
        hv = utils.random_unicode()
        headers = {hk: hv}
        data = utils.random_unicode()
        self.http.request(mthd, uri, headers=headers, data=data)
        self.http.req_methods[mthd].assert_called_once_with(uri,
                headers=headers, data=data)
        self.http.req_methods[mthd] = sav_method

    def test_request_body(self):
        mthd = random.choice(self.http.req_methods.keys())
        sav_method = self.http.req_methods[mthd]
        resp = fakes.FakeResponse()
        self.http.req_methods[mthd] = Mock(return_value=resp)
        uri = utils.random_unicode()
        hk = utils.random_unicode()
        hv = utils.random_unicode()
        headers = {hk: hv}
        body = utils.random_unicode()
        jbody = json.dumps(body)
        self.http.request(mthd, uri, headers=headers, body=body)
        self.http.req_methods[mthd].assert_called_once_with(uri,
                headers=headers, data=jbody)
        self.http.req_methods[mthd] = sav_method

    def test_http_log_req(self):
        args = ("a", "b")
        kwargs = {"headers": {"c": "C"}}
        mthd = utils.random_unicode()
        uri = utils.random_unicode()
        sav_pdbug = pyrax._http_debug
        pyrax._http_debug = False
        self.assertIsNone(self.http.http_log_req(mthd, uri, args, kwargs))
        pyrax._http_debug = True
        sav_pldbug = pyrax._logger.debug
        pyrax._logger.debug = Mock()
        self.http.http_log_req(mthd, uri, args, kwargs)
        pyrax._logger.debug.assert_called_once_with(
                "\nREQ: curl -i -X %s a b -H 'c: C' %s\n" % (mthd, uri))
        kwargs["body"] = "text"
        self.http.http_log_req(mthd, uri, args, kwargs)
        cargs, ckw = pyrax._logger.debug.call_args
        self.assertEqual(cargs, ("REQ BODY: text\n", ))
        pyrax._logger.debug = sav_pldbug
        pyrax._http_debug = sav_pdbug

    def test_http_log_resp(self):
        sav_pldbug = pyrax._logger.debug
        pyrax._logger.debug = Mock()
        resp = "resp"
        body = "body"
        sav_pdbug = pyrax._http_debug
        pyrax._http_debug = False
        self.http.http_log_resp(resp, body)
        self.assertFalse(pyrax._logger.debug.called)
        pyrax._http_debug = True
        self.http.http_log_resp(resp, body)
        self.assertTrue(pyrax._logger.debug.called)
        pyrax._logger.debug.assert_called_once_with(
                "RESP: %s %s\n", "resp", "body")
        pyrax._logger.debug = sav_pldbug
        pyrax._http_debug = sav_pdbug


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_identity
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import datetime
import json
import os
import random
import StringIO
import sys
import unittest
import urllib2

from mock import MagicMock as Mock
from mock import patch

import pyrax
import pyrax.utils as utils
import pyrax.exceptions as exc
from pyrax import base_identity
from pyrax.identity import rax_identity

from pyrax import fakes


class DummyResponse(object):
    def read(self):
        pass

    def readline(self):
        pass


class IdentityTest(unittest.TestCase):
    def __init__(self, *args, **kwargs):
        super(IdentityTest, self).__init__(*args, **kwargs)
        self.username = "TESTUSER"
        self.password = "TESTPASSWORD"
        self.base_identity_class = base_identity.BaseIdentity
        self.keystone_identity_class = pyrax.keystone_identity.KeystoneIdentity
        self.rax_identity_class = pyrax.rax_identity.RaxIdentity
        self.id_classes = {"keystone": self.keystone_identity_class,
                "rackspace": self.rax_identity_class}

    def _get_clean_identity(self):
        return self.rax_identity_class()

    def setUp(self):
        self.identity = fakes.FakeIdentity()
        self.service = fakes.FakeIdentityService(self.identity)

    def tearDown(self):
        pass

    def test_svc_repr(self):
        svc = self.service
        rep = svc.__repr__()
        self.assertTrue(svc.service_type in rep)

    def test_svc_ep_for_region(self):
        svc = self.service
        region = utils.random_unicode().upper()
        bad_region = utils.random_unicode().upper()
        good_url = utils.random_unicode()
        bad_url = utils.random_unicode()
        good_ep = fakes.FakeEndpoint({"public_url": good_url}, svc.service_type,
                region, self.identity)
        bad_ep = fakes.FakeEndpoint({"public_url": bad_url}, svc.service_type,
                bad_region, self.identity)
        svc.endpoints = utils.DotDict({region: good_ep, bad_region: bad_ep})
        ep = svc._ep_for_region(region)
        self.assertEqual(ep, good_ep)

    def test_svc_ep_for_region_all(self):
        svc = self.service
        region = "ALL"
        good_url = utils.random_unicode()
        bad_url = utils.random_unicode()
        good_ep = fakes.FakeEndpoint({"public_url": good_url}, svc.service_type,
                region, self.identity)
        bad_ep = fakes.FakeEndpoint({"public_url": bad_url}, svc.service_type,
                region, self.identity)
        svc.endpoints = utils.DotDict({region: good_ep, "other": bad_ep})
        ep = svc._ep_for_region("notthere")
        self.assertEqual(ep, good_ep)

    def test_svc_ep_for_region_not_found(self):
        svc = self.service
        region = utils.random_unicode().upper()
        good_url = utils.random_unicode()
        bad_url = utils.random_unicode()
        good_ep = fakes.FakeEndpoint({"public_url": good_url}, svc.service_type,
                region, self.identity)
        bad_ep = fakes.FakeEndpoint({"public_url": bad_url}, svc.service_type,
                region, self.identity)
        svc.endpoints = utils.DotDict({region: good_ep, "other": bad_ep})
        ep = svc._ep_for_region("notthere")
        self.assertIsNone(ep)

    def test_svc_get_client(self):
        svc = self.service
        clt = utils.random_unicode()
        region = utils.random_unicode()

        class FakeEPForRegion(object):
            client = clt

        svc._ep_for_region = Mock(return_value=FakeEPForRegion())
        ret = svc.get_client(region)
        self.assertEqual(ret, clt)

    def test_svc_get_client_none(self):
        svc = self.service
        region = utils.random_unicode()
        svc._ep_for_region = Mock(return_value=None)
        self.assertRaises(exc.NoEndpointForRegion, svc.get_client, region)

    def test_svc_regions(self):
        svc = self.service
        key1 = utils.random_unicode()
        val1 = utils.random_unicode()
        key2 = utils.random_unicode()
        val2 = utils.random_unicode()
        svc.endpoints = {key1: val1, key2: val2}
        regions = svc.regions
        self.assertEqual(len(regions), 2)
        self.assertTrue(key1 in regions)
        self.assertTrue(key2 in regions)

    def test_ep_get_client_already_failed(self):
        svc = self.service
        ep_dict = {"publicURL": "http://example.com", "tenantId": "aa"}
        rgn = utils.random_unicode().upper()
        ep = fakes.FakeEndpoint(ep_dict, svc, rgn, self.identity)
        ep._client = exc.NoClientForService()
        self.assertRaises(exc.NoClientForService, ep._get_client)

    def test_ep_get_client_exists(self):
        svc = self.service
        ep_dict = {"publicURL": "http://example.com", "tenantId": "aa"}
        rgn = utils.random_unicode().upper()
        ep = fakes.FakeEndpoint(ep_dict, svc, rgn, self.identity)
        clt = utils.random_unicode()
        ep._client = clt
        ret = ep._get_client()
        self.assertEqual(ret, clt)

    def test_ep_get_client_none(self):
        svc = self.service
        ep_dict = {"publicURL": "http://example.com", "tenantId": "aa"}
        rgn = utils.random_unicode().upper()
        ep = fakes.FakeEndpoint(ep_dict, svc, rgn, self.identity)
        sav = pyrax.client_class_for_service
        pyrax.client_class_for_service = Mock(return_value=None)
        self.assertRaises(exc.NoClientForService, ep._get_client)
        pyrax.client_class_for_service = sav

    def test_ep_get_client_no_url(self):
        svc = self.service
        ep_dict = {"publicURL": "http://example.com", "tenantId": "aa"}
        rgn = utils.random_unicode().upper()
        ep = fakes.FakeEndpoint(ep_dict, svc, rgn, self.identity)
        sav = pyrax.client_class_for_service
        ep.public_url = None
        pyrax.client_class_for_service = Mock(return_value=object)
        self.assertRaises(exc.NoEndpointForService, ep._get_client)
        pyrax.client_class_for_service = sav

    def test_ep_get_client(self):
        svc = self.service
        ep_dict = {"publicURL": "http://example.com", "tenantId": "aa"}
        rgn = utils.random_unicode().upper()
        ep = fakes.FakeEndpoint(ep_dict, svc, rgn, self.identity)
        sav = pyrax.client_class_for_service
        ep.public_url = utils.random_unicode()
        pyrax.client_class_for_service = Mock(return_value=object)
        fake = utils.random_unicode()
        ep._create_client = Mock(return_value=fake)
        ret = ep._get_client()
        self.assertEqual(ret, fake)
        self.assertEqual(ep._client, fake)
        pyrax.client_class_for_service = sav

    def test_ep_get_new_client(self):
        svc = self.service
        ep_dict = {"publicURL": "http://example.com", "tenantId": "aa"}
        rgn = utils.random_unicode().upper()
        ep = fakes.FakeEndpoint(ep_dict, svc, rgn, self.identity)
        ep._get_client = Mock()
        ep.get_new_client()
        ep._get_client.assert_called_once_with(public=True, cached=False)

    def test_ep_get(self):
        svc = self.service
        pub = utils.random_unicode()
        priv = utils.random_unicode()
        ep_dict = {"publicURL": pub, "privateURL": priv, "tenantId": "aa"}
        rgn = utils.random_unicode().upper()
        ep = fakes.FakeEndpoint(ep_dict, svc, rgn, self.identity)
        ret = ep.get("public")
        self.assertEqual(ret, pub)
        ret = ep.get("private")
        self.assertEqual(ret, priv)
        self.assertRaises(ValueError, ep.get, "invalid")

    def test_ep_getattr(self):
        svc = self.service
        pub = utils.random_unicode()
        priv = utils.random_unicode()
        ep_dict = {"publicURL": pub, "privateURL": priv, "tenantId": "aa"}
        rgn = utils.random_unicode().upper()
        ep = fakes.FakeEndpoint(ep_dict, svc, rgn, self.identity)
        svc_att = "exists"
        att_val = utils.random_unicode()
        setattr(svc, svc_att, att_val)
        ep._get_client = Mock(return_value=svc)
        ret = ep.exists
        self.assertEqual(ret, att_val)
        self.assertRaises(AttributeError, getattr, ep, "bogus")

    def test_ep_client_prop(self):
        svc = self.service
        pub = utils.random_unicode()
        priv = utils.random_unicode()
        ep_dict = {"publicURL": pub, "privateURL": priv, "tenantId": "aa"}
        rgn = utils.random_unicode().upper()
        ep = fakes.FakeEndpoint(ep_dict, svc, rgn, self.identity)
        clt = utils.random_unicode()
        ep._get_client = Mock(return_value=clt)
        ret = ep.client
        self.assertEqual(ret, clt)

    def test_ep_client_private_prop(self):
        svc = self.service
        pub = utils.random_unicode()
        priv = utils.random_unicode()
        ep_dict = {"publicURL": pub, "privateURL": priv, "tenantId": "aa"}
        rgn = utils.random_unicode().upper()
        ep = fakes.FakeEndpoint(ep_dict, svc, rgn, self.identity)
        clt = utils.random_unicode()
        ep._get_client = Mock(return_value=clt)
        ret = ep.client_private
        self.assertEqual(ret, clt)

    def test_ep_create_client_obj_store(self):
        svc = self.service
        pub = utils.random_unicode()
        priv = utils.random_unicode()
        ep_dict = {"publicURL": pub, "privateURL": priv, "tenantId": "aa"}
        rgn = utils.random_unicode().upper()
        ep = fakes.FakeEndpoint(ep_dict, svc, rgn, self.identity)
        vssl = random.choice((True, False))
        public = random.choice((True, False))
        sav_gs = pyrax.get_setting
        pyrax.get_setting = Mock(return_value=vssl)
        sav_conn = pyrax.connect_to_cloudfiles
        fake_client = object()
        pyrax.connect_to_cloudfiles = Mock(return_value=fake_client)
        ep.service = "object_store"
        ret = ep._create_client(None, None, public)
        self.assertEqual(ret, fake_client)
        pyrax.connect_to_cloudfiles.assert_called_once_with(region=ep.region,
                public=public, context=ep.identity)
        pyrax.connect_to_cloudfiles = sav_conn
        pyrax.get_setting = sav_gs

    def test_ep_create_client_compute(self):
        svc = self.service
        pub = utils.random_unicode()
        priv = utils.random_unicode()
        ep_dict = {"publicURL": pub, "privateURL": priv, "tenantId": "aa"}
        rgn = utils.random_unicode().upper()
        ep = fakes.FakeEndpoint(ep_dict, svc, rgn, self.identity)
        vssl = random.choice((True, False))
        public = random.choice((True, False))
        sav_gs = pyrax.get_setting
        pyrax.get_setting = Mock(return_value=vssl)
        sav_conn = pyrax.connect_to_cloudservers
        fake_client = object()
        pyrax.connect_to_cloudservers = Mock(return_value=fake_client)
        ep.service = "compute"
        ret = ep._create_client(None, None, public)
        self.assertEqual(ret, fake_client)
        pyrax.connect_to_cloudservers.assert_called_once_with(region=ep.region,
                context=ep.identity)
        pyrax.connect_to_cloudservers = sav_conn
        pyrax.get_setting = sav_gs

    def test_ep_create_client_all_other(self):
        svc = self.service
        pub = utils.random_unicode()
        priv = utils.random_unicode()
        ep_dict = {"publicURL": pub, "privateURL": priv, "tenantId": "aa"}
        rgn = utils.random_unicode().upper()
        ep = fakes.FakeEndpoint(ep_dict, svc, rgn, self.identity)
        vssl = random.choice((True, False))
        public = random.choice((True, False))
        url = utils.random_unicode()
        sav_gs = pyrax.get_setting
        pyrax.get_setting = Mock(return_value=vssl)

        class FakeClientClass(object):
            def __init__(self, identity, region_name, management_url,
                    verify_ssl):
                self.identity = identity
                self.region_name = region_name
                self.management_url = management_url
                self.verify_ssl = verify_ssl

        ret = ep._create_client(FakeClientClass, url, public)
        self.assertTrue(isinstance(ret, FakeClientClass))
        pyrax.get_setting = sav_gs

    def test_init(self):
        for cls in self.id_classes.values():
            ident = cls(username=self.username, password=self.password)
            self.assertEqual(ident.username, self.username)
            self.assertEqual(ident.password, self.password)
            self.assertIsNone(ident.token)
            self.assertIsNone(ident._creds_file)

    def test_auth_with_token_name(self):
        for cls in self.id_classes.values():
            ident = cls()
            tok = utils.random_unicode()
            nm = utils.random_unicode()
            resp = fakes.FakeIdentityResponse()
            # Need to stuff this into the standard response
            sav = resp.content["access"]["user"]["name"]
            resp.content["access"]["user"]["name"] = nm
            ident.method_post = Mock(return_value=(resp, resp.json()))
            ident.auth_with_token(tok, tenant_name=nm)
            ident.method_post.assert_called_once_with("tokens",
                    headers={'Content-Type': 'application/json', 'Accept':
                    'application/json'}, std_headers=False, data={'auth':
                    {'token': {'id': tok}, 'tenantName': nm}})
            self.assertEqual(ident.username, nm)
            resp.content["access"]["user"]["name"] = sav

    def test_auth_with_token_id(self):
        for cls in self.id_classes.values():
            ident = cls()
            tok = utils.random_unicode()
            tenant_id = utils.random_unicode()
            resp = fakes.FakeIdentityResponse()
            # Need to stuff this into the standard response
            sav = resp.content["access"]["token"]["tenant"]["id"]
            resp.content["access"]["token"]["tenant"]["id"] = tenant_id
            ident.method_post = Mock(return_value=(resp, resp.json()))
            ident.auth_with_token(tok, tenant_id=tenant_id)
            ident.method_post.assert_called_once_with("tokens",
                    headers={'Content-Type': 'application/json', 'Accept':
                    'application/json'}, std_headers=False, data={'auth':
                    {'token': {'id': tok}, 'tenantId': tenant_id}})
            self.assertEqual(ident.tenant_id, tenant_id)
            resp.content["access"]["token"]["tenant"]["id"] = sav

    def test_auth_with_token_without_tenant_id(self):
        for cls in self.id_classes.values():
            ident = cls()
            tok = utils.random_unicode()
            tenant_id = None
            resp = fakes.FakeIdentityResponse()
            # Need to stuff this into the standard response
            sav = resp.content["access"]["token"]["tenant"]["id"]
            resp.content["access"]["token"]["tenant"]["id"] = tenant_id
            ident.method_post = Mock(return_value=(resp, resp.json()))
            ident.auth_with_token(tok, tenant_id=tenant_id)
            ident.method_post.assert_called_once_with("tokens",
                    headers={'Content-Type': 'application/json', 'Accept':
                    'application/json'}, std_headers=False, data={'auth':
                    {'token': {'id': tok}}})
            self.assertEqual(ident.tenant_id, tenant_id)
            resp.content["access"]["token"]["tenant"]["id"] = sav

    def test_auth_with_token_id_auth_fail(self):
        for cls in self.id_classes.values():
            ident = cls()
            tok = utils.random_unicode()
            tenant_id = utils.random_unicode()
            resp = fakes.FakeIdentityResponse()
            resp.status_code = 401
            ident.method_post = Mock(return_value=(resp, resp.json()))
            self.assertRaises(exc.AuthenticationFailed, ident.auth_with_token,
                    tok, tenant_id=tenant_id)

    def test_auth_with_token_id_auth_fail_general(self):
        for cls in self.id_classes.values():
            ident = cls()
            tok = utils.random_unicode()
            tenant_id = utils.random_unicode()
            resp = fakes.FakeIdentityResponse()
            resp.status_code = 499
            resp.reason = "fake"
            resp.json = Mock(return_value={"error": {"message": "fake"}})
            ident.method_post = Mock(return_value=(resp, resp.json()))
            self.assertRaises(exc.AuthenticationFailed, ident.auth_with_token,
                    tok, tenant_id=tenant_id)

    def test_auth_with_token_rax(self):
        ident = self.rax_identity_class()
        mid = utils.random_unicode()
        oid = utils.random_unicode()
        token = utils.random_unicode()

        class FakeResp(object):
            info = None

            def json(self):
                return self.info

        resp_main = FakeResp()
        resp_main_body = {"access": {
                "serviceCatalog": [{"a": "a", "name": "a", "type": "a"},
                        {"b": "b", "name": "b", "type": "b"}],
                "user": {"roles":
                        [{"tenantId": oid, "name": "object-store:default"}],
                }}}
        ident._call_token_auth = Mock(return_value=(resp_main, resp_main_body))

        def fake_parse(dct):
            svcs = dct.get("access", {}).get("serviceCatalog", {})
            pyrax.services = [svc["name"] for svc in svcs]

        ident._parse_response = fake_parse
        ident.auth_with_token(token, tenant_id=mid)
        ident._call_token_auth.assert_called_with(token, oid, None)
        self.assertTrue("a" in pyrax.services)
        self.assertTrue("b" in pyrax.services)

    def test_get_client(self):
        ident = self.identity
        ident.authenticated = True
        svc = "fake"
        region = utils.random_unicode()
        pub = utils.random_unicode()
        priv = utils.random_unicode()
        ep_dict = {"publicURL": pub, "privateURL": priv, "tenantId": "aa"}
        rgn = "FOO"
        clt = fakes.FakeClient()
        ep = fakes.FakeEndpoint(ep_dict, svc, rgn, self.identity)
        ep._get_client = Mock(return_value=clt)
        ident.services[svc].endpoints = {region: ep}
        ret = ident.get_client(svc, region)
        self.assertEqual(ret, clt)

    def test_get_client_unauthenticated(self):
        ident = self.identity
        ident.authenticated = False
        svc = "fake"
        region = utils.random_unicode()
        pub = utils.random_unicode()
        priv = utils.random_unicode()
        ep_dict = {"publicURL": pub, "privateURL": priv, "tenantId": "aa"}
        rgn = "FOO"
        clt = fakes.FakeClient()
        ep = fakes.FakeEndpoint(ep_dict, svc, rgn, self.identity)
        ep._get_client = Mock(return_value=clt)
        ident.services[svc].endpoints = {region: ep}
        self.assertRaises(exc.NotAuthenticated, ident.get_client, svc, region)

    def test_get_client_private(self):
        ident = self.identity
        ident.authenticated = True
        svc = "fake"
        region = utils.random_unicode()
        pub = utils.random_unicode()
        priv = utils.random_unicode()
        ep_dict = {"publicURL": pub, "privateURL": priv, "tenantId": "aa"}
        rgn = "FOO"
        clt = fakes.FakeClient()
        ep = fakes.FakeEndpoint(ep_dict, svc, rgn, self.identity)
        ep._get_client = Mock(return_value=clt)
        ident.services[svc].endpoints = {region: ep}
        ret = ident.get_client(svc, region, public=False)
        self.assertEqual(ret, clt)
        ep._get_client.assert_called_once_with(public=False)

    def test_get_client_no_cache(self):
        ident = self.identity
        ident.authenticated = True
        svc = "fake"
        region = utils.random_unicode()
        pub = utils.random_unicode()
        priv = utils.random_unicode()
        ep_dict = {"publicURL": pub, "privateURL": priv, "tenantId": "aa"}
        rgn = "FOO"
        clt = fakes.FakeClient()
        ep = fakes.FakeEndpoint(ep_dict, svc, rgn, self.identity)
        ep.get_new_client = Mock(return_value=clt)
        ident.services[svc].endpoints = {region: ep}
        ret = ident.get_client(svc, region, cached=False)
        self.assertEqual(ret, clt)
        ep.get_new_client.assert_called_once_with(public=True)

    def test_get_client_no_client(self):
        ident = self.identity
        ident.authenticated = True
        svc = "fake"
        region = utils.random_unicode()
        pub = utils.random_unicode()
        priv = utils.random_unicode()
        ep_dict = {"publicURL": pub, "privateURL": priv, "tenantId": "aa"}
        rgn = "FOO"
        ep = fakes.FakeEndpoint(ep_dict, svc, rgn, self.identity)
        ep._get_client = Mock(return_value=None)
        ident.services[svc].endpoints = {region: ep}
        self.assertRaises(exc.NoSuchClient, ident.get_client, svc, region)

    def test_set_credentials(self):
        for cls in self.id_classes.values():
            ident = cls()
            ident.authenticate = Mock()
            ident.set_credentials(self.username, self.password,
                    authenticate=True)
            self.assertEqual(ident.username, self.username)
            self.assertEqual(ident.password, self.password)
            self.assertIsNone(ident.token)
            self.assertIsNone(ident._creds_file)
            ident.authenticate.assert_called_once_with()

    def test_set_credential_file(self):
        ident = self.rax_identity_class()
        user = "fakeuser"
        # Use percent signs in key to ensure it doesn't get interpolated.
        key = "fake%api%key"
        ident.authenticate = Mock()
        with utils.SelfDeletingTempfile() as tmpname:
            with open(tmpname, "wb") as ff:
                ff.write("[rackspace_cloud]\n")
                ff.write("username = %s\n" % user)
                ff.write("api_key = %s\n" % key)
            ident.set_credential_file(tmpname, authenticate=True)
        self.assertEqual(ident.username, user)
        self.assertEqual(ident.password, key)
        # Using 'password' instead of 'api_key'
        with utils.SelfDeletingTempfile() as tmpname:
            with open(tmpname, "wb") as ff:
                ff.write("[rackspace_cloud]\n")
                ff.write("username = %s\n" % user)
                ff.write("password = %s\n" % key)
            ident.set_credential_file(tmpname)
        self.assertEqual(ident.username, user)
        self.assertEqual(ident.password, key)
        # File doesn't exist
        self.assertRaises(exc.FileNotFound, ident.set_credential_file,
                "doesn't exist")
        # Missing section
        with utils.SelfDeletingTempfile() as tmpname:
            with open(tmpname, "wb") as ff:
                ff.write("user = x\n")
            self.assertRaises(exc.InvalidCredentialFile,
                    ident.set_credential_file, tmpname)
        # Incorrect section
        with utils.SelfDeletingTempfile() as tmpname:
            with open(tmpname, "wb") as ff:
                ff.write("[bad_section]\nusername = x\napi_key = y\n")
            self.assertRaises(exc.InvalidCredentialFile,
                    ident.set_credential_file, tmpname)
        # Incorrect option
        with utils.SelfDeletingTempfile() as tmpname:
            with open(tmpname, "wb") as ff:
                ff.write("[rackspace_cloud]\nuserbad = x\napi_key = y\n")
            self.assertRaises(exc.InvalidCredentialFile,
                    ident.set_credential_file, tmpname)

    def test_set_credential_file_keystone(self):
        ident = pyrax.keystone_identity.KeystoneIdentity(username=self.username,
                password=self.password)
        user = "fakeuser"
        password = "fakeapikey"
        tenant_id = "faketenantid"
        with utils.SelfDeletingTempfile() as tmpname:
            with file(tmpname, "wb") as ff:
                ff.write("[keystone]\n")
                ff.write("username = %s\n" % user)
                ff.write("password = %s\n" % password)
                ff.write("tenant_id = %s\n" % tenant_id)
            ident.set_credential_file(tmpname)
        self.assertEqual(ident.username, user)
        self.assertEqual(ident.password, password)

    def test_keyring_auth_no_keyring(self):
        ident = self.identity
        sav = pyrax.base_identity.keyring
        pyrax.base_identity.keyring = None
        self.assertRaises(exc.KeyringModuleNotInstalled, ident.keyring_auth)
        pyrax.base_identity.keyring = sav

    def test_keyring_auth_no_username(self):
        ident = self.identity
        sav = pyrax.get_setting
        pyrax.get_setting = Mock(return_value=None)
        self.assertRaises(exc.KeyringUsernameMissing, ident.keyring_auth)
        pyrax.get_setting = sav

    def test_keyring_auth_no_password(self):
        ident = self.identity
        sav = pyrax.base_identity.keyring.get_password
        pyrax.base_identity.keyring.get_password = Mock(return_value=None)
        self.assertRaises(exc.KeyringPasswordNotFound, ident.keyring_auth,
                "fake")
        pyrax.base_identity.keyring.get_password = sav

    def test_keyring_auth_apikey(self):
        ident = self.identity
        ident.authenticate = Mock()
        sav = pyrax.base_identity.keyring.get_password
        pw = utils.random_unicode()
        pyrax.base_identity.keyring.get_password = Mock(return_value=pw)
        user = utils.random_unicode()
        ident._creds_style = "apikey"
        ident.keyring_auth(username=user)
        ident.authenticate.assert_called_once_with(username=user, api_key=pw)
        pyrax.base_identity.keyring.get_password = sav

    def test_keyring_auth_password(self):
        ident = self.identity
        ident.authenticate = Mock()
        sav = pyrax.base_identity.keyring.get_password
        pw = utils.random_unicode()
        pyrax.base_identity.keyring.get_password = Mock(return_value=pw)
        user = utils.random_unicode()
        ident._creds_style = "password"
        ident.keyring_auth(username=user)
        ident.authenticate.assert_called_once_with(username=user, password=pw)
        pyrax.base_identity.keyring.get_password = sav

    def test_get_extensions(self):
        ident = self.identity
        v1 = utils.random_unicode()
        v2 = utils.random_unicode()
        resp_body = {"extensions": {"values": [v1, v2]}}
        ident.method_get = Mock(return_value=(None, resp_body))
        ret = ident.get_extensions()
        self.assertEqual(ret, [v1, v2])

    def test_get_credentials_rax(self):
        ident = self.rax_identity_class(username=self.username,
                api_key=self.password)
        ident._creds_style = "apikey"
        creds = ident._format_credentials()
        user = creds["auth"]["RAX-KSKEY:apiKeyCredentials"]["username"]
        key = creds["auth"]["RAX-KSKEY:apiKeyCredentials"]["apiKey"]
        self.assertEqual(self.username, user)
        self.assertEqual(self.password, key)

    def test_get_credentials_rax_password(self):
        ident = self.rax_identity_class(username=self.username,
                password=self.password)
        ident._creds_style = "password"
        creds = ident._format_credentials()
        user = creds["auth"]["passwordCredentials"]["username"]
        key = creds["auth"]["passwordCredentials"]["password"]
        self.assertEqual(self.username, user)
        self.assertEqual(self.password, key)

    def test_get_credentials_keystone(self):
        ident = self.keystone_identity_class(username=self.username,
                password=self.password)
        creds = ident._format_credentials()
        user = creds["auth"]["passwordCredentials"]["username"]
        key = creds["auth"]["passwordCredentials"]["password"]
        self.assertEqual(self.username, user)
        self.assertEqual(self.password, key)

    def test_authenticate(self):
        savrequest = pyrax.http.request
        fake_resp = fakes.FakeIdentityResponse()
        fake_body = fakes.fake_identity_response
        pyrax.http.request = Mock(return_value=(fake_resp, fake_body))
        for cls in self.id_classes.values():
            ident = cls()
            if cls is self.keystone_identity_class:
                # Necessary for testing to avoid NotImplementedError.
                utils.add_method(ident, lambda self: "", "_get_auth_endpoint")
            ident.authenticate()
        pyrax.http.request = savrequest

    def test_authenticate_fail_creds(self):
        ident = self.rax_identity_class(username="BAD", password="BAD")
        savrequest = pyrax.http.request
        fake_resp = fakes.FakeIdentityResponse()
        fake_resp.status_code = 401
        fake_body = fakes.fake_identity_response
        pyrax.http.request = Mock(return_value=(fake_resp, fake_body))
        self.assertRaises(exc.AuthenticationFailed, ident.authenticate)
        pyrax.http.request = savrequest

    def test_authenticate_fail_other(self):
        ident = self.rax_identity_class(username="BAD", password="BAD")
        savrequest = pyrax.http.request
        fake_resp = fakes.FakeIdentityResponse()
        fake_resp.status_code = 500
        fake_body = {u'unauthorized': {
                u'message': u'Username or api key is invalid', u'code': 500}}
        pyrax.http.request = Mock(return_value=(fake_resp, fake_body))
        self.assertRaises(exc.InternalServerError, ident.authenticate)
        pyrax.http.request = savrequest

    def test_authenticate_fail_no_message(self):
        ident = self.rax_identity_class(username="BAD", password="BAD")
        savrequest = pyrax.http.request
        fake_resp = fakes.FakeIdentityResponse()
        fake_resp.status_code = 500
        fake_body = {u'unauthorized': {
                u'bogus': u'Username or api key is invalid', u'code': 500}}
        pyrax.http.request = Mock(return_value=(fake_resp, fake_body))
        self.assertRaises(exc.InternalServerError, ident.authenticate)
        pyrax.http.request = savrequest

    def test_authenticate_fail_gt_299(self):
        ident = self.rax_identity_class(username="BAD", password="BAD")
        savrequest = pyrax.http.request
        fake_resp = fakes.FakeIdentityResponse()
        fake_resp.status_code = 444
        fake_body = {u'unauthorized': {
                u'message': u'Username or api key is invalid', u'code': 500}}
        pyrax.http.request = Mock(return_value=(fake_resp, fake_body))
        self.assertRaises(exc.AuthenticationFailed, ident.authenticate)
        pyrax.http.request = savrequest

    def test_authenticate_fail_gt_299ino_message(self):
        ident = self.rax_identity_class(username="BAD", password="BAD")
        savrequest = pyrax.http.request
        fake_resp = fakes.FakeIdentityResponse()
        fake_resp.status_code = 444
        fake_body = {u'unauthorized': {
                u'bogus': u'Username or api key is invalid', u'code': 500}}
        pyrax.http.request = Mock(return_value=(fake_resp, fake_body))
        self.assertRaises(exc.AuthenticationFailed, ident.authenticate)
        pyrax.http.request = savrequest

    def test_rax_endpoints(self):
        ident = self.rax_identity_class()
        ep = ident._get_auth_endpoint()
        self.assertEqual(ep, rax_identity.AUTH_ENDPOINT)

    def test_auth_token(self):
        for cls in self.id_classes.values():
            ident = cls()
            test_token = utils.random_unicode()
            ident.token = test_token
            self.assertEqual(ident.auth_token, test_token)

    def test_auth_endpoint(self):
        for cls in self.id_classes.values():
            ident = cls()
            test_ep = utils.random_unicode()
            ident._get_auth_endpoint = Mock(return_value=test_ep)
            self.assertEqual(ident.auth_endpoint, test_ep)

    def test_set_auth_endpoint(self):
        for cls in self.id_classes.values():
            ident = cls()
            test_ep = utils.random_unicode()
            ident.auth_endpoint = test_ep
            self.assertEqual(ident._auth_endpoint, test_ep)

    def test_regions(self):
        ident = self.base_identity_class()
        fake_resp = fakes.FakeIdentityResponse()
        ident._parse_response(fake_resp.json())
        expected = ("DFW", "ORD", "SYD", "FAKE")
        self.assertEqual(len(ident.regions), len(expected))
        for rgn in expected:
            self.assertTrue(rgn in ident.regions)

    def test_getattr_service(self):
        ident = self.base_identity_class()
        ident.authenticated = True
        svc = self.service
        pub = utils.random_unicode()
        priv = utils.random_unicode()
        ep_dict = {"publicURL": pub, "privateURL": priv, "tenantId": "aa"}
        rgn = "FOO"
        ep = fakes.FakeEndpoint(ep_dict, svc, rgn, self.identity)
        self.service.endpoints = {rgn: ep}
        ident.services = {"fake": self.service}
        ret = ident.fake
        self.assertEqual(ret, self.service.endpoints)

    def test_getattr_region(self):
        ident = self.base_identity_class()
        ident.authenticated = True
        svc = self.service
        pub = utils.random_unicode()
        priv = utils.random_unicode()
        ep_dict = {"publicURL": pub, "privateURL": priv, "tenantId": "aa"}
        rgn = "FOO"
        ep = fakes.FakeEndpoint(ep_dict, svc, rgn, self.identity)
        self.service.endpoints = {rgn: ep}
        ident.services = {"fake": self.service}
        ret = ident.FOO
        self.assertEqual(ret, {"fake": ep})

    def test_getattr_fail(self):
        ident = self.base_identity_class()
        ident.authenticated = True
        svc = self.service
        pub = utils.random_unicode()
        priv = utils.random_unicode()
        ep_dict = {"publicURL": pub, "privateURL": priv, "tenantId": "aa"}
        rgn = "FOO"
        ep = fakes.FakeEndpoint(ep_dict, svc, rgn, self.identity)
        self.service.endpoints = {rgn: ep}
        ident.services = {"fake": self.service}
        self.assertRaises(AttributeError, getattr, ident, "BAR")

    def test_getattr_not_authed(self):
        ident = self.base_identity_class()
        ident.authenticated = False
        svc = self.service
        pub = utils.random_unicode()
        priv = utils.random_unicode()
        ep_dict = {"publicURL": pub, "privateURL": priv, "tenantId": "aa"}
        rgn = "FOO"
        ep = fakes.FakeEndpoint(ep_dict, svc, rgn, self.identity)
        self.service.endpoints = {rgn: ep}
        ident.services = {"fake": self.service}
        self.assertRaises(exc.NotAuthenticated, getattr, ident, "BAR")

    def test_http_methods(self):
        ident = self.base_identity_class()
        ident._call = Mock()
        uri = utils.random_unicode()
        dkv = utils.random_unicode()
        data = {dkv: dkv}
        hkv = utils.random_unicode()
        headers = {hkv: hkv}
        std_headers = True
        ident.method_get(uri, admin=False, data=data, headers=headers,
                std_headers=std_headers)
        ident._call.assert_called_with("GET", uri, False, data, headers,
                std_headers)
        ident.method_head(uri, admin=False, data=data, headers=headers,
                std_headers=std_headers)
        ident._call.assert_called_with("HEAD", uri, False, data, headers,
                std_headers)
        ident.method_post(uri, admin=False, data=data, headers=headers,
                std_headers=std_headers)
        ident._call.assert_called_with("POST", uri, False, data, headers,
                std_headers)
        ident.method_put(uri, admin=False, data=data, headers=headers,
                std_headers=std_headers)
        ident._call.assert_called_with("PUT", uri, False, data, headers,
                std_headers)
        ident.method_delete(uri, admin=False, data=data, headers=headers,
                std_headers=std_headers)
        ident._call.assert_called_with("DELETE", uri, False, data,
                headers, std_headers)
        ident.method_patch(uri, admin=False, data=data, headers=headers,
                std_headers=std_headers)
        ident._call.assert_called_with("PATCH", uri, False, data,
                headers, std_headers)

    def test_call(self):
        ident = self.base_identity_class()
        sav_req = pyrax.http.request
        pyrax.http.request = Mock()
        sav_debug = ident.http_log_debug
        ident.http_log_debug = True
        uri = "https://%s/%s" % (utils.random_ascii(), utils.random_ascii())
        sav_stdout = sys.stdout
        out = StringIO.StringIO()
        sys.stdout = out
        utils.add_method(ident, lambda self: "", "_get_auth_endpoint")
        dkv = utils.random_ascii()
        data = {dkv: dkv}
        hkv = utils.random_ascii()
        headers = {hkv: hkv}
        for std_headers in (True, False):
            expected_headers = ident._standard_headers() if std_headers else {}
            expected_headers.update(headers)
            for admin in (True, False):
                ident.method_post(uri, data=data, headers=headers,
                        std_headers=std_headers, admin=admin)
                pyrax.http.request.assert_called_with("POST", uri, body=data,
                        headers=expected_headers)
                self.assertEqual(out.getvalue(), "")
                out.seek(0)
                out.truncate()
        out.close()
        pyrax.http.request = sav_req
        ident.http_log_debug = sav_debug
        sys.stdout = sav_stdout

    def test_call_without_slash(self):
        ident = self.base_identity_class()
        ident._get_auth_endpoint = Mock()
        ident._get_auth_endpoint.return_value = "http://example.com/v2.0"
        ident.verify_ssl = False
        pyrax.http.request = Mock()
        ident._call("POST", "tokens", False, {}, {}, False)
        pyrax.http.request.assert_called_with("POST",
                "http://example.com/v2.0/tokens", headers={},
                raise_exception=False)

    def test_call_with_slash(self):
        ident = self.base_identity_class()
        ident._get_auth_endpoint = Mock()
        ident._get_auth_endpoint.return_value = "http://example.com/v2.0/"
        ident.verify_ssl = False
        pyrax.http.request = Mock()
        ident._call("POST", "tokens", False, {}, {}, False)
        pyrax.http.request.assert_called_with("POST",
                "http://example.com/v2.0/tokens", headers={},
                raise_exception=False)

    def test_list_users(self):
        ident = self.rax_identity_class()
        resp = fakes.FakeIdentityResponse()
        resp.response_type = "users"
        ident.method_get = Mock(return_value=(resp, resp.json()))
        ret = ident.list_users()
        self.assertTrue(isinstance(ret, list))
        are_users = [isinstance(itm, pyrax.rax_identity.User) for itm in ret]
        self.assertTrue(all(are_users))

    def test_list_users_alt_body(self):
        ident = self.rax_identity_class()
        resp = fakes.FakeIdentityResponse()
        resp.response_type = "users"
        alt = fakes.fake_identity_user_response.get("users")
        alt[0]["password"] = "foo"
        ident.method_get = Mock(return_value=(resp, alt))
        ret = ident.list_users()
        self.assertTrue(isinstance(ret, list))
        are_users = [isinstance(itm, pyrax.rax_identity.User) for itm in ret]
        self.assertTrue(all(are_users))

    def test_list_users_fail(self):
        ident = self.rax_identity_class()
        resp = fakes.FakeIdentityResponse()
        resp.response_type = "users"
        resp.status_code = 401
        ident.method_get = Mock(return_value=(resp, resp.json()))
        self.assertRaises(exc.AuthorizationFailure, ident.list_users)

    def test_find_user_by_name_rax(self):
        ident = self.rax_identity_class()
        ident.get_user = Mock()
        fake_name = utils.random_unicode()
        ret = ident.find_user_by_name(fake_name)
        ident.get_user.assert_called_with(username=fake_name)

    def test_find_user_by_email_rax(self):
        ident = self.rax_identity_class()
        ident.get_user = Mock()
        fake_email = utils.random_unicode()
        ret = ident.find_user_by_email(fake_email)
        ident.get_user.assert_called_with(email=fake_email)

    def test_find_user_by_id_rax(self):
        ident = self.rax_identity_class()
        ident.get_user = Mock()
        fake_id = utils.random_unicode()
        ret = ident.find_user_by_id(fake_id)
        ident.get_user.assert_called_with(user_id=fake_id)

    def test_find_user_fail_rax(self):
        ident = self.rax_identity_class()
        resp = fakes.FakeIdentityResponse()
        resp.response_type = "users"
        resp.status_code = 404
        ident.method_get = Mock(return_value=(resp, resp.json()))
        fake_user = utils.random_unicode()
        self.assertRaises(exc.NotFound, ident.get_user, username=fake_user)

    def test_find_user_fail_base(self):
        ident = self.identity
        fake = utils.random_unicode()
        self.assertRaises(NotImplementedError, ident.find_user_by_name, fake)
        self.assertRaises(NotImplementedError, ident.find_user_by_email, fake)
        self.assertRaises(NotImplementedError, ident.find_user_by_id, fake)
        self.assertRaises(NotImplementedError, ident.get_user, fake)

    def test_get_user_by_id(self):
        ident = self.rax_identity_class()
        resp = fakes.FakeIdentityResponse()
        resp.response_type = "users"
        resp_body = resp.json().copy()
        del resp_body["users"]
        fake = utils.random_unicode()
        ident.method_get = Mock(return_value=(resp, resp_body))
        ret = ident.get_user(user_id=fake)
        self.assertTrue(isinstance(ret, base_identity.User))

    def test_get_user_by_username(self):
        ident = self.rax_identity_class()
        resp = fakes.FakeIdentityResponse()
        resp.response_type = "users"
        resp_body = resp.json().copy()
        del resp_body["users"]
        fake = utils.random_unicode()
        ident.method_get = Mock(return_value=(resp, resp_body))
        ret = ident.get_user(username=fake)
        self.assertTrue(isinstance(ret, base_identity.User))

    def test_get_user_by_email(self):
        ident = self.rax_identity_class()
        resp = fakes.FakeIdentityResponse()
        resp.response_type = "users"
        resp_body = resp.json()
        fake = utils.random_unicode()
        ident.method_get = Mock(return_value=(resp, resp_body))
        ret = ident.get_user(email=fake)
        self.assertTrue(isinstance(ret[0], base_identity.User))

    def test_get_user_missing_params(self):
        ident = self.rax_identity_class()
        resp = fakes.FakeIdentityResponse()
        resp.response_type = "users"
        ident.method_get = Mock(return_value=(resp, resp.json()))
        self.assertRaises(ValueError, ident.get_user)

    def test_get_user_not_found(self):
        ident = self.rax_identity_class()
        resp = fakes.FakeIdentityResponse()
        resp.response_type = "users"
        resp_body = resp.json().copy()
        del resp_body["users"]
        del resp_body["user"]
        fake = utils.random_unicode()
        ident.method_get = Mock(return_value=(resp, resp_body))
        self.assertRaises(exc.NotFound, ident.get_user, username=fake)

    def test_create_user(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "users"
            resp.status_code = 201
            ident.method_post = Mock(return_value=(resp, resp.json()))
            fake_name = utils.random_unicode()
            fake_email = utils.random_unicode()
            fake_password = utils.random_unicode()
            ident.create_user(fake_name, fake_email, fake_password)
            cargs = ident.method_post.call_args
            self.assertEqual(len(cargs), 2)
            self.assertEqual(cargs[0], ("users", ))
            data = cargs[1]["data"]["user"]
            self.assertEqual(data["username"], fake_name)
            self.assertTrue(fake_password in data.values())

    def test_create_user_not_authorized(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "users"
            resp.status_code = 401
            ident.method_post = Mock(return_value=(resp, resp.json()))
            fake_name = utils.random_unicode()
            fake_email = utils.random_unicode()
            fake_password = utils.random_unicode()
            self.assertRaises(exc.AuthorizationFailure, ident.create_user,
                    fake_name, fake_email, fake_password)

    def test_create_user_duplicate(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "users"
            resp.status_code = 409
            ident.method_post = Mock(return_value=(resp, resp.json()))
            fake_name = utils.random_unicode()
            fake_email = utils.random_unicode()
            fake_password = utils.random_unicode()
            self.assertRaises(exc.DuplicateUser, ident.create_user,
                    fake_name, fake_email, fake_password)

    def test_create_user_bad_email(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "users"
            resp.status_code = 400
            resp_body = {"badRequest": {"message":
                    "Expecting valid email address"}}
            ident.method_post = Mock(return_value=(resp, resp_body))
            fake_name = utils.random_unicode()
            fake_email = utils.random_unicode()
            fake_password = utils.random_unicode()
            self.assertRaises(exc.InvalidEmail, ident.create_user,
                    fake_name, fake_email, fake_password)

    def test_create_user_not_found(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "users"
            resp.status_code = 404
            ident.method_post = Mock(return_value=(resp, resp.json()))
            fake_name = utils.random_unicode()
            fake_email = utils.random_unicode()
            fake_password = utils.random_unicode()
            self.assertRaises(exc.AuthorizationFailure, ident.create_user,
                    fake_name, fake_email, fake_password)

    def test_create_user_other(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "users"
            resp.status_code = 400
            resp_body = {"badRequest": {"message": "fake"}}
            ident.method_post = Mock(return_value=(resp, resp_body))
            fake_name = utils.random_unicode()
            fake_email = utils.random_unicode()
            fake_password = utils.random_unicode()
            self.assertRaises(exc.BadRequest, ident.create_user,
                    fake_name, fake_email, fake_password)

    def test_update_user(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "users"
            ident.method_put = Mock(return_value=(resp, resp.json()))
            fake_name = utils.random_unicode()
            fake_email = utils.random_unicode()
            fake_username = utils.random_unicode()
            fake_uid = utils.random_unicode()
            fake_region = utils.random_unicode()
            fake_enabled = random.choice((True, False))
            kwargs = {"email": fake_email, "username": fake_username,
                    "uid": fake_uid, "enabled": fake_enabled}
            if isinstance(ident, self.rax_identity_class):
                kwargs["defaultRegion"] = fake_region
            ident.update_user(fake_name, **kwargs)
            cargs = ident.method_put.call_args
            self.assertEqual(len(cargs), 2)
            self.assertEqual(cargs[0], ("users/%s" % fake_name, ))
            data = cargs[1]["data"]["user"]
            self.assertEqual(data["enabled"], fake_enabled)
            self.assertEqual(data["username"], fake_username)
            self.assertTrue(fake_email in data.values())
            if isinstance(ident, self.rax_identity_class):
                self.assertTrue(fake_region in data.values())

    def test_update_user_fail(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "users"
            resp.status_code = 401
            ident.method_put = Mock(return_value=(resp, resp.json()))
            fake_name = utils.random_unicode()
            fake_email = utils.random_unicode()
            fake_username = utils.random_unicode()
            fake_uid = utils.random_unicode()
            fake_region = utils.random_unicode()
            fake_enabled = random.choice((True, False))
            kwargs = {"email": fake_email, "username": fake_username,
                    "uid": fake_uid, "enabled": fake_enabled}
            if isinstance(ident, self.rax_identity_class):
                kwargs["defaultRegion"] = fake_region
            self.assertRaises(exc.AuthorizationFailure, ident.update_user,
                    fake_name, **kwargs)

    def test_delete_user(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "users"
            ident.method_delete = Mock(return_value=(resp, resp.json()))
            fake_name = utils.random_unicode()
            ident.delete_user(fake_name)
            cargs = ident.method_delete.call_args
            self.assertEqual(len(cargs), 2)
            self.assertEqual(cargs[0], ("users/%s" % fake_name, ))

    def test_delete_user_not_found(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "users"
            resp.status_code = 404
            ident.method_delete = Mock(return_value=(resp, resp.json()))
            fake_name = utils.random_unicode()
            self.assertRaises(exc.UserNotFound, ident.delete_user, fake_name)

    def test_delete_user_fail(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "users"
            resp.status_code = 401
            ident.method_delete = Mock(return_value=(resp, resp.json()))
            fake_name = utils.random_unicode()
            self.assertRaises(exc.AuthorizationFailure, ident.delete_user,
                    fake_name)

    def test_list_roles_for_user(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "users"
            resp.status_code = 200
            ident.method_get = Mock(return_value=(resp, resp.json()))
            resp = ident.list_roles_for_user("fake")
            self.assertTrue(isinstance(resp, list))
            role = resp[0]
            self.assertTrue("description" in role)
            self.assertTrue("name" in role)
            self.assertTrue("id" in role)

    def test_list_roles_for_user_fail(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "users"
            resp.status_code = 401
            ident.method_get = Mock(return_value=(resp, resp.json()))
            self.assertRaises(exc.AuthorizationFailure,
                    ident.list_roles_for_user, "fake")

    def test_list_credentials(self):
        ident = self.rax_identity_class()
        resp = fakes.FakeIdentityResponse()
        resp.response_type = "users"
        resp.status_code = 200
        ident.method_get = Mock(return_value=(resp, resp.json()))
        fake_name = utils.random_unicode()
        ident.list_credentials(fake_name)
        cargs = ident.method_get.call_args
        called_uri = cargs[0][0]
        self.assertTrue("/credentials" in called_uri)
        self.assertTrue("users/%s/" % fake_name in called_uri)

    def test_list_credentials_no_user(self):
        ident = self.identity
        ident.user = fakes.FakeEntity()
        resp = fakes.FakeIdentityResponse()
        resp.response_type = "users"
        resp.status_code = 200
        ident.method_get = Mock(return_value=(resp, resp.json()))
        ident.list_credentials()
        cargs = ident.method_get.call_args
        called_uri = cargs[0][0]
        self.assertTrue("/credentials" in called_uri)
        self.assertTrue("users/%s/" % ident.user.id in called_uri)

    def test_get_keystone_endpoint(self):
        ident = self.keystone_identity_class()
        fake_ep = utils.random_unicode()
        sav_setting = pyrax.get_setting
        pyrax.get_setting = Mock(return_value=fake_ep)
        ep = ident._get_auth_endpoint()
        self.assertEqual(ep, fake_ep)
        pyrax.get_setting = sav_setting

    def test_get_keystone_endpoint_fail(self):
        ident = self.keystone_identity_class()
        sav_setting = pyrax.get_setting
        pyrax.get_setting = Mock(return_value=None)
        self.assertRaises(exc.EndpointNotDefined, ident._get_auth_endpoint)

    def test_get_token(self):
        for cls in self.id_classes.values():
            ident = cls()
            ident.token = "test_token"
            sav_valid = ident._has_valid_token
            sav_auth = ident.authenticate
            ident._has_valid_token = Mock(return_value=True)
            ident.authenticate = Mock()
            tok = ident.get_token()
            self.assertEqual(tok, "test_token")
            # Force
            tok = ident.get_token(force=True)
            ident.authenticate.assert_called_with()
            # Invalid token
            ident._has_valid_token = Mock(return_value=False)
            ident.authenticated = False
            tok = ident.get_token()
            ident.authenticate.assert_called_with()
            ident._has_valid_token = sav_valid
            ident.authenticate = sav_auth

    def test_has_valid_token(self):
        savrequest = pyrax.http.request
        pyrax.http.request = Mock(return_value=(fakes.FakeIdentityResponse(),
                fakes.fake_identity_response))
        for cls in self.id_classes.values():
            ident = cls()
            if cls is self.keystone_identity_class:
                # Necessary for testing to avoid NotImplementedError.
                utils.add_method(ident, lambda self: "", "_get_auth_endpoint")
            ident.authenticate()
            valid = ident._has_valid_token()
            self.assertTrue(valid)
            ident.expires = datetime.datetime.now() - datetime.timedelta(1)
            valid = ident._has_valid_token()
            self.assertFalse(valid)
            ident = self._get_clean_identity()
            valid = ident._has_valid_token()
            self.assertFalse(valid)
        pyrax.http.request = savrequest

    def test_list_token(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "tokens"
            ident.method_get = Mock(return_value=(resp, resp.json()))
            tokens = ident.list_tokens()
            ident.method_get.assert_called_with("tokens/%s" % ident.token,
                    admin=True)
            self.assertTrue("token" in tokens)

    def test_list_token_fail(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "tokens"
            resp.status_code = 403
            ident.method_get = Mock(return_value=(resp, resp.json()))
            self.assertRaises(exc.AuthorizationFailure, ident.list_tokens)

    def test_check_token(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "tokens"
            ident.method_head = Mock(return_value=(resp, resp.json()))
            valid = ident.check_token()
            ident.method_head.assert_called_with("tokens/%s" % ident.token,
                    admin=True)
            self.assertTrue(valid)

    def test_check_token_fail_auth(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "tokens"
            resp.status_code = 403
            ident.method_head = Mock(return_value=(resp, resp.json()))
            self.assertRaises(exc.AuthorizationFailure, ident.check_token)

    def test_check_token_fail_valid(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "tokens"
            resp.status_code = 404
            ident.method_head = Mock(return_value=(resp, resp.json()))
            valid = ident.check_token()
            ident.method_head.assert_called_with("tokens/%s" % ident.token,
                    admin=True)
            self.assertFalse(valid)

    def test_revoke_token(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "tokens"
            token = ident.token = utils.random_unicode()
            ident.method_delete = Mock(return_value=(resp, resp.json()))
            valid = ident.revoke_token(token)
            ident.method_delete.assert_called_with("tokens/%s" % ident.token,
                    admin=True)
            self.assertTrue(valid)

    def test_revoke_token_fail(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "tokens"
            resp.status_code = 401
            token = ident.token = utils.random_unicode()
            ident.method_delete = Mock(return_value=(resp, resp.json()))
            self.assertRaises(exc.AuthorizationFailure, ident.revoke_token,
                    token)

    def test_get_token_endpoints(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "endpoints"
            ident.method_get = Mock(return_value=(resp, resp.json()))
            eps = ident.get_token_endpoints()
            self.assertTrue(isinstance(eps, list))
            ident.method_get.assert_called_with("tokens/%s/endpoints" %
                    ident.token, admin=True)

    def test_get_token_endpoints_fail(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "endpoints"
            resp.status_code = 401
            ident.method_get = Mock(return_value=(resp, resp.json()))
            self.assertRaises(exc.AuthorizationFailure,
                    ident.get_token_endpoints)

    def test_reset_api_key(self):
        ident = self.identity
        self.assertRaises(NotImplementedError, ident.reset_api_key)

    def test_reset_api_key_rax(self):
        ident = self.rax_identity_class()
        user = utils.random_unicode()
        nm = utils.random_unicode()
        key = utils.random_unicode()
        resp = fakes.FakeResponse()
        resp_body = {"RAX-KSKEY:apiKeyCredentials": {
                "username": nm, "apiKey": key}}
        ident.method_post = Mock(return_value=(resp, resp_body))
        exp_uri = "users/%s/OS-KSADM/credentials/" % user
        exp_uri += "RAX-KSKEY:apiKeyCredentials/RAX-AUTH/reset"
        ret = ident.reset_api_key(user)
        self.assertEqual(ret, key)
        ident.method_post.assert_called_once_with(exp_uri)

    @patch("pyrax.utils.get_id")
    def test_reset_api_key_rax_no_user(self, mock_get_id):
        ident = self.rax_identity_class()
        user = utils.random_unicode()
        mock_get_id.return_value = user
        ident.authenticated = True
        nm = utils.random_unicode()
        key = utils.random_unicode()
        resp = fakes.FakeResponse()
        resp_body = {"RAX-KSKEY:apiKeyCredentials": {
                "username": nm, "apiKey": key}}
        ident.method_post = Mock(return_value=(resp, resp_body))
        exp_uri = "users/%s/OS-KSADM/credentials/" % user
        exp_uri += "RAX-KSKEY:apiKeyCredentials/RAX-AUTH/reset"
        ret = ident.reset_api_key()
        self.assertEqual(ret, key)
        ident.method_post.assert_called_once_with(exp_uri)

    def test_get_tenant(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "tenants"
            ident.method_get = Mock(return_value=(resp, resp.json()))
            tenant = ident.get_tenant()
            self.assertTrue(isinstance(tenant, base_identity.Tenant))

    def test_get_tenant_none(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "tenants"
            ident._list_tenants = Mock(return_value=[])
            tenant = ident.get_tenant()
            self.assertIsNone(tenant)

    def test_list_tenants(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "tenants"
            ident.method_get = Mock(return_value=(resp, resp.json()))
            tenants = ident.list_tenants()
            self.assertTrue(isinstance(tenants, list))
            are_tenants = [isinstance(itm, base_identity.Tenant)
                    for itm in tenants]
            self.assertTrue(all(are_tenants))

    def test_list_tenants_auth_fail(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "tenants"
            resp.status_code = 403
            ident.method_get = Mock(return_value=(resp, resp.json()))
            self.assertRaises(exc.AuthorizationFailure, ident.list_tenants)

    def test_list_tenants_other_fail(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "tenants"
            resp.status_code = 404
            ident.method_get = Mock(return_value=(resp, resp.json()))
            self.assertRaises(exc.TenantNotFound, ident.list_tenants)

    def test_create_tenant(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "tenant"
            ident.method_post = Mock(return_value=(resp, resp.json()))
            fake_name = utils.random_unicode()
            fake_desc = utils.random_unicode()
            tenant = ident.create_tenant(fake_name, description=fake_desc)
            self.assertTrue(isinstance(tenant, base_identity.Tenant))
            cargs = ident.method_post.call_args
            self.assertEqual(len(cargs), 2)
            self.assertEqual(cargs[0], ("tenants", ))
            data = cargs[1]["data"]["tenant"]
            self.assertEqual(data["name"], fake_name)
            self.assertEqual(data["description"], fake_desc)

    def test_update_tenant(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "tenant"
            ident.method_put = Mock(return_value=(resp, resp.json()))
            fake_id = utils.random_unicode()
            fake_name = utils.random_unicode()
            fake_desc = utils.random_unicode()
            tenant = ident.update_tenant(fake_id, name=fake_name,
                    description=fake_desc)
            self.assertTrue(isinstance(tenant, base_identity.Tenant))
            cargs = ident.method_put.call_args
            self.assertEqual(len(cargs), 2)
            self.assertEqual(cargs[0], ("tenants/%s" % fake_id, ))
            data = cargs[1]["data"]["tenant"]
            self.assertEqual(data["name"], fake_name)
            self.assertEqual(data["description"], fake_desc)

    def test_delete_tenant(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "tenant"
            ident.method_delete = Mock(return_value=(resp, resp.json()))
            fake_id = utils.random_unicode()
            ident.delete_tenant(fake_id)
            ident.method_delete.assert_called_with("tenants/%s" % fake_id)

    def test_delete_tenantfail(self):
        for cls in self.id_classes.values():
            ident = cls()
            resp = fakes.FakeIdentityResponse()
            resp.response_type = "tenant"
            resp.status_code = 404
            ident.method_delete = Mock(return_value=(resp, resp.json()))
            fake_id = utils.random_unicode()
            self.assertRaises(exc.TenantNotFound, ident.delete_tenant, fake_id)

    def test_list_roles(self):
        ident = self.identity
        nm = utils.random_unicode()
        id_ = utils.random_unicode()
        svcid = utils.random_unicode()
        limit = utils.random_unicode()
        marker = utils.random_unicode()
        resp = fakes.FakeResponse()
        resp_body = {"roles": [{"name": nm, "id": id_}]}
        ident.method_get = Mock(return_value=(resp, resp_body))
        exp_uri = "OS-KSADM/roles?serviceId=%s&limit=%s&marker=%s" % (svcid,
                limit, marker)
        ret = ident.list_roles(service_id=svcid, limit=limit, marker=marker)
        ident.method_get.assert_called_once_with(exp_uri)
        self.assertEqual(len(ret), 1)
        role = ret[0]
        self.assertTrue(isinstance(role, base_identity.Role))

    def test_get_role(self):
        ident = self.identity
        role = utils.random_unicode()
        nm = utils.random_unicode()
        id_ = utils.random_unicode()
        resp = fakes.FakeResponse()
        resp_body = {"role": {"name": nm, "id": id_}}
        ident.method_get = Mock(return_value=(resp, resp_body))
        exp_uri = "OS-KSADM/roles/%s" % role
        ret = ident.get_role(role)
        ident.method_get.assert_called_once_with(exp_uri)
        self.assertTrue(isinstance(ret, base_identity.Role))
        self.assertEqual(ret.name, nm)
        self.assertEqual(ret.id, id_)

    def test_add_role_to_user(self):
        ident = self.identity
        role = utils.random_unicode()
        user = utils.random_unicode()
        ident.method_put = Mock(return_value=(None, None))
        exp_uri = "users/%s/roles/OS-KSADM/%s" % (user, role)
        ident.add_role_to_user(role, user)
        ident.method_put.assert_called_once_with(exp_uri)

    def test_delete_role_from_user(self):
        ident = self.identity
        role = utils.random_unicode()
        user = utils.random_unicode()
        ident.method_delete = Mock(return_value=(None, None))
        exp_uri = "users/%s/roles/OS-KSADM/%s" % (user, role)
        ident.delete_role_from_user(role, user)
        ident.method_delete.assert_called_once_with(exp_uri)

    def test_parse_api_time_us(self):
        test_date = "2012-01-02T05:20:30.000-05:00"
        expected = datetime.datetime(2012, 1, 2, 10, 20, 30)
        for cls in self.id_classes.values():
            ident = cls()
            parsed = ident._parse_api_time(test_date)
            self.assertEqual(parsed, expected)

    def test_parse_api_time_uk(self):
        test_date = "2012-01-02T10:20:30.000Z"
        expected = datetime.datetime(2012, 1, 2, 10, 20, 30)
        for cls in self.id_classes.values():
            ident = cls()
            parsed = ident._parse_api_time(test_date)
            self.assertEqual(parsed, expected)


if __name__ == "__main__":
    unittest.main()
#    suite = unittest.TestLoader().loadTestsFromTestCase(IdentityTest)
#    unittest.TextTestRunner(verbosity=2).run(suite)

########NEW FILE########
__FILENAME__ = test_image
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import random
import unittest

from mock import patch
from mock import MagicMock as Mock

import pyrax
from pyrax.manager import BaseManager
import pyrax.image
from pyrax.image import assure_image
from pyrax.image import ImageMember
from pyrax.image import ImageTasksManager
from pyrax.image import JSONSchemaManager

import pyrax.exceptions as exc
import pyrax.utils as utils

from pyrax import fakes


class ImageTest(unittest.TestCase):
    def __init__(self, *args, **kwargs):
        super(ImageTest, self).__init__(*args, **kwargs)

    def setUp(self):
        self.identity = fakes.FakeIdentity()
        self.client = fakes.FakeImageClient(self.identity)
        self.client._manager = fakes.FakeImageManager(self.client)
        self.image = fakes.FakeImage()
        super(ImageTest, self).setUp()

    def tearDown(self):
        super(ImageTest, self).tearDown()

    def test_assure_image(self):
        class TestClient(object):
            _manager = fakes.FakeManager()

            @assure_image
            def test_method(self, img):
                return img

        client = TestClient()
        client._manager.get = Mock(return_value=self.image)
        # Pass the image
        ret = client.test_method(self.image)
        self.assertTrue(ret is self.image)
        # Pass the ID
        ret = client.test_method(self.image.id)
        self.assertTrue(ret is self.image)

    def test_img_update(self):
        img = self.image
        key = utils.random_unicode()
        val = utils.random_unicode()
        img.manager.update = Mock()
        img.update({key: val})
        img.manager.update.assert_called_once_with(img, {key: val})

    def test_img_change_name(self):
        img = self.image
        nm = utils.random_unicode()
        img.update = Mock()
        img.change_name(nm)
        img.update.assert_called_once_with({"name": nm})

    def test_img_list_members(self):
        img = self.image
        img._member_manager.list = Mock()
        img.list_members()
        img._member_manager.list.assert_called_once_with()

    def test_img_get_member(self):
        img = self.image
        member = utils.random_unicode()
        img._member_manager.get = Mock()
        img.get_member(member)
        img._member_manager.get.assert_called_once_with(member)

    def test_img_create_member(self):
        img = self.image
        project_id = utils.random_unicode()
        img._member_manager.create = Mock()
        img.add_member(project_id)
        img._member_manager.create.assert_called_once_with(name=None,
                project_id=project_id)

    def test_img_delete_member(self):
        img = self.image
        project_id = utils.random_unicode()
        img._member_manager.delete = Mock()
        img.delete_member(project_id)
        img._member_manager.delete.assert_called_once_with(project_id)

    def test_img_add_tag(self):
        img = self.image
        tag = utils.random_unicode()
        img._tag_manager.add = Mock()
        img.add_tag(tag)
        img._tag_manager.add.assert_called_once_with(tag)

    def test_img_delete_tag(self):
        img = self.image
        tag = utils.random_unicode()
        img._tag_manager.delete = Mock()
        img.delete_tag(tag)
        img._tag_manager.delete.assert_called_once_with(tag)

    def test_member_id(self):
        mid = utils.random_unicode()
        member = ImageMember(self.client._manager, {"member_id": mid})
        self.assertEqual(member.id, mid)

    def test_imgmgr_create_body(self):
        clt = self.client
        mgr = clt._manager
        nm = utils.random_unicode()
        meta = utils.random_unicode()
        body = mgr._create_body(nm, metadata=meta)
        self.assertEqual(body, {"metadata": meta})

    def test_imgmgr_create_body_empty(self):
        clt = self.client
        mgr = clt._manager
        nm = utils.random_unicode()
        body = mgr._create_body(nm)
        self.assertEqual(body, {})

    def test_imgmgr_list(self):
        clt = self.client
        mgr = clt._manager
        limit = utils.random_unicode()
        marker = utils.random_unicode()
        name = utils.random_unicode()
        visibility = utils.random_unicode()
        member_status = utils.random_unicode()
        owner = utils.random_unicode()
        tag = utils.random_unicode()
        status = utils.random_unicode()
        size_min = utils.random_unicode()
        size_max = utils.random_unicode()
        sort_key = utils.random_unicode()
        sort_dir = utils.random_unicode()
        return_raw = utils.random_unicode()
        qs = utils.random_unicode()
        mgr._list = Mock()
        sav = utils.dict_to_qs
        utils.dict_to_qs = Mock(return_value=qs)
        expected = "/%s?%s" % (mgr.uri_base, qs)
        mgr.list(limit=limit, marker=marker, name=name, visibility=visibility,
                member_status=member_status, owner=owner, tag=tag,
                status=status, size_min=size_min, size_max=size_max,
                sort_key=sort_key, sort_dir=sort_dir, return_raw=return_raw)
        mgr._list.assert_called_once_with(expected, return_raw=return_raw)
        utils.dict_to_qs = sav

    def test_imgmgr_list_all(self):
        clt = self.client
        mgr = clt._manager
        next_link = "/images?marker=00000000-0000-0000-0000-0000000000"
        fake_body = {"images": [{"name": "fake1"}], "next": "/v2%s" % next_link}
        mgr.list = Mock(return_value=(None, fake_body))
        fake_last_body = {"images": [{"name": "fake2"}], "next": ""}
        mgr.api.method_get = Mock(return_value=(None, fake_last_body))
        ret = mgr.list_all()
        self.assertEqual(len(ret), 2)
        mgr.list.assert_called_once_with(name=None, visibility=None,
                member_status=None, owner=None, tag=None, status=None,
                size_min=None, size_max=None, sort_key=None, sort_dir=None,
                return_raw=True)
        mgr.api.method_get.assert_called_once_with(next_link)

    def test_imgmgr_update(self):
        clt = self.client
        mgr = clt._manager
        img = self.image
        setattr(img, "foo", "old")
        valdict = {"foo": "new", "bar": "new"}
        mgr.api.method_patch = Mock(return_value=(None, None))
        mgr.get = Mock(return_value=img)
        exp_uri = "/%s/%s" % (mgr.uri_base, img.id)
        exp_body = [{"op": "replace", "path": "/foo", "value": "new"},
                {"op": "add", "path": "/bar", "value": "new"}]
        exp_hdrs = {"Content-Type":
                "application/openstack-images-v2.1-json-patch"}
        mgr.update(img, valdict)
        mgr.api.method_patch.assert_called_once_with(exp_uri, body=exp_body,
                headers=exp_hdrs)

    def test_imgmgr_update_member(self):
        clt = self.client
        mgr = clt._manager
        img = self.image
        status = random.choice(("pending", "accepted", "rejected"))
        project_id = utils.random_unicode()
        clt.identity.tenant_id = project_id
        exp_uri = "/%s/%s/members/%s" % (mgr.uri_base, img.id, project_id)
        exp_body = {"status": status}
        mgr.api.method_put = Mock(return_value=(None, None))
        mgr.update_image_member(img.id, status)
        mgr.api.method_put.assert_called_once_with(exp_uri, body=exp_body)

    def test_imgmgr_update_member_bad(self):
        clt = self.client
        mgr = clt._manager
        img = self.image
        bad_status = "BAD"
        self.assertRaises(exc.InvalidImageMemberStatus, mgr.update_image_member,
                img.id, bad_status)

    def test_imgmgr_update_member_not_found(self):
        clt = self.client
        mgr = clt._manager
        img = self.image
        status = random.choice(("pending", "accepted", "rejected"))
        project_id = utils.random_unicode()
        clt.identity.tenant_id = project_id
        exp_uri = "/%s/%s/members/%s" % (mgr.uri_base, img.id, project_id)
        exp_body = {"status": status}
        mgr.api.method_put = Mock(side_effect=exc.NotFound(""))
        self.assertRaises(exc.InvalidImageMember, mgr.update_image_member,
                img.id, status)

    def test_img_member_mgr_create_body(self):
        img = self.image
        mgr = img._member_manager
        nm = utils.random_unicode()
        project_id = utils.random_unicode()
        ret = mgr._create_body(nm, project_id)
        self.assertEqual(ret, {"member": project_id})

    def test_img_member_mgr_create(self):
        img = self.image
        mgr = img._member_manager
        nm = utils.random_unicode()
        val = utils.random_unicode()
        sav = BaseManager.create
        BaseManager.create = Mock(return_value=val)
        ret = mgr.create(nm)
        self.assertEqual(ret, val)
        BaseManager.create = sav

    def test_img_member_mgr_create_403(self):
        img = self.image
        mgr = img._member_manager
        nm = utils.random_unicode()
        sav = BaseManager.create
        err = exc.Forbidden(403)
        BaseManager.create = Mock(side_effect=err)
        self.assertRaises(exc.UnsharableImage, mgr.create, nm)
        BaseManager.create = sav

    def test_img_member_mgr_create_other(self):
        img = self.image
        mgr = img._member_manager
        nm = utils.random_unicode()
        sav = BaseManager.create
        err = exc.OverLimit(413)
        BaseManager.create = Mock(side_effect=err)
        self.assertRaises(exc.OverLimit, mgr.create, nm)
        BaseManager.create = sav

    def test_img_tag_mgr_create(self):
        img = self.image
        mgr = img._tag_manager
        nm = utils.random_unicode()
        ret = mgr._create_body(nm)
        self.assertEqual(ret, {})

    def test_img_tag_mgr_add(self):
        img = self.image
        mgr = img._tag_manager
        tag = utils.random_unicode()
        exp_uri = "/%s/%s" % (mgr.uri_base, tag)
        mgr.api.method_put = Mock(return_value=(None, None))
        mgr.add(tag)
        mgr.api.method_put.assert_called_once_with(exp_uri)

    def test_img_tasks_mgr_create_export(self):
        clt = self.client
        mgr = clt._tasks_manager
        img = self.image
        cont = utils.random_unicode()
        img_format = utils.random_unicode()
        img_name = utils.random_unicode()
        name = "export"
        ret = mgr._create_body(name, img=img, cont=cont, img_format=img_format,
                img_name=img_name)
        exp = {"type": name, "input": {
                "image_uuid": img.id,
                "receiving_swift_container": cont}}
        self.assertEqual(ret, exp)

    def test_img_tasks_mgr_create_import(self):
        clt = self.client
        mgr = clt._tasks_manager
        img = self.image
        cont = utils.random_unicode()
        img_format = utils.random_unicode()
        img_name = utils.random_unicode()
        name = "import"
        ret = mgr._create_body(name, img=img, cont=cont, img_format=img_format,
                img_name=img_name)
        exp = {"type": name, "input": {
                "image_properties": {"name": img_name},
                "import_from": "%s/%s" % (cont, img.id),
                "import_from_format": img_format}}
        self.assertEqual(ret, exp)

    @patch("pyrax.manager.BaseManager.create")
    def test_img_tasks_mgr_create(self, mock_create):
        clt = self.client
        mgr = clt._tasks_manager
        nm = utils.random_unicode()
        cont = utils.random_unicode()

        class FakeCF(object):
            def get_container(self, cont):
                return cont

        class FakeRegion(object):
            client = FakeCF()

        api = mgr.api
        rgn = api.region_name
        api.identity.object_store = {rgn: FakeRegion()}
        mgr.create(nm, cont=cont)
        mock_create.assert_called_once_with(nm, cont=cont)

    def test_jsonscheme_mgr(self):
        mgr = JSONSchemaManager(self.client)
        nm = utils.random_unicode()
        ret = mgr._create_body(nm)
        self.assertIsNone(ret)

    def test_jsonscheme_mgr_images(self):
        mgr = JSONSchemaManager(self.client)
        mgr.api.method_get = Mock(return_value=(None, None))
        exp_uri = "/%s/images" % mgr.uri_base
        mgr.images()
        mgr.api.method_get.assert_called_once_with(exp_uri)

    def test_jsonscheme_mgr_image(self):
        mgr = JSONSchemaManager(self.client)
        mgr.api.method_get = Mock(return_value=(None, None))
        exp_uri = "/%s/image" % mgr.uri_base
        mgr.image()
        mgr.api.method_get.assert_called_once_with(exp_uri)

    def test_jsonscheme_mgr_members(self):
        mgr = JSONSchemaManager(self.client)
        mgr.api.method_get = Mock(return_value=(None, None))
        exp_uri = "/%s/members" % mgr.uri_base
        mgr.image_members()
        mgr.api.method_get.assert_called_once_with(exp_uri)

    def test_jsonscheme_mgr_member(self):
        mgr = JSONSchemaManager(self.client)
        mgr.api.method_get = Mock(return_value=(None, None))
        exp_uri = "/%s/member" % mgr.uri_base
        mgr.image_member()
        mgr.api.method_get.assert_called_once_with(exp_uri)

    def test_jsonscheme_mgr_tasks(self):
        mgr = JSONSchemaManager(self.client)
        mgr.api.method_get = Mock(return_value=(None, None))
        exp_uri = "/%s/tasks" % mgr.uri_base
        mgr.image_tasks()
        mgr.api.method_get.assert_called_once_with(exp_uri)

    def test_jsonscheme_mgr_task(self):
        mgr = JSONSchemaManager(self.client)
        mgr.api.method_get = Mock(return_value=(None, None))
        exp_uri = "/%s/task" % mgr.uri_base
        mgr.image_task()
        mgr.api.method_get.assert_called_once_with(exp_uri)

    def test_clt_list(self):
        clt = self.client
        mgr = clt._manager
        limit = utils.random_unicode()
        marker = utils.random_unicode()
        name = utils.random_unicode()
        visibility = utils.random_unicode()
        member_status = utils.random_unicode()
        owner = utils.random_unicode()
        tag = utils.random_unicode()
        status = utils.random_unicode()
        size_min = utils.random_unicode()
        size_max = utils.random_unicode()
        sort_key = utils.random_unicode()
        sort_dir = utils.random_unicode()
        mgr.list = Mock()
        clt.list(limit=limit, marker=marker, name=name, visibility=visibility,
                member_status=member_status, owner=owner, tag=tag,
                status=status, size_min=size_min, size_max=size_max,
                sort_key=sort_key, sort_dir=sort_dir)
        mgr.list.assert_called_once_with(limit=limit, marker=marker, name=name,
                visibility=visibility, member_status=member_status,
                owner=owner, tag=tag, status=status, size_min=size_min,
                size_max=size_max, sort_key=sort_key, sort_dir=sort_dir)

    def test_clt_list_all(self):
        clt = self.client
        mgr = clt._manager
        mgr.list_all = Mock()
        clt.list_all()
        mgr.list_all.assert_called_once_with(name=None, visibility=None,
                member_status=None, owner=None, tag=None, status=None,
                size_min=None, size_max=None, sort_key=None, sort_dir=None)

    def test_clt_update(self):
        clt = self.client
        mgr = clt._manager
        img = self.image
        key = utils.random_unicode()
        val = utils.random_unicode()
        upd = {key: val}
        mgr.update = Mock()
        clt.update(img, upd)
        mgr.update.assert_called_once_with(img, upd)

    def test_clt_change_image_name(self):
        clt = self.client
        mgr = clt._manager
        img = self.image
        nm = utils.random_unicode()
        clt.update = Mock()
        clt.change_image_name(img, nm)
        clt.update.assert_called_once_with(img, {"name": nm})

    def test_clt_list_image_members(self):
        clt = self.client
        img = self.image
        img.list_members = Mock()
        clt.list_image_members(img)
        img.list_members.assert_called_once_with()

    def test_clt_get_image_member(self):
        clt = self.client
        img = self.image
        member = utils.random_unicode()
        img.get_member = Mock()
        clt.get_image_member(img, member)
        img.get_member.assert_called_once_with(member)

    def test_clt_add_image_member(self):
        clt = self.client
        img = self.image
        project_id = utils.random_unicode()
        img.add_member = Mock()
        clt.add_image_member(img, project_id)
        img.add_member.assert_called_once_with(project_id)

    def test_clt_delete_image_member(self):
        clt = self.client
        img = self.image
        project_id = utils.random_unicode()
        img.delete_member = Mock()
        clt.delete_image_member(img, project_id)
        img.delete_member.assert_called_once_with(project_id)

    def test_clt_update_img_member(self):
        clt = self.client
        mgr = clt._manager
        img = self.image
        status = utils.random_unicode()
        mgr.update_image_member = Mock()
        clt.update_image_member(img, status)
        mgr.update_image_member.assert_called_once_with(img, status)

    def test_clt_add_image_tag(self):
        clt = self.client
        img = self.image
        tag = utils.random_unicode()
        img.add_tag = Mock()
        clt.add_image_tag(img, tag)
        img.add_tag.assert_called_once_with(tag)

    def test_clt_delete_image_tag(self):
        clt = self.client
        img = self.image
        tag = utils.random_unicode()
        img.delete_tag = Mock()
        clt.delete_image_tag(img, tag)
        img.delete_tag.assert_called_once_with(tag)

    def test_clt_list_tasks(self):
        clt = self.client
        mgr = clt._tasks_manager
        mgr.list = Mock()
        clt.list_tasks()
        mgr.list.assert_called_once_with()

    def test_clt_get_task(self):
        clt = self.client
        mgr = clt._tasks_manager
        task = utils.random_unicode()
        mgr.get = Mock()
        clt.get_task(task)
        mgr.get.assert_called_once_with(task)

    def test_clt_export_task(self):
        clt = self.client
        mgr = clt._tasks_manager
        img = self.image
        cont = utils.random_unicode()
        mgr.create = Mock()
        clt.export_task(img, cont)
        mgr.create.assert_called_once_with("export", img=img, cont=cont)

    def test_clt_import_task(self):
        clt = self.client
        mgr = clt._tasks_manager
        img = self.image
        cont = utils.random_unicode()
        img_format = utils.random_unicode()
        img_name = utils.random_unicode()
        mgr.create = Mock()
        clt.import_task(img, cont, img_format=img_format, img_name=img_name)
        mgr.create.assert_called_once_with("import", img=img, cont=cont,
                img_format=img_format, img_name=img_name)

    def test_clt_get_images_schema(self):
        clt = self.client
        mgr = clt._schema_manager
        mgr.images = Mock()
        clt.get_images_schema()
        mgr.images.assert_called_once_with()

    def test_clt_get_image_schema(self):
        clt = self.client
        mgr = clt._schema_manager
        mgr.image = Mock()
        clt.get_image_schema()
        mgr.image.assert_called_once_with()

    def test_clt_get_image_members_schema(self):
        clt = self.client
        mgr = clt._schema_manager
        mgr.image_members = Mock()
        clt.get_image_members_schema()
        mgr.image_members.assert_called_once_with()

    def test_clt_get_image_member_schema(self):
        clt = self.client
        mgr = clt._schema_manager
        mgr.image_member = Mock()
        clt.get_image_member_schema()
        mgr.image_member.assert_called_once_with()

    def test_clt_get_image_tasks_schema(self):
        clt = self.client
        mgr = clt._schema_manager
        mgr.image_tasks = Mock()
        clt.get_image_tasks_schema()
        mgr.image_tasks.assert_called_once_with()

    def test_clt_get_image_task_schema(self):
        clt = self.client
        mgr = clt._schema_manager
        mgr.image_task = Mock()
        clt.get_image_task_schema()
        mgr.image_task.assert_called_once_with()





if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_manager
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import random
import unittest

from mock import MagicMock as Mock

import pyrax.exceptions as exc
from pyrax import manager
import pyrax.utils as utils

from pyrax import fakes

fake_url = "http://example.com"


class ManagerTest(unittest.TestCase):
    def __init__(self, *args, **kwargs):
        super(ManagerTest, self).__init__(*args, **kwargs)

    def setUp(self):
        self.fake_api = fakes.FakeClient()
        self.manager = manager.BaseManager(self.fake_api)

    def tearDown(self):
        self.manager = None
        self.fake_api = None

    def test_list(self):
        mgr = self.manager
        mgr._list = Mock()
        mgr.uri_base = "test"
        mgr.list()
        mgr._list.assert_called_once_with("/test", return_raw=False)

    def test_under_list_return_raw(self):
        mgr = self.manager
        uri = utils.random_unicode()
        resp = utils.random_unicode()
        resp_body = utils.random_unicode()
        mgr.api.method_get = Mock(return_value=(resp, resp_body))
        ret = mgr._list(uri, return_raw=True)
        mgr.api.method_get.assert_called_once_with(uri)
        self.assertEqual(ret, (resp, resp_body))

    def test_list_paged(self):
        mgr = self.manager
        mgr._list = Mock()
        mgr.uri_base = "test"
        fake_limit = random.randint(10, 20)
        fake_marker = random.randint(100, 200)
        mgr.list(limit=fake_limit, marker=fake_marker)
        expected_uri = "/test?limit=%s&marker=%s" % (fake_limit, fake_marker)
        mgr._list.assert_called_once_with(expected_uri, return_raw=False)

    def test_head(self):
        mgr = self.manager
        mgr._head = Mock()
        mgr.uri_base = "test"
        x = fakes.FakeException()
        x.id = "fakeid"
        mgr.head(x)
        expected = "/%s/%s" % ("test", x.id)
        mgr._head.assert_called_once_with(expected)

    def test_under_head(self):
        mgr = self.manager
        uri = utils.random_unicode()
        resp = utils.random_unicode()
        resp_body = utils.random_unicode()
        mgr.api.method_head = Mock(return_value=(resp, resp_body))
        ret = mgr._head(uri)
        mgr.api.method_head.assert_called_once_with(uri)
        self.assertEqual(ret, resp)

    def test_get(self):
        mgr = self.manager
        mgr._get = Mock()
        mgr.uri_base = "test"
        x = fakes.FakeException()
        x.id = "fakeid"
        mgr.get(x)
        expected = "/%s/%s" % ("test", x.id)
        mgr._get.assert_called_once_with(expected)

    def test_api_get(self):
        mgr = self.manager
        mgr.resource_class = fakes.FakeEntity
        mgr.response_key = "fake"
        mgr.api.method_get = Mock(return_value=(None, {"fake": ""}))
        resp = mgr._get(fake_url)
        self.assert_(isinstance(resp, fakes.FakeEntity))

    def test_create(self):
        mgr = self.manager
        mgr._create = Mock()
        mgr.uri_base = "test"
        mgr._create_body = Mock(return_value="body")
        nm = utils.random_unicode()
        mgr.create(nm)
        mgr._create.assert_called_once_with("/test", "body", return_none=False,
                return_raw=False, return_response=False)

    def test_delete(self):
        mgr = self.manager
        mgr._delete = Mock()
        mgr.uri_base = "test"
        x = fakes.FakeException()
        x.id = "fakeid"
        mgr.delete(x)
        expected = "/%s/%s" % ("test", x.id)
        mgr._delete.assert_called_once_with(expected)

    def test_under_list_post(self):
        mgr = self.manager
        resp = fakes.FakeResponse()
        body = {"fakes": {"foo": "bar"}}
        mgr.api.method_post = Mock(return_value=(resp, body))
        mgr.plural_response_key = "fakes"
        mgr.resource_class = fakes.FakeEntity
        ret = mgr._list(fake_url, body="test")
        mgr.api.method_post.assert_called_once_with(fake_url, body="test")
        self.assertTrue(isinstance(ret, list))
        self.assertEqual(len(ret), 1)
        self.assertTrue(isinstance(ret[0], fakes.FakeEntity))

    def test_under_list_get(self):
        mgr = self.manager
        resp = object()
        body = {"fakes": {"foo": "bar"}}
        mgr.api.method_get = Mock(return_value=(resp, body))
        mgr.plural_response_key = "fakes"
        mgr.resource_class = fakes.FakeEntity
        ret = mgr._list(fake_url)
        mgr.api.method_get.assert_called_once_with(fake_url)
        self.assertTrue(isinstance(ret, list))
        self.assertEqual(len(ret), 1)
        self.assertTrue(isinstance(ret[0], fakes.FakeEntity))

    def test_under_create_return_none(self):
        mgr = self.manager
        mgr.run_hooks = Mock()
        mgr.api.method_post = Mock()
        resp = fakes.FakeResponse()
        body = None
        mgr.api.method_post = Mock(return_value=(resp, body))
        ret = mgr._create(fake_url, "", return_none=True, return_raw=False)
        self.assertIsNone(ret)
        mgr.api.method_post.assert_called_once_with(fake_url, body="")

    def test_under_create_return_raw(self):
        mgr = self.manager
        mgr.run_hooks = Mock()
        mgr.api.method_post = Mock()
        resp = object()
        body = {"fakes": {"foo": "bar"}}
        mgr.api.method_post = Mock(return_value=(resp, body))
        mgr.response_key = "fakes"
        ret = mgr._create(fake_url, "", return_none=False, return_raw=True)
        self.assertEqual(ret, body["fakes"])
        mgr.api.method_post.assert_called_once_with(fake_url, body="")

    def test_under_create_return_resource(self):
        mgr = self.manager
        mgr.run_hooks = Mock()
        mgr.api.method_post = Mock()
        resp = fakes.FakeResponse()
        body = {"fakes": {"foo": "bar"}}
        mgr.api.method_post = Mock(return_value=(resp, body))
        mgr.resource_class = fakes.FakeEntity
        mgr.response_key = "fakes"
        ret = mgr._create(fake_url, "", return_none=False, return_raw=False)
        self.assertTrue(isinstance(ret, fakes.FakeEntity))
        mgr.api.method_post.assert_called_once_with(fake_url, body="")

    def test_under_delete(self):
        mgr = self.manager
        mgr.api.method_delete = Mock(return_value=("resp", "body"))
        mgr._delete(fake_url)
        mgr.api.method_delete.assert_called_once_with(fake_url)

    def test_under_update(self):
        mgr = self.manager
        mgr.run_hooks = Mock()
        mgr.api.method_put = Mock()
        resp = fakes.FakeResponse()
        body = {"fakes": {"foo": "bar"}}
        mgr.api.method_put = Mock(return_value=(resp, body))
        mgr.resource_class = fakes.FakeEntity
        mgr.response_key = "fakes"
        ret = mgr._update(fake_url, "")
        mgr.api.method_put.assert_called_once_with(fake_url, body="")
        self.assertEqual(ret, body)

    def test_action(self):
        mgr = self.manager
        mgr.uri_base = "testing"
        mgr.api.method_post = Mock()
        item = fakes.FakeEntity()
        mgr.action(item, "fake")
        mgr.api.method_post.assert_called_once_with("/testing/%s/action" %
                item.id, body={"fake": {}})

    def test_find_no_match(self):
        mgr = self.manager
        mgr.findall = Mock(return_value=[])
        mgr.resource_class = fakes.FakeEntity
        self.assertRaises(exc.NotFound, mgr.find)

    def test_find_mult_match(self):
        mgr = self.manager
        mtch = fakes.FakeEntity()
        mgr.resource_class = fakes.FakeEntity
        mgr.findall = Mock(return_value=[mtch, mtch])
        self.assertRaises(exc.NoUniqueMatch, mgr.find)

    def test_find_single_match(self):
        mgr = self.manager
        mtch = fakes.FakeEntity()
        mgr.resource_class = fakes.FakeEntity
        mgr.findall = Mock(return_value=[mtch])
        ret = mgr.find()
        self.assertEqual(ret, mtch)

    def test_findall(self):
        mgr = self.manager
        o1 = fakes.FakeEntity()
        o1.some_att = "ok"
        o2 = fakes.FakeEntity()
        o2.some_att = "bad"
        o3 = fakes.FakeEntity()
        o3.some_att = "ok"
        mgr.list = Mock(return_value=[o1, o2, o3])
        ret = mgr.findall(some_att="ok")
        self.assertTrue(o1 in ret)
        self.assertFalse(o2 in ret)
        self.assertTrue(o3 in ret)

    def test_findall_bad_att(self):
        mgr = self.manager
        o1 = fakes.FakeEntity()
        o1.some_att = "ok"
        o2 = fakes.FakeEntity()
        o2.some_att = "bad"
        o3 = fakes.FakeEntity()
        o3.some_att = "ok"
        mgr.list = Mock(return_value=[o1, o2, o3])
        ret = mgr.findall(some_att="ok", bad_att="oops")
        self.assertFalse(o1 in ret)
        self.assertFalse(o2 in ret)
        self.assertFalse(o3 in ret)

    def test_add_hook(self):
        mgr = self.manager
        tfunc = Mock()
        mgr.add_hook("test", tfunc)
        self.assertTrue("test" in mgr._hooks_map)
        self.assertTrue(tfunc in mgr._hooks_map["test"])

    def test_run_hooks(self):
        mgr = self.manager
        tfunc = Mock()
        mgr.add_hook("test", tfunc)
        mgr.run_hooks("test", "dummy_arg")
        tfunc.assert_called_once_with("dummy_arg")



if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_module
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import json
import os
import unittest
import warnings

from mock import patch
from mock import MagicMock as Mock

import pyrax
import pyrax.exceptions as exc
import pyrax.utils as utils
from pyrax import fakes



class PyraxInitTest(unittest.TestCase):
    def __init__(self, *args, **kwargs):
        reload(pyrax)
        self.orig_connect_to_cloudservers = pyrax.connect_to_cloudservers
        self.orig_connect_to_cloudfiles = pyrax.connect_to_cloudfiles
        ctclb = pyrax.connect_to_cloud_loadbalancers
        self.orig_connect_to_cloud_loadbalancers = ctclb
        self.orig_connect_to_cloud_databases = pyrax.connect_to_cloud_databases
        self.orig_get_service_endpoint = pyrax._get_service_endpoint
        super(PyraxInitTest, self).__init__(*args, **kwargs)
        self.username = "fakeuser"
        self.password = "fakeapikey"
        self.tenant_id = "faketenantid"

    def setUp(self):
        vers = pyrax.version.version
        pyrax.settings._settings = {
                "default": {
                    "auth_endpoint": "DEFAULT_AUTH",
                    "region": "DFW",
                    "encoding": "utf-8",
                    "http_debug": False,
                    "identity_class": pyrax.rax_identity.RaxIdentity,
                    "identity_type": "rax_identity.RaxIdentity",
                    "keyring_username": "fakeuser",
                    "tenant_id": None,
                    "tenant_name": None,
                    "user_agent": "pyrax/%s" % vers,
                    "use_servicenet": False,
                    "verify_ssl": False,
                },
                "alternate": {
                    "auth_endpoint": "ALT_AUTH",
                    "region": "NOWHERE",
                    "encoding": "utf-8",
                    "http_debug": False,
                    "identity_class": pyrax.keystone_identity.KeystoneIdentity,
                    "identity_type": "keystone_identity.KeystoneIdentity",
                    "keyring_username": "fakeuser",
                    "tenant_id": None,
                    "tenant_name": None,
                    "user_agent": "pyrax/%s" % vers,
                    "use_servicenet": False,
                    "verify_ssl": False,
                }}
        pyrax.identity = fakes.FakeIdentity()
        pyrax.identity.authenticated = True
        pyrax.connect_to_cloudservers = Mock()
        pyrax.connect_to_cloudfiles = Mock()
        pyrax.connect_to_cloud_loadbalancers = Mock()
        pyrax.connect_to_cloud_databases = Mock()
        pyrax._get_service_endpoint = Mock(return_value="http://example.com/")
        pyrax.USER_AGENT = "DUMMY"

    def tearDown(self):
        pyrax.connect_to_cloudservers = self.orig_connect_to_cloudservers
        pyrax.connect_to_cloudfiles = self.orig_connect_to_cloudfiles
        octclb = self.orig_connect_to_cloud_loadbalancers
        pyrax.connect_to_cloud_loadbalancers = octclb
        pyrax.connect_to_cloud_databases = self.orig_connect_to_cloud_databases
        pyrax._get_service_endpoint = self.orig_get_service_endpoint

    def test_require_auth(self):

        @pyrax._require_auth
        def testfunc():
            pass

        pyrax.identity.authenticated = True
        testfunc()
        pyrax.identity.authenticated = False
        self.assertRaises(exc.NotAuthenticated, testfunc)

    def test_import_identity(self):
        sav = pyrax.utils.import_class
        cls = utils.random_unicode()
        pyrax.utils.import_class = Mock(return_value=cls)
        ret = pyrax._import_identity(cls)
        self.assertEqual(ret, cls)
        pyrax.utils.import_class = sav

    def test_import_identity_external(self):
        sav = pyrax.utils.import_class
        cls = utils.random_unicode()

        def fake_import(nm):
            if "pyrax.identity." in nm:
                raise ImportError()
            else:
                return nm

        pyrax.utils.import_class = fake_import
        ret = pyrax._import_identity(cls)
        self.assertEqual(ret, cls)
        pyrax.utils.import_class = sav

    def test_create_context(self):
        sav = pyrax._create_identity
        pyrax._create_identity = Mock()
        id_type = utils.random_unicode()
        username = utils.random_unicode()
        password = utils.random_unicode()
        tenant_id = utils.random_unicode()
        tenant_name = utils.random_unicode()
        api_key = utils.random_unicode()
        verify_ssl = utils.random_unicode()
        pyrax.create_context(id_type=id_type, username=username,
                password=password, tenant_id=tenant_id,
                tenant_name=tenant_name, api_key=api_key,
                verify_ssl=verify_ssl)
        pyrax._create_identity.assert_called_once_with(id_type=id_type,
                username=username, password=password, tenant_id=tenant_id,
                tenant_name=tenant_name, api_key=api_key,
                verify_ssl=verify_ssl, return_context=True)
        pyrax._create_identity = sav

    def test_settings_get(self):
        def_ep = pyrax.get_setting("auth_endpoint", "default")
        alt_ep = pyrax.get_setting("auth_endpoint", "alternate")
        self.assertEqual(def_ep, "DEFAULT_AUTH")
        self.assertEqual(alt_ep, "ALT_AUTH")

    def test_settings_get_from_env(self):
        pyrax.settings._settings = {"default": {}}
        pyrax.settings.env_dct = {"identity_type": "fake"}
        typ = utils.random_unicode()
        ident = utils.random_unicode()
        sav_env = os.environ
        sav_imp = pyrax._import_identity
        pyrax._import_identity = Mock(return_value=ident)
        os.environ = {"fake": typ}
        ret = pyrax.get_setting("identity_class")
        pyrax._import_identity = sav_imp
        os.environ = sav_env

    def test_settings_set_bad_env(self):
        key = utils.random_unicode()
        val = utils.random_unicode()
        self.assertRaises(exc.EnvironmentNotFound, pyrax.settings.set, key,
                val, "bad_env")

    def test_settings_set_bad_key(self):
        key = utils.random_unicode()
        val = utils.random_unicode()
        self.assertRaises(exc.InvalidSetting, pyrax.settings.set, key, val)

    def test_settings_set_region(self):
        key = "region"
        val = utils.random_unicode()
        pyrax.settings.set(key, val)
        self.assertEqual(pyrax.get_setting(key), val)

    def test_settings_set_region_no_identity(self):
        key = "region"
        val = utils.random_unicode()
        sav = pyrax.identity
        pyrax.identity = None
        ret = pyrax.settings.set(key, val)
        self.assertIsNone(ret)
        pyrax.identity = sav

    def test_settings_set_verify_ssl(self):
        key = "verify_ssl"
        val = utils.random_unicode()
        pyrax.settings.set(key, val)
        self.assertEqual(pyrax.get_setting(key), val)

    def test_settings_set_verify_ssl_no_identity(self):
        key = "verify_ssl"
        val = utils.random_unicode()
        sav = pyrax.identity
        pyrax.identity = None
        ret = pyrax.settings.set(key, val)
        self.assertIsNone(ret)
        pyrax.identity = sav

    def test_read_config(self):
        dummy_cfg = fakes.fake_config_file
        sav_region = pyrax.default_region
        sav_USER_AGENT = pyrax.USER_AGENT
        with utils.SelfDeletingTempfile() as cfgfile:
            with open(cfgfile, "w") as cfg:
                cfg.write(dummy_cfg)
            pyrax.settings.read_config(cfgfile)
        self.assertEqual(pyrax.get_setting("region"), "FAKE")
        self.assertTrue(pyrax.get_setting("user_agent").startswith("FAKE "))
        pyrax.default_region = sav_region
        pyrax.USER_AGENT = sav_USER_AGENT

    def test_read_config_creds(self):
        dummy_cfg = fakes.fake_config_file
        sav_region = pyrax.default_region
        sav_USER_AGENT = pyrax.USER_AGENT
        with utils.SelfDeletingTempfile() as cfgfile:
            with open(cfgfile, "w") as cfg:
                cfg.write(dummy_cfg)
                # Add password entry
                cfg.write("password = fake\n")
            with warnings.catch_warnings(record=True) as warn:
                pyrax.settings.read_config(cfgfile)
                self.assertEqual(len(warn), 1)
        pyrax.default_region = sav_region
        pyrax.USER_AGENT = sav_USER_AGENT

    def test_read_config_bad(self):
        sav_region = pyrax.default_region
        dummy_cfg = fakes.fake_config_file
        # Test invalid setting
        dummy_cfg = dummy_cfg.replace("custom_user_agent", "fake")
        sav_USER_AGENT = pyrax.USER_AGENT
        with utils.SelfDeletingTempfile() as cfgfile:
            with open(cfgfile, "w") as cfg:
                cfg.write(dummy_cfg)
            pyrax.settings.read_config(cfgfile)
        self.assertEqual(pyrax.USER_AGENT, sav_USER_AGENT)
        # Test bad file
        with utils.SelfDeletingTempfile() as cfgfile:
            with open(cfgfile, "w") as cfg:
                cfg.write("FAKE")
            self.assertRaises(exc.InvalidConfigurationFile,
                    pyrax.settings.read_config, cfgfile)
        pyrax.default_region = sav_region
        pyrax.USER_AGENT = sav_USER_AGENT

    def test_set_credentials(self):
        pyrax.set_credentials(self.username, self.password)
        self.assertEqual(pyrax.identity.username, self.username)
        self.assertEqual(pyrax.identity.password, self.password)
        self.assertTrue(pyrax.identity.authenticated)

    def test_set_bad_credentials(self):
        self.assertRaises(exc.AuthenticationFailed, pyrax.set_credentials,
                "bad", "creds")
        self.assertFalse(pyrax.identity.authenticated)

    def test_set_credential_file(self):
        with utils.SelfDeletingTempfile() as tmpname:
            with open(tmpname, "wb") as tmp:
                tmp.write("[keystone]\n")
                tmp.write("username = %s\n" % self.username)
                tmp.write("password = %s\n" % self.password)
                tmp.write("tenant_id = %s\n" % self.tenant_id)
            pyrax.set_credential_file(tmpname)
            self.assertEqual(pyrax.identity.username, self.username)
            self.assertEqual(pyrax.identity.password, self.password)
            self.assertTrue(pyrax.identity.authenticated)

    def test_set_bad_credential_file(self):
        with utils.SelfDeletingTempfile() as tmpname:
            with open(tmpname, "wb") as tmp:
                tmp.write("[keystone]\n")
                tmp.write("username = bad\n")
                tmp.write("password = creds\n")
                tmp.write("tenant_id = stuff\n")
            self.assertRaises(exc.AuthenticationFailed,
                    pyrax.set_credential_file, tmpname)
        self.assertFalse(pyrax.identity.authenticated)

    def test_keyring_auth_no_module(self):
        pyrax.keyring = None
        self.assertRaises(exc.KeyringModuleNotInstalled, pyrax.keyring_auth)

    def test_keyring_auth_no_username(self):
        pyrax.keyring = object()
        set_obj = pyrax.settings
        env = set_obj.environment
        set_obj._settings[env]["keyring_username"] = ""
        self.assertRaises(exc.KeyringUsernameMissing, pyrax.keyring_auth)

    def test_keyring_auth(self):
        class FakeKeyring(object):
            pass
        fake_keyring = FakeKeyring()
        pyrax.keyring = fake_keyring
        fake_keyring.get_password = Mock(return_value="fakeapikey")
        pyrax.keyring_username = "fakeuser"
        pyrax.keyring_auth()
        self.assertTrue(pyrax.identity.authenticated)

    def test_auth_with_token(self):
        pyrax.authenticated = False
        tok = utils.random_unicode()
        tname = utils.random_unicode()
        pyrax.auth_with_token(tok, tenant_name=tname)
        self.assertTrue(pyrax.identity.authenticated)
        self.assertEqual(pyrax.identity.token, tok)
        self.assertEqual(pyrax.identity.tenant_name, tname)

    def test_clear_credentials(self):
        pyrax.set_credentials(self.username, self.password)
        # These next lines are required to test that clear_credentials
        # actually resets them to None.
        pyrax.cloudservers = object()
        pyrax.cloudfiles = object()
        pyrax.cloud_loadbalancers = object()
        pyrax.cloud_databases = object()
        default_region = object()
        self.assertTrue(pyrax.identity.authenticated)
        self.assertIsNotNone(pyrax.cloudfiles)
        pyrax.clear_credentials()
        self.assertIsNone(pyrax.identity)
        self.assertIsNone(pyrax.cloudservers)
        self.assertIsNone(pyrax.cloudfiles)
        self.assertIsNone(pyrax.cloud_loadbalancers)
        self.assertIsNone(pyrax.cloud_databases)

    def test_get_environment(self):
        env = pyrax.get_environment()
        all_envs = pyrax.list_environments()
        self.assertTrue(env in all_envs)

    def test_set_environment(self):
        env = "alternate"
        sav = pyrax.authenticate
        pyrax.authenticate = Mock()
        pyrax.set_environment(env)
        self.assertEqual(pyrax.get_environment(), env)
        pyrax.authenticate = sav

    def test_set_environment_fail(self):
        sav = pyrax.authenticate
        pyrax.authenticate = Mock()
        env = "doesn't exist"
        self.assertRaises(exc.EnvironmentNotFound, pyrax.set_environment, env)
        pyrax.authenticate = sav

    def test_set_default_region(self):
        orig_region = pyrax.default_region
        new_region = "test"
        pyrax.set_default_region(new_region)
        self.assertEqual(pyrax.default_region, new_region)
        pyrax.default_region = orig_region

    def test_set_identity_type_setting(self):
        savtyp = pyrax.get_setting("identity_type")
        savcls = pyrax.get_setting("identity_class")
        pyrax.set_setting("identity_class", None)
        pyrax.set_setting("identity_type", "keystone")
        cls = pyrax.get_setting("identity_class")
        self.assertEqual(cls, pyrax.keystone_identity.KeystoneIdentity)
        pyrax.set_setting("identity_type", savtyp)
        pyrax.set_setting("identity_class", savcls)

    def test_set_region_setting(self):
        ident = pyrax.identity
        ident.region = "DFW"
        pyrax.set_setting("region", "ORD")
        self.assertEqual(ident.region, "DFW")
        pyrax.set_setting("region", "LON")
        self.assertEqual(ident.region, "LON")

    def test_safe_region(self):
        # Pass direct
        reg = utils.random_unicode()
        ret = pyrax._safe_region(reg)
        self.assertEqual(reg, ret)
        # From config setting
        orig_reg = pyrax.get_setting("region")
        reg = utils.random_unicode()
        pyrax.set_setting("region", reg)
        ret = pyrax._safe_region()
        self.assertEqual(reg, ret)
        # Identity default
        pyrax.set_setting("region", None)
        orig_defreg = pyrax.identity.get_default_region
        reg = utils.random_unicode()
        pyrax.identity.get_default_region = Mock(return_value=reg)
        ret = pyrax._safe_region()
        self.assertEqual(reg, ret)
        pyrax.identity.get_default_region = orig_defreg
        pyrax.set_setting("region", orig_reg)

    def test_safe_region_no_context(self):
        reg = None
        sav_ident = pyrax.identity
        sav_create = pyrax._create_identity

        def set_ident():
            pyrax.identity = sav_ident

        pyrax._create_identity = Mock(side_effect=set_ident)
        sav_get = pyrax.settings.get
        pyrax.settings.get = Mock(return_value=None)
        pyrax.identity = None
        ret = pyrax._safe_region(reg)
        self.assertIsNotNone(ret)
        pyrax._create_identity = sav_create
        pyrax.identity = sav_ident
        pyrax.settings.get = sav_get

    def test_make_agent_name(self):
        test_agent = "TEST"
        ret = pyrax._make_agent_name(test_agent)
        self.assertTrue(ret.endswith(test_agent))
        self.assertTrue(ret.startswith(pyrax.USER_AGENT))

    def test_connect_to_services(self):
        pyrax.connect_to_services()
        pyrax.connect_to_cloudservers.assert_called_once_with(region=None)
        pyrax.connect_to_cloudfiles.assert_called_once_with(region=None)
        pyrax.connect_to_cloud_loadbalancers.assert_called_once_with(
                region=None)
        pyrax.connect_to_cloud_databases.assert_called_once_with(region=None)

    @patch('pyrax._cs_client.Client', new=fakes.FakeCSClient)
    def test_connect_to_cloudservers(self):
        pyrax.cloudservers = None
        sav = pyrax.connect_to_cloudservers
        pyrax.connect_to_cloudservers = self.orig_connect_to_cloudservers
        pyrax.cloudservers = pyrax.connect_to_cloudservers()
        self.assertIsNotNone(pyrax.cloudservers)
        pyrax.connect_to_cloudservers = sav

    @patch('pyrax._cf.CFClient', new=fakes.FakeService)
    def test_connect_to_cloudfiles(self):
        pyrax.cloudfiles = None
        pyrax.connect_to_cloudfiles = self.orig_connect_to_cloudfiles
        pyrax.cloudfiles = pyrax.connect_to_cloudfiles()
        self.assertIsNotNone(pyrax.cloudfiles)

    @patch('pyrax._cf.CFClient')
    def test_connect_to_cloudfiles_ServiceNet(self, client):
        orig = pyrax.get_setting("use_servicenet")
        pyrax.set_setting("use_servicenet", True)
        pyrax.cloudfiles = None
        pyrax.connect_to_cloudfiles = self.orig_connect_to_cloudfiles
        cf = pyrax.connect_to_cloudfiles(public=False)
        # Check the call arguments to see that our setting stuck and we're
        # sending internalURL on to CFClient.
        _, kwargs = client.call_args
        opts = kwargs["os_options"]
        self.assertEqual(opts["endpoint_type"], "internalURL")
        self.assertIsNotNone(cf)
        pyrax.set_setting("use_servicenet", orig)

    @patch('pyrax.CloudLoadBalancerClient', new=fakes.FakeService)
    def test_connect_to_cloud_loadbalancers(self):
        pyrax.cloud_loadbalancers = None
        octclb = self.orig_connect_to_cloud_loadbalancers
        pyrax.connect_to_cloud_loadbalancers = octclb
        pyrax.cloud_loadbalancers = pyrax.connect_to_cloud_loadbalancers()
        self.assertIsNotNone(pyrax.cloud_loadbalancers)

    @patch('pyrax.CloudDatabaseClient', new=fakes.FakeService)
    def test_connect_to_cloud_databases(self):
        pyrax.cloud_databases = None
        pyrax.connect_to_cloud_databases = self.orig_connect_to_cloud_databases
        pyrax.cloud_databases = pyrax.connect_to_cloud_databases()
        self.assertIsNotNone(pyrax.cloud_databases)

    def test_set_http_debug(self):
        pyrax.cloudservers = None
        sav = pyrax.connect_to_cloudservers
        pyrax.connect_to_cloudservers = self.orig_connect_to_cloudservers
        pyrax.cloudservers = pyrax.connect_to_cloudservers()
        pyrax.cloudservers.http_log_debug = False
        pyrax.set_http_debug(True)
        self.assertTrue(pyrax.cloudservers.http_log_debug)
        pyrax.set_http_debug(False)
        self.assertFalse(pyrax.cloudservers.http_log_debug)
        pyrax.connect_to_cloudservers = sav

    def test_get_encoding(self):
        sav = pyrax.get_setting
        pyrax.get_setting = Mock(return_value=None)
        enc = pyrax.get_encoding()
        self.assertEqual(enc, pyrax.default_encoding)
        pyrax.get_setting = sav

    def test_import_fail(self):
        import __builtin__
        sav_import = __builtin__.__import__

        def fake_import(nm, *args):
            if nm == "identity":
                raise ImportError
            else:
                return sav_import(nm, *args)

        __builtin__.__import__ = fake_import
        self.assertRaises(ImportError, reload, pyrax)
        __builtin__.__import__ = sav_import
        reload(pyrax)



if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_queues
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import random
import unittest

from mock import patch
from mock import MagicMock as Mock

import pyrax
import pyrax.queueing
from pyrax.queueing import BaseQueueManager
from pyrax.queueing import Queue
from pyrax.queueing import QueueClaim
from pyrax.queueing import QueueClaimManager
from pyrax.queueing import QueueClient
from pyrax.queueing import QueueManager
from pyrax.queueing import QueueMessage
from pyrax.queueing import QueueMessageManager
from pyrax.queueing import assure_queue
from pyrax.queueing import _parse_marker

import pyrax.exceptions as exc
import pyrax.utils as utils

from pyrax import fakes


def _safe_id():
    """
    Remove characters that shouldn't be in IDs, etc., that are being parsed
    from HREFs. This is a consequence of the random_unicode() function, which
    sometimes causes the urlparse function to return the wrong values when
    these characters are present.
    """
    val = utils.random_ascii()
    for bad in "#;/?":
        val = val.replace(bad, "")
    return val


class QueuesTest(unittest.TestCase):
    def __init__(self, *args, **kwargs):
        super(QueuesTest, self).__init__(*args, **kwargs)

    def setUp(self):
        self.identity = fakes.FakeIdentity()
        self.client = fakes.FakeQueueClient(self.identity)
        self.client._manager = fakes.FakeQueueManager(self.client)
        self.queue = fakes.FakeQueue()
        self.queue.manager = self.client._manager

    def tearDown(self):
        pass

    def test_parse_marker(self):
        fake_marker = "%s" % random.randint(10000, 100000)
        href = "http://example.com/foo?marker=%s" % fake_marker
        body = {"links": [
                {"rel": "next", "href": href},
                {"rel": "bogus", "href": "fake"},
                ]}
        ret = _parse_marker(body)
        self.assertEqual(ret, fake_marker)

    def test_parse_marker_no_next(self):
        fake_marker = "%s" % random.randint(10000, 100000)
        href = "http://example.com/foo?marker=%s" % fake_marker
        body = {"links": [
                {"rel": "bogus", "href": "fake"},
                ]}
        ret = _parse_marker(body)
        self.assertIsNone(ret)

    def test_parse_marker_fail(self):
        fake_marker = "%s" % random.randint(10000, 100000)
        href = "http://example.com/foo?not_valid=%s" % fake_marker
        body = {"links": [
                {"rel": "next", "href": href},
                {"rel": "bogus", "href": "fake"},
                ]}
        ret = _parse_marker(body)
        self.assertIsNone(ret)

    def test_assure_queue(self):
        @assure_queue
        def test(self, queue):
            return queue
        clt = self.client
        q = self.queue
        clt._manager.get = Mock(return_value=q)
        ret = test(clt, q.id)
        self.assertEqual(ret, q)

    def test_base_list(self):
        clt = self.client
        mgr = clt._manager
        mgr.api.method_get = Mock(side_effect=exc.NotFound(""))
        uri = utils.random_unicode()
        ret = mgr.list(uri)
        self.assertEqual(ret, [])

    def test_queue_get_message(self):
        q = self.queue
        q._message_manager.get = Mock()
        msgid = utils.random_unicode()
        q.get_message(msgid)
        q._message_manager.get.assert_called_once_with(msgid)

    def test_queue_delete_message(self):
        q = self.queue
        q._message_manager.delete = Mock()
        msg_id = utils.random_unicode()
        claim_id = utils.random_unicode()
        q.delete_message(msg_id, claim_id=claim_id)
        q._message_manager.delete.assert_called_once_with(msg_id,
                claim_id=claim_id)

    def test_queue_list(self):
        q = self.queue
        q._message_manager.list = Mock()
        include_claimed = utils.random_unicode()
        echo = utils.random_unicode()
        marker = utils.random_unicode()
        limit = utils.random_unicode()
        q.list(include_claimed=include_claimed, echo=echo, marker=marker,
                limit=limit)
        q._message_manager.list.assert_called_once_with(
                include_claimed=include_claimed, echo=echo, marker=marker,
                limit=limit)

    def test_queue_list_by_ids(self):
        q = self.queue
        q._message_manager.list_by_ids = Mock()
        ids = utils.random_unicode()
        q.list_by_ids(ids)
        q._message_manager.list_by_ids.assert_called_once_with(ids)

    def test_queue_delete_by_ids(self):
        q = self.queue
        q._message_manager.delete_by_ids = Mock()
        ids = utils.random_unicode()
        q.delete_by_ids(ids)
        q._message_manager.delete_by_ids.assert_called_once_with(ids)

    def test_queue_list_by_claim(self):
        q = self.queue
        qclaim = fakes.FakeQueueClaim()
        q._claim_manager.get = Mock(return_value=qclaim)
        claim_id = utils.random_unicode()
        ret = q.list_by_claim(claim_id)
        self.assertEqual(ret, qclaim.messages)

    def test_queue_post_message(self):
        q = self.queue
        q._message_manager.create = Mock()
        body = utils.random_unicode()
        ttl = utils.random_unicode()
        q.post_message(body, ttl)
        q._message_manager.create.assert_called_once_with(body, ttl)

    def test_queue_claim_messages(self):
        q = self.queue
        q._claim_manager.claim = Mock()
        ttl = utils.random_unicode()
        grace = utils.random_unicode()
        count = random.randint(1, 9)
        q.claim_messages(ttl, grace, count=count)
        q._claim_manager.claim.assert_called_once_with(ttl, grace, count=count)

    def test_queue_get_claim(self):
        q = self.queue
        q._claim_manager.get = Mock()
        claim = utils.random_unicode()
        q.get_claim(claim)
        q._claim_manager.get.assert_called_once_with(claim)

    def test_queue_update_claim(self):
        q = self.queue
        q._claim_manager.update = Mock()
        claim = utils.random_unicode()
        ttl = utils.random_unicode()
        grace = utils.random_unicode()
        q.update_claim(claim, ttl=ttl, grace=grace)
        q._claim_manager.update.assert_called_once_with(claim, ttl=ttl,
                grace=grace)

    def test_queue_release_claim(self):
        q = self.queue
        q._claim_manager.delete = Mock()
        claim = utils.random_unicode()
        q.release_claim(claim)
        q._claim_manager.delete.assert_called_once_with(claim)

    def test_queue_id_property(self):
        q = self.queue
        val = utils.random_unicode()
        q.name = val
        self.assertEqual(q.id, val)
        val = utils.random_unicode()
        q.id = val
        self.assertEqual(q.name, val)

    def test_msg_add_details(self):
        id_ = _safe_id()
        claim_id = utils.random_unicode()
        age = utils.random_unicode()
        body = utils.random_unicode()
        ttl = utils.random_unicode()
        href = "http://example.com/%s" % id_
        info = {"href": href,
                "age": age,
                "body": body,
                "ttl": ttl,
                }
        msg = QueueMessage(manager=None, info=info)
        self.assertEqual(msg.id, id_)
        self.assertIsNone(msg.claim_id)
        self.assertEqual(msg.age, age)
        self.assertEqual(msg.body, body)
        self.assertEqual(msg.ttl, ttl)
        self.assertEqual(msg.href, href)

    def test_msg_add_details_claim(self):
        id_ = _safe_id()
        claim_id = _safe_id()
        age = utils.random_unicode()
        body = utils.random_unicode()
        ttl = utils.random_unicode()
        href = "http://example.com/%s?claim_id=%s" % (id_, claim_id)
        info = {"href": href,
                "age": age,
                "body": body,
                "ttl": ttl,
                }
        msg = QueueMessage(manager=None, info=info)
        self.assertEqual(msg.id, id_)
        self.assertEqual(msg.claim_id, claim_id)

    def test_msg_add_details_no_href(self):
        id_ = utils.random_unicode()
        claim_id = utils.random_unicode()
        age = utils.random_unicode()
        body = utils.random_unicode()
        ttl = utils.random_unicode()
        href = None
        info = {"href": href,
                "age": age,
                "body": body,
                "ttl": ttl,
                }
        msg = QueueMessage(manager=None, info=info)
        self.assertIsNone(msg.id)
        self.assertIsNone(msg.claim_id)

    def test_msg_delete(self):
        q = self.queue
        mgr = q._message_manager
        claim_id = utils.random_unicode()
        mgr.delete = Mock()
        msg = QueueMessage(manager=mgr, info={})
        msg.delete(claim_id=claim_id)
        mgr.delete.assert_called_once_with(msg, claim_id=claim_id)

    def test_claim(self):
        msgs = []
        num = random.randint(1, 9)
        for ii in range(num):
            msg_id = utils.random_unicode()
            claim_id = utils.random_unicode()
            age = utils.random_unicode()
            body = utils.random_unicode()
            ttl = utils.random_unicode()
            href = "http://example.com/%s" % msg_id
            info = {"href": href,
                    "age": age,
                    "body": body,
                    "ttl": ttl,
                    }
            msgs.append(info)
        id_ = _safe_id()
        href = "http://example.com/%s" % id_
        info = {"href": href,
                "messages": msgs,
                }
        mgr = fakes.FakeQueueManager()
        mgr._message_manager = fakes.FakeQueueManager()
        clm = QueueClaim(manager=mgr, info=info)
        self.assertEqual(clm.id, id_)
        self.assertEqual(len(clm.messages), num)

    def test_queue_msg_mgr_create_body(self):
        q = self.queue
        mgr = q._message_manager
        msg = utils.random_unicode()
        ttl = utils.random_unicode()
        ret = mgr._create_body(msg, ttl)
        self.assertTrue(isinstance(ret, list))
        self.assertEqual(len(ret), 1)
        dct = ret[0]
        self.assertTrue(isinstance(dct, dict))
        self.assertEqual(dct["body"], msg)
        self.assertEqual(dct["ttl"], ttl)

    def test_queue_msg_mgr_list(self):
        q = self.queue
        mgr = q._message_manager
        include_claimed = random.choice((True, False))
        echo = random.choice((True, False))
        marker = utils.random_unicode()
        limit = random.randint(15, 35)
        rbody = {"links": [], "messages": [{"href": "fake"}]}
        pyrax.queueing._parse_marker = Mock(return_value="fake")
        mgr._list = Mock(return_value=(None, rbody))
        msgs = mgr.list(include_claimed=include_claimed, echo=echo,
                marker=marker, limit=limit)

    def test_queue_msg_mgr_no_limit_or_body(self):
        q = self.queue
        mgr = q._message_manager
        include_claimed = random.choice((True, False))
        echo = random.choice((True, False))
        marker = utils.random_unicode()
        pyrax.queueing._parse_marker = Mock(return_value="fake")
        mgr._list = Mock(return_value=(None, None))
        msgs = mgr.list(include_claimed=include_claimed, echo=echo,
                marker=marker)

    def test_queue_msg_mgr_delete_claim(self):
        q = self.queue
        mgr = q._message_manager
        msg = utils.random_unicode()
        claim_id = utils.random_unicode()
        mgr._delete = Mock()
        expected_uri = "/%s/%s?claim_id=%s" % (mgr.uri_base, msg, claim_id)
        mgr.delete(msg, claim_id=claim_id)
        mgr._delete.assert_called_once_with(expected_uri)

    def test_queue_msg_mgr_delete_no_claim(self):
        q = self.queue
        mgr = q._message_manager
        msg = utils.random_unicode()
        claim_id = None
        mgr._delete = Mock()
        expected_uri = "/%s/%s" % (mgr.uri_base, msg)
        mgr.delete(msg, claim_id=claim_id)
        mgr._delete.assert_called_once_with(expected_uri)

    def test_queue_msg_mgr_list_by_ids(self):
        q = self.queue
        mgr = q._message_manager
        mgr._list = Mock()
        id1 = utils.random_unicode()
        id2 = utils.random_unicode()
        mgr.list_by_ids([id1, id2])
        expected = "/%s?ids=%s" % (mgr.uri_base, ",".join([id1, id2]))
        mgr._list.assert_called_once_with(expected)

    def test_queue_msg_mgr_delete_by_ids(self):
        q = self.queue
        mgr = q._message_manager
        mgr.api.method_delete = Mock()
        id1 = utils.random_unicode()
        id2 = utils.random_unicode()
        mgr.delete_by_ids([id1, id2])
        expected = "/%s?ids=%s" % (mgr.uri_base, ",".join([id1, id2]))
        mgr.api.method_delete.assert_called_once_with(expected)

    def test_queue_claim_mgr_claim(self):
        q = self.queue
        mgr = q._claim_manager
        ttl = utils.random_unicode()
        grace = utils.random_unicode()
        count = utils.random_unicode()
        claim_id = utils.random_unicode()
        rbody = [{"href": "http://example.com/foo?claim_id=%s" % claim_id}]
        mgr.api.method_post = Mock(return_value=(fakes.FakeResponse(), rbody))
        mgr.get = Mock()
        exp_uri = "/%s?limit=%s" % (mgr.uri_base, count)
        exp_body = {"ttl": ttl, "grace": grace}
        mgr.claim(ttl, grace, count=count)
        mgr.api.method_post.assert_called_once_with(exp_uri, body=exp_body)
        mgr.get.assert_called_once_with(claim_id)

    def test_queue_claim_mgr_claim_no_count(self):
        q = self.queue
        mgr = q._claim_manager
        ttl = utils.random_unicode()
        grace = utils.random_unicode()
        claim_id = utils.random_unicode()
        rbody = [{"href": "http://example.com/foo?claim_id=%s" % claim_id}]
        mgr.api.method_post = Mock(return_value=(fakes.FakeResponse(), rbody))
        mgr.get = Mock()
        exp_uri = "/%s" % mgr.uri_base
        exp_body = {"ttl": ttl, "grace": grace}
        mgr.claim(ttl, grace)
        mgr.api.method_post.assert_called_once_with(exp_uri, body=exp_body)
        mgr.get.assert_called_once_with(claim_id)

    def test_queue_claim_mgr_claim_empty(self):
        q = self.queue
        mgr = q._claim_manager
        ttl = utils.random_unicode()
        grace = utils.random_unicode()
        claim_id = utils.random_unicode()
        rbody = [{"href": "http://example.com/foo?claim_id=%s" % claim_id}]
        resp = fakes.FakeResponse()
        resp.status_code = 204
        mgr.api.method_post = Mock(return_value=(resp, rbody))
        mgr.get = Mock()
        exp_uri = "/%s" % mgr.uri_base
        exp_body = {"ttl": ttl, "grace": grace}
        mgr.claim(ttl, grace)
        mgr.api.method_post.assert_called_once_with(exp_uri, body=exp_body)

    def test_queue_claim_mgr_update(self):
        q = self.queue
        mgr = q._claim_manager
        claim = utils.random_unicode()
        ttl = utils.random_unicode()
        grace = utils.random_unicode()
        mgr.api.method_patch = Mock(return_value=(None, None))
        exp_uri = "/%s/%s" % (mgr.uri_base, claim)
        exp_body = {"ttl": ttl, "grace": grace}
        mgr.update(claim, ttl=ttl, grace=grace)
        mgr.api.method_patch.assert_called_once_with(exp_uri, body=exp_body)

    def test_queue_claim_mgr_update_missing(self):
        q = self.queue
        mgr = q._claim_manager
        claim = utils.random_unicode()
        self.assertRaises(exc.MissingClaimParameters, mgr.update, claim)

    def test_queue_mgr_create_body(self):
        clt = self.client
        mgr = clt._manager
        name = utils.random_unicode()
        metadata = utils.random_unicode()
        ret = mgr._create_body(name, metadata=metadata)
        self.assertEqual(ret, {"metadata": metadata})

    def test_queue_mgr_create_body_no_meta(self):
        clt = self.client
        mgr = clt._manager
        name = utils.random_unicode()
        ret = mgr._create_body(name)
        self.assertEqual(ret, {})

    def test_queue_mgr_get(self):
        clt = self.client
        mgr = clt._manager
        id_ = utils.random_unicode()
        mgr.api.queue_exists = Mock(return_value=True)
        q = mgr.get(id_)
        self.assertTrue(isinstance(q, Queue))
        self.assertEqual(q.name, id_)

    def test_queue_mgr_get_not_found(self):
        clt = self.client
        mgr = clt._manager
        id_ = utils.random_unicode()
        mgr.api.queue_exists = Mock(return_value=False)
        self.assertRaises(exc.NotFound, mgr.get, id_)

    def test_queue_mgr_create(self):
        clt = self.client
        mgr = clt._manager
        name = utils.random_unicode()
        exp_uri = "/%s/%s" % (mgr.uri_base, name)
        resp = fakes.FakeResponse()
        resp.status_code = 201
        mgr.api.method_put = Mock(return_value=(resp, None))
        q = mgr.create(name)
        self.assertTrue(isinstance(q, Queue))
        self.assertEqual(q.name, name)

    def test_queue_mgr_create_invalid(self):
        clt = self.client
        mgr = clt._manager
        name = utils.random_unicode()
        exp_uri = "/%s/%s" % (mgr.uri_base, name)
        resp = fakes.FakeResponse()
        resp.status_code = 400
        mgr.api.method_put = Mock(return_value=(resp, None))
        self.assertRaises(exc.InvalidQueueName, mgr.create, name)

    def test_queue_mgr_get_stats(self):
        clt = self.client
        mgr = clt._manager
        q = utils.random_unicode()
        exp_uri = "/%s/%s/stats" % (mgr.uri_base, q)
        msgs = utils.random_unicode()
        rbody = {"messages": msgs}
        mgr.api.method_get = Mock(return_value=(None, rbody))
        ret = mgr.get_stats(q)
        self.assertEqual(ret, msgs)
        mgr.api.method_get.assert_called_once_with(exp_uri)

    def test_queue_mgr_get_metadata(self):
        clt = self.client
        mgr = clt._manager
        q = utils.random_unicode()
        exp_uri = "/%s/%s/metadata" % (mgr.uri_base, q)
        rbody = utils.random_unicode()
        mgr.api.method_get = Mock(return_value=(None, rbody))
        ret = mgr.get_metadata(q)
        self.assertEqual(ret, rbody)
        mgr.api.method_get.assert_called_once_with(exp_uri)

    def test_queue_mgr_set_metadata_clear(self):
        clt = self.client
        mgr = clt._manager
        q = utils.random_unicode()
        exp_uri = "/%s/%s/metadata" % (mgr.uri_base, q)
        val = utils.random_unicode()
        metadata = {"new": val}
        mgr.api.method_put = Mock(return_value=(None, None))
        ret = mgr.set_metadata(q, metadata, clear=True)
        mgr.api.method_put.assert_called_once_with(exp_uri, body=metadata)

    def test_queue_mgr_set_metadata_no_clear(self):
        clt = self.client
        mgr = clt._manager
        q = utils.random_unicode()
        exp_uri = "/%s/%s/metadata" % (mgr.uri_base, q)
        val = utils.random_unicode()
        metadata = {"new": val}
        old_val = utils.random_unicode()
        old_metadata = {"old": val}
        exp_body = old_metadata
        exp_body.update(metadata)
        mgr.api.method_put = Mock(return_value=(None, None))
        mgr.get_metadata = Mock(return_value=old_metadata)
        ret = mgr.set_metadata(q, metadata, clear=False)
        mgr.api.method_put.assert_called_once_with(exp_uri, body=exp_body)

    def test_clt_add_custom_headers(self):
        clt = self.client
        dct = {}
        client_id = utils.random_unicode()
        sav = os.environ.get
        os.environ.get = Mock(return_value=client_id)
        clt._add_custom_headers(dct)
        self.assertEqual(dct, {"Client-ID": client_id})
        os.environ.get = sav

    def test_clt_add_custom_headers_no_clt_id(self):
        clt = self.client
        dct = {}
        sav = os.environ.get
        os.environ.get = Mock(return_value=None)
        clt._add_custom_headers(dct)
        self.assertEqual(dct, {})
        os.environ.get = sav

    def test_api_request(self):
        clt = self.client
        uri = utils.random_ascii()
        method = utils.random_ascii()
        kwargs = {"fake": utils.random_ascii()}
        fake_resp = utils.random_ascii()
        fake_body = utils.random_ascii()
        clt._time_request = Mock(return_value=(fake_resp, fake_body))
        clt.management_url = utils.random_unicode()
        id_svc = clt.identity
        sav = id_svc.authenticate
        id_svc.authenticate = Mock()
        ret = clt._api_request(uri, method, **kwargs)
        self.assertEqual(ret, (fake_resp, fake_body))
        id_svc.authenticate = sav

    def test_api_request_missing_clt_id(self):
        clt = self.client
        uri = utils.random_ascii()
        method = utils.random_ascii()
        kwargs = {"fake": utils.random_ascii()}
        err = exc.BadRequest("400", 'The "Client-ID" header is required.')
        clt._time_request = Mock(side_effect=err)
        clt.management_url = utils.random_unicode()
        id_svc = clt.identity
        sav = id_svc.authenticate
        id_svc.authenticate = Mock()
        self.assertRaises(exc.QueueClientIDNotDefined, clt._api_request, uri,
                method, **kwargs)
        id_svc.authenticate = sav

    def test_api_request_other_error(self):
        clt = self.client
        uri = utils.random_ascii()
        method = utils.random_ascii()
        kwargs = {"fake": utils.random_ascii()}
        err = exc.BadRequest("400", "Some other message")
        clt._time_request = Mock(side_effect=err)
        clt.management_url = utils.random_unicode()
        id_svc = clt.identity
        sav = id_svc.authenticate
        id_svc.authenticate = Mock()
        self.assertRaises(exc.BadRequest, clt._api_request, uri,
                method, **kwargs)
        id_svc.authenticate = sav

    def test_clt_get_home_document(self):
        clt = self.client
        parts = [_safe_id() for ii in range(4)]
        clt.management_url = "/".join(parts)
        exp_uri = "/".join(parts[:-1])
        clt.method_get = Mock()
        clt.get_home_document()
        clt.method_get.assert_called_once_with(exp_uri)

    def test_clt_queue_exists(self):
        clt = self.client
        clt._manager.head = Mock()
        name = utils.random_unicode()
        ret = clt.queue_exists(name)
        self.assertTrue(ret)
        clt._manager.head.assert_called_once_with(name)

    def test_clt_queue_not_exists(self):
        clt = self.client
        clt._manager.head = Mock(side_effect=exc.NotFound(""))
        name = utils.random_unicode()
        ret = clt.queue_exists(name)
        self.assertFalse(ret)
        clt._manager.head.assert_called_once_with(name)

    def test_clt_create(self):
        clt = self.client
        clt.queue_exists = Mock(return_value=False)
        clt._manager.create = Mock()
        name = utils.random_unicode()
        clt.create(name)
        clt._manager.create.assert_called_once_with(name)

    def test_clt_create_dupe(self):
        clt = self.client
        clt.queue_exists = Mock(return_value=True)
        name = utils.random_unicode()
        self.assertRaises(exc.DuplicateQueue, clt.create, name)

    def test_clt_get_stats(self):
        clt = self.client
        clt._manager.get_stats = Mock()
        q = utils.random_unicode()
        clt.get_stats(q)
        clt._manager.get_stats.assert_called_once_with(q)

    def test_clt_get_metadata(self):
        clt = self.client
        clt._manager.get_metadata = Mock()
        q = utils.random_unicode()
        clt.get_metadata(q)
        clt._manager.get_metadata.assert_called_once_with(q)

    def test_clt_set_metadata(self):
        clt = self.client
        clt._manager.set_metadata = Mock()
        q = utils.random_unicode()
        metadata = utils.random_unicode()
        clear = random.choice((True, False))
        clt.set_metadata(q, metadata, clear=clear)
        clt._manager.set_metadata.assert_called_once_with(q, metadata,
                clear=clear)

    def test_clt_get_message(self):
        clt = self.client
        q = self.queue
        msg_id = utils.random_unicode()
        q.get_message = Mock()
        clt.get_message(q, msg_id)
        q.get_message.assert_called_once_with(msg_id)

    def test_clt_delete_message(self):
        clt = self.client
        q = self.queue
        msg_id = utils.random_unicode()
        claim_id = utils.random_unicode()
        q.delete_message = Mock()
        clt.delete_message(q, msg_id, claim_id=claim_id)
        q.delete_message.assert_called_once_with(msg_id, claim_id=claim_id)

    def test_clt_list_messages(self):
        clt = self.client
        q = self.queue
        include_claimed = utils.random_unicode()
        echo = utils.random_unicode()
        marker = utils.random_unicode()
        limit = utils.random_unicode()
        q.list = Mock()
        clt.list_messages(q, include_claimed=include_claimed, echo=echo,
                marker=marker, limit=limit)
        q.list.assert_called_once_with(include_claimed=include_claimed,
                echo=echo, marker=marker, limit=limit)

    def test_clt_list_messages_by_ids(self):
        clt = self.client
        q = self.queue
        ids = utils.random_unicode()
        q.list_by_ids = Mock()
        clt.list_messages_by_ids(q, ids)
        q.list_by_ids.assert_called_once_with(ids)

    def test_clt_delete_messages_by_ids(self):
        clt = self.client
        q = self.queue
        ids = utils.random_unicode()
        q.delete_by_ids = Mock()
        clt.delete_messages_by_ids(q, ids)
        q.delete_by_ids.assert_called_once_with(ids)

    def test_clt_list_messages_by_claim(self):
        clt = self.client
        q = self.queue
        claim = utils.random_unicode()
        q.list_by_claim = Mock()
        clt.list_messages_by_claim(q, claim)
        q.list_by_claim.assert_called_once_with(claim)

    def test_clt_post_message(self):
        clt = self.client
        q = self.queue
        body = utils.random_unicode()
        ttl = utils.random_unicode()
        q.post_message = Mock()
        clt.post_message(q, body, ttl)
        q.post_message.assert_called_once_with(body, ttl)

    def test_clt_claim_messages(self):
        clt = self.client
        q = self.queue
        ttl = utils.random_unicode()
        grace = utils.random_unicode()
        count = utils.random_unicode()
        q.claim_messages = Mock()
        clt.claim_messages(q, ttl, grace, count=count)
        q.claim_messages.assert_called_once_with(ttl, grace, count=count)

    def test_clt_get_claim(self):
        clt = self.client
        q = self.queue
        claim = utils.random_unicode()
        q.get_claim = Mock()
        clt.get_claim(q, claim)
        q.get_claim.assert_called_once_with(claim)

    def test_clt_update_claim(self):
        clt = self.client
        q = self.queue
        claim = utils.random_unicode()
        ttl = utils.random_unicode()
        grace = utils.random_unicode()
        q.update_claim = Mock()
        clt.update_claim(q, claim, ttl=ttl, grace=grace)
        q.update_claim.assert_called_once_with(claim, ttl=ttl, grace=grace)

    def test_clt_release_claim(self):
        clt = self.client
        q = self.queue
        claim = utils.random_unicode()
        q.release_claim = Mock()
        clt.release_claim(q, claim)
        q.release_claim.assert_called_once_with(claim)


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_resource
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import unittest

from mock import MagicMock as Mock

import pyrax.utils as utils
import pyrax.exceptions as exc
from pyrax import resource

from pyrax import fakes

fake_url = "http://example.com"


class ResourceTest(unittest.TestCase):
    def __init__(self, *args, **kwargs):
        super(ResourceTest, self).__init__(*args, **kwargs)

    def _create_dummy_resource(self):
        mgr = fakes.FakeManager()
        info = {"name": "test_resource",
                "size": 42,
                "id": utils.random_unicode()}
        return resource.BaseResource(mgr, info)

    def setUp(self):
        self.resource = self._create_dummy_resource()

    def tearDown(self):
        self.resource = None

    def test_human_id(self):
        rsc = self.resource
        sav_hu = rsc.HUMAN_ID
        rsc.HUMAN_ID = True
        sav_slug = utils.slugify

        def echo(val):
            return val

        utils.slugify = Mock(side_effect=echo)
        self.assertEqual(rsc.name, rsc.human_id)
        rsc.HUMAN_ID = sav_hu
        utils.slugify = sav_slug

    def test_human_id_false(self):
        rsc = self.resource
        sav_hu = rsc.HUMAN_ID
        rsc.HUMAN_ID = False
        sav_slug = utils.slugify

        def echo(val):
            return val

        utils.slugify = Mock(side_effect=echo)
        self.assertIsNone(rsc.human_id)
        rsc.HUMAN_ID = sav_hu
        utils.slugify = sav_slug

    def test_add_details(self):
        rsc = self.resource
        info = {"foo": 1, "bar": 2}
        self.assertFalse(hasattr(rsc, "foo"))
        self.assertFalse(hasattr(rsc, "bar"))
        rsc._add_details(info)
        self.assertTrue(hasattr(rsc, "foo"))
        self.assertTrue(hasattr(rsc, "bar"))
        self.assertEqual(rsc.foo, 1)
        self.assertEqual(rsc.bar, 2)

    def test_getattr(self):
        rsc = self.resource
        sav = rsc.get
        rsc.get = Mock()
        sav_lo = rsc.loaded
        rsc.loaded = False
        self.assertRaises(AttributeError, rsc.__getattr__, "xname")
        rsc.loaded = sav_lo
        rsc.get = sav

    def test_repr(self):
        rsc = self.resource
        ret = rsc.__repr__()
        self.assertTrue("name=%s" % rsc.name in ret)
        self.assertTrue("size=%s" % rsc.size in ret)

    def test_get(self):
        rsc = self.resource
        sav_ga = rsc.__getattr__
        rsc.__getattr__ = Mock()
        sav_mgr = rsc.manager.get
        ent = fakes.FakeEntity
        new_att = utils.random_ascii()
        ent._info = {new_att: None}
        rsc.manager.get = Mock(return_value=ent)
        rsc.get()
        self.assertTrue(hasattr(rsc, new_att))
        rsc.manager.get = sav_mgr
        rsc.__getattr__ = sav_ga

    def test_delete(self):
        rsc = self.resource
        sav_mgr = rsc.manager.delete
        rsc.manager.delete = Mock()
        rsc.delete()
        rsc.manager.delete.assert_called_once_with(rsc)
        rsc.manager.delete = sav_mgr

    def test_delete_no_mgr(self):
        rsc = self.resource
        rsc.manager = object()
        ret = rsc.delete()
        self.assertIsNone(ret)

    def test_not_eq(self):
        rsc = self.resource
        fake = object()
        self.assertFalse(fake == rsc)

    def test_id_eq(self):
        rsc = self.resource
        fake = self._create_dummy_resource()
        fake.id = rsc.id
        self.assertEqual(fake, rsc)

    def test_info_eq(self):
        rsc = self.resource
        fake = self._create_dummy_resource()
        self.assertNotEqual(fake, rsc)

    def test_reload(self):
        rsc = self.resource
        fake = self._create_dummy_resource()
        fake._info["status"] = "TESTING"
        sav = rsc.manager.get
        rsc.manager.get = Mock(return_value=fake)
        rsc.reload()
        self.assertEqual(rsc.status, "TESTING")
        fake._info["status"] = "OK"
        sav = rsc.manager.get
        rsc.manager.get = Mock(return_value=fake)
        rsc.reload()
        self.assertEqual(rsc.status, "OK")
        rsc.manager.get = sav

    def test_loaded(self):
        rsc = self.resource
        orig_loaded = rsc.loaded
        rsc.loaded = not orig_loaded
        self.assertNotEqual(orig_loaded, rsc.loaded)


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_service_catalog
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import unittest

from mock import MagicMock as Mock

import six

import pyrax.utils as utils
import pyrax.exceptions as exc
from pyrax import service_catalog

from pyrax import fakes

fake_url = "http://example.com"


class ServiceCatalogTest(unittest.TestCase):
    def __init__(self, *args, **kwargs):
        super(ServiceCatalogTest, self).__init__(*args, **kwargs)

    def setUp(self):
        self.service_catalog = service_catalog.ServiceCatalog(
                fakes.fake_identity_response)

    def tearDown(self):
        self.service_catalog = None

    def test_get_token(self):
        sc = self.service_catalog
        tok = sc.get_token()
        self.assertEqual(len(tok), 36)

    def test_url_for_no_catalog(self):
        sc = self.service_catalog
        sc.catalog = {"access": {}}
        ret = sc.url_for()
        self.assertIsNone(ret)

    def test_url_for_no_match(self):
        sc = self.service_catalog
        self.assertRaises(exc.EndpointNotFound, sc.url_for,
                service_type="test")

    def test_url_for_ambiguous(self):
        sc = self.service_catalog
        self.assertRaises(exc.AmbiguousEndpoints, sc.url_for,
                service_type="object-store")

    def test_url_for_object_store(self):
        sc = self.service_catalog
        ret = sc.url_for(service_type="object-store", attr="region",
                filter_value="DFW")
        self.assertTrue(isinstance(ret, six.string_types))
        self.assertTrue("http" in ret)


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_utils
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import datetime
import hashlib
import os
import random
import StringIO
import sys
import time
import unittest

import six

from mock import patch
from mock import MagicMock as Mock

from pyrax import base_identity
import pyrax.exceptions as exc
from pyrax import fakes
import pyrax.utils as utils

FAKE_CONTENT = "x" * 100


class UtilsTest(unittest.TestCase):
    def __init__(self, *args, **kwargs):
        super(UtilsTest, self).__init__(*args, **kwargs)

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_runproc(self):
        currdir = os.getcwd()
        out, err = utils.runproc("pwd")
        self.assertEqual(err, "")
        self.assertEqual(out.strip(), currdir)

    def test_self_deleting_temp_file(self):
        with utils.SelfDeletingTempfile() as tmp:
            self.assert_(isinstance(tmp, six.string_types))
            self.assert_(os.path.exists(tmp))
            self.assert_(os.path.isfile(tmp))
        # File shoud be deleted after exiting the block
        self.assertFalse(os.path.exists(tmp))

    def test_self_deleting_temp_directory(self):
        with utils.SelfDeletingTempDirectory() as tmp:
            self.assert_(isinstance(tmp, six.string_types))
            self.assert_(os.path.exists(tmp))
            self.assert_(os.path.isdir(tmp))
        # Directory shoud be deleted after exiting the block
        self.assertFalse(os.path.exists(tmp))

    def test_dot_dict(self):
        key = "fake"
        val = utils.random_unicode()
        dct = {key: val}
        dd = utils.DotDict(dct)
        self.assertEqual(dd.fake, val)
        self.assertRaises(AttributeError, getattr, dd, "bogus")

    def test_get_checksum_from_string(self):
        test = utils.random_ascii()
        md = hashlib.md5()
        md.update(test)
        expected = md.hexdigest()
        received = utils.get_checksum(test)
        self.assertEqual(expected, received)

    def test_get_checksum_from_unicode(self):
        test = utils.random_unicode()
        md = hashlib.md5()
        enc = "utf8"
        md.update(test.encode(enc))
        expected = md.hexdigest()
        received = utils.get_checksum(test)
        self.assertEqual(expected, received)

    def test_get_checksum_from_unicode_alt_encoding(self):
        test = u"some Ã±Ã¸Ã±Ã¥ÃÃ§Ã®Ã® text"
        md = hashlib.md5()
        enc = "Windows-1252"
        md.update(test.encode(enc))
        expected = md.hexdigest()
        received = utils.get_checksum(test, enc)
        self.assertEqual(expected, received)

    def test_get_checksum_from_binary(self):
        test = fakes.get_png_content()
        md = hashlib.md5()
        enc = "utf8"
        md.update(test)
        expected = md.hexdigest()
        received = utils.get_checksum(test)
        self.assertEqual(expected, received)

    def test_get_checksum_from_file(self):
        test = "some random text"
        md = hashlib.md5()
        md.update(test)
        expected = md.hexdigest()
        with utils.SelfDeletingTempfile() as tmp:
            with open(tmp, "w") as testfile:
                testfile.write(test)
            with open(tmp, "r") as testfile:
                received = utils.get_checksum(testfile)
        self.assertEqual(expected, received)

    def test_random_unicode(self):
        testlen = random.randint(50, 500)
        nm = utils.random_unicode(testlen)
        self.assertEqual(len(nm), testlen)

    def test_folder_size_bad_folder(self):
        self.assertRaises(exc.FolderNotFound, utils.folder_size,
                "/doesnt_exist")

    def test_folder_size_no_ignore(self):
        with utils.SelfDeletingTempDirectory() as tmpdir:
            # write 5 files of 100 bytes each
            for idx in six.moves.range(5):
                pth = os.path.join(tmpdir, "test%s" % idx)
                with open(pth, "w") as ff:
                    ff.write(FAKE_CONTENT)
            fsize = utils.folder_size(tmpdir)
        self.assertEqual(fsize, 500)

    def test_folder_size_ignore_string(self):
        with utils.SelfDeletingTempDirectory() as tmpdir:
            # write 5 files of 100 bytes each
            for idx in six.moves.range(5):
                pth = os.path.join(tmpdir, "test%s" % idx)
                with open(pth, "w") as ff:
                    ff.write(FAKE_CONTENT)
            # ignore one file
            fsize = utils.folder_size(tmpdir, ignore="*2")
        self.assertEqual(fsize, 400)

    def test_folder_size_ignore_list(self):
        with utils.SelfDeletingTempDirectory() as tmpdir:
            # write 5 files of 100 bytes each
            for idx in six.moves.range(5):
                pth = os.path.join(tmpdir, "test%s" % idx)
                with open(pth, "w") as ff:
                    ff.write(FAKE_CONTENT)
            # ignore odd files
            ignore = ["*1", "*3"]
            fsize = utils.folder_size(tmpdir, ignore=ignore)
        self.assertEqual(fsize, 300)

    def test_add_method(self):
        def fake_method(self):
            pass
        obj = fakes.FakeEntity()
        utils.add_method(obj, fake_method, "fake_name")
        self.assertTrue(hasattr(obj, "fake_name"))
        self.assertTrue(callable(obj.fake_name))

    def test_add_method_no_name(self):
        def fake_method(self):
            pass
        obj = fakes.FakeEntity()
        utils.add_method(obj, fake_method)
        self.assertTrue(hasattr(obj, "fake_method"))
        self.assertTrue(callable(obj.fake_method))

    def test_case_insensitive_update(self):
        k1 = utils.random_ascii()
        k2 = utils.random_ascii()
        k2up = k2.upper()
        k3 = utils.random_ascii()
        d1 = {k1: "fake", k2up: "fake"}
        d2 = {k2: "NEW", k3: "NEW"}
        expected = {k1: "fake", k2up: "NEW", k3: "NEW"}
        utils.case_insensitive_update(d1, d2)
        self.assertEqual(d1, expected)

    def test_env(self):
        args = ("foo", "bar")
        ret = utils.env(*args)
        self.assertFalse(ret)
        os.environ["bar"] = "test"
        ret = utils.env(*args)
        self.assertEqual(ret, "test")

    def test_unauthenticated(self):
        def dummy():
            pass
        utils.unauthenticated(dummy)
        self.assertTrue(hasattr(dummy, "unauthenticated"))

    def test_isunauthenticated(self):
        def dummy():
            pass
        self.assertFalse(utils.isunauthenticated(dummy))
        utils.unauthenticated(dummy)
        self.assertTrue(utils.isunauthenticated(dummy))

    def test_safe_issubclass_good(self):
        ret = utils.safe_issubclass(fakes.FakeIdentity,
                base_identity.BaseIdentity)
        self.assertTrue(ret)

    def test_safe_issubclass_bad(self):
        fake = fakes.FakeEntity()
        ret = utils.safe_issubclass(fake, None)
        self.assertFalse(ret)

    def test_slugify(self):
        test = "SAMPLE test_with-hyphen"
        expected = u"sample-test_with-hyphen"
        ret = utils.slugify(test)
        self.assertEqual(ret, expected)

    def test_wait_until(self):
        status_obj = fakes.FakeStatusChanger()
        self.assertRaises(exc.NoReloadError, utils.wait_until, status_obj,
                "status", "available")
        status_obj.manager = fakes.FakeManager()
        status_obj.manager.get = Mock(return_value=status_obj)
        status_obj.get = status_obj.manager.get
        sav_out = sys.stdout
        out = StringIO.StringIO()
        sys.stdout = out
        ret = utils.wait_until(status_obj, "status", "ready", interval=0.00001,
                verbose=True, verbose_atts="progress")
        self.assertTrue(isinstance(ret, fakes.FakeStatusChanger))
        self.assertEqual(ret.status, "ready")
        self.assertTrue(len(out.getvalue()) > 0)
        sys.stdout = sav_out

    def test_wait_until_fail(self):
        status_obj = fakes.FakeStatusChanger()
        self.assertRaises(exc.NoReloadError, utils.wait_until, status_obj,
                "status", "available")
        status_obj.manager = fakes.FakeManager()
        status_obj.manager.get = Mock(return_value=status_obj)
        status_obj.get = status_obj.manager.get
        ret = utils.wait_until(status_obj, "status", "fake", interval=0.00001,
                attempts=2)
        self.assertFalse(ret.status == "fake")

    def test_wait_until_callback(self):
        cback = Mock()
        status_obj = fakes.FakeStatusChanger()
        status_obj.manager = fakes.FakeManager()
        status_obj.manager.get = Mock(return_value=status_obj)
        status_obj.get = status_obj.manager.get
        thread = utils.wait_until(obj=status_obj, att="status", desired="ready",
                interval=0.00001, callback=cback)
        thread.join()
        cback.assert_called_once_with(status_obj)

    def test_wait_for_build(self):
        sav = utils.wait_until
        utils.wait_until = Mock()
        obj = fakes.FakeEntity()
        att = utils.random_unicode()
        desired = utils.random_unicode()
        callback = utils.random_unicode()
        interval = utils.random_unicode()
        attempts = utils.random_unicode()
        verbose = utils.random_unicode()
        verbose_atts = utils.random_unicode()
        utils.wait_for_build(obj, att, desired, callback, interval, attempts,
                verbose, verbose_atts)
        utils.wait_until.assert_called_once_with(obj, att, desired,
                callback=callback, interval=interval, attempts=attempts,
                verbose=verbose, verbose_atts=verbose_atts)
        utils.wait_until = sav

    def test_time_string_empty(self):
        testval = None
        self.assertEqual(utils.iso_time_string(testval), "")

    def test_time_string_invalid(self):
        testval = "abcde"
        self.assertRaises(exc.InvalidDateTimeString, utils.iso_time_string,
                testval)

    def test_time_string_date(self):
        dt = "1999-12-31"
        iso = utils.iso_time_string(dt)
        self.assertEqual(iso, "1999-12-31T00:00:00")

    def test_time_string_date_obj(self):
        dt = datetime.date(1999, 12, 31)
        self.assertEqual(utils.iso_time_string(dt), "1999-12-31T00:00:00")

    def test_time_string_datetime(self):
        dt = "1999-12-31 23:59:59"
        self.assertEqual(utils.iso_time_string(dt), "1999-12-31T23:59:59")

    def test_time_string_datetime_add_tz(self):
        dt = "1999-12-31 23:59:59"
        self.assertEqual(utils.iso_time_string(dt, show_tzinfo=True),
                "1999-12-31T23:59:59+0000")

    def test_time_string_datetime_show_tz(self):

        class TZ(datetime.tzinfo):
            def utcoffset(self, dt):
                return datetime.timedelta(minutes=-120)

        dt = datetime.datetime(1999, 12, 31, 23, 59, 59, tzinfo=TZ())
        self.assertEqual(utils.iso_time_string(dt, show_tzinfo=True),
                "1999-12-31T23:59:59-0200")

    def test_time_string_datetime_hide_tz(self):

        class TZ(datetime.tzinfo):
            def utcoffset(self, dt):
                return datetime.timedelta(minutes=-120)

        dt = datetime.datetime(1999, 12, 31, 23, 59, 59, tzinfo=TZ())
        self.assertEqual(utils.iso_time_string(dt, show_tzinfo=False),
                "1999-12-31T23:59:59")

    def test_rfc2822_format(self):
        now = datetime.datetime.now()
        now_year = str(now.year)
        fmtd = utils.rfc2822_format(now)
        self.assertTrue(now_year in fmtd)

    def test_rfc2822_format_str(self):
        now = str(datetime.datetime.now())
        fmtd = utils.rfc2822_format(now)
        self.assertEqual(fmtd, now)

    def test_rfc2822_format_fail(self):
        now = {}
        fmtd = utils.rfc2822_format(now)
        self.assertEqual(fmtd, now)

    def test_dict_to_qs(self):
        k1 = utils.random_unicode()
        v1 = utils.random_unicode()
        k2 = utils.random_unicode()
        v2 = None
        k3 = utils.random_unicode()
        v3 = utils.random_unicode()
        dct = {k1: v1, k2: v2, k3: v3}
        qs = utils.dict_to_qs(dct)
        self.assertTrue("%s=%s" % (k1, v1) in qs)
        self.assertFalse("%s=%s" % (k2, v2) in qs)
        self.assertTrue("%s=%s" % (k3, v3) in qs)

    def test_match_pattern(self):
        ignore_pat = "*.bad"
        self.assertTrue(utils.match_pattern("some.bad", ignore_pat))
        self.assertFalse(utils.match_pattern("some.good", ignore_pat))

    def test_get_id(self):
        target = utils.random_unicode()

        class ObjWithID(object):
            id = target

        obj = ObjWithID()
        self.assertEqual(utils.get_id(obj), target)
        self.assertEqual(utils.get_id(obj.id), target)
        plain = object()
        self.assertEqual(utils.get_id(plain), plain)

    def test_get_name(self):
        nm = utils.random_unicode()

        class ObjWithName(object):
            name = nm

        obj = ObjWithName()
        self.assertEqual(utils.get_name(obj), nm)
        self.assertEqual(utils.get_name(obj.name), nm)
        self.assertRaises(exc.MissingName, utils.get_name, object())

    def test_params_to_dict(self):
        dct = {}
        k1 = utils.random_unicode()
        k2 = utils.random_unicode()
        k3 = utils.random_unicode()
        k4 = utils.random_unicode()
        v1 = utils.random_unicode()
        v2 = utils.random_unicode()
        v3 = utils.random_unicode()
        local = {k1: v1, k2: v2, k3: v3}
        params = [k2, k3, k4]
        expected = {k2: v2, k3: v3}
        utils.params_to_dict(params, dct, local)
        self.assertEqual(dct, expected)

    def test_import_class(self):
        cls_string = "pyrax.utils.SelfDeletingTempfile"
        ret = utils.import_class(cls_string)
        self.assertTrue(ret is utils.SelfDeletingTempfile)

    def test_update_exc(self):
        msg1 = utils.random_unicode()
        msg2 = utils.random_unicode()
        err = exc.PyraxException(400)
        err.message = msg1
        sep = random.choice(("!", "@", "#", "$"))
        exp = "%s%s%s" % (msg2, sep, msg1)
        ret = utils.update_exc(err, msg2, before=True, separator=sep)
        self.assertEqual(ret.message, exp)
        err = exc.PyraxException(400)
        err.message = msg1
        sep = random.choice(("!", "@", "#", "$"))
        exp = "%s%s%s" % (msg1, sep, msg2)
        ret = utils.update_exc(err, msg2, before=False, separator=sep)
        self.assertEqual(ret.message, exp)


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
