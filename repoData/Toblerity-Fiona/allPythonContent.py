__FILENAME__ = benchmark-max

import timeit
from fiona import collection
from osgeo import ogr

PATH = 'docs/data/test_uk.shp'
NAME = 'test_uk'

# Fiona
s = """
with collection(PATH, "r") as c:
    for f in c:
        id = f["id"]
"""
t = timeit.Timer(
    stmt=s,
    setup='from __main__ import collection, PATH, NAME'
    )
print "Fiona 0.5"
print "%.2f usec/pass" % (1000000 * t.timeit(number=1000)/1000)
print

# OGR
s = """
source = ogr.Open(PATH)
layer = source.GetLayerByName(NAME)

schema = []
ldefn = layer.GetLayerDefn()
for n in range(ldefn.GetFieldCount()):
    fdefn = ldefn.GetFieldDefn(n)
    schema.append((fdefn.name, fdefn.type))

for feature in layer:
    id = feature.GetFID()
    props = {}
    for i in range(feature.GetFieldCount()):
        props[schema[i][0]] = feature.GetField(i)
    
    coordinates = []
    for part in feature.GetGeometryRef():
        ring = []
        for i in range(part.GetPointCount()):
            xy = part.GetPoint(i)
            ring.append(xy)
        coordinates.append(ring)

source.Destroy()
"""
print "osgeo.ogr 1.7.2 (maximum)"
t = timeit.Timer(
    stmt=s,
    setup='from __main__ import ogr, PATH, NAME'
    )
print "%.2f usec/pass" % (1000000 * t.timeit(number=1000)/1000)


########NEW FILE########
__FILENAME__ = benchmark-min

import timeit
from fiona import collection
from osgeo import ogr

PATH = 'docs/data/test_uk.shp'
NAME = 'test_uk'

# Fiona
s = """
with collection(PATH, "r") as c:
    for f in c:
        id = f["id"]
"""
t = timeit.Timer(
    stmt=s,
    setup='from __main__ import collection, PATH, NAME'
    )
print "Fiona 0.5"
print "%.2f usec/pass" % (1000000 * t.timeit(number=1000)/1000)
print

# OGR
s = """
source = ogr.Open(PATH)
layer = source.GetLayerByName(NAME)
for feature in layer:
    id = feature.GetFID()
source.Destroy()
"""
print "osgeo.ogr 1.7.2 (minimum)"
t = timeit.Timer(
    stmt=s,
    setup='from __main__ import ogr, PATH, NAME'
    )
print "%.2f usec/pass" % (1000000 * t.timeit(number=1000)/1000)


########NEW FILE########
__FILENAME__ = benchmark

import timeit
from fiona import collection
from osgeo import ogr

PATH = 'docs/data/test_uk.shp'
NAME = 'test_uk'

# Fiona
s = """
with collection(PATH, "r") as c:
    for f in c:
        id = f["id"]
"""
t = timeit.Timer(
    stmt=s,
    setup='from __main__ import collection, PATH, NAME'
    )
print "Fiona 0.5"
print "%.2f usec/pass" % (1000000 * t.timeit(number=1000)/1000)
print

# OGR
s = """
source = ogr.Open(PATH)
layer = source.GetLayerByName(NAME)
schema = []
ldefn = layer.GetLayerDefn()
for n in range(ldefn.GetFieldCount()):
    fdefn = ldefn.GetFieldDefn(n)
    schema.append((fdefn.name, fdefn.type))
layer.ResetReading()
while 1:
    feature = layer.GetNextFeature()
    if not feature:
        break
    id = feature.GetFID()
    props = {}
    for i in range(feature.GetFieldCount()):
        props[schema[i][0]] = feature.GetField(i)
    geometry = feature.GetGeometryRef()
    feature.Destroy()
source.Destroy()
"""
print "osgeo.ogr 1.7.2"
t = timeit.Timer(
    stmt=s,
    setup='from __main__ import ogr, PATH, NAME'
    )
print "%.2f usec/pass" % (1000000 * t.timeit(number=1000)/1000)


########NEW FILE########
__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# Fiona documentation build configuration file, created by
# sphinx-quickstart on Mon Dec 26 12:16:26 2011.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import fiona
import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'Fiona'
copyright = u'2011, Sean Gillies'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = fiona.__version__
# The full version, including alpha/beta/rc tags.
release = fiona.__version__

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
#html_theme = 'default'
html_theme = 'sphinxdoc'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'Fionadoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'Fiona.tex', u'Fiona Documentation',
   u'Sean Gillies', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'fiona', u'Fiona Documentation',
     [u'Sean Gillies'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'Fiona', u'Fiona Documentation',
   u'Sean Gillies', 'Fiona', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'


# -- Options for Epub output ---------------------------------------------------

# Bibliographic Dublin Core info.
epub_title = u'Fiona'
epub_author = u'Sean Gillies'
epub_publisher = u'Sean Gillies'
epub_copyright = u'2011, Sean Gillies'

# The language of the text. It defaults to the language option
# or en if the language is not set.
#epub_language = ''

# The scheme of the identifier. Typical schemes are ISBN or URL.
#epub_scheme = ''

# The unique identifier of the text. This can be a ISBN number
# or the project homepage.
#epub_identifier = ''

# A unique identification for the text.
#epub_uid = ''

# A tuple containing the cover image and cover page html template filenames.
#epub_cover = ()

# HTML files that should be inserted before the pages created by sphinx.
# The format is a list of tuples containing the path and title.
#epub_pre_files = []

# HTML files shat should be inserted after the pages created by sphinx.
# The format is a list of tuples containing the path and title.
#epub_post_files = []

# A list of files that should not be packed into the epub file.
#epub_exclude_files = []

# The depth of the table of contents in toc.ncx.
#epub_tocdepth = 3

# Allow duplicate toc entries.
#epub_tocdup = True

########NEW FILE########
__FILENAME__ = open

import fiona

# This module contains examples of opening files to get feature collections in
# different ways.
#
# It is meant to be run from the distribution root, the directory containing
# setup.py.
#
# A ``path`` is always the ``open()`` function's first argument. It can be
# absolute or relative to the working directory. It is the only positional
# argument, though it is conventional to use the mode as a 2nd positional
# argument.

# 1. Opening a file with a single data layer (shapefiles, etc).
#
# args: path, mode
# kwds: none
#
# The relative path to a file on the filesystem is given and its single layer
# is selected implicitly (a shapefile has a single layer). The file is opened
# for reading (mode 'r'), but since this is the default, we'll omit it in
# following examples.

with fiona.open('docs/data/test_uk.shp', 'r') as c:
    assert len(c) == 48

# 2. Opening a file with explicit layer selection (FileGDB, etc).
#
# args: path
# kwds: layer
#
# Same as above but layer specified explicitly by name..

with fiona.open('docs/data/test_uk.shp', layer='test_uk') as c:
    assert len(c) == 48

# 3. Opening a directory for access to a single file.
#
# args: path
# kwds: layer
#
# Same as above but using the path to the directory containing the shapefile,
# specified explicitly by name.

with fiona.open('docs/data', layer='test_uk') as c:
    assert len(c) == 48

# 4. Opening a single file within a zip archive.
#
# args: path
# kwds: vfs
#
# Open a file given its absolute path within a virtual filesystem. The VFS
# is given an Apache Commons VFS identifier. It may contain either an absolute
# path or a path relative to the working directory.
#
# Example archive:
#
# $ unzip -l docs/data/test_uk.zip
# Archive:  docs/data/test_uk.zip
#   Length     Date   Time    Name
#  --------    ----   ----    ----
#     10129  04-08-13 20:49   test_uk.dbf
#       143  04-08-13 20:49   test_uk.prj
#     65156  04-08-13 20:49   test_uk.shp
#       484  04-08-13 20:49   test_uk.shx
#  --------                   -------
#     75912                   4 files

with fiona.open('/test_uk.shp', vfs='zip://docs/data/test_uk.zip') as c:
    assert len(c) == 48

# 5. Opening a directory within a zip archive to select a layer.
#
# args: path
# kwds: layer, vfs
#
# The most complicated case. As above, but specifying the root directory within
# the virtual filesystem as the path and the layer by name (combination of
# 4 and 3). It ought to be possible to open a file geodatabase within a zip
# file like this.

with fiona.open('/', layer='test_uk', vfs='zip://docs/data/test_uk.zip') as c:
    assert len(c) == 48


########NEW FILE########
__FILENAME__ = orient-ccw
# An example of flipping feature polygons right side up.

import datetime
import logging
import sys

import fiona


logging.basicConfig(stream=sys.stderr, level=logging.INFO)

def signed_area(coords):
    """Return the signed area enclosed by a ring using the linear time
    algorithm at http://www.cgafaq.info/wiki/Polygon_Area. A value >= 0
    indicates a counter-clockwise oriented ring.
    """
    xs, ys = map(list, zip(*coords))
    xs.append(xs[1])
    ys.append(ys[1]) 
    return sum(xs[i]*(ys[i+1]-ys[i-1]) for i in range(1, len(coords)))/2.0


with fiona.open('docs/data/test_uk.shp', 'r') as source:
    
    # Copy the source schema and add two new properties.
    schema = source.schema.copy()
    schema['properties']['s_area'] = 'float'
    schema['properties']['timestamp'] = 'str'
    
    # Create a sink for processed features with the same format and 
    # coordinate reference system as the source.
    with fiona.open(
            'oriented-ccw.shp', 'w',
            driver=source.driver,
            schema=schema,
            crs=source.crs
            ) as sink:
        
        for f in source:
            
            try:

                # If any feature's polygon is facing "down" (has rings
                # wound clockwise), its rings will be reordered to flip
                # it "up".
                g = f['geometry']
                assert g['type'] == 'Polygon'
                rings = g['coordinates']
                sa = sum(signed_area(r) for r in rings)
                if sa < 0.0:
                    rings = [r[::-1] for r in rings]
                    g['coordinates'] = rings
                    f['geometry'] = g

                # Add the signed area of the polygon and a timestamp
                # to the feature properties map.
                f['properties'].update(
                    s_area=sa,
                    timestamp=datetime.datetime.now().isoformat() )

                sink.write(f)
            
            except Exception, e:
                logging.exception("Error processing feature %s:", f['id'])


########NEW FILE########
__FILENAME__ = with-descartes-functional
# Making maps with reduce()

from matplotlib import pyplot
from descartes import PolygonPatch
import fiona

BLUE = '#6699cc'

def render(fig, rec):
    """Given matplotlib axes and a record, adds the record as a patch
    and returns the axes so that reduce() can accumulate more
    patches."""
    fig.gca().add_patch(
        PolygonPatch(rec['geometry'], fc=BLUE, ec=BLUE, alpha=0.5, zorder=2))
    return fig

with fiona.open('docs/data/test_uk.shp', 'r') as source:
    fig = reduce(render, source, pyplot.figure(figsize=(8, 8)))
    fig.gca().autoscale(tight=False)
    fig.savefig('with-descartes-functional.png')


########NEW FILE########
__FILENAME__ = with-descartes

import subprocess

from matplotlib import pyplot
from descartes import PolygonPatch

import fiona

# Set up the figure and axes.
BLUE = '#6699cc'
fig = pyplot.figure(1, figsize=(6, 6), dpi=90)
ax = fig.add_subplot(111)

with fiona.drivers():

    # For each feature in the collection, add a patch to the axes.
    with fiona.open('docs/data/test_uk.shp', 'r') as input:
        for f in input:
            ax.add_patch(
                PolygonPatch(
                    f['geometry'], fc=BLUE, ec=BLUE, alpha=0.5, zorder=2 ))

# Should be able to get extents from the collection in a future version
# of Fiona.
ax.set_xlim(-9.25, 2.75)
ax.set_ylim(49.5, 61.5)

fig.savefig('test_uk.png')

subprocess.call(['open', 'test_uk.png'])

########NEW FILE########
__FILENAME__ = with-pyproj

import logging
import sys

from pyproj import Proj, transform

import fiona
from fiona.crs import from_epsg

logging.basicConfig(stream=sys.stderr, level=logging.INFO)

with fiona.open('docs/data/test_uk.shp', 'r') as source:
    
    sink_schema = source.schema.copy()
    p_in = Proj(source.crs)

    with fiona.open(
            'with-pyproj.shp', 'w',
            crs=from_epsg(27700),
            driver=source.driver,
            schema=sink_schema,
            ) as sink:
        
        p_out = Proj(sink.crs)

        for f in source:
            
            try:
                assert f['geometry']['type'] == "Polygon"
                new_coords = []
                for ring in f['geometry']['coordinates']:
                    x2, y2 = transform(p_in, p_out, *zip(*ring))
                    new_coords.append(zip(x2, y2))
                f['geometry']['coordinates'] = new_coords
                sink.write(f)
            
            except Exception, e:
                # Writing uncleanable features to a different shapefile
                # is another option.
                logging.exception("Error transforming feature %s:", f['id'])


########NEW FILE########
__FILENAME__ = with-shapely

import logging
import sys

from shapely.geometry import mapping, shape

import fiona

logging.basicConfig(stream=sys.stderr, level=logging.INFO)

with fiona.open('docs/data/test_uk.shp', 'r') as source:
    
    # **source.meta is a shortcut to get the crs, driver, and schema
    # keyword arguments from the source Collection.
    with fiona.open(
            'with-shapely.shp', 'w',
            **source.meta) as sink:
        
        for f in source:
            
            try:
                geom = shape(f['geometry'])
                if not geom.is_valid:
                    clean = geom.buffer(0.0)
                    assert clean.is_valid
                    assert clean.geom_type == 'Polygon'
                    geom = clean
                f['geometry'] = mapping(geom)
                sink.write(f)
            
            except Exception, e:
                # Writing uncleanable features to a different shapefile
                # is another option.
                logging.exception("Error cleaning feature %s:", f['id'])


########NEW FILE########
__FILENAME__ = collection
# -*- coding: utf-8 -*-
# Collections provide file-like access to feature data

import os
import sys

from fiona.ogrext import Iterator, Session, WritingSession
from fiona.errors import DriverError, SchemaError, CRSError
from fiona._drivers import driver_count, GDALEnv
from six import string_types

class Collection(object):

    """A file-like interface to features in the form of GeoJSON-like
    mappings."""

    def __init__(
            self, path, mode='r', 
            driver=None, schema=None, crs=None, 
            encoding=None,
            layer=None,
            vsi=None,
            archive=None,
            **kwargs):
        
        """The required ``path`` is the absolute or relative path to
        a file, such as '/data/test_uk.shp'. In ``mode`` 'r', data can
        be read only. In ``mode`` 'a', data can be appended to a file.
        In ``mode`` 'w', data overwrites the existing contents of
        a file.
        
        In ``mode`` 'w', an OGR ``driver`` name and a ``schema`` are
        required. A Proj4 ``crs`` string is recommended.
        
        In 'w' mode, kwargs will be mapped to OGR layer creation
        options.
        """
        if not isinstance(path, string_types):
            raise TypeError("invalid path: %r" % path)
        if not isinstance(mode, string_types) or mode not in ('r', 'w', 'a'):
            raise TypeError("invalid mode: %r" % mode)
        if driver and not isinstance(driver, string_types):
            raise TypeError("invalid driver: %r" % driver)
        if schema and not hasattr(schema, 'get'):
            raise TypeError("invalid schema: %r" % schema)
        if crs and not hasattr(crs, 'get'):
            raise TypeError("invalid schema: %r" % crs)
        if encoding and not isinstance(encoding, string_types):
            raise TypeError("invalid encoding: %r" % encoding)
        if layer and not isinstance(layer, tuple(list(string_types) + [int])):
            raise TypeError("invalid name: %r" % layer)
        if vsi:
            if not isinstance(vsi, string_types) or vsi not in ('zip', 'tar', 'gzip'):
                raise TypeError("invalid vsi: %r" % vsi)
        if archive and not isinstance(archive, string_types):
            raise TypeError("invalid archive: %r" % archive)

        self.session = None
        self.iterator = None
        self._len = 0
        self._bounds = None
        self._driver = None
        self._schema = None
        self._crs = None
        self.env = None
        
        self.path = vsi_path(path, vsi, archive)
        
        if mode == 'w':
            if layer and not isinstance(layer, string_types):
                raise ValueError("in 'r' mode, layer names must be strings")
            if driver == 'GeoJSON':
                if layer is not None:
                    raise ValueError("the GeoJSON format does not have layers")
                self.name = 'OgrGeoJSON'
            # TODO: raise ValueError as above for other single-layer formats.
            else:
                self.name = layer or os.path.basename(os.path.splitext(path)[0])
        else:
            if layer in (0, None):
                self.name = 0
            else:
                self.name = layer or os.path.basename(os.path.splitext(path)[0])
        
        self.mode = mode
        
        if self.mode == 'w':
            if not driver:
                raise DriverError("no driver")
            elif driver not in supported_drivers:
                raise DriverError(
                    "unsupported driver: %r" % driver)
            elif self.mode not in supported_drivers[driver]:
                raise DriverError(
                    "unsupported mode: %r" % self.mode)
            self._driver = driver
            
            if not schema:
                raise SchemaError("no schema")
            elif 'properties' not in schema:
                raise SchemaError("schema lacks: properties")
            elif 'geometry' not in schema:
                raise SchemaError("schema lacks: geometry")
            self._schema = schema
            
            if crs:
                if 'init' in crs or 'proj' in crs:
                    self._crs = crs
                else:
                    raise CRSError("crs lacks init or proj parameter")
        
        if driver_count == 0:
            # create a local manager and enter
            self.env = GDALEnv(True)
        else:
            self.env = GDALEnv(False)
        self.env.__enter__()

        if self.mode == "r":
            self.encoding = encoding
            self.session = Session()
            self.session.start(self)
            
            # If encoding param is None, we'll use what the session
            # suggests.
            self.encoding = encoding or self.session.get_fileencoding().lower()

        elif self.mode in ("a", "w"):
            self.encoding = encoding
            self.session = WritingSession()
            self.session.start(self, **kwargs)
            self.encoding = encoding or self.session.get_fileencoding().lower()

        if self.session:
            self.guard_driver_mode()
        
    def __repr__(self):
        return "<%s Collection '%s', mode '%s' at %s>" % (
            self.closed and "closed" or "open",
            self.path + ":" + str(self.name),
            self.mode,
            hex(id(self)))

    def guard_driver_mode(self):
        driver = self.session.get_driver()
        if driver not in supported_drivers:
            raise DriverError("unsupported driver: %r" % driver)
        if self.mode not in supported_drivers[driver]:
            raise DriverError("unsupported mode: %r" % self.mode)

    @property
    def driver(self):
        """Returns the name of the proper OGR driver."""
        if not self._driver and self.mode in ("a", "r") and self.session:
            self._driver = self.session.get_driver()
        return self._driver

    @property 
    def schema(self):
        """Returns a mapping describing the data schema.
        
        The mapping has 'geometry' and 'properties' items. The former is a
        string such as 'Point' and the latter is an ordered mapping that
        follows the order of fields in the data file.
        """
        if not self._schema and self.mode in ("a", "r") and self.session:
            self._schema = self.session.get_schema()
        return self._schema

    @property
    def crs(self):
        """Returns a Proj4 string."""
        if self._crs is None and self.mode in ("a", "r") and self.session:
            self._crs = self.session.get_crs()
        return self._crs

    @property
    def meta(self):
        """Returns a mapping with the driver, schema, and crs properties."""
        return {
            'driver': self.driver, 
            'schema': self.schema, 
            'crs': self.crs }

    def filter(self, bbox=None):
        """Returns an iterator over records, but filtered by a test for
        spatial intersection with the provided ``bbox``, a (minx, miny,
        maxx, maxy) tuple."""
        if self.closed:
            raise ValueError("I/O operation on closed collection")
        elif self.mode != 'r':
            raise IOError("collection not open for reading")
        self.iterator = Iterator(self, bbox)
        return self.iterator

    def __iter__(self):
        """Returns an iterator over records."""
        return self.filter()

    def __next__(self):
        """Returns next record from iterator."""
        if not self.iterator:
            iter(self)
        return next(self.iterator)

    next = __next__

    def writerecords(self, records):
        """Stages multiple records for writing to disk."""
        if self.closed:
            raise ValueError("I/O operation on closed collection")
        if self.mode not in ('a', 'w'):
            raise IOError("collection not open for writing")
        self.session.writerecs(records, self)
        self._len = self.session.get_length()
        self._bounds = self.session.get_extent()

    def write(self, record):
        """Stages a record for writing to disk."""
        self.writerecords([record])

    def validate_record(self, record):
        """Compares the record to the collection's schema.

        Returns ``True`` if the record matches, else ``False``.
        """
        # Currently we only compare keys of properties, not the types of
        # values.
        return set(record['properties'].keys()
            ) == set(self.schema['properties'].keys()
            ) and self.validate_record_geometry(record)

    def validate_record_geometry(self, record):
        """Compares the record's geometry to the collection's schema.

        Returns ``True`` if the record matches, else ``False``.
        """
        # Shapefiles welcome mixes of line/multis and polygon/multis.
        # OGR reports these mixed files as type "Polygon" or "LineString"
        # but will return either these or their multi counterparts when 
        # reading features.
        if (self.driver == "ESRI Shapefile" and 
                "Point" not in record['geometry']['type']):
            return record['geometry']['type'].lstrip(
                "Multi") == self.schema['geometry'].lstrip("3D ").lstrip(
                    "Multi")
        else:
            return (record['geometry']['type'] ==
                self.schema['geometry'].lstrip("3D "))

    def __len__(self):
        if self._len <= 0 and self.session is not None:
            self._len = self.session.get_length()
        return self._len

    @property
    def bounds(self):
        """Returns (minx, miny, maxx, maxy)."""
        if self._bounds is None and self.session is not None:
            self._bounds = self.session.get_extent()
        return self._bounds

    def flush(self):
        """Flush the buffer."""
        if self.session is not None and self.session.get_length() > 0:
            self.session.sync(self)
            new_len = self.session.get_length()
            self._len = new_len > self._len and new_len or self._len
            self._bounds = self.session.get_extent()

    def close(self):
        """In append or write mode, flushes data to disk, then ends
        access."""
        if self.session is not None: 
            if self.mode in ('a', 'w'):
                self.flush()
            self.session.stop()
            self.session = None
            self.iterator = None
        if self.env:
            self.env.__exit__()

    @property
    def closed(self):
        """``False`` if data can be accessed, otherwise ``True``."""
        return self.session is None

    def __enter__(self):
        return self

    def __exit__(self, type, value, traceback):
        self.close()

    def __del__(self):
        # Note: you can't count on this being called. Call close() explicitly
        # or use the context manager protocol ("with").
        self.__exit__(None, None, None)


def vsi_path(path, vsi=None, archive=None):
    # If a VSF and archive file are specified, we convert the path to
    # an OGR VSI path (see cpl_vsi.h).
    if vsi:
        if archive:
            result = "/vsi%s/%s%s" % (vsi, archive, path)
        else:
            result = "/vsi%s/%s" % (vsi, path)
    else:
        result = path
    return result


# Here is the list of available drivers as (name, modes) tuples. Currently,
# we only expose the defaults (excepting FileGDB). We also don't expose
# the CSV or GeoJSON drivers. Use Python's csv and json modules instead.
# Might still exclude a few more of these after making a pass through the
# entries for each at http://www.gdal.org/ogr/ogr_formats.html to screen
# out the multi-layer formats.

supported_drivers = dict([
#OGR Vector Formats
#Format Name 	Code 	Creation 	Georeferencing 	Compiled by default
#Aeronav FAA files 	AeronavFAA 	No 	Yes 	Yes
    ("AeronavFAA", "r"),
#ESRI ArcObjects 	ArcObjects 	No 	Yes 	No, needs ESRI ArcObjects
#Arc/Info Binary Coverage 	AVCBin 	No 	Yes 	Yes
# multi-layer
#   ("AVCBin", "r"),
#Arc/Info .E00 (ASCII) Coverage 	AVCE00 	No 	Yes 	Yes
# multi-layer
#    ("AVCE00", "r"),
#Arc/Info Generate 	ARCGEN 	No 	No 	Yes
    ("ARCGEN", "r"),
#Atlas BNA 	BNA 	Yes 	No 	Yes
    ("BNA", "raw"),
#AutoCAD DWG 	DWG 	No 	No 	No
#AutoCAD DXF 	DXF 	Yes 	No 	Yes
    ("DXF", "raw"),
#Comma Separated Value (.csv) 	CSV 	Yes 	No 	Yes
#CouchDB / GeoCouch 	CouchDB 	Yes 	Yes 	No, needs libcurl
#DODS/OPeNDAP 	DODS 	No 	Yes 	No, needs libdap
#EDIGEO 	EDIGEO 	No 	Yes 	Yes
# multi-layer? Hard to tell from the OGR docs
#   ("EDIGEO", "r"),
#ElasticSearch 	ElasticSearch 	Yes (write-only) 	- 	No, needs libcurl
#ESRI FileGDB 	FileGDB 	Yes 	Yes 	No, needs FileGDB API library
# multi-layer
    ("FileGDB", "raw"),
#ESRI Personal GeoDatabase 	PGeo 	No 	Yes 	No, needs ODBC library
#ESRI ArcSDE 	SDE 	No 	Yes 	No, needs ESRI SDE
#ESRI Shapefile 	ESRI Shapefile 	Yes 	Yes 	Yes
    ("ESRI Shapefile", "raw"),
#FMEObjects Gateway 	FMEObjects Gateway 	No 	Yes 	No, needs FME
#GeoJSON 	GeoJSON 	Yes 	Yes 	Yes
    ("GeoJSON", "rw"),
#GÃ©oconcept Export 	Geoconcept 	Yes 	Yes 	Yes
# multi-layers
#   ("Geoconcept", "raw"),
#Geomedia .mdb 	Geomedia 	No 	No 	No, needs ODBC library
#GeoRSS 	GeoRSS 	Yes 	Yes 	Yes (read support needs libexpat)
#Google Fusion Tables 	GFT 	Yes 	Yes 	No, needs libcurl
#GML 	GML 	Yes 	Yes 	Yes (read support needs Xerces or libexpat)
#GMT 	GMT 	Yes 	Yes 	Yes
    ("GMT", "raw"),
#GPSBabel 	GPSBabel 	Yes 	Yes 	Yes (needs GPSBabel and GPX driver)
#GPX 	GPX 	Yes 	Yes 	Yes (read support needs libexpat)
    ("GPX", "raw"),
#GRASS 	GRASS 	No 	Yes 	No, needs libgrass
#GPSTrackMaker (.gtm, .gtz) 	GPSTrackMaker 	Yes 	Yes 	Yes
    ("GPSTrackMaker", "raw"),
#Hydrographic Transfer Format 	HTF 	No 	Yes 	Yes
# TODO: Fiona is not ready for multi-layer formats: ("HTF", "r"),
#Idrisi Vector (.VCT) 	Idrisi 	No 	Yes 	Yes
    ("Idrisi", "r"),
#Informix DataBlade 	IDB 	Yes 	Yes 	No, needs Informix DataBlade
#INTERLIS 	"Interlis 1" and "Interlis 2" 	Yes 	Yes 	No, needs Xerces (INTERLIS model reading needs ili2c.jar)
#INGRES 	INGRES 	Yes 	No 	No, needs INGRESS
#KML 	KML 	Yes 	Yes 	Yes (read support needs libexpat)
#LIBKML 	LIBKML 	Yes 	Yes 	No, needs libkml
#Mapinfo File 	MapInfo File 	Yes 	Yes 	Yes
    ("MapInfo File", "raw"),
#Microstation DGN 	DGN 	Yes 	No 	Yes
    ("DGN", "raw"),
#Access MDB (PGeo and Geomedia capable) 	MDB 	No 	Yes 	No, needs JDK/JRE
#Memory 	Memory 	Yes 	Yes 	Yes
#MySQL 	MySQL 	No 	Yes 	No, needs MySQL library
#NAS - ALKIS 	NAS 	No 	Yes 	No, needs Xerces
#Oracle Spatial 	OCI 	Yes 	Yes 	No, needs OCI library
#ODBC 	ODBC 	No 	Yes 	No, needs ODBC library
#MS SQL Spatial 	MSSQLSpatial 	Yes 	Yes 	No, needs ODBC library
#Open Document Spreadsheet 	ODS 	Yes 	No 	No, needs libexpat
#OGDI Vectors (VPF, VMAP, DCW) 	OGDI 	No 	Yes 	No, needs OGDI library
#OpenAir 	OpenAir 	No 	Yes 	Yes
# multi-layer
#   ("OpenAir", "r"),
#PCI Geomatics Database File 	PCIDSK 	No 	No 	Yes, using internal PCIDSK SDK (from GDAL 1.7.0)
    ("PCIDSK", "r"),
#PDS 	PDS 	No 	Yes 	Yes
    ("PDS", "r"),
#PGDump 	PostgreSQL SQL dump 	Yes 	Yes 	Yes
#PostgreSQL/PostGIS 	PostgreSQL/PostGIS 	Yes 	Yes 	No, needs PostgreSQL client library (libpq)
#EPIInfo .REC 	REC 	No 	No 	Yes
#S-57 (ENC) 	S57 	No 	Yes 	Yes
# multi-layer
#   ("S57", "r"),
#SDTS 	SDTS 	No 	Yes 	Yes
# multi-layer
#   ("SDTS", "r"),
#SEG-P1 / UKOOA P1/90 	SEGUKOOA 	No 	Yes 	Yes
# multi-layers
#   ("SEGUKOOA", "r"),
#SEG-Y 	SEGY 	No 	No 	Yes
    ("SEGY", "r"),
#Norwegian SOSI Standard 	SOSI 	No 	Yes 	No, needs FYBA library
#SQLite/SpatiaLite 	SQLite 	Yes 	Yes 	No, needs libsqlite3 or libspatialite
#SUA 	SUA 	No 	Yes 	Yes
    ("SUA", "r"),
#SVG 	SVG 	No 	Yes 	No, needs libexpat
#UK .NTF 	UK. NTF 	No 	Yes 	Yes
# multi-layer
#   ("UK. NTF", "r"),
#U.S. Census TIGER/Line 	TIGER 	No 	Yes 	Yes
# multi-layer
#   ("TIGER", "r"),
#VFK data 	VFK 	No 	Yes 	Yes
# multi-layer
#   ("VFK", "r"),
#VRT - Virtual Datasource 	VRT 	No 	Yes 	Yes
# multi-layer
#   ("VRT", "r"),
#OGC WFS (Web Feature Service) 	WFS 	Yes 	Yes 	No, needs libcurl
#MS Excel format 	XLS 	No 	No 	No, needs libfreexl
#Office Open XML spreadsheet 	XLSX 	Yes 	No 	No, needs libexpat
#X-Plane/Flighgear aeronautical data 	XPLANE 	No 	Yes 	Yes
# multi-layer
#   ("XPLANE", "r") 
])


########NEW FILE########
__FILENAME__ = crs
# Coordinate reference systems and functions.
#
# PROJ.4 is the law of this land: http://proj.osgeo.org/. But whereas PROJ.4
# coordinate reference systems are described by strings of parameters such as
#
#   +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs
#
# here we use mappings:
#
#   {'proj': 'longlat', 'ellps': 'WGS84', 'datum': 'WGS84', 'no_defs': True}
#

from six import string_types

def to_string(crs):
    """Turn a parameter mapping into a more conventional PROJ.4 string.

    Mapping keys are tested against the ``all_proj_keys`` list. Values of
    ``True`` are omitted, leaving the key bare: {'no_defs': True} -> "+no_defs"
    and items where the value is otherwise not a str, int, or float are
    omitted.
    """
    items = []
    for k, v in sorted(filter(
            lambda x: x[0] in all_proj_keys and x[1] is not False and (
                isinstance(x[1], (bool, int, float)) or 
                isinstance(x[1], string_types)),
            crs.items() )):
        items.append(
            "+" + "=".join(
                map(str, filter(lambda y: y and y is not True, (k, v)))) )
    return " ".join(items)

def from_string(prjs):
    """Turn a PROJ.4 string into a mapping of parameters.

    Bare parameters like "+no_defs" are given a value of ``True``. All keys
    are checked against the ``all_proj_keys`` list.
    """
    parts = [o.lstrip('+') for o in prjs.strip().split()]
    def parse(v):
        try:
            return int(v)
        except ValueError:
            pass
        try:
            return float(v)
        except ValueError:
            return v
    items = map(
        lambda kv: len(kv) == 2 and (kv[0], parse(kv[1])) or (kv[0], True),
        (p.split('=') for p in parts) )
    return dict((k,v) for k, v in items if k in all_proj_keys)

def from_epsg(code):
    """Given an integer code, returns an EPSG-like mapping.

    Note: the input code is not validated against an EPSG database.
    """
    if int(code) <= 0:
        raise ValueError("EPSG codes are positive integers")
    return {'init': "epsg:%s" % code, 'no_defs': True}


# Below is the big list of PROJ4 parameters from
# http://trac.osgeo.org/proj/wiki/GenParms.
# It is parsed into a list of paramter keys ``all_proj_keys``.

_param_data = """
+a         Semimajor radius of the ellipsoid axis
+alpha     ? Used with Oblique Mercator and possibly a few others
+axis      Axis orientation (new in 4.8.0)
+b         Semiminor radius of the ellipsoid axis
+datum     Datum name (see `proj -ld`)
+ellps     Ellipsoid name (see `proj -le`)
+init      Initialize from a named CRS
+k         Scaling factor (old name)
+k_0       Scaling factor (new name)
+lat_0     Latitude of origin
+lat_1     Latitude of first standard parallel
+lat_2     Latitude of second standard parallel
+lat_ts    Latitude of true scale
+lon_0     Central meridian
+lonc      ? Longitude used with Oblique Mercator and possibly a few others
+lon_wrap  Center longitude to use for wrapping (see below)
+nadgrids  Filename of NTv2 grid file to use for datum transforms (see below)
+no_defs   Don't use the /usr/share/proj/proj_def.dat defaults file
+over      Allow longitude output outside -180 to 180 range, disables wrapping (see below)
+pm        Alternate prime meridian (typically a city name, see below)
+proj      Projection name (see `proj -l`)
+south     Denotes southern hemisphere UTM zone
+to_meter  Multiplier to convert map units to 1.0m
+towgs84   3 or 7 term datum transform parameters (see below)
+units     meters, US survey feet, etc.
+vto_meter vertical conversion to meters.
+vunits    vertical units.
+x_0       False easting
+y_0       False northing
+zone      UTM zone
+a         Semimajor radius of the ellipsoid axis
+alpha     ? Used with Oblique Mercator and possibly a few others
+azi
+b         Semiminor radius of the ellipsoid axis
+belgium
+beta
+czech
+e         Eccentricity of the ellipsoid = sqrt(1 - b^2/a^2) = sqrt( f*(2-f) )
+ellps     Ellipsoid name (see `proj -le`)
+es        Eccentricity of the ellipsoid squared
+f         Flattening of the ellipsoid (often presented as an inverse, e.g. 1/298)
+gamma
+geoc
+guam
+h
+k         Scaling factor (old name)
+K
+k_0       Scaling factor (new name)
+lat_0     Latitude of origin
+lat_1     Latitude of first standard parallel
+lat_2     Latitude of second standard parallel
+lat_b
+lat_t
+lat_ts    Latitude of true scale
+lon_0     Central meridian
+lon_1
+lon_2
+lonc      ? Longitude used with Oblique Mercator and possibly a few others
+lsat
+m
+M
+n
+no_cut
+no_off
+no_rot
+ns
+o_alpha
+o_lat_1
+o_lat_2
+o_lat_c
+o_lat_p
+o_lon_1
+o_lon_2
+o_lon_c
+o_lon_p
+o_proj
+over
+p
+path
+proj      Projection name (see `proj -l`)
+q
+R
+R_a
+R_A       Compute radius such that the area of the sphere is the same as the area of the ellipsoid
+rf        Reciprocal of the ellipsoid flattening term (e.g. 298)
+R_g
+R_h
+R_lat_a
+R_lat_g
+rot
+R_V
+s
+south     Denotes southern hemisphere UTM zone
+sym
+t
+theta
+tilt
+to_meter  Multiplier to convert map units to 1.0m
+units     meters, US survey feet, etc.
+vopt
+W
+westo
+x_0       False easting
+y_0       False northing
+zone      UTM zone
"""

_lines = filter(lambda x: len(x) > 1, _param_data.split("\n"))
all_proj_keys = list(
    set(line.split()[0].lstrip("+").strip() for line in _lines) 
    ) + ['no_mayo']


########NEW FILE########
__FILENAME__ = errors
class FionaValueError(ValueError):
    """Fiona-specific value errors"""

class DriverError(FionaValueError):
    """Encapsulates unsupported driver and driver mode errors."""

class SchemaError(FionaValueError):
    """When a schema mapping has no properties or no geometry."""

class CRSError(FionaValueError):
    """When a crs mapping has neither init or proj items."""

########NEW FILE########
__FILENAME__ = inspector

import code
import logging
import sys

import fiona


logging.basicConfig(stream=sys.stderr, level=logging.INFO)
logger = logging.getLogger('fiona.inspector')


def main(srcfile):
    
    with fiona.drivers(), fiona.open(srcfile) as src:
            
        code.interact(
            'Fiona %s Interactive Inspector (Python %s)\n'
            'Type "src.schema", "next(src)", or "help(src)" '
            'for more information.' %  (
                fiona.__version__, '.'.join(map(str, sys.version_info[:3]))),
            local=locals())

    return 1

if __name__ == '__main__':
    
    import argparse

    parser = argparse.ArgumentParser(
        prog="python -m fiona.inspector",
        description="Open a data file and drop into an interactive interpreter")
    parser.add_argument(
        'src', 
        metavar='FILE', 
        help="Input dataset file name")
    args = parser.parse_args()
    
    main(args.src)


########NEW FILE########
__FILENAME__ = odict
try:
    from collections import OrderedDict
except ImportError:    
    from ordereddict import OrderedDict

########NEW FILE########
__FILENAME__ = rfc3339
# Fiona's date and time is founded on RFC 3339.
#
# OGR knows 3 time "zones": GMT, "local time", amd "unknown". Fiona, when
# writing will convert times with a timezone offset to GMT (Z) and otherwise
# will write times with the unknown zone.

import datetime
import logging
import re

log = logging.getLogger("Fiona")

# Fiona's 'date', 'time', and 'datetime' types are sub types of 'str'.

class FionaDateType(str):
    """Dates without time."""

class FionaTimeType(str):
    """Times without dates."""

class FionaDateTimeType(str):
    """Dates and times."""

pattern_date = re.compile(r"(\d\d\d\d)(-)?(\d\d)(-)?(\d\d)")
pattern_time = re.compile(
    r"(\d\d)(:)?(\d\d)(:)?(\d\d)?(\.\d+)?(Z|([+-])?(\d\d)?(:)?(\d\d))?" )
pattern_datetime = re.compile(
    r"(\d\d\d\d)(-)?(\d\d)(-)?(\d\d)(T)?(\d\d)(:)?(\d\d)(:)?(\d\d)?(\.\d+)?(Z|([+-])?(\d\d)?(:)?(\d\d))?" )

class group_accessor(object):
    def __init__(self, m):
        self.match = m
    def group(self, i):
        try:
            return self.match.group(i) or 0
        except IndexError:
            return 0

def parse_time(s):
    """Given a RFC 3339 time, returns a tz-naive datetime tuple"""
    match = re.search(pattern_time, s)
    if match is None:
        raise ValueError("Time data '%s' does not match pattern" % s)
    g = group_accessor(match)
    log.debug("Match groups: %s", match.groups())
    return (0, 0, 0,
        int(g.group(1)), 
        int(g.group(3)), 
        int(g.group(5)), 
        1000000.0*float(g.group(6)) )

def parse_date(s):
    """Given a RFC 3339 date, returns a tz-naive datetime tuple"""
    match = re.search(pattern_date, s)
    if match is None:
        raise ValueError("Time data '%s' does not match pattern" % s)
    g = group_accessor(match)
    log.debug("Match groups: %s", match.groups())
    return (
        int(g.group(1)), 
        int(g.group(3)), 
        int(g.group(5)),
        0, 0, 0, 0.0 )

def parse_datetime(s):
    """Given a RFC 3339 datetime, returns a tz-naive datetime tuple"""
    match = re.search(pattern_datetime, s)
    if match is None:
        raise ValueError("Time data '%s' does not match pattern" % s)
    g = group_accessor(match)
    log.debug("Match groups: %s", match.groups())
    return (
        int(g.group(1)), 
        int(g.group(3)), 
        int(g.group(5)),
        int(g.group(7)), 
        int(g.group(9)), 
        int(g.group(11)), 
        1000000.0*float(g.group(12)) )


########NEW FILE########
__FILENAME__ = tool
""" fiona.tool

Converts Shapefiles (etc) to GeoJSON.
"""

import json
import logging
import pprint
import sys

from six.moves import map

import fiona


def open_output(arg):
    """Returns an opened output stream."""
    if arg == sys.stdout:
        return arg
    else:
        return open(arg, 'w')

def make_ld_context(context_items):
    """Returns a JSON-LD Context object. 
    
    See http://json-ld.org/spec/latest/json-ld."""
    ctx = {
        'type': '@type',
        'id': '@id',
        'FeatureCollection': '_:n1',
        '_crs': {'@id': '_:n2', '@type': '@id'},
        'bbox': 'http://geovocab.org/geometry#bbox',
        'features': '_:n3',
        'Feature': 'http://geovocab.org/spatial#Feature',
        'properties': '_:n4',
        'geometry': 'http://geovocab.org/geometry#geometry',
        'Point': 'http://geovocab.org/geometry#Point',
        'LineString': 'http://geovocab.org/geometry#LineString',
        'Polygon': 'http://geovocab.org/geometry#Polygon',
        'MultiPoint': 'http://geovocab.org/geometry#MultiPoint',
        'MultiLineString': 'http://geovocab.org/geometry#MultiLineString',
        'MultiPolygon': 'http://geovocab.org/geometry#MultiPolygon',
        'GeometryCollection': 
            'http://geovocab.org/geometry#GeometryCollection',
        'coordinates': '_:n5'}
    for item in context_items or []:
        t, uri = item.split("=")
        ctx[t.strip()] = uri.strip()
    return ctx

def crs_uri(crs):
    """Returns a CRS URN computed from a crs dict."""
    # References version 6.3 of the EPSG database.
    # TODO: get proper version from GDAL/OGR API?
    if crs['proj'] == 'longlat' and (
            crs['datum'] == 'WGS84' or crs['ellps'] == 'WGS84'):
        return 'urn:ogc:def:crs:OGC:1.3:CRS84'
    elif 'epsg:' in crs.get('init', ''):
        epsg, code = crs['init'].split(':')
        return 'urn:ogc:def:crs:EPSG::%s' % code
    else:
        return None

def id_record(rec):
    """Converts a record's id to a blank node id and returns the record."""
    rec['id'] = '_:f%s' % rec['id']
    return rec

def main(args, dump_kw, item_sep, ignore_errors):
    """Returns 0 on success, 1 on error, for sys.exit."""
    with fiona.drivers():
        
        with open_output(args.outfile) as sink:

            with fiona.open(args.infile) as source:

                meta = source.meta.copy()
                meta['fields'] = dict(source.schema['properties'].items())

                if args.description:
                    meta['name'] = args.infile
                    meta['schema']['properties'] = list(
                        source.schema['properties'].items())
                    json.dump(meta, sink, **dump_kw)
                
                elif args.record_buffered:
                    # Buffer GeoJSON data at the feature level for smaller
                    # memory footprint.

                    indented = bool(args.indent)
                    rec_indent = "\n" + " " * (2 * (args.indent or 0))

                    collection = {
                        'type': 'FeatureCollection',  
                        'fiona:schema': meta['schema'], 
                        'fiona:crs': meta['crs'],
                        '_crs': crs_uri(meta['crs']),
                        'features': [] }
                    if args.use_ld_context:
                        collection['@context'] = make_ld_context(
                            args.ld_context_items)
                    
                    head, tail = json.dumps(collection, **dump_kw).split('[]')
                    
                    sink.write(head)
                    sink.write("[")
                    
                    itr = iter(source)
                    
                    # Try the first record.
                    try:
                        i, first = 0, next(itr)
                        if args.use_ld_context:
                            first = id_record(first)
                        if indented:
                            sink.write(rec_indent)
                        sink.write(
                            json.dumps(first, **dump_kw
                                ).replace("\n", rec_indent))
                    except StopIteration:
                        pass
                    except Exception as exc:
                        # Ignoring errors is *not* the default.
                        if ignore_errors:
                            logger.error(
                                "failed to serialize file record %d (%s), "
                                "continuing",
                                i, exc)
                        else:
                            # Log error and close up the GeoJSON, leaving it
                            # more or less valid no matter what happens above.
                            logger.critical(
                                "failed to serialize file record %d (%s), "
                                "quiting",
                                i, exc)
                            sink.write("]")
                            sink.write(tail)
                            if indented:
                                sink.write("\n")
                            return 1
                    
                    # Because trailing commas aren't valid in JSON arrays
                    # we'll write the item separator before each of the
                    # remaining features.
                    for i, rec in enumerate(itr, 1):
                        try:
                            if args.use_ld_context:
                                rec = id_record(rec)
                            if indented:
                                sink.write(rec_indent)
                            sink.write(item_sep)
                            sink.write(
                                json.dumps(rec, **dump_kw
                                    ).replace("\n", rec_indent))
                        except Exception as exc:
                            if ignore_errors:
                                logger.error(
                                    "failed to serialize file record %d (%s), "
                                    "continuing",
                                    i, exc)
                            else:
                                logger.critical(
                                    "failed to serialize file record %d (%s), "
                                    "quiting",
                                    i, exc)
                                sink.write("]")
                                sink.write(tail)
                                if indented:
                                    sink.write("\n")
                                return 1
                    
                    # Close up the GeoJSON after writing all features.
                    sink.write("]")
                    sink.write(tail)
                    if indented:
                        sink.write("\n")

                else:
                    # Buffer GeoJSON data at the collection level. The default.
                    collection = {
                        'type': 'FeatureCollection', 
                        'fiona:schema': meta['schema'], 
                        'fiona:crs': meta['crs'],
                        '_crs': crs_uri(meta['crs']) }
                    if args.use_ld_context:
                        collection['@context'] = make_ld_context(
                            args.ld_context_items)
                        collection['features'] = list(map(id_record, source))
                    else:
                        collection['features'] = list(source)
                    json.dump(collection, sink, **dump_kw)

    return 0

if __name__ == '__main__':

    import argparse

    logging.basicConfig(stream=sys.stderr, level=logging.INFO)
    logger = logging.getLogger('fiona.tool')

    parser = argparse.ArgumentParser(
        description="Serialize a file's records or description to GeoJSON")
    
    parser.add_argument('infile', 
        help="input file name")
    parser.add_argument('outfile',
        nargs='?', 
        help="output file name, defaults to stdout if omitted", 
        default=sys.stdout)
    parser.add_argument('-d', '--description',
        action='store_true', 
        help="serialize file's data description (schema) only")
    parser.add_argument('-n', '--indent', 
        type=int,
        default=None,
        metavar='N',
        help="indentation level in N number of chars")
    parser.add_argument('--compact', 
        action='store_true',
        help="use compact separators (',', ':')")
    parser.add_argument('--encoding', 
        default=None,
        metavar='ENC',
        help="Specify encoding of the input file")
    parser.add_argument('--record-buffered',
        dest='record_buffered',
        action='store_true',
        help="Economical buffering of writes at record, not collection (default), level")
    parser.add_argument('--ignore-errors',
        dest='ignore_errors',
        action='store_true',
        help="log errors but do not stop serialization")
    parser.add_argument('--use-ld-context',
        dest='use_ld_context',
        action='store_true',
        help="add a JSON-LD context to JSON output")
    parser.add_argument('--add-ld-context-item',
        dest='ld_context_items',
        action='append',
        metavar='TERM=URI',
        help="map a term to a URI and add it to the output's JSON LD context")

    args = parser.parse_args()

    # Keyword args to be used in all following json.dump* calls.
    dump_kw = {'sort_keys': True}
    if args.indent:
        dump_kw['indent'] = args.indent
    if args.compact:
        dump_kw['separators'] = (',', ':')

    item_sep = args.compact and ',' or ', '
    ignore_errors = args.ignore_errors

    sys.exit(main(args, dump_kw, item_sep, ignore_errors))


########NEW FILE########
__FILENAME__ = test_bounds
import fiona

def test_bounds():
    with fiona.open("docs/data/test_uk.shp") as src:
        f = next(src)
        assert tuple(round(v, 6) for v in fiona.bounds(f)) == (
                                                         0.735,
                                                         51.357216,
                                                         0.947778,
                                                         51.444717)
        assert tuple(round(v, 6) for v in fiona.bounds(f['geometry'])) == (
                                                         0.735,
                                                         51.357216,
                                                         0.947778,
                                                         51.444717)

########NEW FILE########
__FILENAME__ = test_collection
# Testing collections and workspaces

import logging
import os
import shutil
import sys
import subprocess
import unittest
import tempfile

import fiona
from fiona.collection import Collection, supported_drivers
from fiona.errors import FionaValueError, DriverError, SchemaError, CRSError

logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)

TEMPDIR = tempfile.gettempdir()

class SupportedDriversTest(unittest.TestCase):
    def test_shapefile(self):
        self.failUnless("ESRI Shapefile" in supported_drivers)
        self.failUnlessEqual(
            set(supported_drivers["ESRI Shapefile"]), set("raw") )
    def test_map(self):
        self.failUnless("MapInfo File" in supported_drivers)
        self.failUnlessEqual(
            set(supported_drivers["MapInfo File"]), set("raw") )

class CollectionArgsTest(unittest.TestCase):
    def test_path(self):
        self.assertRaises(TypeError, Collection, (0))
    def test_mode(self):
        self.assertRaises(TypeError, Collection, ("foo"), mode=0)
    def test_driver(self):
        self.assertRaises(TypeError, Collection, ("foo"), mode='w', driver=1)
    def test_schema(self):
        self.assertRaises(
            TypeError, Collection, ("foo"), mode='w', 
            driver="ESRI Shapefile", schema=1)
    def test_crs(self):
        self.assertRaises(
            TypeError, Collection, ("foo"), mode='w', 
            driver="ESRI Shapefile", schema=0, crs=1)
    def test_encoding(self):
        self.assertRaises(
            TypeError, Collection, ("foo"), mode='r', 
            encoding=1)
    def test_layer(self):
        self.assertRaises(
            TypeError, Collection, ("foo"), mode='r', 
            layer=0.5)
    def test_vsi(self):
        self.assertRaises(
            TypeError, Collection, ("foo"), mode='r', 
            vsi='git')
    def test_archive(self):
        self.assertRaises(
            TypeError, Collection, ("foo"), mode='r', 
            archive=1)
    def test_write_numeric_layer(self):
        self.assertRaises(ValueError, Collection, ("foo"), mode='w', layer=1)
    def test_write_geojson_layer(self):
        self.assertRaises(ValueError, Collection, ("foo"), mode='w', driver='GeoJSON', layer='foo')
    def test_append_geojson(self):
        self.assertRaises(ValueError, Collection, ("foo"), mode='w', driver='ARCGEN')

class OpenExceptionTest(unittest.TestCase):
    def test_no_archive(self):
        self.assertRaises(IOError, fiona.open, ("/"), mode='r', vfs="zip:///foo.zip")

class ReadingTest(unittest.TestCase):
    
    def setUp(self):
        self.c = fiona.open("docs/data/test_uk.shp", "r")
    
    def tearDown(self):
        self.c.close()

    def test_open_repr(self):
        self.failUnlessEqual(
            repr(self.c),
            ("<open Collection 'docs/data/test_uk.shp:test_uk', mode 'r' "
            "at %s>" % hex(id(self.c))))

    def test_closed_repr(self):
        self.c.close()
        self.failUnlessEqual(
            repr(self.c),
            ("<closed Collection 'docs/data/test_uk.shp:test_uk', mode 'r' "
            "at %s>" % hex(id(self.c))))

    def test_path(self):
        self.failUnlessEqual(self.c.path, 'docs/data/test_uk.shp')

    def test_name(self):
        self.failUnlessEqual(self.c.name, 'test_uk')
    
    def test_mode(self):
        self.failUnlessEqual(self.c.mode, 'r')

    def test_collection(self):
        self.failUnlessEqual(self.c.encoding, 'iso-8859-1')

    def test_iter(self):
        self.failUnless(iter(self.c))
    
    def test_closed_no_iter(self):
        self.c.close()
        self.assertRaises(ValueError, iter, self.c)

    def test_len(self):
        self.failUnlessEqual(len(self.c), 48)
    
    def test_closed_len(self):
        # Len is lazy, it's never computed in this case. TODO?
        self.c.close()
        self.failUnlessEqual(len(self.c), 0)

    def test_len_closed_len(self):
        # Lazy len is computed in this case and sticks.
        len(self.c)
        self.c.close()
        self.failUnlessEqual(len(self.c), 48)
    
    def test_driver(self):
        self.failUnlessEqual(self.c.driver, "ESRI Shapefile")
    
    def test_closed_driver(self):
        self.c.close()
        self.failUnlessEqual(self.c.driver, None)

    def test_driver_closed_driver(self):
        self.c.driver
        self.c.close()
        self.failUnlessEqual(self.c.driver, "ESRI Shapefile")
    
    def test_schema(self):
        s = self.c.schema['properties']
        self.failUnlessEqual(s['CAT'], "float:16")
        self.failUnlessEqual(s['FIPS_CNTRY'], "str")

    def test_closed_schema(self):
        # Schema is lazy too, never computed in this case. TODO?
        self.c.close()
        self.failUnlessEqual(self.c.schema, None)

    def test_schema_closed_schema(self):
        self.c.schema
        self.c.close()
        self.failUnlessEqual(
            sorted(self.c.schema.keys()),
            ['geometry', 'properties'])

    def test_crs(self):
        crs = self.c.crs
        self.failUnlessEqual(crs['datum'], 'WGS84')
        self.failUnless(crs['no_defs'])

    def test_closed_crs(self):
        # Crs is lazy too, never computed in this case. TODO?
        self.c.close()
        self.failUnlessEqual(self.c.crs, None)

    def test_crs_closed_crs(self):
        self.c.crs
        self.c.close()
        self.failUnlessEqual(
            sorted(self.c.crs.keys()),
            ['datum', 'no_defs', 'proj'])

    def test_meta(self):
        self.failUnlessEqual(
            sorted(self.c.meta.keys()), 
            ['crs', 'driver', 'schema'])

    def test_bounds(self):
        self.failUnlessAlmostEqual(self.c.bounds[0], -8.621389, 6)
        self.failUnlessAlmostEqual(self.c.bounds[1], 49.911659, 6)
        self.failUnlessAlmostEqual(self.c.bounds[2], 1.749444, 6)
        self.failUnlessAlmostEqual(self.c.bounds[3], 60.844444, 6)

    def test_context(self):
        with fiona.open("docs/data/test_uk.shp", "r") as c:
            self.failUnlessEqual(c.name, 'test_uk')
            self.failUnlessEqual(len(c), 48)
        self.failUnlessEqual(c.closed, True)

    def test_iter_one(self):
        itr = iter(self.c)
        f = next(itr)
        self.failUnlessEqual(f['id'], "0")
        self.failUnlessEqual(f['properties']['FIPS_CNTRY'], 'UK')

    def test_iter_list(self):
        f = list(self.c)[0]
        self.failUnlessEqual(f['id'], "0")
        self.failUnlessEqual(f['properties']['FIPS_CNTRY'], 'UK')

    def test_re_iter_list(self):
        f = list(self.c)[0] # Run through iterator
        f = list(self.c)[0] # Run through a new, reset iterator
        self.failUnlessEqual(f['id'], "0")
        self.failUnlessEqual(f['properties']['FIPS_CNTRY'], 'UK')

    def test_no_write(self):
        self.assertRaises(IOError, self.c.write, {})

class FilterReadingTest(unittest.TestCase):
    def setUp(self):
        self.c = fiona.open("docs/data/test_uk.shp", "r")
    def tearDown(self):
        self.c.close()
    def test_filter_1(self):
        results = list(self.c.filter(bbox=(-15.0, 35.0, 15.0, 65.0)))
        self.failUnlessEqual(len(results), 48)
        f = results[0]
        self.failUnlessEqual(f['id'], "0")
        self.failUnlessEqual(f['properties']['FIPS_CNTRY'], 'UK')

class UnsupportedDriverTest(unittest.TestCase):
    
    def test_immediate_fail_driver(self):
        schema = {
            'geometry': 'Point', 
            'properties': {'label': 'str', u'verit\xe9': 'int'} }
        self.assertRaises(
            DriverError, 
            fiona.open, os.path.join(TEMPDIR, "foo"), "w", "Bogus", schema=schema)

class GenericWritingTest(unittest.TestCase):

    def setUp(self):
        self.tempdir = tempfile.mkdtemp()
        schema = {
            'geometry': 'Point', 
            'properties': [('label', 'str'), (u'verit\xe9', 'int')] }
        self.c = fiona.open(
                os.path.join(self.tempdir, "test-no-iter.shp"),
                "w", 
                "ESRI Shapefile", 
                schema=schema,
                encoding='Windows-1252')

    def tearDown(self):
        self.c.close()
        shutil.rmtree(self.tempdir)

    def test_encoding(self):
        self.assertEquals(self.c.encoding, 'Windows-1252')

    def test_no_iter(self):
        self.assertRaises(IOError, iter, self.c)

    def test_no_filter(self):
        self.assertRaises(IOError, self.c.filter)

class PointWritingTest(unittest.TestCase):

    def setUp(self):
        self.tempdir = tempfile.mkdtemp()
        self.sink = fiona.open(
            os.path.join(self.tempdir, "point_writing_test.shp"),
            "w",
            driver="ESRI Shapefile",
            schema={
                'geometry': 'Point', 
                'properties': [('title', 'str'), ('date', 'date')]},
            crs={'init': "epsg:4326", 'no_defs': True},
            encoding='utf-8')

    def tearDown(self):
        self.sink.close()
        shutil.rmtree(self.tempdir)

    def test_cpg(self):
        """Requires GDAL 1.9"""
        self.sink.close()
        self.failUnless(open(os.path.join(self.tempdir, "point_writing_test.cpg")).readline() == 'UTF-8')

    def test_write_one(self):
        self.failUnlessEqual(len(self.sink), 0)
        self.failUnlessEqual(self.sink.bounds, (0.0, 0.0, 0.0, 0.0))
        f = {
            'geometry': {'type': 'Point', 'coordinates': (0.0, 0.1)},
            'properties': {'title': 'point one', 'date': "2012-01-29"}}
        self.sink.writerecords([f])
        self.failUnlessEqual(len(self.sink), 1)
        self.failUnlessEqual(self.sink.bounds, (0.0, 0.1, 0.0, 0.1))

    def test_write_two(self):
        self.failUnlessEqual(len(self.sink), 0)
        self.failUnlessEqual(self.sink.bounds, (0.0, 0.0, 0.0, 0.0))
        f1 = {
            'geometry': {'type': 'Point', 'coordinates': (0.0, 0.1)},
            'properties': {'title': 'point one', 'date': "2012-01-29"}}
        f2 = {
            'geometry': {'type': 'Point', 'coordinates': (0.0, -0.1)},
            'properties': {'title': 'point two', 'date': "2012-01-29"}}
        self.sink.writerecords([f1, f2])
        self.failUnlessEqual(len(self.sink), 2)
        self.failUnlessEqual(self.sink.bounds, (0.0, -0.1, 0.0, 0.1))

    def test_write_one_null_geom(self):
        self.failUnlessEqual(len(self.sink), 0)
        self.failUnlessEqual(self.sink.bounds, (0.0, 0.0, 0.0, 0.0))
        f = {
            'geometry': None,
            'properties': {'title': 'point one', 'date': "2012-01-29"}}
        self.sink.writerecords([f])
        self.failUnlessEqual(len(self.sink), 1)
        self.failUnlessEqual(self.sink.bounds, (0.0, 0.0, 0.0, 0.0))

    def test_validate_record(self):
        fvalid = {
            'geometry': {'type': 'Point', 'coordinates': (0.0, 0.1)},
            'properties': {'title': 'point one', 'date': "2012-01-29"}}
        finvalid = {
            'geometry': {'type': 'Point', 'coordinates': (0.0, -0.1)},
            'properties': {'not-a-title': 'point two', 'date': "2012-01-29"}}
        self.assertTrue(self.sink.validate_record(fvalid))
        self.assertFalse(self.sink.validate_record(finvalid))

class LineWritingTest(unittest.TestCase):

    def setUp(self):
        self.tempdir = tempfile.mkdtemp()
        self.sink = fiona.open(
            os.path.join(self.tempdir, "line_writing_test.shp"),
            "w",
            driver="ESRI Shapefile",
            schema={
                'geometry': 'LineString', 
                'properties': [('title', 'str'), ('date', 'date')]},
            crs={'init': "epsg:4326", 'no_defs': True})

    def tearDown(self):
        self.sink.close()
        shutil.rmtree(self.tempdir)
    
    def test_write_one(self):
        self.failUnlessEqual(len(self.sink), 0)
        self.failUnlessEqual(self.sink.bounds, (0.0, 0.0, 0.0, 0.0))
        f = {
            'geometry': {'type': 'LineString', 
                         'coordinates': [(0.0, 0.1), (0.0, 0.2)]},
            'properties': {'title': 'line one', 'date': "2012-01-29"}}
        self.sink.writerecords([f])
        self.failUnlessEqual(len(self.sink), 1)
        self.failUnlessEqual(self.sink.bounds, (0.0, 0.1, 0.0, 0.2))

    def test_write_two(self):
        self.failUnlessEqual(len(self.sink), 0)
        self.failUnlessEqual(self.sink.bounds, (0.0, 0.0, 0.0, 0.0))
        f1 = {
            'geometry': {'type': 'LineString', 
                         'coordinates': [(0.0, 0.1), (0.0, 0.2)]},
            'properties': {'title': 'line one', 'date': "2012-01-29"}}
        f2 = {
            'geometry': {'type': 'MultiLineString', 
                         'coordinates': [
                            [(0.0, 0.0), (0.0, -0.1)], 
                            [(0.0, -0.1), (0.0, -0.2)] ]},
            'properties': {'title': 'line two', 'date': "2012-01-29"}}
        self.sink.writerecords([f1, f2])
        self.failUnlessEqual(len(self.sink), 2)
        self.failUnlessEqual(self.sink.bounds, (0.0, -0.2, 0.0, 0.2))

class PointAppendTest(unittest.TestCase):
    # Tests 3D shapefiles too
    def setUp(self):
        self.tempdir = tempfile.mkdtemp()
        with fiona.open("docs/data/test_uk.shp", "r") as input:
            output_schema = input.schema.copy()
            output_schema['geometry'] = '3D Point'
            with fiona.open(
                    os.path.join(self.tempdir, "test_append_point.shp"),
                    "w", crs=None, driver="ESRI Shapefile", schema=output_schema
                    ) as output:
                for f in input.filter(bbox=(-5.0, 55.0, 0.0, 60.0)):
                    f['geometry'] = {
                        'type': 'Point',
                        'coordinates': f['geometry']['coordinates'][0][0] }
                    output.write(f)

    def tearDown(self):
        shutil.rmtree(self.tempdir)

    def test_append_point(self):
        with fiona.open(os.path.join(self.tempdir, "test_append_point.shp"), "a") as c:
            self.assertEqual(c.schema['geometry'], '3D Point')
            c.write({'geometry': {'type': 'Point', 'coordinates': (0.0, 45.0)},
                     'properties': { 'FIPS_CNTRY': 'UK', 
                                     'AREA': 0.0, 
                                     'CAT': 1.0, 
                                     'POP_CNTRY': 0, 
                                     'CNTRY_NAME': u'Foo'} })
            self.assertEqual(len(c), 8)

class LineAppendTest(unittest.TestCase):

    def setUp(self):
        self.tempdir = tempfile.mkdtemp()
        with fiona.open(
                os.path.join(self.tempdir, "test_append_line.shp"),
                "w",
                driver="ESRI Shapefile",
                schema={
                    'geometry': 'MultiLineString', 
                    'properties': {'title': 'str', 'date': 'date'}},
                crs={'init': "epsg:4326", 'no_defs': True}) as output:
            f = {'geometry': {'type': 'MultiLineString', 
                              'coordinates': [[(0.0, 0.1), (0.0, 0.2)]]},
                'properties': {'title': 'line one', 'date': "2012-01-29"}}
            output.writerecords([f])

    def tearDown(self):
        shutil.rmtree(self.tempdir)

    def test_append_line(self):
        with fiona.open(os.path.join(self.tempdir, "test_append_line.shp"), "a") as c:
            self.assertEqual(c.schema['geometry'], 'LineString')
            f1 = {
                'geometry': {'type': 'LineString', 
                             'coordinates': [(0.0, 0.1), (0.0, 0.2)]},
                'properties': {'title': 'line one', 'date': "2012-01-29"}}
            f2 = {
                'geometry': {'type': 'MultiLineString', 
                             'coordinates': [
                                [(0.0, 0.0), (0.0, -0.1)], 
                                [(0.0, -0.1), (0.0, -0.2)] ]},
                'properties': {'title': 'line two', 'date': "2012-01-29"}}
            c.writerecords([f1, f2])
            self.failUnlessEqual(len(c), 3)
            self.failUnlessEqual(c.bounds, (0.0, -0.2, 0.0, 0.2))

class ShapefileFieldWidthTest(unittest.TestCase):
    
    def test_text(self):
        self.tempdir = tempfile.mkdtemp()
        with fiona.open(os.path.join(self.tempdir, "textfield.shp"), "w",
                driver="ESRI Shapefile",
                schema={'geometry': 'Point', 'properties': {'text': 'str:254'}}
                ) as c:
            c.write(
                {'geometry': {'type': 'Point', 'coordinates': (0.0, 45.0)},
                 'properties': { 'text': 'a' * 254 }})
        c = fiona.open(os.path.join(self.tempdir, "textfield.shp"), "r")
        self.failUnlessEqual(c.schema['properties']['text'], 'str:254')
        f = next(iter(c))
        self.failUnlessEqual(f['properties']['text'], 'a' * 254)
        c.close()

    def tearDown(self):
        shutil.rmtree(self.tempdir)

class CollectionTest(unittest.TestCase):

    def test_invalid_mode(self):
        self.assertRaises(ValueError, fiona.open, os.path.join(TEMPDIR, "bogus.shp"), "r+")

    def test_w_args(self):
        self.assertRaises(FionaValueError, fiona.open, os.path.join(TEMPDIR, "test-no-iter.shp"), "w")
        self.assertRaises(
            FionaValueError, fiona.open, os.path.join(TEMPDIR, "test-no-iter.shp"), "w", "Driver")

    def test_no_path(self):
        self.assertRaises(IOError, fiona.open, "no-path.shp", "a")

    def test_no_read_conn_str(self):
        self.assertRaises(IOError, fiona.open, "PG:dbname=databasename", "r")

    def test_no_read_directory(self):
        self.assertRaises(ValueError, fiona.open, "/dev/null", "r")

class GeoJSONCRSWritingTest(unittest.TestCase):

    def setUp(self):
        self.tempdir = tempfile.mkdtemp()
        self.filename = os.path.join(self.tempdir, "crs_writing_test.json")
        self.sink = fiona.open(
            self.filename,
            "w",
            driver="GeoJSON",
            schema={
                'geometry': 'Point', 
                'properties': [('title', 'str'), ('date', 'date')]},
            crs={'a': 6370997, 'lon_0': -100, 'y_0': 0, 'no_defs': True, 'proj': 'laea', 'x_0': 0, 'units': 'm', 'b': 6370997, 'lat_0': 45})

    def tearDown(self):
        self.sink.close()
        shutil.rmtree(self.tempdir)

    def test_crs(self):
        """OGR's GeoJSON driver only deals in WGS84"""
        self.sink.close()
        info = subprocess.check_output(
            ["ogrinfo", self.filename, "OGRGeoJSON"])
        self.assert_(
            'GEOGCS["WGS 84' in info.decode('utf-8'),
            info)


########NEW FILE########
__FILENAME__ = test_crs

from fiona import crs

def test_proj_keys():
    assert len(crs.all_proj_keys) == 86
    assert 'init' in crs.all_proj_keys
    assert 'proj' in crs.all_proj_keys
    assert 'no_mayo' in crs.all_proj_keys

def test_from_string():
    # A PROJ.4 string with extra whitespace.
    val = crs.from_string(
        " +proj=longlat +ellps=WGS84 +datum=WGS84  +no_defs +foo  " )
    assert len(val.items()) == 4
    assert val['proj'] == 'longlat'
    assert val['ellps'] == 'WGS84'
    assert val['datum'] == 'WGS84'
    assert val['no_defs'] == True
    assert 'foo' not in val

def test_from_string_utm():
    # A PROJ.4 string with extra whitespace and integer UTM zone.
    val = crs.from_string(
        " +proj=utm +zone=13 +ellps=WGS84 +foo  " )
    assert len(val.items()) == 3
    assert val['proj'] == 'utm'
    assert val['ellps'] == 'WGS84'
    assert val['zone'] == 13
    assert 'foo' not in val

def test_to_string():
    # Make a string from a mapping with a few bogus items
    val = {
        'proj': 'longlat', 'ellps': 'WGS84', 'datum': 'WGS84', 
        'no_defs': True, 'foo': True, 'axis': False, 'belgium': [1,2] }
    assert crs.to_string(
        val) == "+datum=WGS84 +ellps=WGS84 +no_defs +proj=longlat"

def test_to_string_utm():
    # Make a string from a mapping with a few bogus items
    val = {
        'proj': 'utm', 'ellps': 'WGS84', 'zone': 13, 
        'no_defs': True, 'foo': True, 'axis': False, 'belgium': [1,2] }
    assert crs.to_string(
        val) == "+ellps=WGS84 +no_defs +proj=utm +zone=13"

def test_to_string_epsg():
    val = {'init': 'epsg:4326', 'no_defs': True}
    assert crs.to_string(val) == "+init=epsg:4326 +no_defs"

def test_from_epsg():
    val = crs.from_epsg(4326)
    assert val['init'] == "epsg:4326"
    assert val['no_defs'] == True

def test_from_epsg_neg():
    try:
        val = crs.from_epsg(-1)
    except ValueError:
        pass
    except:
        raise

def test_to_string_unicode():
    # See issue #83.
    val = crs.to_string({
        u'units': u'm', 
        u'no_defs': True, 
        u'datum': u'NAD83', 
        u'proj': u'utm', 
        u'zone': 16})
    assert 'NAD83' in val

########NEW FILE########
__FILENAME__ = test_drivers

import logging
import os.path
import shutil
import sys
import tempfile

import fiona

def test_options(tmpdir=None):
    """Test that setting CPL_DEBUG=ON works"""
    if tmpdir is None:
        tempdir = tempfile.mkdtemp()
        logfile = os.path.join(tempdir, 'example.log')
    else:
        logfile = str(tmpdir.join('example.log'))
    logger = logging.getLogger('Fiona')
    logger.setLevel(logging.DEBUG)
    fh = logging.FileHandler(logfile)
    fh.setLevel(logging.DEBUG)
    logger.addHandler(fh)

    with fiona.drivers(CPL_DEBUG=True):
        c = fiona.open("docs/data/test_uk.shp")
        c.close()
        log = open(logfile).read()
        assert "Option CPL_DEBUG" in log

    if tempdir and tmpdir is None:
        shutil.rmtree(tempdir)

########NEW FILE########
__FILENAME__ = test_feature
# testing features, to be called by nosetests

import logging
import os
import shutil
import sys
import tempfile
import unittest

from fiona import collection
from fiona.collection import Collection
from fiona.ogrext import featureRT

#logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)

class PointRoundTripTest(unittest.TestCase):
    def setUp(self):
        self.tempdir = tempfile.mkdtemp()
        schema = {'geometry': 'Point', 'properties': {'title': 'str'}}
        self.c = Collection(os.path.join(self.tempdir, "foo.shp"),
                            "w", driver="ESRI Shapefile", schema=schema)
    def tearDown(self):
        self.c.close()
        shutil.rmtree(self.tempdir)
    def test_geometry(self):
        f = { 'id': '1', 
              'geometry': {'type': 'Point', 'coordinates': (0.0, 0.0)},
              'properties': {'title': u'foo'} }
        g = featureRT(f, self.c)
        self.failUnlessEqual(
            sorted(g['geometry'].items()),
            [('coordinates', (0.0, 0.0)), ('type', 'Point')])
    def test_properties(self):
        f = { 'id': '1', 
              'geometry': {'type': 'Point', 'coordinates': (0.0, 0.0)},
              'properties': {'title': u'foo'} }
        g = featureRT(f, self.c)
        self.failUnlessEqual(g['properties']['title'], 'foo')
    def test_none_property(self):
        f = { 'id': '1',
              'geometry': {'type': 'Point', 'coordinates': (0.0, 0.0)},
              'properties': {'title': None} }
        g = featureRT(f, self.c)
        self.failUnlessEqual(g['properties']['title'], None)

class LineStringRoundTripTest(unittest.TestCase):
    def setUp(self):
        self.tempdir = tempfile.mkdtemp()
        schema = {'geometry': 'LineString', 'properties': {'title': 'str'}}
        self.c = Collection(os.path.join(self.tempdir, "foo.shp"),
                            "w", "ESRI Shapefile", schema=schema)
    def tearDown(self):
        self.c.close()
        shutil.rmtree(self.tempdir)
    def test_geometry(self):
        f = { 'id': '1', 
              'geometry': { 'type': 'LineString', 
                            'coordinates': [(0.0, 0.0), (1.0, 1.0)] },
              'properties': {'title': u'foo'} }
        g = featureRT(f, self.c)
        self.failUnlessEqual(
            sorted(g['geometry'].items()),
            [('coordinates', [(0.0, 0.0), (1.0, 1.0)]), 
             ('type', 'LineString')])
    def test_properties(self):
        f = { 'id': '1',
              'geometry': {'type': 'Point', 'coordinates': (0.0, 0.0)},
              'properties': {'title': u'foo'} }
        g = featureRT(f, self.c)
        self.failUnlessEqual(g['properties']['title'], 'foo')

class PolygonRoundTripTest(unittest.TestCase):
    def setUp(self):
        self.tempdir = tempfile.mkdtemp()
        schema = {'geometry': 'Polygon', 'properties': {'title': 'str'}}
        self.c = Collection(os.path.join(self.tempdir, "foo.shp"),
                            "w", "ESRI Shapefile", schema=schema)
    def tearDown(self):
        self.c.close()
        shutil.rmtree(self.tempdir)
    def test_geometry(self):
        f = { 'id': '1', 
              'geometry': { 'type': 'Polygon', 
                            'coordinates': 
                                [[(0.0, 0.0), 
                                  (0.0, 1.0), 
                                  (1.0, 1.0), 
                                  (1.0, 0.0), 
                                  (0.0, 0.0)]] },
              'properties': {'title': u'foo'} }
        g = featureRT(f, self.c)
        self.failUnlessEqual(
            sorted(g['geometry'].items()),
            [('coordinates', [[(0.0, 0.0), 
                                  (0.0, 1.0), 
                                  (1.0, 1.0), 
                                  (1.0, 0.0), 
                                  (0.0, 0.0)]]), 
             ('type', 'Polygon')])
    def test_properties(self):
        f = { 'id': '1', 
              'geometry': { 'type': 'Polygon', 
                            'coordinates': 
                                [[(0.0, 0.0), 
                                  (0.0, 1.0), 
                                  (1.0, 1.0), 
                                  (1.0, 0.0), 
                                  (0.0, 0.0)]] },
              'properties': {'title': u'foo'} }
        g = featureRT(f, self.c)
        self.failUnlessEqual(g['properties']['title'], 'foo')


########NEW FILE########
__FILENAME__ = test_geojson

import logging
import os
import shutil
import sys
import tempfile
import unittest

import fiona
from fiona.collection import supported_drivers
from fiona.errors import FionaValueError, DriverError, SchemaError, CRSError

logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)


class ReadingTest(unittest.TestCase):
    
    def setUp(self):
        self.c = fiona.open('docs/data/test_uk.json', 'r')
    
    def tearDown(self):
        self.c.close()

    def test_json(self):
        self.assertEquals(len(self.c), 48)

class WritingTest(unittest.TestCase):

    def setUp(self):
        self.tempdir = tempfile.mkdtemp()

    def tearDown(self):
        shutil.rmtree(self.tempdir)

    def test_json(self):
        path = os.path.join(self.tempdir, 'foo.json')
        with fiona.open(path, 'w', 
                driver='GeoJSON', 
                schema={'geometry': 'Unknown', 'properties': [('title', 'str')]}) as c:
            c.writerecords([{
                'geometry': {'type': 'Point', 'coordinates': [0.0, 0.0]},
                'properties': {'title': 'One'}}])
            c.writerecords([{
                'geometry': {'type': 'MultiPoint', 'coordinates': [[0.0, 0.0]]},
                'properties': {'title': 'Two'}}])
        with fiona.open(path) as c:
            self.assertEquals(c.schema['geometry'], 'Unknown')
            self.assertEquals(len(c), 2)

########NEW FILE########
__FILENAME__ = test_geometry
# testing geometry extension, to be called by nosetests

import logging
import sys
import unittest

from fiona.ogrext import GeomBuilder, geometryRT

logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)

def geometry_wkb(wkb):
    return GeomBuilder().build_wkb(wkb)


class OGRBuilderExceptionsTest(unittest.TestCase):
    def test(self):
        geom = {'type': "Bogus", 'coordinates': None}
        self.assertRaises(ValueError, geometryRT, geom)

# The round tripping tests are defined in this not to be run base class.
#
class RoundTripping(object):
    """Derive type specific classes from this."""
    def test_type(self):
        self.failUnlessEqual(
            geometryRT(self.geom)['type'], self.geom['type'])
    def test_coordinates(self):
        self.failUnlessEqual(
            geometryRT(self.geom)['coordinates'], self.geom['coordinates'])

# All these get their tests from the RoundTripping class.
#
class PointRoundTripTest(unittest.TestCase, RoundTripping):
    def setUp(self):
        self.geom = {'type': "Point", 'coordinates': (0.0, 0.0)}

class LineStringRoundTripTest(unittest.TestCase, RoundTripping):
    def setUp(self):
        self.geom = {
            'type': "LineString", 
            'coordinates': [(0.0, 0.0), (1.0, 1.0)]}

class PolygonRoundTripTest1(unittest.TestCase, RoundTripping):
    """An explicitly closed polygon."""
    def setUp(self):
        self.geom = {
            'type': "Polygon", 
            'coordinates': [
                [(0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0)]]}

class PolygonRoundTripTest2(unittest.TestCase, RoundTripping):
    """An implicitly closed polygon."""
    def setUp(self):
        self.geom = {
            'type': "Polygon", 
            'coordinates': [
                [(0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (1.0, 0.0)]]}
    def test_coordinates(self):
        self.failUnlessEqual(
            [geometryRT(self.geom)['coordinates'][0][:-1]], 
            self.geom['coordinates'])

class MultiPointRoundTripTest(unittest.TestCase, RoundTripping):
    def setUp(self):
        self.geom = {
            'type': "MultiPoint", 'coordinates': [(0.0, 0.0), (1.0, 1.0)]}

class MultiLineStringRoundTripTest(unittest.TestCase, RoundTripping):
    def setUp(self):
        self.geom = {
            'type': "MultiLineString", 
            'coordinates': [[(0.0, 0.0), (1.0, 1.0)]]}

class MultiPolygonRoundTripTest1(unittest.TestCase, RoundTripping):
    def setUp(self):
        # This is an explicitly closed polygon.
        self.geom = {
            'type': "MultiPolygon", 
            'coordinates': [[
                [(0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0)]
                ]]}

class MultiPolygonRoundTripTest2(unittest.TestCase, RoundTripping):
    def setUp(self):
        # This is an implicitly closed polygon.
        self.geom = {
            'type': "MultiPolygon", 
            'coordinates': 
                [[[(0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (1.0, 0.0)]]]}
    def test_coordinates(self):
        self.failUnlessEqual(
            [[geometryRT(self.geom)['coordinates'][0][0][:-1]]], 
            self.geom['coordinates'])

class GeometryCollectionRoundTripTest(unittest.TestCase):
    def setUp(self):
        self.geom = {
            'type': "GeometryCollection",
            'geometries': [
                {'type': "Point", 'coordinates': (0.0, 0.0)}, {
                    'type': "LineString", 
                    'coordinates': [(0.0, 0.0), (1.0, 1.0)]}]}
    def test_len(self):
        result = geometryRT(self.geom)
        self.failUnlessEqual(len(result['geometries']), 2)
    def test_type(self):
        result = geometryRT(self.geom)
        self.failUnlessEqual(
            [g['type'] for g in result['geometries']], 
            ['Point', 'LineString'])

class PointTest(unittest.TestCase):
    def test_point(self):
        # Hex-encoded Point (0 0)
        try:
            wkb = bytes.fromhex("010100000000000000000000000000000000000000")
        except:
            wkb = "010100000000000000000000000000000000000000".decode('hex')
        geom = geometry_wkb(wkb)
        self.failUnlessEqual(geom['type'], "Point")
        self.failUnlessEqual(geom['coordinates'], (0.0, 0.0))

class LineStringTest(unittest.TestCase):
    def test_line(self):
        # Hex-encoded LineString (0 0, 1 1)
        try:
            wkb = bytes.fromhex("01020000000200000000000000000000000000000000000000000000000000f03f000000000000f03f")
        except:
            wkb = "01020000000200000000000000000000000000000000000000000000000000f03f000000000000f03f".decode('hex')
        geom = geometry_wkb(wkb)
        self.failUnlessEqual(geom['type'], "LineString")
        self.failUnlessEqual(geom['coordinates'], [(0.0, 0.0), (1.0, 1.0)])

class PolygonTest(unittest.TestCase):
    def test_polygon(self):
        # 1 x 1 box (0, 0, 1, 1)
        try:
            wkb = bytes.fromhex("01030000000100000005000000000000000000f03f0000000000000000000000000000f03f000000000000f03f0000000000000000000000000000f03f00000000000000000000000000000000000000000000f03f0000000000000000")
        except:
            wkb = "01030000000100000005000000000000000000f03f0000000000000000000000000000f03f000000000000f03f0000000000000000000000000000f03f00000000000000000000000000000000000000000000f03f0000000000000000".decode('hex')
        geom = geometry_wkb(wkb)
        self.failUnlessEqual(geom['type'], "Polygon")
        self.failUnlessEqual(len(geom['coordinates']), 1)
        self.failUnlessEqual(len(geom['coordinates'][0]), 5)
        x, y = zip(*geom['coordinates'][0])
        self.failUnlessEqual(min(x), 0.0)
        self.failUnlessEqual(min(y), 0.0)
        self.failUnlessEqual(max(x), 1.0)
        self.failUnlessEqual(max(y), 1.0)

class MultiPointTest(unittest.TestCase):
    def test_multipoint(self):
        try:
            wkb = bytes.fromhex("0104000000020000000101000000000000000000000000000000000000000101000000000000000000f03f000000000000f03f")
        except:
            wkb = "0104000000020000000101000000000000000000000000000000000000000101000000000000000000f03f000000000000f03f".decode('hex')
        geom = geometry_wkb(wkb)
        self.failUnlessEqual(geom['type'], "MultiPoint")
        self.failUnlessEqual(geom['coordinates'], [(0.0, 0.0), (1.0, 1.0)])

class MultiLineStringTest(unittest.TestCase):
    def test_multilinestring(self):
        # Hex-encoded LineString (0 0, 1 1)
        try:
            wkb = bytes.fromhex("01050000000100000001020000000200000000000000000000000000000000000000000000000000f03f000000000000f03f")
        except:
            wkb = "01050000000100000001020000000200000000000000000000000000000000000000000000000000f03f000000000000f03f".decode('hex')
        geom = geometry_wkb(wkb)
        self.failUnlessEqual(geom['type'], "MultiLineString")
        self.failUnlessEqual(len(geom['coordinates']), 1)
        self.failUnlessEqual(len(geom['coordinates'][0]), 2)
        self.failUnlessEqual(geom['coordinates'][0], [(0.0, 0.0), (1.0, 1.0)])

class MultiPolygonTest(unittest.TestCase):
    def test_multipolygon(self):
        # [1 x 1 box (0, 0, 1, 1)]
        try:
            wkb = bytes.fromhex("01060000000100000001030000000100000005000000000000000000f03f0000000000000000000000000000f03f000000000000f03f0000000000000000000000000000f03f00000000000000000000000000000000000000000000f03f0000000000000000")
        except:
            wkb = "01060000000100000001030000000100000005000000000000000000f03f0000000000000000000000000000f03f000000000000f03f0000000000000000000000000000f03f00000000000000000000000000000000000000000000f03f0000000000000000".decode('hex')
        geom = geometry_wkb(wkb)
        self.failUnlessEqual(geom['type'], "MultiPolygon")
        self.failUnlessEqual(len(geom['coordinates']), 1)
        self.failUnlessEqual(len(geom['coordinates'][0]), 1)
        self.failUnlessEqual(len(geom['coordinates'][0][0]), 5)
        x, y = zip(*geom['coordinates'][0][0])
        self.failUnlessEqual(min(x), 0.0)
        self.failUnlessEqual(min(y), 0.0)
        self.failUnlessEqual(max(x), 1.0)
        self.failUnlessEqual(max(y), 1.0)


########NEW FILE########
__FILENAME__ = test_layer
import logging
import os
import shutil
import sys
import tempfile
import unittest

import fiona

logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)

from .test_collection import ReadingTest

def test_index_selection():
    with fiona.open('docs/data/test_uk.shp', 'r', layer=0) as c:
        assert len(c) == 48

class FileReadingTest(ReadingTest):
    
    def setUp(self):
        self.c = fiona.open('docs/data/test_uk.shp', 'r', layer='test_uk')
    
    def tearDown(self):
        self.c.close()

    def test_open_repr(self):
        self.failUnlessEqual(
            repr(self.c),
            ("<open Collection 'docs/data/test_uk.shp:test_uk', mode 'r' "
            "at %s>" % hex(id(self.c))))

    def test_closed_repr(self):
        self.c.close()
        self.failUnlessEqual(
            repr(self.c),
            ("<closed Collection 'docs/data/test_uk.shp:test_uk', mode 'r' "
            "at %s>" % hex(id(self.c))))

    def test_name(self):
        self.failUnlessEqual(self.c.name, 'test_uk')

class DirReadingTest(ReadingTest):
    
    def setUp(self):
        self.c = fiona.open("docs/data", "r", layer="test_uk")
    
    def tearDown(self):
        self.c.close()

    def test_open_repr(self):
        self.failUnlessEqual(
            repr(self.c),
            ("<open Collection 'docs/data:test_uk', mode 'r' "
            "at %s>" % hex(id(self.c))))

    def test_closed_repr(self):
        self.c.close()
        self.failUnlessEqual(
            repr(self.c),
            ("<closed Collection 'docs/data:test_uk', mode 'r' "
            "at %s>" % hex(id(self.c))))

    def test_name(self):
        self.failUnlessEqual(self.c.name, 'test_uk')

    def test_path(self):
        self.failUnlessEqual(self.c.path, "docs/data")

class InvalidLayerTest(unittest.TestCase):

    def test_invalid(self):
        self.assertRaises(ValueError, fiona.open, ("docs/data/test_uk.shp"), layer="foo")

    def test_write_numeric_layer(self):
        self.assertRaises(ValueError, fiona.open,
                          (os.path.join(tempfile.gettempdir(), "test-no-iter.shp")),
                          mode='w', layer=0)

########NEW FILE########
__FILENAME__ = test_listing
import logging
import os
import shutil
import sys
import unittest

import fiona
import fiona.ogrext

logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)

def test_single_file_private():
    with fiona.drivers():
        assert fiona.ogrext._listlayers('docs/data/test_uk.shp') == ['test_uk']

def test_single_file():
    assert fiona.listlayers('docs/data/test_uk.shp') == ['test_uk']

def test_directory():
    assert fiona.listlayers('docs/data') == ['test_uk']

def test_directory_trailing_slash():
    assert fiona.listlayers('docs/data/') == ['test_uk']

def test_zip_path():
    assert fiona.listlayers('zip://docs/data/test_uk.zip') == ['test_uk']

def test_zip_path_arch():
    assert fiona.listlayers('/test_uk.shp', vfs='zip://docs/data/test_uk.zip') == ['test_uk']

class ListLayersArgsTest(unittest.TestCase):
    def test_path(self):
        self.assertRaises(TypeError, fiona.listlayers, (1))
    def test_vfs(self):
        self.assertRaises(TypeError, fiona.listlayers, ("/"), vfs=1)
    def test_path_ioerror(self):
        self.assertRaises(IOError, fiona.listlayers, ("foobar"))

def test_parse_path():
    assert fiona.parse_paths("zip://foo.zip") == ("foo.zip", "zip", None)

def test_parse_path2():
    assert fiona.parse_paths("foo") == ("foo", None, None)

def test_parse_vfs():
    assert fiona.parse_paths("/", "zip://foo.zip") == ("/", "zip", "foo.zip")


########NEW FILE########
__FILENAME__ = test_multiconxn
import logging
import os
import shutil
import sys
import tempfile
import unittest

import fiona
from fiona.odict import OrderedDict

logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)

class ReadAccess(unittest.TestCase):
    # To check that we'll be able to get multiple 'r' connections to layers
    # in a single file.
    
    def setUp(self):
        self.c = fiona.open("docs/data/test_uk.shp", "r", layer="test_uk")
    
    def tearDown(self):
        self.c.close()

    def test_meta(self):
        with fiona.open("docs/data/test_uk.shp", "r", layer="test_uk") as c2:
            self.assertEqual(len(self.c), len(c2))
            self.assertEqual(sorted(self.c.schema.items()), sorted(c2.schema.items()))

    def test_meta(self):
        f1 = next(self.c)
        with fiona.open("docs/data/test_uk.shp", "r", layer="test_uk") as c2:
            f2 = next(c2)
            self.assertEqual(f1, f2)

class ReadWriteAccess(unittest.TestCase):
    # To check that we'll be able to read from a file that we're
    # writing to.
    
    def setUp(self):
        self.tempdir = tempfile.mkdtemp()
        self.c = fiona.open(
            os.path.join(self.tempdir, "multi_write_test.shp"),
            "w",
            driver="ESRI Shapefile",
            schema={
                'geometry': 'Point', 
                'properties': [('title', 'str'), ('date', 'date')]},
            crs={'init': "epsg:4326", 'no_defs': True},
            encoding='utf-8')
        self.f = {
            'type': 'Feature',
            'geometry': {'type': 'Point', 'coordinates': (0.0, 0.1)},
            'properties': OrderedDict([('title', 'point one'), ('date', '2012-01-29')])}
        self.c.writerecords([self.f])
        self.c.flush()

    def tearDown(self):
        self.c.close()
        shutil.rmtree(self.tempdir)

    def test_meta(self):
        c2 = fiona.open(os.path.join(self.tempdir, "multi_write_test.shp"), "r")
        self.assertEqual(len(self.c), len(c2))
        self.assertEqual(sorted(self.c.schema.items()), sorted(c2.schema.items()))

    def test_read(self):
        c2 = fiona.open(os.path.join(self.tempdir, "multi_write_test.shp"), "r")
        f2 = next(c2)
        del f2['id']
        self.assertEqual(self.f, f2)

    def test_read_after_close(self):
        c2 = fiona.open(os.path.join(self.tempdir, "multi_write_test.shp"), "r")
        self.c.close()
        f2 = next(c2)
        del f2['id']
        self.assertEqual(self.f, f2)

class LayerCreation(unittest.TestCase):

    def setUp(self):
        self.tempdir = tempfile.mkdtemp()
        self.dir = os.path.join(self.tempdir, 'layer_creation')
        if os.path.exists(self.dir):
            shutil.rmtree(self.dir)
        os.mkdir(self.dir)
        self.c = fiona.open(
            self.dir,
            'w',
            layer='write_test',
            driver='ESRI Shapefile',
            schema={
                'geometry': 'Point', 
                'properties': [('title', 'str'), ('date', 'date')]},
            crs={'init': "epsg:4326", 'no_defs': True},
            encoding='utf-8')
        self.f = {
            'type': 'Feature',
            'geometry': {'type': 'Point', 'coordinates': (0.0, 0.1)},
            'properties': OrderedDict([('title', 'point one'), ('date', '2012-01-29')])}
        self.c.writerecords([self.f])
        self.c.flush()

    def tearDown(self):
        self.c.close()
        shutil.rmtree(self.tempdir)

    def test_meta(self):
        c2 = fiona.open(os.path.join(self.dir, "write_test.shp"), "r")
        self.assertEqual(len(self.c), len(c2))
        self.assertEqual(sorted(self.c.schema.items()), sorted(c2.schema.items()))

    def test_read(self):
        c2 = fiona.open(os.path.join(self.dir, "write_test.shp"), "r")
        f2 = next(c2)
        del f2['id']
        self.assertEqual(self.f, f2)

    def test_read_after_close(self):
        c2 = fiona.open(os.path.join(self.dir, "write_test.shp"), "r")
        self.c.close()
        f2 = next(c2)
        del f2['id']
        self.assertEqual(self.f, f2)


########NEW FILE########
__FILENAME__ = test_props

from six import text_type
from fiona import prop_type, prop_width
from fiona.rfc3339 import FionaDateType

def test_width_str():
    assert prop_width('str:254') == 254
    assert prop_width('str') == 80

def test_width_other():
    assert prop_width('int') == None
    assert prop_width('float') == None
    assert prop_width('date') == None

def test_types():
    assert prop_type('str:254') == text_type
    assert prop_type('str') == text_type
    assert prop_type('int') == type(0)
    assert prop_type('float') == type(0.0)
    assert prop_type('date') == FionaDateType

########NEW FILE########
__FILENAME__ = test_revolvingdoor
# Test of opening and closing and opening

import logging
import os.path
import shutil
import subprocess
import sys
import tempfile
import unittest

import fiona

logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)
log = logging.getLogger('fiona.tests')

class RevolvingDoorTest(unittest.TestCase):

    def setUp(self):
        self.tempdir = tempfile.mkdtemp()
    
    def tearDown(self):
        shutil.rmtree(self.tempdir)

    def test_write_revolving_door(self):

        with fiona.open('docs/data/test_uk.shp') as src:
            meta = src.meta
            features = list(src)

        shpname = os.path.join(self.tempdir, 'foo.shp')
        
        with fiona.open(shpname, 'w', **meta) as dst:
            dst.writerecords(features)

        with fiona.open(shpname) as src:
            pass


########NEW FILE########
__FILENAME__ = test_rfc3339
# testing Fiona's RFC 3339 support, to be called by nosetests

import logging
import re
import sys
import unittest

from fiona.rfc3339 import parse_date, parse_datetime, parse_time
from fiona.rfc3339 import group_accessor, pattern_date

logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)

class DateParseTest(unittest.TestCase):

    def test_yyyymmdd(self):
        self.failUnlessEqual(
            parse_date("2012-01-29"), (2012, 1, 29, 0, 0, 0, 0.0))

    def test_error(self):
        self.assertRaises(ValueError, parse_date, ("xxx"))

class TimeParseTest(unittest.TestCase):
    
    def test_hhmmss(self):
        self.failUnlessEqual(
            parse_time("10:11:12"), (0, 0, 0, 10, 11, 12, 0.0))

    def test_hhmm(self):
        self.failUnlessEqual(
            parse_time("10:11"), (0, 0, 0, 10, 11, 0, 0.0))

    def test_hhmmssff(self):
        self.failUnlessEqual(
            parse_time("10:11:12.42"), 
            (0, 0, 0, 10, 11, 12, 0.42*1000000.0))

    def test_hhmmssz(self):
        self.failUnlessEqual(
            parse_time("10:11:12Z"), (0, 0, 0, 10, 11, 12, 0.0))

    def test_hhmmssoff(self):
        self.failUnlessEqual(
            parse_time("10:11:12-01:00"), (0, 0, 0, 10, 11, 12, 0.0))

    def test_error(self):
        self.assertRaises(ValueError, parse_time, ("xxx"))

class DatetimeParseTest(unittest.TestCase):
    
    def test_yyyymmdd(self):
        self.failUnlessEqual(
            parse_datetime("2012-01-29T10:11:12"), 
            (2012, 1, 29, 10, 11, 12, 0.0))

    def test_error(self):
        self.assertRaises(ValueError, parse_datetime, ("xxx"))

def test_group_accessor_indexerror():
    match = re.search(pattern_date, '2012-01-29')
    g = group_accessor(match)
    assert g.group(-1) == 0
    assert g.group(6) == 0


########NEW FILE########
__FILENAME__ = test_schema
import os
import shutil
import tempfile
import unittest
import fiona

class SchemaOrder(unittest.TestCase):

    def setUp(self):
        self.tempdir = tempfile.mkdtemp()

    def tearDown(self):
        shutil.rmtree(self.tempdir)

    def test_schema_ordering_items(self):
        items = [('title', 'str'), ('date', 'date')]
        with fiona.open(os.path.join(self.tempdir, 'test_schema.shp'), 'w',
                driver="ESRI Shapefile",
                schema={
                    'geometry': 'LineString', 
                    'properties': items }) as c:
            self.assertEqual(list(c.schema['properties'].items()), items)
        with fiona.open(os.path.join(self.tempdir, 'test_schema.shp')) as c:
            self.assertEqual(list(c.schema['properties'].items()), items)

class ShapefileSchema(unittest.TestCase):

    def setUp(self):
        self.tempdir = tempfile.mkdtemp()

    def tearDown(self):
        shutil.rmtree(self.tempdir)

    def test_schema(self):
        items = sorted({
            'AWATER10': 'float',
            'CLASSFP10': 'str',
            'ZipCodeType': 'str',
            'EstimatedPopulation': 'float',
            'LocationType': 'str',
            'ALAND10': 'float',
            'TotalWages': 'float',
            'FUNCSTAT10': 'str',
            'Long': 'float',
            'City': 'str',
            'TaxReturnsFiled': 'float',
            'State': 'str',
            'Location': 'str',
            'GSrchCnt': 'float',
            'INTPTLAT10': 'str',
            'Lat': 'float',
            'MTFCC10': 'str',
            'Decommisioned': 'str',
            'GEOID10': 'str',
            'INTPTLON10': 'str'}.items())
        with fiona.open(os.path.join(self.tempdir, 'test_schema.shp'), 'w',
                driver="ESRI Shapefile",
                schema={
                    'geometry': 'Polygon', 
                    'properties': items }) as c:
            self.assertEqual(list(c.schema['properties'].items()), items)
            c.write(
                {'geometry': {'coordinates': [[(-117.882442, 33.783633),
                                               (-117.882284, 33.783817),
                                               (-117.863348, 33.760016),
                                               (-117.863478, 33.760016),
                                               (-117.863869, 33.760017),
                                                (-117.864, 33.760017999999995),
                                                (-117.864239, 33.760019),
                                                (-117.876608, 33.755769),
                                                (-117.882886, 33.783114),
                                                (-117.882688, 33.783345),
                                                (-117.882639, 33.783401999999995),
                                                (-117.88259, 33.78346),
                                                (-117.882442, 33.783633)]],
                               'type': 'Polygon'},
                 'id': '1',
                 'properties':{
                    'ALAND10': 8819240.0,
                    'AWATER10': 309767.0,
                    'CLASSFP10': 'B5',
                    'City': 'SANTA ANA',
                    'Decommisioned': False,
                    'EstimatedPopulation': 27773.0,
                    'FUNCSTAT10': 'S',
                    'GEOID10': '92706',
                    'GSrchCnt': 0.0,
                    'INTPTLAT10': '+33.7653010',
                    'INTPTLON10': '-117.8819759',
                    'Lat': 33.759999999999998,
                    'Location': 'NA-US-CA-SANTA ANA',
                    'LocationType': 'PRIMARY',
                    'Long': -117.88,
                    'MTFCC10': 'G6350',
                    'State': 'CA',
                    'TaxReturnsFiled': 14635.0,
                    'TotalWages': 521280485.0,
                    'ZipCodeType': 'STANDARD'},
                 'type': 'Feature'} )
            self.assertEqual(len(c), 1)
        with fiona.open(os.path.join(self.tempdir, 'test_schema.shp')) as c:
            self.assertEqual(
                list(c.schema['properties'].items()), 
                sorted([('AWATER10', 'float'), 
                 ('CLASSFP10', 'str'), 
                 ('ZipCodeTyp', 'str'), 
                 ('EstimatedP', 'float'), 
                 ('LocationTy', 'str'), 
                 ('ALAND10', 'float'), 
                 ('INTPTLAT10', 'str'), 
                 ('FUNCSTAT10', 'str'), 
                 ('Long', 'float'), 
                 ('City', 'str'), 
                 ('TaxReturns', 'float'), 
                 ('State', 'str'), 
                 ('Location', 'str'), 
                 ('GSrchCnt', 'float'), 
                 ('TotalWages', 'float'), 
                 ('Lat', 'float'), 
                 ('MTFCC10', 'str'), 
                 ('INTPTLON10', 'str'), 
                 ('GEOID10', 'str'), 
                 ('Decommisio', 'str')]) )
            f = next(c)
            self.assertEqual(f['properties']['EstimatedP'], 27773.0)


########NEW FILE########
__FILENAME__ = test_unicode
# coding: utf-8

import logging
import os
import shutil
import sys
import tempfile
import unittest

import six

import fiona

logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)

class UnicodePathTest(unittest.TestCase):

    def setUp(self):
        tempdir = tempfile.mkdtemp()
        self.dir = os.path.join(tempdir, 'franÃ§ais')
        shutil.copytree('docs/data/', self.dir)

    def tearDown(self):
        shutil.rmtree(os.path.dirname(self.dir))

    def test_unicode_path(self):
        path = self.dir + '/test_uk.shp'
        if sys.version_info < (3,):
            path = path.decode('utf-8')
        with fiona.open(path) as c:
            assert len(c) == 48

    def test_unicode_path_layer(self):
        path = self.dir
        layer = 'test_uk'
        if sys.version_info < (3,):
            path = path.decode('utf-8')
            layer = layer.decode('utf-8')
        with fiona.open(path, layer=layer) as c:
            assert len(c) == 48

    def test_utf8_path(self):
        path = self.dir + '/test_uk.shp'
        if sys.version_info < (3,):
            with fiona.open(path) as c:
                assert len(c) == 48


########NEW FILE########
__FILENAME__ = test_vfs
import logging
import os
import shutil
import sys
import unittest

import fiona

logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)

from .test_collection import ReadingTest


class VsiReadingTest(ReadingTest):
    
    # There's a bug in GDAL 1.9.2 http://trac.osgeo.org/gdal/ticket/5093
    # in which the VSI driver reports the wrong number of features.
    # I'm overriding ReadingTest's test_filter_1 with a function that
    # passes and creating a new method in this class that we can exclude
    # from the test runner at run time.

    def test_filter_vsi(self):
        results = list(self.c.filter(bbox=(-15.0, 35.0, 15.0, 65.0)))
        self.failUnlessEqual(len(results), 48)
        f = results[0]
        self.failUnlessEqual(f['id'], "0")
        self.failUnlessEqual(f['properties']['FIPS_CNTRY'], 'UK')

class ZipReadingTest(VsiReadingTest):
    
    def setUp(self):
        self.c = fiona.open("zip://docs/data/test_uk.zip", "r")
    
    def tearDown(self):
        self.c.close()

    def test_open_repr(self):
        self.failUnlessEqual(
            repr(self.c),
            ("<open Collection '/vsizip/docs/data/test_uk.zip:test_uk', mode 'r' "
            "at %s>" % hex(id(self.c))))

    def test_closed_repr(self):
        self.c.close()
        self.failUnlessEqual(
            repr(self.c),
            ("<closed Collection '/vsizip/docs/data/test_uk.zip:test_uk', mode 'r' "
            "at %s>" % hex(id(self.c))))

    def test_path(self):
        self.failUnlessEqual(self.c.path, '/vsizip/docs/data/test_uk.zip')

class ZipArchiveReadingTest(VsiReadingTest):
    
    def setUp(self):
        self.c = fiona.open("/test_uk.shp", "r", vfs="zip://docs/data/test_uk.zip")
    
    def tearDown(self):
        self.c.close()

    def test_open_repr(self):
        self.failUnlessEqual(
            repr(self.c),
            ("<open Collection '/vsizip/docs/data/test_uk.zip/test_uk.shp:test_uk', mode 'r' "
            "at %s>" % hex(id(self.c))))

    def test_closed_repr(self):
        self.c.close()
        self.failUnlessEqual(
            repr(self.c),
            ("<closed Collection '/vsizip/docs/data/test_uk.zip/test_uk.shp:test_uk', mode 'r' "
            "at %s>" % hex(id(self.c))))

    def test_path(self):
        self.failUnlessEqual(self.c.path, '/vsizip/docs/data/test_uk.zip/test_uk.shp')

class TarArchiveReadingTest(VsiReadingTest):
    
    def setUp(self):
        self.c = fiona.open("/testing/test_uk.shp", "r", vfs="tar://docs/data/test_uk.tar")
    
    def tearDown(self):
        self.c.close()

    def test_open_repr(self):
        self.failUnlessEqual(
            repr(self.c),
            ("<open Collection '/vsitar/docs/data/test_uk.tar/testing/test_uk.shp:test_uk', mode 'r' "
            "at %s>" % hex(id(self.c))))

    def test_closed_repr(self):
        self.c.close()
        self.failUnlessEqual(
            repr(self.c),
            ("<closed Collection '/vsitar/docs/data/test_uk.tar/testing/test_uk.shp:test_uk', mode 'r' "
            "at %s>" % hex(id(self.c))))

    def test_path(self):
        self.failUnlessEqual(self.c.path, '/vsitar/docs/data/test_uk.tar/testing/test_uk.shp')


########NEW FILE########
